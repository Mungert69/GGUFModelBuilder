[
  {
    "input": "What are the key reasons why people may not be as concerned about online privacy as they should be, and how can they protect themselves in the digital world?",
    "summary": "This book explains how to protect your privacy in the digital age, emphasizing that everyone is being watched. It covers topics like encryption, password security, and hiding your online presence. The author, Kevin Mitnick, shares his expertise to help readers take control of their personal information and avoid surveillance.",
    "output": "Copyright\nCopyright © 2017 by Kevin Mitnick Foreword copyright © 2017 by\nMikko Hypponen Cover design by Julianna Lee\nAuthor photograph by Tolga Katas\nCover copyright © 2017 by Hachette Book Group, Inc.\nHachette Book Group supports the right to free expression and the value of\ncopyright. The purpose of copyright is to encourage writers and artists to\nproduce the creative works that enrich our culture.\nThe scanning, uploading, and distribution of this book without permission\nis a theft of the author’s intellectual property. If you would like permission\nto use material from the book (other than for review purposes), please\ncontact permissions@hbgusa.com. Thank you for your support of the\nauthor’s rights.\nLittle, Brown and Company\nHachette Book Group\n1290 Avenue of the Americas, New York, NY 10104\nlittlebrown.com\ntwitter.com/littlebrown\nfacebook.com/littlebrownandcompany\nFirst ebook edition: February 2017\nLittle, Brown and Company is a division of Hachette Book Group, Inc. The\nLittle, Brown name and logo are trademarks of Hachette Book Group, Inc.\nThe publisher is not responsible for websites (or their content) that are not\nowned by the publisher.\nThe Hachette Speakers Bureau provides a wide range of authors for\nspeaking events. To find out more, go to hachettespeakersbureau.com or\ncall (866) 376-6591.\nISBN 978-0-316-38049-2\nE3-20161223-JV-PC\nContents\nCover\nTitle Page\nCopyright\nDedication\nForeword by Mikko Hypponen\nIntroduction | Time to Disappear\nChapter One | Your Password Can Be Cracked!\nChapter Two | Who Else Is Reading Your E-mail?\nChapter Three | Wiretapping 101\nChapter Four | If You Don’t Encrypt, You’re Unequipped\nChapter Five | Now You See Me, Now You Don’t\nChapter Six | Every Mouse Click You Make, I’ll Be Watching You\nChapter Seven | Pay Up or Else!\nChapter Eight | Believe Everything, Trust Nothing\nChapter Nine | You Have No Privacy? Get Over It!\nChapter Ten | You Can Run but Not Hide\nChapter Eleven | Hey, KITT, Don’t Share My Location\nChapter Twelve | The Internet of Surveillance\nChapter Thirteen | Things Your Boss Doesn’t Want You to Know\nChapter Fourteen | Obtaining Anonymity Is Hard Work\nChapter Fifteen | The FBI Always Gets Its Man\nChapter Sixteen | Mastering the Art of Invisibility\nAcknowledgments\nAbout the Authors\nBooks by Kevin Mitnick\nNotes\nNewsletters\nTo my loving mother, Shelly\nJaffe,\nand my grandmother Reba\nVartanian\nForeword by Mikko Hypponen\nA couple of months ago\n, I met up with an old friend who I hadn’t\nseen since high school. We went for a cup of coffee to catch up on what\neach of us had been doing for the past decades. He told me about his work\nof distributing and supporting various types of modern medical devices,\nand I explained how I’ve spent the last twenty-five years working with\nInternet security and privacy. My friend let out a chuckle when I\nmentioned online privacy. “That sounds all fine and dandy,” he said, “but\nI’m not really worried. After all, I’m not a criminal, and I’m not doing\nanything bad. I don’t care if somebody looks at what I’m doing online.”\nListening to my old friend, and his explanation on why privacy does\nnot matter to him, I was saddened. I was saddened because I’ve heard\nthese arguments before, many times. I hear them from people who think\nthey have nothing to hide. I hear them from people who think only\ncriminals need to protect themselves. I hear them from people who think\nonly terrorists use encryption. I hear them from people who think we don’t\nneed to protect our rights. But we do need to protect our rights. And\nprivacy does not just affect our rights, it is a human right. In fact, privacy\nis recognized as a fundamental human right in the 1948 United Nations\nUniversal Declaration of Human Rights.\nIf our privacy needed protection in 1948, it surely needs it much more\ntoday. After all, we are the first generation in human history that can be\nmonitored at such a precise level. We can be monitored digitally\nthroughout our lives. Almost all of our communications can be seen one\nway or another. We even carry small tracking devices on us all the time—\nwe just don’t call them tracking devices, we call them smartphones.\nOnline monitoring can see what books we buy and what news articles\nwe read—even which parts of the articles are most interesting to us. It can\nsee where we travel and who we travel with. And online monitoring knows\nif you are sick, or sad, or horny. Much of the monitoring that is done today\ncompiles this data to make money. Companies that offer free services\nsomehow convert those free services into billions of dollars of revenue—\nnicely illustrating just how valuable it is to profile Internet users in mass\nscale. However, there’s also more targeted monitoring: the kind of\nmonitoring done by government agencies, domestic or foreign.\nDigital communication has made it possible for governments to do\nbulk surveillance. But it has also enabled us to protect ourselves better. We\ncan protect ourselves with tools like encryption, by storing our data in safe\nways, and by following basic principles of operations security (OPSEC).\nWe just need a guide on how to do it right.\nWell, the guide you need is right here in your hands. I’m really happy\nKevin took the time to write down his knowledge on the art of invisibility.\nAfter all, he knows a thing or two about staying invisible. This is a great\nresource. Read it and use the knowledge to your advantage. Protect\nyourself and protect your rights.\nBack at the cafeteria, after I had finished coffee with my old friend, we\nparted ways. I wished him well, but I still sometimes think about his\nwords: “I don’t care if somebody looks at what I’m doing online.” You\nmight not have anything to hide, my friend. But you have everything to\nprotect.\nMikko Hypponen is the chief research officer of F-Secure. He’s the only\nliving person who has spoken at both DEF CON and TED conferences.\nINTRODUCTION\nTime to Disappear\nAlmost two years to the\nday after Edward Joseph Snowden, a\ncontractor for Booz Allen Hamilton, first disclosed his cache of secret\nmaterial taken from the National Security Agency (NSA), HBO comedian\nJohn Oliver went to Times Square in New York City to survey people at\nrandom for a segment of his show on privacy and surveillance. His\nquestions were clear. Who is Edward Snowden? What did he do?1\nIn the interview clips Oliver aired, no one seemed to know. Even when\npeople said they recalled the name, they couldn’t say exactly what\nSnowden had done (or why). After becoming a contractor for the NSA,\nEdward Snowden copied thousands of top secret and classified documents\nthat he subsequently gave to reporters so they could make them public\naround the world. Oliver could have ended his show’s segment about\nsurveillance on a depressing note—after years of media coverage, no one\nin America really seemed to care about domestic spying by the\ngovernment—but the comedian chose another tack. He flew to Russia,\nwhere Snowden now lives in exile, for a one-on-one interview.2\nThe first question Oliver put to Snowden in Moscow was: What did you\nhope to accomplish? Snowden answered that he wanted to show the world\nwhat the NSA was doing—collecting data on almost everyone. When\nOliver showed him the interviews from Times Square, in which one person\nafter another professed not to know who Snowden was, his response was,\n“Well, you can’t have everyone well informed.”\nWhy aren’t we more informed when it comes to the privacy issues that\nSnowden and others have raised? Why don’t we seem to care that a\ngovernment agency is wiretapping our phone calls, our e-mails, and even\nour text messages? Probably because the NSA, by and large, doesn’t\ndirectly affect the lives of most of us—at least not in a tangible way, as an\nintrusion that we can feel.\nBut as Oliver also discovered in Times Square that day, Americans do\ncare about privacy when it hits home. In addition to asking questions about\nSnowden, he asked general questions about privacy. For example, when he\nasked how they felt about a secret (but made-up) government program that\nrecords images of naked people whenever the images are sent over the\nInternet, the response among New Yorkers was also universal—except this\ntime everyone opposed it, emphatically. One person even admitted to\nhaving recently sent such a photo.\nEveryone interviewed in the Times Square segment agreed that people\nin the United States should be able to share anything—even a photo of a\npenis—privately over the Internet. Which was Snowden’s basic point.\nIt turns out that the fake government program that records naked\npictures is less far-fetched than you might imagine. As Snowden explained\nto Oliver in their interview, because companies like Google have servers\nphysically located all over the world, even a simple message (perhaps\nincluding nudity) between a husband and wife within the same US city\nmight first bounce off a foreign server. Since that data leaves the United\nStates, even for a nanosecond, the NSA could, thanks to the Patriot Act,\ncollect and archive that text or e-mail (including the indecent photo)\nbecause it technically entered the United States from a foreign source at\nthe moment when it was captured. Snowden’s point: average Americans\nare being caught up in a post-9/11 dragnet that was initially designed to\nstop foreign terrorists but that now spies on practically everyone.\nYou would think, given the constant news about data breaches and\nsurveillance campaigns by the government, that we’d be much more\noutraged. You would think that given how fast this happened—in just a\nhandful of years—we’d be reeling from the shock and marching in the\nstreets. Actually, the opposite is true. Many of us, even many readers of\nthis book, now accept to at least some degree the fact that everything we\ndo—all our phone calls, our texts, our e-mails, our social media—can be\nseen by others.\nAnd that’s disappointing.\nPerhaps you have broken no laws. You live what you think is an\naverage and quiet life, and you feel you are unnoticed among the crowds\nof others online today. Trust me: even you are not invisible. At least not\nyet.\nI enjoy magic, and some might argue that sleight of hand is necessary for\ncomputer hacking. One popular magic trick is to make an object invisible.\nThe secret, however, is that the object does not physically disappear or\nactually become invisible. The object always remains in the background,\nbehind a curtain, up a sleeve, in a pocket, whether we can see it or not.\nThe same is true of the many personal details about each and every one\nof us that are currently being collected and stored, often without our\nnoticing. Most of us simply don’t know how easy it is for others to view\nthese details about us or even where to look. And because we don’t see this\ninformation, we might believe that we are invisible to our exes, our\nparents, our schools, our bosses, and even our governments.\nThe problem is that if you know where to look, all that information is\navailable to just about anyone.\nWhenever I speak before large crowds—no matter the size of the room\n—I usually have one person who challenges me on this fact. After one\nsuch event I was challenged by a very skeptical reporter.\nI remember we were seated at a private table in a hotel bar in a large\nUS city when the reporter said she’d never been a victim of a data breach.\nGiven her youth, she said she had relatively few assets to her name, hence\nfew records. She never put personal details into any of her stories or her\npersonal social media—she kept it professional. She considered herself\ninvisible. So I asked her for permission to find her Social Security number\nand any other personal details online. Reluctantly she agreed.\nWith her seated nearby I logged in to a site, one that is reserved for\nprivate investigators. I qualify as the latter through my work investigating\nhacking incidents globally. I already knew her name, so I asked where she\nlived. This I could have found on the Internet as well, on another site, if\nshe hadn’t told me.\nIn a couple of minutes I knew her Social Security number, her city of\nbirth, and even her mother’s maiden name. I also knew all the places she’d\never called home and all the phone numbers she’d ever used. Staring at the\nscreen, with a surprised look on her face, she confirmed that all the\ninformation was more or less true.\nThe site I used is restricted to vetted companies or individuals. It\ncharges a low fee per month plus additional costs for any information\nlookups, and from time to time it will audit me to find out whether I have\na legitimate purpose for conducting a particular search.\nBut similar information about anyone can be found for a small lookup\nfee. And it’s perfectly legal.\nHave you ever filled out an online form, submitted information to a\nschool or organization that puts its information online, or had a legal case\nposted to the Internet? If so, you have volunteered personal information to\na third party that may do with the information what it pleases. Chances are\nthat some—if not all—of that data is now online and available to\ncompanies that make it their business to collect every bit of personal\ninformation off the Internet. The Privacy Rights Clearinghouse lists more\nthan 130 companies that collect personal information (whether or not it’s\naccurate) about you.3\nAnd then there’s the data that you don’t volunteer online but that is\nnonetheless being harvested by corporations and governments—\ninformation about whom we e-mail, text, and call; what we search for\nonline; what we buy, either in a brick-and-mortar or an online store; and\nwhere we travel, on foot or by car. The volume of data collected about\neach and every one of us is growing exponentially each day.\nYou may think you don’t need to worry about this. Trust me: you do. I\nhope that by the end of this book you will be both well-informed and\nprepared enough to do something about it.\nThe fact is that we live with an illusion of privacy, and we probably have\nbeen living this way for decades.\nAt a certain point, we might find ourselves uncomfortable with how\nmuch access our government, our employers, our bosses, our teachers, and\nour parents have into our personal lives. But since that access has been\ngained gradually, since we’ve embraced each small digital convenience\nwithout resisting its impact on our privacy, it becomes increasingly hard to\nturn back the clock. Besides, who among us wants to give up our toys?\nThe danger of living within a digital surveillance state isn’t so much\nthat the data is being collected (there’s little we can do about that) but\nwhat is done with the data once it is collected.\nImagine what an overzealous prosecutor could do with the large dossier\nof raw data points available on you, perhaps going back several years.\nData today, sometimes collected out of context, will live forever. Even US\nSupreme Court justice Stephen Breyer agrees that it is “difficult for\nanyone to know, in advance, just when a particular set of statements might\nlater appear (to a prosecutor) to be relevant to some such investigation.”4\nIn other words, a picture of you drunk that someone posted on Facebook\nmight be the least of your concerns.\nYou may think you have nothing to hide, but do you know that for sure?\nIn a well-argued opinion piece in Wired, respected security researcher\nMoxie Marlinspike points out that something as simple as being in\npossession of a small lobster is actually a federal crime in the United\nStates.5 “It doesn’t matter if you bought it at a grocery store, if someone\nelse gave it to you, if it’s dead or alive, if you found it after it died of\nnatural causes, or even if you killed it while acting in self-defense. You\ncan go to jail because of a lobster.”6 The point here is there are many\nminor, unenforced laws that you could be breaking without knowing it.\nExcept now there’s a data trail to prove it just a few taps away, available to\nany person who wants it.\nPrivacy is complex. It is not a one-size-fits-all proposition. We all have\ndifferent reasons for sharing some information about ourselves freely with\nstrangers and keeping other parts of our lives private. Maybe you simply\ndon’t want your significant other reading your personal stuff. Maybe you\ndon’t want your employer to know about your private life. Or maybe you\nreally do fear that a government agency is spying on you.\nThese are very different scenarios, so no one recommendation offered\nhere is going to fit them all. Because we hold complicated and therefore\nvery different attitudes toward privacy, I’ll guide you through what’s\nimportant—what’s happening today with surreptitious data collection—\nand let you decide what works for your own life.\nIf anything, this book will make you aware of ways to be private within\nthe digital world and offer solutions that you may or may not choose to\nadopt. Since privacy is a personal choice, degrees of invisibility, too, will\nvary by individual.\nIn this book I’ll make the case that each and every one of us is being\nwatched, at home and out in the world—as you walk down the street, sit at\na café, or drive down the highway. Your computer, your phone, your car,\nyour home alarm system, even your refrigerator are all potential points of\naccess into your private life.\nThe good news is, in addition to scaring you, I’m also going to show\nyou what to do about the lack of privacy—a situation that has become the\nnorm.\nIn this book, you’ll learn how to:\nencrypt and send a secure e-mail\nprotect your data with good password management\nhide your true IP address from places you visit\nobscure your computer from being tracked\ndefend your anonymity\nand much more\nNow, get ready to master the art of invisibility."
  },
  {
    "input": "What steps can individuals take to protect their online accounts and personal devices from unauthorized access and data breaches?",
    "summary": "The Jennifer Lawrence incident in 2014 highlighted how private photos can be leaked through weak passwords and cloud vulnerabilities. Strong, unique passwords and two-factor authentication (2FA) are essential to protect online accounts, as even common passwords can be easily cracked. 2FA adds an extra layer of security by requiring a second form of verification, such as a code sent to a phone, making it much harder for attackers to gain access.",
    "output": "CHAPTER ONE\nYour Password Can Be Cracked!\nJennifer Lawrence was having a\nrough Labor Day weekend.\nThe Academy Award winner was one of several celebrities who woke one\nmorning in 2014 to find that their most private pictures—many of which\nshowed them in the nude—were being splashed about on the Internet.\nTake a moment to mentally scan all the images that are currently stored\non your computer, phone, and e-mail. Sure, many of them are perfectly\nbenign. You’d be fine with the whole world seeing the sunsets, the cute\nfamily snapshots, maybe even the jokey bad-hair-day selfie. But would\nyou be comfortable sharing each and every one of them? How would you\nfeel if they suddenly all appeared online? Maybe not all our personal\nphotos are salacious, but they’re still records of private moments. We\nshould be able to decide whether, when, and how to share them, yet with\ncloud services the choice may not always be ours.\nThe Jennifer Lawrence story dominated the slow Labor Day weekend\nnews cycle in 2014. It was part of an event called theFappening, a huge\nleak of nude and nearly nude photographs of Rihanna, Kate Upton, Kaley\nCuoco, Adrianne Curry, and almost three hundred other celebrities, most\nof them women, whose cell-phone images had somehow been remotely\naccessed and shared. While some people were, predictably, interested in\nseeing these photos, for many the incident was an unsettling reminder that\nthe same thing could have happened to them.\nSo how did someone get access to those private images of Jennifer\nLawrence and others?\nSince all the celebrities used iPhones, early speculation centered on a\nmassive data breach affecting Apple’s iCloud service, a cloud-storage\noption for iPhone users. As your physical device runs out of memory, your\nphotos, new files, music, and games are instead stored on a server at\nApple, usually for a small monthly fee. Google offers a similar service for\nAndroid.\nApple, which almost never comments in the media on security issues,\ndenied any fault on their end. The company issued a statement calling the\nincident a “very targeted attack on user names, passwords, and security\nquestions” and added that “none of the cases we have investigated has\nresulted from any breach in any of Apple’s systems including iCloud or\nFind my iPhone.”1\nThe photos first started appearing on a hacker forum well known for\nposting compromised photos.2 Within that forum you can find active\ndiscussions of the digital forensic tools used for surreptitiously obtaining\nsuch photos. Researchers, investigators, and law enforcement use these\ntools to access data from devices or the cloud, usually following a crime.\nAnd of course the tools have other uses as well.\nOne of the tools openly discussed on the forum, Elcomsoft Phone\nPassword Breaker, or EPPB, is intended to enable law enforcement and\ngovernment agencies to access iCloud accounts and is sold publicly. It is\njust one of many tools out there, but it appears to be the most popular on\nthe forum. EPPB requires that users have the target’s iCloud username and\npassword information first. For people using this forum, however,\nobtaining iCloud usernames and passwords is not a problem. It so\nhappened that over that holiday weekend in 2014, someone posted to a\npopular online code repository (Github) a tool called iBrute, a password-\nhacking mechanism specifically designed for acquiring iCloud credentials\nfrom just about anyone.\nUsing iBrute and EPPB together, someone could impersonate a victim\nand download a full backup of that victim’s cloud-stored iPhone data onto\nanother device. This capability is useful when you upgrade your phone, for\nexample. It is also valuable to an attacker, who then can see everything\nyou’ve ever done on your mobile device. This yields much more\ninformation than just logging in to a victim’s iCloud account.\nJonathan Zdziarski, a forensics consultant and security researcher, told\nWired that his examination of the leaked photos from Kate Upton, for\nexample, was consistent with the use of iBrute and EPPB. Having access\nto a restored iPhone backup gives an attacker lots of personal information\nthat might later be useful for blackmail.3\nIn October 2016, Ryan Collins, a thirty-six-year-old from Lancaster,\nPennsylvania, was sentenced to eighteen months in prison for\n“unauthorized access to a protected computer to obtain information”\nrelated to the hack. He was charged with illegal access to over one hundred\nApple and Google e-mail accounts.4\nTo protect your iCloud and other online accounts, you must set a strong\npassword. That’s obvious. Yet in my experience as a penetration tester\n(pen tester)—someone who is paid to hack into computer networks and\nfind vulnerabilities—I find that many people, even executives at large\ncorporations, are lazy when it comes to passwords. Consider that the CEO\nof Sony Entertainment, Michael Lynton, used “sonyml3” as his domain\naccount password. It’s no wonder his e-mails were hacked and spread\nacross the Internet since the attackers had administrative access to most\neverything within the company.\nBeyond your work-related passwords are those passwords that protect\nyour most personal accounts. Choosing a hard-to-guess password won’t\nprevent hacking tools such as oclHashcat (a password-cracking tool that\nleverages graphics processing units—or GPUs—for high-speed cracking)\nfrom possibly cracking your password, but it will make the process slow\nenough to encourage an attacker to move on to an easier target.\nIt’s a fair guess that some of the passwords exposed during the July\n2015 Ashley Madison hack are certainly being used elsewhere, including\non bank accounts and even work computers. From the lists of 11 million\nAshley Madison passwords posted online, the most common were\n“123456,” “12345,” “password,” “DEFAULT,” “123456789,” “qwerty,”\n“12345678,” “abc123,” and “1234567.”5 If you see one of your own\npasswords here, chances are you are vulnerable to a data breach, as these\ncommon terms are included in most password-cracking tool kits available\nonline. You can always check the site www.haveibeenpwned.com to see if\nyour account has been compromised in the past.\nIn the twenty-first century, we can do better. And I mean much better,\nwith longer and much more complex configurations of letters and\nnumbers. That may sound hard, but I will show you both an automatic and\na manual way to do this.\nThe easiest approach is to forgo the creation of your own passwords\nand simply automate the process. There are several digital password\nmanagers out there. Not only do they store your passwords within a locked\nvault and allow one-click access when you need them, they also generate\nnew and really strong, unique passwords for each site when you need\nthem.\nBe aware, though, of two problems with this approach. One is that\npassword managers use one master password for access. If someone\nhappens to infect your computer with malware that steals the password\ndatabase and your master password through keylogging—when the\nmalware records every keystroke you make—it’s game over. That person\nwill then have access to all your passwords. During my pen-testing\nengagements, I sometimes replace the password manager with a modified\nversion that transmits the master password to us (when the password\nmanager is open-source). This is done after we gain admin access to the\nclient’s network. We then go after all the privileged passwords. In other\nwords, we will use password managers as a back door to get the keys to the\nkingdom.\nThe other problem is kind of obvious: If you lose the master password,\nyou lose all your passwords. Ultimately, this is okay, as you can always\nperform a password reset on each site, but that would be a huge hassle if\nyou have a lot of accounts.\nDespite these flaws, the following tips should be more than adequate to\nkeep your passwords secure.\nFirst, strong passphrases, not passwords, should be long—at least\ntwenty to twenty-five characters. Random characters—ek5iogh#skf&skd\n—work best. Unfortunately the human mind has trouble remembering\nrandom sequences. So use a password manager. Using a password manager\nis far better than choosing your own. I prefer open-source password\nmanagers like Password Safe and KeePass that only store data locally on\nyour computer.\nAnother important rule for good passwords is never use the same\npassword for two different accounts. That’s hard. Today we have\npasswords on just about everything. So have a password manager generate\nand store strong, unique passwords for you.\nEven if you have a strong password, technology can still be used to\ndefeat you. There are password-guessing programs such as John the\nRipper, a free open-source program that anyone can download and that\nworks within configuration parameters set by the user.6 For example, a\nuser might specify how many characters to try, whether to use special\nsymbols, whether to include foreign language sets, and so on. John the\nRipper and other password hackers are able to permute the password\nletters using rule sets that are extremely effective at cracking passwords.\nThis simply means it tries every possible combination of numbers, letters,\nand symbols within the parameters until it is successful at cracking your\npassword. Fortunately, most of us aren’t up against nation-states with\nvirtually unlimited time and resources. More likely we’re up against a\nspouse, a relative, or someone we really pissed off who, when faced with a\ntwenty-five-character password, won’t have the time or resources to\nsuccessfully crack it.\nLet’s say you want to create your passwords the old-fashioned way and\nthat you’ve chosen some really strong passwords. Guess what? It’s okay to\nwrite them down. Just don’t write “Bank of America:\n4the1sttimein4ever*.” That would be too obvious. Instead replace the\nname of your bank (for example) with something cryptic, such as “Cookie\nJar” (because some people once hid their money in cookie jars) and follow\nit with “4the1st.” Notice I didn’t complete the phrase. You don’t need to.\nYou know the rest of the phrase. But someone else might not.\nAnyone finding this printed-out list of incomplete passwords should be\nsufficiently confused—at least at first. Interesting story: I was at a friend’s\nhouse—a very well-known Microsoft employee—and during dinner we\nwere discussing the security of passwords with his wife and child. At one\npoint my friend’s wife got up and went to the refrigerator. She had written\ndown all her passwords on a single piece of paper and stuck it to the\nappliance’s door with a magnet. My friend just shook his head, and I\ngrinned widely. Writing down passwords might not be a perfect solution,\nbut neither is forgetting that rarely used strong password.\nSome websites—such as your banking website—lock out users after\nseveral failed password attempts, usually three. Many sites, however, still\ndo not do this. But even if a site does lock a person out after three failed\nattempts, that isn’t how the bad guys use John the Ripper or oclHashcat.\n(Incidentally, oclHashcat distributes the hacking process over multiple\nGPUs and is much more powerful than John the Ripper.) Also, hackers\ndon’t actually try every single possible password on a live site.\nLet’s say there has been a data breach, and included within the data\ndump are usernames and passwords. But the passwords retrieved from the\ndata breach are mere gibberish.\nHow does that help anyone break into your account?\nWhenever you type in a password, whether it is to unlock your laptop\nor an online service—that password is put through a one-way algorithm\nknown as a hash function. It is not the same as encryption. Encryption is\ntwo-way: you can encrypt and decrypt as long as you have a key. A hash is\na fingerprint representing a particular string of characters. In theory, one-\nway algorithms can’t be reversed—or at least not easily.\nWhat is stored in the password database on your traditional PC, your\nmobile device, or your cloud account is not MaryHadALittleLamb123$\nbut its hash value, which is a sequence of numbers and letters. The\nsequence is a token that represents your password.7\nIt is the password hashes, not the passwords themselves, that are stored\nin the protected memory of our computers and can be obtained from a\ncompromise of targeted systems or leaked in data breaches. Once an\nattacker has obtained these password hashes, the hacker can use a variety\nof publicly available tools, such as John the Ripper or oclHashcat, to crack\nthe hashes and obtain the actual password, either through brute force\n(trying every possible alphanumeric combination) or trying each word in a\nword list, such as a dictionary. Options available in John the Ripper and\noclHashcat allow the attacker to modify the words tried against numerous\nrule sets, for example the rule set called leetspeak—a system for replacing\nletters with numbers, as in “k3v1n m17n1ck.” This rule will change all\npasswords to various leetspeak permutations. Using these methods to\ncrack passwords is much more effective than simple brute force. The\nsimplest and most common passwords are easily cracked first, then more\ncomplex passwords are cracked over time. The length of time it takes\ndepends on several factors. Using a password-cracking tool together with\nyour breached username and hashed password, hackers may be able to\naccess one or more of your accounts by trying that password on additional\nsites connected to your e-mail address or other identifier.\nIn general, the more characters in your password, the longer it will take\npassword-guessing programs such as John the Ripper to run through all the\npossible variations. As computer processors get faster, the length of time\nit takes to calculate all the possible six-character and even eight-character\npasswords is becoming a lot shorter, too. That’s why I recommend using\npasswords of twenty-five characters or more.\nAfter you create strong passwords—and many of them—never give\nthem out. That seems painfully obvious, but surveys in London and other\nmajor cities show that people have traded their passwords in exchange for\nsomething as trivial as a pen or a piece of chocolate.8\nA friend of mine once shared his Netflix password with a girlfriend. It\nmade sense at the time. There was the immediate gratification of letting\nher choose a movie for them to watch together. But trapped within\nNetflix’s recommended-movie section were all his “because you\nwatched…” movies, including movies he had watched with past\ngirlfriends. The Sisterhood of the Traveling Pants, for instance, is not a\nfilm he would have ordered himself, and his girlfriend knew this.\nOf course, everyone has exes. You might even be suspicious if you\ndated someone who didn’t. But no girlfriend wants to be confronted with\nevidence of those who have gone before her.\nIf you password-protect your online services, you should also password-\nprotect your individual devices. Most of us have laptops, and many of us\nstill have desktops. You may be home alone now, but what about those\ndinner guests coming later? Why take a chance that one of them could\naccess your files, photos, and games just by sitting at your desk and\nmoving the mouse? Another Netflix cautionary tale: back in the days when\nNetflix primarily sent out DVDs, I knew a couple who got pranked. During\na party at their house, they’d left their browser open to their Netflix\naccount. Afterward, the couple found that all sorts of raunchy B-and C-list\nmovies had been added to their queue—but only after they’d received\nmore than one of these films in the mail.\nIt’s even more important to protect yourself with passwords at the\noffice. Think of all those times you’re called away from your desk into an\nimpromptu meeting. Someone could walk by your desk and see the\nspreadsheet for the next quarter’s budget. Or all the e-mails sitting in your\ninbox. Or worse, unless you have a password-protected screen saver that\nkicks in after a few seconds of inactivity, whenever you’re away from your\ndesk for an extended period—out to lunch or at a long meeting—someone\ncould sit down and write an e-mail and send it as you. Or even alter the\nnext quarter’s budget.\nThere are creative new methods to preventing this, like screen-locking\nsoftware that uses Bluetooth to verify if you are near your computer. In\nother words, if you go to the bathroom and your mobile phone goes out of\nBluetooth range of the computer, the screen is immediately locked. There\nare also versions that use a Bluetooth device like a wristband or\nsmartwatch and will do the same thing.\nCreating passwords to protect online accounts and services is one thing,\nbut it’s not going to help you if someone gains physical possession of your\ndevice, especially if you’ve left those online accounts open. So if you\npassword-protect only one set of devices, it should be your mobile\ndevices, because these are the most vulnerable to getting lost or stolen. Yet\nConsumer Reports found that 34 percent of Americans don’t protect their\nmobile devices with any security measures at all, such as locking the\nscreen with a simple four-digit PIN.9\nIn 2014 a Martinez, California, police officer confessed to stealing\nnude photos from the cell phone of a DUI suspect, a clear violation of the\nFourth Amendment, which is part of the Constitution’s Bill of Rights.10\nSpecifically, the Fourth Amendment prohibits unreasonable searches and\nseizures without a warrant issued by a judge and supported by probable\ncause—law enforcement officers have to state why they want access to\nyour phone, for instance.\nIf you haven’t already password-protected your mobile device, take a\nmoment now and do so. Seriously.\nThere are three common ways to lock your phone—whether it’s an\nAndroid or iOS or something else. The most familiar is a passcode—a\nsequence of numbers that you enter in a specific order to unlock your\nphone. Don’t settle for the number of digits the phone recommends. Go\ninto your settings and manually configure the passcode to be stronger—\nseven digits if you want (like an old phone number from your childhood.)\nCertainly use more than just four.\nSome mobile devices allow you to choose a text-based passcode, such\nas the examples we created here. Again, choose at least seven characters.\nModern mobile devices display both number and letter keys on the same\nscreen, making it easier to switch back and forth between them.\nAnother lock option is visual. Since 2008, Android phones have been\nequipped with something called Android lock patterns (ALPs). Nine dots\nappear on the screen, and you connect them in any order you want; that\nconnecting sequence becomes your passcode. You might think this\ningenious and that the sheer range of possible combinations makes your\nsequence unbreakable. But at the Passwords-Con conference in 2015,\nresearchers reported that—human nature being what it is—participants in\na study availed themselves of just a few possible patterns out of the\n140,704 possible combinations on ALP.11 And what were those predictable\npatterns? Often the first letter of the user’s name. The study also found\nthat people tended to use the dots in the middle and not in the remote four\ncorners. Consider that the next time you set an ALP.\nFinally there’s the biometric lock. Apple, Samsung, and other popular\nmanufacturers currently allow customers the option of using a fingerprint\nscanner to unlock their phones. Be aware that these are not foolproof.\nAfter the release of Touch ID, researchers—perhaps expecting Apple to\nhave improved upon the current crop of fingerprint scanners already on the\nmarket—were surprised to find that several old methods of defeating\nfingerprint scanners still work on the iPhone. These include capturing a\nfingerprint off of a clean surface using baby powder and clear adhesive\ntape.\nOther phones use the built-in camera for facial recognition of the\nowner. This, too, can be defeated by holding up a high-resolution\nphotograph of the owner in front of the camera.\nIn general, biometrics by themselves are vulnerable to attacks. Ideally\nbiometrics should be used as just one authenticating factor. Swipe your\nfingertip or smile for the camera, then enter a PIN or passcode. That\nshould keep your mobile device secure.\nWhat if you created a strong password but didn’t write it down? Password\nresets are a godsend when you absolutely can’t access an infrequently used\naccount. But they can also be low-hanging fruit for would-be attackers.\nUsing the clues we leave in the form of social media profiles all over the\nInternet, hackers can gain access to our e-mail—and other services—\nsimply by resetting our passwords.\nOne attack that has been in the press involves obtaining the target’s last\nfour digits of his or her credit card number, and then using that as proof of\nidentity when calling in to a service provider to change the authorized e-\nmail address. That way, the attacker can reset the password on his or her\nown without the legitimate owner knowing.\nBack in 2008 a student at the University of Tennessee, David Kernell,\ndecided to see whether he could access then vice presidential candidate\nSarah Palin’s personal Yahoo e-mail account.12 Kernell could have\nguessed various passwords, but access to the account might have been\nlocked after a few failed tries. Instead he used the password reset function,\na process he later described as “easy.”13\nI’m sure we’ve all received strange e-mails from friends and associates\ncontaining links to porn sites in foreign countries only to learn later that\nour friends’ e-mail accounts had been taken over. These e-mail takeovers\noften occur because the passwords guarding the accounts are not strong.\nEither someone learned the password—through a data breach—or the\nattacker used the password reset function.\nWhen first setting up an account such as an e-mail or even a bank\naccount, you may have been asked what are usually labeled as security\nquestions. Typically there are three of them. Often there are drop-down\nmenus listing suggested questions, so you can choose which ones you want\nto answer. Usually they are really obvious.\nWhere were you born? Where did you go to high school? Or college?\nAnd the old favorite, your mother’s maiden name, which apparently has\nbeen in use as a security question since at least 1882.14 As I’ll discuss\nbelow, companies can and do scan the Internet and collect personal\ninformation that makes answering these basic security questions a piece of\ncake. A person can spend a few minutes on the Internet and have a good\nchance of being able to answer all the security questions of a given\nindividual.\nOnly recently have these security questions improved somewhat. For\nexample, “What is the state where your brother-in-law was born?” is\npretty distinct, though answering these “good” questions correctly can\ncarry its own risks, which I’ll get to in a minute. But many so-called\nsecurity questions are still too easy, such as “What is your father’s\nhometown?”\nIn general, when setting these security questions, try to avoid the most\nobvious suggestions available from the drop-down menu. Even if the site\nincludes only basic security questions, be creative. No one says you have\nto provide straightforward answers. You can be clever about it. For\nexample, as far as your streaming video service is concerned, maybe tutti-\nfrutti is your new favorite color. Who would guess that? It is a color, right?\nWhat you provide as the answer becomes the “correct” answer to that\nsecurity question.\nWhenever you do provide creative answers, be sure to write down both\nthe question and the answer and put them in a safe place (or simply use a\npassword manager to store your questions and answers). There may be a\nlater occasion when you need to talk to technical support, and a\nrepresentative might ask you one of the security questions. Have a binder\nhandy or keep a card in your wallet (or memorize and consistently use the\nsame set of responses) to help you remember that “In a hospital” is the\ncorrect answer to the question “Where were you born?” This simple\nobfuscation would thwart someone who later did their Internet research on\nyou and tried a more reasonable response, such as “Columbus, Ohio.”\nThere are additional privacy risks in answering very specific security\nquestions honestly: you are giving out more personal information than is\nalready out there. For example, the honest answer to “What state was your\nbrother-in-law born in?” can then be sold by the site you gave that answer\nto and perhaps combined with other information or used to fill in missing\ninformation. For example, from the brother-in-law answer one can infer\nthat you are or were married and that your partner, or your ex, has a\nsibling who is either a man or married to a man born in the state you\nprovided. That’s a lot of additional information from a simple answer. On\nthe other hand, if you don’t have a brother-in-law, go ahead and answer the\nquestion creatively, perhaps by answering “Puerto Rico.” That should\nconfuse anyone trying to build a profile on you. The more red herrings you\nprovide, the more you become invisible online.\nWhen answering these relatively uncommon questions, always consider\nhow valuable the site is to you. For example, you might trust your bank to\nhave this additional personal information but not your streaming video\nservice. Also consider what the site’s privacy policy might be: look for\nlanguage that says or suggests that it might sell the information it collects\nto third parties.\nThe password reset for Sarah Palin’s Yahoo e-mail account required her\nbirth date, zip code, and the answer to the security question “Where did\nyou meet your husband?” Palin’s birth date and zip code could easily be\nfound online (at the time, Palin was the governor of Alaska). The security\nquestion took a bit more work, but the answer to it, too, was accessible to\nKernell. Palin gave many interviews in which she stated repeatedly that\nher husband was her high school sweetheart. That, it turns out, was the\ncorrect answer to her security question: “High school.”\nBy guessing the answer to Palin’s security question, Kernell was able to\nreset her Yahoo Mail password to one that he controlled. This allowed him\nto see all her personal Yahoo e-mails. A screenshot of her inbox was\nposted on a hacker website. Palin herself was locked out of her e-mail\nuntil she reset the password.15\nWhat Kernell did was illegal, a violation of the Computer Fraud and\nAbuse Act. Specifically, he was found guilty on two counts: anticipatory\nobstruction of justice by destruction of records, a felony, and gaining\nunauthorized access to a computer, a misdemeanor. He was sentenced in\n2010 to one year and one day in prison plus three years of supervised\nrelease.16\nIf your e-mail account has been taken over, as Palin’s was, first you\nwill need to change your password using (yes, you guessed it) the\npassword reset option. Make this new password a stronger password, as I\nsuggested above. Second, check the Sent box to see exactly what was sent\nin your name. You might see a spam message that was sent to multiple\nparties, even your entire contacts list. Now you know why your friends\nhave been sending you spam for all these years—someone hacked their e-\nmail accounts.\nAlso check to see whether anyone has added himself to your account.\nEarlier we talked about mail forwarding with regard to multiple e-mail\naccounts. Well, an attacker who gains access to your e-mail service could\nalso have all your e-mail forwarded to his account. You would still see\nyour e-mail normally, but the attacker would see it as well. If someone has\nadded himself to your account, delete this forwarding e-mail address\nimmediately.\nPasswords and PINs are part of the security solution, but we’ve just seen\nthat these can be guessed. Even better than complex passwords are two-\nfactor authentication methods. In fact, in response to Jennifer Lawrence\nand other celebrities having their nude photos plastered over the Internet,\nApple instituted two-factor authentication, or 2FA, for its iCloud services.\nWhat is 2FA?\nWhen attempting to authenticate a user, sites or applications look for at\nleast two of three things. Typically these are something you have,\nsomething you know, and something you are. Something you have can be a\nmagnetic stripe or chip-embedded credit or debit card. Something you\nknow is often a PIN or an answer to a security question. And something\nyou are encompasses biometrics—fingerprint scanning, facial recognition,\nvoice recognition, and so on. The more of these you have, the surer you\ncan be that the user is who she says she is.\nIf this sounds like new technology, it’s not. For more than forty years\nmost of us have been performing 2FA without realizing it.\nWhenever you use an ATM, you perform 2FA. How is that possible?\nYou have a bank-issued card (that’s something you have) and a PIN (that’s\nsomething you know). When you put them together, the unmanned ATM\nout on the street knows that you want access to the account identified on\nthe card. In some countries, there are additional means of authentication at\nATMs, such as facial recognition and a palm print. This is called\nmultifactor authentication (MFA).\nSomething similar is possible online. Many financial and health-care\ninstitutions, as well as commercial e-mail and social media accounts,\nallow you to choose 2FA. In this case, the something you know is your\npassword, and the something you have is your cell phone. Using the phone\nto access these sites is considered “out of band” because the phone is not\nconnected to the computer you are using. But if you have 2FA enabled, an\nattacker should not be able to access your 2FA-protected accounts without\nhaving your mobile device in hand.\nSay you use Gmail. To enable 2FA you will be asked to input your cell-\nphone number on the Gmail site. To verify your identity, Google will then\nsend an SMS code of six digits to your phone. By subsequently inputting\nthat code on the Gmail site, you have just verified that this computer and\nthat cell-phone number are connected.\nAfter that, if someone tries to change the password on your account\nfrom a new computer or device, a text message will be sent to your phone.\nOnly when the correct verification code is entered on the website will any\nchange to your account be saved.\nThere’s a wrinkle to that, though. According to researchers at\nSymantec, if you do send an SMS to confirm your identity, someone who\nhappens to know your cell-phone number can do a bit of social\nengineering and steal your 2FA-protected password reset code if you are\nnot paying close attention.17\nSay I want to take over your e-mail account and don’t know your\npassword. I do know your cell-phone number because you’re easy to find\nthrough Google. I can go to the reset page for your e-mail service and\nrequest a password reset, which, because you enabled two-factor\nauthentication, will result in an SMS code being sent to your phone. So\nfar, so good, right? Hang on.\nA recent attack on a phone used by political activist DeRay Mckesson\nshowed how the bad guys could trick your mobile operator to do a SIM\nswap.18 In other words, the attacker could hijack your cellular service and\nthen receive your SMS messages—for example, the SMS code from\nGoogle to reset Mckesson’s Gmail account that was protected with two-\nfactor authentication. This is much more likely than fooling someone into\nreading off his or her SMS message with a new password. Although that is\nstill possible, and involves social engineering.\nBecause I won’t see the verification code sent by your e-mail provider\nto your phone, I’ll need to pretend to be someone else in order to get it\nfrom you. Just seconds before you receive the actual SMS from, say,\nGoogle, I as the attacker can send a one-time SMS, one that says: “Google\nhas detected unusual activity on your account. Please respond with the\ncode sent to your mobile device to stop unauthorized activity.”\nYou will see that yes, indeed, you just got an SMS text from Google\ncontaining a legitimate verification code, and so you might, if you are not\nbeing careful, simply reply to me in a message and include the code. I\nwould then have less than sixty seconds to enter the verification code.\nNow I have what I need to enter on the password reset page and, after\nchanging your password, take over your e-mail account. Or any other\naccount.\nSince SMS codes are not encrypted and can be obtained in the way I\njust described, an even more secure 2FA method is to download the\nGoogle Authenticator app from Google Play or the iTunes app store for\nuse with an iPhone. This app will generate a unique access code on the app\nitself each time you want to visit a site that requires 2FA—so there’s no\nSMS to be sent. This app-generated six-digit code is synced with the site’s\nauthentication mechanism used to grant access to the site. However,\nGoogle Authenticator stores your one-time password seed in the Apple\nKeychain with a setting for “This Device Only.” That means if you back up\nyour iPhone and restore to a different device because you are upgrading or\nreplacing a lost phone, your Google Authenticator codes will not be\ntransferred and it’s a huge hassle to reset them. It’s always a good idea to\nprint out the emergency codes in case you end up switching physical\ndevices. Other apps like 1Password allow you to back up and restore your\none-time password seeds so you don’t have this problem.\nOnce you have registered a device, as long as you continue to log in to\nthe site from that device, you will be prompted for a new access code\nunless you specifically check the box (if available) to trust the computer\nfor thirty days, even if you take your laptop or phone to another location.\nHowever, if you use another device—say, you borrow your spouse’s\ncomputer—then you will be asked for additional authentication. Needless\nto say, if you’re using 2FA, always have your cell phone handy.\nGiven all these precautions, you might wonder what advice I give to\npeople who are conducting any type of financial transaction online.\nFor about $100 a year you can get antivirus and firewall protection for\nup to three computers under your control. The trouble is that when you’re\nsurfing the Web, you might load into your browser a banner ad that\ncontains malware. Or maybe you open your e-mail, and one of the e-mails\ncontains malware. One way or another you are going to get your computer\ninfected if it regularly touches the Internet, and your antivirus product\nmay not catch everything that’s out there.\nSo I recommend you spend around $200 to get yourself a Chromebook.\nI like iPads, but they’re expensive. The Chromebook is as close to an easy-\nto-use tablet as an iPad is, and it costs much less.\nMy point is that you need to have a secondary device that you use\nexclusively for financial stuff—perhaps even medical stuff as well. No\napps can be installed unless you first register with a Gmail account—this\nwill limit you to opening the browser to surf the Internet.\nThen, if you haven’t already done so, activate 2FA on the site so that it\nrecognizes the Chromebook. Once you’ve completed your banking or\nhealth-care business, put the Chromebook away until the next time you\nhave to balance your checkbook or arrange a doctor’s appointment.\nThis seems like a hassle. It is. It replaces the convenience of anytime\nbanking with almost anytime banking. But the result is that you are far less\nlikely to have someone messing around with your banking and credit\ninformation. If you use the Chromebook only for the two or three apps you\ninstall, and if you bookmark the banking or health-care websites and visit\nno others, it is very unlikely that you will have a Trojan or some other\nform of malware residing on your machine.\nSo we’ve established that you need to create strong passwords and not\nshare them. You need to turn on 2FA whenever possible. In the next few\nchapters we’ll look at how common day-to-day interactions can leave\ndigital fingerprints everywhere and what you can do to protect your\nprivacy."
  },
  {
    "input": "",
    "summary": "Web-based email services like Gmail and Outlook store copies of emails on multiple servers, allowing third parties to access them for reasons beyond security, such as advertising or surveillance. While encryption can protect email content, metadata like IP addresses and timestamps can still reveal sensitive information. To stay anonymous, users should use tools like Tor for browsing and PGP for encryption, but even these methods require careful management and verification to prevent exposure. Snowden's experience highlights the importance of securing communications through multiple layers of privacy protection, as any oversight can compromise anonymity.",
    "output": "CHAPTER TWO\nWho Else Is Reading Your E-mail?\nIf you’re like me\n, one of the first things you do in the morning is\ncheck your e-mail. And, if you’re like me, you also wonder who else has\nread your e-mail. That’s not a paranoid concern. If you use a Web-based e-\nmail service such as Gmail or Outlook 365, the answer is kind of obvious\nand frightening.\nEven if you delete an e-mail the moment you read it on your computer\nor mobile phone, that doesn’t necessarily erase the content. There’s still a\ncopy of it somewhere. Web mail is cloud-based, so in order to be able to\naccess it from any device anywhere, at any time, there have to be\nredundant copies. If you use Gmail, for example, a copy of every e-mail\nsent and received through your Gmail account is retained on various\nservers worldwide at Google. This is also true if you use e-mail systems\nprovided by Yahoo, Apple, AT&T, Comcast, Microsoft, or even your\nworkplace. Any e-mails you send can also be inspected, at any time, by the\nhosting company. Allegedly this is to filter out malware, but the reality is\nthat third parties can and do access our e-mails for other, more sinister and\nself-serving, reasons.\nIn principle, most of us would never stand for anyone except the intended\nrecipient reading our mail. There are laws protecting printed mail\ndelivered through the US Postal Service, and laws protecting stored\ncontent such as e-mail. Yet in practice, we usually know and probably\naccept that there’s a certain trade-off involved in the ease of\ncommunication e-mail affords. We know that Yahoo (among others) offers\na free Web-mail service, and we know that Yahoo makes the majority of\nits money from advertising. Perhaps we’ve not realized exactly how the\ntwo might be connected and how that might affect our privacy.\nOne day, Stuart Diamond, a resident of Northern California, did. He\nrealized that the ads he saw in the upper-right-hand corner of his Yahoo\nMail client were not random; they were based on the contents of the e-\nmails he had been sending and receiving. For example, if I mentioned in\nan e-mail an upcoming speaking trip to Dubai, the ads I might see in my e-\nmail account would suggest airlines, hotels, and things to do while in the\nUnited Arab Emirates.\nThis practice is usually carefully spelled out in the terms of service that\nmost of us agreed to but probably never read. Nobody wants to see ads that\nhave nothing to do with our individual interests, right? And as long as the\ne-mail travels between Yahoo account holders, it seems reasonable that the\ncompany would be able to scan the contents of those e-mails in order to\ntarget ads to us and maybe block malware and spam, which is unwanted e-\nmail.\nHowever, Diamond, along with David Sutton, also from Northern\nCalifornia, began to notice that the contents of e-mails sent to and\nreceived from addresses outside Yahoo also influenced the ad selection\npresented to them. That suggested that the company was intercepting and\nreading all their e-mail, not just those sent to and from its own servers.\nBased on the patterns they observed, the two filed a class-action\nlawsuit in 2012 against Yahoo on behalf of its 275 million account holders,\nciting concerns around what is essentially equivalent to illegal wiretapping\nby the company.\nDid that end the scanning? No.\nIn a class-action suit, there is a period of discovery and response from\nboth parties. In this case that initial phase lasted nearly three years. In\nJune of 2015, a judge in San Jose, California, ruled that the men had\nsufficient grounds for their class-action suit to proceed and that people\nwho sent or received Yahoo Mail since October 2, 2011, when the men\nfiled their initial request, could join in the lawsuit under the Stored\nCommunications Act. Additionally, a class of non–Yahoo Mail account\nholders living in California may also sue under that state’s Invasion of\nPrivacy Act. That case is still pending.\nIn defending itself against another e-mail-scanning lawsuit, this one\nfiled early in 2014, Google accidentally published information about its e-\nmail scanning process in a court hearing, then quickly attempted and\nfailed to have that information redacted or removed. The case involved the\nquestion of precisely what was scanned or read by Google. According to\nthe plaintiffs in the case, which included several large media companies,\nincluding the owners of USA Today, Google realized at some point that by\nscanning only the contents of the inbox, they were missing a lot of\npotentially useful content. This suit alleged that Google shifted from\nscanning only archived e-mail, which resides on the Google server, to\nscanning all Gmail still in transit, whether it was sent from an iPhone or a\nlaptop while the user was sitting in Starbucks.\nSometimes companies have even tried to secretly scan e-mails for their\nown purposes. One well-known instance of this happened at Microsoft,\nwhich suffered a huge backlash when it revealed that it had scanned the\ninbox of a Hotmail user who was suspected of having pirated a copy of the\ncompany’s software. As a result of this disclosure, Microsoft has said it\nwill let law enforcement handle such investigations in the future.\nThese practices aren’t limited to your private e-mail. If you send e-\nmail through your work network, your company’s IT department may also\nbe scanning and archiving your communications. It is up to the IT staff or\ntheir managers whether to let any flagged e-mail pass through their servers\nand networks or involve law enforcement. This includes e-mails that\ncontain trade secrets or questionable material such as pornography. It also\nincludes scanning e-mail for malware. If your IT staff is scanning and\narchiving your e-mails, they should remind you each time you log in what\ntheir policy is—although most companies do not.\nWhile most of us may tolerate having our e-mails scanned for malware,\nand perhaps some of us tolerate scanning for advertising purposes, the idea\nof third parties reading our correspondence and acting on specific contents\nfound within specific e-mails is downright disturbing. (Except, of course,\nwhen it comes to child pornography.1)\nSo whenever you write an e-mail, no matter how inconsequential, and\neven if you delete it from your inbox, remember that there’s an excellent\nchance that a copy of those words and images will be scanned and will live\non—maybe not forever, but for a good long while. (Some companies may\nhave short retention policies, but it’s safe to assume that most companies\nkeep e-mail for a long time.)\nNow that you know the government and corporations are reading your\ne-mails, the least you can do is make it much harder for them to do so.\nMost web-based e-mail services use encryption when the e-mail is in\ntransit. However, when some services transmit mail between Mail\nTransfer Agents (MTAs), they may not be using encryption, thus your\nmessage is in the open. For example, within the workplace a boss may\nhave access to the company e-mail system. To become invisible you will\nneed to encrypt your messages—that is, lock them so that only the\nrecipients can unlock and read them. What is encryption? It is a code.\nA very simple encryption example—a Caesar cipher, say—substitutes\neach letter for another one a certain number of positions away in the\nalphabet. If that number is 2, for example, then using a Caesar cipher, a\nbecomes c, c becomes e, z becomes b, and so forth. Using this offset-by-\ntwo encryption scheme, “Kevin Mitnick” becomes “Mgxkp Okvpkem.”2\nMost encryption systems used today are, of course, much stronger than\nany basic Caesar cipher. Therefore they should be much harder to break.\nOne thing that’s true about all forms of encryption is that they require a\nkey, which is used as a password to lock and open the encrypted message.\nSymmetrical encryption means that the same key is used both to lock and\nunlock the encrypted message. Symmetrical keys are hard to share,\nhowever, when two parties are unknown to each other or physically far\napart, as they are on the Internet.\nMost e-mail encryption actually uses what’s called asymmetrical\nencryption. That means I generate two keys: a private key that stays on my\ndevice, which I never share, and a public key that I post freely on the\nInternet. The two keys are different yet mathematically related.\nFor example: Bob wants to send Alice a secure e-mail. He finds Alice’s\npublic key on the Internet or obtains it directly from Alice, and when\nsending a message to her encrypts the message with her key. This message\nwill stay encrypted until Alice—and only Alice—uses a passphrase to\nunlock her private key and unlock the encrypted message.\nSo how would encrypting the contents of your e-mail work?\nThe most popular method of e-mail encryption is PGP, which stands for\n“Pretty Good Privacy.” It is not free. It is a product of the Symantec\nCorporation. But its creator, Phil Zimmermann, also authored an open-\nsource version, OpenPGP, which is free. And a third option, GPG (GNU\nPrivacy Guard), created by Werner Koch, is also free. The good news is\nthat all three are interoperational. That means that no matter which version\nof PGP you use, the basic functions are the same.\nWhen Edward Snowden first decided to disclose the sensitive data he’d\ncopied from the NSA, he needed the assistance of like-minded people\nscattered around the world. Paradoxically, he needed to get off the grid\nwhile still remaining active on the Internet. He needed to become\ninvisible.\nEven if you don’t have state secrets to share, you might be interested in\nkeeping your e-mails private. Snowden’s experience and that of others\nillustrate that it isn’t easy to do that, but it is possible, with proper\ndiligence.\nSnowden used his personal account through a company called Lavabit\nto communicate with others. But e-mail is not point-to-point, meaning that\na single e-mail might hit several servers around the world before landing\nin the intended recipient’s inbox. Snowden knew that whatever he wrote\ncould be read by anyone who intercepted the e-mail anywhere along its\njourney.\nSo he had to perform a complicated maneuver to establish a truly\nsecure, anonymous, and fully encrypted means of communication with\nprivacy advocate and filmmaker Laura Poitras, who had recently finished\na documentary about the lives of whistle-blowers. Snowden wanted to\nestablish an encrypted exchange with Poitras, except only a few people\nknew her public key. She didn’t make her public key very public.\nTo find her public key, Snowden had to reach out to a third party, Micah\nLee of the Electronic Frontier Foundation, a group that supports privacy\nonline. Lee’s public key was available online and, according to the account\npublished on the Intercept, an online publication, he had Poitras’s public\nkey, but he first needed to check to see if she would permit him to share it.\nShe would.3\nAt this point neither Lee nor Poitras had any idea who wanted her\npublic key; they only knew that someone did. Snowden had used a\ndifferent account, not his personal e-mail account, to reach out. But if you\ndon’t use PGP often, you may forget to include your PGP key on important\ne-mails now and again, and that is what happened to Snowden. He had\nforgotten to include his own public key so Lee could reply.\nWith no secure way to contact this mystery person, Lee was left with\nno choice but to send a plain-text, unencrypted e-mail back to Snowden\nasking for his public key, which he provided.\nOnce again Lee, a trusted third party, had to be brought into the\nsituation. I can tell you from personal experience that it is very important\nto verify the identity of the person with whom you are having a secure\nconversation, preferably through a mutual friend—and make sure you are\ncommunicating with that friend and not someone else in disguise.\nI know how important this is because I’ve been the poser before, in a\nsituation where it worked to my advantage that the other party didn’t\nquestion my real identity or the public key I sent. I once wanted to\ncommunicate with Neill Clift, a graduate student in organic chemistry at\nthe University of Leeds, in England, who was very skilled at finding\nsecurity vulnerabilities in the Digital Equipment Corporation’s VMS\noperating system. I wanted Clift to send me all the security holes that he’d\nreported to DEC. For that I needed him to think that I actually worked for\nDEC.\nI started by posing as someone named Dave Hutchins and sending Clift\na spoofed message from him. I had previously called Clift pretending to be\nDerrell Piper from VMS engineering, so I (posing as Hutchins) wrote in\nmy e-mail that Piper wanted to exchange e-mails with Clift about a\nproject. In going through DEC’s e-mail system, I already knew that Clift\nand the real Piper had previously e-mailed each other, so this new request\nwouldn’t sound all that odd. I then sent an e-mail spoofing Piper’s real e-\nmail address.\nTo further convince Clift this was all on the up-and-up, I even\nsuggested that he use PGP encryption so that someone like Kevin Mitnick\nwouldn’t be able to read the e-mails. Soon Clift and “Piper” were\nexchanging public keys and encrypting communications—\ncommunications that I, as Piper, could read. Clift’s mistake was in not\nquestioning the identity of Piper himself. Similarly, when you receive an\nunsolicited phone call from your bank asking for your Social Security\nnumber or account information, you should always hang up and call the\nbank yourself—you never know who is on the other side of the phone call\nor e-mail.\nGiven the importance of the secrets they were about to share, Snowden\nand Poitras could not use their regular e-mail addresses. Why not? Their\npersonal e-mail accounts contained unique associations—such as specific\ninterests, lists of contacts—that could identify each of them. Instead\nSnowden and Poitras decided to create new e-mail addresses.\nThe only problem was, how would they know each other’s new e-mail\naddresses? In other words, if both parties were totally anonymous, how\nwould they know who was who and whom they could trust? How could\nSnowden, for example, rule out the possibility that the NSA or someone\nelse wasn’t posing as Poitras’s new e-mail account? Public keys are long,\nso you can’t just pick up a secure phone and read out the characters to the\nother person. You need a secure e-mail exchange.\nBy enlisting Micah Lee once again, both Snowden and Poitras could\nanchor their trust in someone when setting up their new and anonymous e-\nmail accounts. Poitras first shared her new public key with Lee. But PGP\nencryption keys themselves are rather long (not quite pi length, but they\nare long), and, again, what if someone were watching his e-mail account as\nwell? So Lee did not use the actual key but instead a forty-character\nabbreviation (or a fingerprint) of Poitras’s public key. This he posted to a\npublic site—Twitter.\nSometimes in order to become invisible you have to use the visible.\nNow Snowden could anonymously view Lee’s tweet and compare the\nshortened key to the message he received. If the two didn’t match,\nSnowden would know not to trust the e-mail. The message might have\nbeen compromised. Or he might be talking instead to the NSA.\nIn this case, the two matched.\nNow several orders removed from who they were online—and where\nthey were in the world—Snowden and Poitras were almost ready to begin\ntheir secure anonymous e-mail communication. Snowden finally sent\nPoitras an encrypted e-mail identifying himself only as “Citizenfour.” This\nsignature became the title of her Academy Award–winning documentary\nabout his privacy rights campaign.\nThat might seem like the end—now they could communicate securely\nvia encrypted e-mail—but it wasn’t. It was just the beginning.\nIn the wake of the 2015 terrorist attacks in Paris, there was discussion\nfrom various governments about building in back doors or other ways for\nthose in government to decrypt encrypted e-mail, text, and phone\nmessages—ostensibly from foreign terrorists. This would, of course,\ndefeat the purpose of encryption. But governments actually don’t need to\nsee the encrypted contents of your e-mail to know whom you are\ncommunicating with and how often, as we will see.\nAs I mentioned before, the purpose of encryption is to encode your\nmessage so that only someone with the correct key can later decode it.\nBoth the strength of the mathematical operation and the length of the\nencryption key determine how easy it is for someone without a key to\ncrack your code.\nEncryption algorithms in use today are public. You want that.4 Be\nafraid of encryption algorithms that are proprietary and not public. Public\nalgorithms have been vetted for weakness—meaning people have been\npurposely trying to break them. Whenever one of the public algorithms\nbecomes weak or is cracked, it is retired, and newer, stronger algorithms\nare used instead. The older algorithms still exist, but their use is strongly\ndiscouraged.\nThe keys are (more or less) under your control, and so, as you might\nguess, their management is very important. If you generate an encryption\nkey, you—and no one else—will have the key stored on your device. If you\nlet a company perform the encryption, say, in the cloud, then that company\nmight also keep the key after he or she shares it with you. The real concern\nis that this company may also be compelled by court order to share the key\nwith law enforcement or a government agency, with or without a warrant.\nYou will need to read the privacy policy for each service you use for\nencryption and understand who owns the keys.\nWhen you encrypt a message—an e-mail, text, or phone call—use end-\nto-end encryption. That means your message stays unreadable until it\nreaches its intended recipient. With end-to-end encryption, only you and\nyour recipient have the keys to decode the message. Not the\ntelecommunications carrier, website owner, or app developer—the parties\nthat law enforcement or government will ask to turn over information\nabout you. How do you know whether the encryption service you are using\nis end-to-end encryption? Do a Google search for “end-to-end encryption\nvoice call.” If the app or service doesn’t use end-to-end encryption, then\nchoose another.\nIf all this sounds complicated, that’s because it is. But there are PGP\nplug-ins for the Chrome and Firefox Internet browsers that make\nencryption easier. One is Mailvelope, which neatly handles the public and\nprivate encryption keys of PGP. Simply type in a passphrase, which will be\nused to generate the public and private keys. Then whenever you write a\nWeb-based e-mail, select a recipient, and if the recipient has a public key\navailable, you will then have the option to send that person an encrypted\nmessage.5\nEven if you encrypt your e-mail messages with PGP, a small but\ninformation-rich part of your message is still readable by just about\nanyone. In defending itself from the Snowden revelations, the US\ngovernment stated repeatedly that it doesn’t capture the actual contents of\nour e-mails, which in this case would be unreadable with PGP encryption.\nInstead, the government said it collects only the e-mail’s metadata.\nWhat is e-mail metadata? It is the information in the To and From\nfields as well as the IP addresses of the various servers that handle the e-\nmail from origin to recipient. It also includes the subject line, which can\nsometimes be very revealing as to the encrypted contents of the message.\nMetadata, a legacy from the early days of the Internet, is still included on\nevery e-mail sent and received, but modern e-mail readers hide this\ninformation from display.6\nPGP, no matter what “flavor” you use, does not encrypt the metadata—\nthe To and From fields, the subject line, and the time-stamp information.\nThis remains in plain text, whether it is visible to you or not. Third parties\nwill still be able to see the metadata of your encrypted message; they’ll\nknow that on such-and-such a date you sent an e-mail to someone, that two\ndays later you sent another e-mail to that same person, and so on.\nThat might sound okay, since the third parties are not actually reading\nthe content, and you probably don’t care about the mechanics of how those\ne-mails traveled—the various server addresses and the time stamps—but\nyou’d be surprised by how much can be learned from the e-mail path and\nthe frequency of e-mails alone.\nBack in the ’90s, before I went on the run from the FBI, I performed\nwhat I called a metadata analysis on various phone records. I began this\nprocess by hacking into PacTel Cellular, a cellular provider in Los\nAngeles, to obtain the call detail records (CDRs) of anyone who called an\ninformant whom the FBI was using to obtain information about my\nactivities.\nCDRs are very much like the metadata I’m talking about here; they\nshow the time a phone call was made, the number dialed, the length of the\ncall, and the number of times a particular number was called—all very\nuseful information.\nBy searching through the calls that were being placed through PacTel\nCellular to the informant’s landline, I was able to obtain a list of the cell-\nphone numbers of the people who called him. Upon analysis of the callers’\nbilling records, I was able to identify those callers as members of the\nFBI’s white-collar crime squad, operating out of the Los Angeles office.\nSure enough, some of the numbers each individual dialed were internal to\nthe Los Angeles office of the FBI, the US attorney’s office, and other\ngovernment offices. Some of those calls were quite long. And quite\nfrequent.\nWhenever they moved the informant to a new safe house, I was able to\nobtain the landline number of the safe house because the agents would call\nit after trying to reach the informant on his pager. Once I had the landline\nnumber for the informant, I was also able to obtain the physical address\nthrough social engineering—that is, by pretending to be someone at\nPacific Bell, the company that provided the service at the safe house.\nSocial engineering is a hacking technique that uses manipulation,\ndeception, and influence to get a human target to comply with a request.\nOften people are tricked into giving up sensitive information. In this case,\nI knew the internal numbers at the phone company, and I pretended to be a\nfield technician who spoke the correct terminology and lingo, which was\ninstrumental in obtaining sensitive information.\nSo while recording the metadata in an e-mail is not the same as\ncapturing the actual content, it is nonetheless intrusive from a privacy\nperspective.\nIf you look at the metadata from any recent e-mail you’ll see the IP\naddresses of the servers that passed your e-mail around the world before it\nreached its target. Each server—like each person who accesses the Internet\n—has a unique IP address, a numerical value that is calculated using the\ncountry where you are located and who your Internet provider is. Blocks of\nIP addresses are set aside for various countries, and each provider has its\nown sub-block, and this is further subdivided by type of service—dial-up,\ncable, or mobile. If you purchased a static IP address it will be associated\nwith your subscriber account and home address, otherwise your external IP\naddress will be generated from a pool of addresses assigned to your\nInternet service provider. For example, a sender—someone sending you an\nemail—might have the IP address 27.126.148.104, which is located in\nVictoria, Australia.\nOr it could be 175.45.176.0, which is one of North Korea’s IP\naddresses. If it is the latter, then your e-mail account might be flagged for\ngovernment review. Someone in the US government might want to know\nwhy you’re communicating with someone from North Korea, even if the\nsubject line reads “Happy Birthday.”\nBy itself, you still might not think the server address is very\ninteresting. But the frequency of contact can tell you a lot. Additionally, if\nyou identify each element—the sender and the receiver and their locations\n—you can start to infer what’s really going on. For example, the metadata\nassociated with phone calls—the duration, the time of day they’re made,\nand so on—can tell you a lot about a person’s mental health. A 10:00 p.m.\ncall to a domestic violence hotline lasting ten minutes or a midnight call\nfrom the Brooklyn Bridge to a suicide prevention hotline lasting twenty\nminutes can be very revealing. An app developed at Dartmouth College\nmatches patterns of stress, depression, and loneliness in user data. This\nuser activity has also been correlated with student grades.7\nStill don’t see the danger in having your e-mail metadata exposed? A\nprogram created at MIT called Immersion will visually map the\nrelationships between the senders and receivers of all the e-mail you have\nstored in your e-mail account just by using the metadata. The tool is a way\nto visually quantify who matters to you most. The program even includes a\nsliding time scale, so you can see how the people you know rise and fall in\nimportance to you over time. Although you might think you understand\nyour relationships, seeing them graphically represented can be a sobering\nexperience. You might not realize how often you e-mail someone you\ndon’t really know or how little you e-mail someone you know very well.\nWith the Immersion tool you can choose whether to upload the data, and\nyou can also delete the information once it has been graphed.8\nAccording to Snowden, our e-mail, text, and phone metadata is being\ncollected by the NSA and other agencies. But the government can’t collect\nmetadata from everyone—or can it? Technically, no. However, there’s\nbeen a sharp rise in “legal” collection since 2001.\nAuthorized under the US Foreign Intelligence Surveillance Act of 1978\n(FISA), the US Foreign Intelligence Surveillance Court (known as FISC,\nor the FISA Court) oversees all requests for surveillance warrants against\nforeign individuals within the United States. On the surface it seems\nreasonable that a court order would stand between law enforcement and an\nindividual. The reality is somewhat different. In 2012 alone, 1,856\nrequests were presented, and 1,856 requests were approved, suggesting\nthat the process today is largely a rubber-stamp approval operation for the\nUS government.9 After the FISA Court grants a request, law enforcement\ncan compel private corporations to turn over all their data on you—that is,\nif they haven’t already done so.\nTo become truly invisible in the digital world you will need to do more\nthan encrypt your messages. You will need to:\nRemove your true IP address: This is your point of connection to the\nInternet, your fingerprint. It can show where you are (down to your\nphysical address) and what provider you use.\nObscure your hardware and software: When you connect to a\nwebsite online, a snapshot of the hardware and software you’re\nusing may be collected by the site. There are tricks that can be used\nto find out if you have particular software installed, such as Adobe\nFlash. The browser software tells a website what operating system\nyou’re using, what version of that operating system you have, and\nsometimes what other software you have running on your desktop\nat the time.\nDefend your anonymity: Attribution online is hard. Proving that you\nwere at the keyboard when an event occurred is difficult. However,\nif you walk in front of a camera before going online at Starbucks, or\nif you just bought a latte at Starbucks with your credit card, these\nactions can be linked to your online presence a few moments later.\nAs we’ve learned, every time you connect to the Internet, there’s an IP\naddress associated with that connection.10 This is problematic if you’re\ntrying to be invisible online: you might change your name (or not give it at\nall), but your IP address will still reveal where you are in the world, what\nprovider you use, and the identity of the person paying for the Internet\nservice (which may or may not be you). All these pieces of information\nare included within the e-mail metadata and can later be used to identify\nyou uniquely. Any communication, whether it’s e-mail or not, can be used\nto identify you based on the Internal Protocol (IP) address that’s assigned\nto the router you are using while you are at home, work, or a friend’s\nplace.\nIP addresses in e-mails can of course be forged. Someone might use a\nproxy address—not his or her real IP address but someone else’s—so that\nan e-mail appears to originate from another location. A proxy is like a\nforeign-language translator—you speak to the translator, and the translator\nspeaks to the foreign-language speaker—only the message remains exactly\nthe same. The point here is that someone might use a proxy from China or\neven Germany to evade detection on an e-mail that really comes from\nNorth Korea.\nInstead of hosting your own proxy, you can use a service known as an\nanonymous remailer, which will mask your e-mail’s IP address for you.\nAn anonymous remailer simply changes the e-mail address of the sender\nbefore sending the message to its intended recipient. The recipient can\nrespond via the remailer. That’s the simplest version.\nThere are also variations. Some type I and type II remailers do not\nallow you to respond to e-mails; they are simply one-way correspondence.\nType III, or Mixminion, remailers do offer a full suite of services:\nresponding, forwarding, and encryption. You will need to find out which\nservice your remailer supplies if you choose this method of anonymous\ncorrespondence.\nOne way to mask your IP address is to use the onion router (Tor), which\nis what Snowden and Poitras did.\nDeveloped by the US Naval Research Laboratory in 2004 as a way for\nmilitary personnel to conduct searches without exposing their physical\nlocations, the Tor open-source program has since been expanded. Tor is\ndesigned to be used by people living in harsh regimes as a way to avoid\ncensorship of popular media and services and to prevent anyone from\ntracking what search terms they use. Tor remains free and can be used by\nanyone, anywhere—even you.\nHow does Tor work? It upends the usual model for accessing a website.\nUsually when you go online you open an Internet browser and type in\nthe name of the site you want to visit. A request goes out to that site, and\nmilliseconds later a response comes back to your browser with the website\npage. The website knows—based on the IP address—who the service\nprovider is, and sometimes even where in the world you are located, based\non where the service provider is located or the latency of the hops from\nyour device to the site. For example, if your device says it is in the United\nStates, but the time and number of hops your request takes to reach its\ndestination suggest you are somewhere else in the world, some sites—\ngaming sites, in particular—will detect that as possible fraud.\nWhen you use Tor, the direct line between you and your target website\nis obscured by additional nodes, and every ten seconds the chain of nodes\nconnecting you to whatever site you are looking at changes without\ndisruption to you. The various nodes that connect you to a site are like\nlayers within an onion. In other words, if someone were to backtrack from\nthe destination website and try to find you, they’d be unable to because the\npath would be constantly changing. Unless your entry point and your exit\npoint become associated somehow, your connection is considered\nanonymous.\nWhen you use Tor, your request to open a page—say,\nmitnicksecurity.com—is not sent directly to that server but first to another\nTor node. And just to make things even more complicated, that node then\npasses the request to another node, which finally connects to\nmitnicksecurity.com. So there’s an entry node, a node in the middle, and an\nexit node. If I were to look at who was visiting my company site, I would\nonly see the IP address and information from the exit node, the last in the\nchain, and not the first, your entry node. You can configure Tor so it uses\nexit nodes in a particular country, such as Spain, or even a specific exit\nnode, perhaps in Honolulu.\nTo use Tor you will need the modified Firefox browser from the Tor site\n(torproject.org). Always look for legitimate Tor browsers for your\noperating system from the Tor project website. Do not use a third-party\nsite. For Android operating systems, Orbot is a legitimate free Tor app\nfrom Google Play that both encrypts your traffic and obscures your IP\naddress.11 On iOS devices (iPad, iPhone), install the Onion Browser, a\nlegitimate app from the iTunes app store.\nYou might be thinking, why doesn’t someone just build an e-mail\nserver within Tor? Someone did. Tor Mail was a service hosted on a site\naccessible only to Tor browsers. However, the FBI seized that server in an\nunrelated case and therefore gained access to all the encrypted e-mail\nstored on Tor Mail. This is a cautionary tale showing that even when you\nthink your information is safe, foolproof, it probably isn’t.12\nAlthough Tor uses a special network, you can still access the Internet\nfrom it, but the pages are much slower to load. However, in addition to\nallowing you to surf the searchable Internet, Tor gives you access to a\nworld of sites that are not ordinarily searchable—what’s called the Dark\nWeb. These are sites that don’t resolve to common names such as\nGoogle.com and instead end with the .onion extension. Some of these\nhidden sites offer, sell, or provide items and services that may be illegal.\nSome of them are legitimate sites maintained by people in oppressed parts\nof the world.\nIt should be noted, however, that there are several weaknesses with Tor:\nYou have no control over the exit nodes, which may be under the\ncontrol of government or law enforcement13\nYou can still be profiled and possibly identified14\nTor is very slow\nThat being said, if you still decide to use Tor you should not run it in\nthe same physical device that you use for browsing. In other words, have a\nlaptop for browsing the Web and a separate device for Tor (for instance, a\nRaspberry Pi minicomputer running Tor software). The idea here is that if\nsomebody is able to compromise your laptop they still won’t be able to\npeel off your Tor transport layer as it is running on a separate physical\nbox.15\nIn the case of Snowden and Poitras, as I said, simply connecting to each\nother over encrypted e-mail wasn’t good enough. After Poitras created a\nnew public key for her anonymous e-mail account, she could have sent it\nto Snowden’s previous e-mail address, but if someone were watching that\naccount, then her new identity would be exposed. A very basic rule is that\nyou have to keep your anonymous accounts completely separate from\nanything that could relate back to your true identity.\nTo be invisible you will need to start with a clean slate for each new\nsecure contact you make. Legacy e-mail accounts might be connected in\nvarious ways to other parts of your life—friends, hobbies, work. To\ncommunicate in secrecy, you will need to create new e-mail accounts\nusing Tor so that the IP address setting up the account is not associated\nwith your real identity in any way.\nCreating anonymous e-mail addresses is challenging but possible.\nThere are private e-mail services you can use. Since you will leave a\ntrail if you pay for those services, you’re actually better off using a free\nWeb service. A minor hassle: Gmail, Microsoft, Yahoo, and others require\nyou to supply a phone number to verify your identify. Obviously you can’t\nuse your real cell-phone number, since it may be connected to your real\nname and real address. You might be able to set up a Skype phone number\nif it supports voice authentication instead of SMS authentication; however,\nyou will still need an existing e-mail account and a prepaid gift card to set\nup a Skype number.16 If you think using a prepaid cell phone in and of\nitself will protect your anonymity, you’re wrong. If you’ve ever used a\nprepaid phone to make calls associated with your real identity, it’s child’s\nplay to discover who you are.\nInstead you’ll want to use a disposable phone. Some people think of\nburner phones as devices used only by terrorists, pimps, and drug dealers,\nbut there are plenty of perfectly legitimate uses for them. For example, a\nbusiness reporter, after having her garbage gone through by private\ninvestigators hired by Hewlett-Packard, who was eager to find out who\nmight be leaking critical board-of-directors information, switched over to\nburner phones so that the private investigators would have a harder time\nidentifying her calls. After that experience she only spoke to her source on\nthat burner phone.17\nSimilarly, a woman who is avoiding an abusive ex might gain a little\npeace of mind by using a phone that doesn’t require a contract or, for that\nmatter, a Google or an Apple account. A burner phone typically has few or\nvery limited Internet capabilities. Burner phones mostly provide voice,\ntext, and e-mail service, and that’s about all some people need. You,\nhowever, should also get data because you can tether this burner phone to\nyour laptop and use it to surf the Internet. (Here I tell you how to change\nthe media access control—MAC—address on your laptop so that each\ntime you tether with a burner phone it appears to be new device.)\nHowever, purchasing a burner phone anonymously will be tricky.\nActions taken in the real world can be used to identify you in the virtual\nworld. Sure, I could walk into Walmart and pay cash for a burner phone\nand one hundred minutes of airtime. Who would know? Well, lots of\npeople would.\nFirst, how did I get to Walmart? Did I take an Uber car? Did I take a\ntaxi? These records can all be subpoenaed.\nI could drive my own car, but law enforcement uses automatic license\nplate recognition technology (ALPR) in large public parking lots to look\nfor missing and stolen vehicles as well as people on whom there are\noutstanding warrants. The ALPR records can be subpoenaed.\nEven if I walked to Walmart, once I entered the store my face would be\nvisible on several security cameras within the store itself, and that video\ncan be subpoenaed.\nOkay, so let’s say I send someone else to the store—someone I don’t\nknow, maybe a homeless person I hired on the spot. That person walks in\nand buys the phone and several data refill cards with cash. That would be\nthe safest approach. Maybe you arrange to meet this person later away\nfrom the store. This would help physically distance yourself from the\nactual sales transaction. In this case the weakest link could still be the\nperson you sent—how trustworthy is he? If you pay him more than the\nvalue of the phone, he will probably be happy to deliver the phone as\npromised.\nActivation of the prepaid phone requires either calling the mobile\noperator’s customer service department or activating it on the provider’s\nwebsite. To avoid being recorded for “quality assurance,” it’s safer to\nactivate over the Web. Using Tor over an open wireless network after\nyou’ve changed your MAC address should be the minimum safeguards.\nYou should make up all the subscriber information you enter on the\nwebsite. For your address, just Google the address of a major hotel and use\nthat. Make up a birth date and PIN that you’ll remember in case you need\nto contact customer service in the future.\nThere are e-mail services that don’t require verification, and if you\ndon’t need to worry about authorities, Skype numbers work well for\nGoogle account registration and similar stuff, but for the sake of\nillustration, let’s say that after using Tor to randomize your IP address, and\nafter creating a Gmail account that has nothing to do with your real phone\nnumber, Google sends your phone a verification code or a voice call. Now\nyou have a Gmail account that is virtually untraceable.\nSo we have an anonymous e-mail address established using familiar\nand common services. We can produce reasonably secure e-mails whose IP\naddress—thanks to Tor—is anonymous (although you don’t have control\nover the exit nodes) and whose contents, thanks to PGP, can’t be read\nexcept by the intended recipient.\nNote that to keep this account anonymous you can only access the\naccount from within Tor so that your IP address will never be associated\nwith it. Further, you should never perform any Internet searches while\nlogged in to that anonymous Gmail account; you might inadvertently\nsearch for something that is related to your true identity. Even searching\nfor weather information could reveal your location.18\nAs you can see, becoming invisible and keeping yourself invisible\nrequire tremendous discipline and perpetual diligence. But it is worth it in\norder to be invisible.\nThe most important takeaways are: first, be aware of all the ways that\nsomeone can identify you even if you undertake some but not all of the\nprecautions I’ve described. And if you do undertake all these precautions,\nknow that you need to perform due diligence every time you use your\nanonymous accounts. No exceptions.\nIt’s also worth reiterating that end-to-end encryption—keeping your\nmessage unreadable and secure until it reaches the recipient as opposed to\nsimply encrypting it—is very important. End-to-end encryption can be\nused for other purposes, such as encrypted phone calls and instant\nmessaging, which we’ll discuss in the next two chapters."
  },
  {
    "input": "How can law enforcement or other entities track a person's location or communications using cellular technology and what steps can individuals take to protect their privacy?",
    "summary": "Wiretapping involves intercepting signals from cellular towers, which can track users' locations and communications. IMSI catchers and SS7 protocols allow law enforcement to monitor phone activity, even with burner phones, as they can be traced through patterns of usage. While encryption can help protect calls, systems like SDES and VoIP services often share keys with carriers, making them less secure. Signal, however, offers true end-to-end encryption with perfect forward secrecy, making it harder for authorities to access conversations.",
    "output": "CHAPTER THREE\nWiretapping 101\nYou spend countless hours on\nyour cell phone every day,\nchatting, texting, surfing the Internet. But do you actually know how your\ncell phone works?\nCellular service, which we use on our mobile devices, is wireless and\nrelies upon cellular towers, or base stations. To maintain connectivity, cell\nphones continually send out tiny beacons to the tower or towers physically\nclosest to them. The signal response to those beacons from the towers\ntranslates into the number of “bars” you have—no bars, no signal.\nTo protect the identity of the user somewhat, these beacons from your\ncell phone use what is known as international mobile subscriber identity,\nor IMSI, a unique number assigned to your SIM card. This was originally\nfrom the time when cellular networks needed to know when you were on\ntheir towers and when you were roaming (using other carriers’ cell\ntowers). The first part of the IMSI code uniquely identifies the mobile\nnetwork operator, and the remaining part identifies your mobile phone to\nthat network operator.\nLaw enforcement has created devices that pretend to be cellular base\nstations. These are designed to intercept voice and text messages. In the\nUnited States, law enforcement and intelligence agencies also use other\ndevices to catch IMSIs (see here). The IMSI is captured instantly, in less\nthan a second, and without warning. Typically IMSI catchers are used at\nlarge rallies, allowing law enforcement to later identify who was in\nattendance, particularly if those individuals were actively calling others to\njoin in.\nDevices like these can also be used by commuting services and apps to\ncreate traffic reports. Here the actual account number, or IMSI, doesn’t\nmatter, only how fast your cell phone moves from tower to tower or\ngeographic region to geographic region. The amount of time it takes a cell\nphone to come and go from each tower determines the traffic status: red,\nyellow, or green.1\nYour mobile device connects to a series of cellular towers whenever it’s\npowered up. The closest tower actually handles your call, text, or Internet\nsession. As you move around, your phone pings the nearest tower and, if\nnecessary, your call moves from tower to tower, all the while maintaining\nconsistency. The other nearby towers are all on standby, so that if you\nmove from point A to point B and another tower comes into range for a\nbetter signal, then the handoff is smooth and you shouldn’t experience a\ndropped call.\nSuffice it to say that your mobile device emits a unique sequence that\nis logged on a number of individual cellular towers. So anyone looking at\nthe logs of a specific tower would see the temporary mobile subscriber\nidentity (TMSI) of all the people in the general area at any given moment,\nwhether they made calls or not. Law enforcement can and does request this\ninformation from cellular carriers, including the back-end account\nidentities of specific holders.\nOrdinarily, if you look at just one cell tower’s log, the data might only\nshow that someone was passing through and that his or her device\ncontacted a specific cell tower as a standby. If a call was made or if data\nwas exchanged, there would also be a record of that call and its duration.\nData from multiple cell-tower logs, however, can be used to\ngeographically pinpoint a user. Most mobile devices ping three or more\ntowers at a time. Using logs from those cell towers, someone can\ntriangulate, based on the relative strength of each ping, a fairly exact\nlocation of the phone’s user. So the phone you carry around every day is\nessentially a tracking device.\nHow can you avoid being tracked?\nSigning a contract with a cell-phone carrier requires a name, address,\nand a Social Security number. Additionally, there’s a credit check to make\nsure you can pay your monthly bill. You can’t avoid this if you go with a\ncommercial carrier.\nA burner phone seems like a reasonable option. A prepaid cell phone,\nperhaps one that you replace frequently (say, weekly or even monthly),\navoids leaving much of a trail. Your TMSI will show up on cell tower logs,\nthen disappear. If you purchased the phone discreetly, it won’t be traceable\nback to a subscriber account. Prepaid cell services are still subscriber\naccounts, so the IMSI will always be assigned to an account. Therefore, a\nperson’s anonymity depends on how he or she acquired the burner device.\nFor the sake of argument, let’s assume you have successfully\ndisconnected yourself from the purchase of a burner phone. You followed\nthe steps outlined here and used a person unrelated to you to purchase the\nphone for cash. Is the use of that disposable phone untraceable? The short\nanswer is no.\nHere’s a cautionary tale: one afternoon in 2007, a $500 million container\nloaded with the drug ecstasy went missing from a port in Melbourne,\nAustralia. The owner of the container, Pat Barbaro, a known drug dealer,\nreached into his pocket, pulled out one of his twelve cell phones, and\ndialed the number of a local reporter, Nick McKenzie, who would only\nknow the caller by the name Stan.Barbaro would later use his other burner\nphones to text McKenzie, attempting to anonymously obtain information\nfrom the investigative reporter about the missing container. As we will\nsee, this didn’t work.\nBurner phones, despite what many people may think, are not truly\nanonymous. Under the US Communications Assistance for Law\nEnforcement Act (CALEA), all IMSIs connected with burner phones are\nreported, just as those subscribers under contract with major carriers are.\nIn other words, a law enforcement official can spot a burner phone from a\nlog file just as easily as he can spot a registered contract phone. While the\nIMSI won’t identify who owns the phone, patterns of usage might.\nIn Australia, where CALEA does not exist, law enforcement was still\nable to keep tabs on Barbaro’s many phones using rather traditional\nmethods. For instance, they might have noticed a call made with his\npersonal phone and then a few seconds later seen in the log files another\ncall or text from one of his burner phones in the same cell site. Over time,\nthe fact that these IMSIs more often than not appeared together on the\nsame cell sites might suggest that they belonged to a single individual.\nThe problem with Barbaro’s having many cell phones at his disposal\nwas that no matter which phone he used, personal or burner, so long as he\nstayed in the same spot, the signal would hit the same cellular tower. The\nburner-phone calls always appeared next to his registered-phone calls. The\nregistered phone, listed in his name with a carrier, was entirely traceable\nand helped law enforcement identify him. It established a solid case\nagainst him, particularly because this pattern was repeated at other\nlocations. This helped Australian authorities convict Barbaro of\norchestrating one of the largest ecstasy shipments in Australia’s history.\nMcKenzie concluded, “Ever since the phone buzzed that day in my\npocket, and ‘Stan’ briefly entered my life, I’ve been especially conscious\nabout how a person’s communications leave a trail, no matter how careful\nthey are.”2\nYou could, of course, have only a burner phone. This would mean that\nyou would need to purchase additional minutes anonymously using\nprepaid cards or Bitcoin from time to time, which you can do by using an\nopen Wi-Fi safely after changing your media access control (MAC)\naddress on your wireless card (see here), and being out of any camera\nview. Or you could, as suggested in the previous chapter, hire a stranger to\npay cash at the store to purchase the prepaid phone and several refill\ncards.3 This adds cost and perhaps inconvenience, but you would have an\nanonymous phone.\nAlthough it may seem brand new, cellular technology is more than forty\nyears old, and it, like copper-wire telephone systems, contains legacy\ntechnologies that can compromise your privacy.\nEach generation of cell-phone technology has offered new features,\nmostly intended to move more data more efficiently. First-generation\nphones, or 1G, had the telephone technology available in the 1980s. These\nearly 1G networks and handsets were analog-based, and they used a\nvariety of now discontinued mobile standards. In 1991, the second-\ngeneration (2G) digital network was introduced. This 2G network offered\ntwo standards: global system for mobile communications (GSM) and code\ndivision multiple access (CDMA). It also introduced short message\nservice (SMS), unstructured supplementary services data (USSD), and\nother simple communications protocols that are still in use today. We’re\ncurrently in the middle of 4G/LTE and on the way toward 5G.\nNo matter what generation of technology a given carrier is using (2G,\n3G, 4G, or 4G/LTE), there is an underlying international signal protocol\nknown as the signaling system. The signaling system protocol (currently\nin version 7), among other things, keeps mobile calls connected when you\ndrive along a freeway and switch from cell tower to cell tower. It can also\nbe used for surveillance. Signaling system 7 (SS7) does basically\neverything necessary to route a call, such as:\nSetting up a new connection for a call\nTearing down that connection when the call ends\nBilling the appropriate party making the call\nManaging extra features such as call-forwarding, calling party name\nand number display, three-way calling, and other Intelligent Network\n(IN) services\nToll-free (800 and 888) as well as toll (900) calls\nWireless services, including subscriber identification, carrier, and\nmobile roaming\nSpeaking at the Chaos Communication Congress, an annual computer\nhacker conference held in Berlin, Germany, Tobias Engel, founder of\nSternraute, and Karsten Nohl, chief scientist for Security Research Labs,\nexplained that they could not only locate cell-phone callers anywhere in\nthe world, they could also listen in on their phone conversations. And if\nthey couldn’t listen in real time, they could record the encrypted calls and\ntexts for later decryption.\nIn security, you are only as secure as the weakest link. What Engel and\nNohl found was that while developed countries in North America and\nEurope have invested billions in creating relatively secure and private 3G\nand 4G networks, they must still use signaling system 7 (SS7) as an\nunderlying protocol.\nSS7 handles the process for call-establishment, billing, routing, and\ninformation-exchange functions. Which means if you can tap into SS7,\nyou can manipulate the call. SS7 allows an attacker to use a small carrier\nin, say, Nigeria to access calls made in Europe or the United States. “It’s\nlike you secure the front door of the house, but the back door is wide\nopen,” said Engel.\nThe two researchers tested a method in which an attacker uses a\nphone’s call-forwarding function and SS7 to forward a target’s outgoing\ncalls to himself before conferencing (three-way calling) in their intended\nrecipient. Once the attacker has established himself, he can listen to all\ncalls made by the targeted individual from any place on earth.\nAnother strategy would be for the attacker to set up radio antennas to\ncollect all cellular calls and texts within a given area. For any encrypted\n3G calls, the attacker could ask SS7 to provide him with the proper\ndecryption key.\n“It’s all automated, at the push of a button,” Nohl said. “It would strike\nme as a perfect spying capability, to record and decrypt pretty much any\nnetwork… Any network we have tested, it works.”4 He then enumerated\nalmost every major carrier in North America and Europe, around twenty in\nall.\nNohl and Engel also found that they could locate any cell-phone user\nby using an SS7 function called an anytime interrogation query. That is,\nthey could do so until the function was shut down early in 2015. However,\nsince all carriers must track their users in order to provide service, SS7\nprovides other functions that still allow some remote surveillance. It\nshould be noted that the specific flaws identified by Nohl and Engel have\nbeen mostly mitigated by the carriers since their research went public.\nYou might think that encryption alone would help keep cell-phone calls\nprivate. Beginning with 2G, GSM-based phone calls have been encrypted.\nHowever, the initial methods used to encrypt calls in 2G were weak and\neventually broke down. Unfortunately, the cost of upgrading cellular\nnetworks to 3G proved prohibitive for many carriers, so a weakened 2G\nremained in use until around 2010 or so.\nIn the summer of 2010, a team of researchers led by Nohl divided all\nthe possible encryption keys used by 2G GSM networks among themselves\nand crunched the numbers to produce what’s called a rainbow table, a list\nof precomputed keys or passwords. They published the table to show\ncarriers around the world just how insecure 2G encryption using GSM is.\nEach packet—or unit of data between source and destination—of voice,\ntext, or data sent over 2G GSM could be decrypted in just a few minutes\nusing the published table of keys.5 This was an extreme example, but the\nteam considered it necessary; when Nohl and others had previously\npresented their findings to the carriers, their warnings fell on deaf ears. By\ndemonstrating how they could crack 2G GSM encryption, they more or\nless forced the carriers to make the change.\nIt is important to note that 2G still exists today, and carriers are\nconsidering selling access to their old 2G networks for use in Internet of\nThings devices (devices other than computers that connect to the Internet,\nsuch as your TV and refrigerator), which only need occasional data\ntransmission. If this happens, we will need to make sure the devices\nthemselves have end-to-end encryption because we know that 2G will not\nprovide strong enough encryption by itself.\nOf course eavesdropping existed before mobile devices really took off. For\nAnita Busch, the nightmare started the morning of June 20, 2002, when\nshe awoke to a neighbor’s urgent knock on her door. Someone had put a\nbullet hole in the windshield of her car as it sat in the driveway. Not only\nthat, someone had also left Busch a rose, a dead fish, and a one-word note\n—“Stop”—on the car’s hood.6 Later she would learn that her phones had\nbeen tapped, and not by law enforcement.\nThe fact that the scene with a bullet hole and a dead fish was\nreminiscent of a bad Hollywood gangster movie made some sense. Busch,\na seasoned reporter, was at the time only a few weeks into a freelance\nassignment chronicling organized crime’s growing influence in Hollywood\nfor the Los Angeles Times. She was researching Steven Seagal and his\nformer business partner, Julius R. Nasso, who had been indicted for\nconspiring with the New York Mafia to extort money from Seagal.7\nWhat followed finding the note on her car was a series of phone\nmessages. The caller apparently wanted to share some information about\nSeagal. Much later Busch learned that the caller had been hired by\nAnthony Pellicano, a former high-profile Los Angeles private investigator\nwho at the time Busch’s car was tampered with was already suspected by\nthe FBI of illegal wiretapping, bribery, identity theft, and obstruction of\njustice. Busch’s copper-wire phone had been tapped by Pellicano, who\nknew by eavesdropping on her calls that she was writing a newspaper story\nabout his clients. The fish head on her car was an attempt to warn her off.\nTypically wiretapping is only associated with phone calls, but\nwiretapping laws in the United States can also cover eavesdropping on e-\nmail and instant messages. For the moment I’ll focus on wiretapping’s\ntraditional use, in copper-wire landlines.\nLandlines are the hardwired phones in your home or business, and\nwiretapping involves literally tapping into the live wire. Back in the day,\nphone companies each had physical banks of switches on which they\nperformed a version of wiretapping. What that means is that the phone\ncompany had special appliances that the frame techs hooked up to the\ntarget phone number on the mainframe in the central office. There is\nadditional wiretapping equipment that dials into this appliance and is used\nto monitor the target. Today, that way of eavesdropping is retired: phone\ncompanies are all required to implement the technical requirements\nmandated by CALEA.\nAlthough a growing number of people today have shifted to mobile\nphones, many still retain their landlines for their copper-wire\ndependability. Others use what’s called Voice over Internet Protocol (VoIP)\ntechnology, which is telephony over the Internet and usually bundled in the\nhome or office with your cable or Internet service. Whether it’s a physical\nswitch at the phone company or a digital switch, law enforcement does\nhave the ability to eavesdrop on calls.\nThe 1994 CALEA requires telecommunications manufacturers and\ncarriers to modify their equipment for the purposes of allowing law\nenforcement to wiretap the line. So under CALEA, any landline call in the\nUnited States is theoretically subject to interception. And under CALEA,\nall law enforcement access requires a Title III warrant. That said, it’s still\nillegal for an ordinary citizen to conduct a wiretap, which is what Anthony\nPellicano did to covertly monitor Anita Busch and others. His list of\neavesdropping victims happens to include Hollywood celebrities such as\nSylvester Stallone, David Carradine, and Kevin Nealon, among others.\nHis list of wiretap victims also includes my friend Erin Finn, because\nher ex-boyfriend was obsessed with her and wanted to track her every\nmove. Because her phone line had been tapped, I, too, was monitored when\nI called her. The coolest part of the saga is that AT&T paid me thousands\nof dollars as part of a class-action settlement because of Pellicano’s\nwiretapping of my calls to Finn. Which is somewhat ironic, because on\nanother occasion, I was the one doing the tapping. Pellicano’s purpose in\nwiretapping people was perhaps more malicious than mine; he was trying\nto intimidate witnesses into either not testifying or testifying in a certain\nway.\nBack in the mid-1990s, a wiretap had to be installed by technicians. So\nPellicano, or one of his people, had to hire someone who worked at\nPacBell to tap Busch’s and Finn’s telephone lines. The technicians were\nable to set up extensions of the target phones at Pellicano’s office, in\nBeverly Hills. In this case there were no taps done at the junction box, or\nthe terminal at the side of the house or apartment complex, although that\nis also possible.8\nAs you may recall from reading my previous book Ghost in the Wires, I\nonce drove down from my father’s apartment in Calabasas to Long Beach\nto set up a physical wiretap on a phone line used by Kent, a friend of my\nlate brother. There were many questions surrounding my brother’s death,\nfrom a drug overdose, and I believed he had a part in that death, though I\nlater learned he was not involved. In the utility space within the apartment\ncomplex where Kent lived, I used social engineering to pretend to be a line\ntechnician calling a particular unit within GTE (General Telephone and\nElectronics) to find where the cable and pair assigned to Kent’s phone\nwere located. It turned out that Kent’s phone wires ran through a\ncompletely separate apartment building. And so in a second utility space, I\nwas ultimately able to clip my voice-activated microcassette tape recorder\nto his phone line at the terminal box (the place where phone company\ntechnicians connect the lines to each apartment).\nAfter that, anytime Kent made a call, I could record both sides of the\nconversation without his knowing I was doing so—though I should note\nthat while the recordings were in real time, my listening to them was not.\nEvery day over the next ten days I had to make the sixty-minute drive to\nKent’s apartment, afterward listening to the retrieved tapes for any\nmention of my brother. Unfortunately, nothing ever came of it. Years later\nI learned that my uncle had likely been responsible for my brother’s death.\nGiven how easy it was for Pellicano and me to tap into private phone\nconversations, you may wonder how you can become invisible with a\ncopper-wire landline phone that is apparently open to surveillance? You\ncan’t, without buying special equipment. For the truly paranoid, there are\nlandline phones that will encrypt all your voice conversations over copper\nwires.9 These phones do solve the problem of interception of private\nphone calls, but only if both ends of the call use encryption; otherwise\nthey may be easy to monitor.10 For the rest of us, there are some basic\ntelephone choices we can make to avoid being eavesdropped on.\nThe move toward digital telephony has made surveillance easier, not\nharder. Today, if a tap is necessary on a digital phone line, it can be done\nremotely. The switching computer simply creates a second, parallel stream\nof data; no additional monitoring equipment is required. This also makes\nit much harder to determine whether a given line has been tapped. And in\nmost cases such taps are only discovered by accident.\nShortly after Greece hosted the 2004 Summer Olympics, engineers at\nVodafone-Panafon removed some rogue software that had been discovered\nto be running in the company’s cellular network for more than a year. In\npractice, law enforcement intercepts all voice and text data sent over any\ncellular network through a remote-controlled system called RES (remote-\ncontrol equipment subsystem), the digital equivalent of an analog wiretap.\nWhen a subject under surveillance makes a mobile call, the RES creates a\nsecond data stream that feeds directly to a law enforcement officer.\nThe rogue software discovered in Greece tapped into Vodafone’s RES,\nmeaning that someone other than a legitimate law enforcement officer was\nlistening to conversations conducted over its cellular network; in this case,\nthe wiretapper was interested in government officials. During the\nOlympics, some countries—such as the United States and Russia—\nprovided their own private communications systems for state-level\nconversations. Other heads of state and business executives from around\nthe world used the compromised Vodafone system.\nAn investigation showed that the communications of the Greek prime\nminister and his wife—as well as those of the mayor of Athens, the Greek\nEuropean Union commissioner, and the ministries of national defense,\nforeign affairs, the mercantile marine, and justice—had been monitored\nduring the Olympics. Other intercepted phones belonged to members of\ncivil rights organizations, antiglobalization groups, the ruling New\nDemocracy party, the Hellenic Navy general staff, as well as peace\nactivists and a Greek-American employee at the United States embassy in\nAthens.11\nThe spying might have continued longer had Vodafone not called in the\nhardware vendor for its RES system, Ericsson, while investigating a\nseparate complaint—that its text messages were suffering delivery failures\nat a higher than normal rate. After diagnosing the problem, Ericsson\nnotified Vodafone that it had found rogue software.\nUnfortunately, more than a decade afterward, we still don’t know who\ndid this. Or why. Or even how common this activity might be. To make\nmatters worse, Vodafone apparently mishandled the investigation.12 For\none thing, key log files covering the event were missing. And instead of\nletting the rogue program run after discovery—a common practice in\ncomputer criminal investigations—Vodafone abruptly removed it from\ntheir system, which may have tipped off the perpetrators and allowed them\nto further cover their tracks.\nThe Vodafone case is an unsettling reminder of how vulnerable our cell\nphones are to interception. But there are ways you can still be invisible\nwith a digital phone.\nBesides cell phones and old-fashioned landlines, a third telephony option,\nas I mentioned earlier, is Voice over Internet Protocol (VoIP). VoIP is\ngreat for any wireless device that lacks a native means of making a phone\ncall, e.g., an Apple iPod Touch; it’s more like surfing the Internet than\nmaking a classic phone call. Landlines require copper wire. Mobile phones\nuse cell towers. VoIP is simply transmitting your voice over the Internet—\neither using wired or wireless Internet services. VoIP also works on mobile\ndevices, such as laptops and tablets, whether or not they have cellular\nservice.\nTo save money, many homes and offices have switched to the VoIP\nsystems being offered by new service providers and existing cable\ncompanies. VoIP uses the same coaxial cable that brings streaming video\nand high-speed Internet into your home.\nThe good news is that VoIP phone systems do use encryption;\nspecifically, something called session description protocol security\ndescriptions, or SDES. The bad news is that on its own, SDES is not very\nsecure.\nPart of the problem with SDES is the encryption key is not shared over\nSSL/TLS (a network cryptographic protocol), which is secure. If the\nvendor doesn’t use SSL/TLS, however, then the key is sent in the clear.\nInstead of asymmetric encryption, it uses symmetric encryption, which\nmeans that the key generated by the sender must somehow be passed to the\nrecipient in order for the call to be unscrambled.\nLet’s say Bob wants to make a call to Alice, who is in China. Bob’s\nSDES-encrypted VoIP phone generates a new key for that call. Somehow\nBob has to get that new key to Alice so her VoIP equipment can decrypt\nhis phone call and they can have a conversation. The solution SDES offers\nis to send the key to Bob’s carrier, which then passes it to Alice’s carrier,\nwhich then shares it with her.\nDo you see the flaw? Remember what I said about end-to-end\nencryption in the previous chapter? The conversation stays secure until the\nrecipient opens it at the other end. But SDES shares the key from Bob to\nBob’s carrier and, if Alice’s carrier is different, the call is encrypted from\nAlice’s carrier to Alice. Whether the gap is significant is debatable.\nSomething like this also happens with Skype and Google Voice. New keys\nare generated whenever a call is initialized, but those keys are then given\nover to Microsoft and Google. So much for wanting to have a private\nconversation.\nFortunately, there are ways to encrypt mobile VoIP from end to end.\nSignal, an application from Open Whisper Systems, is a free, open-\nsource VoIP system for mobile phones that provides true end-to-end\nencryption for both iPhone and Android.13\nThe main advantage of using Signal is that the key management is\nhandled only between the calling parties, not through any third party. That\nmeans that, as in SDES, new keys are generated with each call; however,\nthe only copies of the keys are stored on the users’ devices. Since CALEA\nallows access to any record of a specific call, law enforcement would in\nthis case only see the encrypted traffic across the mobile carrier’s line,\nwhich would be unintelligible. And Open Whisper Systems, the nonprofit\norganization that makes Signal, does not have the keys, so a warrant would\nbe useless. The keys exist only on the devices at either end of the call. And\nonce the call ends, those session keys are destroyed.\nCurrently CALEA does not extend to end users or their devices.\nYou might think that having encryption on your cell phone would drain\nyour battery. It does, but not by much. Signal uses push notifications, as do\nthe apps WhatsApp and Telegram. Thus you only see a call when it is\nincoming, which cuts down on battery use while you’re listening for new\ncalls. The Android and iOS apps also use audio codecs and buffer\nalgorithms native to the mobile network, so again the encryption is not\ndraining a lot of power while you’re making a call.\nIn addition to using end-to-end encryption, Signal also uses perfect\nforward secrecy (PFS). What is PFS? It’s a system that uses a slightly\ndifferent encryption key for every call, so that even if someone does\nmanage to get hold of your encrypted phone call and the key that was used\nto encrypt it, your other calls will remain secure. All PFS keys are based\non a single original key, but the important thing is that if someone\ncompromises one key, it doesn’t mean your potential adversary has access\nto your further communications."
  },
  {
    "input": "What are the key considerations for keeping text messages private in the digital age, and what are some secure alternatives to native text messaging services?",
    "summary": "Not encrypting your mobile device means your text messages, emails, and other data can be accessed by others if they gain physical access. In 2014, the Washington State Supreme Court ruled that text messages should be protected under privacy laws, similar to traditional letters. To keep messages private, use end-to-end encrypted apps like Signal or Tor Messenger, which ensure only the sender and receiver can read them. However, even these apps may not be fully secure without independent review and proper setup.",
    "output": "CHAPTER FOUR\nIf You Don’t Encrypt, You’re Unequipped\nIf someone were to pick\nup your unlocked cell phone right now,\nthat person could gain access to your e-mail, your Facebook account, and\nperhaps even your Amazon account. On our mobile devices, we no longer\nlog in individually to services, as we do on our laptops and desktops; we\nhave mobile apps, and, once we’re logged in, they remain open. Besides\nyour photos and your music, there are other unique features on your cell\nphone, such as SMS text messages. These, too, become exposed if\nsomeone gains physical access to your unlocked mobile device.\nConsider this: in 2009 Daniel Lee of Longview, Washington, was\narrested on suspicion of selling drugs.1 While he was in custody the police\nwent through his non-password-protected cell phone and immediately\ndiscovered several drug-related text messages. One such thread was from\nan individual called Z-Jon.\nIt read, “I’ve got a hundred and thirty for the one-sixty I owe you from\nlast night.” According to court testimony, the Longview police didn’t just\nread Z-Jon’s messages to Lee, they also actively responded, arranging their\nown drug deal. Posing as Lee, the police sent Z-Jon a text message in\nreply, asking him if he “needed more.” Z-Jon responded, “Yeah, that would\nbe cool.” When Z-Jon (whose real name is Jonathan Roden) showed up for\nthat meeting, the Longview police arrested him for attempted heroin\npossession.\nThe police also noticed another thread of text messages on Lee’s phone\nand arrested Shawn Daniel Hinton under similar circumstances.2\nBoth men appealed, and in 2014, with the help of the American Civil\nLiberties Union, the Washington State Supreme Court overturned Roden’s\nand Hinton’s convictions by a lower court, asserting that the police had\nviolated the defendants’ expectation of privacy.\nThe Washington State justices said that had Lee seen the messages\nfrom Roden and Hinton first or instructed the police officers to respond by\nsaying “Daniel’s not here,” that would have changed the fundamentals in\nboth cases. “Text messages can encompass the same intimate subjects as\nphone calls, sealed letters and other traditional forms of communication\nthat have historically been strongly protected under Washington law,”\nJustice Steven Gonzalez wrote in Hinton’s case.3\nThe justices ruled that the expectation of privacy should extend from\nthe paper-letter era into the digital age. In the United States, law\nenforcement is not permitted to open a physically sealed letter without the\nrecipient’s permission. The expectation of privacy is a legal test. It is used\nto determine whether the privacy protections within the Fourth\nAmendment to the United States Constitution apply. It remains to be seen\nhow the courts decide future cases and whether they include this legal test.\nText technology—also known as short message service, or SMS—has been\naround since 1992. Cell phones, even feature phones (i.e., non-\nsmartphones), allow for sending brief text messages. Text messages are\nnot necessarily point-to-point: in other words, the messages do not\nliterally travel from phone to phone. Like an e-mail, the message you type\nout on your phone is sent unencrypted, in the clear, to a short message\nservice center (SMSC), part of the mobile network designed to store,\nforward, and deliver the SMS—sometimes hours later.\nNative mobile text messages—those initiated from your phone and not\nan app—pass through an SMSC at the carrier, where they may or may not\nbe not stored. The carriers state they retain texts for only a few days. After\nthat time has expired, the carriers insist that your text messages are stored\nonly on the phones that send and receive them, and the number of\nmessages stored varies by the phone model. Despite these claims, I think\nall mobile operators in the United States retain text messages regardless of\nwhat they tell the public.4\nThere is some doubt surrounding this claim by the carriers. Documents\nexposed by Edward Snowden suggest a tight relationship between the NSA\nand at least one of the carriers, AT&T. According to Wired, beginning in\n2002—shortly after 9/11—the NSA approached AT&T and asked them to\nbegin building secret rooms in some of the carrier’s facilities. One was to\nbe located in Bridgeton, Missouri, and another on Folsom Street in\ndowntown San Francisco. Eventually other cities were added, including\nSeattle, San Jose, Los Angeles, and San Diego. The purpose of these secret\nrooms was to channel all the Internet, e-mail, and phone traffic through a\nspecial filter that would look for keywords. It is unclear whether text\nmessages were included, although it seems reasonable to think they were.\nIt is also unclear whether this practice still exists at AT&T or any other\ncarrier post-Snowden.5\nOne clue suggests that this practice does not continue.\nIn the 2015 AFC championship game, leading up to Super Bowl XLIX,\nthe New England Patriots ignited controversy with their victory over the\nIndianapolis Colts, 45–7. At the heart of the controversy was whether the\nNew England team had knowingly underinflated their footballs. The\nNational Football League has strict rules around the proper inflation of its\nfootballs, and after that playoff game it was determined that the balls\ncontributed by the New England team did not meet the criteria. Central to\nthe investigation were text messages sent by the Patriots’ star quarterback,\nTom Brady.\nPublicly Brady denied involvement. Showing investigators the text\nmessages he sent and received before and during the game would have\nperhaps confirmed this. Unfortunately, the day he met with key\ninvestigators, Brady abruptly switched cell phones, discarding the one he\nhad used between November 2014 and approximately March 6, 2015, to a\nbrand-new phone. Brady later told the committee that he had destroyed his\noriginal phone and all the data on it, including his stored text messages. As\na result Brady received a four-game suspension from the NFL, which was\nlater lifted by court order.6\n“During the four months that the cell phone was in use, Brady had\nexchanged nearly 10,000 text messages, none of which can now be\nretrieved from that device,” the league said. “Following the appeal\nhearing, Mr. Brady’s representatives provided a letter from his cellphone\ncarrier confirming that the text messages sent from or received by the\ndestroyed cellphone could no longer be recovered.”7\nSo if Tom Brady had a note from his carrier saying that his text\nmessages were all destroyed, and the carriers themselves say they don’t\nretain them, the only way to prolong the life of a text is to back up your\nmobile device to the cloud. If you use a service from your carrier, or even\nfrom Google or Apple, those companies may have access to your text\nmessages. Apparently Tom Brady didn’t have time to back up the contents\nof his old phone to the cloud before his emergency upgrade.\nCongress has not addressed the issue of data retention in general and\nmobile phones in particular. In fact, Congress has debated in recent years\nwhether to require all mobile carriers to archive text messages for up to\ntwo years. Australia decided to do this in 2015, so it remains to be seen if\nthis works there.\nSo how can you keep your text messages private? First of all, don’t use the\nnative text messaging service that goes through your wireless carrier.\nInstead use a third-party app. But which one?\nTo mask our online identities—to enjoy the Internet anonymously—we\nwill need to trust some software and software services. That trust is hard to\nverify. In general, open-source and nonprofit organizations provide\nperhaps the most secure software and services because there are literally\nthousands of eyes poring over the code and flagging anything that looks\nsuspicious or vulnerable. When you use proprietary software, you more or\nless have to take the vendor’s word.\nSoftware reviews, by their nature, can only tell you so much—such as\nhow a particular interface feature works. The reviewers spend a few days\nwith the software and write their impressions. They don’t actually use the\nsoftware, nor can they report on what happens over the long term. They\nonly record their initial impressions.\nIn addition, reviewers do not tell you whether you can trust the\nsoftware. They don’t vet the security and privacy aspects of the product.\nAnd just because a product comes from a well-known brand name doesn’t\nmean it is secure. In fact we should be wary of popular brand names\nbecause they may lure us into a false sense of security. You shouldn’t take\nthe vendor at its word.\nBack in the 1990s, when I needed to encrypt my Windows 95 laptop, I\nchose a now discontinued utility product from Norton called Norton\nDiskreet. Peter Norton is a genius. His first computer utility automated the\nprocess of undeleting a file. He went on to create a lot of great system\nutilities back in the 1980s, at a time when few people could understand a\ncommand prompt. But then he sold the company to Symantec, and\nsomeone else started writing the software in his name.\nAt the time I acquired Diskreet, a product that is no longer available,\n56-bit DES encryption (DES stands for “data encryption standard”) was a\nbig deal. It was the strongest encryption you could hope for. To give you\nsome context, today we use AES 256-bit encryption (AES stands for\n“advanced encryption standard”). Each added bit of encryption adds\nexponentially more encryption keys and therefore more security. DES 56-\nbit encryption was considered state-of-the-art secure until it was cracked\nin 1998.8\nAnyway, I wanted to see whether the Diskreet program was robust\nenough to hide my data. I also wanted to challenge the FBI if they ever\nseized my computer. After purchasing the program I hacked into Symantec\nand located the program’s source code.9 After I analyzed what it did and\nhow it did it, I discovered that Diskreet only used thirty bits of the 56-bit\nkey—the rest was just padding with zeros.10 That’s even less secure than\nthe forty bits that was allowed to be exported outside the United States.\nWhat that meant in practical terms was that someone—the NSA, law\nenforcement, or an enemy with a very fast computer—could crack the\nDiskreet product much more easily than advertised, since it didn’t really\nuse 56-bit encryption at all. Yet the company was marketing the product as\nhaving 56-bit encryption. I decided to use something else instead.\nHow would the public know this? They wouldn’t.\nAlthough social networks such as Facebook, Snapchat, and Instagram rank\nat the top when it comes to popularity among teens, text messaging reigns\nsupreme overall, according to data supplied by Niche.com.11 A recent\nstudy found that 87 percent of teenagers text daily, compared to the 61\npercent who say they use Facebook, the next most popular choice. Girls\nsend, on average, about 3,952 text messages per month, and boys send\ncloser to 2,815 text messages per month, according to the study.12\nThe good news is that today all the popular messaging apps provide\nsome form of encryption when sending and receiving your texts—that is,\nthey protect what’s called “data in motion.” The bad news is that not all\nthe encryption being used is strong. In 2014, researcher Paul Jauregui of\nthe security firm Praetorian found that it was possible to circumvent the\nencryption used by WhatsApp and engage in a man-in-the-middle (MitM)\nattack, in which the attacker intercepts messages between the victim and\nhis recipient and is able to see every message. “This is the kind of stuff the\nNSA would love,” Jauregui observed.13 As of this writing, the encryption\nused in WhatsApp has been updated and uses end-to-end encryption on\nboth iOS and Android devices. And the parent company for WhatsApp,\nFacebook, has added encryption to its 900 million Messenger users,\nalthough it is an opt-in, meaning you have to configure “Secret\nConversations” to work.14\nThe worse news is what happens to data that’s archived, or “data at\nrest.” Most mobile text apps do not encrypt archived data, either on your\ndevice or on a third-party system. Apps such as AIM, BlackBerry\nMessenger, and Skype all store your messages without encrypting them.\nThat means the service provider can read the content (if it’s stored in the\ncloud) and use it for advertising. It also means that if law enforcement—or\ncriminal hackers—were to gain access to the physical device, they could\nalso read those messages.\nAnother issue is data retention, which we mentioned above—how long\ndoes data at rest stay at rest? If apps such as AIM and Skype archive your\nmessages without encryption, how long do they keep them? Microsoft,\nwhich owns Skype, has said that “Skype uses automated scanning within\nInstant Messages and SMS to (a) identify suspected spam and/or (b)\nidentify URLs that have been previously flagged as spam, fraud, or\nphishing links.” So far this sounds like the anti-malware scanning activity\nthat companies perform on our e-mails. However, the privacy policy goes\non to say: “Skype will retain your information for as long as is necessary\nto: (1) fulfill any of the Purposes (as defined in article 2 of this Privacy\nPolicy) or (2) comply with applicable legislation, regulatory requests and\nrelevant orders from competent courts.”15\nThat doesn’t sound so good. How long is “as long as is necessary”?\nAOL Instant Messenger (AIM) may have been the first instant message\nservice that any of us used. It’s been around a long while. Designed for\ndesktop or traditional PCs, AIM originally took the form of a little pop-up\nwindow that appeared in the lower right-hand corner of the desktop. Today\nit is available as a mobile app as well. But in terms of privacy, AIM raises\nsome red flags. First, AIM keeps an archive of all messages sent through\nits service. And, like Skype, it also scans the contents of those messages.\nA third concern is that AOL keeps records of the messages in the cloud in\ncase you ever want to access a chat history from any terminal or device\ndifferent from the one where you had your last session.16\nSince your AOL chat data is not encrypted and is available from any\nterminal because it lives in the cloud, it is easy for law enforcement and\ncriminal hackers to get a copy. For example, my AOL account was hacked\nby a script kiddie whose online handle is Virus—his real name is Michael\nNieves.17 He was able to social-engineer (in other words, get on the phone\nand sweet-talk) AOL and gain access to their internal customer-database\nsystem, called Merlin, which allowed him to change my e-mail address to\none associated with a separate account under his control. Once he did that\nhe was able to reset my password and gain access to all my past messages.\nIn 2007 Nieves was charged with four felonies and a misdemeanor for,\naccording to the complaint, hacking into “internal AOL computer\nnetworks and databases, including customer billing records, addresses and\ncredit card information.”\nAs the Electronic Frontier Foundation has said, “no logs are good\nlogs.” AOL has logs.\nNon-native text apps may say they have encryption, but it might not be\ngood or strong encryption. What should you look for? A text app that\nprovides end-to-end encryption, meaning that no third-party has access to\nthe keys. The keys should exist on each device only. Note, too, if either\ndevice is compromised with malware, then using any type of encryption is\nworthless.\nThere are three basic “flavors” of text apps:\nThose that provide no encryption at all—meaning that anyone can\nread your text messages.\nThose that provide encryption, but not from end to end—meaning\nthat the communication can be intercepted by third parties such as\nthe service provider, which has knowledge of the encryption keys.\nThose that provide encryption from end to end—meaning that the\ncommunication can’t be read by third parties because the keys are\nstored on the individual devices.\nUnfortunately the most popular text-messaging apps—like AIM—are\nnot very private. Even Whisper and Secret may not be totally private.\nWhisper is used by millions and markets itself as anonymous, but\nresearchers have poked holes in these claims. Whisper tracks its users,\nwhile the identities of Secret users are sometimes revealed.\nTelegram is another messaging app that offers encryption, and it is\nconsidered a popular alternative to WhatsApp. It runs on Android, iOS,\nand Windows devices. Researchers have, however, found an adversary can\ncompromise Telegram servers and get access to critical data.18 And\nresearchers have found it easy to retrieve encrypted Telegram messages,\neven after they have been deleted from the device.19\nSo now that we’ve eliminated some popular choices, what remains?\nPlenty. When you’re on the app store or Google Play, look for apps that\nuse something called off-the-record messaging, or OTR. It is a higher-\nstandard end-to-end encryption protocol used for text messages, and it can\nbe found in a number of products.20\nYour ideal text message app should also include perfect forward\nsecrecy (PFS). Remember that this employs a randomly generated session\nkey that is designed to be resilient in the future. That means if one key is\ncompromised, it can’t be used to read your future text messages.\nThere are several apps that use both OTR and PFS.\nChatSecure is a secure text-messaging app that works on both Android\nand iPhones.21 It also provides something called certificate pinning. That\nmeans it includes a proof-of-identity certificate, which is stored on the\ndevice. Upon each contact with the servers at ChatSecure, the certificate\nwithin the app on your device is compared with the certificate at the\nmother ship. If the stored certificate does not match, the session does not\ncontinue. Another nice touch is that ChatSecure also encrypts the\nconversation logs stored on the device—the data at rest.22\nPerhaps the best open-source option is Signal from Open Whisper\nSystems, which works on both iOS and Android (see here).\nAnother text-messaging app to consider is Cryptocat. It is available for\niPhone and most major browsers on your traditional PC. It is not, however,\navailable for Android.23\nAnd, at the time of this writing, the Tor project, which maintains the\nTor browser (see here), has just released Tor Messenger. Like the Tor\nbrowser, the app anonymizes your IP address, which means that messages\nare difficult to trace (however, please note that, like with the Tor browser,\nexit nodes are not by default under your control; see here). Instant\nmessages are encrypted using end-to-end encryption. Like Tor, the app is a\nlittle difficult for the first-time user, but eventually it should work to\nprovide truly private text messages.24\nThere are also commercial apps that provide end-to-end encryption.\nThe only caveat is that their software is proprietary, and without\nindependent review their security and integrity cannot be confirmed.\nSilent Phone offers end-to-end encryption text messaging. It does,\nhowever, log some data, but only to improve its services. The encryption\nkeys are stored on the device. Having the keys on the device means that\nthe government or law enforcement can’t compel Silent Circle, its\nmanufacturer, to release the encryption keys for any of its subscribers.\nI’ve discussed encrypting data in motion and data at rest as well as\nusing end-to-end encryption, PFS, and OTR to do so. What about non-app-\nbased services, such as Web mail? What about passwords?"
  },
  {
    "input": "What are the steps one can take to protect their online privacy and avoid having their browsing history or location data tracked by others or law enforcement?",
    "summary": "The text discusses how deleting browser history can lead to legal consequences, as seen in the cases of Khairullozhon Matanov and David Kernell. It explains that the Sarbanes-Oxley Act requires browser history to be retained, and that even with private browsing, data can still be tracked by internet service providers or websites. The text also provides tips on how to protect privacy online, such as using HTTPS Everywhere, disabling geolocation, and using proxies or encrypted search engines like DuckDuckGo.",
    "output": "CHAPTER FIVE\nNow You See Me, Now You Don’t\nIn April of 2013, Khairullozhon Matanov\n, a twenty-two-\nyear-old former cab driver from Quincy, Massachusetts, went to dinner\nwith a couple of friends—a pair of brothers, in fact. Among other topics,\nthe three men talked about events earlier in the day that occurred near the\nfinish line of the Boston Marathon, where someone had planted rice\ncookers packed with nails and gunpowder and a timer. The resulting blasts\nclaimed three lives and left more than two hundred people injured. The\nbrothers at Matanov’s table, Tamerlan and Dzhokhar Tsarnaev, would later\nbe identified as the prime suspects.\nAlthough Matanov said later that he had no prior knowledge of the\nbombing, he allegedly left an early post-bombing meeting with law\nenforcement officers and promptly deleted the browser history from his\npersonal computer. That simple act—erasing his laptop’s browser history\n—resulted in charges against him.1\nDeleting browser history was also one of the charges against David\nKernell, the college student who hacked Sarah Palin’s e-mail account.\nWhat’s chilling is that when Kernell cleared his browser, ran a disk\ndefragmenter, and deleted the Palin photos he had downloaded, he wasn’t\nyet under investigation. The message here is that in the United States you\nare not allowed to erase anything you do on your computer. Prosecutors\nwant to see your entire browser history.\nThe charges leveled against Matanov and Kernell stem from a nearly\nfifteen-year-old law—the Public Company Accounting Reform and\nInvestor Protection Act (as it’s known in the Senate), or the Corporate and\nAuditing Accountability and Responsibility Act (as it’s known in the\nHouse), more commonly called the Sarbanes-Oxley Act of 2002. The law\nwas a direct result of corporate mismanagement at Enron, a natural gas\ncompany later found to be lying and cheating investors and the US\ngovernment. Investigators in the Enron case discovered that a lot of data\nhad been deleted at the outset of the investigation, preventing prosecutors\nfrom seeing exactly what had gone on within the company. As a result,\nSenator Paul Sarbanes (D-MD) and Representative Michael G. Oxley (R-\nOH) sponsored legislation that imposed a series of requirements aimed at\npreserving data. One was that browser histories must be retained.\nAccording to a grand jury indictment, Matanov deleted his Google\nChrome browser history selectively, leaving behind activity from certain\ndays during the week of April 15, 2013.2 Officially he was indicted on two\ncounts: “(1) destroying, altering, and falsifying records, documents, and\ntangible objects in a federal investigation, and (2) making a materially\nfalse, fictitious, and fraudulent statement in a federal investigation\ninvolving international and domestic terrorism.”3 He was sentenced to\nthirty months in prison.\nTo date, the browser-history provision of Sarbanes-Oxley has rarely\nbeen invoked—either against businesses or individuals. And yes,\nMatanov’s case is an anomaly, a high-profile national security case. In its\nwake, though, prosecutors, aware of its potential, have started invoking it\nmore frequently.\nIf you can’t stop someone from monitoring your e-mail, phone calls, and\ninstant messages, and if you can’t lawfully delete your browser history,\nwhat can you do? Perhaps you can avoid collecting such history in the first\nplace.\nBrowsers such as Mozilla’s Firefox, Google’s Chrome, Apple’s Safari,\nand Microsoft’s Internet Explorer and Edge all offer a built-in alternative\nway to search anonymously on whatever device you prefer—whether you\nuse a traditional PC or a mobile device. In each case the browser itself will\nopen a new window and not record what you searched or where you went\non the Internet during that open session. Shut down the private browser\nwindow, and all traces of the sites you visited will disappear from your PC\nor device. What you exchange for privacy is that unless you bookmark a\nsite while using private browsing, you can’t go back to it; there’s no\nhistory—at least not on your machine.\nAs much as you may feel invincible using a private window on Firefox\nor the incognito mode on Chrome, your request for private website access,\nlike your e-mails, still has to travel through your ISP—your Internet\nservice provider, the company you pay for Internet or cellular service—\nand your provider can intercept any information that’s sent without being\nencrypted. If you access a website that uses encryption, then the ISP can\nobtain the metadata—that you visited such and such site at such and such\ndate and time.\nWhen an Internet browser—either on a traditional PC or a mobile\ndevice—connects to a website, it first determines whether there’s\nencryption, and if there is, what kind. The protocol for Web\ncommunications is known as http. The protocol is specified before the\naddress, which means that a typical URL might look like this:\nhttp://www.mitnicksecurity.com. Even the “www” is superfluous in some\ncases.\nWhen you connect to a site using encryption, the protocol changes\nslightly. Instead of “http,” you see “https.” So now it’s\nhttps://www.mitnicksecurity.com. This https connection is more secure.\nFor one thing, it’s point-to-point, though only if you’re connecting directly\nto the site itself. There are also a lot of Content Delivery Networks\n(CDNs) that cache pages for their clients to deliver them faster, no matter\nwhere you are in the world, and therefore come between you and the\ndesired website.\nKeep in mind, too, that if you are logged in to your Google, Yahoo, or\nMicrosoft accounts, these accounts may record the Web traffic on your PC\nor mobile device—perhaps building your online behavioral profile so the\ncompanies can better target the ads you see. One way to avoid this is to\nalways log out of Google, Yahoo, and Microsoft accounts when you are\nfinished using them. You can log back in to them the next time you need\nto.\nMoreover, there are default browsers built in to your mobile devices.\nThese are not good browsers. They’re crap, because they’re mini versions\nof the desktop and laptop browsers and lack some of the security and\nprivacy protections the more robust versions have. For example, iPhones\nship with Safari, but you might also want to consider going to the online\nApple store and downloading the mobile version of Chrome or Firefox,\nbrowsers that were designed for the mobile environment. Newer versions\nof Android do ship with Chrome as the default. All mobile browsers at\nleast support private browsing.\nAnd if you use a Kindle Fire, neither Firefox nor Chrome are download\noptions through Amazon. Instead you have to use a few manual tricks to\ninstall Mozilla’s Firefox or Chrome through Amazon’s Silk browser. To\ninstall Firefox on the Kindle Fire, open the Silk browser and go to the\nMozilla FTP site. Select “Go,” then select the file that ends with the\nextension .apk.\nPrivate browsing doesn’t create temporary files, and therefore it keeps\nyour browsing history off your laptop or mobile device. Could a third\nparty still see your interaction with a given website? Yes, unless that\ninteraction is first encrypted. To accomplish this, the Electronic Frontier\nFoundation has created a browser plug-in called HTTPS Everywhere.4\nThis is a plug-in for the Firefox and Chrome browsers on your traditional\nPC and for the Firefox browser on your Android device. There’s no iOS\nversion at the time of this writing. But HTTPS Everywhere can confer a\ndistinct advantage: consider that in the first few seconds of connection, the\nbrowser and the site negotiate what kind of security to use. You want\nperfect forward secrecy, which I talked about in the previous chapter. Not\nall sites use PFS. And not all negotiations end with PFS—even if it is\noffered. HTTPS Everywhere can force https usage whenever possible, even\nif PFS is not in use.\nHere’s one more criterion for a safe connection: every website should\nhave a certificate, a third-party guarantee that when you connect, say, to\nthe Bank of America website it truly is the Bank of America site and not\nsomething fraudulent. Modern browsers work with these third parties,\nknown as certificate authorities, to keep updated lists. Whenever you\nconnect to a site that is not properly credentialed, your browser should\nissue a warning asking if you trust the site enough to continue. It’s up to\nyou to make an exception. In general, unless you know the site, don’t\nmake exceptions.\nAdditionally, there isn’t just one type of certificate on the Internet;\nthere are levels of certificates. The most common certificate, one you see\nall the time, identifies only that the domain name belongs to someone who\nrequested the certificate, using e-mail verification. It could be anyone, but\nthat doesn’t matter—the site has a certificate that is recognized by your\nbrowser. The same is true of the second kind of certificate, an\norganizational certificate. This means that the site shares its certificate\nwith other sites related to the same domain—in other words, all the\nsubdomains on mitnicksecurity.com would share the same certificate.\nThe most stringent level of certificate verification, however, is what’s\ncalled an extended verification certificate. On all browsers, some part of\nthe URL turns green (ordinarily it’s gray, like the rest of the URL) when an\nextended verification certificate has been issued. Clicking over the address\n—https://www.mitnicksecurity.com—should reveal additional details\nabout the certificate and its owner, usually the city and state of the server\nproviding the website. This physical-world confirmation indicates that the\ncompany holding the URL is legitimate and has been confirmed by a\ntrusted third-party certificate authority.\nYou might expect the browser on your mobile device to track your\nlocation, but you might be surprised that the browser on your traditional\nPC does the same thing. It does. How?\nRemember when I explained that e-mail metadata contains the IP\naddress of all the servers that handle the e-mails on their way to you?\nWell, once again, the IP address coming from your browser can identify\nwhich ISP you are using and narrow down the possible geographical areas\nwhere you might be located.\nThe very first time you access a site that specifically requests your\nlocation data (such as a weather site), your browser should ask whether\nyou want to share your location with the site. The advantage of sharing is\nthat the site can customize its listing for you. For example, you might see\nads on washingtonpost.com for businesses in the town where you live\nrather than in the DC area.\nUnsure whether you answered that browser question in the past? Then\ntry the test page at http://benwerd.com/lab/geo.php. This is one of many\ntest sites that will tell you whether your browser is reporting your location.\nIf it is and you want to be invisible, then disable the feature. Fortunately,\nyou can turn off browser location tracking. In Firefox, type “about:\nconfig” in the URL address bar. Scroll down to “geo” and change the\nsetting to “disable.” Save your changes. In Chrome, go to Options>Under\nthe Hood>Content Settings>Location. There’s a “Do not allow any site to\ntrack my physical location” option that will disable geolocation in\nChrome. Other browsers have similar configuration options.\nYou might also want to fake your location—if only just for fun. If you\nwant to send out false coordinates—say, the White House—in Firefox, you\ncan install a browser plug-in called Geolocator. In Google Chrome, check\nthe plug-in’s built-in setting called “emulate geolocation coordinates.”\nWhile in Chrome, press Ctrl+Shift+I on Windows or Cmd+Option+I on\nMac to open the Chrome Developer Tools. The Console window will open,\nand you can click the three vertical dots at the top right of the Console,\nthen select more tools>sensors. A sensor tab will open. This allows you to\ndefine the exact latitude and longitude you want to share. You can use the\nlocation of a famous landmark or you can choose a site in the middle of\none of the oceans. Either way, the website won’t know where you really\nare.\nYou can obscure not only your physical location but also your IP\naddress while online. Earlier I mentioned Tor, which randomizes the IP\naddress seen by the website you are visiting. But not all sites accept Tor\ntraffic. Until recently, Facebook did not. For those sites that don’t accept\nTor connections, you can use a proxy.\nAn open proxy is a server that sits between you and the Internet. In\nchapter 2 I explained that a proxy is like a foreign-language translator—\nyou speak to the translator, and the translator speaks to the foreign-\nlanguage speaker, but the message remains exactly the same. I used the\nterm to describe the way someone in a hostile country might try to send\nyou an e-mail pretending to be from a friendly company.\nYou can also use a proxy to allow you to access georestricted websites\n—for example, if you live in a country that limits Google search access.\nOr perhaps you need to hide your identity for downloading illegal or\ncopyrighted content through BitTorrent.\nProxies are not bulletproof, however. When you use a proxy, remember\nthat each browser must be manually configured to point to the proxy\nservice. And even the best proxy sites admit that clever Flash or\nJavaScript tricks can still detect your underlying IP address—the IP\naddress you use to connect to the proxy in the first place. You can limit the\neffectiveness of these tricks by blocking or restricting the use of Flash and\nJavaScript in your browser. But the best way to prevent JavaScript\ninjection from monitoring you via your browser is to use the HTTPS\nEverywhere plug-in (see here).\nThere are many commercial proxy services. But be sure to read the\nprivacy policy of any service you sign up for. Pay attention to the way it\nhandles encryption of data in motion and whether it complies with law\nenforcement and government requests for information.\nThere are also some free proxies, but you must contend with a stream\nof useless advertising in exchange for the use of the service. My advice is\nto beware of free proxies. In his presentation at DEF CON 20, my friend\nand security expert Chema Alonso set up a proxy as an experiment: he\nwanted to attract bad guys to the proxy, so he advertised the IP address on\nxroxy.com. After a few days more than five thousand people were using\nhis free “anonymous” proxy. Unfortunately most of them were using it to\nconduct scams.\nThe flip side, though, is that Alonso could easily use the free proxy to\npush malware into the bad guy’s browser and monitor his or her activities.\nHe did so using what’s called a BeEF hook, a browser exploitation\nframework. He also used an end user license agreement (EULA) that\npeople had to accept to allow him to do it. That’s how he was able to read\nthe e-mails being sent through the proxy and determine that it was\nhandling traffic related to criminal activity. The moral here is that when\nsomething’s free, you get what you pay for.\nIf you use a proxy with https protocol, a law enforcement or\ngovernment agency would only see the proxy’s IP address, not the\nactivities on the websites you visit—that information would be encrypted.\nAs I mentioned, normal http Internet traffic is not encrypted; therefore you\nmust also use HTTPS Everywhere (yes, this is my answer to most browser\ninvisibility woes).\nFor the sake of convenience, people often synchronize their browser\nsettings among different devices. For example, when you sign in to the\nChrome browser or a Chromebook, your bookmarks, tabs, history, and\nother browser preferences are all synced via your Google account. These\nsettings load automatically every time you use Chrome, whether on\ntraditional PCs or mobile devices. To choose what information should be\nsynced to your account, go to the settings page on your Chrome browser.\nThe Google Dashboard gives you full control should you ever want to\nremove synced information from your account. Ensure that sensitive\ninformation is not auto-synced. Mozilla’s Firefox also has a sync option.\nThe downside is that all an attacker needs to do is lure you into signing\nin to your Google account on a Chrome or Firefox browser, then all your\nsearch history will load on their device. Imagine your friend using your\ncomputer and choosing to log in to the browser. Your friend’s history,\nbookmarks, etc., will now be synced. That means that your friend’s surfing\nhistory, among other information, is now viewable on your computer. Plus,\nif you sign in to a synchronized browser account using a public terminal\nand forget to sign out, all your browser’s bookmarks and history will be\navailable to the next user. If you’re signed in to Google Chrome, then even\nyour Google calendar, YouTube, and other aspects of your Google account\nbecome exposed. If you must use a public terminal, be vigilant about\nsigning out before you leave.\nAnother downside of syncing is that all interconnected devices will\nshow the same content. If you live alone, that may be fine. But if you share\nan iCloud account, bad things can happen. Parents who allow their\nchildren to use the family iPad, for example, might unintentionally expose\nthem to adult content.5\nIn an Apple store in Denver, Colorado, Elliot Rodriguez, a local\naccount executive, registered his new tablet with his existing iCloud\naccount. Instantly all his photos, texts, and music and video downloads\nwere available to him on the new tablet. This convenience saved him time;\nhe didn’t have to manually copy and save all that material to multiple\ndevices. And it allowed him access to the items no matter what device he\nchose to use.\nAt some point later on Elliot thought it was a good idea to give his\nolder-technology tablet to his eight-year-old daughter. The fact that she\nwas connected to his devices was a short-term plus. Occasionally on his\ntablet Elliot would notice a new app his daughter had downloaded to her\ntablet. Sometimes they would even share family photos. Then Elliot took a\ntrip to New York City, where he traveled often for business.\nWithout thinking, Elliot took out his iPhone and captured several\nmoments with his New York–based mistress, some of them quite…\nintimate. The images from his iPhone synced automatically to his\ndaughter’s iPad back in Colorado. And of course his daughter asked her\nmother about the woman who was with Daddy. Needless to say, Elliot had\nsome serious explaining to do when he got home.\nAnd then there’s the birthday-present problem. If you share devices or\nsynced accounts, your visits to sites might tip gift recipients off to what\nthey’ll be getting for their birthdays. Or, worse, what they might have\ngotten. Yet another reason why sharing a family PC or tablet can present a\nprivacy problem.\nOne way to avoid this is to set up different users, a relatively easy step\nin Windows. Keep the administrator privileges for yourself so that you can\nadd software to the system and set up additional family or household\nmembers with their own accounts. All users will log in with their own\npasswords and have access to only their own content and their own\nbrowser bookmarks and histories.\nApple allows for similar divisions within its OSX operating systems.\nHowever, not many people remember to segment their iCloud space. And\nsometimes, seemingly through no fault of our own, technology simply\nbetrays us.\nAfter years of dating several women, Dylan Monroe, an LA-based TV\nproducer, finally found “the one” and decided to settle down. His fiancée\nmoved in, and, as part of their new life together, he innocently connected\nhis future wife to his iCloud account.\nWhen you want to start a family, it makes sense to connect everyone to\none account. Doing so allows you to share all your videos, texts, and music\nwith the ones you love. Except that’s in the present tense. What about your\ndigitally stored past?\nSometimes having an automatic cloud backup service like iCloud\nmeans that we accumulate many years’ worth of photos, texts, and music,\nsome of which we tend to forget, just as we forget the contents of old\nboxes in the attic.\nPhotos are the closest thing we have to memories. And yes, spouses\nhave been coming across shoe boxes of old letters and photographs for\ngenerations now. But a digital medium that allows you to take literally\nthousands of high-definition photos without too much effort creates new\nproblems. Suddenly Dylan’s old memories—some of them very private\nindeed—came back to haunt him in the form of photos that were now on\nhis fiancée’s iPhone and iPad.\nThere were items of furniture that had to be removed from the house\nbecause other women had performed intimate acts on that sofa, table, or\nbed. There were restaurants where his fiancée refused to go to because she\nhad seen photos of other women there with him, at that table by the\nwindow or in that corner booth.\nDylan obliged his fiancée lovingly, even when she asked him to make\nthe ultimate sacrifice—selling his house once the two of them were\nmarried. All because he’d connected his iPhone to hers.\nThe cloud creates another interesting problem. Even if you delete your\nbrowser history on your desktop, laptop, or mobile device, a copy of your\nsearch history remains in the cloud. Stored on the search engine\ncompany’s servers, your history is a bit harder to delete and harder to not\nhave stored in the first place. This is just one example of how surreptitious\ndata collection without the proper context can be easily misinterpreted at a\nlater date and time. It’s easy to see how an innocent set of searches can go\nawry.\nOne morning in the late summer of 2013, just weeks after the Boston\nMarathon bombing, Michele Catalano’s husband saw two black SUVs pull\nup in front of their house on Long Island. When he went outside to greet\nthe officers, they asked him to confirm his identity and requested his\npermission to search the house. Having nothing to hide, although uncertain\nwhy they were there, he allowed them to enter. After a cursory check of the\nrooms, the federal agents got down to business.\n“Has anyone in this household searched for information on pressure\ncookers?”\n“Has anyone in this household searched for information on\nbackpacks?”\nApparently the family’s online searches through Google had triggered a\npreemptive investigation by the Department of Homeland Security.\nWithout knowing the exact nature of the Catalano family investigation,\none might imagine that in the weeks following the Boston Marathon\nbombing certain online searches, when combined, suggested the potential\nfor terrorism and so were flagged. Within two hours the Catalano\nhousehold was cleared of any potential wrongdoing. Michele later wrote\nabout the experience for Medium—if only as a warning that what you\nsearch for today might come back to haunt you tomorrow.6\nIn her article, Catalano pointed out that the investigators must have\ndiscounted her searches for “What the hell do I do with quinoa?” and “Is\nA-Rod suspended yet?” She said her pressure-cooker query was about\nnothing more than making quinoa. And the backpack query? Her husband\nwanted a backpack.\nAt least one search engine company, Google, has created several\nprivacy tools that allow you to specify what information you feel\ncomfortable keeping.7 For example, you can turn off personalized ad\ntracking so that if you look up Patagonia (the region in South America)\nyou don’t start seeing ads for South American travel. You can also turn off\nyour search history altogether. Or you could not log in to Gmail, YouTube,\nor any of your Google accounts while you search online.\nEven if you are not logged in to your Microsoft, Yahoo, or Google\naccounts, your IP address is still tied to each search engine request. One\nway to avoid this one-to-one match is to use the Google-proxy\nstartpage.com or the search engine DuckDuckGo instead.\nDuckDuckGo is already a default option within Firefox and Safari.\nUnlike Google, Yahoo, and Microsoft, DuckDuckGo has no provision for\nuser accounts, and the company says your IP address is not logged by\ndefault. The company also maintains its own Tor exit relay, meaning that\nyou can search DuckDuckGo while using Tor without much of a\nperformance lag.8\nBecause DuckDuckGo doesn’t track your use, your search results won’t\nbe filtered by your past searches. Most people don’t realize it, but the\nresults you see within Google, Yahoo, and Bing are filtered by everything\nyou searched for on those sites in the past. For example, if the search\nengine sees that you’re searching for sites related to health issues, it will\nstart to filter the search results and push the results related to health issues\nto the very top. Why? Because very few of us bother to advance to the\nsecond page of a search result. There’s an Internet joke that says that if\nyou want to know the best place to bury a dead body, try here of the search\nresults.\nSome people might like the convenience of not having to scroll through\nseemingly unrelated results, but at the same time it is patronizing for a\nsearch engine to decide what you may or may not be interested in. By most\nmeasures, that is censorship. DuckDuckGo does return relevant search\nresults, but filtered by topic, not by your past history.\nIn the next chapter I’ll talk about specific ways websites make it hard\nfor you to be invisible to them and what you can do to surf the Web\nanonymously."
  },
  {
    "input": "How can users protect their online privacy by managing browser settings, using privacy tools, and being mindful of their digital footprint?",
    "summary": "Many websites track your online activity, including health-related searches, through URLs, third-party requests, and cookies. Even with privacy tools like HTTPS and NoScript, your browsing habits can still be monitored by advertisers, social media platforms, and other entities. To enhance privacy, you can use tools like Ghostery, avoid linking accounts, and use anonymous email addresses and Bitcoin for transactions. Additionally, using Tor and managing cookies carefully can help reduce online tracking, though some persistent tracking methods, like canvas fingerprinting, can still identify you.",
    "output": "CHAPTER SIX\nEvery Mouse Click You Make, I’ll Be Watching You\nBe very careful what you\nsearch for on the Internet. It’s not just\nsearch engines that track your online habits; every website you visit does\nas well. And you’d think that some of them would know better than to\nexpose private matters to others. For example, a 2015 report found that\n“70 percent of health sites’ URLs contain information exposing specific\nconditions, treatments, and diseases.”1\nIn other words, if I’m on WebMD and searching for “athlete’s foot,” the\nunencrypted words athlete’s foot will appear within the URL visible in my\nbrowser’s address bar. This means that anyone—my browser, my ISP, my\ncellular carrier—can see that I am looking for information about athlete’s\nfoot. Having HTTPS Everywhere enabled on your browser would encrypt\nthe contents of the site you are visiting, assuming the site supports https,\nbut it doesn’t encrypt the URL. As even the Electronic Frontier Foundation\nnotes, https was never designed to conceal the identity of the sites you\nvisit.\nAdditionally, the study found that 91 percent of health-related sites\nmake requests to third parties. These calls are embedded in the pages\nthemselves, and they make requests for tiny images (which may or may\nnot be visible on the browser page), which informs these other third-party\nsites that you are visiting a particular page. Do a search for “athlete’s\nfoot,” and as many as twenty different entities—ranging from\npharmaceuticals companies to Facebook, Pinterest, Twitter, and Google—\nare contacted as soon as the search results load in your browser. Now all\nthose parties know you have been searching for information about athlete’s\nfoot.2\nThese third parties use this information to target you with online\nadvertising. Also, if you logged in to the health-care site, they might be\nable to obtain your e-mail address. Fortunately I can help you prevent\nthese entities from learning more about you.\nOn the health-care sites analyzed in the 2015 study, the top ten third\nparties were Google, comScore, Facebook, AppNexus, AddThis, Twitter,\nQuantcast, Amazon, Adobe, and Yahoo. Some—comScore, AppNexus, and\nQuantcast—measure Web traffic, as does Google. Of the third parties\nlisted above, Google, Facebook, Twitter, Amazon, Adobe, and Yahoo are\nspying on your activity for commercial reasons, so they can, for example,\nload ads for athlete’s foot remedies in future searches.\nAlso mentioned in the study were the third parties Experian and\nAxiom, which are simply data warehouses—they collect as much data\nabout a person as they possibly can. And then they sell it. Remember the\nsecurity questions and the creative answers I suggested that you use?\nOften companies like Experian and Axiom collect, provide, and use those\nsecurity questions to build online profiles. These profiles are valuable to\nmarketers that want to target their products to certain demographics.\nHow does that work?\nWhether you type the URL in manually or use a search engine, every\nsite on the Internet has both a hostname and a numerical IP address (some\nsites exist only as numerical addresses). But you almost never see the\nnumerical address. Your browser hides it and uses a domain name service\n(DNS) to translate a site’s hostname name—say, Google—in to a specific\naddress, in Google’s case https://74.125.224.72/.\nDNS is like a global phone book, cross-referencing the hostname with\nthe numerical address of the server of the site you just requested. Type\n“Google.com” into your browser, and the DNS contacts their server at\nhttps://74.125.224.72. Then you see the familiar white screen with the\nday’s Google Doodle above a blank search field. That, in theory, is how all\nWeb browsers work. In practice there is more to it.\nAfter the site has been identified through its numerical address, it will\nsend information back to your Web browser so that it can start “building”\nthe Web page you see. When the page is returned to your browser, you see\nthe elements you would expect—the information you want retrieved, any\nrelated images, and ways to navigate to other parts of the site. But often\nthere are elements that are returned to your browser that call out to other\nwebsites for additional images or scripts. Some, if not all, of these scripts\nare for tracking purposes, and in most cases you simply do not need them.\nAlmost every digital technology produces metadata, and, as you’ve no\ndoubt already guessed, browsers are no different. Your browser can reveal\ninformation about your computer’s configuration if queried by the site you\nare visiting. For example, what version of what browser and operating\nsystem you’re using, what add-ons you have for that browser, and what\nother programs you’re running on your computer (such as Adobe products)\nwhile you search. It can even reveal details of your computer’s hardware,\nsuch as the resolution of the screen and the capacity of the onboard\nmemory.\nYou might think after reading this far that you have taken great strides\nin becoming invisible online. And you have. But there’s more work to be\ndone.\nTake a moment and surf over to Panopticlick.com. This is a site built\nby the Electronic Frontier Foundation that will determine just how\ncommon or unique your browser configuration is compared to others,\nbased on what’s running on your PC or mobile device’s operating system\nand the plug-ins you may have installed. In other words, do you have any\nplug-ins that can be used to limit or otherwise protect the information that\nPanopticlick can glean from your browser alone?\nIf the numbers on the left-hand side, the results from Panopticlick, are\nhigh—say, a six-digit number—then you are somewhat unique, because\nyour browser settings are found in fewer than one in one hundred thousand\ncomputers. Congratulations. However, if your numbers are low—say, less\nthan three digits—then your browser settings are fairly common. You’re\njust one in a few hundred. And that means if I’m going to target you—with\nads or malware—I don’t have to work very hard, because you have a\ncommon browser configuration.3\nYou might think that having a common configuration can help you\nbecome invisible—you’re part of the crowd; you blend in. But from a\ntechnical perspective, this opens you up to malicious activities. A criminal\nhacker doesn’t want to expend a lot of effort. If a house has a door open\nand the house next to it has a door closed, which do you think a thief\nwould rob? If a criminal hacker knows that you have common settings,\nthen perhaps you also lack certain protections that could enhance your\nsecurity.\nI understand I just jumped from discussing marketers trying to track\nwhat you view online to criminal hackers who may or may not use your\npersonal information to steal your identity. These are very different.\nMarketers collect information in order to create ads that keep websites\nprofitable. Without advertising, some sites simply could not continue.\nHowever, marketers, criminal hackers, and, for that matter, governments\nare all trying to get information that you may not want to give, and so, for\nthe sake of argument, they are often lumped together in discussions about\nthe invasion of privacy.\nOne way to be common yet also safe from online eavesdropping is to\nuse a virtual machine (VM; see here), an operating system like Mac OSX\nrunning as a guest on top of your Windows operating system. You can\ninstall VMware on your desktop and use it to run another operating\nsystem. When you’re done, you simply shut it down. The operating system\nand everything you did within it will disappear. The files you save,\nhowever, will remain wherever you saved them.\nSomething else to watch out for is that marketers and criminal hackers\nalike learn something about visitors to a website through what’s known as\na one-pixel image file or web bug. Like a blank browser pop-up window,\nthis is a 1×1-pixel image placed somewhere on a Web page that, although\ninvisible, nonetheless calls back to the third-party site that placed it there.\nThe backend server records the IP address that tried to render that image.\nA one-pixel image placed on a health-care site could tell a\npharmaceuticals company that I was interested in athlete’s foot remedies.\nThe 2015 study I mentioned at the beginning of this chapter found that\nalmost half of third-party requests simply open pop-up windows\ncontaining no content whatsoever. These “blank” windows generate silent\nhttp requests to third-party hosts that are used only for tracking purposes.\nYou can avoid these by instructing your browser not to allow pop-up\nwindows (and this will also eliminate those annoying ads as well).\nNearly a third of the remaining third-party requests, according to the\nstudy, consisted of small lines of code, JavaScript files, which usually just\nexecute animations on a Web page. A website can identify the computer\naccessing the site, mostly by reading the IP address that is requesting the\nJavaScript file.\nEven without a one-pixel image or a blank pop-up window, your Web\nsurfing can still be tracked by the sites you visit. For example, Amazon\nmight know that the last site you visited was a health-care site, so it will\nmake recommendations for health-care products for you on its own site.\nThe way Amazon might do this is to actually see the last site you visited in\nyour browser request.\nAmazon accomplishes this by using third-party referrers—text in the\nrequest for a Web page that tells the new page where the request\noriginated. For example, if I’m reading an article on Wired and it contains\na link, when I click that link the new site will know that I was previously\non a page within Wired.com. You can see how this third-party tracking can\naffect your privacy.\nTo avoid this, you can always go to Google.com first, so the site you\nwant to visit doesn’t know where you were previously. I don’t believe\nthird-party referrers are such a big deal, except when you’re trying to\nmask your identity. This is one more example of a trade-off between\nconvenience (simply going to the next website) and invisibility (always\nstarting from Google.com).\nMozilla’s Firefox offers one of the best defenses against third-party\ntracking through a plug-in called NoScript.4 This add-on effectively\nblocks just about everything considered harmful to your computer and\nbrowser, namely, Flash and JavaScript. Adding security plug-ins will\nchange the look and feel of your browsing session, although you can\ncherry-pick and enable specific features or permanently trust some sites.\nOne result of enabling NoScript is that the page you visit will have no\nads and certainly no third-party referrers. As a result of the blocking, the\nWeb page looks slightly duller than the version without NoScript enabled.\nHowever, should you want to see that Flash-encoded video in the upper\nleft-hand corner of the page, you can specifically allow that one element to\nrender while continuing to block everything else. Or, if you feel you can\ntrust the site, you can temporarily or permanently allow all elements on\nthat page to load—something you might want to do on a banking site, for\nexample.\nFor its part, Chrome has ScriptBlock,5 which allows you to defensively\nblock the use of scripts on a Web page. This is useful for kids who may\nsurf to a site that allows pop-up adult entertainment ads.\nBlocking potentially harmful (and certainly privacy-compromising)\nelements on these pages will keep your computer from being overrun with\nad-generating malware. For example, you may have noticed that ads\nappear on your Google home page. In fact, you should have no flashing\nads on your Google home page. If you see them, your computer and\nbrowser may have been compromised (perhaps some time ago), and as a\nresult you’re seeing third-party ads that may contain Trojan horses—\nkeyloggers, which record every keystroke you make, and other malware—\nif you click on them. Even if the ads don’t contain malware, the\nadvertisers’ revenue comes from the number of clicks they receive. The\nmore people they dupe into clicking, the more money they make.\nAs good as they are, NoScript and ScriptBlock don’t block everything.\nFor complete protection against browser threats, you might want to install\nAdblock Plus. The only problem is that Adblock records everything: this is\nanother company that tracks your surfing history, despite your use of\nprivate browsing. However, in this case the good—blocking potentially\ndangerous ads—outweighs the bad: they know where you’ve been online.\nAnother useful plug-in is Ghostery, available for both Chrome and\nFirefox. Ghostery identifies all the Web traffic trackers (such as\nDoubleClick and Google AdSense) that sites use to follow your activity.\nLike NoScript, Ghostery gives you granular control over which trackers\nyou want to allow on each page. The site says, “Blocking trackers will\nprevent them from running in your browser, which can help control how\nyour behavioral data is tracked. Keep in mind that some trackers are\npotentially useful, such as social network feed widgets or browser-based\ngames. Blocking may have an unintended effect on the sites you visit.”\nMeaning that some sites will no longer work with Ghostery installed.\nFortunately, you can disable it on a site-by-site basis.6\nIn addition to using plug-ins to block sites from identifying you, you\nmight want to confuse potential hackers further by using a variety of e-\nmail addresses tailored for individual purposes. For example, in chapter 2\nI discussed ways of creating anonymous e-mail accounts in order to\ncommunicate without detection. Similarly, for simple day-to-day\nbrowsing, it’s also a good idea to create multiple e-mail accounts—not to\nhide but to make yourself less interesting to third parties on the Internet.\nHaving multiple online personality profiles dilutes the privacy impact of\nhaving only one identifiable address. It makes it harder for anyone to build\nan online profile of you.\nLet’s say you want to purchase something online. You might want to\ncreate an e-mail address that you use exclusively for shopping. You might\nalso want to have anything you purchase with this e-mail address sent to\nyour mail drop instead of your home address.7 In addition, you might want\nto use a gift card for your purchase, perhaps one you reload from time to\ntime.\nThis way the company selling you products will only have your\nnonprimary e-mail address, your nonprimary real-world address, and your\nmore-or-less throwaway gift card. If there’s ever a data breach at that\ncompany, at least the attackers won’t have your real e-mail address, real-\nworld address, or credit card number. This kind of disconnection from an\nonline purchasing event is good privacy practice.\nYou might also want to create another nonprimary e-mail address for\nsocial networks. This address might become your “public” e-mail address,\nwhich strangers and mere acquaintances can use to get in touch with you.\nThe advantage to this is that, once again, people won’t learn much about\nyou. At least not directly. You can further protect yourself by giving each\nnonprimary address a unique name, either a variation on your real name or\nanother name entirely.\nBe careful if you go with the former option. You might not want to list\na middle name—or, if you always go by your middle name, you might not\nwant to list your first name. Even something innocent like\nJohnQDoe@xyz.com just tipped us off that you have a middle name and\nthat it begins with Q. This is an example of giving out personal\ninformation when it isn’t necessary. Remember that you are trying to\nblend into the background, not call attention to yourself.\nIf you use a word or phrase unrelated to your name, make it as\nunrevealing as possible. If your e-mail address is snowboarder@xyz.com,\nwe may not know your name, but we do know one of your hobbies. Better\nto choose something generic, like silverfox@xyz.com.\nYou’ll of course also want to have a personal e-mail address. You\nshould only share this one with close friends and family. And the safest\npractices often come with nice bonuses: you’ll find that not using your\npersonal e-mail address for online purchasing will prevent you from\nreceiving a ton of spam.\nCell phones are not immune from corporate tracking. In the summer of\n2015, an eagle-eyed researcher caught AT&T and Verizon appending\nadditional code to every Web page request made through a mobile browser.\nThis is not the IMSI—international mobile subscriber identity—I talked\nabout in chapter 3 (see here); rather, it’s a unique identification code sent\nwith each Web page request. The code, known as a unique identifier\nheader, or UIDH, is a temporary serial number that advertisers can use to\nidentify you on the Web. The researcher discovered what was going on\nbecause he configured his mobile phone to log all web traffic (which not\nmany people do). Then he noticed the additional data tacked on to Verizon\ncustomers and, later, AT&T customers.8\nThe problem with this additional code is that customers were not told\nabout it. For instance, those who had downloaded the Firefox mobile app\nand used plug-ins to increase their privacy were, if they used AT&T or\nVerizon, nonetheless being tracked by the UIDH codes.\nThanks to these UIDH codes, Verizon and AT&T could take the traffic\nassociated with your Web requests and either use it to build a profile of\nyour mobile online presence for future advertising or simply sell the raw\ndata to others.\nAT&T has suspended the operation—for now.9 Verizon has made it yet\nanother option for the end user to configure.10 Note: by not opting out, you\ngive Verizon permission to continue.\nEven if you turn off JavaScript, a website may still pass a text file with\ndata called an http cookie back to your browser. This cookie could be\nstored for a long time. The term cookie is short for magic cookie, a piece\nof text that is sent from a website and stored in the user’s browser to keep\ntrack of things, such as items in a shopping cart, or even to authenticate a\nuser. Cookies were first used on the Web by Netscape and were originally\nintended to help with creating virtual shopping carts and e-commerce\nfunctions. Cookies are typically stored in the browser on a traditional PC\nand have expiration dates, although these dates could be decades in the\nfuture.\nAre cookies dangerous? No—at least not by themselves. However,\ncookies would provide third parties with information about your account\nand your specific preferences, such as your favorite cities on a weather site\nor your airline preferences on a travel site. The next time your browser\nconnects to that site, if a cookie already exists, the site will remember you\nand perhaps say “Hello, Friend.” And if it is an e-commerce site, it may\nalso remember your last few purchases.\nCookies do not actually store this information on your traditional PC or\nmobile device. Like cell phones that use IMSIs as proxies, the cookie\ncontains a proxy for the data that lives on the back end at the site. When\nyour browser loads a Web page with a cookie attached, additional data is\npulled from the site that is specific to you.\nNot only do cookies store your personal site preferences, they also\nprovide valuable tracking data for the site they came from. For example, if\nyou are a prospective customer of a company and you have previously\nentered your e-mail address or other information to access a white paper,\nchances are there is a cookie in your browser for that company’s site that\nmatches, on the back end, information about you in a customer record\nmanagement (CRM) system—say, Salesforce or HubSpot. Now every time\nyou access that company’s site, you will be identified through the cookie\nin your browser, and that visit will be recorded within the CRM.\nCookies are segmented, meaning that website A can’t necessarily see\nthe contents of a cookie for website B. There have been exceptions, but\ngenerally the information is separate and reasonably secure. From a\nprivacy perspective, however, cookies do not make you very invisible.\nYou can only access cookies in the same domain, a set of resources\nassigned to a specific group of people. Ad agencies get around this by\nloading a cookie that can track your activity on several sites that are part\nof their larger networks. In general, though, cookies cannot access another\nsite’s cookies. Modern browsers provide a way for the user to control\ncookies. For example, if you surf the Web using incognito or private\nbrowsing features, you will not retain a historical record within the\nbrowser of your visit to a given site, nor will you acquire a new cookie for\nthat session. If you had a cookie from an earlier visit, however, it will still\napply in private mode. If you are using the normal browsing feature, on\nthe other hand, you may from time to time want to manually remove some\nor all of the cookies you acquired over the years.\nI should note that removing all cookies may not be advisable.\nSelectively removing the cookies that are associated with one-off visits to\nsites you don’t care about will help remove traces of you from the\nInternet. Sites you revisit won’t be able to see you, for example. But for\nsome sites, such as a weather site, it might be tedious to keep typing in\nyour zip code every time you visit when a simple cookie might suffice.\nRemoving cookies can be accomplished by using an add-on or by going\ninto the settings or preferences section of your browser, where there is\nusually an option to delete one or more (even all) of the cookies. You may\nwant to determine the fate of your cookies on a case-by-case basis.\nSome advertisers use cookies to track how long you spend on the sites\nwhere they’ve placed their ads. Some even record your visits to previous\nsites, what’s known as the referrer site. You should delete these cookies\nimmediately. You will recognize some of them because their names won’t\ncontain the names of the sites you visited. For example, instead of “CNN,”\na referrer cookie will identify itself as “Ad321.” You may also want to\nconsider using a cookie cleaner software tool, such as the one at\npiriform.com/ccleaner, to help manage your cookies easily.\nThere are, however, some cookies that are impervious to whatever\ndecisions you make on the browser side. These are called super cookies\nbecause they exist on your computer, outside of your browser. Super\ncookies access a site’s preferences and tracking data no matter what\nbrowser you use (Chrome today, Firefox tomorrow). And you should\ndelete super cookies from your browser, otherwise your traditional PC will\nattempt to re-create http cookies from memory the next time your browser\naccesses the site.\nThere are two specific super cookies that live outside your browser that\nyou can delete—Flash, from Adobe, and Silverlight, from Microsoft.\nNeither of these super cookies expires. And it is generally safe to delete\nthem.11\nThen there’s the toughest cookie of them all. Samy Kamkar, once\nfamous for creating the rapidly spreading Myspace worm called Samy, has\ncreated something he calls Evercookie, which is simply a very, very\npersistent cookie.12 Kamkar achieved this persistence by storing the\ncookie data in as many browser storage systems as possible throughout the\nWindows operating system. As long as one of the storage sites remains\nintact, Evercookie will attempt to restore the cookie everywhere else.13\nThus simply deleting an Evercookie from the browser’s cookie storage\ncache is not enough. Like the kids’ game whack-a-mole, Evercookies will\nkeep popping up. You will need to delete them completely from your\nmachine in order to win.\nIf you consider how many cookies you might already have on your\nbrowser, and if you multiply that by the number of potential storage areas\non your machine, you can see that you’ll be in for a long afternoon and\nevening.\nIt’s not just websites and mobile carriers that want to track your activities\nonline. Facebook has become ubiquitous—a platform beyond just social\nmedia. You can sign in to Facebook and then use that same Facebook log-\nin to sign in to various other apps.\nHow popular is this practice? At least one marketing report finds that\n88 percent of US consumers have logged in to a website or mobile\napplication using an existing digital identity from a social network such as\nFacebook, Twitter, and Google Plus.14\nThere are pros and cons to this convenience—known as OAuth, an\nauthentication protocol that allows a site to trust you even if you don’t\nenter a password. On the one hand, it’s a shortcut: you can quickly access\nnew sites using your existing social media password. On the other hand,\nthis allows the social media site to glean information about you for its\nmarketing profiles. Instead of just knowing about your visit to a single\nsite, it knows about all the sites, all the brands you use its log-in\ninformation for. When we use OAuth, we’re giving up a lot of privacy for\nthe sake of convenience.\nFacebook is perhaps the most “sticky” of all social media platforms.\nLogging out of Facebook may deauthorize your browser from accessing\nFacebook and its Web applications. Furthermore, Facebook adds trackers\nfor monitoring user activity that function even after you’re logged out,\nrequesting information such as your geographic location, which sites you\nvisit, what you click on within individual sites, and your Facebook\nusername. Privacy groups have expressed concern about Facebook’s intent\nto start tracking information from some of the websites and apps its users\nare visiting in order to display more personalized ads.\nThe point is that Facebook, like Google, wants data about you. It may\nnot come right out and ask, but it will find ways to get it. If you link your\nFacebook account to other services, the platform will have information\nabout you and that other service or app. Maybe you use Facebook to\naccess your bank account—if you do, it knows what financial institution\nyou use. Using just one authentication means that if someone gets into\nyour Facebook account, that person will have access to every other website\nlinked to that account—even your bank account. In the security business,\nhaving what we call a single point of failure is never a good idea.\nAlthough it takes a few seconds more, it’s worth signing in to Facebook\nonly when you need to and signing in to each app you use separately.\nIn addition, Facebook has deliberately chosen not to honor the “do not\ntrack” signal sent by Internet Explorer on the grounds that there’s “no\nindustry consensus” behind it.15 The Facebook trackers come in the classic\nforms: cookies, JavaScript, one-pixel images, and iframes. This allows\ntargeted advertisers to scan and access specific browser cookies and\ntrackers to deliver products, services, and ads, both on and off Facebook.\nFortunately there are browser extensions that block Facebook services\non third-party sites, e.g., Facebook Disconnect for Chrome16 and Facebook\nPrivacy List for Adblock Plus (which works with both Firefox and\nChrome).17 Ultimately the goal of all of these plug-in tools is to give you\ncontrol over what you share with Facebook and any other social networks\nas opposed to forcing you to take a backseat and allowing the service\nyou’re using to govern these things for you.\nGiven what Facebook knows about its 1.65 billion subscribers, the\ncompany has been fairly benevolent—so far.18 It has a ton of data, but it,\nlike Google, has chosen not to act on all of it. But that doesn’t mean it\nwon’t.\nMore overt than cookies—and equally parasitic—are toolbars. The\nadditional toolbar you see at the top of your traditional PC browser might\nbe labeled YAHOO or MCAFEE or ASK. Or it may carry the name of any\nnumber of other companies. Chances are you don’t remember how the\ntoolbar got there. Nor do you ever use it. Nor do you know how to remove\nit.\nToolbars like this draw your attention away from the toolbar that came\nwith your browser. The native toolbar allows you to choose which search\nengine to use as the default. The parasitic one will take you to its own\nsearch site, and the results may be filled with sponsored content. This\nhappened to Gary More, a West Hollywood resident, who found himself\nwith the Ask.com toolbar and no clear way to remove it. “It’s like a bad\nhouseguest,” said More. “It will not leave.”19\nIf you have a second or third toolbar, it may be because you’ve\ndownloaded new software or had to update existing software. For example,\nif you have Java installed on your computer, Oracle, the maker of Java,\nwill automatically include a toolbar unless you specifically tell it not to.\nWhen you were clicking through the download or update screens, you\nprobably didn’t notice the tiny check box that by default indicated your\nconsent to the installation of a toolbar. There’s nothing illegal about this;\nyou did give consent, even if it means that you didn’t opt out of having it\ninstall automatically. But that toolbar allows another company to track\nyour Web habits and perhaps change your default search engine to its own\nservice as well.\nThe best way to remove a toolbar is to uninstall it the way you would\nuninstall any program on your traditional PC. But some of the most\npersistent and parasitic toolbars may require you to download a removal\ntool, and often the process of uninstalling can leave behind enough\ninformation to allow advertising agents related to the toolbar to reinstall\nit.\nWhen installing new software or updating existing software, pay\nattention to all the check boxes. You can avoid a lot of hassle if you don’t\nagree to the installation of these toolbars in the first place.\nWhat if you do use private browsing, have NoScript, HTTPS Everywhere,\nand you periodically delete your browser’s cookies and extraneous\ntoolbars? You should be safe, right? Nope. You can still be tracked online.\nWebsites are coded using something called Hypertext Markup\nLanguage, or HTML. There are many new features available in the current\nversion, HTML5. Some of the features have hastened the demise of the\nsuper cookies Silverlight and Flash—which is a good thing. HTML5 has,\nhowever, enabled new tracking technologies, perhaps by accident.\nOne of these is canvas fingerprinting, an online tracking tool that is\ncool in a very creepy way. Canvas fingerprinting uses the HTML5 canvas\nelement to draw a simple image. That’s it. The drawing of the image takes\nplace within the browser and is not visible to you. It takes only a fraction\nof a second. But the result is visible to the requesting website.\nThe idea is that your hardware and software, when combined as\nresources for the browser, will render the image uniquely. The image—it\ncould be a series of variously colored shapes—is then converted into a\nunique number, roughly the way passwords are. This number is then\nmatched to previous instances of that number seen on other websites\naround the Internet. And from that—the number of places where that\nunique number is seen—a profile of websites you visit can be built up.\nThis number, or canvas fingerprint, can be used to identify your browser\nwhenever it returns to any particular website that requested it, even if you\nhave removed all cookies or blocked future cookies from installing,\nbecause it uses an element built into HTML5 itself.20\nCanvas fingerprinting is a drive-by process; it does not require you to\nclick or do anything but simply view a Web page. Fortunately there are\nplug-ins for your browser that can block it. For Firefox there’s\nCanvasBlocker.21 For Google Chrome there’s CanvasFingerprintBlock.22\nEven the Tor project has added its own anticanvas technology to its\nbrowser.23\nIf you use these plug-ins and follow all my other recommendations,\nyou might think that you’re finally free of online tracking. And you’d be\nwrong.\nFirms such as Drawbridge and Tapad, and Oracle’s Crosswise, take\nonline tracking a step further. They claim to have technologies that can\ntrack your interests across multiple devices, including sites you visit only\non your cell phones and tablets.\nSome of this tracking is the result of machine learning and fuzzy logic.\nFor example, if a mobile device and a traditional PC both contact a site\nusing the same IP address, it’s very possible that they are owned by a\nsingle person. For example, say you search for a particular item of\nclothing on your cell phone, then when you get home and are on your\ntraditional PC, you find that same item of clothing in the “recently\nviewed” section of the retailer’s website. Better yet, let’s say you buy the\nitem of clothing using your traditional PC. The more matches created\nbetween distinct devices, the more likely it is that a single individual is\nusing both of them. Drawbridge alone claims it linked 1.2 billion users\nacross 3.6 billion devices in 2015.24\nGoogle, of course, does the same thing, as do Apple and Microsoft.\nAndroid phones require the use of a Google account. Apple devices use an\nApple ID. Whether a user has a smartphone or a laptop, the Web traffic\ngenerated by each is associated with a specific user. And the latest\nMicrosoft operating systems require a Microsoft account in order to\ndownload apps or to store photos and documents using the company’s\ncloud service.\nThe big difference is that Google, Apple, and Microsoft allow you to\ndisable some or all of this data collection activity and retroactively delete\ncollected data. Drawbridge, Crosswise, and Tapad make the process of\ndisabling and deletion less clear. Or it may simply not be available.\nAlthough using a proxy service or Tor is a convenient way to obscure your\ntrue location when accessing the Internet, this masking can create\ninteresting problems or even backfire on you, because sometimes online\ntracking can be justified—especially when a credit card company is trying\nto fight fraud. For example, just days before Edward Snowden went public,\nhe wanted to create a website to support online rights. He had trouble,\nhowever, paying the host company for the registration with his credit card.\nAt the time, he was still using his real name, real e-mail address, and\npersonal credit cards—this was just before he became a whistle-blower. He\nwas also using Tor, which sometimes triggers fraud warnings from credit\ncard companies when they want to verify your identity and can’t reconcile\nsome of the information you provided with what they have on file. If, say,\nyour credit card account says you live in New York, why does your Tor\nexit node say you are in Germany? A geolocation discrepancy like this\noften flags an attempt to purchase as possible abuse and invites additional\nscrutiny.\nCredit card companies certainly track us online. They know all our\npurchases. They know where we have subscriptions. They know when we\nleave the country. And they know whenever we use a new machine to make\na purchase online.\nAccording to Micah Lee of the EFF, at one point Snowden was in his\nHong Kong hotel room discussing government secrets with Laura Poitras\nand Glenn Greenwald, a reporter from the Guardian, and at the same time\nhe was on hold with the customer support department at DreamHost, an\nInternet provider based in Los Angeles. Apparently Snowden explained to\nDreamHost that he was overseas and didn’t trust the local Internet service,\nhence his use of Tor. Ultimately DreamHost accepted his credit card over\nTor.25\nOne way to avoid this hassle with Tor is to configure the torrec config\nfile to use exit nodes located in your home country. That should keep the\ncredit card companies happy. On the other hand, constantly using the same\nexit nodes might ultimately reveal who you are. There is some serious\nspeculation that government agencies might control some exit nodes, so\nusing different ones makes sense.\nAnother way to pay without leaving a trace is to use Bitcoin, a virtual\ncurrency. Like most currencies, it fluctuates in value based on the\nconfidence people have in it.\nBitcoin is an algorithm that allows people to create—or, in Bitcoin\nterminology, mine—their own currency. But if it were easy, everyone\nwould do it. So it’s not. The process is computationally intensive, and it\ntakes a long while just to create one Bitcoin. Thus there is a finite amount\nof Bitcoin in existence on any given day, and that, in addition to consumer\nconfidence, influences its value.\nEach Bitcoin has a cryptographic signature that identifies it as original\nand unique. Transactions made with that cryptographic signature can be\ntraced back to the coin, but the method by which you obtain the coin can\nbe obscured—for example, by setting up a rock-solid anonymous e-mail\naddress and using that e-mail address to set up an anonymous Bitcoin\nwallet using the Tor network.\nYou buy Bitcoin in person, or anonymously online using prepaid gift\ncards, or find a Bitcoin ATM without camera surveillance. Depending on\nwhat surveillance factors could potentially reveal your true identity, every\nrisk needs to be taken into account when choosing which purchasing\nmethod to use. You can then put these Bitcoins into what’s known as a\ntumbler. A tumbler takes some Bitcoins from me, some from you, and\nsome from other people chosen at random and mixes them together. You\nkeep the value of the coins minus the tumbling fee—it’s just that the\ncryptographic signature of each coin may be different after it’s mixed with\nothers. That anonymizes the system somewhat.\nOnce you have them, how do you store Bitcoins? Because there are no\nBitcoin banks, and because Bitcoin is not physical currency, you will need\nto use a Bitcoin wallet set up anonymously using the detailed instructions\ndescribed later in this book.\nNow that you’ve bought and stored it, how do you use Bitcoin?\nExchanges allow you to invest in Bitcoin and change it into other\ncurrencies, such as US dollars, or purchase goods on sites such as Amazon.\nSay you have one Bitcoin, valued at $618. If you only need around $80 for\na purchase, then you will retain a certain percentage of the original value,\ndepending on the exchange rate, after the transaction.\nTransactions are verified in a public ledger known as a blockchain and\nidentified by IP address. But as we have seen, IP addresses can be changed\nor faked. And although merchants have started accepting Bitcoin, the\nservice fees, typically paid by the merchant, have been transferred to the\npurchaser. Furthermore, unlike credit cards, Bitcoin permits no refunds or\nreimbursements.\nYou can accumulate as much Bitcoin as you would hard currency. But\ndespite its overall success (the Winklevoss brothers, famous for\nchallenging Mark Zuckerberg over the founding of Facebook, are major\ninvestors in Bitcoin), the system has had some monumental failures as\nwell. In 2004, Mt. Gox, a Tokyo-based Bitcoin exchange, declared\nbankruptcy after announcing that its Bitcoin had been stolen. There have\nbeen other reports of theft among Bitcoin exchanges, which, unlike most\nUS bank accounts, are not insured.\nStill, although there have been various attempts at virtual currency in\nthe past, Bitcoin has become the Internet’s standard anonymous currency.\nA work in progress, yes, but an option for anyone looking for privacy.\nYou might feel invisible right now—obscuring your IP address with\nTor; encrypting your e-mail and text messages with PGP and Signal. I\nhaven’t, however, talked much about hardware—which can be used to both\nfind you and hide you on the Internet."
  },
  {
    "input": "What are the steps to secure a home wireless network and protect against unauthorized access and potential cyber threats?",
    "summary": "The text discusses how wireless networks can be exploited by neighbors or hackers due to weak security settings, such as default passwords and unsecured SSIDs. It highlights the importance of securing home networks with strong passwords and encryption to prevent unauthorized access. It also covers phishing attacks, like the one on Sophie Curtis, where malicious emails can trick users into downloading malware, and the dangers of ransomware, such as the case involving Alina Simone's mother, where victims often have to pay to regain access to their files.",
    "output": "CHAPTER SEVEN\nPay Up or Else!\nThe nightmare began online and\nended with federal agents\nstorming a house in suburban Blaine, Minnesota. The agents had only an\nIP address associated with child pornography downloads and even a death\nthreat against Vice President Joe Biden. By contacting the Internet service\nprovider associated with that IP address, the agents acquired the user’s\nphysical address. That sort of tracking was very successful back in the\ndays when everyone still had a wired connection to their modems or\nrouters. At that time, each IP address could be physically traced to a given\nmachine.\nBut today most people use wireless connections within their homes.\nWireless allows everyone inside to move around the house with mobile\ndevices and remain connected to the Internet. And if you’re not careful, it\nalso allows neighbors to access that same signal. In this case the federal\nagents stormed the wrong house in Minnesota. They really wanted the\nhouse next door to it.\nIn 2010, Barry Vincent Ardolf pleaded guilty to charges of hacking,\nidentity theft, possession of child pornography, and making threats against\nVice President Biden. Court records show that the trouble between Ardolf\nand his neighbor began when the neighbor, who was in fact a lawyer and\nwas not named, filed a police report saying that Ardolf allegedly\n“inappropriately touched and kissed” the lawyer’s toddler on the mouth.1\nArdolf then used the IP address of his neighbor’s wireless home router\nto open Yahoo and Myspace accounts in his victim’s name. It was from\nthese fake accounts that Ardolf launched a campaign to embarrass and\ncause legal troubles for the lawyer.\nMany ISPs now provide their home routers with wireless capabilities\nbuilt in.2 Some ISPs, such as Comcast, are creating a second open Wi-Fi\nservice over which you have limited control. For example, you may be\nable to change a few settings, such as the ability to turn it off. You should\nbe aware of it. Someone in a van parked in front of your house might be\nusing your free wireless. Although you don’t have to pay extra for that,\nyou might still notice a slight degradation in Wi-Fi speed if there is heavy\nuse of the second signal. You can disable Comcast’s Xfinity Home Hotspot\nif you don’t think you will ever need to give visitors to your home free\nInternet access.3\nWhile built-in wireless is great for getting you up and running with a\nnew service, often these broadband routers are not configured properly and\ncan create problems when they are not secured. For one thing, unsecured\nwireless access could provide a digital point of entry into your home, as it\ndid for Ardolf. While intruders might not be after your digital files, they\nmight be looking to cause problems nonetheless.\nArdolf was no computer genius. He confessed in court that he didn’t\nknow the difference between WEP (wired equivalent privacy) encryption,\nwhich was what the neighbor’s router used, and WPA (Wi-Fi protected\naccess) encryption, which is much more secure. He was just angry. This is\njust one more reason why you should take a moment to consider the\nsecurity of your own household wireless network. You never know when\nan angry neighbor might try to use your home network against you.\nIf someone does do something bad on your home network, there is\nsome protection for the router owner. According to the EFF, federal judges\nhave rejected BitTorrent lawsuits brought by copyright holders because the\ndefendants successfully claimed that someone else downloaded the movies\nusing their wireless networks.4 The EFF states that an IP address is not a\nperson, meaning that wireless subscribers may not be responsible for the\nactions of others using their wireless networks.5\nAlthough computer forensics will clear an innocent person whose Wi-\nFi was used in the commission of a felony—as it did in the case of the\nMinnesota lawyer—why go through all that?\nEven if you use a telephone-based dial-up modem or a cable-based ASM\n(any-source multicast) router (available from Cisco and Belkin, among\nothers), these devices have had their share of software and configuration\nproblems.\nFirst and foremost, download the latest firmware (software installed in\na hardware device). You can do that by accessing the router’s\nconfiguration screen (see below) or by visiting the manufacturer’s website\nand searching for updates for your particular make and model. Do this as\noften as possible. One easy way to update your router’s firmware is to buy\na new one every year. This can get expensive, but it will ensure that you\nhave the latest and greatest firmware. Second, update your router’s\nconfiguration settings. You don’t want the default settings.\nBut first: what’s in a name? More than you think. Common to both the\nISP-provided router and a router you bought at Best Buy is the naming. All\nwireless routers broadcast by default what’s called a service set identifier\n(SSID).6 The SSID is commonly the name and model of your router, e.g.,\n“Linksys WRT54GL.” If you look at the available wireless connections in\nyour area, you’ll see what I mean.\nBroadcasting the default SSID out to the world may mask the fact that\nthe Wi-Fi signal is actually coming from a specific household, but it also\nallows someone on the street to know the exact make and model of the\nrouter you own. Why is that bad? That person might also know the\nvulnerabilities of that make and model and be able to exploit them.\nSo how do you change the name of the router and update its firmware?\nAccessing the router is easy; you do so from your Internet browser. If\nyou don’t have the instructions for your router, there’s an online list of\nURLs that tells you what to type into your browser window so you can\nconnect directly to the router on your home network.7 After typing in the\nlocal URL (you’re just talking to the router, remember, not to the Internet\nat large), you should see a log-in screen. So what’s the username and\npassword for the log-in?\nTurns out there’s a list of default log-ins published on the Internet as\nwell.8 In the Linksys example above, the username is blank and the\npassword is “admin.” Needless to say, once you’re inside the router’s\nconfiguration screen, you should immediately change its default password,\nfollowing the advice I gave you earlier about creating unique and strong\npasswords (see here) or using a password manager.\nRemember to store this password in your password manager or write it\ndown, as you probably won’t need to access your router very often. Should\nyou forget the password (really, how often are you going to be in the\nconfiguration screen for your router?), don’t worry. There is a physical\nreset button that will restore the default settings. However, in conducting a\nphysical, or hard, reset, you will also have to reenter all the configuration\nsettings I’m about to explain below. So write down the router settings or\ntake screenshots and print them out whenever you establish router settings\nthat are different from the default. These screenshots will be valuable\nwhen you need to reconfigure your router.\nI suggest you change “Linksys WRT54GL” to something innocuous,\nsuch as “HP Inkjet,” so it won’t be obvious to strangers which house the\nWi-Fi signal might be coming from. I often use a generic name, such as\nthe name of my apartment complex or even the name of my neighbor.\nThere is also an option to hide your SSID entirely. That means others\nwill not be able to easily see it listed as a wireless network connection.\nWhile you’re inside your basic router configuration settings, there are\nseveral types of wireless security to consider. These are generally not\nenabled by default. And not all wireless encryption is created equal, nor is\nit supported by all devices.\nThe most basic form of wireless encryption, wired equivalent privacy\n(WEP), is useless. If you see it as an option, don’t even consider it. WEP\nhas been cracked for years, and is therefore no longer recommended. Only\nold routers and devices still offer it as a legacy option. Instead, choose one\nof the newer, stronger encryption standards, such as Wi-Fi protected\naccess, or WPA. WPA2 is even more secure.\nTurning on encryption at the router means that the devices connecting\nto it will also need to match encryption settings. Most new devices\nautomatically sense the type of encryption being used, but older models\nstill require you to indicate manually which encryption level you are\nusing. Always use the highest level possible. You’re only as secure as your\nweakest link, so make sure to max out the oldest device in terms of its\navailable encryption.\nEnabling WPA2 means that when you connect your laptop or mobile\ndevice, you will also need to set it to WPA2, although some new operating\nsystems will recognize the type of encryption automatically. Modern\noperating systems on your phone or laptop will identify the Wi-Fi\navailable in your area. Your SSID broadcast (now “HP Inkjet”) should\nappear on the list at or close to the top. Padlock icons within the list of\navailable Wi-Fi connections (usually overlaid upon the strength of each\nconnection) indicate which Wi-Fi connections require passwords (yours\nshould now have a padlock).\nFrom the list of available connections, click on your own SSID. You\nshould be prompted to enter a password—be sure to make it at least fifteen\ncharacters. Or use a password manager to create a complex password. In\norder to connect to your password-protected Wi-Fi, you will have to type\nin that password at least once on each device in order to connect, so a\npassword manager might not work in all cases, particularly when you have\nto remember the complex password and type it in later yourself. Each\ndevice—including your “smart” refrigerator and digital TV—will all use\nthe one router password you have chosen when you set the encryption on\nyour router. You will need to do this once for every device that accesses\nyour home or office Wi-Fi, but you won’t have to do it again unless you\nchange your home network password or acquire a new device.\nYou can also go one step further and limit Wi-Fi connections only to\nthe devices you specify. This is known as whitelisting. With this process\nyou grant access to (whitelist) some devices and forbid (blacklist)\neverything else. This will require you to enter your device’s media access\ncontrol address, or MAC address. It will also mean that when you next\nupgrade your cell phone, you’ll have to add it to the MAC address in your\nrouter before it will connect.9 This address is unique to every device;\nindeed, the first three sets of characters (octets) are the manufacturer’s\ncode, and the final three are unique to the product. The router will reject\nany device whose hardware MAC has not been previously stored. That\nsaid, a hacker tool called aircrack-ng can reveal the authorized MAC\naddress of a currently connected user and then an attacker can spoof the\nMAC address to connect to the wireless router. Just like hidden wireless\nSSIDs, it’s trivial to bypass MAC address filtering.\nFinding the MAC address on your device is relatively easy. In\nWindows, go to the Start button, type “CMD,” click “Command Prompt,”\nand at the inverted caret, type “IPCONFIG.” The machine will return a\nlong list of data, but the MAC address should be there, and it will consist\nof twelve hexadecimal characters with every two characters separated by a\ncolon. For Apple products it is even easier. Go to the Apple icon, select\n“System Preferences,” and go to “Network.” Then click the network\ndevice on the left panel and go to Advanced>Hardware, and you will see\nthe MAC address. For some older Apple products, the procedure is: Apple\nicon>System Preferences>Networks>Built-in Ethernet. You can find the\nMAC address for your iPhone by selecting Settings>General>About and\nlooking under “Wi-Fi Address.” For an Android phone, go to\nSettings>About Phone>Status, and look under “Wi-Fi MAC address.”\nThese directions may change based on the device and model you are using.\nWith these twelve-digit MAC addresses in hand, you will now need to\ntell the router to allow only these devices and block everything else. There\nare a few downsides. If a guest comes over and wants to connect to your\nhome network, you will have to decide whether to give one of your devices\nand its password to that person or simply turn off MAC address filtering\nby reentering the router configuration screen. Also, there are times when\nyou might want to change the MAC address of a device (see here); if you\ndon’t change it back, you might not be able to connect to your MAC-\nrestricted Wi-Fi network at home or work. Fortunately, rebooting the\ndevice restores the original MAC address in most cases.\nTo make connecting any new device to a home router easy, the Wi-Fi\nAlliance, a group of vendors eager to spread the use of Wi-Fi technologies,\ncreated Wi-Fi protected setup (WPS). WPS was advertised as a way for\nanyone—I mean anyone—to securely set up a mobile device at home or in\nthe office. In reality, though, it’s not very secure.\nWPS is typically a button that you push on the router. Other methods\ninclude use of a PIN and near field communication (NFC). Simply put,\nyou activate the WPS feature, and it communicates with any new devices\nyou have in your home or office, automatically synchronizing them to\nwork with your Wi-Fi network.\nSounds great. However, if the router is out in “public”—say, in your\nliving room—then anyone can touch the WPS button and join your home\nnetwork.\nEven without physical access, an online attacker can use brute force to\nguess your WPS PIN. It could take several hours, but it’s still a viable\nattack method, one you should protect yourself against by immediately\nturning off WPS on the router.\nAnother WPS attack method is known as Pixie Dust. This is an offline\nattack and affects only a few chip makers, including Ralink, Realtek, and\nBroadcom. Pixie Dust works by helping hackers gain access to the\npasswords on wireless routers. Basically the tool is very straightforward\nand can gain access to a device in seconds or hours depending on the\ncomplexity of the chosen or generated WPS PIN.10 For example, one such\nprogram, Reaver, can crack a WPS-enabled router within several hours.\nIn general, it’s a good idea to turn off WPS. You can simply connect\neach new mobile device to your network by typing in whatever password\nyou’ve assigned for access.\nSo you have prevented, through the use of encryption and strong\npasswords, the use of your home wireless router network by others. Does\nthat mean that no one can get inside your home network or even digitally\nsee inside your home? Not entirely.\nWhen high school sophomore Blake Robbins was called into the\nprincipal’s office of his suburban Philadelphia school, he had no idea he\nwas about to be reprimanded for “improper behavior”—at home. The\nLower Merion School District, outside Philadelphia, had given all its high\nschool students, including Robbins, new MacBooks to use for their course\nwork. What the school district didn’t tell the students was that software\ndesigned to recover the devices in the event they were lost could also be\nused to monitor all 2,300 students’ behavior while they were in view of the\nlaptops’ webcams.\nRobbins’s alleged offense? Pill popping. The Robbins family, through\ntheir lawyer, maintained all along that the boy was simply eating Mike and\nIke candy while doing his homework.\nWhy was this even an issue?\nThe school district maintains it activated the theft-tracking software\nonly after one of its laptops was stolen. Theft-tracking software works like\nthis: when someone using the software reports that his or her laptop has\nbeen stolen, the school can log on to a website and see images from the\nstolen laptop’s webcam as well as hear sounds from the microphone. A\nschool administrator could then monitor the laptop and take pictures as\nneeded. This way the device can be located and returned and the guilty\nparty can be identified. However, in this case it was alleged that school\nofficials were turning on this feature to spy on the students while they\nwere at home.\nThe webcam on Robbins’s school-issued Mac laptop recorded hundreds\nof photos, including some of the boy asleep in his bed. For other students\nit was worse. According to court testimony, the school had even more\npictures of some students, a few of whom were “partially undressed.” This\nmight have continued unnoticed by the students had Robbins not been\nreprimanded for something he allegedly did at home.\nRobbins, along with a former student, Jalil Hasan—who had nearly five\nhundred images taken of him and four hundred images of his computer\nscreen captured, revealing his online activity and the sites he visited—\nsued the school district. Robbins received $175,000 and Hasan $10,000.11\nThe district also paid almost half a million dollars to cover the boys’ legal\nexpenses. In total the school district had to pay out, through its insurer,\naround $1.4 million.\nIt’s easy for malicious software to activate the webcam and microphone\non a traditional PC without the user knowing it. And this is true on a\nmobile device as well. In this case it was a deliberate action. But all too\noften it is not. One quick fix is to put tape over the webcam on your laptop\nuntil you intend to use it again.\nIn the fall of 2014, Sophie Curtis, a reporter for the London-based\nTelegraph, received a LinkedIn connection request in an e-mail that\nappeared to come from someone who worked at her newspaper. It was the\nkind of e-mail that Sophie received all the time, and as a professional\ncourtesy she didn’t think twice about accepting it from a colleague. A\ncouple of weeks later she received an e-mail that appeared to be from an\nanonymous whistle-blower organization that was about to release sensitive\ndocuments. As a reporter who had covered groups such as Anonymous and\nWikiLeaks, she had received e-mails like this before, and she was curious\nabout the request. The file attachment looked like a standard file, so she\nclicked to open it.\nImmediately she realized something was wrong. Windows Defender,\nthe security program that comes with every copy of Windows, started\nissuing warnings on her desktop. And the warnings kept piling up on the\nscreen.\nCurtis, like a lot of people today, had been tricked into clicking on an\nattachment that she thought was an ordinary file. While pretending to have\ninformation she wanted to see, the file downloaded and unpacked a series\nof other files that allowed the remote attacker to take complete control\nover her computer. The malicious software even took a picture of her with\nher own webcam. In it her face bears a look of sheer frustration as she tries\nto understand how someone could’ve taken over her computer.\nActually Curtis knew full well who had taken over her computer. As an\nexperiment, a few months earlier she had hired a penetration tester, or pen\ntester. Someone like me. Individuals and companies hire professional\nhackers to try to break into a company’s computer network to see where\nthey need fortification. In Curtis’s case, the process was spread out over\nseveral months.\nAt the start of jobs like this, I always try to get as much information\nabout the client as I can. I spend time learning about his or her life and\nonline habits. I track the client’s public posts to Twitter, Facebook, and,\nyes, even LinkedIn. Which is exactly what Sophie Curtis’s pen tester did.\nAmid all her e-mails was one carefully constructed message—the first one\nsent by her pen tester. The pen tester knew that she worked as a reporter\nand knew that she was open to e-mail solicitations from previously\nunknown individuals. In that first case Curtis later wrote that there was not\nenough context for her to be interested in interviewing a particular person\nfor a future story. But she was impressed by the amount of research the\nhacker and his colleagues at the security company did.\nCurtis said: “They were able to use Twitter to find out my work e-mail\naddress, as well as some of my recent locations and the name of a regular\nsocial night I attend with other journalists. From objects in the background\nof one of the photos I had posted on Twitter they were able to discover\nwhat mobile phone I used to use, and the fact that my fiancé used to smoke\nroll-ups (it was an old photo), as well as the fact he likes cycling.”12 Any\none of these details could have been the basis for another e-mail.\nThere’s also a new Artificial Intelligence–based tool announced at the\nDEF CON 2016 conference that will analyze a target’s tweets. It will then\nconstruct a spear-phishing e-mail based on their personal interests.13 So be\ncareful when clicking links within a tweet.\nIndeed, often it is the little things—the odd comment posted here or\nthere, the unique knickknack on the shelf behind you in a photo, the T-shirt\nfrom a camp you once attended—that provide crucial personal information\nthat you would never have intended to share publicly. We may consider\nthese one-off moments harmless, but the more details an attacker can learn\nabout you, the better he can trick you into opening up e-mail attachments,\nand take over your online world.\nCurtis points out that the pen-test team ended their attack there. Had\nthey been real criminal hackers, the fun and games might have continued\nfor some time, perhaps with the bad guys gaining access to her social\nmedia accounts, her office network at the Telegraph, even her financial\naccounts. And most likely they would have done it in such a way that\nCurtis might not have known her computer had been compromised; most\nattacks do not immediately trigger Windows Defender or antivirus\nsoftware. Some attackers get in and persist for months or years before the\nuser has any clue that he or she has been hacked. And it’s not just your\nlaptop: an e-mail-triggered attack could also be launched from a\njailbroken iPhone or an Android mobile device.\nWhile Google and other e-mail providers scan your messages to prevent\nthe transmission of malware and the spread of online pornography—and to\ncollect advertising data—they do not necessarily scan for fraud. Like\nprivacy, the standard for which, as I’ve said, is different for everyone,\nfraud is hard to quantify. And we don’t always recognize it, even when it’s\nstaring us in the face.\nWithin the body of Curtis’s fake LinkedIn e-mail was a one-by-one-\ninch pixel, a tiny dot of an image, invisible to the eye, like those I said\ncould be found on websites and used to track you online. When that tiny\ndot calls out, it tells a tracking server in a remote location, which could be\nanywhere in the world, what time you opened the e-mail, how long it\nremained on the screen, and on what device you opened it. It can also tell\nwhether you saved, forwarded, or deleted the message. In addition, if the\nscenario used by the pen-test team had been real, the attacker might have\nincluded a link through which Curtis could have visited a fake LinkedIn\npage. This page would resemble a real one in every respect except that it\nwould be hosted on a different server, perhaps in another country.\nFor an advertiser, this Web bug can be used to gather information about\n(and therefore profile) the recipient. For attackers, it can be used to obtain\nthe technical details they need to design their next attack, which would\ninclude a way to get inside your computer. For example, if you are running\nan old version of a browser, there may be bugs that can be exploited.\nSo the second e-mail Curtis received from the pen testers included an\nattachment, a compressed document set to exploit a vulnerability in the\nsoftware that was used to open the file (e.g., Adobe Acrobat). When we\nspeak of malware, most people think of the computer viruses of the early\n2000s, when a single infected e-mail could spread additional infected e-\nmails to everyone on a contact list. These types of mass-infection attacks\nare less common today, in part because of changes to e-mail software\nitself. Instead the most dangerous malware today is much more subtle and\noften targeted and tailored to an individual. As it was in the case of Sophie\nCurtis. The pen testers used a special form of phishing called spear\nphishing, designed to target a specific person.\nPhishing is the criminally fraudulent process of trying to obtain\nsensitive information such as usernames, passwords, and credit card or\nbank information. It has been used against CFOs who are duped into\nwiring large sums of money because the “CEO” has authorized the\ntransfer. Usually, the phishing e-mail or text message includes an action\nitem such as clicking a link or opening up an attachment. In Curtis’s case\nthe intent was to plant malware on her computer for the purpose of\nillustrating how easy it is for someone to do this.\nOne of the most famous phishing schemes was Operation Aurora, in\nwhich a phishing e-mail was sent to Chinese employees of Google. The\nidea was to infect their machines in China in order to gain access to the\ninternal network at Google’s world headquarters, in Mountain View,\nCalifornia. This the attackers did, getting dangerously close to the source\ncode for Google’s search engine. Google wasn’t alone. Companies such as\nAdobe reported similar intrusions. As a result Google briefly pulled its\noperations from China.14\nWhenever we get a LinkedIn or Facebook request, our guard is down.\nPerhaps because we trust those sites, we also trust their e-mail messages.\nAnd yet, as we have seen, anyone can craft a message that looks\nlegitimate. In person, we can usually sense when someone is wearing a\nfake mustache or hair implants or speaking in a false voice; we have\ncenturies’ worth of evolutionary instincts to help us detect deception\nwithout thinking about it. Those instincts don’t apply online, at least not\nfor most of us. Sophie Curtis was a reporter; it was her job to be curious\nand skeptical, to follow leads and check facts. She could have looked\nthrough the Telegraph’s employee list to see who the person on LinkedIn\nwas and learned that the e-mail was probably fake. But she didn’t. And the\nreality is that most of us are equally unguarded.\nAn attacker who is phishing will have some but not all of your personal\ninformation—the little bit he has serves as his bait. For example, a phisher\nmight send you an e-mail including the last four digits of your credit card\nnumber to establish trust, then go on to ask for even more information.\nSometimes the four digits are incorrect, and the phisher will ask that you\nmake any necessary corrections in your response. Don’t do it. In short,\ndon’t interact with a phisher. In general do not respond to any requests for\npersonal information, even if they seem trustworthy. Instead, contact the\nrequester in a separate e-mail (if you have the address) or text (if you have\nthe cell-phone number).\nThe more concerning phishing attack is one that’s used to trick a target\ninto doing an action item that directly exploits his or her computer, giving\nthe attacker full control. That’s what I do in social engineering\nengagements. Credential harvesting is also a popular line of attack, where\na person’s username and password are captured, but the real danger of\nspear phishing is gaining access to the target’s computer system and\nnetwork.\nWhat if you did interact with a phisher and as a result lost all the data—all\nthe personal photographs and private documents—on your infected PC or\nmobile device? That’s what happened to author Alina Simone’s mother.\nWriting in the New York Times, Simone described what it was like for her\nmother—who was not technologically inclined—to be up against a\nsophisticated enemy who was using something called ransomware.15\nIn 2014 a wave of extortionist malware hit the Internet, targeting\nindividuals and corporations alike. Cryptowall is one example: it encrypts\nyour entire hard drive, locking you out of every file until you pay the\nattacker to give you the key to unlock your files. Unless you have a full\nbackup, the contents of your traditional PC or Android device will be\ninaccessible until you pay the ransom.\nDon’t want to pay? The extortion letter that appears on the display\nscreen states that the key to unlock the files will be destroyed within a\ncertain amount of time. Often there is a countdown clock included. If you\ndon’t pay, the deadline is sometimes extended, although the price\nincreases with each delay.\nIn general you should avoid clicking on e-mail attachments (unless you\nopen them in Google Quick View or Google Docs). Still, there are other\nways in which Cryptowall spreads—banner ads on websites, for example.\nJust viewing a page with an infected banner ad can infect your traditional\nPC—this is called a drive-by because you didn’t actively click on the ad.\nHere’s where having ad-removal plug-ins such as Adblock Plus in your\nbrowser is really effective.\nIn the first six months of 2015, the FBI’s Internet Crime Complaint\nCenter (IC3) recorded nearly one thousand cases of Cryptowall 3.0, with\nlosses estimated to be around $18 million. This figure includes ransom\nthat was paid, the cost to IT departments and repair shops, and lost\nproductivity. In some cases the encrypted files contain personally\nidentifiable information such as Social Security numbers, which may\nqualify the attack as a data breach and thus incur more costs.\nAlthough the key to unlock the files can always be purchased for a flat\nfee of $500 to $1000, those who are infected typically try other means—\nsuch as breaking the encryption themselves—to remove the ransomware.\nThat’s what Simone’s mother tried. When she finally called her daughter,\nthey were almost out of time.\nAlmost everyone who tries to break the ransomware encryption fails.\nThe encryption is really strong and requires more powerful computers and\nmore time to break it than most people have at their disposal. So the\nvictims usually pay. According to Simone, the Dickson County, Tennessee,\nsheriff’s office paid in November 2014 a Cryptowall ransom to unlock\n72,000 autopsy reports, witness statements, crime scene photographs, and\nother documents.\nThe hackers often demand payment in Bitcoin, meaning that many\naverage people will have a hard time paying.16 Bitcoin, as I mentioned, is\na decentralized, peer-to-peer virtual currency, and most people do not have\nBitcoin wallets available for withdrawal.\nThroughout the Times piece, Simone reminds readers that they should\nnever pay the ransom—yet she did just that in the end. In fact the FBI now\nadvises people whose computers are infected with ransomware to simply\npay up. Joseph Bonavolonta, the assistant special agent in charge of the\nFBI’s cyber and counterintelligence program in Boston, said, “To be\nhonest, we often advise people just to pay the ransom.” He said not even\nthe FBI is able to crack the ultrasecure encryption used by the ransomware\nauthors, and he added that because so many people have paid the attackers,\nthe $500 cost has remained fairly consistent over the years.17 The FBI\nlater came out to say it’s up to the individual companies to decide whether\nto pay or contact other security professionals.\nSimone’s mother, who had never purchased an app in her life, called\nher daughter at the eleventh hour only because she needed to figure out\nhow to pay with the virtual currency. Simone said she found a Bitcoin\nATM in Manhattan from which, after a software glitch and a service call to\nthe ATM owner, she ultimately made the payment. At that day’s exchange\nrate, each Bitcoin was a bit more than $500.\nWhether these extortionists receive their payment in Bitcoin or in cash,\nthey remain anonymous, although technically there are ways of tracing\nboth forms of payment. Transactions conducted online using Bitcoin can\nbe connected to the purchaser—but not easily. The question is, who is\ngoing to put forth the time and effort to pursue these criminals?\nIn the next chapter I will describe what can happen when you connect\nto the Internet via public Wi-Fi. From a privacy perspective you want the\nanonymity of a public Wi-Fi but at the same time you will need to take\nprecautions."
  },
  {
    "input": "What are the key steps to protect privacy and security when using public Wi-Fi or public computer terminals?",
    "summary": "The chapter discusses how public Wi-Fi networks are insecure and how users can unintentionally connect to fake networks, making their data vulnerable. It emphasizes the importance of using secure methods like a VPN or cellular data to protect sensitive information. Additionally, it highlights the risks of using public computers and suggests steps to minimize exposure, such as avoiding personal accounts, using HTTPS, and properly clearing browsing data.",
    "output": "CHAPTER EIGHT\nBelieve Everything, Trust Nothing\nWhen the telephone was still\na novelty, it was physically wired\ninto the home and perhaps placed in a nook built into the wall. Getting a\nsecond line was considered a status symbol. Similarly, public phone\nbooths were built for privacy. Even banks of pay phones in hotel lobbies\nwere equipped with sound baffles between them to give the illusion of\nprivacy.\nWith mobile phones, that sense of privacy has fallen away entirely. It is\ncommon to walk down the street and hear people loudly sharing some\npersonal drama or—worse—reciting their credit card number within\nearshot of all who pass by. In the midst of this culture of openness and\nsharing, we need to think carefully about the information we’re\nvolunteering to the world.\nSometimes the world is listening. I’m just saying.\nSuppose you like to work at the café around the corner from your home, as\nI sometimes do. It has free Wi-Fi. That should be okay, right? Hate to\nbreak it to you, but no. Public Wi-Fi wasn’t created with online banking or\ne-commerce in mind. It is merely convenient, and it’s also incredibly\ninsecure. Not all that insecurity is technical. Some of it begins—and, I\nhope, ends—with you.1\nHow can you tell if you are on public Wi-Fi? For one thing, you won’t\nbe asked to input a password to connect to the wireless access point. To\ndemonstrate how visible you are on public Wi-Fi, researchers from the\nantivirus company F-Secure built their own access point, or hotspot. They\nconducted their experiment in two different locations in downtown\nLondon—a café and a public space. The results were eye-opening.\nIn the first experiment, the researchers set up in a café in a busy part of\nLondon. When patrons considered the choices of available networks, the\nF-Secure hotspot came up as both strong and free. The researchers also\nincluded a banner that appeared on the user’s browser stating the terms\nand conditions. Perhaps you’ve seen a banner like this at your local coffee\nshop stipulating what you can and cannot do while using their service. In\nthis experiment, however, terms for use of this free Wi-Fi required the\nsurrender of the user’s firstborn child or beloved pet. Six people consented\nto those terms and conditions.2 To be fair, most people don’t take the time\nto read the fine print—they just want whatever is on the other end. Still,\nyou should at least skim the terms and conditions. In this case, F-Secure\nsaid later that neither it nor its lawyers wanted anything to do with\nchildren or pets.\nThe real issue is what can be seen by third parties while you’re on\npublic Wi-Fi. When you’re at home, your wireless connection should be\nencrypted with WPA2 (see here). That means if anyone is snooping, he or\nshe can’t see what you’re doing online. But when you’re using open,\npublic Wi-Fi at a coffee shop or airport, that destination traffic is laid\nbare.\nAgain you might ask, what’s the problem with all this? Well, first of\nall, you don’t know who’s on the other end of the connection. In this case\nthe F-Secure research team ethically destroyed the data they collected, but\ncriminals probably would not. They’d sell your e-mail address to\ncompanies that send you spam, either to get you to buy something or to\ninfect your PC with malware. And they might even use the details in your\nunencrypted e-mails to craft spear-phishing attacks.\nIn the second experiment, the team set the hotspot on a balcony in close\nproximity to the Houses of Parliament, the headquarters of the Labour and\nConservative parties, and the National Crime Agency. Within thirty\nminutes a total of 250 people connected to the experimental free hotspot.\nMost of these were automatic connections made by whatever device was\nbeing used. In other words, the users didn’t consciously choose the\nnetwork: the device did that for them.\nA couple of issues here. Let’s first look at how and why your mobile\ndevices automatically join a Wi-Fi network.\nYour traditional PC and all your mobile devices remember your last\nfew Wi-Fi connections, both public and private. This is good because it\nsaves you the trouble of continually reidentifying a frequently used Wi-Fi\naccess point—such as your home or office. This is also bad because if you\nwalk into a brand-new café, a place you’ve never been before, you might\nsuddenly find that you have wireless connectivity there. Why is that bad?\nBecause you might be connected to something other than the café’s\nwireless network.\nChances are your mobile device detected an access point that matches a\nprofile already on your most recent connection list. You may sense\nsomething amiss about the convenience of automatically connecting to\nWi-Fi in a place you’ve never been before, but you may also be in the\nmiddle of a first-person shooter game and don’t want to think much\nbeyond that.\nHow does automatic Wi-Fi connection work? As I explained in the last\nchapter, maybe you have Comcast Internet service at home, and if you do\nyou might also have a free, nonencrypted public SSID called Xfinity as\npart of your service plan. Your Wi-Fi-enabled device may have connected\nto it once in the past.3 But how do you know that the guy with a laptop at\nthe corner table isn’t broadcasting a spoofed wireless access point called\nXfinity?\nLet’s say you are connected to that shady guy in the corner and not to\nthe café’s wireless network. First, you will still be able to surf the Net. So\nyou can keep on playing your game. However, every packet of\nunencrypted data you send and receive over the Internet will be visible to\nthis shady character through his spoofed laptop wireless access point.\nIf he’s taken the trouble to set up a fake wireless access point, then he’s\nprobably capturing those packets with a free application such as\nWireshark. I use this app in my work as a pen tester. It allows me to see\nthe network activity that’s going on around me. I can see the IP addresses\nof sites people are connecting to and how long they are visiting those sites.\nIf the connection is not encrypted, it is legal to intercept the traffic\nbecause it is generally available to the public. For example, as an IT\nadmin, I would want to know the activity on my network.\nMaybe the shady guy in the corner is just sniffing, seeing where you go\nand not influencing the traffic. Or maybe he is actively influencing your\nInternet traffic. This would serve multiple purposes.\nMaybe he’s redirecting your connection to a proxy that implants a\njavascript keylogger in your browser so when you visit Amazon your\nkeystrokes will be captured as you interact with the site. Maybe he gets\npaid to harvest your credentials—your username and password. Remember\nthat your credit card may be associated with Amazon and other retailers.\nWhen delivering my keynote, I give a demonstration that shows how I\ncan intercept a victim’s username and password when accessing sites once\nhe or she is connected to my spoofed access point. Because I’m sitting in\nthe middle of the interaction between the victim and the website, I can\ninject JavaScript and cause fake Adobe updates to pop up on his or her\nscreen, which, if installed will infect the victim’s computer with malware.\nThe purpose is usually to trick you into installing the fake update to gain\ncontrol of your computer.\nWhen the guy at the corner table is influencing the Internet traffic,\nthat’s called a man-in-the-middle attack. The attacker is proxying your\npackets through to the real site, but intercepting or injecting data along the\nway.\nKnowing that you could unintentionally connect to a shady Wi-Fi\naccess point, how can you prevent it? On a laptop the device will go\nthrough the process of searching for a preferred wireless network and then\nconnect to it. But some laptops and mobile devices automatically choose\nwhat network to join. This was designed to make the process of taking\nyour mobile device from one location to another as painless as possible.\nBut as I mentioned, there are downsides to this convenience.\nAccording to Apple, its various products will automatically connect to\nnetworks in this order of preference:\n1. the private network the device most recently joined,\n2. another private network, and\n3. a hotspot network.\nLaptops, fortunately, provide the means to delete obsolete Wi-Fi\nconnections—for example, that hotel Wi-Fi you connected to last summer\non a business trip. In a Windows laptop, you can uncheck the “Connect\nAutomatically” field next to the network name before you connect. Or\nhead to Control Panel>Network and Sharing Center and click on the\nnetwork name. Click on “Wireless Properties,” then uncheck “Connect\nautomatically when this network is in range.” On a Mac, head to System\nPreferences, go to Network, highlight Wi-Fi on the left-hand panel, and\nclick “Advanced.” Then uncheck “Remember networks this computer has\njoined.” You can also individually remove networks by selecting the name\nand pressing the minus button underneath it.\nAndroid and iOS devices also have instructions for deleting previously\nused Wi-Fi connections. On an iPhone or iPod, go into your settings, select\n“Wi-Fi,” click the “i” icon next to the network name, and choose “Forget\nThis Network.” On an Android phone, you can go into your settings,\nchoose “Wi-Fi,” long-press the network name, and select “Forget\nNetwork.”\nSeriously, if you really have something sensitive to do away from your\nhouse, then I recommend using the cellular connection on your mobile\ndevice instead of using the wireless network at the airport or coffee shop.\nYou can also tether to your personal mobile device using USB, Bluetooth,\nor Wi-Fi. If you use Wi-Fi, then make sure you configure WPA2 security\nas mentioned earlier. The other option is to purchase a portable hotspot to\nuse when traveling. Note, too, this won’t make you invisible, but is a\nbetter alternative than using public Wi-Fi. But if you need to protect your\nprivacy from the mobile operator—say, to download a sensitive\nspreadsheet—then I suggest you use HTTPS Everywhere or a Secure File\nTransfer Protocol (SFTP). SFTP is supported using the Transmit app on\nMac and the Tunnelier app on Windows.\nA virtual private network (VPN) is a secure “tunnel” that extends a private\nnetwork (from your home, office, or a VPN service provider) to your\ndevice on a public network. You can search Google for VPN providers and\npurchase service for approximately $60 a year. The network you’ll find at\nthe local coffee shop or the airport or in other public places is not to be\ntrusted—it’s public. But by using a VPN you can tunnel through the public\nnetwork back to a private and secure network. Everything you do within\nthe VPN is protected by encryption, as all your Internet traffic is now\nsecured over the public network. That’s why it’s important to use a VPN\nprovider you can trust—it can see your Internet traffic. When you use a\nVPN at the coffee shop, the sketchy guy in the corner can only see that you\nhave connected to a VPN server and nothing else—your activities and the\nsites you visit are all completely hidden behind tough-to-crack encryption.\nHowever, you will still touch the Internet with an IP address that is\ntraceable directly to you, in this case the IP address from your home or\noffice. So you’re still not invisible, even using a VPN. Don’t forget—your\nVPN provider knows your originating IP address. Later we’ll discuss how\nto make this connection invisible (see here).\nMany companies provide VPNs for their employees, allowing them to\nconnect from a public network (i.e., the Internet) to a private internal\ncorporate network. But what about the rest of us?\nThere are many commercial VPNs available. But how do you know\nwhether to trust them? The underlying VPN technology, IPsec (Internet\nprotocol security), automatically includes PFS (perfect forward secrecy;\nsee here), but not all services—even corporate ones—actually bother to\nconfigure it. OpenVPN, an open-source project, includes PFS, so you\nmight infer that when a product says it uses OpenVPN it also uses PFS, but\nthis is not always the case. The product might not have OpenVPN\nconfigured properly. Make sure the service specifically includes PFS.\nOne disadvantage is that VPNs are more expensive than proxies.4 And,\nsince commercial VPNs are shared, they can also be slow, or in some cases\nyou simply can’t get an available VPN for your personal use and you will\nhave wait until one becomes available. Another annoyance is that in some\ncases Google will pop up a CAPTCHA request (which asks you to type in\nthe characters you see on the screen) before you can use its search engine\nbecause it wants to make sure you are a human and not a bot. Finally, if\nyour particular VPN vendor keeps logs, read the privacy policy to make\nsure that the service doesn’t retain your traffic or connection logs—even\nencrypted—and that it doesn’t make the data easy to share with law\nenforcement. You can figure this out in the terms of service and privacy\npolicy. If they can report activities to law enforcement, then they do log\nVPN connections.\nAirline passengers who use an in-air Internet service such as GoGo run\nthe same risk as they do going online while sitting in a Starbucks or\nairport lounge, and VPNs aren’t always great solutions. Because they want\nto prevent Skype or other voice-call applications, GoGo and other in-air\nservices throttle UDP packets—which will make most VPN services very\nslow as UDP is the protocol most use by default. However, choosing a\nVPN service that uses the TCP protocol instead of UDP, such as TorGuard\nor ExpressVPN, can greatly improve performance. Both of these VPN\nservices allow the user to set either TCP or UDP as their preferred\nprotocol.\nAnother consideration with a VPN is its privacy policy. Whether you\nuse a commercial VPN or a corporate-provided VPN, your traffic travels\nover its network, which is why it’s important to use https so the VPN\nprovider can’t see the contents of your communications.5\nIf you work in an office, chances are your company provides a VPN so\nthat you can work remotely. Within an app on your traditional PC, you\ntype in your username and password (something you know). The app also\ncontains an identifying certificate placed there by your IT department\n(something you already have), or it may send you a text on your company-\nissued phone (also something you have). The app may employ all three\ntechniques in what’s known as multifactor authentication.\nNow you can sit in a Starbucks or an airport lounge and conduct\nbusiness as though you were using a private Internet service. However,\nyou should not conduct personal business, such as remote banking, unless\nthe actual session is encrypted using the HTTPS Everywhere extension.\nThe only way to trust a VPN provider is to be anonymous from the\nstart. If you really want to be completely anonymous, never use an Internet\nconnection that could be linked to you (i.e., one originating from your\nhome, office, friends’ homes, a hotel room reserved in your name, or\nanything else connected to you). I was caught when the FBI traced a cell-\nphone signal to my hideout in Raleigh, North Carolina, back in the 1990s.\nSo never access personal information using a burner device in the same\nlocation if you’re attempting to avoid governmental authorities. Anything\nyou do on the burner device has to be completely separate in order to\nremain invisible. Meaning that no metadata from the device can be linked\nto your real identity.\nYou can also install a VPN on your mobile device. Apple provides\ninstructions for doing so,6 and you can find instructions for Android\ndevices as well.7\nIf you have been following my advice in the book so far, you’ll\nprobably fare much better than the average Joe. Most of your Internet\nusage will probably be safe from eavesdropping or manipulation by an\nattacker.\nSo will your social media. Facebook uses https for all its sessions.\nChecking your e-mail? Google has also switched over to https only.\nMost Web mail services have followed, as have most major instant\nmessaging services. Indeed, most major sites—Amazon, eBay, Dropbox—\nall now use https.\nTo be invisible, it’s always best to layer your privacy. Your risk of\nhaving your traffic viewed by others in a public network declines with\neach additional layer of security you employ. For example, from a public\nWi-Fi network, access your paid VPN service, then access Tor with the\nHTTPS Everywhere extension installed by default in the Firefox browser.\nThen whatever you do online will be encrypted and hard to trace.\nSay you just want to check the weather and not do anything financial or\npersonal, and you are using your own personal laptop outside your home\nnetwork—that should be secure, right? Once again, not really. There are a\nfew precautions you still need to take.\nFirst, turn off Wi-Fi. Seriously. Many people leave Wi-Fi on their\nlaptops turned on even when they don’t need it. According to documents\nreleased by Edward Snowden, the Communications Security\nEstablishment Canada (CSEC) can identify travelers passing through\nCanadian airports just by capturing their MAC addresses. These are\nreadable by any computer that is searching for any probe request sent from\nwireless devices. Even if you don’t connect, the MAC address can be\ncaptured. So if you don’t need it, turn off your Wi-Fi.8 As we’ve seen,\nconvenience often works against privacy and safety.\nSo far we’ve skirted around an important issue—your MAC address. This\nis unique to whatever device you are using. And it is not permanent; you\ncan change it.\nLet me give you an example.\nIn the second chapter, I told you about encrypting your e-mail using\nPGP (Pretty Good Privacy; see here). But what if you don’t want to go\nthrough the hassle, or what if the recipient doesn’t have a public PGP key\nfor you to use? There is another clandestine way to exchange messages via\ne-mail: use the drafts folder on a shared e-mail account.\nThis is how former CIA director General David Petraeus exchanged\ninformation with his mistress, Paula Broadwell—his biographer. The\nscandal unfolded after Petraeus ended the relationship and noticed that\nsomeone had been sending threatening e-mails to a friend of his. When the\nFBI investigated, they found not only that the threats had come from\nBroadwell but that she had also been leaving romantic messages for\nPetraeus.9\nWhat’s interesting is that the messages between Broadwell and\nPetraeus were not transmitted but rather left in the drafts folder of the\n“anonymous” e-mail account. In this scenario the e-mail does not pass\nthrough other servers in an attempt to reach the recipient. There are fewer\nopportunities for interceptions. And if someone does get access to the\naccount later on, there will be no evidence if you delete the e-mails and\nempty the trash beforehand.\nBroadwell also logged in to her “anonymous” e-mail account using a\ndedicated computer. She did not contact the e-mail site from her home IP\naddress. That would have been too obvious. Instead she went to various\nhotels to conduct her communications.\nAlthough Broadwell had taken considerable pains to hide, she still was\nnot invisible. According to the New York Times, “because the sender’s\naccount had been registered anonymously, investigators had to use\nforensic techniques—including a check of what other e-mail accounts had\nbeen accessed from the same computer address—to identify who was\nwriting the e-mails.”10\nE-mail providers such as Google, Yahoo, and Microsoft retain log-in\nrecords for more than a year, and these reveal the particular IP addresses a\nconsumer has logged in from. For example, if you used a public Wi-Fi at\nStarbucks, the IP address would reveal the store’s physical location. The\nUnited States currently permits law enforcement agencies to obtain these\nlog-in records from the e-mail providers with a mere subpoena—no judge\nrequired.\nThat means the investigators had the physical location of each IP\naddress that contacted that particular e-mail account and could then match\nBroadwell’s device’s MAC address on the router’s connection log at those\nlocations.11\nWith the full authority of the FBI behind them (this was a big deal,\nbecause Petraeus was the CIA director at the time), agents were able to\nsearch all the router log files for each hotel and see when Broadwell’s\nMAC address showed up in hotel log files. Moreover, they were able to\nshow that on the dates in question Broadwell was a registered guest. The\ninvestigators did note that while she logged in to these e-mail accounts,\nshe never actually sent an e-mail.\nWhen you connect to a wireless network, the MAC address on your\ncomputer is automatically recorded by the wireless networking equipment.\nYour MAC address is similar to a serial number assigned to your network\ncard. To be invisible, prior to connecting to any wireless network you need\nto change your MAC address to one not associated with you.\nTo stay invisible, the MAC address should be changed each time you\nconnect to the wireless network so your Internet sessions cannot easily be\ncorrelated to you. It’s also important not to access any of your personal\nonline accounts during this process, as it can compromise your anonymity.\nInstructions for changing your MAC address vary with each operating\nsystem—i.e., Windows, Mac OS, Linux, even Android and iOS.12 Each\ntime you connect to a public (or private) network, you might want to\nremember to change your MAC address. After a reboot, the original MAC\naddress returns.\nLet’s say you don’t own a laptop and have no choice but to use a public\ncomputer terminal, be it in a café, a library, or even a business center in a\nhigh-end hotel. What can you do to protect yourself?\nWhen I go camping I observe the “leave no trace” rule—that is, the\ncampsite should look just as it did when I first arrived. The same is true\nwith public PC terminals. After you leave, no one should know you were\nthere.\nThis is especially true at trade shows. I was at the annual Consumer\nElectronics Show one year and saw a bank of public PCs set out so that\nattendees could check their e-mail while walking the convention floor. I\neven saw this at the annual security-conscious RSA conference, in San\nFrancisco. Having a row of generic terminals out in public is a bad idea for\na number of reasons.\nOne, these are leased computers, reused from event to event. They may\nbe cleaned, the OS reinstalled, but then again they might not be.\nTwo, they tend to run admin rights, which means that the conference\nattendee can install any software he or she wants to. This includes\nmalware such as keyloggers, which can store your username and password\ninformation. In the security business, we speak of the principle of “least\nprivilege,” which means that a machine grants a user only the minimum\nprivileges he or she needs to get the job done. Logging in to a public\nterminal with system admin privileges, which is the default position on\nsome public terminals, violates the principle of least privilege and only\nincreases the risk that you are using a device previously infected with\nmalware. The only solution is to somehow be certain that you are using a\nguest account, with limited privileges, which most people won’t know how\nto do.\nIn general I recommend never trusting a public PC terminal. Assume\nthe person who last used it installed malware—either consciously or\nunconsciously. If you log in to Gmail on a public terminal, and there’s a\nkeylogger on that public terminal, some remote third party now has your\nusername and password. If you log in to your bank—forget it. Remember,\nyou should enable 2FA on every site you access so an attacker armed with\nyour username and password cannot impersonate you. Two-factor\nauthentication will greatly mitigate the chances of your account being\nhacked if someone does gain knowledge of your username and password.\nThe number of people who use public kiosks at computer-based\nconferences such as CES and RSA amazes me. Bottom line, if you’re at a\ntrade show, use your cellular-enabled phone or tablet, your personal\nhotspot (see here), or wait until you get back to your room.\nIf you have to use the Internet away from your home or office, use your\nsmartphone. If you absolutely have to use a public terminal, then do not by\nany means sign in to any personal account, even Web mail. If you’re\nlooking for a restaurant, for example, access only those websites that do\nnot require authentication, such as Yelp. If you use a public terminal on a\nsemiregular basis, then set up an e-mail account to use only on public\nterminals, and only forward e-mail from your legitimate accounts to this\n“throwaway” address when you are on the road. Stop forwarding once you\nreturn home. This minimizes the information that is findable under that e-\nmail address.\nNext, make sure the sites you access from the public terminal have\nhttps in the URL. If you don’t see https (or if you do see it but suspect that\nsomeone has put it there to give you a false sense of security), then\nperhaps you should reconsider accessing sensitive information from this\npublic terminal.\nLet’s say you get a legitimate https URL. If you’re on a log-in page,\nlook for a box that says “Keep me logged in.” Uncheck that. The reason is\nclear: this is not your personal PC. It is shared by others. By keeping\nyourself logged in, you are creating a cookie on that machine. You don’t\nwant the next person at the terminal to see your e-mail or be able to send\ne-mail from your address, do you?\nAs noted, don’t log in to financial or medical sites from a public\nterminal. If you do log in to a site (whether Gmail or otherwise), make\nsure you log off when you are done and perhaps consider changing your\npassword from your own computer or mobile device afterward just to be\nsafe. You may not always log off from your accounts at home, but you\nmust always do this when using someone else’s computer.\nAfter you’ve sent your e-mail (or looked at whatever you wanted to\nlook at) and logged off, then try to erase the browser history so the next\nperson can’t see where you’ve been. Also delete any cookies if you can.\nAnd make sure you didn’t download personal files to the computer. If you\ndo, then try to delete the file or files from the desktop or downloads folder\nwhen you’re finished.\nUnfortunately, though, just deleting the file isn’t enough. Next you will\nneed to empty the trash. That still doesn’t fully remove the deleted stuff\nfrom the computer—I can retrieve the file after you leave if I want to.\nThankfully, most people don’t have the ability to do that, and usually\ndeleting and emptying the trash will suffice.\nAll these steps are necessary to be invisible on a public terminal."
  },
  {
    "input": "What are the various ways that digital and visual information shared online can be used to track or identify an individual's location, activities, or personal details, and how does this challenge the concept of privacy in the digital age?",
    "summary": "The text discusses how digital data, including photos and location information, can be used to track individuals and compromise privacy. It highlights cases like John McAfee, whose location was revealed through a photo's metadata, and the use of facial recognition to link people to their Social Security numbers. It also explains how social media platforms like Facebook and Twitter collect and share personal data, and how even seemingly anonymous activities can be tracked. Additionally, it covers how connected vehicles, such as Tesla and Jeep, can be hacked or monitored, raising concerns about the security and privacy of personal information in the digital age. The text emphasizes the need for better privacy controls and awareness of the data we share online and through our devices.",
    "output": "CHAPTER NINE\nYou Have No Privacy? Get Over It!\nAt some point during the\ntime that former antivirus software\ncreator John McAfee spent as a fugitive from authorities in Belize, he\nstarted a blog. Take it from me: if you’re trying to get off the grid and\ntotally disappear, you don’t want to start a blog. For one thing, you’re\nbound to make a mistake.\nMcAfee is a smart man. He made his fortune in the early days of\nSilicon Valley by pioneering antivirus research. Then he sold his company,\nsold all his assets in the United States, and for around four years, from\n2008 to 2012, he lived in Belize, on a private estate off the coast. Toward\nthe end of that period, the government of Belize had him under near-\nconstant surveillance, raiding his property and accusing him of assembling\na private army in addition to engaging in drug trafficking.\nMcAfee denied doing either. He claimed he was fighting the drug lords\non the island. He said, for example, that he had offered a flat-screen TV to\na small-time marijuana dealer on the condition that the man stop dealing.\nAnd he was known to pull over cars that he suspected were carrying drug\ndealers.1\nMcAfee in fact did have a drug lab, but not necessarily for recreational\ndrugs. He claimed he was creating a new generation of “helpful” drugs.\nHence his growing suspicion that cars full of white men outside his\nproperty were spies from pharmaceuticals companies such as\nGlaxoSmithKline. He further claimed that the raids by the local police\nwere instigated by these same pharmaceuticals companies.\nGuarding his property were several men with guns and eleven dogs. A\nneighbor two houses to the south, Greg Faull, complained regularly to the\nauthorities about the dogs barking late at night. Then one night in\nNovember of 2012, some of McAfee’s dogs were poisoned. And later that\nsame week, Faull was shot, found facedown in a pool of blood in his\nhouse.\nThe Belize authorities naturally considered McAfee a person of interest\nin their investigation. As McAfee relates in his blog, when he heard from\nhis housekeeper that the police wanted to talk to him, he went into hiding.\nHe became a fugitive.\nBut it wasn’t the blog that ultimately led law enforcement to McAfee.\nIt was a photo. And it wasn’t even his own.\nA security researcher named Mark Loveless (better known in security\ncircles as Simple Nomad) noticed a picture of McAfee published on\nTwitter by Vice magazine in early December of 2012. The photo showed\nVice’s editor standing next to McAfee in a tropical location—maybe in\nBelize, maybe somewhere else.\nLoveless knew that digital photos capture a lot of information about\nwhen, where, and how they are taken, and he wanted to see what digital\ninformation this photo might contain. Digital photos store what is known\nas exchangeable image file, or EXIF, data. This is photo metadata, and it\ncontains mundane details such as the amount of color saturation in the\nimage so that the photo can be accurately reproduced on a screen or by a\nprinter. It can also, if the camera is equipped to do so, include the exact\nlongitude and latitude of the place where the photo was taken.\nApparently the photo of McAfee with the Vice magazine editor was\ntaken with an iPhone 4S camera. Some cell phones ship with geolocation\nautomatically enabled. Loveless got lucky: the image posted in the online\nfile included the exact geolocation of John McAfee, who was, it turned\nout, in neighboring Guatemala.\nIn a subsequent blog McAfee said he faked the data, but that seems\nunlikely. Later he said he intended to reveal his location. More likely he\ngot lazy.\nLong story short, the Guatemalan police detained McAfee and wouldn’t\nlet him leave the country. He then suffered a health condition, was\nhospitalized, and was eventually allowed to return to the United States.\nThe murder of Greg Faull remains unsolved. McAfee now lives in\nTennessee, and in 2015 he decided to run for president to advocate for\nmore cyberfriendly policies in the US government. He doesn’t blog nearly\nas often nowadays.\nLet’s say you are an ambitious young jihadist, and you are proud to be\nposted to a recently established military headquarters of Daesh, or ISIL.\nWhat’s the first thing you do? You pull out your cell phone and take a\nselfie. Worse, in addition to the photo of you and your new digs, you post a\nfew words about the sophisticated equipment available at this particular\nfacility.\nHalf a world away, reconnaissance airmen at Florida’s Hurlburt Field\nare combing social media and see the photo. “We got an in,” one of them\nsays. Sure enough, a few hours later three JDAMs (joint direct attack\nmunitions) take out that shiny new military building.2 All because of a\nselfie.3\nWe don’t always consider what else lies inside the frame of a selfie\nwe’ve just taken. In film and theater this is called the mise-en-scène,\nroughly translated from the French as “what’s in the scene.” Your picture\nmight show a crowded city skyline, including the Freedom Tower, outside\nyour apartment window. Even a picture of you in a rural setting—maybe a\nprairie extending out to the flat horizon—gives me valuable information\nabout where you live. These visuals provide tiny location clues that might\ntip off someone who is eager to find you.\nIn the young jihadist’s case, what was in the scene was a military\nheadquarters.\nEmbedded in the metadata of the selfie were the precise longitude and\nlatitude, or geolocation, of the place where the photo was taken. General\nHawk Carlisle, the head of the US Air Combat Command, estimated it was\na mere twenty-four hours from the time that selfie was first posted on\nsocial media to the complete destruction of that headquarters.\nCertainly the metadata inside your image files can be used to locate\nyou. EXIF data in a digital image contains, among other things, the date\nand time when the picture was snapped, the make and model number of\nthe camera, and, if you have geolocation activated on the device taking the\nphoto, the longitude and latitude of the place where you took the image. It\nis this information, within the file, that the US military used to find the\nDaesh headquarters in the desert, just as Mark Loveless used EXIF data to\nidentify John McAfee’s location. Anyone can use this tool—it’s native in\nthe file inspector on Apple OSX and in downloadable tools such as FOCA\nfor Windows and Metagoofil for Linux—to gain access to the metadata\nstored in photos and documents.\nSometimes it’s not a photo but an app that gives up your spot. In the\nsummer of 2015, drug lord Joaquin “El Chapo” Guzman escaped from a\nMexican prison and immediately went off the grid. Or did he?\nTwo months after his escape—from Mexico’s maximum-security\nAltiplano prison—El Chapo’s twenty-nine-year-old son, Jesus Alfredo\nGuzman Salazar, posted an image to Twitter. Although the two men seated\nat a dinner table with Salazar are obscured by emoticons, the build of the\nman on the left bears a strong resemblance to El Chapo. Further, Salazar\ncaptioned the image: “August here, you already know with whom.” The\ntweet also contained the Twitter location data—Costa Rica—suggesting\nthat El Chapo’s son failed to switch off the autotagging function on\nTwitter’s smartphone app.4\nEven if you don’t have an escaped convict in your family, you need to\nbe aware that the digital and visual information hidden (sometimes in\nplain sight) in your photos can reveal a lot to someone who does not know\nyou and it can come back to haunt you.\nOnline photos can do more than just reveal your location. They can, in\nconjunction with certain software programs, reveal personal information\nabout you.\nIn 2011 Alessandro Acquisti, a researcher from Carnegie Mellon\nUniversity, posed a simple hypothesis: “I wanted to see if it was possible\nto go from a face on the street to a Social Security number,” he said. And\nhe found that it was indeed possible.5 By taking a simple webcam\nphotograph of a student volunteer, Acquisti and his team had enough\ninformation to obtain personal information about that individual.\nThink about that. You could take a photo of a person out on the street\nand, using facial recognition software, attempt to identify that person.\nWithout that person’s confirmation of his or her identity, you may get a\nfew false positives. But chances are a majority of the “hits” would reveal\none name more than another.\n“There’s a blending of online and offline data, and your face is the\nconduit—the veritable link between these two worlds,” Acquisti told\nThreatpost. “I think the lesson is a rather gloomy one. We have to face the\nreality that our very notion of privacy is being eroded. You’re no longer\nprivate in the street or in a crowd. The mashup of all these technologies\nchallenges our biological expectation of privacy.”\nFor his study, Acquisti and others stopped students on the Carnegie\nMellon campus and asked them to fill out an online survey. The webcam\non the laptop took a picture of each student as he or she was taking the\nsurvey, and the picture was immediately cross-referenced online using\nfacial recognition software. At the conclusion of each survey, several of\nthe retrieved photos had already appeared on the screen. Acquisti said that\n42 percent of the photos were positively identified and linked to the\nstudents’ Facebook profiles.\nIf you use Facebook, you are perhaps already aware of its limited facial\nrecognition technology. Upload a photo to the site, and Facebook will\nattempt to phototag the people within your network, people with whom\nyou are already friends. You do have some control over this. By going into\nyour Facebook settings you can require the site to notify you every time\nthat happens and choose whether to be identified in the photo. You can\nalso choose to post the photo to your wall or timeline only after you’ve\nbeen notified, if at all.\nTo make tagged photos invisible in Facebook, open your account and\ngo to “Privacy Settings.” There are various options, including limiting the\nimages to your personal timeline. Other than that, Facebook has not yet\nprovided an option to stop people from tagging you without permission.\nCompanies such as Google and Apple also have facial-recognition\ntechnology built into some of their applications, such as Google Photo and\niPhoto. It may be worth looking at the configuration settings for those\napps and services so that you can limit what facial recognition technology\ncan do in each. Google has so far held back from including facial\nrecognition technology in its image search feature (indicated by that little\ncamera icon you see in the Google search window). You can upload an\nexisting picture, and Google will find the picture, but it will not attempt to\nfind other photos showing the same person or people within the image.\nGoogle has, in various public statements, said that letting people identify\nstrangers by face “crosses the creepy line.”6\nEven so, some repressive governments have done just that. They have\ntaken photos of protesters at large antigovernment rallies and then put the\nimages on the Web. This is not using image recognition software so much\nas it is crowdsourcing the identification process. Also, some US states\nhave used their motor vehicle departments’ photo databases to identify\nsuspects in criminal cases. But those are fancy state-based operations.\nWhat could a lone academic do?\nAcquisti and his fellow researchers wanted to see how much image-\nderived information about a person could be cross-referenced online. To\nfind out they used a facial recognition technology called Pittsburgh Pattern\nRecognition, or PittPatt, now owned by Google. The algorithms used in\nPittPatt have been licensed to various security companies and government\ninstitutions. Shortly after the acquisition, Google went on record about its\nintentions: “As we’ve said for over a year, we won’t add face recognition\nto Google unless we can figure out a strong privacy model for it. We\nhaven’t figured it out.”7 Let’s hope the company sticks to its word.\nAt the time of his research, Acquisti was able to use PittPatt paired\nwith data-mined Facebook images from what he and his team considered\nto be searchable profiles, i.e., those on which the Carnegie Mellon\nvolunteers had already posted photos of themselves along with certain\npieces of personal information. They then applied this set of known faces\nto the “anonymous” faces on a popular online dating site. There the\nresearchers found that they could identify 15 percent of these supposedly\n“anonymous” digital heartbreakers.\nThe creepiest experiment, however, involved linking a person’s face to\nhis or her Social Security number. To do that, Acquisti and his team looked\nfor Facebook profiles that included the person’s date and city of birth.\nPreviously, in 2009, the same group of researchers had shown that this\ninformation by itself was enough to enable them to obtain a person’s\nSocial Security number (Social Security numbers are issued sequentially\nper a state’s own formula, and since 1989 SSNs have been issued on or\nvery near the date of birth, making it even easier to guess a person’s last\nfour digits).8\nAfter some initial calculations, the researchers then sent a follow-up\nsurvey to each of their CMU student volunteers asking whether the first\nfive digits of his or her Social Security number as predicted by their\nalgorithm was correct. And a majority of them were.9\nI’ll bet there are some photos that you now don’t want online. Chances are\nyou won’t be able to take them all back, even if you could delete them\nfrom your social media site. That’s in part because once you post\nsomething to a social network, it’s owned by that network and out of your\nhands. And you agreed to this in the terms of service.\nIf you use the popular Google Photos app, even deleting a photo there\ndoesn’t necessarily mean it’s gone. Customers have found that images are\nstill there even after they delete the app from their mobile devices. Why?\nBecause once the image hits the cloud, it is app-independent, meaning that\nother apps may have access to it and may continue to display the image\nyou deleted.10\nThis has real-world consequences. Say you posted some stupid caption\non a photo of someone who now works at the very company that you are\napplying to work for. Or you posted a photo of yourself with someone you\ndon’t want your current spouse to know about. Although it may be your\npersonal social network account, it is the social network’s data.\nYou’ve probably never taken the trouble to read the terms of use for\nany website where you post your personal data, daily experiences,\nthoughts, opinions, stories, gripes, complaints, and so on, or where you\nshop, play, learn, and interact, perhaps on a daily or even hourly basis.\nMost social networking sites require users to agree to terms and conditions\nbefore they use their services. Controversially, these terms often contain\nclauses permitting the sites to store data obtained from users and even\nshare it with third parties.\nFacebook has attracted attention over the years for its data storage\npolicies, including the fact that the site makes it difficult to delete an\naccount. And Facebook isn’t alone. Many websites have nearly identical\nlanguage in their terms of use that would very likely scare you away if you\nhad read the terms before signing on. Here’s one example, from Facebook,\nas of January 30, 2015:\nYou own all of the content and information you post on Facebook,\nand you can control how it is shared through your privacy and\napplication settings. In addition:\n1. For content that is covered by intellectual property rights, like\nphotos and videos (IP content), you specifically give us the\nfollowing permission, subject to your privacy and application\nsettings: you grant us a non-exclusive, transferable, sub-licensable,\nroyalty-free, worldwide license to use any IP content that you post\non or in connection with Facebook (IP License). This IP License\nends when you delete your IP content or your account unless your\ncontent has been shared with others, and they have not deleted it.11\nIn other words, the social media company has the right to use anything\nyou post to the site in any way it wants. It can even sell your picture, your\nopinions, your writing, or anything else you post, making money from\nyour contribution without paying you a penny. It can use your posted\ncomments, criticisms, opinions, libel, slander (if you’re into that sort of\nthing), and the most personal details you’ve posted about your children,\nyour boss, or your lover. And it doesn’t have to do it anonymously: if you\nhave used your real name, the site can use it, too.\nAll this means, among other things, that images you post to Facebook\ncan end up on other sites. To find out whether there are any embarrassing\nphotos of you out there in the world, you can perform what’s called a\nreverse image search in Google. To do this, click on the tiny camera within\nthe Google search window and upload any photo from your hard drive. In a\nfew minutes you will see any copies of that image findable online. In\ntheory, if it’s your photo, you should know all the sites that come up in the\nresults. However, if you find that someone has posted your photo on a site\nyou don’t like, you have limited options.\nReverse image searches are limited by what’s already posted. In other\nwords, if there is a similar image online but not the exact same image,\nGoogle won’t find it. It will find cropped versions of the image you\nsearched for, but in that case the central data, or enough of it, remains the\nsame.\nOnce, for my birthday, someone tried to create a stamp with my image\non it. The company, Stamps.com, has a strict policy against using images\nof convicted persons. My image was rejected. Perhaps they did an online\nimage search.\nI was in a database somewhere as Kevin Mitnick, convicted of a crime.\nThe following year my friend tried an earlier photo under a different\nname, one taken before I was well known. She reasoned that perhaps this\nphoto had not been uploaded online. And guess what? It worked. The\nsecond photo, showing a much younger me, was approved. This shows the\nlimitations of image searches.\nThat said, if you do find photos of yourself that you’d rather not see\nonline, you have a few options.\nFirst, contact the site. Most sites have an “abuse@nameofthesite.com”\ne-mail address. You might also contact the site’s webmaster at\n“admin@nameofthesite.com.” Explain that you own the image and don’t\ngive permission for it to be posted. Most webmasters will take down the\nimage without much fuss. However, if you need to you can file a Digital\nMillennium Copyright Act, or DMCA, request by e-mailing\n“DMCA@nameofthesite.com.”\nBe careful. Misrepresenting a DMCA request might get you into\ntrouble, so seek legal advice if it gets to this level. If you still can’t get the\nimage removed, then consider going upstream and contacting the website’s\nISP (whether it’s Comcast, GoDaddy, or another company). Most will take\na legitimate DMCA request seriously.\nBesides photos, what else is in your social media profile? You wouldn’t\nshare everything there is to know about you with the person sitting next to\nyou on the subway. In the same way, it’s not a good idea to share too much\npersonal information on impersonal websites. You never know who is\nlooking at your profile. And once it’s out there, you can’t take it back.\nThink carefully about what you put in your profile—you don’t have to fill\nin all the blanks, such as the university you attended (or even when you\nattended). In fact, fill in the least amount of information you possibly can.\nYou may also want to create a dedicated social media profile. Don’t lie,\njust be deliberately vague with the facts. For example, if you grew up in\nAtlanta, say you grew up in the “southeastern United States” or simply\n“I’m from the South.”\nYou may also want to create a “security” birthday—a day that is not\nyour real birthday—to mask personal information even further. Be sure to\nkeep track of your security birthdays, since they are sometimes used to\nverify your identity when you phone technical support or need to reenter a\nsite after you’ve been locked out.\nAfter creating or tweaking your online profiles, take a few minutes to\nlook at the privacy options on each site. For example, within Facebook you\nshould enable privacy controls, including tag review. Disable “Suggest\nphotos of me to friends.” Disable “Friends can check me into places.”\nKids with Facebook accounts are perhaps the most worrisome. They\ntend to fill in every blank box they can, even their relationship status. Or\nthey innocently reveal the names of the schools they attend and the\nteachers they have as well as the numbers of the buses they ride each\nmorning. While they don’t necessarily tell the world specifically where\nthey live, they might just as well. Parents need to friend their kids,\nmonitor what they post, and, ideally, discuss in advance what is acceptable\nand what is not.\nBeing invisible doesn’t mean you can’t share updates about your\npersonal life securely, but it involves both common sense and visiting and\nrevisiting the privacy settings of the social media sites you use—because\nprivacy policies do change, and sometimes not for the better. Do not\ndisplay your birthday, even your security birthday, or at the very least hide\nit from the Facebook “friends” you do not personally know.\nConsider a post that says Mrs. Sanchez is a great teacher. Another post\nmight be about a crafts fair at Alamo Elementary. From Google we can\nfind that Mrs. Sanchez teaches the fifth grade at Alamo Elementary—and\nfrom this we can assume the student account holder is around ten years\nold.\nDespite warnings from Consumer Reports and other organizations to\nthose who do post personal information, people continue to tell all online.\nRemember that it is perfectly legal for third parties to come along and to\ntake that information once it is out in public.12\nRemember also that no one is compelling you to post personal\ninformation. You can post as much or as little as you want. In some cases\nyou are required to fill in some information. Beyond that, you decide how\nmuch sharing is right for you. You need to determine your own personal\nprivacy level and understand that whatever information you provide\ncannot be taken back.\nTo help you get on top of all the choices you have, Facebook launched a\nnew privacy checkup tool in May of 2015.13 Despite tools like these,\nalmost thirteen million Facebook users back in 2012 told Consumer\nReports magazine that they had never set, or didn’t know about,\nFacebook’s privacy tools. And 28 percent shared all, or almost all, their\nwall posts with an audience wider than just their friends. More tellingly,\n25 percent of those interviewed by Consumer Reports said they falsified\ninformation in their profiles to protect their identity, and this figure was up\nfrom 10 percent in 2010.14 At least we’re learning.\nWhile you do have the right to post information about yourself that\nisn’t strictly accurate, be aware that in California it is illegal to post online\nas someone else. You cannot impersonate another living individual. And\nFacebook has a policy that will not allow you to create an account under a\nfalse name.\nThis actually happened to me. My account was suspended by Facebook\nbecause Facebook accused me of impersonating Kevin Mitnick. At the\ntime there were twelve Kevin Mitnicks on Facebook. The situation was\nfixed when CNET ran a story about the “real” Kevin Mitnick getting\nlocked out of Facebook.15\nThere are, however, many reasons why individuals might need to post\nunder a different name. If it is important to you, then find a social media\nservice that allows you to post anonymously or under a different name.\nSuch sites, however, will not match the breadth and reach of Facebook.\nBe careful whom you friend. If you have met the person face-to-face,\nfine. Or if the person is a friend of someone you know, maybe. But if you\nreceive an unsolicited request, think carefully. While you can unfriend that\nperson at any point, he or she will nonetheless have a chance to see your\nentire profile—and a few seconds is all it takes for someone with\nmalicious intent to interfere with your life. The best recommendation is to\nlimit all the personal information you share on Facebook, because there\nhave been very personal attacks, even among friends, over social\nnetworking websites. And data visible to your friends can still be reposted\nby them elsewhere without your consent or control.\nI’ll give you an example. A guy once wanted to hire me because he was\nthe victim of extortion. He had met an amazing, beautiful girl on Facebook\nand began sending her nude photos of himself. This continued for a time.\nThen one day he was told to send this woman—who might have been some\nguy living in Nigeria using a woman’s photo—$4,000. He did, but then\ncontacted me after he was asked to send another $4,000 or his nude photos\nwould be sent to all his friends, including his parents, on Facebook. He\nwas desperate to fix this situation. I told him his only real option was to\ntell his family or to wait and see if the extortionist went through with the\nthreat. I told him to stop paying the money—the extortionist wasn’t going\nto quit as long he continued to pay.\nEven legitimate social networks can be hacked: someone could friend\nyou just to get access to someone you know. A law enforcement officer\ncould be seeking information on a person of interest who happens to be\npart of your social network. It happens.\nAccording to the Electronic Frontier Foundation, social networks have\nbeen used for passive surveillance by federal investigators for years. In\n2011 the EFF released a thirty-eight-page training course for IRS\nemployees (obtained through the Freedom of Information Act) that the\nfoundation said was used for conducting investigations via social\nnetworks.16 Although federal agents can’t legally pretend to be someone\nelse, they can legally ask to be your friend. In doing so they can see all\nyour posts (depending on your privacy settings) as well as those of others\nin your network. The EFF continues to study the privacy issues associated\nwith this new form of law enforcement surveillance.\nSometimes corporations follow you, or at least monitor you, if you post or\ntweet something that they find objectionable—something as innocent as a\ncomment about a test you took in school, for example. For one student, a\ntweet like that caused a lot of trouble.\nWhen Elizabeth C. Jewett, the superintendent of the Watchung Hills\nRegional High School, in Warren, New Jersey, received a communication\nfrom the testing company that provided her school with a statewide exam,\nher reaction was surprise rather than concern. She was surprised that\nPearson Education was watching a student’s Twitter account in the first\nplace. Minors are given a certain amount of privacy and leeway when it\ncomes to what they post on social media. But students—whether they’re in\nmiddle school, high school, or college—need to realize that what they are\ndoing online is public and being watched. In this case one of Jewett’s\nstudents had allegedly tweeted material from a standardized test.\nIn fact the student had actually posted a question about a question—not\na picture of the exam page, just a few words—on a one-day statewide test\ngiven in New Jersey, the Partnership for Assessment of Readiness for\nCollege and Careers, or PARCC, test. The tweet was posted around 3:00\np.m.—well after students in the district had taken the test. After the\nsuperintendent spoke with a parent of the student who posted the tweet, the\nstudent removed it. There was no evidence of cheating. The tweet—not\nrevealed to the public—was a subjective comment rather than a\nsolicitation of an answer.\nBut the revelation about Pearson unnerved people. “The DOE\n[Department of Education] informed us that Pearson is monitoring all\nsocial media during PARCC testing,” Jewett wrote to her colleagues in an\ne-mail that a local columnist made public without her permission. In that\ne-mail Jewett confirmed that at least three more cases had been identified\nby Pearson and passed along to the state DOE.\nWhile Pearson is not alone in monitoring social media in order to\ndetect theft of intellectual property, its behavior does raise questions. How,\nfor example, did the company know the identity of the student involved\nfrom his Twitter handle? In a statement provided to the New York Times,\nPearson said: “A breach includes any time someone shares information\nabout a test outside of the classroom—from casual conversations to posts\non social media. Again, our goal is to ensure a fair test for all students.\nEvery student deserves his or her chance to take the test on a level playing\nfield.”17\nThe Times said it confirmed through officials in Massachusetts, which\nis also administering the PARCC test, that Pearson does cross-reference\ntweets about standardized tests with lists of students who have registered\nto take the tests. On this Pearson declined to comment for the Times.\nFor years the state of California also monitored social media during its\nannual Standardized Testing and Reporting (STAR) tests. In 2013, the last\nyear the tests were given statewide, the California Department of\nEducation identified 242 schools whose students posted on social media\nduring administration of the tests, only sixteen of which included postings\nof test questions or answers.18\n“The incident highlighted the degree to which students are under\nsurveillance, both within and outside of traditional school environments,”\nsaid Elana Zeide, a privacy research fellow at New York University’s\nInformation Law Institute. “Social media is generally seen as a separate\ndomain from school. Twitter seems more like ‘off campus’ speech—so\nthat Pearson’s monitoring is more like spying on students’ conversations\nin carpools than school hallways.”19\nHowever, she goes on to say, “The conversation also needs to shift from\nfocusing on individual interests and harms to take the broader\nconsequences of information practices into account. Schools and vendors\nneed to stop dismissing parents as Luddites simply because they can’t\narticulate a specific and immediate harm to their child. Parents, in turn,\nneed to understand that schools can’t defer to all their privacy preferences\nbecause there are also collective interests at stake that affect the entire\neducational system.”\nTwitter, with its iconic 140-character limit, has become pervasive,\ncollecting a lot of seemingly tiny details about our daily lives. Its privacy\npolicy acknowledges that it collects—and retains—personal information\nthrough its various websites, applications, SMS services, APIs\n(application programming interfaces), and other third parties. When\npeople use Twitter’s service, they consent to the collection, transfer,\nstorage, manipulation, disclosure, and other uses of this information. In\norder to create a Twitter account, one must provide a name, username,\npassword, and e-mail address. Your e-mail address cannot be used for\nmore than one Twitter account.\nAnother privacy issue on Twitter concerns leaked tweets—private\ntweets that have been made public. This occurs when friends of someone\nwith a private account retweet, or copy and paste, that person’s private\ntweet to a public account. Once public, it cannot be taken back.\nPersonal information can still be dangerous to share over Twitter,\nespecially if your tweets are public (the default). Avoid sharing addresses,\nphone numbers, credit card numbers, and Social Security numbers over\nTwitter.20 If you must share sensitive information, use the direct message\nfeature to contact a specific individual. But be aware that even private or\ndirect-message tweets can become public.\nFor today’s youth, so-called Generation Z, Facebook and Twitter are\nalready old. Generation Z’s actions on their mobile devices center around\nWhatsApp (ironically, now part of Facebook), Snapchat (not Facebook),\nand Instagram and Instagram Stories (also Facebook). All these apps are\nvisual in that they allow you to post photos and videos or primarily feature\nphotos or videos taken by others.\nInstagram, a photo-and video-sharing app, is Facebook for a younger\naudience. It allows follows, likes, and chats between members. Instagram\nhas terms of service and appears to be responsive to take-down requests by\nmembers and copyright holders.\nSnapchat, perhaps because it is not owned by Facebook, is perhaps the\ncreepiest of the bunch. Snapchat advertises that it allows you to send a\nself-destructing photo to someone. The life of the image is short, about\ntwo seconds, just long enough for the recipient to see the image.\nUnfortunately, two seconds is long enough for someone to grab a quick\nscreenshot that lasts.\nIn the winter of 2013, two underage high school girls in New Jersey\nsnapped photos of themselves, naked, and sent them to a boy at their\nschool over Snapchat, naturally assuming that the images would be\nautomatically deleted two seconds after they sent them. At least that’s\nwhat the company said would happen.\nHowever, the boy knew how to take a screenshot of the Snapchat\nmessage and later uploaded the images to his Instagram app. Instagram\ndoes not delete photos after two seconds. Needless to say the images of the\nnaked underage girls went viral, and the school superintendent had to send\na note home to the parents asking that the images be deleted from all\nstudents’ phones or they would risk being arrested on child pornography\ncharges. As for the three students, as minors they couldn’t be charged with\na crime, but each was subjected to disciplinary action within the school\ndistrict.21\nAnd it’s not just girls sending nude photos to boys. In the United\nKingdom, a fourteen-year-old boy sent a naked picture of himself to a girl\nat his school via Snapchat, again thinking the image would disappear after\na few seconds. The girl, however, took a screenshot and… you know the\nrest of the story. According to the BBC, the boy—and the girl—will be\nlisted in a UK database for sex crimes even though they are too young to\nbe prosecuted.22\nLike WhatsApp, with its inconsistent image-blurring capabilities,\nSnapchat, despite the app’s promises, does not really delete images. In fact\nSnapchat agreed in 2014 to a Federal Trade Commission settlement over\ncharges that the company had deceived users about the disappearing nature\nof its messages, which the federal agency alleged could be saved or\nretrieved at a later time.23 Snapchat’s privacy policy also says that it does\nnot ask for, track, or access any location-specific information from your\ndevice at any time, but the FTC found those claims to be false as well.24\nIt is a requirement of all online services that individuals be thirteen\nyears of age or older to subscribe. That is why these services ask for your\nbirth date. A user could, however, just say, under penalty of perjury, “I\nswear that I am over the age of thirteen”—or twenty-one or whatever.\nParents who find that their ten-year-olds have signed up for Snapchat or\nFacebook can report them and have those accounts removed. On the other\nhand, parents who want their kids to have an account often alter the child’s\nbirth date. That data becomes part of the child’s profile. Suddenly your\nten-year-old is fourteen, which means that he or she might be getting\nonline ads targeted at older children. Also note that every e-mail address\nand photo your child shares over the service is recorded.\nThe Snapchat app also transmits Wi-Fi-based and cellular-based\nlocation information from Android users’ mobile devices to its analytics\ntracking service provider. If you’re an iOS user and enter your phone\nnumber to find friends, Snapchat collects the names and phone numbers of\nall the contacts in your mobile device’s address book without your notice\nor consent, although iOS will prompt for permission the first time it is\nrequested. My recommendation is to try another app if you want true\nprivacy.\nIn North Carolina, a high school student and his girlfriend were\ncharged with possessing naked photos of minors even though the photos\nwere of themselves and had been taken and shared consensually. The\ngirlfriend faced two charges of sexual exploitation of a minor: one for\ntaking the photo and another for possessing it. Sexting aside, that means it\nis illegal for North Carolina teens to take or possess nude photos of\nthemselves. In the police warrant, the girlfriend is listed as both victim and\ncriminal.\nThe boyfriend faced five charges, two for each photo he took of himself\nplus one for possessing a photo of his girlfriend. If convicted he could face\nup to ten years in prison and have to register as a sex offender for the rest\nof his life. All for taking naked photos of himself and keeping one that his\ngirlfriend sent him.25\nWhen I was in high school, I simply met someone and asked her out.\nToday you have to put some information online so people can check you\nout first. But be careful.\nIf you are using a dating site and access it from someone else’s\ncomputer, or should you happen to use a public computer to access it,\nalways log out. Seriously. You don’t want someone to hit the Back button\non the browser and see your dating information. Or change it. Also,\nremember to uncheck the box that says “Remember me” on the log-in\nscreen. You don’t want this—or any other—computer to automatically log\nsomeone else in to your dating account.\nSay you go on a first date, maybe a second date. People don’t always\nreveal their true selves on a first or second date. Once your date has\nfriended you on Facebook or followed you on Twitter or on any other\nsocial network, he or she can see all your friends, your pictures, your\ninterests… things can get weird fast.\nWe’ve covered online services: what about mobile apps?\nDating apps can report your location, and part of that is by design. Say\nyou see someone you like in your area: you can then use the app to find\nout if that person is nearby. The mobile dating app Grindr gives very\nprecise location information for its subscribers… perhaps too precise.\nResearchers Colby Moore and Patrick Wardle from the cybersecurity\nfirm Synack were able to spoof requests to Grindr in order to follow some\nof the people in its service as they moved about a single city. They also\nfound that if they had three accounts search for one individual, they could\ntriangulate the results to get a much more precise measurement of where\nthat person was at any given moment.26\nMaybe dating apps aren’t your thing, but even logging in to the Yelp\nservice to search for a good restaurant gives third-party businesses\ninformation about your sex, age, and location. A default setting within the\napp allows it to send information back to the restaurant, telling it, for\nexample, that a woman, age thirty-one, from New York City was looking\nat its review. You can, however, go into your settings and choose “Basics,”\nwhich reveals only your city (unfortunately you cannot disable the feature\nentirely).27 Perhaps the best way to avoid this is to not log in and simply\nuse Yelp as a guest.\nRegarding geolocation, it is a good idea in general to check if any\nmobile apps you use broadcast your location. In most cases you can turn\nthis feature off, either in each individual app or entirely.28\nAnd before agreeing to download any Android app, always read the\npermissions first. You can view these permissions in Google Play by going\nto the app, then scrolling down to the section above Google Play content\nthat says “Permissions.” If the permissions make you feel uncomfortable,\nor if you think they give the app developer too much control, then do not\ndownload the app. Apple does not provide similar information about the\napps in its store, and instead permissions are prompted as they are needed\nwhen using the app. In fact, I prefer to use iOS devices because the\noperating system always prompts before disclosing private information—\nlike my location data. Also iOS is much more secure than Android if you\ndon’t jailbreak your iPhone or iPad. Of course, well-funded adversaries\ncould purchase exploits for any operating system in the marketplace, but\niOS exploits are quite expensive—costing over a million dollars.29\nCHAPTER TEN\nYou Can Run but Not Hide\nIf you carry your cell\nphone with you throughout the day, as most\nof us do, then you are not invisible. You are being surveilled—even if you\ndon’t have geolocation tracking enabled on your phone. For example, if\nyou have iOS 8.2 or earlier, Apple will turn off GPS in airplane mode, but\nif you have a newer version, as most of us do, GPS remains on—even if\nyou are in airplane mode—unless you take additional steps.1 To find out\nhow much his mobile carrier knew about his daily activity, a prominent\nGerman politician, Malte Spitz, filed suit against the carrier, and a\nGerman court ordered the company to turn over its records. The sheer\nvolume of those records was astounding. Just within a six-month period,\nthey had recorded his location 85,000 times while also tracking every call\nhe had made and received, the phone number of the other party, and how\nlong each call lasted. In other words, this was the metadata produced by\nSpitz’s phone. And it was not just for voice communication but for text\nmessages as well.2\nSpitz teamed up with other organizations, asking them to format the\ndata and make it public. One organization produced daily summaries like\nthe one below. The location of that morning’s Green Party meeting was\nascertained from the latitude and longitude given in the phone company\nrecords.\nMalte Spitz activity for October 12, 2009\nFrom this same data, another organization created an animated map. It\nshows Spitz’s minute-by-minute movements all around Germany and\ndisplays a flashing symbol every time he made or received a call. This is\nan amazing level of detail captured in just few ordinary days.3\nThe data on Spitz isn’t a special case, of course, nor is this situation\nconfined to Germany. It’s simply a striking example of the data that your\ncell-phone carrier keeps. And it can be used in a court of law.\nIn 2015, a case before the United States Court of Appeals for the Fourth\nCircuit involved the use of similar cell-phone records in the United States.\nThe case concerned two robbers who robbed a bank, a 7-Eleven, several\nfast-food restaurants, and a jewelry store in Baltimore. By having Sprint\nhand over information about the location of the prime suspects’ phones for\nthe previous 221 days, police were able to tie the suspects to a series of\ncrimes, both by the crimes’ proximity to each other and by the suspects’\nproximity to the crime scenes themselves.4\nA second case, heard by the United States District Court for the\nNorthern District of California, didn’t detail specifics of the crime, but it\nalso centered on “historical cell site information” available from Verizon\nand AT&T for the targets’ phones. In the words of the American Civil\nLiberties Union, which filed an amicus brief in the case, this data\n“generates a near-continuous record of an individual’s locations and\nmovements.” When a federal judge mentioned cell-phone privacy during\nthe California case, the federal prosecutor suggested that “cellphone users\nwho are concerned about their privacy could either not carry phones or\nturn them off,” according to the official record.\nThis would seem to violate our Fourth Amendment right to be\nprotected against unreasonable searches. Most people would never equate\nsimply carrying a cell phone with forfeiting their right not to be tracked by\nthe government—but that’s what carrying a phone amounts to these days.\nBoth cases note that Verizon, AT&T, and Sprint don’t tell customers in\nprivacy policies how pervasive location tracking is. Apparently AT&T, in a\nletter to Congress in 2011, said it stores cellular data for five years “in\ncase of billing disputes.”5\nAnd location data is not stored only with the carrier; it’s also stored\nwith the vendor. For example, your Google account will retain all your\nAndroid geolocation data. And if you use an iPhone, Apple will also have\na record of your data. To prevent someone from looking at this data on the\ndevice itself and to prevent it from being backed up to the cloud,\nperiodically you should delete location data from your smartphone. On\nAndroid devices, go to Google Settings>Location>Delete location history.\nOn an iOS device you need to drill down a bit; Apple doesn’t make it easy.\nGo to Settings>Privacy>Location Services, then scroll down to “System\nServices,” then scroll down to “Frequent Locations,” then “Clear Recent\nHistory.”\nIn the case of Google, unless you’ve turned the feature off, the\ngeolocation data available online can be used to reconstruct your\nmovements. For example, much of your day might be spent at a single\nlocation, but there might be a burst of travel as you meet with clients or\ngrab a bite to eat. More disturbing is that if anyone ever gains access to\nyour Google or Apple account, that person can perhaps also pinpoint\nwhere you live or who your friends are based on where you spend the\nmajority of your time. At the very least someone can figure out what your\ndaily routine might be.\nSo it’s clear that the simple act of going for a walk today is fraught with\nopportunities for others to track your behavior. Knowing this, say you\nconsciously leave your cell phone at home. That should solve the problem\nof being tracked, right? Well, that depends.\nDo you wear a fitness-tracking device such as Fitbit, Jawbone’s UP\nbracelet, or the Nike+ FuelBand? If not, maybe you wear a smartwatch\nfrom Apple, Sony, or Samsung. If you wear one or both of these—a fitness\nband and/or a smartwatch—you can still be tracked. These devices and\ntheir accompanying apps are designed to record your activity, often with\nGPS information, so whether it is broadcast live or uploaded later, you can\nstill be tracked.\nThe word sousveillance, coined by privacy advocate Steve Mann, is a\nplay off the word surveillance. The French word for “above” is sur; the\nFrench word for “below” is sous. So sousveillance means that instead of\nbeing watched from above—by other people or by security cameras, for\nexample, we’re being watched from “below” by the small devices that we\ncarry around and maybe even wear on our bodies.\nFitness trackers and smartwatches record biometrics such as your heart\nrate, the number of steps you take, even your body temperature. Apple’s\napp store supports lots of independently created applications to track\nhealth and wellness on its phones and watches. Same with the Google Play\nstore. And—surprise!—these apps are set to radio home the data to the\ncompany, ostensibly just to collect it for future review by the owner but\nalso to share it, sometimes without your active consent.\nFor example, during the 2015 Amgen Tour of California, participants in\nthe bicycle race were able to identify who had passed them and later, while\nonline, direct-message them. That could get a little creepy when a stranger\nstarts talking to you about a particular move you made during a race, a\nmove you might not even remember making.\nA similar thing happened to me. On the freeway, driving from Los\nAngeles to Las Vegas, I had been cut off by a guy driving a BMW. Busy on\nhis cell phone, he suddenly switched lanes, swerving within inches of me,\nscaring the crap out of me. He almost wiped out the both of us.\nI grabbed my cell phone, called the DMV, and impersonated law\nenforcement. I got the DMV to run his plate, then they gave me his name,\naddress, and Social Security number. Then I called AirTouch Cellular,\nimpersonating an AirTouch employee, and had them do a search on his\nSocial Security number for any cellular accounts. That’s how I was able to\nget his cell number.\nHardly more than five minutes after the other driver had cut me off, I\ncalled the number and got him on the phone. I was still shaking, pissed and\nangry. I shouted, “Hey, you idiot, I’m the guy you cut off five minutes ago,\nwhen you almost killed us both. I’m from the DMV, and if you pull one\nmore stunt like that, we’re going to cancel your driver’s license!”\nHe must be wondering to this day how some guy on the freeway was\nable to get his cell-phone number. I’d like to think the call scared him into\nbecoming a more considerate driver. But you never know.\nWhat goes around comes around, however. At one point my AT&T\nmobile account was hacked by some script kiddies (a term for\nunsophisticated wannabe hackers) using social engineering. The hackers\ncalled an AT&T store in the Midwest and posed as an employee at another\nAT&T store. They persuaded the clerk to reset the e-mail address on my\nAT&T account so they could reset my online password and gain access to\nmy account details, including all my billing records!\nIn the case of the Amgen Tour of California, riders used the Strava\napp’s Flyby feature to share, by default, personal data with other Strava\nusers. In an interview in Forbes, Gareth Nettleton, director of international\nmarketing at Strava, said “Strava is fundamentally an open platform where\nathletes connect with a global community. However, the privacy of our\nathletes is very important to us, and we’ve taken measures to enable\nathletes to manage their privacy in simple ways.”6\nStrava does offer an enhanced privacy setting that allows you to control\nwho can see your heart rate. You can also create device privacy zones so\nothers can’t see where you live or where you work. At the Amgen Tour of\nCalifornia, customers could opt out of the Flyby feature so that their\nactivities were marked as “private” at the time of upload.\nOther fitness-tracking devices and services offer similar privacy\nprotections. You might think that since you don’t bike seriously and\nprobably won’t cut someone off while running on the footpath around your\noffice complex, you don’t need those protections. What could be the\nharm? But there are other activities you do perform, some in private, that\ncould still be shared over the app and online and therefore create privacy\nissues.\nBy itself, recording actions such as sleeping or walking up several\nflights of stairs, especially when done for a specific medical purpose, such\nas lowering your health insurance premiums, might not compromise your\nprivacy. However, when this data is combined with other data, a holistic\npicture of you starts to emerge. And it may reveal more information than\nyou’re comfortable with.\nOne wearer of a health-tracking device discovered upon reviewing his\nonline data that it showed a significant increase in his heart rate whenever\nhe was having sex.7 In fact, Fitbit as a company briefly reported sex as\npart of its online list of routinely logged activities. Although anonymous,\nthe data was nonetheless searchable by Google until it was publicly\ndisclosed and quickly removed by the company.8\nSome of you might think, “So what?” True: not very interesting by\nitself. But when heart rate data is combined with, say, geolocation data,\nthings could get dicey. Fusion reporter Kashmir Hill took the Fitbit data to\nits logical extreme, wondering, “What if insurance companies combined\nyour activity data with GPS location data to determine not just when you\nwere likely having sex, but where you were having sex? Could a health\ninsurance company identify a customer who was getting lucky in multiple\nlocations per week, and give that person a higher medical risk profile,\nbased on his or her alleged promiscuity?”9\nOn the flip side of that, Fitbit data has been successfully used in court\ncases to prove or disprove previously unverifiable claims. In one extreme\ncase, Fitbit data was used to show that a woman had lied about a rape.10\nTo the police, the woman—while visiting Lancaster, Pennsylvania—\nsaid she’d awakened around midnight with a stranger on top of her. She\nfurther claimed that she’d lost her Fitbit in the struggle for her release.\nWhen the police found the Fitbit and the woman gave them her consent to\naccess it, the device told a different story. Apparently the woman had been\nawake and walking around all night. According to a local TV station, the\nwoman was “charged with false reports to law enforcement, false alarms\nto public safety, and tampering with evidence for allegedly overturning\nfurniture and placing a knife at the scene to make it appear she had been\nraped by an intruder.”11\nOn the other hand, activity trackers can also be used to support\ndisability claims. A Canadian law firm used activity-tracker data to show\nthe severe consequences of a client’s work injury. The client had provided\nthe data company Vivametrica, which collects data from wearable devices\nand compares it to data about the activity and health of the general\npopulation, with Fitbit data showing a marked decrease in his activity.\n“Till now we’ve always had to rely on clinical interpretation,” Simon\nMuller, of McLeod Law, LLC, in Calgary, told Forbes. “Now we’re\nlooking at longer periods of time through the course of a day, and we have\nhard data.”12\nEven if you don’t have a fitness tracker, smartwatches, such as the\nGalaxy Gear, by Samsung, can compromise your privacy in similar ways.\nIf you receive quick-glance notifications, such as texts, e-mails, and phone\ncalls, on your wrist, others might be able to see those messages, too.\nThere’s been tremendous growth recently in the use of GoPro, a tiny\ncamera that you strap to your helmet or to the dashboard of your car so\nthat it can record a video of your movements. But what happens if you\nforget the password to your GoPro mobile app? An Israeli researcher\nborrowed his friend’s GoPro and the mobile app associated with it, but he\ndid not have the password. Like e-mail, the GoPro app allows you to reset\nthe password. However, the procedure—which has since been changed—\nwas flawed. GoPro sent a link to your e-mail as part of the password reset\nprocess, but this link actually led to a ZIP file that was to be downloaded\nand inserted onto the device’s SD card. When the researcher opened the\nZIP file he found a text file named “settings” that contained the user’s\nwireless credentials—including the SSID and password the GoPro would\nuse to access the Internet. The researcher discovered that if he changed the\nnumber in the link—8605145—to another number, say 8604144, he could\naccess other people’s GoPro configuration data, which included their\nwireless passwords.\nYou could argue that Eastman Kodak jump-started the discussion of\nprivacy in America—or at least made it interesting—in the late 1800s.\nUntil that point, photography was a serious, time-consuming, inconvenient\nart requiring specialized equipment (cameras, lights, darkrooms) and long\nstretches of immobility (while subjects posed in a studio). Then Kodak\ncame along and introduced a portable, relatively affordable camera. The\nfirst of its line sold for $25—around $100 today. Kodak subsequently\nintroduced the Brownie camera, which sold for a mere $1. Both these\ncameras were designed to be taken outside the home and office. They were\nthe mobile computers and mobile phones of their day.\nSuddenly people had to deal with the fact that someone on the beach or\nin a public park might have a camera, and that person might actually\ninclude you within the frame of a photo. You had to look nice. You had to\nact responsibly. “It was not only changing your attitude toward\nphotography, but toward the thing itself that you were photographing,”\nsays Brian Wallis, former chief curator at the International Center of\nPhotography. “So you had to stage a dinner, and stage a birthday party.”13\nI believe we actually do behave differently when we are being watched.\nMost of us are on our best behavior when we know there’s a camera on us,\nthough of course there will always be those who couldn’t care less.\nThe advent of photography also influenced how people felt about their\nprivacy. All of a sudden there could be a visual record of someone\nbehaving badly. Indeed, today we have dash cams and body cameras on our\nlaw enforcement officers so there will be a record of our behavior when\nwe’re confronted with the law. And today, with facial recognition\ntechnology, you can take a picture of someone and have it matched to his\nor her Facebook profile. Today we have selfies.\nBut in 1888, that kind of constant exposure was still a shocking and\ndisconcerting novelty. The Hartford Courant sounded an alarm: “The\nsedate citizen can’t indulge in any hilariousness without incurring the risk\nof being caught in the act and having his photograph passed around among\nhis Sunday-school children. And the young fellow who wishes to spoon\nwith his best girl while sailing down the river must keep himself\nconstantly sheltered by his umbrella.”14\nSome people didn’t like the change. In the 1880s, in the United States,\na group of women smashed a camera on board a train because they didn’t\nwant its owner to take their picture. In the UK, a group of British boys\nganged together to roam the beaches, threatening anyone who tried to take\npictures of women coming out of the ocean after a swim.\nWriting in the 1890s, Samuel Warren and Louis Brandeis—the latter of\nwhom subsequently served on the Supreme Court—wrote in an article that\n“instantaneous photographs and newspaper enterprise have invaded the\nsacred precincts of private and domestic life.” They proposed that US law\nshould formally recognize privacy and, in part to stem the tide of\nsurreptitious photography, impose liability for any intrusions.15 Such laws\nwere passed in several states.\nToday several generations have grown up with the threat of\ninstantaneous photographs—Polaroid, anyone? But now we have to also\ncontend with the ubiquity of photography. Everywhere you go you are\nbound to be captured on video—whether or not you give your permission.\nAnd those images might be accessible to anyone, anywhere in the world.\nWe live with a contradiction when it comes to privacy. On the one hand\nwe value it intensely, regard it as a right, and see it as bound up in our\nfreedom and independence: shouldn’t anything we do on our own property,\nbehind closed doors, remain private? On the other hand, humans are\ncurious creatures. And we now have the means to fulfill that curiosity in\npreviously unimaginable ways.\nEver wonder what’s over that fence across the street, in your neighbor’s\nbackyard? Technology may be able to answer that question for almost\nanyone. Drone companies such as 3D Robotics and CyPhy make it easy\ntoday for the average Joe to own his own drone (for example, I have the\nDJI Phantom 4 drone). Drones are remote-controlled aircraft and\nsignificantly more sophisticated than the kind you used to be able to buy at\nRadio Shack. Almost all come with tiny video cameras. They give you the\nchance to see the world in a new way. Some drones can also be controlled\nfrom your cell phone.\nPersonal drones are Peeping Toms on steroids. Almost nothing is out of\nbounds now that you can hover a few hundred feet above the ground.\nCurrently the insurance industry uses drones for business reasons.\nThink about that. If you are an insurance adjuster and need to get a sense\nof the condition of a property you are about to insure, you can fly a drone\naround it, both to visually inspect areas you didn’t have access to before\nand to create a permanent record of what you find. You can fly high and\nlook down to get the type of view that previously you could only have\ngotten from a helicopter.\nThe personal drone is now an option for spying on our neighbors; we\ncan just fly high over someone’s roof and look down. Perhaps the neighbor\nhas a pool. Perhaps the neighbor likes to bathe in the nude. Things have\ngotten complicated: we have the expectation of privacy within our own\nhomes and on our own property, but now that’s being challenged. Google,\nfor example, masks out faces and license plates and other personal\ninformation on Google Street View and Google Earth. But a neighbor with\na private drone gives you none of those assurances—though you can try\nasking him nicely not to fly over your backyard. A video-equipped drone\ngives you Google Earth and Google Street View combined.\nThere are some regulations. The Federal Aviation Administration, for\ninstance, has guidelines stating that a drone cannot leave the operator’s\nline of sight, that it cannot fly within a certain distance of airports, and\nthat it cannot fly at heights exceeding certain levels.16 There’s an app\ncalled B4UFLY that will help you determine where to fly your drone.17\nAnd, in response to commercial drone use, several states have passed laws\nrestricting or severely limiting their use. In Texas, ordinary citizens can’t\nfly drones, although there are exceptions—including one for real estate\nagents. The most liberal attitude toward drones is perhaps found in\nColorado, where civilians can legally shoot drones out of the sky.\nAt a minimum the US government should require drone enthusiasts to\nregister their toys. In Los Angeles, where I live, someone crashed a drone\ninto power lines in West Hollywood, near the intersection of Larrabee\nStreet and Sunset Boulevard. Had the drone been registered, authorities\nmight know who inconvenienced seven hundred people for hours on end\nwhile dozens of power company employees worked into the night to\nrestore power to the area.\nRetail stores increasingly want to get to know their customers. One\nmethod that actually works is a kind of cell-phone IMSI catcher (see here).\nWhen you walk into a store, the IMSI catcher grabs information from your\ncell phone and somehow figures out your number. From there the system\nis able to query tons of databases and build a profile on you. Brick-and-\nmortar retailers are also using facial recognition technology. Think of it as\na supersize Walmart greeter.\n“Hello, Kevin,” could be the standard greeting I get from a clerk in the\nnot-too-distant future, even though I might never have been in that store\nbefore. The personalization of your retail experience is another, albeit very\nsubtle, form of surveillance. We can no longer shop anonymously.\nIn June of 2015, barely two weeks after leaning on Congress to pass the\nUSA Freedom Act—a modified version of the Patriot Act with some\nprivacy protection added—nine consumer privacy groups, some of which\nhad lobbied heavily in favor of the Freedom Act, grew frustrated with\nseveral large retailers and walked out of negotiations to restrict the use of\nfacial recognition.18\nAt issue was whether consumers should by default have to give\npermission before they can be scanned. That sounds reasonable, yet not\none of the major retail organizations involved in the negotiations would\ncede this point. According to them, if you walk into their stores, you\nshould be fair game for scanning and identification.19\nSome people may want that kind of personal attention when they walk\ninto a store, but many of us will find it just plain unsettling. The stores see\nit another way. They don’t want to give consumers the right to opt out\nbecause they’re trying to catch known shoplifters, who would simply opt\nout if that were an option. If automatic facial recognition is used, known\nshoplifters would be identified the moment they enter a store.\nWhat do the customers say? At least in the United Kingdom, seven out\nof ten survey respondents find the use of facial recognition technology\nwithin a store “too creepy.”20 And some US states, including Illinois, have\ntaken it upon themselves to regulate the collection and storage of\nbiometric data.21 These regulations have led to lawsuits. For example, a\nChicago man is suing Facebook because he did not give the online service\nexpress permission to use facial recognition technology to identify him in\nother people’s photos.22\nFacial recognition can be used to identify a person based solely on his\nor her image. But what if you already know who the person is and you just\nwant to make sure he’s where he should be? This is another potential use\nof facial recognition.\nMoshe Greenshpan is the CEO of the Israel-and Las Vegas–based\nfacial-recognition company Face-Six. Their software Churchix is used for\n—among other things—taking attendance at churches. The idea is to help\nchurches identify the congregants who attend irregularly so as to\nencourage them to come more often and to identify the congregants who\ndo regularly attend so as to encourage them to donate more money to the\nchurch.\nFace-Six says there are at least thirty churches around the world using\nits technology. All the church needs to do is upload high-quality photos of\nits congregants. The system will then be on the lookout for them at\nservices and social functions.\nWhen asked if the churches tell their congregants they are being\ntracked, Greenshpan told Fusion, “I don’t think churches tell people. We\nencourage them to do so but I don’t think they do.”23\nJonathan Zittrain, director of Harvard Law School’s Berkman Center\nfor Internet and Society, has facetiously suggested that humans need a\n“nofollow” tag like the ones used on certain websites.24 This would keep\npeople who want to opt out from showing up in facial recognition\ndatabases. Toward that end, the National Institute of Informatics, in Japan,\nhas created a commercial “privacy visor.” The eyeglasses, which sell for\naround $240, produce light visible only to cameras. The photosensitive\nlight is emitted around the eyes to thwart facial recognition systems.\nAccording to early testers, the glasses are successful 90 percent of the\ntime. The only caveat appears to be that they are not suitable for driving or\ncycling. They may not be all that fashionable, either, but they’re perfect\nfor exercising your right to privacy in a public place.25\nKnowing that your privacy can be compromised when you’re out in the\nopen, you might feel safer in the privacy of your car, your home, or even\nyour office. Unfortunately that is no longer the case. In the next few\nchapters I’ll explain why.\nCHAPTER ELEVEN\nHey, KITT, Don’t Share My Location\nResearchers Charlie Miller and Chris Valasek\nwere no\nstrangers to hacking cars. Previously the two had hacked a Toyota Prius—\nbut they had done so while physically connected to the car and sitting in\nthe backseat. Then, in the summer of 2015, Miller and Valasek succeeded\nin taking over the main controls of a Jeep Cherokee while it was traveling\nat seventy miles per hour down a freeway in St. Louis. They could\nremotely control a car without being anywhere near it.1\nThe Jeep in question did have a driver—Wired reporter Andy\nGreenberg. The researchers had told Greenberg beforehand: no matter\nwhat happens, don’t panic. That turned out to be a tall order, even for a\nguy who was expecting to have his car hacked.\n“Immediately my accelerator stopped working,” Greenberg wrote of\nthe experience. “As I frantically pressed the pedal and watched the RPMs\nclimb, the Jeep lost half its speed, then slowed to a crawl. This occurred\njust as I reached a long overpass, with no shoulder to offer an escape. The\nexperiment had ceased to be fun.”\nAfterward, the researchers faced some criticism for being “reckless”\nand “dangerous.” Greenberg’s Jeep was on a public road, not on a test\ntrack, so Missouri law enforcement is, at the time of this writing, still\nconsidering pressing charges against Miller and Valasek—and possibly\nGreenberg.\nHacking connected cars remotely has been talked about for years, but it\ntook Miller and Valasek’s experiment to get the automobile industry to pay\nattention. Whether it was “stunt hacking” or legitimate research, it got car\nmanufacturers to start thinking seriously about cybersafety—and about\nwhether Congress should prohibit the hacking of automobiles.2\nOther researchers have shown they can reverse engineer the protocol\ncontrolling your vehicle by intercepting and analyzing the GSM or CDMA\ntraffic from your car’s onboard computer to the automaker’s systems. The\nresearchers were able to spoof the automotive control systems by sending\nSMS messages to lock and unlock car doors. Some have even hijacked\nremote start capabilities using the same methods as well. But Miller and\nValasek were the first to be able to take complete control of a car\nremotely.3 And they claim that, by using the same methods, they could\ntake over cars in other states as well.\nPerhaps the most important result of the Miller-Valasek experiment\nwas a recall by Chrysler of more than 1.4 million of its cars because of a\nprogramming issue—the first recall of its kind. As an interim measure,\nChrysler also suspended the affected cars’ connection to the Sprint\nnetwork, which the cars had used for telematics, the data that cars collect\nand share with the manufacturer in real time. Miller and Valasek told an\naudience at DEF CON 23 that they had realized they could do that—take\nover cars in other states—but they knew it wasn’t ethical. Instead they\nconducted their controlled experiment with Greenberg in Miller’s\nhometown.\nIn this chapter I’ll discuss the various ways the cars we drive, the trains\nwe ride, and the mobile apps we use to power our daily commute to work\nare vulnerable to cyberattacks, not to mention the numerous privacy\ncompromises that our connected cars introduce into our lives.\nWhen Johana Bhuiyan, a reporter for BuzzFeed, arrived at the New York\noffices of Uber, the car-calling service, in one of Uber’s own cars, Josh\nMohrer, the general manager, was waiting. “There you are,” he said,\nholding up his iPhone. “I was tracking you.” It was not an auspicious start\nto their interview, which touched upon, among other things, consumer\nprivacy.4\nUntil Bhuiyan’s story appeared, in November of 2014, few outside of\nUber were even aware of God View, a tool with which Uber tracks the\nlocation of its thousands of contract drivers as well as their customers, all\nin real time.\nAs I mentioned earlier, apps routinely ask users for various\npermissions, including the right to access their geolocation data. The Uber\napp goes even further: it asks for your approximate (Wi-Fi) and precise\n(GPS) location, the right to access your contacts, and does not allow your\nmobile device to sleep (so it can keep tabs on where you are).\nBhuiyan allegedly told Mohrer up front that she did not give the\ncompany permission to track her anytime and anywhere. But she did,\nalthough maybe not explicitly. The permission was in the user agreement\nshe consented to upon downloading the service to her mobile device. After\ntheir meeting, Mohrer e-mailed Bhuiyan logs of some of her recent Uber\ntrips.\nUber compiles a personal dossier for every customer, recording every\nsingle trip he or she makes. That’s a bad idea if the database isn’t secure.\nKnown in the security business as a honeypot, the Uber database can\nattract all sorts of snoops, from the US government to Chinese hackers.5\nIn 2015, Uber changed some of its privacy policies—in some instances\nto the detriment of the consumer.6 Uber now collects geolocation data\nfrom all US-based users—even if the app runs only in the background and\neven if satellite and cellular communications are turned off. Uber said it\nwill use Wi-Fi and IP addresses to track the users “offline.” That means\nthe Uber app acts as a silent spy on your mobile device. The company did\nnot, however, say why it needs this ability.7\nNor has Uber fully explained why it needs God View. On the other\nhand, according to the company’s privacy policy: “Uber has a strict policy\nprohibiting all employees at every level from accessing a rider or driver’s\ndata. The only exception to this policy is for a limited set of legitimate\nbusiness purposes.” Legitimate business might include monitoring\naccounts suspected of fraud and resolving driver issues (for example,\nmissed connections). It probably doesn’t include tracking a reporter’s\ntravels.\nYou might think Uber would give its customers the right to delete\ntracking information. No. And if after reading this you’ve deleted the app\nfrom your phone, well, guess what? The data still exists within Uber.8\nUnder the revised privacy policy, Uber also collects your address book\ninformation. If you have an iPhone, you can go into your settings and\nchange your preference for contact sharing. If you own an Android, that’s\nnot an option.\nUber representatives have claimed that the company is not currently\ncollecting this kind of customer data. By including data collection in the\nprivacy policy, however, which existing users have already agreed to and\nwhich new users must agree to, the company ensures that it can roll out\nthese features at any time. And the user won’t have any redress.\nUber’s God View is perhaps enough to make you nostalgic for regular\nold taxicabs. In the past, you would jump into a taxi, state your\ndestination, and pay cash for the ride once you arrived. In other words,\nyour trip would be almost completely anonymous.\nWith the advent of nearly universal acceptance of credit cards in the\nearly twenty-first century, a lot of ordinary transactions have become\ntraceable, and so there probably is a record of your taxi ride somewhere—\nmaybe it doesn’t reside with a specific driver or company, but it certainly\nresides with your credit card company. Back in the 1990s I used to work as\na private investigator, and I could figure out my target’s movements by\nobtaining their credit card transactions. One need only look at a statement\nto know that last week you rode a taxi in New York City and paid $54 for\nthat trip.\nAround 2010 taxis began to use GPS data. Now the taxi company\nknows your pickup and drop-off location, the amount of your fare, and\nperhaps the credit card number associated with your trip. This data is kept\nprivate by New York, San Francisco, and other cities that support the open\ndata movement in government, providing researchers with rich—and\nanonymized—data sets. As long as names are not included, what harm\ncould there be in making such anonymized data public?\nIn 2013, Anthony Tockar, then a Northwestern University graduate\nstudent interning for a company called Neustar, looked at the anonymized\nmetadata publicly released by the New York City Taxi and Limousine\nCommission. This data set contained a record of every trip taken by the\ncars in its fleet during the previous year and included the cab number, the\npickup and drop-off times, the locations, the fare and tip amounts, and\nanonymized (hashed) versions of the taxis’ license and medallion\nnumbers.9 By itself, this data set isn’t very interesting. The hash value in\nthis case is unfortunately relatively easy to undo.10\nWhen you combine the public data set with other data sets, however,\nyou start to get a complete picture of what’s going on. In this case, Tockar\nwas able to determine where specific celebrities such as Bradley Cooper\nand Jessica Alba had taken their taxis within New York City during the\nprevious year. How did he make this leap?\nHe already had geolocation data, so he knew where and when the taxis\npicked up and dropped off their fares, but he had to go further to determine\nwho was inside the cab11. So he combined the New York City Taxi and\nLimousine Commission metadata with online photos from ordinary\ntabloid websites available online. A paparazzi database.\nThink about that. Paparazzi frequently photograph celebrities just as\nthey enter and exit New York City’s taxis. In these cases the cab’s unique\nmedallion number is often visible within the image. It’s printed on the side\nof every cab. So a cab number photographed alongside Bradley Cooper,\nfor instance, could be matched to the publicly available data regarding\npickup and drop-off locations and fare and tip amounts.\nFortunately, not all of us have paparazzi on our trail. That doesn’t mean\nthere aren’t other ways to trace our travels, though. Maybe you don’t take\ntaxis. Are there other ways to determine your location? There are. Even if\nyou take public transportation.\nIf you ride a bus, train, or ferry to work, you’re no longer invisible among\nthe masses. Transit systems are experimenting with using mobile apps and\nnear field communication (NFC) to tag riders as they get on and get off\npublic transportation. NFC is a short-distance radio signal that often\nrequires physical contact. Payment systems such as Apple Pay, Android\nPay, and Samsung Pay all use NFC to make fumbling for quarters a thing\nof the past.\nLet’s say you have an NFC-enabled phone with an app from your local\ntransit authority installed. The app will want a connection to your bank\naccount or credit card so that you can always board any bus or train or\nferry without worrying about a negative balance on your account. That\nconnection to your credit card number, if it is not obscured by a token, or\nplaceholder, number, could reveal to the transit authority who you are.\nReplacing your credit card number with a token is a new option that\nApple, Android, and Samsung offer. That way the merchant—in this case\nthe transit authority—only has a token and not your real credit card\nnumber. Using a token will cut down on data breaches affecting credit\ncards in the near future because the criminal would then need two\ndatabases: the token, and the real credit card number behind the token.\nBut say you don’t use an NFC-enabled phone. Instead you have a\ntransit card, like the CharlieCard in Boston, the SmarTrip card in\nWashington, DC, and the Clipper card in San Francisco. These cards use\ntokens to alert the receiving device—whether a turnstile or a fare-\ncollection box—that there is enough of a balance for you to ride the bus,\ntrain, or ferry. However, transit systems don’t use tokens on the back end.\nThe card itself has only an account number—not your credit card\ninformation—on its magnetic strip. But if the transit authority were to be\nbreached on the back end, then your credit card or bank information could\nalso be exposed. Also, some transit systems want you to register for their\ncards online so that they can send you e-mail, meaning your e-mail\naddresses could also be exposed in a future hack. Either way, the ability to\nanonymously ride a bus has largely gone out the window unless you pay\nfor the card using cash, not credit.12\nThis development is enormously helpful for law enforcement. Because\nthese commuter-card companies are privately owned third parties, not\ngovernments, they can set whatever rules they want about sharing data.\nThey can share it not only with law enforcement but also with lawyers\npursuing civil cases—in case your ex wants to harass you.\nSo someone looking at the transit authority logs might know exactly\nwho went through a subway station at such-and-such a time—but that\nperson might not know which train his target boarded, especially if the\nstation is a hub for several lines. What if your mobile device could resolve\nthe question of which train you then rode and therefore infer your\ndestination?\nResearchers at Nanjing University, in China, decided to answer that\nquestion by focusing their work on something inside our phones called an\naccelerometer. Every mobile device has one. It’s a tiny chip responsible\nfor determining the orientation of your device—whether you are holding it\nin landscape or portrait view. These chips are so sensitive that the\nresearchers decided to use accelerometer data alone in their calculations.\nAnd sure enough, they were able to accurately predict which subway train\na user is riding. This is because most subway lines include turns that affect\nthe accelerometer. Also important is the length of time between station\nstops—you need only to look at a map to see why. The accuracy of their\npredictions improved with each station a rider passed. The researchers\nclaim their method has a 92 percent accuracy rate.\nLet’s say you own an old-model car and drive yourself to work. You might\nthink you’re invisible—just one of a million cars on the road today. And\nyou might be right. But new technology—even if it is not part of the car\nitself—is eroding your anonymity. Chances are, with effort, someone\ncould still identify you whizzing by on the freeway pretty quickly.\nIn the city of San Francisco, the Municipal Transportation Agency has\nstarted to use the FasTrak toll system, which allows you to cross any of the\neight Bay Area bridges with ease, to track the movements of FasTrak-\nenabled cars throughout the city. Using technology similar to what toll\nbridges use to read the FasTrak (or E-ZPass) device in your car, the city\nhas started searching for those devices as users circle around looking for\nparking. But officials are not always interested in your movements: rather,\nthey’re interested in the parking spaces—most of which are equipped with\nelectronic parking meters. Spaces that are highly sought after can charge a\nhigher rate. The city can wirelessly adjust the price at specific meters—\nincluding meters near a popular event.\nIn addition, in 2014 officials decided not to use human toll takers at the\nGolden Gate Bridge, so everyone, even tourists, is required to pay\nelectronically or receive a bill in the mail. How do the authorities know\nwhere to send your bill? They photograph your license plate when you\ncross the toll plaza. These license-plate photographs are also used to nab\nred-light runners at problematic intersections. And increasingly, police are\nusing a similar strategy as they drive by parking lots and residential\ndriveways.\nPolice departments passively track your car’s movements every day\nwith automated license plate recognition (ALPR) technology. They can\nphotograph your car’s license plate and store that data, sometimes for\nyears, depending on the police department’s policy. ALPR cameras scan\nand read every plate they pass, whether the car is registered to a criminal\nor not.\nOstensibly ALPR technology is used primarily to locate stolen cars,\nwanted criminals, and assist with AMBER Alerts. The technology involves\nthree cameras mounted to the top of a patrol car that are hooked up to a\ncomputer screen inside the vehicle. The system is further linked to a\nDepartment of Justice database that keeps track of the license plates of\nstolen cars and vehicles associated with crimes. As an officer drives, the\nALPR technology can scan up to sixty plates per second. If a scanned plate\nmatches a plate in the DOJ database, the officer receives an alert both\nvisually and audibly.\nThe Wall Street Journal first reported on license plate recognition\ntechnology in 2012.13 At issue for those who oppose or question ALPR\ntechnology is not the system itself but rather how long the data is kept and\nwhy some law enforcement agencies will not release it, even to the owner\nof the car being tracked. It’s a disturbing tool that the police can use to\nfigure out where you’ve been.\n“Automatic license plate readers are a sophisticated way of tracking\ndrivers’ locations, and when their data is aggregated over time they can\npaint detailed pictures of people’s lives,” notes Bennett Stein of the\nACLU’s Project on Speech, Privacy, and Technology.14\nOne California man who filed a public records request was disturbed by\nthe number of photos (more than one hundred) that had been taken of his\nlicense plate. Most were at bridge crossings and other very public\nlocations. One, however, showed him and his daughters exiting their\nfamily car while it was parked in their own driveway. Mind you, this\nperson wasn’t under suspicion for committing a crime. Documents\nobtained by the ACLU show that even the office of the FBI’s general\ncounsel has questioned the use of ALPR in the absence of a coherent\ngovernment policy.15\nUnfortunately, you don’t have to file a public records request to see\nsome of the ALPR data. According to the EFF, the images from more than\na hundred ALPR cameras are available to anyone online. All you need is a\nbrowser. Before it went public with its findings, the EFF worked with law\nenforcement to correct the leakage of data. The EFF said this\nmisconfiguration was found in more than just those one hundred instances\nand urged law enforcement around the country to take down or limit\nwhat’s posted on the Internet. But as of this writing, it is still possible, if\nyou type the right query into a search window, to gain access to license\nplate images in many communities. One researcher found more than\n64,000 plate images and their corresponding locational data points during\na one-week period.16\nPerhaps you don’t own a car and only rent one occasionally. Still, you are\ndefinitely not invisible, given all the personal and credit card information\nyou must supply at the time of rental. What’s more, most rental cars today\nhave GPS built in. I know. I found out the hard way.\nWhen you are given a loaner car from a dealership because your car is\nbeing serviced, you typically agree not to take it across state lines. The\ndealership wants to keep the car in the state where it was borrowed. This\nrule mostly concerns their insurance, not yours.\nThis happened to me. I brought my car into a Lexus dealer in Las Vegas\nfor servicing, and they let me use a loaner car. Since it was past closing\ntime at the dealership, I just signed the paperwork without reading it,\nmostly because I was being rushed by the service associate. Later, I drove\nthe car to Northern California, to the Bay Area, for a consulting gig. When\nthe service guy called me to discuss his recommendations, he asked,\n“Where are you?” I said, “San Ramon, California.” He said, “Yeah, that’s\nwhere we see the car.” He then read me the riot act about taking the car out\nof state. Apparently the loaner agreement I had quickly signed stipulated\nthat I was not to take the car out of Nevada.\nWhen you rent or borrow a car today, there’s a temptation to pair your\nwireless device to the entertainment system, to re-create the audio\nexperience you have at home. Of course there are some immediate privacy\nconcerns. This isn’t your car. So what happens to your infotainment data\nonce you return the car to the rental agency?\nBefore you pair your device with a car that isn’t yours, take a look at\nthe entertainment system. Perhaps by tapping the mobile phone setting\nyou will see previous users’ devices and/or names listed on the Bluetooth\nscreen. Think about whether you want to join that list.\nIn other words, your data doesn’t just disappear when you leave the car.\nYou have to remove it yourself.\nYou might be thinking, “What harm is there in sharing my favorite\ntunes with others?” The problem is that your music isn’t the only thing\nthat gets shared. When most mobile devices connect to an automobile\ninfotainment system, they automatically link your contacts to the car’s\nsystem. The assumption is that you might want to make a hands-free call\nwhile driving, so having your contacts stored in the car makes it that much\neasier. Trouble is, it’s not your car.\n“When I get a rental car,” says David Miller, chief security officer for\nCovisint, “the last thing I do is pair my phone. It downloads all my\ncontacts because that’s what it wants to do. In most rental cars you can go\nin and—if somebody’s paired with it—see their contacts.”\nThe same is true when you finally sell your car. Modern cars give you\naccess to your digital world while on the road. Want to check Twitter?\nWant to post to Facebook? Cars today bear an increasing resemblance to\nyour traditional PC and your cell phone: they contain personal data that\nyou should remove before the machine or device is sold.\nWorking in the security business will get you in the habit of thinking\nahead, even about mundane transactions. “I spend all this time connecting\nmy vehicle to my whole life,” says Miller, “and then in five years I sell it\n—how do I disconnect it from my whole life? I don’t want the guy who\nbuys [my car] to be able to see my Facebook friends, so you have to de-\nprovision. Security guys are much more interested in the security\nvulnerabilities around de-provisioning than provisioning.”17\nAnd, just as you do with your mobile device, you will need to password\nprotect your car. Except at the time of this writing, there is no mechanism\navailable that will allow you to password lock your infotainment system.\nNor is it easy to delete all the accounts you’ve put into your car over the\nyears—how you do it varies by manufacturer, make, and model. Perhaps\nthat will change—someone could invent a one-stop button that removes an\nentire user profile from your car. Until then, at least go online and change\nall your social media passwords after you sell your car.\nPerhaps the best example of a computer on wheels is a Tesla, a state-of-\nthe-art all-electronic vehicle. In June of 2015, Tesla reached a significant\nmilestone: collectively, Tesla cars worldwide had been driven more than\none billion miles.18\nI drive a Tesla. They’re great cars, but given their sophisticated\ndashboards and constant cellular communication, they raise questions\nabout the data they collect.\nWhen you take possession of a Tesla you are offered a consent form.\nYou have the ability to control whether Tesla will record any information\nabout your car over a wireless communication system. You can enable or\ndisable sharing your personal data with Tesla via a touch screen on the\ndashboard. Many people accept the argument that their data will help Tesla\nmake a better car in the future.\nAccording to Tesla’s privacy policy, the company may collect the\nvehicle identification number, speed information, odometer readings,\nbattery usage information, battery charging history, information about\nelectrical system functions, software version information, infotainment\nsystem data, and safety-related data (including information regarding the\nvehicle’s SRS systems, brakes, security, and e-brake system), among other\nthings, to assist in analyzing the performance of the vehicle. Tesla states\nthat they may collect such information in person (e.g., during a service\nappointment) or via remote access.\nThat’s what they say in their printed policy.\nIn practice, they can also determine your car’s location and status at\nany time. To the media, Tesla has been cagey about what data it collects in\nreal time and how it uses that data. Like Uber, Tesla sits in a God-like\nposition that allows it to know everything about each car and its location\nat any moment.\nIf that unnerves you, you can contact Tesla and opt out of its telematics\nprogram. However, if you do, you will miss out on automatic software\nupdates, which include security fixes and new features.\nOf course the security community is interested in the Tesla, and\nindependent security researcher Nitesh Dhanjani has identified some\nproblems. While he agrees with me that the Tesla Model S is a great car\nand a fantastic product of innovation, Dhanjani found that Tesla uses a\nrather weak one-factor authentication system to access the car’s systems\nremotely.19 The Tesla website and app lack the ability to limit the number\nof log-in attempts on a user account, which means an attacker could\npotentially use brute force to crack a user’s password. That means a third\nparty could (assuming your password is cracked) log in and use the Tesla\nAPI to check the location of your vehicle. That person could also log in\nremotely to the Tesla app and control the vehicle’s systems—its air\nconditioner, lights, and so on, although the vehicle must be stationary.\nMost of Dhanjani’s concerns have been addressed by Tesla at the time\nof this writing, but the situation is an example of how much more auto\nmanufacturers need to do today to secure their cars. Just offering an app to\nremotely start and check the status of your car isn’t good enough. It also\nhas to be secure. The most recent update, a feature called Summon, allows\nyou to tell the car to pull itself out of the garage or park itself in a tight\nspot. In the future, Summon will allow the car to pick you up from any\nlocation across the country. Kinda like the old TV show Knight Rider.\nIn refuting a negative review in the New York Times, Tesla admitted to\nthe power of data they have on their side. Times reporter John Broder said\nthat his Tesla Model S had broken down and left him stranded. In a blog,\nTesla countered, identifying several data points they said called into\nquestion Broder’s version of the story. For example, Tesla noted that\nBroder drove at speeds ranging from sixty-five miles per hour to eighty-\none miles per hour, with an average cabin temperature setting of seventy-\ntwo degrees Fahrenheit.20 According to Forbes, “data recorders in the\nModel S knew the temperature settings in the car, the battery level\nthroughout the trip, the car’s speed from minute to minute, and the exact\nroute taken—down to the fact that the car reviewer drove circles in a\nparking lot when the car’s battery was almost dead.”21\nTelematics capability is a logical extension of the black boxes\nmandatory in all cars produced for sale in the United States after 2015. But\nblack boxes in cars aren’t new at all. They date back to the 1970s, when air\nbags were first introduced. In collisions, people back then sustained life-\nthreatening injuries from air bags, and some died from the force of the\nbags hitting their bodies. In some cases, had the car not been equipped\nwith those bags, the occupants might be alive today. In order to make\nimprovements, engineers needed the data on the deployment of the bags in\nthe moments before and after a crash, collected by the air bags’ sensing\nand diagnostic modules (SDMs). However, the vehicle owners were not\ntold until very recently that the sensors in their cars recorded data about\ntheir driving.\nTriggered by sudden changes in g-forces, black boxes in cars, like\nblack boxes in airplanes, record only the last few seconds or so\nsurrounding a g-force event, such as sudden acceleration, torque, and hard\nbraking.\nBut it is easy to envision more kinds of data being collected in these\nblack boxes and transmitted in real time via cellular connections. Imagine,\nin the future, that data collected over a three-to-five-day period could be\nstored either on the vehicle or in the cloud. Instead of trying to describe\nthat ping-ping noise you hear when your car travels thirty-five miles per\nhour or more, you’d just give your mechanic access to the recorded data.\nThe real question is, who else has access to all this data? Even Tesla\nadmits that the data it collects might be used by third parties.\nWhat if the third party was your bank? If it had an agreement with your\ncar’s manufacturer, it could track your driving ability and judge your\neligibility for future auto loans accordingly. Or your health insurer could\ndo the same. Or even your car insurer. It might be necessary for the federal\ngovernment to weigh in on who owns data from your car and what rights\nyou have to keep such data private.\nThere is little you can do about this today, but it’s worth paying\nattention to in the future.\nEven if you don’t own a Tesla, your auto manufacturer might offer an app\nthat allows you to open the car doors, start the engine, or even inspect\ncertain diagnostics on your car. One researcher has shown that these\nsignals—between the car, the cloud, and the app—can be hacked and used\nto track a target vehicle, effortlessly unlock it, trigger the horn and alarm,\nand even control its engine. The hacker can do just about everything\nexcept put the car in gear and drive it away. That still requires the driver’s\nkey. Although, I recently figured how to disable the Tesla key fob so that\nthe Tesla is completely grounded. By using a small transmitter at 315 MHz\nyou can make it so the key fob cannot be detected, thus disabling the car.\nSpeaking at DEF CON 23, Samy Kamkar, the security researcher best\nknown for developing the Myspace-specific Samy worm back in 2005,\ndemonstrated a device he built called OwnStar, which can impersonate a\nknown vehicle network. With it he could open your OnStar-enabled\nGeneral Motors vehicle, for example. The trick involves physically\nplacing the device on the bumper or underside of a target car or truck. The\ndevice spoofs the automobile’s wireless access point, which automatically\nassociates the unsuspecting driver’s mobile device with the new access\npoint (assuming the driver has previously associated with the original\naccess point). Whenever the user launches the OnStar mobile app, on\neither iOS or Android, the OwnStar code exploits a flaw in the app to steal\nthe driver’s OnStar credentials. “As soon as you’re on my network and you\nopen the app, I’ve taken over,” Kamkar said.22\nAfter obtaining the user’s log-in credentials for RemoteLink, the\nsoftware that powers OnStar, and listening for the locking or unlocking\nsound (beep-beep), an attacker can track down a car in a crowded parking\nlot, open it, and steal anything valuable inside. The attacker would then\nremove the device from the bumper. It’s a very neat attack, since there’s no\nsign of a forced intrusion. The owner and the insurance company are left\nto puzzle out what happened.\nResearchers have found that connected-car standards designed to\nimprove traffic flow can also be tracked. The vehicle-to-vehicle (V2V)\nand vehicle-to-infrastructure (V2I) communications, together known as\nV2X, call for cars to broadcast messages ten times a second, using a\nportion of the Wi-Fi spectrum at 5.9 gigahertz known as 802.11p.23\nUnfortunately this data is sent unencrypted—it has to be. When cars\nare speeding down a highway, the millisecond of delay needed to decrypt\nthe signal could result in a dangerous crash, so the designers have opted\nfor open, unencrypted communications. Knowing this, they insist that the\ncommunications contain no personal information, not even a license plate\nnumber. However, to prevent forgeries, the messages are digitally signed.\nIt’s these digital signatures, like the IMEI (mobile phone serial number)\ndata sent from our cell phones, that can be traced back to the registered\nowners of the vehicle.\nJonathan Petit, one of the researchers behind the study, told Wired,\n“The vehicle is saying ‘I’m Alice, this is my location, this is my speed and\nmy direction.’ Everyone around you can listen to that.… They can say,\n‘There’s Alice, she claimed she was at home, but she drove by the drug\nstore, went to a fertility clinic,’ this kind of thing… Someone can infer a\nlot of private information about the passenger.”24\nPetit has designed a system for around $1,000 that can listen for the\nV2X communications, and he suggests that a small town could be covered\nwith his sensors for about $1 million. Rather than having a large police\nforce, the town would use the sensors to identify drivers and, more\nimportant, their habits.\nOne proposal from the National Highway Traffic Safety Administration\nand European authorities is to have the 802.11p signal—the vehicle’s\n“pseudonym”—change every five minutes. That won’t, however, stop a\ndedicated attacker—he will just install more roadside sensors that will\nidentify the vehicle before and after it makes the change. In short, there\nappear to be very few options to avoid vehicle identification.\n“Pseudonym changing doesn’t stop tracking. It can only mitigate this\nattack,” says Petit. “But it’s still needed to improve privacy… We want to\ndemonstrate that in any deployment, you still have to have this protection,\nor someone will be able to track you.”\nCar connectivity to the Internet is actually good for vehicle owners:\nmanufacturers are able to push out software bug fixes instantly should\nthey be required. At the time of this writing, Volkswagen,25 Land Rover,26\nand Chrysler27 have experienced high-profile software vulnerabilities.\nHowever, only a few automakers, such as Mercedes, Tesla, and Ford, send\nover-the-air updates to all their cars. The rest of us still have to go into the\nshop to get our automobile software updated.\nIf you think the way Tesla and Uber are tracking every ride you take is\nscary, then self-driving cars will be even scarier. Like the personal\nsurveillance devices we keep in our pockets—our cell phones—self-\ndriving cars will need to keep track of where we want to go and perhaps\neven know where we are at a given moment in order to be always at the\nready. The scenario proposed by Google and others is that cities will no\nlonger need parking lots or garages—your car will drive around until it is\nneeded. Or perhaps cities will follow the on-demand model, in which\nprivate ownership is a thing of the past and everyone shares whatever car\nis nearby.\nJust as our cell phones are less like copper-wire phones than they are\nlike traditional PCs, self-driving cars will also be a new form of computer.\nThey’ll be self-contained computing devices, able to make split-second\nautonomous decisions while driving in case they are cut off from their\nnetwork communications. Using cellular connections, they will be able to\naccess a variety of cloud services, allowing them to receive real-time\ntraffic information, road construction updates, and weather reports from\nthe National Weather Service.\nThese updates are available on some conventional vehicles right now.\nBut it’s predicted that by 2025 a majority of the cars on the road will be\nconnected—to other cars, to roadside assistance services—and it’s likely\nthat a sizable percentage of these will be self-driving.28 Imagine what a\nsoftware bug in a self-driving car would look like.\nMeanwhile, every trip you take will be recorded somewhere. You will\nneed an app, much like the Uber app, that will be registered to you and to\nyour mobile device. That app will record your travels and, presumably, the\nexpenses associated with your trip if they would be charged to the credit\ncard on file, which could be subpoenaed, if not from Uber then from your\ncredit card company. And given that a private company will most likely\nhave a hand in designing the software that runs these self-driving cars, you\nwould be at the mercy of those companies and their decisions about\nwhether to share any or all of your personal information with law\nenforcement agencies.\nWelcome to the future.\nI hope that by the time you read this there will be tougher regulations—\nor at least the hint of tougher regulations in the near future—regarding the\nmanufacture of connected cars and their communications protocols.\nRather than use widely accepted software and hardware security practices\nthat are standard today, the auto industry, like the medical-device industry\nand others, is attempting to reinvent the wheel—as though we haven’t\nlearned much about network security over the last forty years. We have,\nand it would be best if these industries started following existing best\npractices instead of insisting that what they are doing is radically different\nfrom what’s been done before. It’s not. Unfortunately, failure to secure\ncode in a car has much greater consequences than a mere software crash,\nwith its blue screen of death. In a car, that failure could harm or kill a\nhuman being. At the time of this writing, at least one person has died\nwhile a Tesla was in beta autopilot mode—whether the result of faulty\nbrakes or an error in judgment by the car’s software remains to be\nresolved.29\nReading this, you may not want to leave your home. In the next\nchapter, I’ll discuss ways in which the gadgets in our homes are listening\nand recording what we do behind closed doors. In this case it’s not the\ngovernment that we need to be afraid of."
  },
  {
    "input": "What are the key security and privacy concerns associated with Internet of Things (IoT) devices and how can they be mitigated?",
    "summary": "The text discusses the increasing surveillance capabilities of Internet of Things (IoT) devices, highlighting vulnerabilities in smart thermostats, TVs, and home automation systems that can be exploited by hackers. It also covers how IoT devices can be used for remote access and data collection, which poses risks to personal privacy. Additionally, the text explores how corporate environments use tracking and monitoring technologies to surveil employees, and how sensitive data can be accessed through these systems. Finally, it delves into the challenges of maintaining anonymity while traveling, including the risks of electronic devices being searched at borders and the importance of encryption, secure backups, and using anonymous networks like Tor to protect personal information.",
    "output": "CHAPTER TWELVE\nThe Internet of Surveillance\nA few years ago nobody\ncared about the thermostat in your home.\nIt was a simple manually operated thermostat that kept your home at a\ncomfortable temperature. Then thermostats became programmable. And\nthen a company, Nest, decided that you should be able to control your\nprogrammable thermostat with an Internet-based app. You can sense where\nI’m going with this, right?\nIn one vengeful product review of the Honeywell Wi-Fi Smart\nTouchscreen Thermostat, someone who calls himself the General wrote on\nAmazon that his ex-wife took the house, the dog, and the 401(k), but he\nretained the password to the Honeywell thermostat. When the ex-wife and\nher boyfriend were out of town, the General claimed he would jack up the\ntemperature in the house and then lower it back down before they\nreturned: “I can only imagine what their electricity bills might be. It\nmakes me smile.”1\nResearchers at Black Hat USA 2014, a conference for people in the\ninformation security industry, revealed a few ways in which the firmware\nof a Nest thermostat could be compromised.2 It is important to note that\nmany of these compromises require physical access to the device, meaning\nthat someone would have to get inside your house and install a USB port\non the thermostat. Daniel Buentello, an independent security researcher,\none of four presenters who talked about hacking the device, said, “This is a\ncomputer that the user can’t put an antivirus on. Worse yet, there’s a secret\nback door that a bad person could use and stay there forever. It’s a literal\nfly on the wall.”3\nThe team of researchers showed a video in which they changed the Nest\nthermostat interface (they made it look like the HAL 9000 fishbowl\ncamera lens) and uploaded various other new features. Interestingly, they\nwere not able to turn off the automatic reporting feature within the device\n—so the team produced their own tool to do so.4 This tool would cut off\nthe stream of data flowing back to Google, the parent company of Nest.\nCommenting on the presentation, Zoz Cuccias of Nest later told\nVentureBeat, “All hardware devices—from laptops to smartphones—are\nsusceptible to jailbreaking; this is not a unique problem. This is a physical\njailbreak requiring physical access to the Nest Learning Thermostat. If\nsomeone managed to get in your home and had their choice, chances are\nthey would install their own devices, or take the jewelry. This jailbreak\ndoesn’t compromise the security of our servers or the connections to them\nand to the best of our knowledge, no devices have been accessed and\ncompromised remotely. Customer security is very important to us, and our\nhighest priority is on remote vulnerabilities. One of your best defenses is\nto buy a Dropcam Pro so you can monitor your home when you’re not\nthere.”5\nWith the advent of the Internet of Things, companies like Google are\neager to colonize parts of it—to own the platforms that other products will\nuse. In other words, these companies want devices developed by other\ncompanies to connect to their services and not someone else’s. Google\nowns both Dropcam and Nest, but they want other Internet of Things\ndevices, such as smart lightbulbs and baby monitors, to connect to your\nGoogle account as well. The advantage of this, at least to Google, is that\nthey get to collect more raw data about your personal habits (and this\napplies to any large company—Apple, Samsung, even Honeywell).\nIn talking about the Internet of Things, computer security expert Bruce\nSchneier concluded in an interview, “This is very much like the computer\nfield in the ’90s. No one’s paying any attention to security, no one’s doing\nupdates, no one knows anything—it’s all really, really bad and it’s going to\ncome crashing down.… There will be vulnerabilities, they’ll be exploited\nby bad guys, and there will be no way to patch them.”6\nTo prove that point, in the summer of 2013 journalist Kashmir Hill did\nsome investigative reporting and some DIY computer hacking. By using a\nGoogle search she found a simple phrase that allowed her to control some\nInsteon hub devices for the home. A hub is a central device that provides\naccess to a mobile app or to the Internet directly. Through the app, people\ncan control the lighting in their living rooms, lock the doors to their\nhouses, or adjust the temperature of their homes. Through the Internet, the\nowner can adjust these things while, say, on a business trip.\nAs Hill showed, an attacker could also use the Internet to remotely\ncontact the hub. As further proof, she reached out to Thomas Hatley, a\ncomplete stranger, in Oregon, and asked if she could use his home as a test\ncase.\nFrom her home in San Francisco, Hill was able to turn on and off the\nlights within Hatley’s home, some six hundred miles up the Pacific coast.\nShe also could have controlled his hot tubs, fans, televisions, water pumps,\ngarage doors, and video surveillance cameras if he had had those\nconnected.\nThe problem—now corrected—was that Insteon made all Hatley’s\ninformation available on Google. Worse, access to this information wasn’t\nprotected by a password at the time—anyone who stumbled upon this fact\ncould control any Insteon hub that could be found online. Hatley’s router\ndid have a password, but that could be bypassed by looking for the port\nused by Insteon, which is what Hill did.\n“Thomas Hatley’s home was one of eight that I was able to access,”\nHill wrote. “Sensitive information was revealed—not just what appliances\nand devices people had, but their time zone (along with the closest major\ncity to their home), IP addresses and even the name of a child; apparently,\nthe parents wanted the ability to pull the plug on his television from afar.\nIn at least three cases, there was enough information to link the homes on\nthe Internet to their locations in the real world. The names for most of the\nsystems were generic, but in one of those cases, it included a street address\nthat I was able to track down to a house in Connecticut.”7\nAround the same time, a similar problem was found by Nitesh\nDhanjani, a security researcher. Dhanjani was looking in particular at the\nPhilips Hue lighting system, which allows the owner to adjust the color\nand brightness of a lightbulb from a mobile device. The bulb has a range\nof sixteen million colors.\nDhanjani found that a simple script inserted onto a home computer on\nthe home network was enough to cause a distributed denial-of-service\nattack—or DDoS attack—on the lighting system.8 In other words, he could\nmake any room with a Hue lightbulb go dark at will. What he scripted was\na simple code so that when the user restarted the bulb, it would quickly go\nout again—and would keep going out as long as the code was present.\nDhanjani said that this could spell serious trouble for an office building\nor apartment building. The code would render all the lights inoperable, and\nthe people affected would call the local utility only to find there was no\npower outage in their area.\nWhile Internet-accessible home-automation devices can be the direct\ntargets of DDoS attacks, they can also be compromised and joined to a\nbotnet—an army of infected devices under one controller that can be used\nto launch DDoS attacks against other systems on the Internet. In October\n2016, a company called Dyn, which handles DNS infrastructure services\nfor major Internet brands like Twitter, Reddit, and Spotify, was hit hard by\none of these attacks. Millions of users on the eastern part of the United\nStates couldn’t access many major sites because their browsers couldn’t\nreach Dyn’s DNS services.\nThe culprit was a piece of malware called Mirai, a malicious program\nthat scours the Internet looking for insecure Internet of Things devices,\nsuch as CCTV cameras, routers, DVRs, and baby monitors, to hijack and\nleverage in further attacks. Mirai attempts to take over the device by\nsimple password guessing. If the attack is successful, the device is joined\nto a botnet where it lies in wait for instructions. Now with a simple one-\nline command, the botnet operator can instruct every device—hundreds of\nthousands or millions of them—to send data to a target site and flood it\nwith information, forcing it to go offline.\nWhile you cannot stop hackers from launching DDoS attacks against\nothers, you can become invisible to their botnets. The first item of\nbusiness when deploying an Internet of Things device is to change the\npassword to something hard to guess. If you already have a device\ndeployed, rebooting it should remove any existing malicious code.\nComputer scripts can affect other smart-home systems.\nIf you have a newborn in your home, you may also have a baby\nmonitor. This device, either a microphone or a camera or a combination of\nboth, allows parents to be out of the nursery but still keep track of their\nbaby. Unfortunately, these devices can invite others to observe the child as\nwell.\nAnalog baby monitors use retired wireless frequencies in the 43–50\nMHz range. These frequencies were first used for cordless phones in the\n1990s, and anyone with a cheap radio scanner could easily intercept\ncordless phone calls without the target ever knowing what happened.\nEven today, a hacker could use a spectrum analyzer to discover the\nfrequency that a particular analog baby monitor uses, then employ various\ndemodulation schemes to convert the electrical signal to audio. A police\nscanner from an electronics store would also suffice. There have been\nnumerous legal cases in which neighbors using the same brand of baby\nmonitor set to the same channel eavesdropped on one other. In 2009 Wes\nDenkov of Chicago sued the manufacturers of the Summer Infant Day &\nNight baby video monitor, claiming that his neighbor could hear private\nconversations held in his home.9\nAs a countermeasure, you might want to use a digital baby monitor.\nThese are still vulnerable to eavesdropping, but they have better security\nand more configuration options. For example, you can update the\nmonitor’s firmware (the software on the chip) immediately after purchase.\nAlso be sure to change the default username and password.\nHere again you might come up against a design choice that is out of\nyour control. Nitesh Dhanjani found that the Belkin WeMo wireless baby\nmonitor uses a token in an app that, once installed on your mobile device\nand used on your home network, remains active—from anywhere in the\nworld. Say you agree to babysit your newborn niece and your brother\ninvites you to download the Belkin app to your phone through his local\nhome network (with any luck, it is protected with a WPA2 password). Now\nyou have access to your brother’s baby monitor from across the country,\nfrom across the globe.\nDhanjani notes that this design flaw is present in many interconnected\nInternet of Things devices. Basically, these devices assume that everything\non the local network is trusted. If, as some believe, we’ll all have twenty\nor thirty such devices in our homes before long, the security model will\nhave to change. Since everything on the network is trusted, then a flaw in\nany one device—your baby monitor, your lightbulb, your thermostat—\ncould allow a remote attacker onto your smart home network and give him\nan opportunity to learn even more about your personal habits.\nLong before mobile apps, there were handheld remotes. Most of us are too\nyoung to remember the days before TVs had remote controls—the days\nwhen people had to physically get up off the couch and turn a dial to\nchange the channel. Or to pump up the volume. Today, from the comfort of\nour sofas, we can just instruct the TV with our words. That may be very\nconvenient, but it also means that the TV is listening—if only for the\ncommand to turn itself on.\nIn the early days, remote controls for TVs required direct line of sight\nand functioned by using light—specifically, infrared technology. A\nbattery-operated remote would emit a sequence of flashes of light barely\nvisible to the human eye but visible (again, within a line of sight) to a\nreceptor on the TV. How would the TV know if you wanted to turn it on\nwhen it was off? Simple: the infrared sensor located within the TV was\nalways on, on standby, waiting for a particular sequence of infrared light\npulses from the handheld remote to wake it up.\nRemote-control TVs evolved over the years to include wireless signals,\nwhich meant you didn’t have to stand directly in front of the TV; you\ncould be off to one side, sometimes even in another room. Again, the TV\nwas on in standby mode, waiting for the proper signal to wake it up.\nFast-forward to voice-activated TVs. These TVs do away with the\nremote you hold in your hand—which, if you’re like me, you can never\nfind when you want it anyway. Instead you say something silly like “TV\non” or “Hi, TV,” and the TV—magically—turns on.\nIn the spring of 2015 security researchers Ken Munro and David Lodge\nwanted to see whether voice-activated Samsung TVs were listening in on\nconversations in the room even when the TV was not in use. While they\nfound that digital TVs do in fact sit idle when they are turned off—which\nis reassuring—the TVs record everything spoken after you give them a\nsimple command, such as “Hi, TV” (that is, they record everything until\nthe TV is commanded to turn off again). How many of us will remember\nto keep absolutely quiet while the TV is on?\nWe won’t, and to make matters even more disturbing, what we say (and\nwhat is recorded) after the “Hi, TV” command is not encrypted. If I can\nget on your home network, I can eavesdrop on whatever conversation\nyou’re having in your home while the TV is turned on. The argument in\nfavor of keeping the TV in listening mode is that the device needs to hear\nany additional commands you might give it, such as “Volume up,”\n“Change the channel,” and “Mute the sound.” That might be okay, except\nthe captured voice commands go up to a satellite before they come back\ndown again. And because the entire string of data is not encrypted, I can\ncarry out a man-in-the-middle attack on your TV, inserting my own\ncommands to change your channel, pump up your volume, or simply turn\noff the TV whenever I want.\nLet’s think about that for a second. That means if you’re in a room with\na voice-activated TV, in the middle of a conversation with someone, and\nyou decide to turn on the TV, the stream of conversation that follows may\nbe recorded by your digital TV. Moreover, that recorded conversation\nabout the upcoming bake sale at the elementary school may be streamed\nback to a server somewhere far from your living room. In fact, Samsung\nstreams that data not only to itself but also to another company called\nNuance, a voice-recognition software company. That’s two companies that\nhave vital information about the upcoming bake sale.\nAnd let’s get real here: the average conversation you’re having in your\nTV room probably isn’t about a bake sale. Maybe you’re talking about\nsomething illegal, which law enforcement might want to know about. It is\nentirely likely that these companies would inform law enforcement, but if\nlaw enforcement, for example, were already interested in you, then\nofficers might get a warrant forcing these companies to provide complete\ntranscripts. “Sorry, but it was your smart TV that narc’d on you…”\nSamsung has, in its defense, stated that such eavesdropping scenarios\nare mentioned in the privacy agreement that all users implicitly agree to\nwhen they turn on the TV. But when was the last time you read a privacy\nagreement before turning on a device for the first time? Samsung says in\nthe near future all its TV communications will be encrypted.10 But as of\n2015, most models on the market are not protected.\nFortunately, there are ways to disable this HAL 9000–like feature on\nyour Samsung and presumably on other manufacturers’ TVs as well. On\nthe Samsung PN60F8500 and similar products, go into the Settings menu,\nselect “Smart Features,” and then under “Voice Recognition,” select “Off.”\nBut if you want to stop your TV from being able to record sensitive\nconversations in your home, you’ll have to sacrifice being able to walk\ninto a room and voice-command your TV to turn on. You can still, with\nremote in hand, select the microphone button and speak your commands.\nOr you could get up off the couch and switch the channels yourself. I\nknow. Life is hard.\nUnencrypted data streams are not unique to Samsung. While testing LG\nsmart TVs, a researcher found that data is being sent back to LG over the\nInternet every time the viewer changes the channel. The TV also has a\nsettings option called “Collection of watching info,” enabled by default.\nYour “watching info” includes the names of files stored on any USB drive\nyou connect to your LG television—say, one that contains photos from\nyour family vacation. Researchers carried out another experiment in which\nthey created a mock video file and loaded it to a USB drive, then plugged\nit into their TV. When they analyzed network traffic, they found that the\nvideo file name was transmitted unencrypted within http traffic and sent to\nthe address GB.smartshare.lgtvsdp.com.\nSensory, a company that makes embedded speech-recognition solutions\nfor smart products, thinks it can do even more. “We think the magic in\n[smart TVs] is to leave it always on and always listening,” says Todd\nMozer, CEO of Sensory. “Right now [listening] consumes too much power\nto do that. Samsung’s done a really intelligent thing and created a listening\nmode. We want to go beyond that and make it always on, always listening\nno matter where you are.”11\nNow that you know what your digital TV is capable of, you might be\nwondering: Can your cell phone eavesdrop when it’s turned off? There are\nthree camps. Yes, no, and it depends.\nThere are those in the privacy community who swear you have to take\nthe battery out of your turned-off smartphone to be sure that it is not\nlistening. There doesn’t seem to be a lot of evidence to support this; it’s\nmostly anecdotal. Then there are the people who swear that just turning off\nyour phone is good enough; case closed. But I think in reality there are\ninstances—say, if malware is added to a smartphone—when it doesn’t turn\noff entirely and could still record conversations held nearby. So it depends\non a variety of factors.\nThere are some phones that wake up when you say a magic phrase, just\nas voice-activated TVs do. This would imply that the phones are listening\nat all times, waiting for the magic phrase. This would also imply that what\nis said is somehow being recorded or transmitted. In some malware-\ninfected phones that is true: the phone’s camera or microphone is activated\nwhen there is not a call in progress. These cases, I think, are rare.\nBut back to the main question. There are some in the privacy\ncommunity who swear that you can activate a phone when it is turned off.\nThere is malware that can make the phone appear to be off when it is not.\nHowever, the possibility that someone could activate a turned-off phone\n(no battery power) strikes me as impossible. Basically any device that has\nbattery power that allows its software to be in a running state can be\nexploited. It’s not hard for a firmware back door to make the device appear\nthat it’s off when it isn’t. A device with no power can’t do anything. Or\ncan it? Some still argue that the NSA has put chips in our phones that\nprovide power and allow tracking even when the phone is physically\npowered off (even if the physical battery is pulled).\nWhether or not your phone is capable of listening, the browser you use\non it certainly is. Around 2013 Google started what’s called hotwording, a\nfeature that allows you to give a simple command that activates the\nlistening mode in Chrome. Others have followed suit, including Apple’s\nSiri, Microsoft’s Cortana, and Amazon’s Alexa. So your phone, your\ntraditional PC, and that stand-alone device on your coffee table all contain\nback-end, in-the-cloud services that are designed to respond to voice\ncommands such as “Siri, how far to the nearest gas station?” Which means\nthey listen. And if that doesn’t concern you, know that the searches\nconducted by these services are recorded and saved indefinitely.12\nIndefinitely.\nSo how much do these devices hear? Actually, it’s a little unclear what\nthey do when they are not answering questions or turning your TV on and\noff. For example, using the traditional PC version of the Chrome browser,\nresearchers found that someone—Google?—appeared to be listening all\nthe time by enabling the microphone. This feature came to Chrome from\nits open-source equivalent, a browser known as Chromium. In 2015,\nresearchers discovered that someone—Google?—appeared to be listening\nall the time. Upon further investigation, they discovered that this is\nbecause the browser turns the microphone on by default. Despite being\nincluded in open-source software, this code was not available for\ninspection.\nThere are several problems with this. First, “open source” means that\npeople should be able to look at the code, but in this case the code was a\nblack box, code that no one had vetted. Second, this code made its way to\nthe popular version of the browser via an automatic update from Google,\nwhich users weren’t given a chance to refuse. And as of 2015 Google has\nnot removed it. They did offer a means for people to opt out, but that opt-\nout requires coding skills so complicated that average users can’t do it on\ntheir own.13\nThere are other, more low-tech ways to mitigate this creepy\neavesdropping feature in Chrome and other programs. For the webcam,\nsimply put a piece of tape over it. For the microphone, one of the best\ndefenses is to put a dummy mic plug in the microphone socket of your\ntraditional PC. To do this, get an old, broken set of headphones or earbuds\nand simply cut the wire near the microphone jack. Now plug that stub of a\nmic jack into the socket. Your computer will think there’s a microphone\nthere when there isn’t. Of course if you want to make a call using Skype or\nsome other online service, then you will need to remove the plug first.\nAlso—and this is very important—make sure the two wires on the mic\nstub do not touch so that you don’t fry your microphone port.\nAnother connected device that lives in the home is the Amazon Echo,\nan Internet hub that allows users to order movies on demand and other\nproducts from Amazon just by speaking. The Echo is also always on, in\nstandby mode, listening to every word, waiting for the “wake word.”\nBecause Amazon Echo does more than a smart TV does, it requires first-\ntime users to speak up to twenty-five specific phrases into the device\nbefore they give it any commands. Amazon can tell you the weather\noutside, provide the latest sports scores, and order or reorder items from\nits collection if you ask it to. Given the generic nature of some of the\nphrases Amazon recognizes—for example, “Will it rain tomorrow?”—it\nstands to reason that your Echo might be listening more than your smart\nTV is.\nFortunately, Amazon provides ways to remove your voice data from\nEcho.14 If you want to delete everything (for example, if you plan to sell\nyour Echo to another party), then you need to go online to do that.15\nWhile all these voice-activated devices require a specific phrase to\nwake up, it remains unclear what each device is doing during downtime—\nthe time when no one is commanding it to do anything. When possible,\nturn off the voice activation feature in the configuration settings. You can\nalways turn it back on again when you need it.\nJoining the Amazon Echo in the Internet of Things, in addition to your TV\nand thermostat, is your refrigerator.\nRefrigerator?\nSamsung has announced a model of refrigerator that connects with your\nGoogle calendar to display upcoming events on a flat screen embedded in\nthe appliance’s door—kind of like that whiteboard you once had in its\nplace. Only now the refrigerator connects to the Internet through your\nGoogle account.\nSamsung did several things right in designing this smart fridge. They\nincluded an SSL/https connection so traffic between the refrigerator and\nthe Google Calendar server is encrypted. And they submitted their\nfuturistic refrigerator for testing at DEF CON 23—one of the most intense\nhacker conventions on earth.\nBut according to security researchers Ken Munro and David Lodge, the\nindividuals who hacked the digital TV communications, Samsung failed to\ncheck the certificate to communicate with Google servers and obtain\nGmail calender information. A certificate would validate that the\ncommunications between the refrigerator and the Google servers are\nsecure. But without it someone with malicious intent could come along\nand create his own certificate, allowing him to eavesdrop on the\nconnection between your refrigerator and Google.16\nSo what?\nWell, in this case, by being on your home network, someone could not\nonly gain access to your refrigerator and spoil your milk and eggs but also\ngain access to your Google account information by performing a man-in-\nthe-middle attack on the fridge calendar client and stealing your Google\nlog-in credentials—allowing him or her to read your Gmail and perhaps do\neven greater damage.\nSmart refrigerators are not the norm yet. But it stands to reason that as\nwe connect more devices to the Internet, and even to our home networks,\nthere will be lapses in security. Which is frightening, especially when the\nthing being compromised is something really precious and private, like\nyour home.\nInternet of Things companies are working on apps that will turn any\ndevice into a home security system. Your TV, for instance, might someday\ncontain a camera. In that scenario an app on a smartphone or tablet could\nallow you to view any room in your home or office from any remote\nlocation. Lights, too, can be turned on when there is motion inside or\noutside the house.\nIn one scenario, you might drive up to your house, and as you do so the\nalarm system app on your phone or in your car uses its built-in geolocation\ncapabilities to sense your arrival. When you’re fifty feet away, the app\nsignals the home alarm system to unlock the front or garage door (the app\non your phone has already connected to the house and authenticated). The\nalarm system further contacts the in-home lighting system, asking it to\nilluminate the porch, entryway, and maybe either the living room or\nkitchen. Additionally, you may want to enter your home while soft\nchamber music or the latest Top 40 tune from a service such as Spotify is\nplaying on the stereo. And of course the temperature of the house warms\nor cools, according to the season and your preferences, now that you are\nhome again.\nHome alarms became popular around the turn of the twenty-first\ncentury. Home alarm systems at that time required a technician to mount\nwired sensors in the doors and windows of the house. These wired sensors\nwere connected to a central hub that used a wired landline to send and\nreceive messages from the monitoring service. You would set the alarm,\nand if anyone compromised the secured doors and windows, the\nmonitoring service would contact you, usually by phone. A battery was\noften provided in case the power went out. Note that a landline usually\nnever loses power unless the wire to the house is cut.\nWhen a lot of people got rid of their copper-wire landlines and relied\nsolely upon their mobile communication services, the alarm monitoring\ncompanies began offering cellular-based connections. Lately they’ve\nswitched to Internet-based app services.\nThe alarm sensors on the doors and windows themselves are now\nwireless. There is certainly less drilling and stringing of ugly cable, but\nthere is also more risk. Researchers have repeatedly found that the signals\nfrom these wireless sensors are not encrypted. A would-be attacker need\nonly listen to the communications between devices in order to\ncompromise them. For example, if I can breach your local network, I can\neavesdrop on the communications between your alarm company servers\nand your in-home device (assuming it’s on the same local network and not\nencrypted), and by manipulating those communications I can start to\ncontrol your smart home, spoofing commands to control the system.\nCompanies are now providing “do-it-yourself” home monitoring\nservices. If any sensors are disturbed, your cell phone lights up with a text\nmessage informing you of the change. Or perhaps the app provides a\nwebcam image from inside the house. Either way, you are in control and\nare monitoring the house yourself. That’s great until your home Internet\ngoes out.\nEven when the Internet is working, the bad guys can still subvert or\nsuppress these do-it-yourself wireless alarm systems. For example, an\nattacker can trigger false alarms (which in some cities the homeowner has\nto pay for). Devices that create false alarms could be set off from the\nstreet in front of your house or up to 250 yards away. Too many false\nalarms could render the system unreliable (and the homeowner out of\npocket for a hefty fee).\nOr the attacker could jam the do-it-yourself wireless sensor signals by\nsending radio noise to prevent communication back to the main hub or\ncontrol panel. It suppresses the alarm and prevents it from sounding,\neffectively neutralizing the protection and allowing the criminal to walk\nright in.\nA lot people have installed webcams in their homes—whether for security,\nfor monitoring a cleaning person or nanny, or for keeping tabs on a\nhomebound senior or loved one with special needs. Unfortunately, a lot of\nthese over-the-Internet webcams are vulnerable to remote attacks.\nThere’s a publicly available Web search engine known as Shodan that\nexposes nontraditional devices configured to connect to the Internet.17\nShodan displays results not only from your Internet of Things devices at\nhome but also from internal municipal utilities networks and industrial\ncontrol systems that have been misconfigured to connect their servers to\nthe public network. It also displays data streams from countless\nmisconfigured commercial webcams all over the world. It has been\nestimated that on any given day there may be as many as one hundred\nthousand webcams with little or no security transmitting over the Internet.\nAmong these are Internet cameras without default authentication from\na company called D-Link, which can be used to spy on people in their\nprivate moments (depending on what these cameras are set to capture). An\nattacker can use Google filters to search for “D-Link Internet cameras.”\nThe attacker can then look for the models that default to no authentication,\nthen go to a website such as Shodan, click a link, and view the video\nstreams at his leisure.\nTo help prevent this, keep your Internet-accessible webcams turned off\nwhen they’re not in use. Physically disconnect them to be sure they’re off.\nWhen they are in use, make sure they have proper authentication and are\nset to a strong customized password, not the default one.\nIf you think your home is a privacy nightmare, wait until you see your\nworkplace. I’ll explain in the next chapter.\nCHAPTER THIRTEEN\nThings Your Boss Doesn’t Want You to Know\nIf you’ve read this far\n, you’re obviously concerned about privacy,\nbut for most of us it’s not a matter of hiding from the federal government.\nRather, we know that when we’re at work, our employers can see exactly\nwhat we’re doing online over their networks (e.g., shopping, playing\ngames, goofing off). A lot of us just want to cover our asses!\nAnd that’s getting harder to do, thanks in part to the cell phones we\ncarry. Whenever Jane Rodgers, finance manager of a Chicago landscaping\ncompany, wants to know whether her employees in the field are where they\nshould be, she pulls up their exact locations on her laptop. Like many\nmanagers and company owners, she is turning to tracking software on\ncorporate-owned, personally enabled (COPE) smartphones and service\ntrucks with GPS devices to surveil her employees. One day a customer\nasked Jane whether one of her landscapers had been out to perform a\nservice. After a few keystrokes, Jane verified that between 10:00 a.m. and\n10:30 a.m. one of her employees had been to the specified place.\nThe telematics service Rodgers uses provides capabilities beyond\ngeolocation. For example, on her nine company-owned phones she can\nalso view photos, text messages, and e-mails sent by her gardeners. She\nalso has access to their call logs and website visits. But Rodgers says she\nonly uses the GPS feature.1\nGPS tracking in the service industry has been available for a long time.\nIt, along with United Parcel Service’s own ORION system of algorithmic\nroute selection, has allowed the package delivery company to cut down on\ngas expenses by monitoring and suggesting optimized routes for its\ndrivers. The company was also able to crack down on lazy drivers. In these\nways, UPS has increased its volume by 1.4 million additional packages per\nday—with one thousand fewer drivers.2\nAll this is good for the employers, who argue that by squeezing out\nhigher margins they can in turn afford to pay better wages. But how do\nemployees feel? There is a downside to all this surveillance. In an\nanalysis, Harper’s magazine featured a profile of a driver who was\nelectronically monitored while at work. The driver, who did not give his\nname, said that the software timed his deliveries to the second and\ninformed him whenever he was under or over optimal time. At the end of a\ntypical day, the driver said he might be over by as much as four hours.\nSlacking off? The driver pointed out that a single stop might include\nmultiple packages—which the ORION software does not always account\nfor. The driver described coworkers in his New York distribution center\nwho were battling chronic pain in their lower backs and knees from trying\nto carry too much in a single trip—despite constant reminders from the\ncompany regarding proper handling of heavy loads—in order to keep up\nwith the software. So there’s one kind of human cost to this employee\nmonitoring.\nAnother place where work surveillance is used regularly is the food\nservice industry. From cameras in the ceilings of restaurants to kiosks at\nthe tabletop, wait staff can be watched and rated by various software\nsystems. A 2013 study by researchers from Washington University,\nBrigham Young University, and MIT found that theft-monitoring software\nused in 392 restaurants produced a 22 percent reduction in server-side\nfinancial theft after it was installed.3 As I mentioned, actively monitoring\npeople does change their behavior.\nThere are currently no federal statutes in the United States to prohibit\ncompanies from tracking their employees. Only Delaware and Connecticut\nrequire employers to tell employees when they are being tracked. In most\nstates, employees have no idea whether they are being watched at work.\nWhat about employees in the office? The American Management\nAssociation found that 66 percent of employers monitor the Internet use of\ntheir employees, 45 percent track employee keystrokes at the computer\n(noting idle time as potential “breaks”), and 43 percent monitor the\ncontents of employee e-mail.4 Some companies monitor employees’\nOutlook calendar entries, e-mail headers, and instant-messaging logs. The\ndata is ostensibly used to help companies figure out how their employees\nare spending their time—from how much time salespeople are spending\nwith customers to which divisions of the company are staying in touch by\ne-mail to how much time employees are spending in meetings or away\nfrom their desks.\nOf course there’s a positive spin: having such metrics means that the\ncompany can be more efficient in scheduling meetings or in encouraging\nteams to have more contact with each other. But the bottom line is that\nsomeone is collecting all this corporate data. And it could someday be\nturned over to law enforcement or at the very least used against you in a\nperformance review.\nYou are not invisible at work. Anything passing through a corporate\nnetwork belongs to the company—it is not yours. Even if you are checking\nyour personal e-mail account, your last order with Amazon, or planning a\nvacation, you are probably using a company-issued phone, laptop, or VPN,\nso expect to have someone monitoring everything you do.\nHere’s an easy way to keep your manager and even your coworkers\nfrom snooping: when you leave your desk to go to a meeting or the\nbathroom, lock your computer screen. Seriously. Don’t leave your e-mail,\nor details about the project you’ve spent weeks on, open—just sitting there\nfor someone to mess with. Lock your computer until you return to your\nscreen. It takes a few extra seconds, but it’ll spare you a lot of grief. Set a\ntimer in the operating system to lock the screen after a certain number of\nseconds. Or look into one of the Bluetooth apps that will automatically\nlock your screen if your mobile phone is not near the computer. That said,\nthere is a new attack that uses a weaponized USB device. A lot of offices\nseal the USB ports on their laptops and desktops, but if yours doesn’t a\nweaponized USB stick could still unlock your computer without a\npassword.5\nIn addition to corporate secrets, there’s also a fair amount of personal\ne-mail that passes through our computers during the workday, and\nsometimes we print it out for ourselves while in the office. If you are\nconcerned about privacy, don’t do anything personal while at work. Keep a\nstrict firewall between your work life and your home life. Or bring a\npersonal device such as a laptop or an iPad from home if you feel the need\nto do personal stuff while on break. And if your mobile device is cellular-\nenabled, never use the company Wi-Fi, and, further, turn off the SSID\nbroadcast if you are using a portable hotspot (see here). Only use cellular\ndata when conducting personal business at work.\nReally, once you arrive at your office, your public game face needs to\nbe on. Just as you wouldn’t talk about really personal things with your\ncasual office mates, you need to keep your personal business off the\ncompany computer systems (especially when you’re searching for health-\nrelated topics or looking for a new job).\nIt’s harder than it sounds. For one thing, we’re used to the ubiquity of\ninformation and the nearly universal availability of the Internet. But if you\nare going to master the art of invisibility, you have to prevent yourself\nfrom doing private things in public.\nAssume that everything you type into your office computer is public.\nThat doesn’t mean that your IT department is actively monitoring your\nparticular device or will ever act on the fact that you printed out your\nchild’s science fair project on the expensive color printer on the fifth floor\n—although they might. The point is, there’s a record that you did these\nthings, and should there be suspicion in the future, they can access the\nrecords of everything you did on that machine. It’s their machine, not\nyours. And it’s their network. That means they’re scanning the content that\nflows in and out of the company.\nConsider the case of Adam, who downloaded his free credit report on\nhis work computer. He logged in to the credit bureau’s site using the\ncompany computer over the company network. Let’s say you, like Adam,\nalso download your credit report at work. You want to print it out, right?\nSo why not send it to the company printer over in the corner? Because if\nyou do, there will be a copy of the PDF file containing your credit history\nsitting on the hard drive of the printer. You don’t control that printer. And\nafter the printer is retired and removed from the office, you don’t have\ncontrol over how that hard drive is disposed of. Some printers are now\nencrypting their drives, but can you be sure that the printer in your office\nis encrypted? You can’t.\nThat’s not all. Every Word or Excel document that you create using\nMicrosoft Office includes metadata that describes the document. Typically\ndocument metadata includes the author’s name, the date created, the\nnumber of revisions, and the file size as well as an option to add more\ndetails. This is not enabled by default by Microsoft; you have to go\nthrough some hoops to see it.6 Microsoft has, however, included a\nDocument Inspector that can remove these details before you export the\ndocument elsewhere.7\nA 2012 study sponsored by Xerox and McAfee found that 54 percent of\nemployees say they don’t always follow their company’s IT security\npolicies, and 51 percent of employees whose workplace has a printer,\ncopier, or multifunction printer say they’ve copied, scanned, or printed\nconfidential personal information at work. And it’s not just work: the same\ngoes for printers at the local copy shop and the local library. They all\ncontain hard drives that remember everything they’ve printed over their\nlifetimes. If you need something personal printed out, perhaps you should\nprint it out later at home, on a network and printer over which you have\ncontrol.\nSpying, even on employees, has gotten very creative. Some companies\nenlist nontraditional office devices that we might otherwise take for\ngranted, never imagining they could be used to spy on us. Consider the\nstory of a young Columbia University graduate student named Ang Cui.\nWondering if he could hack into a corporate office and steal sensitive data\nthrough nontraditional means, Cui decided first to attack laser printers, a\nstaple in most offices today.\nCui noticed that printers were way behind the times. During several pen\ntests, I have observed this as well. I have been able to leverage the printer\nto get further access into the corporate network. This is because workers\nrarely change the admin password on printers that are internally deployed.\nThe software and the firmware used in printers—especially\ncommercial printers for the home office—contain a lot of basic security\nflaws. The thing is, very few people see an office printer as vulnerable.\nThey think they’re enjoying what’s sometimes called “security by\nobscurity”—if no one notices the flaw, then you are safe.\nBut as I’ve said, printers and copy machines, depending on the model,\nhave one important thing in common—they both may contain hard drives.\nAnd unless that hard drive is encrypted—and many are still not—it is\npossible to access what has been printed at a later date. All this has been\nknown for years. What Cui wondered was if he could turn a company\nprinter against its owners and exfiltrate whatever was printed.\nTo make things more interesting, Cui wanted to attack the printer’s\nfirmware code, the programming embedded inside a chip within the\nprinter. Unlike our traditional PCs and mobile devices, digital TVs and\nother “smart” electronics do not have the power or the processing\nresources to run a full-blown operating system such as Android, Windows,\nand iOS. Instead these devices use what’s called real-time operating\nsystems (RTOS), which are stored on individual chips inside the device\n(frequently known as fireware). These chips store only the commands\nneeded to operate the system and not much else. Occasionally even these\nsimple commands need to be updated by the manufacturer or vendor by\nflashing or replacing the chips. Given that this is done so infrequently, it’s\nobvious that many manufacturers simply did not build in the proper\nsecurity measures. This, the lack of update, was the vector that Cui\ndecided to pursue for his attack.\nCui wanted to see what would happen if he hacked the file format HP\nused for its firmware updates, and he discovered that HP didn’t check the\nvalidity of each update. So he created printer firmware of his own—and\nthe printer accepted it. Just like that. There was no authentication on the\nprinter’s side that the update came from HP. The printer only cared that the\ncode was in the expected format.\nCui now was free to explore.\nIn one famous experiment, Cui reported that he could turn on the fuser\nbar, the part of the printer that heats the paper after the ink has been\napplied, and leave it on, which would cause the printer to catch fire. The\nvendor—not HP—immediately responded by arguing that there was a\nthermo fail-safe within the fuser bar, meaning the printer could not\noverheat. However, that was Cui’s point—he’d managed to turn that fail-\nsafe feature off so that the machine could actually catch fire.\nAs a result of these experiments, Cui and his adviser, Salvatore Stolfo,\nargued that printers were weak links in any organization or home. For\nexample, the HR department of a Fortune 500 company might receive a\nmaliciously-coded résumé file over the Internet. In the time it takes the\nhiring manager to print that document, the printer through which it travels\ncould be fully compromised by installing a malicious version of the\nfirmware.\nPreventing someone from grabbing your documents off the printer,\nsecure printing, also known as pull printing, ensures that documents are\nonly released upon a user’s authentication at the printer (usually a\npasscode must be entered before the document will print). This can be\ndone by using a PIN, smart card, or biometric fingerprint. Pull printing\nalso eliminates unclaimed documents, preventing sensitive information\nfrom lying around for everyone to see.8\nBuilding on his printer attacks, Cui began to look around the typical office\nfor other common objects that might be vulnerable and settled on Voice\nover Internet Protocol (VoIP) telephones. As with printers, no one had\nappreciated the hidden yet obvious-once-you-thought-about-it value of\nthese devices in collecting information. And as with a printer, an update to\nthe system can be faked and accepted by the VoIP phone.\nMost VoIP phones have a hands-free option that allows you to put\nsomeone on speakerphone in your cubicle or office. Which means there’s\nnot only a speaker but also a microphone on the outside of the handset.\nThere’s also an “off the hook” switch, which tells the phone when someone\nhas picked up the receiver and wants to make or listen to a call as well as\nwhen the receiver has been put back and the speakerphone is enabled. Cui\nrealized that if he could compromise the “off the hook” switch, he could\nmake the phone listen to conversations nearby via the speakerphone\nmicrophone—even when the receiver was on the hook!\nOne caveat: unlike a printer, which can receive malicious code via the\nInternet, VoIP phones need to be “updated” individually by hand. This\nrequires the code to be propagated using a USB drive. Not a problem, Cui\ndecided. For a price, a night janitor could install the code on each phone\nwith a USB stick as he or she cleaned the office.\nCui has presented this research at a number of conferences, each time\nusing different VoIP telephones. And each time the vendor was notified in\nadvance, and each time the vendor did produce a fix. But Cui has pointed\nout that just because a patch exists doesn’t mean it gets applied. Some of\nthe unpatched phones might still be sitting in offices, hotels, and hospitals\nright now.\nSo how did Cui get the data off the phone? Since office computer\nnetworks are monitored for unusual activity, he needed another means of\nextracting the data. He decided to go “off network” and use radio waves\ninstead.\nPreviously, researchers at Stanford University and in Israel found that\nhaving your mobile phone positioned next to your computer can allow a\nremote third party to eavesdrop on your conversations. The trick requires\nmalware to be inserted onto your mobile device. But with maliciously\ncoded apps available for download from rogue app stores, that’s easy\nenough, right?\nWith the malware installed on your mobile phone, the gyroscope within\nthe phone is now sensitive enough to pick up slight vibrations. The\nmalware in this case, researchers say, can also pick up minute air\nvibrations, including those produced by human speech. Google’s Android\noperating system allows movements from the sensors to be read at 200 Hz,\nor 200 cycles per second. Most human voices range from 80 to 250 Hz.\nThat means the sensor can pick up a significant portion of those voices.\nResearchers even built a custom speech-recognition program designed to\ninterpret the 80–250 Hz signals further.9\nCui found something similar within the VoIP phones and printers. He\nfound that the fine pins sticking out of just about any microchip within any\nembedded device today could be made to oscillate in unique sequences\nand therefore exfiltrate data over radio frequency (RF). This is what he\ncalls a funtenna, and it is a virtual playground for would-be attackers.\nOfficially, says security researcher Michael Ossmann, whom Cui credits\nfor the idea, “a funtenna is an antenna that was not intended by the\ndesigner of the system to be an antenna, particularly when used as an\nantenna by an attacker.”10\nAside from a funtenna, what are some other ways people can spy on\nwhat you do at work?\nResearchers in Israel have found that ordinary cell phones can—with\nmalware installed—be made to receive binary data from computers. And\npreviously, Stanford researchers found that mobile phone sensors could\nintercept the sound of electronic emissions from a wireless keyboard.11\nThis builds on similar research conducted by scientists at MIT and\nGeorgia Tech.12 Suffice it to say that everything you type or view or use in\nthe office can be listened to in one way or another by a remote third party.\nFor instance, say you use a wireless keyboard. The wireless radio signal\nsent from the keyboard to the laptop or desktop PC can be intercepted.\nSecurity researcher Samy Kamkar developed something called\nKeySweeper that’s designed to do just that: a disguised USB charger that\nwirelessly and passively looks for, decrypts, logs, and reports back (over\nGSM) all keystrokes from any Microsoft wireless keyboard in the\nvicinity.13\nWe’ve discussed the danger of using bogus hotspots at cafés and\nairports. The same can be true in offices. Someone in your office may set\nup a wireless hotspot, and your device might automatically connect to it.\nIT departments typically scan for such devices, but sometimes they don’t.\nA modern equivalent of bringing your own hotspot to the office is\nbringing your own cellular connection. Femtocells are small devices\navailable from your mobile carrier. They’re designed to boost cellular\nconnections within a home or office where the signal might be weak. They\nare not without privacy risks.\nFirst of all, because femtocells are base stations for cellular\ncommunications, your mobile device will often connect to them without\ninforming you. Think about that.\nIn the United States, law enforcement uses something called a\nStingRay, also known as an IMSI catcher, a cell-site simulator.\nAdditionally there are TriggerFish, Wolfpack, Gossamer, and swamp box.\nThough the technologies vary, these devices basically all act like a\nfemtocell without the cellular connection. They’re designed to collect the\ninternational mobile subscriber identity, or IMSI, from your cellular\nphone. Their use in the United States is significantly behind that of Europe\n—for now. IMSI catchers are used at large social protests, for example, to\nhelp law enforcement identify who was at the assembly. Presumably the\norganizers will be on their phones, coordinating events.\nAfter a protracted legal battle, the American Civil Liberties Union of\nNorthern California obtained documents from the government detailing\nhow it goes about using StingRay. For example, law enforcement agents\nare told to obtain a pen register or a trap-and-trace court order. Pen\nregisters have been used to obtain phone numbers, a record of digits dialed\non a phone. Trap-and-trace technology has been used to collect\ninformation about received calls. In addition, law enforcement can, with a\nwarrant, legally obtain the voice recording of a phone call or the text of an\ne-mail. According to Wired, the documents received by the ACLU state\nthat the devices “may be capable of intercepting the contents of\ncommunications and, therefore, such devices must be configured to\ndisable the interception function, unless interceptions have been\nauthorized by a Title III order.”14 A Title III order allows for real-time\ninterception of communication.\nLet’s say you’re not under surveillance by law enforcement. Let’s say\nyou’re in an office that is highly regulated—for example, at a public\nutility. Someone may install a femtocell to allow personal\ncommunications outside the utility’s normal call-logging system. The\ndanger is that the coworker with the modified femtocell at his or her desk\ncould perform a man-in-the-middle attack, and he or she could also listen\nin on your calls or intercept your texts.\nIn a demonstration at Black Hat USA 2013, researchers were able to\ncapture voice calls, SMS text messages, and even Web traffic from\nvolunteers in the audience on their Verizon femtocells. The vulnerability\nin Verizon-issued femtocells had already been patched, but the researchers\nwanted to show companies that they should avoid using them anyway.\nSome versions of Android will inform you when you switch cellular\nnetworks; iPhones will not. “Your phone will associate to a femtocell\nwithout your knowledge,” explained researcher Doug DePerry. “This is not\nlike Wi-Fi; you do not have a choice.”15\nOne company, Pwnie Express, produces a device called Pwn Pulse that\nidentifies femtocells and even IMSI catchers such as StingRay.16 It gives\ncompanies the ability to monitor cellular networks around them. Tools like\nthese, which detect the full spectrum of potential cellular threats, were\nonce bought largely by the government—but not anymore.\nAs user-friendly as it is, Skype is not the friendliest when it comes to\nprivacy. According to Edward Snowden, whose revelations were first\npublished in the Guardian, Microsoft worked with the NSA to make sure\nthat Skype conversations could be intercepted and monitored. One\ndocument boasts that an NSA program known as Prism monitors Skype\nvideo, among other communications services. “The audio portions of these\nsessions have been processed correctly all along, but without the\naccompanying video. Now, analysts will have the complete ‘picture’,” the\nGuardian wrote.17\nIn March of 2013, a computer-science graduate student at the\nUniversity of New Mexico found that TOM-Skype, a Chinese version of\nSkype created through a collaboration between Microsoft and the Chinese\ncompany TOM Group, uploads keyword lists to every Skype user’s\nmachine—because in China there are words and phrases you are not\npermitted to search for online (including “Tiananmen Square”). TOM-\nSkype also sends the Chinese government the account holder’s username,\nthe time and date of transmission, and information about whether the\nmessage was sent or received by the user.18\nResearchers have found that even very high-end videoconferencing\nsystems—the expensive kind, not Skype—can be compromised by man-\nin-the-middle attacks. That means the signal is routed through someone\nelse before it arrives at your end. The same is true with audio conferences.\nUnless the moderator has a list of numbers that have dialed in, and unless\nhe has asked to verify any questionable numbers—say, area codes outside\nthe United States—there is no way to prove or determine whether an\nuninvited party has joined. The moderator should call out any new arrivals\nand, if they fail to identify themselves, hang up and use a second\nconference-call number instead.\nSay your office has spent big bucks and bought a really expensive\nvideoconferencing system. You’d think it would be more secure than a\nconsumer-grade system. But you’d be wrong.\nIn looking at these high-end systems, researcher H. D. Moore found\nthat almost all of them default to auto-answer incoming video calls. That\nmakes sense. You set a meeting for 10:00 a.m., and you want participants\nto dial in. However, it also means that at some other time of day, anyone\nwho knows that number could dial in and, well, literally take a peek at\nyour office.\n“The popularity of video conferencing systems among the venture\ncapital and finance industries leads to a small pool of incredibly high-\nvalue targets for any attacker intent on industrial espionage or obtaining\nan unfair business advantage,” Moore wrote.19\nHow hard is it to find these systems? Conferencing systems use a\nunique H.323 protocol. So Moore looked at a sliver of the Internet and\nidentified 250,000 systems using that protocol. He estimates from that\nnumber that fewer than five thousand of these were configured to auto-\nanswer—a small percentage of the whole, but still a very large number by\nitself. And that’s not counting the rest of the Internet.\nWhat can an attacker learn from hacking such a system? The\nconferencing system camera is under the control of the user, so a remote\nattacker could tilt it up, down, left, or right. In most cases the camera does\nnot have a red light to indicate that it’s on, so unless you are watching the\ncamera, you might not be aware that someone has moved it. The camera\ncan also zoom in. Moore said his research team was able to read a six-digit\npassword posted on a wall twenty feet from the camera. They could also\nread e-mail on a user’s screen across the room.\nNext time you’re at the office, consider what can be seen from the\nvideoconferencing camera. Perhaps the department’s organizational chart\nis on the wall. Perhaps your desktop screen faces the conference room.\nPerhaps pictures of your kids and spouse are visible as well. That’s what a\nremote attacker could see and possibly use against your company or even\nyou personally.\nSome system vendors are aware of this issue. Polycom, for example,\nprovides a multipage hardening (security-strengthening) guide, even\nlimiting the repositioning of the camera.20 However, IT staffers don’t\nusually have the time to follow guidelines like these, and they often don’t\neven deem security a concern. There are thousands of conferencing\nsystems on the Internet with default settings enabled.\nThe researchers also discovered that corporate firewalls don’t know\nhow to handle the H.323 protocol. They suggest giving the device a public\nInternet address and setting a rule for it within the corporate firewall.\nThe biggest risk is that many of the administration consoles for these\nconferencing systems have little or no security built in. In one example,\nMoore and his team were able to access a law firm’s system, which\ncontained an address-book entry for the boardroom of a well-known\ninvestment bank. The researchers had purchased a used videoconferencing\ndevice from eBay, and when it arrived its hard drive still had old data on it\n—including the address book, which listed dozens of private numbers,\nmany of which were configured to auto-answer incoming calls from the\nInternet at large.21 As with old printers and copy machines, if it has a hard\ndrive, you need to securely wipe the data from it before you sell it or\ndonate it (see here).\nSometimes at work we are tasked with collaborating on a project with a\ncolleague who may be halfway across the planet. Files can be shared back\nand forth over corporate e-mail, but sometimes they’re so large that e-mail\nsystems will simply balk and not accept them as attachments. Increasingly,\npeople have been using file-sharing services to send large files back and\nforth.\nHow secure are these cloud-based services? It varies.\nThe four big players—Apple’s iCloud, Google Drive, Microsoft’s\nOneDrive (formerly SkyDrive), and Dropbox—all provide two-step\nverification. That means you will receive an out-of-band text on your\nmobile device containing an access code to confirm your identity. And\nwhile all four services encrypt the data while it is in transit you must—if\nyou don’t want the company or the NSA to read it—encrypt the data\nbefore you send it.22\nThere the similarities end.\nTwo-factor authentication is important, but I can still bypass this by\nhijacking unused accounts. For example, I recently did a pen test where\nthe client added Google’s 2FA to their VPN website using publicly\navailable tools. The way I was able to get in was by obtaining the active\ndirectory log-in credentials for a user who didn’t sign up to use the VPN\nportal. Since I was the first to log in to the VPN service, I was prompted to\nset up 2FA using Google Authenticator. If the employee never accesses the\nservice himself, then the attacker will have continued access.\nFor data at rest, Dropbox uses 256-bit AES encryption (which is pretty\nstrong). However, it retains the keys, which could lead to unauthorized\naccess by Dropbox or law enforcement. Google Drive and iCloud use a\nconsiderably weaker 128-bit encryption for data at rest. The concern here\nis that the data could potentially be decrypted by strong computational\nforce. Microsoft OneDrive doesn’t bother with encryption, which leads\none to suspect that this was by design, perhaps at the urging of some\ngovernments.\nGoogle Drive has introduced a new information rights management\n(IRM) feature. In addition to the documents, spreadsheets, and\npresentations created within Google Docs, Google Drive now accepts PDF\nand other file formats as well. Useful features include the ability to disable\nthe download, print, and copy capabilities for commenters and viewers.\nYou can also prevent anyone from adding additional people to a shared\nfile. Of course these management features are only available to file\nowners. That means if someone has invited you to share a file, that person\nhas to set the privacy restrictions, not you.\nMicrosoft has also introduced a unique per-file encryption feature,\nwhich is what it sounds like: a feature that encrypts each individual file\nwith its own key. If one key is compromised, only that individual file will\nbe affected rather than the whole archive. But this is not the default, so\nusers will have to get in the habit of encrypting each file themselves.\nWhich seems like a good recommendation overall. Employees and\nusers in general should get used to encrypting data before it gets sent to\nthe cloud. That way you retain control of the keys. If a government agency\ncomes knocking at the door of Apple, Google, Dropbox, or Microsoft,\nthose companies won’t be able to help—you’ll have the individual keys.\nYou could also choose to use the one cloud service provider that sets\nitself apart from the rest—SpiderOak, which offers the full benefits of\ncloud storage and sync capability along with 100 percent data privacy.\nSpiderOak protects sensitive user data through two-factor password\nauthentication and 256-bit AES encryption so that files and passwords stay\nprivate. Users can store and sync sensitive information with complete\nprivacy, because this cloud service has absolutely zero knowledge of\npasswords and data.\nBut most users will continue to use other services at their own risk.\nPeople love the ease of grabbing data from the cloud, and so do law\nenforcement agencies. A huge concern about using the cloud is that your\ndata does not have the same Fourth Amendment protections that it would\nhave if it were stored in a desk drawer or even on your desktop computer.\nLaw enforcement agencies are requesting cloud-based data with increasing\n(and unsettling) frequency. And they can obtain access with relative ease,\nsince everything you upload online—whether to a Web-based e-mail\nservice, Google Drive, or Shutterfly—goes to a server that belongs to the\ncloud service provider, not to you. The only true protection is to\nunderstand that anything you put up there can be accessed by somebody\nelse and to act accordingly by encrypting everything first.\nCHAPTER FOURTEEN\nObtaining Anonymity Is Hard Work\nA few years ago I\nwas returning to the United States from a trip to\nBogota, Colombia, and upon arriving in Atlanta, I was quietly escorted by\ntwo US Customs agents into a private room. Having previously been\narrested, and having served time in prison, I was perhaps a bit less\nflustered than the average Joe would have been. Still, it was unsettling. I\nhad not done anything wrong. And I was in that room for four hours—five\nshort of the maximum that I could be held without being arrested.\nThe trouble started when a US Customs agent swiped my passport and\nthen stared at the screen. “Kevin,” the agent said with a big smile on his\nface. “Guess what? There are some people downstairs who want to have a\nword with you. But don’t worry. Everything will be okay.”\nI had been in Bogota to give a speech sponsored by the newspaper El\nTiempo. I was also visiting the woman who was my girlfriend at the time.\nWhile I was waiting in that room downstairs, I called my girlfriend back\nin Bogota. She said the police in Colombia had called asking for her\npermission to search a package I had put in a FedEx box to the United\nStates. “They found traces of cocaine,” she said. I knew they hadn’t.\nThe package contained a 2.5-inch internal hard drive. Apparently the\nColombian—or maybe the US—authorities wanted to check the contents\nof the drive, which was encrypted. The cocaine was a lame excuse to open\nthe package. I never got my hard drive back.\nLater I learned that the police had torn open the box, taken the\nelectronic equipment apart, then destroyed my hard drive while trying to\nopen it by drilling a hole in it to check for cocaine. They could have used a\nspecial screwdriver to open the drive. They didn’t find any drugs.\nMeanwhile, back in Atlanta, officials opened my luggage and found my\nMacBook Pro, a Dell XPS M1210 laptop, an Asus 900 laptop, three or four\nhard drives, numerous USB storage devices, some Bluetooth dongles,\nthree iPhones, and four Nokia cell phones (each with its own SIM card, so\nI could avoid roaming charges while speaking in different countries).\nThese are standard tools in my profession.\nAlso in my luggage was my lock-picking kit and a cloning device that\ncould read and replay any HID proximity card. The latter can be used to\nretrieve credentials stored on access cards by placing it in close proximity\nto them. I can, for example, spoof a person’s card credentials and enter\nlocked doors without having to make a forged card. I had these because I\nhad given a keynote presentation about security in Bogota. Naturally, the\ncustoms agents’ eyes lit up when they saw them, thinking I was up to\nsomething else—e.g., skimming credit cards, which was impossible with\nthese devices.\nEventually agents from US Immigration and Customs Enforcement\n(ICE) arrived and asked why I was in Atlanta. I was there to moderate a\npanel at a security conference sponsored by the American Society for\nIndustrial Security (ASIS). Later an FBI agent on the same panel was able\nto confirm the reason for my trip.\nThings seemed to get worse when I opened my laptop and logged in to\nshow them the e-mail confirming my presence on the panel.\nMy browser was set to automatically clear my history when started, so\nwhen I launched it I was prompted to clear my history. When I confirmed\nand clicked the OK button to clear my history, the agents freaked out. But\nthen I just pressed the power button to power down the MacBook, so my\ndrive was inaccessible without my PGP passphrase.\nUnless I was under arrest, which I was told repeatedly that I was not, I\nshould not have had to give up my password. Even if I had been under\narrest, I wouldn’t technically have had to give up my password under US\nlaw, but whether that right is protected depends on how long one is willing\nto fight.1 And different countries have different laws on this. In the UK\nand Canada, for example, authorities can force you to reveal your\npassword.\nAfter my four hours, both ICE and the customs agents let me go. If an\nagency like the NSA had targeted me, however, they would have likely\nsucceeded in figuring out the contents of my hard drive. Government\nagencies can compromise the firmware in your computer or mobile phone,\nimpair the network you use to connect to the Internet, and exploit a variety\nof vulnerabilities found in your devices.\nI can travel to foreign countries that have even more stringent rules and\nnever have the problems I have in the United States because of my\ncriminal record here. So how do you travel abroad with sensitive data?\nAnd how do you travel to “hostile” countries such as China?\nIf you don’t want to have any sensitive data available on your hard\ndrive, the choices are:\n1. Clean up any sensitive data before you travel and perform a full\nbackup.\n2. Leave the data there but encrypt it with a strong key (although some\ncountries may be able to compel you to reveal the key or password).\nDo not keep the passphrase with you: perhaps give half of the\npassphrase to a friend outside the United States who cannot be\ncompelled to give it up.\n3. Upload the encrypted data to a cloud service, then download and\nupload as needed.\n4. Use a free product such as VeraCrypt to create a hidden encrypted\nfile folder on your hard drive. Again, a foreign government, if it\nfinds the hidden file folder, may be able to force you to reveal the\npassword.\n5. Whenever entering your password into your devices, cover yourself\nand your computer, perhaps with a jacket or other item of clothing,\nto prevent camera surveillance.\n6. Seal your laptop and other devices in a FedEx or other Tyvek\nenvelope and sign it, then put it in the hotel room safe. If the\nenvelope is tampered with, you should notice it. Note, too, that\nhotel safes aren’t really that safe. You should consider buying a\ncamera device that you can put inside the safe to take a photo of\nanyone opening it and send the photo via cellular in real time.\n7. Best of all, don’t take any risk. Carry your device with you at all\ntimes, and don’t let it out of your sight.\nAccording to documents obtained by the American Civil Liberties Union\nthrough the Freedom of Information Act, between October of 2008 and\nJune of 2010, more than 6,500 people traveling to and from the United\nStates had their electronic devices searched at the border. This is an\naverage of more than three hundred border searches of electronic devices\nper month. And almost half of those travelers were US citizens.\nLittle known fact: Anyone’s electronic devices can be searched without\na warrant or reasonable suspicion within one hundred air miles of the US\nborder, which likely includes San Diego. Just because you crossed the\nborder doesn’t necessarily mean you are safe!\nTwo government agencies are primarily responsible for inspecting\ntravelers and items entering the United States: the Department of\nHomeland Security’s Customs and Border Protection (CBP) and\nImmigration and Customs Enforcement (ICE). In 2008, the Department of\nHomeland Security announced that it could search any electronic device\nentering the United States.2 It also introduced its proprietary Automated\nTargeting System (ATS), which creates an instant personal dossier about\nyou—a very detailed one—whenever you travel internationally. CBP\nagents use your ATS file to decide whether you will be subject to an\nenhanced and sometimes invasive search upon reentering the United\nStates.\nThe US government can seize an electronic device, search through all\nthe files, and keep it for further scrutiny without any suggestion of\nwrongdoing whatsoever. CBP agents may search your device, copy its\ncontents, and try to undelete images and video.\nSo here’s what I do.\nTo protect my privacy and that of my clients, I encrypt the confidential\ndata on my laptops. When I’m in a foreign country, I transmit the\nencrypted files over the Internet for storage on secure servers anywhere in\nthe world. Then I wipe them physically from the computer before I return\nhome, just in case government officials decide to search or seize my\nequipment.\nWiping data is not the same as deleting data. Deleting data only\nchanges the master boot record entry for a file (the index used to find parts\nof the file on the hard drive); the file (or some of its parts) remains on the\nhard drive until new data is written over that part of the hard drive. This is\nhow digital forensics experts are able to reconstruct deleted data.\nWiping, on the other hand, securely overwrites the data in the file with\nrandom data. On solid-state drives, wiping is very difficult, so I carry a\nlaptop that has a standard hard drive and wipe it with at least thirty-five\npasses. File-shredding software does this by overwriting random data\nhundreds of times in each pass over a deleted file, making it hard for\nanyone to recover that data.\nI used to make a full image backup of my device onto an external hard\ndrive and encrypt it. I would then send the backup drive to the United\nStates. I wouldn’t wipe the data on my end until the drive was confirmed\nto be received by a colleague in readable condition. Then I’d securely wipe\nall personal and client files. I wouldn’t format the entire drive, and I’d\nleave the operating system intact. That way, if I was searched, it would be\neasier to restore my files remotely without having to reinstall the entire\noperating system.\nSince the experience in Atlanta, I’ve changed my protocol somewhat. I\nhave started to keep an up-to-date “clone” of all my travel computers with\na business colleague. My colleague can then just send the cloned systems\nto me anywhere in the United States, if needed.\nMy iPhone is another matter. If you ever connect your iPhone to your\nlaptop to charge, and you click “Trust” when it shows you the “Trust This\nComputer” question, a pairing certificate is stored on the computer that\nallows the computer to access the entire contents of the iPhone without\nneeding to know the passcode. The pairing certificate will be used\nwhenever the same iPhone is connected to that computer.\nFor example, if you plug your iPhone into another person’s computer\nand “trust” it, a trusted relationship is created between the computer and\nthe iOS device, which allows the computer to access photos, videos, SMS\nmessages, call logs, WhatsApp messages, and most everything else\nwithout needing the passcode. Even more concerning, that person can just\nmake an iTunes backup of your entire phone unless you previously set a\npassword for encrypted iTunes backups (which is a good idea). If you\ndidn’t set that password, an attacker could set one for you and simply back\nup your mobile device to his or her computer without your knowledge.\nThat means if law enforcement wants to see what’s on your passcode-\nprotected iPhone, they can do so easily by connecting it to your laptop,\nsince it likely has a valid pairing certificate with that phone. The rule is:\nnever “trust this computer” unless it’s your personal system. What if you\nwant to revoke your entire Apple device’s pairing certificates? The good\nnews is that you can reset your pairing certificate on your Apple devices.3\nIf you need to share files, and you are using an Apple product, use\nAirDrop. And if you need to charge your phone, use the lightning cable\nplugged into your system or an electrical outlet, not into someone else’s\ncomputer. Or you can buy a USB condom from syncstop.com, which\nallows you to safely plug into any USB charger or computer.\nWhat if you only have your iPhone and not your computer when\ntraveling?\nI have enabled Touch ID on my iPhone so that it recognizes my\nfingerprint. What I do is reboot my iPhone before approaching\nimmigration control in any country. And when it powers up, I deliberately\ndo not put in my passcode. Even though I have enabled Touch ID, that\nfeature is by default disabled until I first put in my passcode. The US\ncourts are clear that law enforcement cannot demand your password.\nTraditionally, in the United States, you cannot be compelled to give\ntestimonial evidence; however, you can be compelled to turn over a\nphysical key to a safe. As such, a court can compel you to provide your\nfingerprints to unlock the device.4 Simple solution: reboot your phone.\nThat way your fingerprint won’t be enabled and you won’t have to give up\nyour passcode.\nIn Canada, however, it’s the law; you must, if you are a Canadian\ncitizen, provide your passcode when it’s requested. This happened to Alain\nPhilippon, from Sainte-Anne-des-Plaines, Quebec. He was on his way\nhome from Puerto Plata, in the Dominican Republic, when he refused to\nprovide the border agents in Nova Scotia with his mobile phone’s\npasscode. He was charged under section 153.1(b) of the Canadian Customs\nAct for hindering or preventing border officers from performing their role.\nThe penalty if you’re found guilty is $1,000, with a maximum fine of\n$25,000 and the possibility of one year in jail.5\nI know firsthand about the Canadian password law. I hired a car service\nlike Uber to take me from Chicago to Toronto in 2015 (I didn’t want to fly\nin severe thunderstorms), and when we crossed the border into Canada\nfrom Michigan, we were immediately sent to a secondary inspection site.\nMaybe it was because a Middle Eastern guy with only a green card was\ndriving. As soon as we arrived at the secondary inspection point, we\nentered a scene straight out of CSI.\nA team of customs agents made sure we left the vehicle with all our\nbelongings inside, including our cell phones. The driver and I were\nseparated. One of the agents went to the driver’s side of the car and\nremoved his cell phone from the cradle. The agent demanded the driver’s\npasscode and started going through his phone.\nI previously had made up my mind never to give out my password. I\nfelt I would have to choose between giving up my password and being\nallowed to travel into Canada for my gig. So I decided to use a bit of social\nengineering.\nI yelled over to the customs agent searching the driver’s phone. “Hey—\nyou aren’t going to search my suitcase, right? It’s locked so you can’t.” It\nimmediately got her attention. She said they had every right to search my\nsuitcase.\nI replied, “I locked it, so it cannot be searched.”\nNext thing I know, two agents walked over to me and demanded the\nkey. I started asking them why they needed to search my suitcase, and they\nexplained again that they had the right to search everything. I pulled out\nmy wallet and handed the agent the key to my suitcase.\nThat was enough. They completely forgot about the cell phones and\nconcentrated on my suitcase instead. Mission accomplished through\nmisdirection. I was let go and, thankfully, was never asked for my cell-\nphone password.\nIn the confusion of being screened, it is easy to become distracted.\nDon’t let yourself fall victim to circumstance. When going through any\nsecurity checkpoint, make sure your laptop and electronic devices are the\nlast on the conveyor belt. You don’t want your laptop sitting at the other\nend while someone ahead of you is holding up the line. Also, if you need\nto step out of the line, make sure you have your laptop and electronic\ndevice with you.\nWhatever privacy protections we may enjoy at home don’t necessarily\napply to travelers at the US border. For doctors, lawyers, and many\nbusiness professionals, an invasive border search might compromise the\nprivacy of sensitive professional information. This information might\ninclude trade secrets, attorney–client and doctor–patient communications,\nand research and business strategies, some of which a traveler has legal\nand contractual obligations to protect.\nFor the rest of us, searches on our hard drives and mobile devices\nmight reveal e-mail, health information, and even financial records. If\nyou’ve recently traveled to certain countries deemed unfriendly to US\ninterests, be aware that this may trigger additional scrutiny from customs\nagents.\nRepressive governments present another challenge. They may insist on\nlooking at your electronic devices more thoroughly—reading your e-mail\nand checking your Downloads folder. There is also a possibility—\nespecially if they take your laptop from you—that they might attempt to\ninstall tracking software on your device.\nMany companies issue burner phones and loaner laptops when\nemployees travel abroad. These devices are either thrown away or wiped\nclean when the employee returns to the United States. But for most of us,\nuploading encrypted files to the cloud or buying a new device and\ndisposing of it upon return are not practical options.\nIn general, don’t bring electronics that store sensitive information with\nyou unless you absolutely need to. If you do, bring only the bare\nminimum. And if you need to bring your mobile phone, think about\ngetting a burner phone for the duration of your visit. Especially since\nvoice and data roaming rates are outrageous. Better to bring an unlocked\nburner phone and purchase a SIM card in the country you are visiting.\nYou might think that getting in and out of customs is the most nightmarish\npart of any trip. But it might not be. Your hotel room can also be searched.\nI made several trips to Colombia in 2008—not just the one when I was\nstopped in Atlanta. On one of the trips I made later that year, something\nstrange happened in my Bogota hotel room. And this was not a\nquestionable hotel; it was one of the hotels where Colombian officials\nfrequently stayed.\nPerhaps that was the problem.\nI had gone out to dinner with my girlfriend, and when we came back,\nmy door lock displayed yellow when I inserted my room key. Not green.\nNot red. But yellow, which typically means the door is locked from the\ninside.\nI went down to the front desk and had the clerk issue me a new key\ncard. Again, the lock displayed a yellow light. I did this again. Same\nresult. After the third time, I persuaded the hotel to send someone up with\nme. The door opened.\nInside, nothing looked immediately wrong. In fact at the time, I\nchalked the whole thing up to the lock being crappy. It wasn’t until I\nreturned to the United States that I realized what had happened.\nBefore leaving the United States, I had called a former girlfriend, Darci\nWood, who used to be the lead technician at TechTV, and asked her to\ncome over to my place and swap out the hard drive in my MacBook Pro\nlaptop. At the time, MacBook Pro hard drives weren’t easy to remove. She\ndid it, though. In its place she put a brand-new drive that I had to format\nand install the OSX operating system on.\nSeveral weeks later, when I returned from that trip to Colombia, I\nasked Darci to come over to my place in Las Vegas to swap back the\ndrives.\nImmediately she noticed something was different. She said someone\nhad tightened the hard-drive screws much more than she had. Clearly\nsomeone in Bogota had removed the drive, perhaps to make an image copy\nof it when I left my room.\nThis happened more recently to Stefan Esser, a researcher known for\njailbreaking iOS products. He tweeted a picture of his poorly remounted\nhard drive.\nEven a drive with very little data has some data on it. Fortunately, I\nused Symantec’s PGP Whole Disk Encryption to encrypt the entire\ncontents of my hard drive. (You could also use WinMagic for Windows or\nFileVault 2 for OSX; see here.) So the clone of my hard drive would be\nworthless unless the thief could obtain the key to unlock it. It is because of\nwhat I think happened in Bogota that I now bring my laptop with me when\nI travel, even when I’m going out to dinner. If I have to leave my laptop\nbehind, then I never leave it in hibernate mode. Rather, I power it down. If\nI didn’t, an attacker could possibly dump the memory and obtain my PGP\nWhole Disk encryption keys.6 So I turn it all the way off.\nAt the beginning of the book I talked about the many precautions that\nEdward Snowden took to keep his communication with Laura Poitras\nprivate. Once Snowden’s secret cache of data was ready to be released to\nthe public, however, he and Poitras needed a place to store it. The most\ncommon operating systems—Windows, iOS, Android, and even Linux—\ncontain vulnerabilities. All software does. So they needed a secure\noperating system, one that is encrypted from day one and requires a key to\nunlock it.\nHard-disk encryption works like this: when you boot up your computer,\nyou enter a secure password or, rather, a passphrase such as “We don’t\nneed no education” (from the famous Pink Floyd song). Then the operating\nsystem boots up, and you can access your files and perform your tasks\nwithout noticing any time delay, because a driver performs the encryption\ntasks transparently and on the fly. This does, however, create the\npossibility that if you get up and leave your device, even for a moment,\nsomeone could access your files (since they are unlocked). The important\nthing to remember is that while your encrypted hard drive is unlocked, you\nneed to take precautions to keep it secure. As soon as you shut down, the\nencryption key is no longer available to the operating system: that is, it\njust removes the key from memory so the data on the drive is no longer\naccessible.7\nTails is an operating system that can be booted up on any modern-day\ncomputer to avoid leaving any forensically recoverable data on the hard\ndrive, preferably one that can be write-protected.8 Download Tails onto a\nDVD or a USB stick, then set your BIOS firmware or EFI (OSX) initial\nboot sequence for either DVD or USB to boot the Tails distribution. When\nyou boot, it will start up the operating system, which features several\nprivacy tools, including the Tor browser. The privacy tools allow you to\nencrypt e-mail using PGP, encrypt your USB and hard drives, and secure\nyour messages with OTR (off-the-record messaging).\nIf you want to encrypt individual files instead of your entire hard drive,\nthere are several choices. One free option, TrueCrypt, still exists but is no\nlonger maintained and doesn’t offer full-disk encryption. Because it is no\nlonger maintained, new vulnerabilities will not be addressed. If you\ncontinue to use TrueCrypt, be aware of the risks. A replacement for\nTrueCrypt 7.1a is VeraCrypt, which is a continuation of the TrueCrypt\nproject.\nThere are several programs for sale, too. One obvious one is Windows\nBitLocker, which is generally not included in the home editions of the\nWindows operating system. To enable BitLocker, if installed, open File\nExplorer, right-click on the C drive, and scroll down to the “Turn on\nBitLocker” option. BitLocker takes advantage of a special chip on your\nmotherboard known as a trusted platform module, or TPM. It’s designed to\nunlock your encryption key only after confirming that your bootloader\nprogram hasn’t been modified. This is a perfect defense against evil maid\nattacks, which I will describe shortly. You can set BitLocker to unlock\nwhen you power up or only when there’s a PIN or a special USB that you\nprovide. The latter choices are much safer. You also have the option of\nsaving the key to your Microsoft account. Don’t do that, because if you do\nyou will have more or less given Microsoft your keys (which, as you will\nsee, it might already have).\nThere are several issues with BitLocker. First, it uses a pseudorandom\nnumber generator (PRNG) called Dual_EC_DRBG, short for dual elliptic\ncurve deterministic random bit generator, which might contain an NSA\nback door.9 It is also privately owned, meaning that you just have to take\nMicrosoft’s word that it works and that it doesn’t have any back doors for\nthe NSA—which may not be the case with open-source software. Another\nproblem with BitLocker is that you must share the key with Microsoft\nunless you purchase it for $250. Not doing so may allow law enforcement\nto request the key from Microsoft.\nDespite these reservations, the EFF actually does recommend\nBitLocker for the average consumer looking to protect his or her files.10\nHowever, be aware there is a way to bypass BitLocker as well.11\nAnother commercial option is PGP Whole Disk Encryption from\nSymantec. A lot of universities use this, as do many corporations. I have\nused it in the past as well. PGP Whole Disk Encryption was created by\nPhil Zimmermann, the man who created PGP for e-mail. Like BitLocker,\nPGP can support the TPM chip to provide additional authentication when\nyou turn on your PC. A perpetual license sells for around $200.\nThere is also WinMagic, one of the few options that requires two-factor\nauthentication instead of just a password. WinMagic also doesn’t rely on a\nmaster password. Rather, encrypted files are grouped, and each group has\na password. This can make password recovery harder, so it may not be\nsuitable for everyone.\nAnd for Apple there’s FileVault 2. After installation, you can enable\nFileVault 2 by opening System Preferences, clicking on the “Security &\nPrivacy” icon, and switching to the FileVault tab. Again, do not save your\nencryption key to your Apple account. This may give Apple access to it,\nwhich they in turn could give to law enforcement. Instead choose “Create\na recovery key and do not use my iCloud account,” then print out or write\ndown the twenty-four-character key. Protect this key, as anyone who finds\nit could unlock your hard drive.\nIf you have iOS 8 or a more recent version of the operating system on\nyour iPhone or iPad, its contents are automatically encrypted. Going a step\nfurther, Apple has said that the key remains on the device, with the user.\nThat means that the US government cannot ask Apple for the key: it’s\nunique to each and every device. FBI director James Comey claims that\nunbreakable encryption ultimately is not a good thing. In a speech he said,\n“Sophisticated criminals will come to count on these means of evading\ndetection. And my question is, at what cost?”12 The fear is that bad things\nwill be kept under the cover of encryption.\nThe same fear delayed my case for months as I languished in jail back\nin the 1990s. My legal defense team wanted access to the discovery that\nthe government planned to use against me at my trial. The government\nrefused to turn over any encrypted files unless I provided the decryption\nkey. I refused.13 The court, in turn, refused to order the government to\nprovide the discovery because I wouldn’t give them the key.14\nAndroid devices, beginning with version 3.0 (Honeycomb), also can be\nencrypted. Most of us choose not to do so. Beginning with Android 5.0\n(Lollipop), encrypted drives are the default on the Nexus line of Android\nphones but optional on phones from other manufacturers, such as LG,\nSamsung, and others. If you choose to encrypt your Android phone, note\nthat it could take up to an hour to do so and that your device should be\nplugged in during the process. Reportedly, encrypting your mobile device\ndoes not significantly hinder performance, but once you’ve made the\ndecision to encrypt, you can’t undo it.\nIn any of these whole-disk encryption programs, there always remains\nthe possibility of a back door. I was once hired by a company to test a USB\nproduct that allowed users to store files in an encrypted container. During\nanalysis of the code, we found that the developer had put in a secret back\ndoor—the key to unlock the encrypted container was buried in a random\nlocation on the USB drive. That meant that anyone with knowledge of the\nlocation of the key could unlock the data encrypted by the user.\nWorse, companies don’t always know what to do with this information.\nWhen I completed my security analysis of the encrypted USB device, the\nCEO called me and asked whether he should leave the back door in or not.\nHe was concerned that law enforcement or the NSA may need to access a\nuser’s data. The fact that he needed to ask says a lot.\nIn its 2014 wiretap report, the US government reported encountering\nencrypted drives on only twenty-five out of the 3,554 devices that law\nenforcement had searched for evidence.15 And they were still able to\ndecrypt the drives on twenty-one of the twenty-five. So while having\nencryption often is good enough to keep a common thief from accessing\nyour data, for a dedicated government, it might not pose much of a\nchallenge.\nYears ago researcher Joanna Rutkowska wrote about what she called an\nevil maid attack.16 Say someone leaves a powered-down laptop whose\nhard drive is encrypted with either TrueCrypt or PGP Whole Disk\nEncryption in a hotel room. (I had used PGP Whole Disk Encryption in\nBogota; I had also powered down the laptop.) Later, someone enters the\nroom and inserts a USB stick containing a malicious bootloader. The target\nlaptop must then be booted off the USB to install the malicious bootloader\nthat steals the user’s passphrase. Now the trap is set.\nA maid, someone who can frequent a hotel room without too much\nsuspicion, would be the best candidate to do this—hence the name of the\nattack. A maid can reenter almost any hotel room the next day and type in\na secret key combination that extracts the passphrase that was secretly\nstored on the disk. Now the attacker can enter the passphrase and obtain\naccess to all your files.\nI don’t know whether someone did this on my laptop in Bogota. The\nhard drive itself had been removed and then replaced with the screws\nturned too tightly. Either way, fortunately, the drive contained no real\ninformation.\nWhat about putting your electronics in a hotel safe? Is it better than\nleaving them out or keeping them in suitcases? Yes, but not much better.\nWhen attending a recent Black Hat, I stayed at the Four Seasons in Las\nVegas. I placed $4,000 cash in the safe with various credit cards and\nchecks. A few days later, I went and tried to open the safe but the code\nfailed. I called security and they opened it up. I immediately noticed that\nthe pile of $100 bills was much less thick. There was $2,000 left. So where\ndid the other $2,000 go? Hotel security had no idea. A friend of mine who\nspecializes in physical pen testing tried hacking the safe but could not\nexploit it. Today, it’s still a mystery. Ironically, the safe was called a Safe\nPlace.\nA German antivirus company, G DATA, found that in hotel rooms\nwhere their research staff stayed, “more often than not” the safe had the\ndefault password (0000) in place. In cases like that, no matter what private\npassword you select, anyone knowing the default password could also gain\naccess to your valuables inside. G DATA did say that this information was\nnot discovered systematically but anecdotally over several years.17\nIf an attacker doesn’t know the default password for a given hotel-room\nsafe, another option for him is to literally brute-force the lock. Although\nthe hotel manager is entrusted with an emergency electronic device that\nplugs into the USB port and unlocks the safe, a savvy thief can simply\nunscrew the plate on the front of the safe and use a digital device to open\nthe lock underneath. Or he can short-circuit the safe and initiate a reset,\nthen enter a new code.\nIf that doesn’t bother you, consider this. G DATA also found that the\ncredit card readers on room safes—often the means by which you pay for\ntheir use—can be read by a third party who could skim the credit card data\nand then use or sell that information on the Internet.\nToday hotels use NFC or even magnetic-strip swipe cards to lock and\nunlock your room. The advantage is that the hotel can change these access\ncodes quickly and easily from the front desk. If you lose your card, you\ncan request a new one. A simple code is sent to the lock, and by the time\nyou get to your room, the new key card works. Samy Kamkar’s MagSpoof\ntool can be used to spoof the correct sequences and open a hotel room lock\nthat uses magnetic-strip cards. This tool was used on an episode of the TV\nshow Mr. Robot.\nThe presence of a magnetic strip or an NFC chip has given rise to the\nidea that personal information might be stored on the hotel key card. It’s\nnot. But the urban legend continues. There’s even a famous story that\noriginated in San Diego County. Supposedly a sheriff’s deputy there issued\na warning that a hotel guest’s name, home address, and credit card\ninformation had been found on a hotel key card. Perhaps you’ve seen the\ne-mail. It looks something like this:\nSouthern California law enforcement professionals assigned to\ndetect new threats to personal security issues recently discovered\nwhat type of information is embedded in the credit card–type hotel\nroom keys used throughout the industry.\nAlthough room keys differ from hotel to hotel, a key obtained\nfrom the DoubleTree chain that was being used for a regional\nidentity theft presentation was found to contain the following\ninformation:\nCustomer’s name\nCustomer’s partial home address\nHotel room number\nCheck-in date and checkout date\nCustomer’s credit card number and expiration date!\nWhen you turn them in to the front desk, your personal information\nis there for any employee to access by simply scanning the card in\nthe hotel scanner. An employee can take a handful of cards home\nand, using a scanning device, access the information onto a laptop\ncomputer and go shopping at your expense.\nSimply put, hotels do not erase these cards until an employee\nissues the card to the next hotel guest. It is usually kept in a drawer\nat the front desk with YOUR INFORMATION ON IT!!!!\nThe bottom line is, keep the cards or destroy them! NEVER\nleave them behind and NEVER turn them in to the front desk when\nyou check out of a room. They will not charge you for the card.18\nThe truthfulness of this e-mail has been widely disputed.19 Frankly, it\nsounds like bullshit to me.\nThe information listed certainly could be stored on a key card, but that\nseems extreme, even to me. Hotels use what can be considered a token, a\nplaceholder number, for each guest. Only with access to the back-end\ncomputers that do the billing can the token be connected with personal\ninformation.\nI don’t think you need to collect and destroy your old key cards, but\nhey—you might want to do so all the same.\nAnother common question that concerns travel and your data: What’s in\nthe bar code on the bottom of your plane ticket? What, if anything, might\nit reveal? In truth, relatively little personal information, unless you have a\nfrequent flyer number.\nStarting in 2005, the International Air Transport Association (IATA)\ndecided to use bar-coded boarding passes for the simple reason that\nmagnetic boarding passes were much more expensive to maintain. The\nsavings have been estimated at $1.5 billion. Furthermore, using bar codes\non airline tickets allows passengers to download their tickets from the\nInternet and print them at home, or they can use a mobile phone at the gate\ninstead.\nNeedless to say, this change in procedure required some sort of\nstandard. According to researcher Shaun Ewing, the typical boarding-pass\nbar code contains information that is mostly harmless—name of\npassenger, name of airline, seat number, departure airport, arrival airport,\nand flight number.20 However, the most sensitive part of the bar code is\nyour frequent flyer number.21 All airline websites now protect their\ncustomer accounts with personal passwords. Giving out your frequent\nflyer number is not like giving out your Social Security number, but it still\nis a privacy concern.\nA bigger privacy concern is the loyalty cards offered at supermarkets,\npharmacies, gas stations, and other businesses. Unlike airline tickets,\nwhich have to be in your legal name, loyalty cards can be registered under\na fake name, address, and phone number (a fake number you can\nremember), so your purchasing habits cannot be linked back to you.\nWhen you check into your hotel and boot up your computer, you might see\na list of available Wi-Fi networks, such as “Hotel Guest,” “tmobile123,”\n“Kimberley’s iPhone,” “attwifi,” “Steve’s Android,” and “Chuck’s\nHotspot.” Which one should you connect to? I hope you know the answer\nby now!\nMost hotel Wi-Fi doesn’t use encryption but does require the guest’s\nlast name and room number as authentication. There are tricks to get\naround paywalls, of course.\nOne trick for getting free Internet at any hotel is to call any other room\n—perhaps the one across the hall—posing as room service. If the hotel\nuses caller ID, just use the house phone in the lobby. Tell the party\nanswering the phone that her two burgers are on the way. When the guest\nsays she didn’t place an order, you politely ask for her surname to fix the\nerror. Now you have both the room number (you called it) and the\nsurname, which is all that’s needed to authenticate you (a nonpaying guest)\nas a legitimate guest at that hotel.\nLet’s say you are staying at a five-star hotel with Internet access, free or\notherwise. As you log on, perhaps you see a message informing you that\nAdobe (or some other software maker) has an update available. Being a\ngood citizen of the Internet, you might be tempted to download the update\nand move on. Except the hotel network should still be considered hostile—\neven if it has a password. It’s not your home network—so the update might\nnot be real, and if you go ahead and download it you may inadvertently\ninstall malicious code on your PC.\nIf you are on the road a lot, as I am, whether to update or not is a tough\ncall. There is little you can do except verify that there is an update\navailable. The problem is, if you use the hotel’s Internet to download that\nupdate, you might be directed to a spoofed website providing the\nmalicious “update.” If you can, use your mobile device to confirm the\nexistence of the update from the vendor’s site and, if it’s not critical, wait\nuntil you’re back in a safe environment, such as a corporate office or back\nhome, to download it.22\nResearchers at Kaspersky Lab, a software security company, discovered\na group of criminal hackers they call DarkHotel (also known as Tapaoux)\nwho use this technique. They operate by identifying business executives\nwho might be staying at a particular luxury hotel, then anticipate their\narrival by placing malware on the hotel server. When the executives check\nin and connect to the hotel Wi-Fi, the malware is downloaded and\nexecuted on their devices. After the infection is complete, the malware is\nremoved from the hotel server. Apparently this has been going on for\nalmost a decade, the researchers noted.\nAlthough it primarily affects executives staying at luxury hotels in\nAsia, it could be common elsewhere. The DarkHotel group in general uses\na low-level spear-phishing attack for mass targets and reserves the hotel\nattacks for high-profile, singular targets—such as executives in the\nnuclear power and defense industries.\nOne early analysis suggested that DarkHotel was South Korea–based. A\nkeylogger—malware used to record the keystrokes of compromised\nsystems—used in the attacks contains Korean characters within the code.\nAnd the zero-days—vulnerabilities in software that are unknown to the\nvendor—were very advanced flaws that were previously unknown.\nMoreover, a South Korean name identified within the keylogger has been\ntraced to other sophisticated keyloggers used by Koreans in the past.\nIt should be noted, however, that this is not enough to confirm\nattribution. Software can be cut and pasted from a variety of sources. Also,\nsoftware can be made to look as though it is created in one country when it\nis actually created in another.\nTo get the malware on the laptops, DarkHotel uses forged certificates\nthat appear as though they are issued from the Malaysian government and\nDeutsche Telekom. Certificates, if you remember from chapter 5, are used\nto verify the origin of the software or the Web server. To further hide their\nwork, the hackers arranged it so that the malware stays dormant for up to\nsix months before becoming active. This is to throw off IT departments\nthat might link a visit with an infection.\nKaspersky only learned of this attack when a group of its customers\nbecame infected after staying at certain luxury hotels in Asia. The\nresearchers turned to a third-party Wi-Fi host common to both, and the\nWi-Fi host partnered with the antivirus company to find out what was\nhappening on its networks. Although the files used to infect the guests\nwere long gone, file deletion records were left behind that corresponded to\nthe dates of the guests’ stays.\nThe easiest way to protect yourself against this kind of attack is to\nconnect to a VPN service as soon as you connect to the Internet at the\nhotel. The one I use is cheap—only six dollars per month. However, that’s\nnot a good choice if you want to be invisible, since it won’t allow\nanonymous setup.\nIf you want to be invisible, don’t trust the VPN provider with your real\ninformation. This requires setting up a fake e-mail address in advance (see\nhere) and using an open wireless network. Once you have that fake e-mail\naddress, use Tor to set up a Bitcoin wallet, find a Bitcoin ATM to fund the\nwallet, and then use a tumbler to essentially launder the Bitcoin so it\ncannot be traced back to you on the blockchain. This laundering process\nrequires setting up two Bitcoin wallets using different Tor circuits. The\nfirst wallet is used to send the Bitcoin to the laundering service, and the\nsecond is set up to receive the laundered Bitcoin.\nOnce you have achieved true anonymity by using open Wi-Fi out of\ncamera view plus Tor, find a VPN service that accepts Bitcoin for\npayment. Pay with the laundered Bitcoin. Some VPN providers, including\nWiTopia, block Tor, so you need to find one that doesn’t—preferably with\na VPN provider that doesn’t log connections.\nIn this case, we are not “trusting” the VPN provider with our real IP\naddress or name. However, when using the newly set-up VPN, you must be\ncareful not to use any of the services connected to your real name and not\nto connect to the VPN from an IP address that can be tied back to you. You\nmight consider tethering to an anonymously acquired burner phone, see\nhere.\nIt’s best to purchase a portable hotspot—purchased in such a way that it\nwould be very difficult to identify you. For example, you can hire\nsomeone to purchase it for you so your face does not appear on a\nsurveillance camera in a store. When you’re using the anonymous hotspot,\nyou should turn off any of your personal devices that use cellular signals\nto prevent the pattern of your personal devices registering in the same\nplace as the anonymous device.\nTo summarize, here’s what you need to do to use the Internet privately\nwhile traveling:\n1. Purchase prepaid gift cards anonymously (see here). In the EU, you\ncan purchase prepaid credit cards anonymously at viabuy.com.\n2. Use open Wi-Fi after changing your MAC address (see here).\n3. Find an e-mail provider that allows you to sign up without SMS\nvalidation. Or you can sign up for a Skype-in number using Tor and\na prepaid gift card. With Skype-in, you can receive voice calls to\nverify your identity. Make sure you are out of camera view (i.e., not\nin a Starbucks or anywhere else with camera surveillance). Use Tor\nto mask your location when you sign up for this e-mail service.\n4. Using your new anonymous e-mail address, sign up at a site such as\npaxful.com, again using Tor, to sign up for a Bitcoin wallet and buy\na supply of Bitcoin. Pay for them using the prepaid gift cards.\n5. Set up a second anonymous e-mail address and new secondary\nBitcoin wallet after closing and establishing a new Tor circuit to\nprevent any association with the first e-mail account and wallet.\n6. Use a Bitcoin laundering service such as bitlaunder.com to make it\nhard to trace the currency’s origin. Have the laundered Bitcoin sent\nto the second Bitcoin address.23\n7. Sign up for a VPN service using the laundered Bitcoin that does not\nlog traffic or IP connections. You can usually find out what is\nlogged by reviewing the VPN provider’s privacy policy (e.g.,\nTorGuard).\n8. Have a cutout obtain a burner portable hotspot device on your\nbehalf. Give the cutout cash to purchase it.\n9. To access the Internet, use the burner hotspot device away from\nhome, work, and your other cellular devices.\n10. Once powered up, connect to VPN through the burner hotspot\ndevice.\n11. Use Tor to browse the Internet.\nCHAPTER FIFTEEN\nThe FBI Always Gets Its Man\nIn the science fiction section\nof the Glen Park branch of the San\nFrancisco Public Library, not far from his apartment, Ross William\nUlbricht was engaged in an online customer-support chat for the company\nhe owned. At the time—October of 2013—the person on the other end of\nthe Internet chat thought he was talking to the site’s admin, who went by\nthe Internet name of Dread Pirate Roberts, a name taken from the movie\nThe Princess Bride. Roberts, also known as DPR, was in fact Ross Ulbricht\n—not only the admin but also the owner of Silk Road, an online drug\nemporium, and as such was the subject of a federal manhunt.1 Ulbricht\nfrequently used public Wi-Fi locations such as the library for his work,\nperhaps under the mistaken impression that the FBI, should it ever identify\nhim as DPR, would never conduct a raid in a public place. On that day,\nhowever, the person with whom Ulbricht was chatting happened to be an\nundercover FBI agent.\nRunning an online drug emporium, in which customers could order\ncocaine and heroin and a wide range of designer drugs anonymously,\nrequired a certain moxie. The site was hosted on the Dark Web (see here)\nand was only accessible through Tor. The site only took Bitcoin as\npayment. And the creator of Silk Road had been careful, but not careful\nenough.\nA few months before Ulbricht sat in the San Francisco Public Library\nwith the FBI circling him, an unlikely hero connected with the federal\nmanhunt came forward with evidence tying Ulbricht to DPR. The hero, an\nIRS agent named Gary Alford, had been reading up on Silk Road and its\norigins, and in the evenings he had been running advanced Google\nsearches to see what he could find. One of the earliest mentions of Silk\nRoad he found was from 2011. Someone who went by the name “altoid”\nhad been talking it up in a chat group. Since Silk Road had not yet\nlaunched, Alford figured that altoid most likely had inside knowledge of\nthe operation. Naturally Alford started a search for other references.\nHe struck gold.\nApparently altoid had posted a question to another chat group—but had\ndeleted the original message. Alford pulled up a response to the now\ndeleted query that contained the original message. In that message, altoid\nsaid that if anyone could answer his question, that person could contact\nhim at rossulbricht@gmail.com.2\nIt was not the last time that slipup would be made. There were other\nposted questions, one to a site called Stack Overflow: the original question\nhad been sent in from rossulbricht@gmail.com, but then, remarkably, the\nsender’s name had been changed to DPR.\nRule number 1 about being invisible: you can’t ever link your\nanonymous online persona with your real-world persona. You just can’t.\nThere were other linkages established after that. Ulbricht, like DPR,\nespoused Ron Paul–free market–libertarian philosophies. And at one point\nUlbricht had even ordered a set of false IDs—driver’s licenses in different\nnames from various states—which drew federal authorities to his doorstep\nin San Francisco in July of 2013, but at that time the authorities had no\nidea they were talking with DPR.\nSlowly the evidence grew so compelling that one morning in October\nof 2013, as soon as DPR’s customer-support chat began, federal agents\nbegan quietly entering the Glen Park library. Then, in a surgical strike,\nthey seized Ulbricht before he could shut down his laptop. Had he shut it\ndown, certain key evidence would have been destroyed. As it was, they\nwere able to photograph the system administration screens for a site called\nSilk Road moments after the arrest and thereby establish a concrete link\nbetween Ulbricht, Dread Pirate Roberts, and Silk Road, thus ending any\nfuture hope of anonymity.\nOn that October morning in Glen Park, Ulbricht was logged in to Silk\nRoad as an administrator. And the FBI knew that because they had been\nobserving his machine logging on to the Internet. But what if he could\nhave faked his location? What if he wasn’t in the library at all but using a\nproxy server instead?\nIn the summer of 2015, researcher Ben Caudill of Rhino Security\nannounced that not only would he be speaking at DEF CON 23 about his\nnew device, ProxyHam, he would also be selling it at cost—around $200—\nin the DEF CON vendors’ room. Then, approximately one week later,\nCaudill announced that his talk was canceled and that all existing\nProxyHam units would be destroyed. He offered no further explanation.3\nTalks at major security conferences get pulled for various reasons.\nEither the companies whose products are being discussed or the federal\ngovernment puts pressure on researchers to not go public. In this case,\nCaudill wasn’t pointing out a particular flaw; he had built something new.\nFunny thing about the Internet: once an idea is out there, it tends to\nremain out there. So even if the feds or someone else convinced Caudill\nthat his talk was not in the interests of national security, it seemed likely\nthat someone else would create a new device. And that’s exactly what\nhappened.\nProxyHam is a very remote access point. Using it is much like putting a\nWi-Fi transmitter in your home or office. Except that the person using and\ncontrolling ProxyHam could be up to a mile away. The Wi-Fi transmitter\nuses a 900 MHz radio to connect to an antenna dongle on a computer as far\nas 2.5 miles away. So in the case of Ross Ulbricht, the FBI could have been\namassing outside the Glen Park library while he was in someone’s\nbasement doing laundry several blocks away.\nThe need for such devices is clear if you live in an oppressed country.\nContacting the outside world through Tor is a risk many take. This kind of\ndevice would add another layer of security by masking the geolocation of\nthe requester.\nExcept someone didn’t want Caudill to speak about it at DEF CON.\nIn interviews Caudill denied that the Federal Communications\nCommission had discouraged him. Wired speculated that secretly planting\na ProxyHam on someone else’s network might be interpreted as\nunauthorized access under America’s draconian and vague Computer\nFraud and Abuse Act. Caudill refuses to comment on any of the\nspeculation.\nAs I said, once an idea is out there, anyone can run with it. So security\nresearcher Samy Kamkar created ProxyGambit, a device that essentially\nreplaces ProxyHam.4 Except it uses reverse cellular traffic, meaning that\ninstead of your being only a few miles from the device when you use it,\nyou could be halfway across the world. Cool!\nProxyGambit and devices like it will of course create headaches for law\nenforcement when criminals decide to use them.\nUlbricht’s Silk Road was an online drug emporium. It was not something\nyou could search for on Google; it was not on what’s called the Surface\nWeb, which can easily be indexed and searched. The Surface Web,\ncontaining familiar sites like Amazon and YouTube, represents only 5\npercent of the entire Internet. All the websites most of you have been to or\nknow about make up a trivial number compared to the actual number of\nsites out there. The vast majority of Internet sites are actually hidden from\nmost search engines.\nAfter the Surface Web, the next biggest chunk of the Internet is what’s\ncalled the Deep Web. This is the part of the Web that is hidden behind\npassword access—for example, the contents of the card catalog for the\nGlen Park branch of the San Francisco Public Library. The Deep Web also\nincludes most subscription-only sites and corporate intranet sites. Netflix.\nPandora. You get the idea.\nFinally, there is a much smaller piece of the Internet known as the Dark\nWeb. This part of the Internet is not accessible through an ordinary\nbrowser, nor is it searchable on sites such as Google, Bing, and Yahoo.\nThe Dark Web is where Silk Road lived, alongside sites where you can\nhire an assassin and acquire child pornography. Sites like these live on the\nDark Web because it is virtually anonymous. I say “virtually” because\nnothing truly ever is.\nAccess to the Dark Web can be gained only through a Tor browser. In\nfact Dark Web sites, with complicated alphanumeric URLs, all end with\n.onion. As I mentioned earlier, the onion router was created by the US\nNaval Research Laboratory to give oppressed people a way to contact each\nother as well as the outside world. I’ve also explained that Tor does not\nconnect your browser directly to a site; rather, it establishes a link to\nanother server, which then attaches to another server to finally reach the\ndestination site. The multiple hops make it harder to trace. And sites such\nas Silk Road are the products of hidden services within the Tor network.\nTheir URLs are generated from an algorithm, and lists of Dark Web sites\nchange frequently. Tor can access both the Surface Web and the Dark Web.\nAnother Dark Web browser, I2P, can also access the Surface Web and Dark\nWeb.\nEven before the takedown of Silk Road, people speculated that the NSA\nor others had a way to identify users on the Dark Web. One way for the\nNSA to do that would be to plant and control what are called exit nodes,\nthe points at which an Internet request is passed to one of these hidden\nservices, though that still wouldn’t allow identification of the initial\nrequester.\nTo do that the government observer would have to see that a request\nwas made to access site X and that a few seconds earlier, someone in New\nHampshire fired up the Tor browser. The observer might suspect that the\ntwo events were related. Over time, access to the site and repeated access\nto Tor around the same time could establish a pattern. One way to avoid\ncreating that pattern is to keep your Tor browser connected at all times.\nIn Ulbricht’s case—he got sloppy. Ulbricht apparently didn’t have a plan\nearly on. In his initial discussions of Silk Road, he alternated between\nusing his real e-mail address and a pseudonymous one.\nAs you can see, it is very hard to operate in the world today without\nleaving traces of your true identity somewhere on the Internet. But as I\nsaid at the outset, with a little bit of care, you, too, can master the art of\ninvisibility. In the following pages, I will show you how."
  },
  {
    "input": "What steps are necessary to maintain online anonymity and how can one ensure that their digital activities remain untraceable to their real identity?",
    "summary": "The chapter discusses how to maintain online anonymity by using separate devices, changing MAC addresses, and avoiding any links between your real identity and anonymous activities. It emphasizes the importance of using tools like Tor and Tails, purchasing prepaid gift cards anonymously, and converting them to Bitcoin through laundering services. Additionally, it highlights the risks of behavioral patterns, such as typing habits, that can reveal your identity even if your IP address is hidden. The goal is to create plausible deniability and avoid being tracked by authorities or investigators.",
    "output": "CHAPTER SIXTEEN\nMastering the Art of Invisibility\nAfter reading this far\n, you might be thinking about your level of\nexperience and how easy (or hard) it will be for you to disappear online.\nOr you might be asking yourself how far you should go or whether any of\nthis is for you. After all, you may not have state secrets to share! You\nmight, however, be fighting your ex in a legal dispute. Or you might be in\na disagreement with your boss. You might be contacting a friend who is\nstill in touch with an abusive family member. Or you might want to keep\nsome activities private and unobservable by a lawyer. There are a variety\nof legitimate reasons why you might need to communicate with others\nonline or to use the Web and other technology anonymously. So…\nWhat steps do you really need to take to go all-in? How long will it\ntake? And how much will it cost?\nIf it’s not abundantly clear by now, to be invisible online you more or\nless need to create a separate identity, one that is completely unrelated to\nyou. That is the meaning of being anonymous. When you’re not being\nanonymous, you must also rigorously defend the separation of your life\nfrom that anonymous identity. What I mean by that is that you need to\npurchase a few separate devices that are only used when you are\nanonymous. And this could get costly.\nYou could, for example, use your current laptop and create what’s\ncalled a virtual machine (VM) on your desktop. A virtual machine is a\nsoftware computer. It is contained within a virtual machine application,\nsuch a VMware Fusion. You can load a licensed copy of Windows 10\ninside a VM and tell it how much RAM you want, how much disk space\nyou need, and so on. To someone observing you on the other side of the\nInternet, it would appear that you are using a Windows 10 machine even if\nin fact you are using a Mac.\nProfessional security researchers use VMs all the time—creating and\ndestroying them easily. But even among professionals there exists the\npossibility of leakage. For example, you might be in your VM version of\nWindows 10 and, for some reason, log in to your personal e-mail account.\nNow that VM can be associated with you.\nSo the first step of being anonymous is purchasing a stand-alone laptop\nthat you will only use for your anonymous online activities. As we have\nseen, the nanosecond that you lapse and, say, check your personal e-mail\naccount on that machine, the anonymity game is over. So I recommend a\nlow-priced Windows laptop (Linux is better, if you know how to use it).\nThe reason I’m not recommending a MacBook Pro is that it’s much more\nexpensive than a Windows laptop.\nPreviously I recommended that you buy a second laptop, specifically, a\nChromebook, to use only for online banking. Another option for online\nbanking would be to use an iPad. You must sign up for an Apple ID using\nyour e-mail address and a credit card, or by purchasing an iTunes gift card.\nBut since this device is only used for your secure personal banking,\ninvisibility is not the goal.\nBut if your objective here is invisibility, a Chromebook is not the best\nsolution because you don’t have the same flexibility as using a laptop with\nWindows or a Linux-based operating system like Ubuntu. Windows 10 is\nokay as long as you skip the option that asks you to sign up for a Microsoft\naccount. You do not want to create any links from your computer to\nMicrosoft whatsoever.\nYou should purchase the new laptop with cash in person, not online—\nthat way the purchase cannot easily be traced to you. Remember, your new\nlaptop has a wireless network card with a unique MAC address. You do not\nwant anyone possibly tracing the equipment to you—in the event your real\nMAC address is somehow leaked. For example, if you’re at a Starbucks\nand power up the laptop, the system will probe for any previously\n“connected to” wireless networks. If there is monitoring equipment in the\narea that logs the probe request, it could possibly result in revealing your\nreal MAC address. One concern is that the government may have a way of\ntracing the purchase of your laptop if any link exists between the MAC\naddress of your network card and the serial number of your computer. If\nso, the feds would only need to find who purchased the specific computer\nto identify you, which probably isn’t so difficult.\nYou should install both Tails (see here) and Tor (see here) and use those\ninstead of the native operating system and browser.\nDo not log in to any sites or applications under your real identity. You\nalready learned the risks based on how easy it is to track people and\ncomputers on the Internet. As we have discussed, using sites or accounts\nunder your real identify is a very bad idea—banks and other sites routinely\nuse device fingerprinting to minimize fraud, and this leaves a huge\nfootprint that can identify your computer if you ever access the same sites\nanonymously.\nIn fact, it’s best to turn your wireless router off before you boot your\nanonymous laptop at home. Your service provider could obtain your\nanonymous laptop’s MAC address if you connect to your home router\n(assuming the provider owns and manages the router in your home). It’s\nalways best to purchase your own home router that you have full control\nover, so the service provider cannot obtain the MAC addresses assigned to\nyour computers on your local network. As such, the service provider will\nonly see the MAC address of your router, which is no risk to you.\nWhat you want is plausible deniability. You want to proxy your\nconnections through multiple layers so that it would very, very hard for an\ninvestigator to ever tie them back to a single person, let alone you. I made\na mistake while still a fugitive. I repeatedly dialed up to modems at\nNetcom—a ghost of Internet service providers past—using a cellular\nphone modem to mask my physical location. Since I was at a fixed\nlocation it was child’s play to use radio direction-finding techniques to\nfind me—once they knew what cellular tower my mobile phone was using\nfor data connections. This allowed my adversary (Tsutomu Shimomura) to\nfind the general location and pass it along to the FBI.1\nWhat this means is that you can’t ever use your anonymous laptop at\nhome or work. Ever. So get a laptop and commit to never using it to check\nyour personal e-mail, Facebook, or even the local weather.2\nAnother way you can be traced online is through the tried-and-true method\nof following the money. You will need to pay for a few things, so prior to\ntaking your anonymous laptop out and finding an open wireless network,\nthe first step is to anonymously purchase some gift cards. Since every\nstore that sells gift cards most likely has surveillance cameras at the kiosk\nor counter, you must exercise extreme caution. You should not purchase\nthese yourself. You should hire a randomly chosen person off the street to\npurchase the gift cards while you wait a safe distance away.\nBut how do you do that? You might approach, as I did, someone in a\nparking lot and say that your ex works in that store over there and you\ndon’t want a confrontation—or offer some other excuse that sounds\nplausible. Perhaps you add that she has a restraining order against you. For\n$100 in cash, making a purchase for you might sound very reasonable to\nsomeone.\nNow that we’ve set up our cutout to go inside the store and purchase a\nhandful of prepaid cards, which cards should he or she purchase? I\nrecommend purchasing a few prepaid, preset $100 cards. Don’t purchase\nany of the refillable credit cards, as you have to provide your real identity\nunder the Patriot Act when you activate them. These purchases require\nyour real name, address, birth date, and a Social Security number that will\nmatch the information about you on file with the credit bureaus. Providing\na made-up name or someone else’s Social Security number is against the\nlaw and is probably not worth the risk.\nWe’re trying to be invisible online, not break the law.\nI recommend having the cutout purchase Vanilla Visa or Vanilla\nMasterCard $100 gift cards from a chain pharmacy, 7-Eleven, Walmart, or\nbig box store. These are often given out as gifts and can be used just as\nregular credit cards would be. For these you do not have to provide any\nidentifying information. And you can purchase them anonymously, with\ncash. If you live in the EU, you should anonymously order a physical\ncredit card using viabuy.com. In Europe they can ship the cards to the post\noffice, which requires no ID to pick up. My understanding is that they send\nyou a PIN code, and you can open up the drop box with the PIN to\nanonymously pick up the cards (assuming there is no camera).\nSo where can you use your new laptop and anonymously purchased\nprepaid cards?\nWith the advent of inexpensive optical storage devices, businesses\nproviding free wireless access can store surveillance camera footage for\nyears. For an investigator it is relatively easy to get that footage and look\nfor potential suspects. During the time of your visit, the investigator can\nanalyze the logs—searching for MAC addresses authenticated on the\nwireless network that match your MAC address. That’s why it’s important\nto change your MAC address each time you connect to a free wireless\nnetwork. So you need to find a location near or adjacent to one that offers\nfree Wi-Fi. For example, there may be a Chinese restaurant next door to a\nStarbucks or other establishment that offers free wireless access. Sit at a\ntable near the wall adjoining the service provider. You might experience\nslightly slower connection speeds, but you will have relative anonymity\n(at least until the investigator starts looking at all the surveillance footage\nfrom the surrounding area).\nYour MAC address will likely be logged and stored once you\nauthenticate on the free wireless network. Remember General David\nPetraeus’s mistress? Remember that the times and dates of her hotel\nregistrations matched the times and dates of her MAC address’s\nappearance on the hotel’s network? You don’t want simple mistakes like\nthese to compromise your anonymity. So remember to change your MAC\naddress each time you access public Wi-Fi (see here).\nSo far this seems pretty straightforward. You want to buy a separate\nlaptop from which you will do your anonymous activity. You want to\nanonymously purchase some gift cards. You want to find a Wi-Fi network\nthat you can access from a near or adjacent site to avoid being seen on\ncamera. And you want to change your MAC address every time you\nconnect to a free wireless network.\nOf course there’s more. Much more. We’re only getting started.\nYou might also want to hire a second cutout, this time to make a more\nimportant purchase: a personal hotspot. As I mentioned before, the FBI\ncaught me because I was dialing up to systems around the world using my\ncellular phone and modem, and over time my fixed location was\ncompromised because my mobile phone was connected to the same\ncellular tower. At that point it was easy to use radio-direction finding to\nlocate the transceiver (my cell phone). You can avoid that by hiring\nsomeone to go into a Verizon store (or AT&T or T-Mobile) and purchase a\npersonal hotspot that allows you to connect to the Internet using cellular\ndata. That means you have your own local access to the Internet, so you\ndon’t have to go through a public Wi-Fi network. Most important, you\nshould never use a personal hotspot in a fixed location for too long when\nyou need to maintain your anonymity.\nIdeally the person you hire won’t see your license plate or have any\nway to identify you. Give the person cash: $200 for the hotspot and\nanother $100 when the person returns with the hotspot. The mobile\noperator will sell the cutout a personal hotspot that carries no identifying\ninformation. And while you’re at it, why not purchase a few refill cards to\nadd more data? Hopefully the cutout won’t abscond with your money, but\nit’s a worthwhile risk for anonymity. Later you can refill the burner device\nusing Bitcoin.3\nOnce you have anonymously purchased a portable hotspot, it is very\nimportant that, as with the laptop, you never, never, never turn the device\non at home. Every time the hotspot is turned on, it registers with the\nclosest cellular tower. You don’t want your home or office or anyplace you\nfrequent to show up in the mobile operator’s log files.\nAnd never turn on your personal phone or personal laptop in the same\nlocation where you turn on your anonymous laptop or burner phone or\nanonymous hotspot. The separation is really important. Any record that\nlinks you to your anonymous self at a later date and time negates the\nwhole operation.\nNow, armed with prepaid gift cards and a personal hotspot with a\nprepaid data plan—both purchased anonymously by two very different\npeople who wouldn’t have any information about you to identify you to\nthe police—we’re almost set. Almost.\nFrom this point on, the Tor browser should always be used to create and\naccess all online accounts because it constantly changes your IP address.\nOne of the first steps is to set up a couple of anonymous e-mail\naccounts using Tor. This was something that Ross Ulbricht neglected to do.\nAs we saw in the previous chapter, he used his personal e-mail account\nmore than once while conducting his Silk Road business on the Dark Web.\nThese unintentional crossovers from Dread Pirate Roberts to Ross Ulbricht\nand back again helped investigators confirm that the two names were\nassociated with one person.\nTo prevent abuse, most e-mail providers—such as Gmail, Hotmail,\nOutlook, and Yahoo—require mobile phone verification. That means you\nhave to provide your mobile number and, immediately during the sign-up\nprocess, a text message is sent to that device to confirm your identity.\nYou can still use a commercial service like the ones mentioned above if\nyou use a burner phone. However, that burner phone and any refill cards\nmust be obtained securely—i.e., purchased in cash by a third party who\ncannot be traced back to you. Also, once you have a burner phone, you\ncannot use it when you’re close to any other cellular devices you own.\nAgain, leave your personal phone at home.\nIn order to purchase Bitcoin online, you are going to need at least two\nanonymously created e-mail addresses and Bitcoin wallets. So how do you\ncreate anonymous e-mail addresses like those created by Edward Snowden\nand Laura Poitras?\nIn my research, I found I was able to create an e-mail account on\nprotonmail.com and one on tutanota.com using Tor, both without any\nrequests to verify my identity. Neither of these two e-mail providers asked\nme for verification upon setup. You can conduct your own research by\nsearching for e-mail providers and checking to see whether they require\nyour mobile phone number during the sign-up process. You can also see\nhow much information they need to create the new accounts. Another e-\nmail option is fastmail.com, which is not nearly as feature rich as Gmail,\nbut because it is a paid service, there is no mining of user data or\ndisplaying of ads.\nSo now we have a laptop, with Tor and Tails loaded, a burner phone, a\nhandful of anonymous prepaid gift cards, and an anonymous hotspot with\nan anonymously purchased data plan. We’re still not ready. To maintain\nthis anonymity, we need to convert our anonymously purchased prepaid\ngift cards to Bitcoin.\nIn chapter 6 I talked about Bitcoin, virtual currency. By itself Bitcoin is\nnot anonymous. They can be traced through what’s called a blockchain\nback to the source of the purchase; similarly, all subsequent purchases can\nbe traced as well. So Bitcoin by itself is not going to hide your identity. We\nwill have to run the funds through an anonymity mechanism: converting\nprepaid gift cards into Bitcoin, then running the Bitcoin through a\nlaundering service. This process will result in anonymized Bitcoin to be\nused for future payments. We will need the laundered Bitcoin, for\nexample, to pay for our VPN service and any future purchases of data\nusage on our portable hotspot or burner phone.\nUsing Tor, you can set up an initial Bitcoin wallet at paxful.com or\nother Bitcoin wallet sites. Some sites broker deals in which you can buy\nBitcoin with prepaid gift cards, such as those preset Vanilla Visa and\nVanilla MasterCard gift cards I mentioned earlier. The downside is that\nyou will pay a huge premium for this service, at least 50 percent.\nPaxful.com is more like an eBay auction site where you find Bitcoin\nsellers—the site just connects you with buyers and sellers.\nApparently anonymity has a high cost. The less identity information\nyou provide in a transaction, the more you’ll pay. That makes sense: the\npeople selling the Bitcoin are taking a huge risk by not verifying your\nidentity. I was able to purchase Bitcoin in exchange for my anonymously\npurchased Vanilla Visa gift cards at a rate of $1.70 per dollar, which is\noutrageous but necessary to ensure anonymity.\nI mentioned that Bitcoin by itself is not anonymous. For example, there\nis a record that I exchanged certain prepaid gift cards for Bitcoin. An\ninvestigator could trace my Bitcoin back to the gift cards.\nBut there are ways to launder Bitcoin, obscuring any link back to me.\nMoney laundering is something that criminals do all the time. It is\nmost often used in drug trafficking, but it also plays a role in white-collar\nfinancial crime. Laundering means that you disguise the original\nownership of the funds, often by sending the money out of the country, to\nmultiple banks in countries that have strict privacy laws. Turns out you\ncan do something similar with virtual currency.\nThere are services called tumblers that will take Bitcoin from a variety\nof sources and mix—or tumble—them together so that the resulting\nBitcoin retains its value but carries traces of many owners. This makes it\nhard for someone to say later which owner made a certain purchase. But\nyou have to be extremely careful, because there are tons of scams out\nthere.\nI took a chance. I found a laundering service online and they took an\nextra fee out of the transaction. I actually got the Bitcoin value that I\nwanted. But think about this: that laundering service now has one of my\nanonymous e-mail addresses and both Bitcoin addresses that were used in\nthe transaction. So to further mix things up, I had the Bitcoin delivered to\na second Bitcoin wallet that was set up by opening a new Tor circuit,\nwhich established new hops between me and the site I wanted to visit.\nNow the transaction is thoroughly obfuscated, making it very hard for\nsomeone to come along later and figure out that the two Bitcoin addresses\nare owned by the same person. Of course, the Bitcoin laundering service\ncould cooperate with third parties by providing both Bitcoin addresses.\nThat’s why it’s so important to securely purchase the prepaid gift cards.\nAfter using the gift cards to purchase Bitcoin, remember to securely\ndispose of the plastic cards (not in your trash at home). I recommend using\na cross-cut shredder that’s rated for plastic cards, then disposing of the\nshreds in a random dumpster away from your home or office. Once the\nlaundered Bitcoin has been received, you can sign up for a VPN service\nthat makes your privacy a priority. The best policy when you are trying to\nbe anonymous is simply not to trust any VPN provider, especially those\nthat claim not to retain any logs. Chances are they’ll still cough up your\ndetails if contacted by law enforcement or the NSA.\nFor example, I cannot imagine any VPN provider not being able to\ntroubleshoot issues within its own network. And troubleshooting requires\nkeeping some logs—e.g., connection logs that could be used to match\ncustomers to their originating IP addresses.\nSo because even the best of these providers cannot be trusted, we will\npurchase a VPN service using laundered Bitcoin through the Tor browser. I\nsuggest reviewing a VPN provider’s terms of service and privacy policies\nand find the one that seems the best of the bunch. You’re not going to find\na perfect match, only a good one. Remember that you cannot trust any\nprovider to maintain your anonymity. You have to do it yourself with the\nunderstanding that a single error can reveal your true identity.\nNow, with a stand-alone laptop, running either Tor or Tails, using a\nVPN provider purchased with laundered Bitcoin, over an anonymously\npurchased hotspot, and with a supply of even more laundered Bitcoin, you\nhave completed the easy part: the setup. This will cost you a couple of\nhundred bucks, perhaps five hundred, but all the pieces have been\nrandomized so that they can’t easily be connected back to you. Now comes\nthe hard part—maintaining that anonymity.\nAll the setup and processes we’ve just gone through can be lost in a second\nif you use the anonymous hotspot at home, or if you power on your\npersonal cell phone, tablet, or any other cellular device linked to your real\nidentity at the physical location where you are using your anonymous\nidentity. It only takes one slip by you for a forensic investigator to be able\nto correlate your presence to a location by analyzing the cellular\nprovider’s logs. If there is a pattern of anonymous access at the same time\nyour cellular device is registered in the same cell site, it could lead to\nunmasking your true identity.\nI’ve already given a number of examples of this.\nNow, should your anonymity be compromised and should you decide to\nengage in another anonymous activity, you might need to go through this\nprocess once again—wiping and reinstalling the operating system on your\nanonymous laptop and creating another set of anonymous e-mail accounts\nwith Bitcoin wallets and purchasing another anonymous hotspot.\nRemember that Edward Snowden and Laura Poitras, both of whom already\nhad anonymous e-mail accounts, set up additional anonymous e-mail\naccounts so they could communicate specifically with each other. This is\nonly necessary if you suspect that the original anonymity you’ve\nestablished is compromised. Otherwise you could use the Tor browser\n(after establishing a new Tor circuit) through the anonymous hotspot and\nVPN to access the Internet using a different persona.\nOf course, how much or how little you choose to follow these\nrecommendations is up to you.\nEven if you follow my recommendations, it is still possible for someone\non the other end to recognize you. How? By the way you type.\nThere is a considerable body of research that has focused on the\nspecific word choices people make when writing e-mails and commenting\non social media posts. By looking at those words, researchers can often\nidentify sex and ethnicity. But beyond that they cannot be more specific.\nOr can they?\nIn World War II the British government set up a number of listening\nstations around the country to intercept signals from the German military.\nThe advances that led to the Allies decrypting these messages came a bit\nlater—at Bletchley Park, the site of the Government Code and Cypher\nSchool, where the German Enigma code was broken. Early on, the people\nat Bletchley Park intercepting the German telegraph messages could\nidentify certain unique characteristics of a sender based on the intervals\nbetween the dots and the dashes. For example, they could recognize when\na new telegraph operator came on, and they even started giving the\noperators names.\nHow could mere dots and dashes reveal the people behind them?\nWell, the time interval between the sender’s tapping of a key and the\ntapping of the key again can be measured. This method of differentiation\nlater became known as the Fist of the Sender. Various Morse code key\noperators could be identified by their unique “fists.” It wasn’t what the\ntelegraph was designed to do (who cares who sent the message; what was\nthe message?), but in this case the unique tapping was an interesting by-\nproduct.\nToday, with advances in digital technology, electronic devices can\nmeasure the nanosecond differences in the way each person presses keys\non computer keyboards—not only the length of time a given key is held\nbut also how quickly the next key follows. It can tell the difference\nbetween someone who types normally and someone who hunts and pecks\nat the keyboard. That, coupled with the words chosen, can reveal a lot\nabout an anonymous communication.\nThis is a problem if you’ve gone through the trouble of anonymizing\nyour IP address. The site on the other side can still recognize you—not\nbecause of something technical but because of something uniquely human.\nThis is also known as behavioral analysis.\nLet’s say a Tor-anonymized website decides to track your keystroke\nprofile. Maybe the people behind it are malicious and just want to know\nmore about you. Or maybe they work with law enforcement.\nMany financial institutions already use keystroke analysis to further\nauthenticate account holders. That way if someone does have your\nusername and password, he or she can’t really fake the cadence of your\ntyping. That’s reassuring when you want to be authenticated online. But\nwhat if you don’t?\nBecause keystroke analysis is so disturbingly easy to deploy,\nresearchers Per Thorsheim and Paul Moore created a Chrome browser\nplug-in called Keyboard Privacy. The plug-in caches your individual\nkeystrokes and then plays them out at different intervals. The idea is to\nintroduce randomness in your normal keystroke cadence as a means of\nachieving anonymity online. The plug-in might further mask your\nanonymous Internet activities.4\nAs we have seen, maintaining the separation between your real life and\nyour anonymous life online is possible, but it requires constant vigilance.\nIn the previous chapter I talked about some spectacular failures at being\ninvisible. These were glorious but short-term attempts at invisibility.\nIn the case of Ross Ulbricht, he didn’t really plan his alter ego very\ncarefully, occasionally using his real e-mail address instead of an\nanonymous one, particularly in the beginning. Through the use of a Google\nadvanced search, an investigator was able to piece together enough\ninformation to reveal the mysterious owner of Silk Road.\nSo what about Edward Snowden and others like him who are concerned\nabout their surveillance by one or more government agencies? Snowden,\nfor example, has a Twitter account. As do quite a few other privacy folks\n—how else might I engage them in a round of feisty conversation online?\nThere are a couple of possibilities to explain how these people remain\n“invisible.”\nThey’re not under active surveillance. Perhaps a government or\ngovernment agency knows exactly where its targets are but doesn’t care.\nIn that case, if the targets aren’t breaking any laws, who’s to say they\nhaven’t let their guard down at some point? They might claim to only use\nTor for their anonymous e-mails, but then again they might be using that\naccount for their Netflix purchases as well.\nThey’re under surveillance, but they can’t be arrested. I think that\nmight very well describe Snowden. It is possible he has slipped regarding\nhis anonymity at some point and that he is now being actively tracked\nwherever he goes—except he’s living in Russia. Russia has no real reason\nto arrest him and return him to the United States.\nYou’ll notice I said “slipped”: unless you have amazing attention to\ndetail, it’s really hard to live two lives. I know. I’ve done it. I let my guard\ndown by using a fixed location when accessing computers through a\ncellular phone network.\nThere’s a truism in the security business that a persistent attacker will\nsucceed given enough time and resources. I succeed all the time when\ntesting my client’s security controls. All you are really doing by trying to\nmake yourself anonymous is putting up so many obstacles that an attacker\nwill give up and move on to another target.\nMost of us only have to hide for a little while. To avoid that boss who is\nout to get you fired. To avoid that ex whose lawyers are looking for\nsomething, anything, to hold against you. To evade that creepy stalker who\nsaw your picture on Facebook and is determined to harass you. Whatever\nyour reason for being invisible, the steps I’ve outlined will work long\nenough to get you out from under a bad situation.\nBeing anonymous in today’s digital world requires a lot of work and\nconstant vigilance. Each person’s requirements for anonymity differ—do\nyou need to protect your passwords and keep private documents away\nfrom your coworkers? Do you need to hide from a fan who is stalking you?\nDo you need to evade law enforcement because you’re a whistleblower?\nYour individual requirements will dictate the necessary steps you need\nto take to maintain your desired level of anonymity—from setting strong\npasswords and realizing that your office printer is out to get you all the\nway to going through the steps detailed here to make it extremely difficult\nfor a forensic investigator to discover your true identity.\nIn general, though, we can all learn something about how to minimize\nour fingerprints in the digital world. We can think before posting that\nphoto with a home address visible in the background. Or before providing\na real birth date and other personal information on our social media\nprofiles. Or before browsing the Internet without using the HTTPS\nEverywhere extension. Or before making confidential calls or sending\ntexts without using an end-to-end encryption tool such as Signal. Or before\nmessaging a doctor through AOL, MSN Messenger, or Google Talk\nwithout OTR. Or before sending a confidential e-mail without using PGP\nor GPG.\nWe can think proactively about our information and realize that even if\nwhat we’re doing with it feels benign—sharing a photograph, forgetting to\nchange default log-ins and passwords, using a work phone for a personal\nmessage, or setting up a Facebook account for our kids—we’re actually\nmaking decisions that carry a lifetime of ramifications. So we need to act.\nThis book is all about staying online while retaining our precious\nprivacy. Everyone—from the most technologically challenged to\nprofessional security experts—should make a committed practice of\nmastering this art, which becomes more essential with each passing day:\nthe art of invisibility."
  },
  {
    "input": "What are the key points discussed in the acknowledgments section of the book \"The Art of Invisibility\"?",
    "summary": "The book is dedicated to the author's mother and grandmother, who supported him through personal struggles. It was written with the help of security expert Robert Vamosi and includes insights from various professionals and organizations. The author aims to educate readers on protecting their privacy in an era of surveillance and spying, emphasizing the importance of anonymity and security in the digital world.",
    "output": "Acknowledgments\nThis book is dedicated to\nmy loving mother, Shelly Jaffe, and my\ngrandmother Reba Vartanian, who both sacrificed a great deal for me all\nmy life. No matter what situation I got myself into, my mom and Gram\nwere always there for me, especially in my times of need. This book would\nnot have been possible without my wonderful family, who has given me so\nmuch unconditional love and support throughout my life.\nOn April 15, 2013, my mother passed away after a long struggle with\nlung cancer. It came after years of hardship and struggling to deal with the\neffects of chemotherapy. There were few good days after the terrible\ntreatments used in modern medicine to fight off these types of cancers.\nUsually patients have a very short time—typically it is only months before\nthey succumb to the disease. I feel very fortunate for the time I was able to\nspend with her while she was fighting this horrible battle. I am so grateful\nto have been raised by such a loving and dedicated mother, whom I also\nconsider my best friend. My mom is such an amazing person and I miss\nher incredibly so.\nOn March 7, 2012, my grandmother passed away unexpectedly while\nbeing treated at Sunrise Hospital in Las Vegas. Our family was expecting\nher to return home, but it never happened. For the past several years\nleading up to my grandmother passing away, her heart was in constant\nsadness because of my mother’s battle with cancer. She is missed terribly\nand I wish she were here to enjoy this accomplishment.\nI hope this book will bring much happiness to my mother’s and\ngrandmother’s hearts and make them proud that I’m helping to protect\npeople’s right to privacy.\nI wish my dad, Alan Mitnick, and my brother, Adam Mitnick, were\nhere to celebrate the publication of this important book on becoming\ninvisible when spying and surveillance is now the norm.\nI have had the good fortune of being teamed up with security and\nprivacy expert Robert Vamosi to write this book. Rob’s notable knowledge\nin security and skills as a writer include his ability to find compelling\nstories, research these topics, and take information provided by me and\nwrite it up in such a style and manner that any nontechnical person could\nunderstand it. I must tip my hat to Rob, who did a tremendous amount of\nhard work on this project. Truthfully, I couldn’t have done it without him.\nI’m eager to thank those people who represent my professional career\nand are dedicated in extraordinary ways. My literary agent, David Fugate\nof LaunchBooks, negotiated the book contract and acted as a liaison with\nthe publisher, Little, Brown. The concept of The Art of Invisibility was\ncreated by John Rafuse of 121 Minds, who is my agent for speaking\nengagements and endorsements, and he also performs strategic business\ndevelopment for my company. Entirely upon his own initiative, John gave\nme an intriguing book proposal, along with a mock-up of the cover. He\nstrongly encouraged me to write this book to help educate the world’s\npopulation on how to protect their personal privacy rights from the\noverstepping of Big Brother and Big Data. John is awesome.\nI’m grateful to have had the opportunity to work with Little, Brown on\ndeveloping this exciting project. I wish to thank my editor, John Parsley,\nfor all his hard work and great advice on this project. Thank you, John.\nI wish to thank my friend Mikko Hypponen, chief research officer of F-\nSecure, for spending his valuable time penning the foreword for this book.\nMikko is a highly respected security and privacy expert who has focused\non malware research for over twenty-five years.\nI would also like to thank Tomi Tuominen of F-Secure for taking time\nout of his busy schedule to do a technical review of the manuscript and\nhelp spot any errors and catch anything that was overlooked.\nAbout the Author\nKEVIN MITNICK has been the subject of countless profiles published and\nbroadcast throughout the world. Mitnick’s leading penetration-testing\nteam is highly respected and sought after for its security services by the\nworld’s top corporations and governments. The company he founded,\nMitnick Security Consulting LLC, has clients that include dozens from the\nFortune 500 and many nations across the globe. Mitnick is the bestselling\nauthor of Ghost in the Wires, The Art of Intrusion, and The Art of\nDeception. He lives in Las Vegas and travels the world as the top keynote\nspeaker on cybersecurity.\nmitnicksecurity.com\ntwitter.com/kevinmitnick\nBooks by Kevin Mitnick\nThe Art of Invisibility (with Robert Vamosi)\nGhost in the Wires (with William L. Simon)\nThe Art of Intrusion (with William L. Simon)\nThe Art of Deception (with William L. Simon)\nNotes\nAll source URLs cited below were accurate as of the original writing of\nthis book, July 2016.\nIntroduction: Time to Disappear\n1. https://www.youtube.com/watch?t=33&v=XEVlyP4_11M.\n2. Snowden first went to Hong Kong before receiving permission to live\nin Russia. He has since applied to live in Brazil and other nations and\nhas not ruled out a return to the United States if he were to receive a\nfair trial.\n3. http://www.reuters.com/article/2011/02/24/idUSN2427826420110224.\n4. https://www.law.cornell.edu/supct/html/98-93.ZD.html.\n5. https://www.law.cornell.edu/uscode/text/16/3372.\n6. http://www.wired.com/2013/06/why-i-have-nothing-to-hide-is-the-\nwrong-way-to-think-about-surveillance/.\nChapter One: Your Password Can Be Cracked!\n1. https://www.apple.com/pr/library/2014/09/02Apple-Media-\nAdvisory.html.\n2. http://anon-ib.com/. Please note this site is not safe for work and may\nalso contain disturbing images as well.\n3. http://www.wired.com/2014/09/eppb-icloud/.\n4. https://www.justice.gov/usao-mdpa/pr/lancaster-county-man-\nsentenced-18-months-federal-prison-hacking-apple-and-google-e-\nmail.\n5. http://arstechnica.com/security/2015/09/new-stats-show-ashley-\nmadison-passwords-are-just-as-weak-as-all-the-rest/.\n6. http://www.openwall.com/john/.\n7. “MaryHadALittleLamb123$” as rendered by\nhttp://www.danstools.com/md5-hash-generator/.\n8. http://news.bbc.co.uk/2/hi/technology/3639679.stm.\n9. http://www.consumerreports.org/cro/news/2014/04/smart-phone-\nthefts-rose-to-3-1-million-last-year/index.htm.\n10. http://www.mercurynews.com/california/ci_26793089/warrant-chp-\nofficer-says-stealing-nude-photos-from.\n11. http://arstechnica.com/security/2015/08/new-data-uncovers-the-\nsurprising-predictability-of-android-lock-patterns/.\n12. http://www.knoxnews.com/news/local/official-explains-placing-david-\nkernell-at-ky-facility-ep-406501153-358133611.html.\n13. http://www.wired.com/2008/09/palin-e-mail-ha/.\n14. http://fusion.net/story/62076/mothers-maiden-name-security-\nquestion/.\n15.\nhttp://web.archive.org/web/20110514200839/http://latimesblogs.latim\nes.com/webscout/2008/09/4chans-half-hac.html.\n16. http://www.commercialappeal.com/news/david-kernell-ut-student-in-\npalin-email-case-is-released-from-supervision-ep-361319081-\n326647571.html;\nhttp://edition.cnn.com/2010/CRIME/11/12/tennessee.palin.hacking.cas\ne/.\n17. http://www.symantec.com/connect/blogs/password-recovery-scam-\ntricks-users-handing-over-email-account-access.\n18. https://techcrunch.com/2016/06/10/how-activist-deray-mckessons-\ntwitter-account-was-hacked/.\nChapter Two: Who Else Is Reading Your E-mail?\n1. In case you’re wondering, images of child sexual abuse are identified\nand tagged by the National Center for Missing and Exploited Children,\nwhich is how Google and other search engine companies’ automated\nscanning system distinguishes those images from the nonpornographic\nimages on their networks. See\nhttp://www.dailymail.co.uk/news/article-2715396/Google-s-email-\nscan-helps-catch-sex-offender-tips-police-indecent-images-children-\nGmail-account.html.\n2. http://www.braingle.com/brainteasers/codes/caesar.php.\n3. https://theintercept.com/2014/10/28/smuggling-snowden-secrets/.\n4. For example, see the list here:\nhttps://en.wikipedia.org/wiki/Category:Cryptographic_algorithms.\n5. Mailvelope works with Outlook, Gmail, Yahoo Mail, and several other\nWeb-based e-mail services. See https://www.mailvelope.com/.\n6. To see the metadata on your Gmail account, choose a message, open it,\nthen click the down arrow in the upper right corner of the message.\nAmong the choices (“Reply,” “Reply All,” “Forward,” and so on) is\n“Show Original.” In Apple Mail, select the message, then choose\nView>Message>All Headers. In Yahoo, click “More,” then “View Full\nHeader.” Similar options appear in other mail programs.\n7. http://www.bbc.com/future/story/20150206-biggest-myth-about-\nphone-privacy.\n8. https://immersion.media.mit.edu/.\n9. http://www.npr.org/2013/06/13/191226106/fisa-court-appears-to-be-\nrubberstamp-for-government-requests.\n10. You can type “IP Address” into the Google search window to see your\nown IP address at the time of the request.\n11. https://play.google.com/store/apps/details?id=org.torproject.android.\n12. http://www.wired.com/threatlevel/2014/01/tormail/.\n13. https://www.theguardian.com/technology/2014/oct/28/tor-users-\nadvised-check-computers-malware.\n14. http://arstechnica.com/security/2014/07/active-attack-on-tor-network-\ntried-to-decloak-users-for-five-months/.\n15. For the Tor box on a Raspberry Pi, you can use something like Portal:\nhttps://github.com/grugq/PORTALofPi.\n16. https://www.skype.com/en/features/online-number/.\n17. http://www.newyorker.com/magazine/2007/02/19/the-kona-files.\n18. Again, it’s probably best not to use Google or large e-mail providers,\nbut for the sake of illustration I’m using it here.\nChapter Three: Wiretapping 101\n1. You can opt out of sharing your personal data with commuting services\non the Android. Go to Settings>Search & Now>Accounts &\nprivacy>Commute sharing. Apple does not provide a similar service,\nbut future versions of iOS may help you plan trips based on where your\nphone is at a given moment.\n2. http://www.abc.net.au/news/2015-07-06/nick-mckenzie-speaks-out-\nabout-his-brush-with-the-mafia/6596098.\n3. You would actually purchase a refill card that you would use with the\nphone itself. Best to use Bitcoin to do it.\n4. https://www.washingtonpost.com/news/the-\nswitch/wp/2014/12/18/german-researchers-discover-a-flaw-that-could-\nlet-anyone-listen-to-your-cell-calls-and-read-your-texts/.\n5. http://arstechnica.com/gadgets/2010/12/15-phone-3-minutes-all-thats-\nneeded-to-eavesdrop-on-gsm-call/.\n6. http://www.latimes.com/local/la-me-pellicano5mar05-\nstory.html#navtype=storygallery.\n7.\nhttp://www.nytimes.com/2008/03/24/business/media/24pellicano.html\n?pagewanted=all.\n8. https://www.hollywoodreporter.com/thr-esq/anthony-pellicanos-\nprison-sentence-vacated-817558.\n9. http://www.cryptophone.de/en/products/landline/.\n10. https://www.kickstarter.com/projects/620001568/jackpair-safeguard-\nyour-phone-conversation/posts/1654032.\n11. http://spectrum.ieee.org/telecom/security/the-athens-affair.\n12. http://bits.blogs.nytimes.com/2007/07/10/engineers-as-counterspys-\nhow-the-greek-cellphone-system-was-bugged/.\n13. https://play.google.com/store/apps/details?\nid=org.thoughtcrime.redphone.\nChapter Four: If You Don’t Encrypt, You’re Unequipped\n1. http://caselaw.findlaw.com/wa-supreme-court/1658742.html.\n2.\nhttp://courts.mrsc.org/mc/courts/zsupreme/179wn2d/179wn2d0862.ht\nm.\n3. http://www.komonews.com/news/local/Justices-People-have-right-to-\nprivacy-in-text-messages-247583351.html.\n4.\nhttp://www.democracynow.org/2016/10/26/headlines/project_hemisphe\nre_at_ts_secret_program_to_spy_on_americans_for_profit.\n5. http://www.wired.com/2015/08/know-nsa-atts-spying-pact/.\n6. http://espn.go.com/nfl/story/_/id/13570716/tom-brady-new-england-\npatriots-wins-appeal-nfl-deflategate.\n7. https://www.bostonglobe.com/sports/2015/07/28/tom-brady-destroyed-\nhis-cellphone-and-texts-along-\nwith/ZuIYu0he05XxEeOmHzwTSK/story.html.\n8. DES was cracked partly because it only encrypted the data once. AES\nuses three layers of encryption and is therefore much stronger, even\nindependent of the number of bits.\n9. Diskreet is no longer available.\n10. https://twitter.com/kevinmitnick/status/346065664592711680. This\nlink provides a more technical explanation of the thirty-two-bit DES\nused: https://www.cs.auckland.ac.nz/~pgut001/pubs/norton.txt.\n11. http://www.theatlantic.com/technology/archive/2014/06/facebook-\ntexting-teens-instagram-snapchat-most-popular-social-\nnetwork/373043/.\n12. http://www.pewinternet.org/2015/04/09/teens-social-media-\ntechnology-2015.\n13. http://www.forbes.com/sites/andygreenberg/2014/02/21/whatsapp-\ncomes-under-new-scrutiny-for-privacy-policy-encryption-gaffs/.\n14. https://www.wired.com/2016/10/facebook-completely-encrypted-\nmessenger-update-now/.\n15. https://community.skype.com/t5/Security-Privacy-Trust-and/Skype-to-\nSkype-call-recording/td-p/2064587.\n16. https://www.eff.org/deeplinks/2011/12/effs-raises-concerns-about-\nnew-aol-instant-messenger-0.\n17. http://www.wired.com/2007/05/always_two_ther/.\n18. http://venturebeat.com/2016/08/02/hackers-break-into-telegram-\nrevealing-15-million-users-phone-numbers/.\n19. http://www.csmonitor.com/World/Passcode/2015/0224/Private-chat-\napp-Telegram-may-not-be-as-secretive-as-advertised.\n20. https://otr.cypherpunks.ca/.\n21. https://chatsecure.org/.\n22. https://guardianproject.info/apps/chatsecure/.\n23. https://crypto.cat/.\n24. https://getconfide.com/.\nChapter Five: Now You See Me, Now You Don’t\n1. https://www.techdirt.com/articles/20150606/16191831259/according-\nto-government-clearing-your-browser-history-is-felony.shtml.\n2. http://www.cbc.ca/news/trending/clearing-your-browser-history-can-\nbe-deemed-obstruction-of-justice-in-the-u-s-1.3105222.\n3. http://ftpcontent2.worldnow.com/whdh/pdf/Matanov-Khairullozhon-\nindictment.pdf.\n4. https://www.eff.org/https-everywhere%20.\n5. http://www.tekrevue.com/safari-sync-browser-history/.\n6. http://www.theguardian.com/commentisfree/2013/aug/01/government-\ntracking-google-searches.\n7. https://myaccount.google.com/intro/privacy.\n8. http://www.fastcompany.com/3026698/inside-duckduckgo-googles-\ntiniest-fiercest-competitor.\nChapter Six: Every Mouse Click You Make, I’ll Be Watching You\n1. https://timlibert.me/pdf/Libert-2015-Health_Privacy_on_Web.pdf.\n2. An informal test conducted while writing this book showed that the\nGhostery plug-in on Chrome blocked up to twenty-one requests from\npartners of the Mayo Clinic and twelve requests from partners of\nWebMD when returning results for “athlete’s foot.”\n3. For a more detailed look at what information your browser leaks,\ncheck out http://browserspy.dk/.\n4. https://noscript.net/.\n5.\nhttps://chrome.google.com/webstore/detail/scriptblock/hcdjknjpbnhdo\nabbngpmfekaecnpajba?hl=en.\n6. https://www.ghostery.com/en/download?src=external-ghostery.com.\n7. By “mail drop” I mean commercial mailbox outfits such as the UPS\nStore, although many do require a photo ID before you can obtain one.\n8. http://www.wired.com/2014/10/verizons-perma-cookie/.\n9. http://www.pcworld.com/article/2848026/att-kills-the-permacookie-\nstops-tracking-customers-internet-usage-for-now.html.\n10. http://www.verizonwireless.com/support/unique-identifier-header-\nfaqs/.\n11. http://www.reputation.com/blog/privacy/how-disable-and-delete-flash-\ncookies; http://www.brighthub.com/computing/smb-\nsecurity/articles/59530.aspx.\n12. http://en.wikipedia.org/wiki/Samy_Kamkar.\n13. https://github.com/samyk/evercookie.\n14. http://venturebeat.com/2015/07/14/consumers-want-privacy-yet-\ndemand-personalization/.\n15. http://www.businessinsider.com/facebook-will-not-honor-do-not-track-\n2014-6.\n16. https://chrome.google.com/webstore/detail/facebook-\ndisconnect/ejpepffjfmamnambagiibghpglaidiec?hl=en.\n17. https://facebook.adblockplus.me/.\n18. https://zephoria.com/top-15-valuable-facebook-statistics/.\n19. http://www.latimes.com/business/la-fi-lazarus-20150417-column.html.\n20. https://www.propublica.org/article/meet-the-online-tracking-device-\nthat-is-virtually-impossible-to-block#.\n21. https://addons.mozilla.org/en-us/firefox/addon/canvasblocker/.\n22.\nhttps://chrome.google.com/webstore/detail/canvasfingerprintblock/ip\nmjngkmngdcdpmgmiebdmfbkcecdndc?hl=en-US.\n23. https://trac.torproject.org/projects/tor/ticket/6253.\n24. https://www.technologyreview.com/s/538731/how-ads-follow-you-\nfrom-phone-to-desktop-to-tablet/.\n25. https://theintercept.com/2014/10/28/smuggling-snowden-secrets/.\nChapter Seven: Pay Up or Else!\n1. http://www.computerworld.com/article/2511814/security0/man-used-\nneighbor-s-wi-fi-to-threaten-vice-president-biden.html.\n2. http://www.computerworld.com/article/2476444/mobile-security-\ncomcast-xfinity-wifi-just-say-no.html.\n3. http://customer.xfinity.com/help-and-support/internet/disable-xfinity-\nwifi-home-hotspot/.\n4. BitTorrent is a streaming video service for movies, some of which are\nprovided by sources other than the copyright holders.\n5. http://blog.privatewifi.com/why-six-strikes-could-be-a-nightmare-for-\nyour-internet-privacy/.\n6. There is also the basic service set (BSS), which provides the basic\nbuilding block of an 802.11 wireless LAN (local area network). Each\nBSS or ESS (extended service set) is identified by a service set\nidentifier (SSID).\n7. http://www.techspot.com/guides/287-default-router-ip-addresses/.\n8. http://www.routeripaddress.com/.\n9. It’s easy to figure out the MAC address of authorized devices by using\na penetration-test tool known as Wireshark.\n10. https://www.pwnieexpress.com/blog/wps-cracking-with-reaver.\n11. http://www.wired.com/2010/10/webcam-spy-settlement/.\n12. http://www.telegraph.co.uk/technology/internet-\nsecurity/11153381/How-hackers-took-over-my-computer.html.\n13. https://www.blackhat.com/docs/us-16/materials/us-16-Seymour-Tully-\nWeaponizing-Data-Science-For-Social-Engineering-Automated-E2E-\nSpear-Phishing-On-Twitter.pdf.\n14. http://www.wired.com/2010/01/operation-aurora/.\n15. http://www.nytimes.com/2015/01/04/opinion/sunday/how-my-mom-\ngot-hacked.html.\n16. http://arstechnica.com/security/2013/10/youre-infected-if-you-want-\nto-see-your-data-again-pay-us-300-in-bitcoins/.\n17. https://securityledger.com/2015/10/fbis-advice-on-cryptolocker-just-\npay-the-ransom/.\nChapter Eight: Believe Everything, Trust Nothing\n1. It’s important to note that public Wi-Fi is not open in all parts of the\nworld. For example, in Singapore, to use public Wi-Fi outside your\nhotel or a McDonald’s restaurant, you will need to register. Locals\nmust have a Singapore cell-phone number, and tourists must present\ntheir passports to a local authority before getting approval.\n2. https://business.f-secure.com/the-dangers-of-public-wifi-and-crazy-\nthings-people-do-to-use-it/.\n3. http://dnlongen.blogspot.com/2015/05/is-your-home-router-spying-on-\nyou.html.\n4. There are lots of considerations a user should know about when\nchoosing a VPN provider. See https://torrentfreak.com/anonymous-\nvpn-service-provider-review-2015-150228/3/.\n5. One commercial VPN choice is TunnelBear, a Canadian VPN\ncompany. They state: “TunnelBear does NOT store users originating IP\naddresses when connected to our service and thus cannot identify users\nwhen provided IP addresses of our servers. Additionally, we cannot\ndisclose information about the applications, services or websites our\nusers consume while connected to our Services; as TunnelBear does\nNOT store this information.” https://www.tunnelbear.com/privacy-\npolicy/.\n6. http://www.howtogeek.com/215730/how-to-connect-to-a-vpn-from-\nyour-iphone-or-ipad/.\n7. http://www.howtogeek.com/135036/how-to-connect-to-a-vpn-on-\nandroid/?PageSpeed=noscript.\n8. http://www.cbc.ca/news/politics/csec-used-airport-wi-fi-to-track-\ncanadian-travellers-edward-snowden-documents-1.2517881.\n9.\nhttp://www.telegraph.co.uk/news/worldnews/northamerica/usa/967342\n9/David-Petraeus-ordered-lover-Paula-Broadwell-to-stop-emailing-\nJill-Kelley.html.\n10. http://www.nytimes.com/2012/11/12/us/us-officials-say-petraeuss-\naffair-known-in-summer.html.\n11. https://www.wired.com/2012/11/gmail-location-data-petraeus/.\n12. http://www.howtogeek.com/192173/how-and-why-to-change-your-\nmac-address-on-windows-linux-and-mac/?PageSpeed=noscript.\nChapter Nine: You Have No Privacy? Get Over It!\n1. http://www.wired.com/2012/12/ff-john-mcafees-last-stand/.\n2. http://defensetech.org/2015/06/03/us-air-force-targets-and-destroys-\nisis-hq-building-using-social-media/.\n3. http://www.bbc.com/future/story/20150206-biggest-myth-about-\nphone-privacy.\n4. http://www.dailymail.co.uk/news/article-3222298/Is-El-Chapo-hiding-\nCosta-Rica-Net-closes-world-s-wanted-drug-lord-hapless-son-forgets-\nswitch-location-data-Twitter-picture.html.\n5. https://threatpost.com/how-facebook-and-facial-recognition-are-\ncreating-minority-report-style-privacy-meltdown-080511/75514.\n6. http://www.forbes.com/sites/kashmirhill/2011/08/01/how-face-\nrecognition-can-be-used-to-get-your-social-security-number/2/.\n7. http://searchengineland.com/with-mobile-face-recognition-google-\ncrosses-the-creepy-line-70978.\n8. Robert Vamosi, When Gadgets Betray Us: The Dark Side of Our\nInfatuation with New Technologies (New York: Basic Books, 2011).\n9. http://www.forbes.com/sites/kashmirhill/2011/08/01/how-face-\nrecognition-can-be-used-to-get-your-social-security-number/.\n10. https://techcrunch.com/2015/07/13/yes-google-photos-can-still-sync-\nyour-photos-after-you-delete-the-app/.\n11. https://www.facebook.com/legal/terms.\n12. http://www.consumerreports.org/cro/news/2014/03/how-to-beat-\nfacebook-s-biggest-privacy-risk/index.htm.\n13. http://www.forbes.com/sites/amitchowdhry/2015/05/28/facebook-\nsecurity-checkup/.\n14. http://www.consumerreports.org/cro/magazine/2012/06/facebook-\nyour-privacy/index.htm.\n15. http://www.cnet.com/news/facebook-will-the-real-kevin-mitnick-\nplease-stand-up/.\n16. http://www.eff.org/files/filenode/social_network/training_course.pdf.\n17. http://bits.blogs.nytimes.com/2015/03/17/pearson-under-fire-for-\nmonitoring-students-twitter-posts/.\n18. http://www.washingtonpost.com/blogs/answer-\nsheet/wp/2015/03/14/pearson-monitoring-social-media-for-security-\nbreaches-during-parcc-testing/.\n19. http://www.csmonitor.com/World/Passcode/Passcode-\nVoices/2015/0513/Is-student-privacy-erased-as-classrooms-turn-\ndigital.\n20. https://motherboard.vice.com/blog/so-were-sharing-our-social-\nsecurity-numbers-on-social-media-now.\n21. http://pix11.com/2013/03/14/snapchat-sexting-scandal-at-nj-high-\nschool-could-result-in-child-porn-charges/.\n22. http://www.bbc.co.uk/news/uk-34136388.\n23. https://www.ftc.gov/news-events/press-releases/2014/05/snapchat-\nsettles-ftc-charges-promises-disappearing-messages-were.\n24. http://www.informationweek.com/software/social/5-ways-snapchat-\nviolated-your-privacy-security/d/d-id/1251175.\n25. http://fusion.net/story/192877/teens-face-criminal-charges-for-taking-\nkeeping-naked-photos-of-themselves/.\n26. http://www.bbc.com/future/story/20150206-biggest-myth-about-\nphone-privacy.\n27. http://fusion.net/story/141446/a-little-known-yelp-setting-tells-\nbusinesses-your-gender-age-and-hometown/?\nutm_source=rss&utm_medium=feed&utm_campaign=/author/kashmir\n-hill/feed/.\n28. On the iPhone or iPad, go to Settings>Privacy>Location Services,\nwhere you find a list of all of your location-aware apps. For example,\nit is possible to disable the geolocation for the Facebook Messenger\napp by itself. Scroll to “Facebook Messenger” and ensure that its\nlocation services are set to “Never.” On Android devices, Open the\nFacebook Messenger app, click the “Settings” icon (shaped like a gear)\nin the upper right corner, scroll to “New messages include your\nlocation by default,” and uncheck it. On Android devices in general\nyou will have to individually disable geolocation (if it’s offered as a\nchoice); there is no one-size-fits-all setting.\n29. https://blog.lookout.com/blog/2016/08/25/trident-pegasus/.\nChapter Ten: You Can Run but Not Hide\n1. You can turn off GPS in later verions of iOS as described here:\nhttp://smallbusiness.chron.com/disable-gps-tracking-iphone-\n30007.html.\n2. https://gigaom.com/2013/07/08/your-metadata-can-show-snoops-a-\nwhole-lot-just-look-at-mine/.\n3. http://www.zeit.de/datenschutz/malte-spitz-data-retention.\n4. https://www.washingtonpost.com/local/public-safety/federal-appeals-\ncourt-that-includes-va-md-allows-warrantless-tracking-of-historical-\ncell-site-records/2016/05/31/353950d2-2755-11e6-a3c4-\n0724e8e24f3f_story.html.\n5. http://fusion.net/story/177721/phone-location-tracking-google-feds/?\nutm_source=rss&utm_medium=feed&utm_campaign=/author/kashmir\n-hill/feed/.\n6. http://www.forbes.com/sites/andyrobertson/2015/05/19/strava-flyby/?\nss=future-tech.\n7. http://fusion.net/story/119745/in-the-future-your-insurance-company-\nwill-know-when-youre-having-sex/?\nutm_source=rss&utm_medium=feed&utm_campaign=/author/kashmir\n-hill/feed/.\n8. http://thenextweb.com/insider/2011/07/04/details-of-fitbit-users-sex-\nlives-removed-from-search-engine-results/.\n9. http://fusion.net/story/119745/in-the-future-your-insurance-company-\nwill-know-when-youre-having-sex/?\nutm_source=rss&utm_medium=feed&utm_campaign=/author/kashmir\n-hill/feed/.\n10. http://www.engadget.com/2015/06/28/fitbit-data-used-by-police/.\n11. http://abc27.com/2015/06/19/police-womans-fitness-watch-disproved-\nrape-report/.\n12. http://www.theguardian.com/technology/2014/nov/18/court-accepts-\ndata-fitbit-health-tracker.\n13. http://www.smithsonianmag.com/innovation/invention-snapshot-\nchanged-way-we-viewed-world-180952435/?all&no-ist.\n14. https://books.google.com/books?\nid=SlMEAAAAMBAJ&pg=PA158&lpg=PA158&dq=%22The+kodak+\nhas+added+a+new+terror+to+the+picnic%22&source=bl&ots=FLtKb\nYGv6Y&sig=YzE2BisTYejb1pT3vYhR2QBPAYM&hl=en&sa=X&ei=\nBhUwT7fVBOTgiALv2-\nS3Cg&ved=0CCAQ6AEwAA#v=onepage&q=%22The%20koda&f=fal\nse.\n15. http://www.smithsonianmag.com/innovation/invention-snapshot-\nchanged-way-we-viewed-world-180952435/?no-ist=&page=2.\n16. https://www.faa.gov/uas/media/Part_107_Summary.pdf.\n17. https://www.faa.gov/uas/where_to_fly/b4ufly/.\n18.\nhttp://www.slate.com/articles/technology/future_tense/2015/06/facial_\nrecognition_privacy_talks_why_i_walked_out.html.\n19. http://www.extremetech.com/mobile/208815-how-facial-recognition-\nwill-change-shopping-in-stores.\n20. http://www.retail-week.com/innovation/seven-in-ten-uk-shoppers-\nfind-facial-recognition-technology-creepy/5077039.article.\n21. http://www.ilga.gov/legislation/ilcs/ilcs3.asp?\nActID=3004&ChapterID=57.\n22. http://arstechnica.com/business/2015/06/retailers-want-to-be-able-to-\nscan-your-face-without-your-permission/.\n23. http://fusion.net/story/154199/facial-recognition-no-rules/?\nutm_source=rss&utm_medium=feed&utm_campaign=/author/kashmir\n-hill/feed/.\n24. https://www.youtube.com/watch?v=NEsmw7jpODc.\n25. http://motherboard.vice.com/read/glasses-that-confuse-facial-\nrecognition-systems-are-coming-to-japan.\nChapter Eleven: Hey, KITT, Don’t Share My Location\n1. http://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/.\n2. This is silly. Just because something is prohibited doesn’t mean it\nwon’t happen. And this creates a dangerous scenario in which hacked\ncars can still affect the driving public. Zero-days for automobiles,\nanyone?\n3. http://keenlab.tencent.com/en/2016/06/19/Keen-Security-Lab-of-\nTencent-Car-Hacking-Research-Remote-Attack-to-Tesla-Cars/.\n4. http://www.buzzfeed.com/johanabhuiyan/uber-is-investigating-its-top-\nnew-york-executive-for-privacy.\n5. http://www.theregister.co.uk/2015/06/22/epic_uber_ftc/.\n6. http://nypost.com/2014/11/20/uber-reportedly-tracking-riders-without-\npermission/.\n7. https://www.uber.com/legal/usa/privacy.\n8. http://fortune.com/2015/06/23/uber-privacy-epic-ftc/.\n9. http://www.bbc.com/future/story/20150206-biggest-myth-about-\nphone-privacy.\n10. http://tech.vijay.ca/of-taxis-and-rainbows-f6bc289679a1.\n11. http://arstechnica.com/tech-policy/2014/06/poorly-anonymized-logs-\nreveal-nyc-cab-drivers-detailed-whereabouts/.\n12. You can walk into a transit authority office and request to pay cash for\nan NFC card, but this requires extra time and will undoubtedly result\nin a lecture about tying your bank or credit card to the card instead.\n13.\nhttp://www.wsj.com/articles/SB10000872396390443995604578004723\n603576296.\n14. https://www.aclu.org/blog/free-future/internal-documents-show-fbi-\nwas-wrestling-license-plate-scanner-privacy-issues.\n15. http://www.wired.com/2015/05/even-fbi-privacy-concerns-license-\nplate-readers/.\n16. Five of the sources were the St. Tammany Parish Sheriff’s Office, the\nJefferson Parish Sheriff’s Office, and the Kenner Police Department, in\nLouisiana; the Hialeah Police Department, in Florida; and the\nUniversity of Southern California Department of Public Safety.\n17. http://www.forbes.com/sites/robertvamosi/2015/05/04/dont-sell-that-\nconnected-car-or-home-just-yet/.\n18. https://www.washingtonpost.com/blogs/the-\nswitch/wp/2015/06/24/tesla-says-its-drivers-have-traveled-a-billion-\nmiles-and-tesla-knows-how-many-miles-youve-driven/.\n19. http://www.dhanjani.com/blog/2014/03/curosry-evaluation-of-the-\ntesla-model-s-we-cant-protect-our-cars-like-we-protect-our-\nworkstations.html.\n20. http://www.teslamotors.com/blog/most-peculiar-test-drive.\n21. http://www.forbes.com/sites/kashmirhill/2013/02/19/the-big-privacy-\ntakeaway-from-tesla-vs-the-new-york-times/.\n22. http://www.wired.com/2015/07/gadget-hacks-gm-cars-locate-unlock-\nstart/.\n23. http://spectrum.ieee.org/cars-that-think/transportation/advanced-\ncars/researchers-prove-connected-cars-can-be-tracked.\n24. http://www.wired.com/2015/10/cars-that-talk-to-each-other-are-much-\neasier-to-spy-on/.\n25. https://grahamcluley.com/2013/07/volkswagen-security-flaws/.\n26. https://grahamcluley.com/2015/07/land-rover-cars-bug/.\n27. http://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/.\n28. http://www.forbes.com/sites/robertvamosi/2015/03/24/securing-\nconnected-cars-one-chip-at-a-time/.\n29. http://www.nytimes.com/2016/07/30/business/tesla-faults-teslas-\nbrakes-but-not-autopilot-in-fatal-crash.html.\nChapter Twelve: The Internet of Surveillance\n1. http://www.amazon.com/review/R3IMEYJFO6YWHD.\n2. https://www.blackhat.com/docs/us-14/materials/us-14-Jin-Smart-Nest-\nThermostat-A-Smart-Spy-In-Your-Home.pdf.\n3. http://venturebeat.com/2014/08/10/hello-dave-i-control-your-\nthermostat-googles-nest-gets-hacked/.\n4. http://www.forbes.com/sites/kashmirhill/2014/07/16/nest-hack-\nprivacy-tool/.\n5. http://venturebeat.com/2014/08/10/hello-dave-i-control-your-\nthermostat-googles-nest-gets-hacked/.\n6. http://www.networkworld.com/article/2909212/security0/schneier-on-\nreally-bad-iot-security-it-s-going-to-come-crashing-down.html.\n7. http://www.forbes.com/sites/kashmirhill/2013/07/26/smart-homes-\nhack/.\n8. http://www.dhanjani.com/blog/2013/08/hacking-lightbulbs.html.\n9. http://www.wired.com/2009/11/baby-monitor/.\n10. http://www.bbc.com/news/technology-31523497.\n11. http://mashable.com/2012/05/29/sensory-galaxy-s-iii/.\n12. http://www.forbes.com/sites/marcwebertobias/2014/01/26/heres-how-\neasy-it-is-for-google-chrome-to-eavesdrop-on-your-pc-microphone/.\n13. http://www.theguardian.com/technology/2015/jun/23/google-\neavesdropping-tool-installed-computers-without-permission.\n14. Perhaps the easiest way is to open the Amazon Echo app. Go to your\nsettings, then go to History>Tap Individual Recording>Delete.\n15. Log in to your account on Amazon, then from “Account Settings,”\nclick on Your Devices>Amazon Echo>Delete.\n16. http://www.theregister.co.uk/2015/08/24/smart_fridge_security_fubar/.\n17. www.shodan.io.\nChapter Thirteen: Things Your Boss Doesn’t Want You to Know\n1.\nhttp://www.wsj.com/articles/SB10001424052702303672404579151440\n488919138.\n2. http://theweek.com/articles/564263/rise-workplace-spying.\n3. https://olin.wustl.edu/docs/Faculty/Pierce_Cleaning_House.pdf.\n4. http://harpers.org/archive/2015/03/the-spy-who-fired-me/.\n5. https://room362.com/post/2016/snagging-creds-from-locked-\nmachines/.\n6. Normally document metadata is hidden from view. You can see the\nmetadata included with your document by clicking File>Info, then\nviewing the properties on the right side of the window.\n7. If you use Document Inspector, first make a copy of your document,\nbecause changes made cannot be undone. In the copy of your original\ndocument, click the “File” tab, then click “Info.” Under “Prepare for\nSharing,” click “Check for Issues,” then click “Inspect Document.” In\nthe Document Inspector dialog box, select the check boxes for the\ncontent that you want to be inspected. Click “Inspect.” Review the\nresults of the inspection in the Document Inspector dialog box. Click\n“Remove All” next to the inspection results for the types of hidden\ncontent that you want to remove from your document.\n8. http://www.infosecurity-magazine.com/news/printer-related-security-\nbreaches-affect-63-of/.\n9. http://www.wired.com/2014/08/gyroscope-listening-hack/.\n10. http://ossmann.blogspot.com/2013/01/funtenna.html.\n11. http://cs229.stanford.edu/proj2013/Chavez-ReconstructingNon-\nIntrusivelyCollectedKeystrokeDataUsingCellphoneSensors.pdf.\n12. http://www.cc.gatech.edu/~traynor/papers/traynor-ccs11.pdf.\n13. http://samy.pl/keysweeper/.\n14. http://www.wired.com/2015/10/stingray-government-spy-tools-can-\nrecord-calls-new-documents-confirm/.\n15. http://phys.org/news/2013-07-femtocell-hackers-isec-smartphone-\ncontent.html.\n16. http://arstechnica.com/information-technology/2015/04/this-machine-\ncatches-stingrays-pwnie-express-demos-cellular-threat-detector/.\n17. http://www.guardian.co.uk/world/2013/jul/11/microsoft-nsa-\ncollaboration-user-data.\n18. http://www.computerworld.com/article/2474090/data-privacy/new-\nsnowden-revelation-shows-skype-may-be-privacy-s-biggest-\nenemy.html.\n19.\nhttps://community.rapid7.com/community/metasploit/blog/2012/01/23\n/video-conferencing-and-self-selecting-targets.\n20.\nhttp://www.polycom.com/global/documents/solutions/industry_solutio\nns/government/max_security/uc-deployment-for-maximum-\nsecurity.pdf.\n21.\nhttps://community.rapid7.com/community/metasploit/blog/2012/01/23\n/video-conferencing-and-self-selecting-targets.\n22. For example, https://www.boxcryptor.com/en.\nChapter Fourteen: Obtaining Anonymity Is Hard Work\n1. That this is a border search and arrest is not really relevant. U.S. courts\nhave not settled whether a person of interest has to give up their\npasswords—so far not. However, a court has ruled that a person of\ninterest can be forced into authenticating his or her iPhone by using\nTouch ID (fingerprint). To eliminate the risk, whenever you pass\nthrough customs in any country, reboot your iPhone or any other Apple\ndevice with Touch ID and do not put in your passcode. As long as you\ndon’t enter your passcode, Touch ID will fail.\n2. http://www.computerweekly.com/Articles/2008/03/13/229840/us-\ndepartment-of-homeland-security-holds-biggest-ever-\ncybersecurity.htm.\n3. In iOS 8 or more recent versions of the operating system, you can reset\nall pairing relationships by going to Settings>General>Reset>Reset\nLocation & Privacy or Reset Network Settings. Researcher Jonathan\nZdziarski has published a number of blog posts on the topic. The\ninstructions are beyond the scope of this book, but if you are serious\nabout removing these, he offers a way. See\nhttp://www.zdziarski.com/blog/?p=2589.\n4. http://www.engadget.com/2014/10/31/court-rules-touch-id-is-not-\nprotected-by-the-fifth-amendment-bu/.\n5. http://www.cbc.ca/news/canada/nova-scotia/quebec-resident-alain-\nphilippon-to-fight-charge-for-not-giving-up-phone-password-at-\nairport-1.2982236.\n6. http://www.ghacks.net/2013/02/07/forensic-tool-to-decrypt-truecrypt-\nbitlocker-and-pgp-contains-and-disks-released/.\n7. https://www.symantec.com/content/en/us/enterprise/white_papers/b-\npgp_how_wholedisk_encryption_works_WP_21158817.en-us.pdf.\n8. http://www.kanguru.com/storage-accessories/kanguru-ss3.shtml.\n9. https://www.schneier.com/blog/archives/2007/11/the_strange_sto.html.\n10. https://theintercept.com/2015/04/27/encrypting-laptop-like-mean/.\n11. http://www.securityweek.com/researcher-demonstrates-simple-\nbitlocker-bypass.\n12. https://www.fbi.gov/news/speeches/going-dark-are-technology-\nprivacy-and-public-safety-on-a-collision-course.\n13.\nhttp://www.nytimes.com/library/tech/00/01/cyber/cyberlaw/28law.html\n.\n14.\nhttps://partners.nytimes.com/library/tech/00/01/cyber/cyberlaw/28law.\nhtml.\n15. https://www.wired.com/2015/10/cops-dont-need-encryption-backdoor-\nto-hack-iphones/.\n16. http://theinvisiblethings.blogspot.com/2009/10/evil-maid-goes-after-\ntruecrypt.html.\n17. https://blog.gdatasoftware.com/blog/article/hotel-safes-are-they-\nreally-safe.html.\n18. http://www.snopes.com/crime/warnings/hotelkey.asp.\n19. http://www.themarysue.com/hotel-key-myth/.\n20. https://shaun.net/posts/whats-contained-in-a-boarding-pass-barcode.\n21. Apparently United is one of the few airlines that only gives a partial\nfrequent flyer mile number. Most other airlines do put the full number\nin the bar code.\n22. http://www.wired.com/2014/11/darkhotel-malware/.\n23. https://bitlaunder.com/launder-bitcoin.\nChapter Fifteen: The FBI Always Gets Its Man\n1. https://www.wired.com/2015/05/silk-road-creator-ross-ulbricht-\nsentenced-life-prison/.\n2. http://www.nytimes.com/2015/12/27/business/dealbook/the-unsung-\ntax-agent-who-put-a-face-on-the-silk-road.html?_r=0.\n3. http://www.wired.com/2015/07/online-anonymity-box-puts-mile-\naway-ip-address/.\n4. https://samy.pl/proxygambit/.\nChapter Sixteen: Mastering the Art of Invisibility\n1. There’s more. Even though the FBI identified my apartment complex,\nthey didn’t know where I was. That changed when I stepped outside\none night. This story can be found in my book Ghost in the Wires.\n2. Sites like Weather Underground put the longitude and latitude of the\nvisitor in the URL.\n3. For example, https://www.bitrefill.com.\n4. https://nakedsecurity.sophos.com/2015/07/30/websites-can-track-us-\nby-the-way-we-type-heres-how-to-stop-it/."
  },
  {
    "input": "What is the purpose of the newsletter sign-up provided in the text?",
    "summary": "Thank you for purchasing this ebook from Hachette Digital. To get special offers and updates, sign up for their newsletters. You can join by visiting hachettebookgroup.com/newsletters.",
    "output": "Thank you for buying this ebook, published by Hachette\nDigital.\nTo receive special offers, bonus content, and news about our latest ebooks\nand apps, sign up for our newsletters.\nSign Up\nOr visit us at hachettebookgroup.com/newsletters"
  }
]