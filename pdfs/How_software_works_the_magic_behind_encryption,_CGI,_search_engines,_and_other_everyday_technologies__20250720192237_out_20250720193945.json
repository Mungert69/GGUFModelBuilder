[
  {
    "input": "What is the main topic of the book \"How Software Works\"?",
    "summary": "This book explains the inner workings of everyday technologies like encryption, CGI, search engines, and more, from a non-technical perspective. It covers topics such as data encryption, password protection, web security, computer graphics, data compression, and how software searches for information. The book also explores how software can work together efficiently and how map software determines the best routes.",
    "output": "HOW SOFTWARE WORKS\nThe Magic Behind Encryption, CGI, Search Engines, and\nOther Everyday Technologies\nby V. Anton Spraul\nSan Francisco\nWOW! eBook\nwww.wowebook.org\nHOW SOFTWARE WORKS. Copyright © 2015 by V. Anton Spraul.\nAll rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, electronic or\nmechanical, including photocopying, recording, or by any information storage or retrieval system, without the prior\nwritten permission of the copyright owner and the publisher.\nPrinted in USA\nFirst printing\n19 18 17 16 15 1 2 3 4 5 6 7 8 9\nISBN-10: 1-59327-666-4\nISBN-13: 978-1-59327-666-9\nPublisher: William Pollock\nProduction Editor: Alison Law\nCover Illustration: Josh Ellingson\nInterior Design: Octopod Studios\nDevelopmental Editors: Hayley Baker, Seph Kramer, and Greg Poulos\nTechnical Reviewer: Randall Hyde\nCopyeditor: Rachel Monaghan\nCompositor: Susan Glinert Stevens\nProofreader: James Fraleigh\nFor information on distribution, translations, or bulk sales, please contact No Starch Press, Inc. directly:\nNo Starch Press, Inc.\n245 8th Street, San Francisco, CA 94103\nphone: 415.863.9900; info@nostarch.com\nwww.nostarch.com\nLibrary of Congress Cataloging-in-Publication Data:\nSpraul, V. Anton.\nHow software works : the magic behind encryption, CGI, search engines, and other everyday technologies / by\nV. Anton Spraul.\npages cm\nIncludes index.\nSummary: “A guide for non-technical readers that explores topics like data encryption; computer graphics\ncreation; password protection; video compression; how data is found in huge databases; how programs can work\ntogether on the same problem without conflict; and how map software finds routes.”— Provided by publisher.\nISBN 978-1-59327-666-9 — ISBN 1-59327-666-4\n1. Electronic data processing—Popular works. 2. Computer software—Popular works. 3. Computer networks—\nPopular works. I. Title.\nQA76.5.S6663 2015\n005.3—dc23\n2015022623\nNo Starch Press and the No Starch Press logo are registered trademarks of No Starch Press, Inc. Other product and\ncompany names mentioned herein may be the trademarks of their respective owners. Rather than use a trademark\nsymbol with every occurrence of a trademarked name, we are using the names only in an editorial fashion and to the\nbenefit of the trademark owner, with no intention of infringement of the trademark.\nThe information in this book is distributed on an “As Is” basis, without warranty. While every precaution has been taken\nin the preparation of this work, neither the author nor No Starch Press, Inc. shall have any liability to any person or\nentity with respect to any loss or damage caused or alleged to be caused directly or indirectly by the information\ncontained in it.\nWOW! eBook\nwww.wowebook.org\nAbout the Author\nV. Anton Spraul has taught introductory programming and computer science to students\nfrom all over the world for more than 15 years. He is also the author of Think Like a\nProgrammer (No Starch Press) and Computer Science Made Simple (Broadway).\nWOW! eBook\nwww.wowebook.org\nAbout the Technical Reviewer\nRandall Hyde is the author of The Art of Assembly Language and Write Great Code (both\nNo Starch Press), and is also the co-author of The Waite Group’s Microsoft Macro\nAssembler 6.0 Bible (Sams Publishing). Hyde taught assembly language at the University\nof California, Riverside, for more than a decade and has been programming software for\nnuclear reactor consoles for the past 12 years.\nWOW! eBook\nwww.wowebook.org\nBrief Contents\nAcknowledgments\nIntroduction\nChapter 1: Encryption\nChapter 2: Passwords\nChapter 3: Web Security\nChapter 4: Movie CGI\nChapter 5: Game Graphics\nChapter 6: Data Compression\nChapter 7: Search\nChapter 8: Concurrency\nChapter 9: Map Routes\nIndex\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What are the key concepts discussed in this section of the book?",
    "summary": "This book explains how software works by covering key topics like encryption, passwords, web security, movie CGI, game graphics, data compression, search, concurrency, and map routing. It is designed for anyone with curiosity, including casual tech fans and aspiring programmers, and avoids complex programming code. The content provides enough detail to truly understand how these software processes function in real life.",
    "output": "Contents in Detail\nAcknowledgments\nIntroduction\nWho This Book Is For\nTopics Covered\nBehind the Magic\n1 Encryption\nThe Goal of Encryption\nTransposition: Same Data, Different Order\nCipher Keys\nAttacking the Encryption\nSubstitution: Replacing Data\nVarying the Substitution Pattern\nKey Expansion\nThe Advanced Encryption Standard\nBinary Basics\nAES Encryption: The Big Picture\nKey Expansion in AES\nAES Encryption Rounds\nBlock Chaining\nWhy AES Is Secure\nPossible AES Attacks\nThe Limits of Private-Key Encryption\n2 Passwords\nTransforming a Password into a Number\nProperties of Good Hash Functions\nThe MD5 Hash Function\nEncoding the Password\nBitwise Operations\nMD5 Hashing Rounds\nMeeting the Criteria of a Good Hash Function\nWOW! eBook\nwww.wowebook.org\nDigital Signatures\nThe Problem of Identity\nCollision Attacks\nPasswords in Authentication Systems\nThe Dangers of Password Tables\nHashing Passwords\nDictionary Attacks\nHash Tables\nHash Chaining\nIterative Hashing\nSalting Passwords\nAre Password Tables Safe?\nPassword Storage Services\nA Final Thought\n3 Web Security\nHow Public-Key Cryptography Solves the Shared Key Problem\nMath Tools for Public-Key Cryptography\nInvertible Functions\nOne-Way Functions\nTrapdoor Functions\nThe RSA Encryption Method\nCreating the Keys\nEncrypting Data with RSA\nRSA Effectiveness\nRSA Use in the Real World\nRSA for Authentication\nSecurity on the Web: HTTPS\nHandshaking\nTransmitting Data Under HTTPS\nThe Shared Key Problem Solved?\n4 Movie CGI\nSoftware for Traditional Animation\nWOW! eBook\nwww.wowebook.org\nHow Digital Images Work\nHow Colors Are Defined\nHow Software Makes Cel Animations\nFrom Cel Animation Software to Rendered 2D Graphics\nSoftware for 3D CGI\nHow 3D Scenes Are Described\nThe Virtual Camera\nDirect Lighting\nGlobal Illumination\nHow Light Is Traced\nFull-Scene Anti-Aliasing\nCombining the Real and the Fake\nThe Ideal of Movie-Quality Rendering\n5 Game Graphics\nHardware for Real-Time Graphics\nWhy Games Don’t Ray Trace\nAll Lines and No Curves\nProjection Without Ray Tracing\nRendering Triangles\nThe Painter’s Algorithm\nDepth Buffering\nReal-Time Lighting\nShadows\nAmbient Light and Ambient Occlusion\nTexture Mapping\nNearest-Neighbor Sampling\nBilinear Filtering\nMipmaps\nTrilinear Filtering\nReflections\nFaking Curves\nDistant Impostors\nWOW! eBook\nwww.wowebook.org\nBump Mapping\nTessellation\nAnti-Aliasing in Real Time\nSupersampling\nMultisampling\nPost-Process Anti-Aliasing\nThe Rendering Budget\nWhat’s Next for Game Graphics\n6 Data Compression\nRun-Length Encoding\nDictionary Compression\nThe Basic Method\nHuffman Encoding\nReorganizing Data for Better Compression\nPredictive Encoding\nQuantization\nJPEG Images\nA Different Way to Store Colors\nThe Discrete Cosine Transform\nThe DCT for Two Dimensions\nCompressing the Results\nJPEG Picture Quality\nCompressing High-Definition Video\nTemporal Redundancy\nMPEG-2 Video Compression\nVideo Quality with Temporal Compression\nThe Present and Future of Video Compression\n7 Search\nDefining the Search Problem\nPutting Data in Order\nSelection Sort\nQuicksort\nWOW! eBook\nwww.wowebook.org\nBinary Search\nIndexing\nHashing\nWeb Search\nRanking Results\nUsing the Index Effectively\nWhat’s Next for Web Search\n8 Concurrency\nWhy Concurrency Is Needed\nPerformance\nMultiuser Environments\nMultitasking\nHow Concurrency Can Fail\nMaking Concurrency Safe\nRead-Only Data\nTransaction-Based Processing\nSemaphores\nThe Problem of Indefinite Waits\nOrderly Queues\nStarvation from Circular Waits\nPerformance Issues of Semaphores\nWhat’s Next for Concurrency\n9 Map Routes\nWhat a Map Looks Like to Software\nBest-First Search\nReusing Prior Search Results\nFinding All the Best Routes at Once\nFloyd’s Algorithm\nStoring Route Directions\nThe Future of Routing\nIndex\nWOW! eBook\nwww.wowebook.org\nAcknowledgments\nThis book was shaped and guided by a platoon of talented editors: Alison Law, Greg\nPoulos, Seph Kramer, Hayley Baker, Randall Hyde, Rachel Monaghan, and the “Big Fish”\nof No Starch, Bill Pollock. Beyond the editorial staff, I appreciate the support and\nkindness of everyone I’ve worked with at No Starch.\nThe two people who helped me the most, though, are Mary Beth and Madeline, the\nbest wife and daughter I can imagine. Without their love and support, this book would not\nhave been written.\nWOW! eBook\nwww.wowebook.org\nIntroduction\nScience fiction author Arthur C. Clarke wrote that “any sufficiently advanced technology\nis indistinguishable from magic.” If we don’t know how something works, then it might as\nwell be explained by supernatural forces. By that standard, we live in an age of magic.\nSoftware is woven into our lives, into everyday things like online transactions, special\neffects in movies, and streaming video. We’re forgetting we used to live in a world in\nwhich the answer to a question wasn’t just a Google search away, or where finding a route\nfor a car trip began with unfolding a cumbersome map.\nBut few of us have any idea how all this software works. Unlike many innovations of\nthe past, you can’t take software apart to see what it’s doing. Everything happens on a\ncomputer chip that looks the same whether the device is performing an amazing task or\nisn’t even turned on. Knowing how a program works seems to require spending years of\nstudy to become a programmer. So it’s no wonder that many of us assume that software is\nbeyond our understanding, a collection of secrets known only to a technological elite. But\nthat’s wrong.\nWho This Book Is For\nAnyone can learn how software works. All you need is curiosity. Whether you’re a casual\nfan of technology, a programmer in the making, or someone in between, this book is for\nyou.\nThis book covers the most commonly used processes in software and does so without a\nsingle line of programming code. No prior knowledge of how computers operate is\nrequired. To make this possible, I’ve simplified a few processes and clipped some details,\nbut that doesn’t mean these are mere high-level overviews; you’ll be getting the real\ngoods, with enough details that you’ll truly understand how these programs do what they\ndo.\nTopics Covered\nComputers are so ubiquitous in the modern world that the list of subjects I could cover\nseems endless. I’ve chosen topics that are most central to our daily lives and with the most\ninteresting explanations.\n• Chapter 1: Encryption allows us to scramble our data so that only we can access it.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What is the purpose of encryption and how does it ensure that only authorized users can access data while making it difficult for attackers to decrypt it?",
    "summary": "The text explains how encryption works, focusing on techniques like transposition, substitution, and key expansion, and introduces the Advanced Encryption Standard (AES) as a secure method. It discusses how AES uses a combination of these techniques to create strong, reversible encryption that is difficult for attackers to break. The text also covers how AES resists common attacks, such as brute force and frequency analysis, through methods like block chaining and diffusion.",
    "output": "When you lock your phone or password-protect a .zip file, you’re using encryption.\nWe’ll see how different scrambling techniques are combined in modern encryption\nsoftware.\n• Chapter 2: Passwords are the keys we use to lock our data and how we identify\nourselves to remote systems. You’ll see how passwords are used in encryption and learn\nthe surprising steps that must be taken to keep passwords safe from attackers.\n• Chapter 3: Web Security is what we need to safely purchase goods online or access our\naccounts. Locking data for transmission requires a different method of scrambling called\npublic-key encryption. You’ll discover how a secure web session requires all the\ntechniques covered in the first three chapters.\n• Chapter 4: Movie CGI is pure software magic, creating whole worlds out of\nmathematical descriptions. You’ll discover how software took over traditional cel\nanimation and then learn the key concepts behind making a complete movie set with\nsoftware.\n• Chapter 5: Game Graphics are impressive not just for their visuals but also for how\nthey are created in mere fractions of a second. We’ll explore a host of clever tricks\ngames use to produce stunning images when they don’t have time for the techniques\ndiscussed in the previous chapter.\n• Chapter 6: Data Compression shrinks data so that we can get more out of our storage\nand bandwidth limits. We’ll explore the best methods for shrinking data, and then see\nhow they are combined to compress high-definition video for Blu-ray discs and web\nstreams.\n• Chapter 7: Search is about finding data instantly, whether it’s a search for a file on our\nown computer or a search across the whole Web. We’ll explore how data is organized\nfor quick searches, how search zeros in on requested data, and how web searches return\nthe most useful results.\n• Chapter 8: Concurrency allows multiple programs to share data. Without concurrency,\nmultiplayer video games wouldn’t be possible, and online bank systems could allow\nonly one customer at a time. We’ll talk about the methods that enable different\nprocessors to access the same data without getting in each other’s way.\n• Chapter 9: Map Routes are those instant directions we get from mapping sites and in-\ncar navigators. You’ll discover what a map looks like to software and the specialized\nsearch techniques that find the best routes.\nBehind the Magic\nI think it’s important to share this knowledge. We shouldn’t have to live in a world we\ndon’t understand, and it’s becoming impossible to understand the modern world without\nalso understanding software. Clarke’s message can be taken as a warning that those who\nunderstand technology can fool those who don’t. For example, a company may claim that\nthe theft of its login data poses little danger to its customers. Could this be true, and how?\nAfter reading this book, you’ll know the answer to questions like these.\nWOW! eBook\nwww.wowebook.org\nBeyond that, though, there’s an even better reason to learn the secrets of how software\nworks: because those secrets are really cool. I think the best magic tricks are even more\nmagical once you learn how they are done. Read on and you’ll see what I mean.\nWOW! eBook\nwww.wowebook.org\n1\nEncryption\nWe rely on software to protect our data every day, but most of us know little about how\nthis protection works. Why does a “lock” icon in the corner of your browser mean it’s safe\nto enter your credit card number? How does creating a password for your phone actually\nprotect the data inside? What really prevents other people from logging into your online\naccounts?\nComputer security is the science of protecting data. In a way, computer security\nrepresents technology solving a problem that technology created. Not that long ago, most\ndata wasn’t stored digitally. We had filing cabinets in our offices and shoeboxes of\nphotographs under our beds. Of course, back then you couldn’t easily share your\nphotographs with friends around the world or check your bank balance from a mobile\nphone, but neither could anyone steal your private data without physically taking it. Today,\nnot only can you be robbed at a distance, but you might not even know you’ve been\nrobbed—that is, until your bank calls to ask why you are buying thousands of dollars in\ngift cards.\nOver these first three chapters, we’ll discuss the most important concepts behind\ncomputer security. In this chapter, we talk about encryption. By itself, encryption provides\nus with the capability to lock our data so only we can unlock it. Additional techniques,\ndiscussed in the next two chapters, are needed to provide the full security suite that we\ndepend on, but encryption is the core of computer security.\nThe Goal of Encryption\nThink of a file on your computer: it might contain text, a photograph, a spreadsheet, audio,\nor video. You want to access the file but keep it secret from everyone else. This is the\nfundamental problem of computer security. To keep the file secret, you can use encryption\nto transform it into a new format that is unreadable until the file has been returned to its\noriginal form using decryption. The original file is the plaintext (even if the file isn’t text),\nand the encrypted file is the ciphertext.\nAn attacker is someone who attempts to decrypt the ciphertext without authorization.\nThe goal of encryption is to create a ciphertext that is easy for authorized users to decrypt,\nwhile practically impossible for attackers to decrypt. “Practically” is the source of many\nWOW! eBook\nwww.wowebook.org\nheadaches for security researchers. Just as no lock is absolutely unbreakable, no\nencryption can be absolutely impossible to decrypt. With enough time and enough\ncomputing power, any encryption scheme can be broken in theory. The goal of computer\nsecurity is to make an attacker’s job so difficult that successful attacks are impossible in\npractice, requiring computing resources beyond an attacker’s means.\nRather than jump headfirst into the intricacies of software-based encryption, I’ll start\nthis chapter with some simple examples from the pre-software days of codes and spies.\nAlthough the strength of encryption has vastly improved over the years, these same classic\ntechniques form the basis of all encryption. Later, you’ll see how these ideas are combined\nin a modern digital encryption scheme.\nTransposition: Same Data, Different Order\nOne of the simplest ways to encrypt data is called transposition, which simply means\n“changing position.” Transposition is the kind of encryption my friends and I used when\npassing notes in grade school. Because these notes were passed through untrustworthy\nhands, it was imperative the notes were unintelligible to anyone but us.\nTo keep messages secret, we rearranged the order of the letters using a simple, easy-to-\nreverse scheme. Suppose I needed to share the vital intelligence that CATHY LIKES\nKEITH (the names have been changed to protect the innocent). To encrypt the message, I\ncopied every third letter of the plaintext (ignoring any spaces). During the first pass\nthrough the message, I copied five letters, as shown in Figure 1-1.\nFigure 1-1: The first pass in the transposition of the sample message\nHaving reached the end of the message, I started back at the beginning and continued\nselecting every third remaining letter. The second pass got me to the state shown in Figure\n1-2.\nFigure 1-2: The second transposition pass\nOn the last pass I copied the remaining letters, as shown in Figure 1-3.\nWOW! eBook\nwww.wowebook.org\nFigure 1-3: The final transposition pass\nThe resulting ciphertext is CHISIAYKKTTLEEH. My friends could read the message\nby reversing the transposition process. The first step is shown in Figure 1-4. Returning all\nthe letters to their original position reveals the plaintext.\nFigure 1-4: The first pass in reversing the transposition for decryption\nThis basic transposition method was fun to use, but it’s terribly weak encryption. The\nbiggest concern is a leak—one of my friends blabbing about the encryption method to\nsomeone outside the circle. Once that happens, sending encrypted messages won’t be\nsecure anymore; it will just be more work. Leaks are sadly inevitable—and not just with\nschoolchildren. Every encryption method is vulnerable to leaks, and the more people use a\nparticular method, the more likely it will leak.\nFor this reason, all good encryption systems follow a rule formulated by early Dutch\ncryptographer Auguste Kerckhoffs, known as Kerckhoffs’s principle: the security of data\nshould not depend on the encryption method remaining a secret.\nCipher Keys\nThis raises an obvious question. If the encryption method is not a secret, how do we\nsecurely encrypt data? The answer lies in following a general, publically disclosed\nencryption method, but varying the encryption of individual messages using a cipher key\n(or just key). To understand what a key is, let’s examine a more general transposition\nmethod.\nIn this method, senders and receivers share a secret number prior to sending any\nmessages. Let’s say my friends and I agree on 374. We’ll use this number to alter the\ntransposition pattern in our ciphertexts. This pattern is shown in Figure 1-5 for the\nmessage CATHY LIKES KEITH. The digits of our secret number dictate which letter\nshould be copied from the plaintext to the ciphertext. Because the first digit is 3, the third\nletter of the plaintext, T, becomes the first letter of the ciphertext. The next digit is 7, so\nthe next letter is the seventh letter after the T, which is S. Next, we select the fourth letter\nfrom the S. The first three letters of the ciphertext are TST.\nFigure 1-6 shows how the next two letters are copied to the ciphertext. Starting from\nWOW! eBook\nwww.wowebook.org\nwhere we left off (indicated by the circled 1 in the figure), we count three positions,\nreturning to the beginning of the plaintext when we reach the end, to select A as the fourth\nletter of the ciphertext. The next letter chosen is seven positions after the A, skipping\nletters that have already been copied: the K. The process continues until all of the letters of\nthe plaintext have been transposed.\nFigure 1-5: The first pass in transposing using the key 374\nFigure 1-6: The second pass in transposing using the key 374\nThe secret number 374, then, is our cipher key. Someone who intercepts this message\nwon’t be able to decrypt it without the key, even if they understand we’re using a\ntransposition method. The code can be regularly changed to prevent blabbermouths and\nturncoats from compromising the encryption.\nAttacking the Encryption\nEven without the key, attackers can still try to recover the plaintext through other means.\nEncrypted data can be attacked through brute force, trying all the possible ways of\napplying the encryption method to the ciphertext. For a message encrypted using\ntransposition, a brute-force attack would examine all permutations of the ciphertext.\nBecause brute force is almost always an option, the number of trials an attacker will need\nto find the plaintext is a good baseline for encryption strength. In our example, the\nmessage CATHY LIKES KEITH has around 40 billion permutations.\nThat’s a huge number, so instead of brute force, a smart attacker would apply some\ncommon sense to recover the plaintext faster. If the attacker can assume the plaintext is in\nEnglish, then most of the permutations can be ruled out before they are tested. For\nexample, the attacker can assume the plaintext won’t start with the letters HT because no\nEnglish word starts with those letters. That’s a billion permutations the attacker won’t\nhave to check.\nAn attacker with some idea of the words in the message can be even smarter about\nfiguring out the plaintext. In our example, the attacker might guess the message includes\nthe name of a classmate. They can see what names can be formed from the ciphertext\nWOW! eBook\nwww.wowebook.org\nletters and then determine what words can be formed from the leftover letters.\nGuesses about the plaintext content are known as cribs. The strongest kind of crib is a\nknown-plaintext attack. To carry out this type of attack, the attacker must have access to a\nplaintext A, its matching ciphertext A, and a ciphertext B that uses the same cipher key as\nciphertext A. Although this scenario sounds unlikely, it does happen. People often leave\ndocuments unguarded when they are no longer considered secret without realizing they\nmay aid attacks on other documents. Known-plaintext attacks are power ful; figuring out\nthe transposition pattern is easy when you have both the plaintext and ciphertext in front\nof you.\nThe best defenses against known-plaintext attacks are good security practices, such as\nregularly changing passwords. Even with the best security practices, though, attackers will\nalmost always have some idea of a plaintext’s contents (that’s why are they so interested in\nreading it). In many cases, they will know most of the plaintext and may have access to\nknown plaintext-ciphertext pairs. A good encryption system should render cribs and\nknown plaintexts useless to attackers.\nSubstitution: Replacing Data\nThe other fundamental encryption technique is more resistant to cribs. Instead of moving\nthe data around, substitution methods systematically replace individual pieces of data.\nWith text messages, the simplest form of substitution replaces every occurrence of one\nletter with another letter. For example, every A becomes a D, every B an H, and so on. A\nkey for this type of encryption looks like Table 1-1.\nTable 1-1: A Substitution Cipher Key\nOriginal A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\nReplacement M N B V C X Z L K F H G J D S A P O I U Y T R E W Q\nAlthough simple substitution, as this method is called, is an improvement over\ntransposition, it too has problems: there are only so many possible substitutions, so an\nattacker can sometimes decrypt ciphertext through brute force.\nSimple substitution is also vulnerable to frequency analysis, in which an attacker\napplies knowledge of how often letters or letter combinations occur in a given language.\nStated broadly, knowing how often data items are likely to appear in a plaintext gives the\nattacker an advantage. For example, the letter E is the most common letter in English\nwriting, and TH is the most common letter pair. Therefore, the most frequently occurring\nletter in a long ciphertext is likely to represent plaintext E, and the most frequently\noccurring letter pair is likely to represent plaintext TH.\nThe power of frequency analysis means that substitution encryption becomes more\nvulnerable as the text grows longer. Attacks are also easier when a collection of\nciphertexts is known to have been encrypted with the same key; avoiding such key reuse is\nan important security practice.\nWOW! eBook\nwww.wowebook.org\nVarying the Substitution Pattern\nTo strengthen encryption against frequency analysis, we can vary the substitution pattern\nduring encryption, so the first E in the plaintext might be replaced with A, but the second\nE in the plaintext is replaced with a T. This technique is known as polyalphabetic\nsubstitution. One method of polyalphabetic substitution uses a grid of alphabets known as\na tabula recta, shown in Figure 1-7. In this table, each row and column is labeled with the\nletter of the alphabet that starts the row or column. Every location in the grid is located\nwith two letters, such as row D, column H, which contains the letter K.\nFigure 1-7: A tabula recta—the shaded first column and row are labels.\nWhen using a tabula recta, the key is textual—letters are used to vary the encryption\ninstead of numbers, as we used in our transposition example. The letters of the plaintext\nselect rows in the tabula recta, and the letters of the key select columns. For example,\nsuppose our plaintext message is the word SECRET, and our encryption key is the word\nTOUGH. Because the first letter of the plaintext is S and the first letter of the key is T, the\nfirst letter of the ciphertext is found at row S, column T in the tabula recta: the letter L. We\nthen use the O column of the table to encrypt the second plaintext letter E (resulting in S),\nand so on, as shown in Figure 1-8. Because the plaintext is longer than the key, we must\nreuse the first letter of the key.\nWOW! eBook\nwww.wowebook.org\nFigure 1-8: Encryption using the tabula recta and cipher key TOUGH\nDecryption reverses the process, as shown in Figure 1-9. The letters in the key indicate\nthe columns, which are scanned to find the corresponding letter in the ciphertext. The row\nwhere the ciphertext letter is found indicates the plaintext letter. In our example, the first\nletter of our key is T, and the first letter of the ciphertext is L. We scan the T column of the\ntabula recta to find L; because L appears in row S, the plaintext letter is S. The process\nrepeats for every letter of the ciphertext.\nFigure 1-9: Decryption using the tabula recta and cipher key TOUGH\nPolyalphabetic substitution is more effective than simple substitution because it varies\nthe substitution pattern throughout the message. In our example, the two occurrences of E\nin the plaintext become different ciphertext letters, and the two occurrences of L in the\nciphertext represent two different plaintext letters.\nKey Expansion\nAlthough polyalphabetic substitution is a great improvement over simple substitution, it’s\neffective only when the key isn’t repeated too often; otherwise it has the same problems as\nsimple substitution. With a key length of five, for example, each plaintext letter would be\nrepresented by only five different ciphertext letters, leaving long ciphertexts vulnerable to\nfrequency analysis and cribs. An attacker would have to work harder, but given enough\nciphertext to work with, an attacker could still break the encryption.\nFor maximum effectiveness, we need encryption keys that are as long as the plaintext,\na technique known as a one-time pad. But that’s not a practical solution for most\nsituations. Instead, a method called key expansion allows short keys to do the work of\nWOW! eBook\nwww.wowebook.org\nlonger ones. One implementation of this idea frequently appears in spy novels. Instead of\nsharing a super-long key, two spies who need to exchange messages agree on a code book,\nwhich is used as a repository of long keys. To avoid arousing suspicion, the code book is\nan ordinary piece of literature, like a specific edition of Shakespeare’s plays.\nLet’s suppose a 50-letter message will be sent using this scheme. In addition to the\nciphertext, the message sender also appends the unexpanded key. Using the works of\nShakespeare as the code book, the unexpanded key might be 2.2.4.9. The first 2 indicates\nthe second of Shakespeare’s plays when listed alphabetically (As You Like It). The second\n2 means Act II of the play. The 4 means Scene 4 of that act. The 9 means the ninth\nsentence of that scene in the specified edition: “When I was at home, I was in a better\nplace, but travelers must be content.” The number of letters in this sentence exceeds the\nnumber in the plaintext and could be used for encryption and decryption using a tabula\nrecta as before. In this way, a relatively short key can be expanded to fit a particular\nmessage.\nNote that this scheme doesn’t qualify as a one-time pad because the code book is finite,\nand therefore the sentence-keys would have to be reused eventually. But it does mean our\nspies only have to remember short cipher keys while encrypting their messages more\nsecurely with longer keys. As you’ll see, the key expansion concept is important in\ncomputer encryption because the cipher keys required are huge but need to be stored in\nsmaller forms.\nThe Advanced Encryption Standard\nNow that we’ve seen how transposition, substitution, and key expansion work\nindividually, let’s see how secure digital encryption results from a careful combination of\nall three techniques.\nThe Advanced Encryption Standard (AES) is an open standard, which means the\nspecifications may be implemented by anyone without paying a license fee. Whether you\nrealize it or not, much of your data is protected by AES. If you have a secure wireless\nnetwork at your home or office, if you have ever password-protected a file in a .zip\narchive, or if you use a credit card at a store or make a withdrawal from an ATM, you are\nprobably relying, at least in part, on AES.\nBinary Basics\nUp to now, I’ve used text encryption samples to keep the examples simple. The data\nencrypted by computers, though, is represented in the form of binary numbers. If you\nhaven’t worked with these numbers before, here’s an introduction.\nDecimal Versus Binary\nThe number system we all grew up with is called the decimal system, deci meaning “ten,”\nbecause the system uses 10 digits, 0 through 9. Each digit in a number represents the\nquantity of a unit 10 times greater than the digit to its right. The units and quantities for\nthe decimal number 23,065 are shown in Figure 1-10. The 2 in the fifth position from the\nWOW! eBook\nwww.wowebook.org\nleft means we have 2 “ten thousands,” for example, and the 6 means 6 “tens.”\nFigure 1-10: Each digit in the decimal number 23,065 represents a different unit quantity.\nIn the binary number system, there are only two possible digits, 0 or 1, which are\ncalled bits, for binary digits. Each bit in a binary number represents a unit twice as large as\nthe bit to the right. The units and quantities for the binary number 110101 are shown in\nFigure 1-11. As shown, we have one of each of the following units: 32, 16, 4, and 1.\nTherefore, the binary number 110101 represents the sum of these four unit values, which\nis the decimal number 53.\nFigure 1-11: Each bit in the binary number 110101 represents a different unit quantity.\nBinary numbers are often written with a fixed number of bits. The most common\nlength for a binary number is eight bits, known as a byte. Although the decimal number 53\ncan be written as 110101 in binary, writing 53 as a byte requires eight bits, so leading 0\nbits fill out the other positions to make 00110101. The smallest byte value, 00000000,\nrepresents decimal 0; the largest possible byte, 11111111, represents decimal 255.\nBitwise Operations\nAlong with the usual mathematical operations such as addition and multiplication,\nsoftware also uses some operations unique to binary numbers. These are known as bitwise\noperations because they are applied individually to each bit rather than to the binary\nnumber as whole.\nThe bitwise operation known as exclusive-or, or XOR, is common in encryption. When\ntwo binary numbers are XORed together, the 1s in the second number flip the\ncorresponding bits in the first number, as shown in Figure 1-12.\nWOW! eBook\nwww.wowebook.org\nFigure 1-12: The exclusive-or (XOR) operation. The 1 bits in the second byte indicate\nwhich bits are “flipped” in the first byte, as shown in the shaded columns.\nRemember, encryption must be reversible. XOR alters the bit patterns in a way that’s\nimpossible to predict without knowing the binary numbers involved, but it’s easily\nreversed. XORing the result with the second number flips the same bits back to their\noriginal state, as shown in Figure 1-13.\nFigure 1-13: If we XOR a byte with the same byte twice, we’re back to where we started.\nConverting Data to Binary Form\nComputers use binary numbers to represent all kinds of data. A plaintext file could be a\ntext message, a spreadsheet, an image, an audio file, or anything else—but in the end,\nevery file is a sequence of bytes. Most computer data is already numeric and can therefore\nbe directly converted into binary numbers. In some cases, though, a special encoding\nsystem is needed to convert non-numeric data into binary form.\nFor example, to see how a text message becomes a sequence of bytes, consider this\nmessage:\nSend more money!\nThis message has 16 characters, counting the letters, spaces, and exclamation point. We\ncan turn each character into a byte using a system such as the American Standard Code for\nInformation Interchange, which is always referred to by its acronym, ASCII, pronounced\n“as-key”. In ASCII, capital A is represented by the number 65, B by 66, and so on, through\n90 for Z. Table 1-2 shows some selected entries from the ASCII table.\nTable 1-2: Selected Entries from the ASCII Table\nWOW! eBook\nwww.wowebook.org\nCharacter Decimal number Binary byte\n(space) 32 00100000\n! 33 00100001\n, 44 00101100\n. 46 00101110\nA 65 01000001\nB 66 01000010\nC 67 01000011\nD 68 01000100\nE 69 01000101\na 97 01100001\nb 98 01100010\nc 99 01100011\nd 100 01100100\ne 101 01100101\nAES Encryption: The Big Picture\nBefore we examine the details of AES encryption, here’s an overview of the process.\nCipher keys in AES are binary numbers. The size of the key can vary, but we’ll discuss\nthe simplest version of AES, which uses a 128-bit key. Using mathematical key\nexpansion, AES transforms the original 128-bit key into eleven 128-bit keys.\nAES divides plaintext data into blocks of 16 bytes in a 4×4 grid; the grid for the sample\nmessage Send more money! is shown in Figure 1-14. Heavy lines separate the 16 bytes,\nand light lines separate the bits within the bytes.\nWOW! eBook\nwww.wowebook.org\nFigure 1-14: The sample message Send more money! transformed into a grid of bytes,\nready for encryption using AES\nThe plaintext data is divided into as many 16-byte blocks as necessary. If the last block\nisn’t full, the rest of the block is padded with random binary numbers.\nAES then subjects each 16-byte block of plaintext data to 10 rounds of encryption.\nDuring a round, the bytes are transposed within the block and substituted using a table.\nThen, using the XOR operation, the bytes in the block are combined with each other and\nwith one of the 128-bit keys.\nThat’s AES in a nutshell; now let’s look at some of these steps in more detail.\nKey Expansion in AES\nKey expansion in a digital encryption system is a bit different than the “code book”\nconcept we discussed earlier. Instead of just looking up a longer key in a book, AES\nexpands the key using the same tools it will later use for the encryption itself: the binary\nXOR operation, transposition, and simple substitution.\nFigure 1-15 shows the first few stages of the key expansion process. Each of the blocks\nin the figure is 32 bits, and one row in this figure represents one 128-bit key. The original\n128-bit key makes up the first four blocks, which are shaded in the figure. Every other\nblock is the result of an XOR between two previous blocks; the XOR operation is\nrepresented by a plus sign in a circle. Block 6, for example, results from the XOR of\nBlock 2 and Block 5.\nFigure 1-15: Key expansion process for AES\nAs you can see on the right of the figure, every fourth block passes through a box\nlabeled “Extra Scrambling.” This process includes transposing the bytes inside the block\nand substituting each byte according to a table called the S-box.\nThe S-box table, which is used both in the key expansion and later in the encryption\nitself, is carefully designed to amplify differences in the plaintext. That is, two plaintext\nbytes that are similar will tend to have S-box replacements that are quite different. The\nWOW! eBook\nwww.wowebook.org\nfirst eight entries from the table are shown in Table 1-3.\nTable 1-3: Excerpts from the S-Box Table\nOriginal bit pattern Replacement bit pattern\n00000000 01100011\n00000001 01111100\n00000010 01110111\n00000011 01111011\n00000100 11110010\n00000101 01101011\n00000110 01101111\n00000111 11000101\n00001000 00110000\n00001001 00000001\nAES Encryption Rounds\nOnce AES has all the required keys, the real encryption can begin. Recall that the binary\nplaintext is stored in a grid of 16 bytes or 128 bits, which is the same size as the original\nkey. This is not a coincidence. The first step of the actual encryption is to XOR the 128-bit\ndata grid with the original 128-bit key. Now the work begins in earnest, as the data grid is\nsubjected to 10 rounds of number crunching. There are four steps in each round.\n1. Substitution.\nEach of the 16 bytes in the grid is replaced using the same S-box table used in the key\nexpansion process.\n2. Row Transposition.\nNext, the bytes are moved to different positions within their row in the grid.\n3. Column Combination.\nNext, for each byte in the grid, a new byte is calculated from a combination of all four\nbytes in that column. This computation involves the XOR operation again, but also a\nbinary form of transposition. To give you the flavor of the process, Figure 1-16 shows\nthe computation of the leftmost byte in the lowest row. The four bytes of the leftmost\nWOW! eBook\nwww.wowebook.org\ncolumn are XORed together, but the top and bottom bytes in the column have their\nbits transposed first. This kind of transposition is known as bitwise rotation; the bits\nslide one position to the left, with the leftmost bit moving over to the right end.\nEvery byte in the new grid is computed in a similar way, by combining the bytes in\nthe column using XOR; the only variation is which bytes have their bits rotated before\nthe XOR.\nFigure 1-16: One part of the column-scrambling step in an AES round\n4. XOR with Cipher Key.\nFinally, the grid that results from the previous step is XORed with the key for that\nround. This is why key expansion is needed, so that each round XORs with a different\nkey.\nThe AES decryption process performs the same steps as the encryption process, in\nreverse. Because the only operations in the encryption are XORs, simple substitution from\nthe S-box, and transpositions of bits and bytes, everything is reversible if the key is\nknown.\nBlock Chaining\nAES encryption could be applied individually to each 16-byte block in a file, but this\nwould create vulnerabilities in the ciphertext. As we’ve discussed, the more times an\nencryption key is used, the more likely it is that attackers will discover and exploit\npatterns. Computer files are often enormous, and using the same key to encrypt millions of\nblocks is a form of large-scale key reuse that exposes the ciphertext to frequency analysis\nand related techniques.\nFor this reason, block-based encryption systems like AES are modified so that identical\nWOW! eBook\nwww.wowebook.org\nblocks in plaintext produce different ciphertext blocks. One such modification is called\nblock chaining.\nWhen block chaining, the first block of the plaintext is XORed with a random 128-bit\nnumber before encryption. This random number is called the starting variable and is\nstored along with the ciphertext. Because each encryption is assigned a random starting\nvariable, two files that begin with the same data will have different ciphertexts even when\nencrypted with the same key.\nEvery subsequent plaintext block is XORed with the previous ciphertext block before\nencryption, “chaining” the encryption as shown in Figure 1-17. Chaining ensures that\nduplicate blocks in a plaintext will result in different ciphertext blocks. This means files of\nany length can be encrypted without fear of frequency analysis.\nFigure 1-17: AES encryption using block chaining\nWhy AES Is Secure\nAs you can see, although AES contains many steps, each individual step is just\ntransposition or simple substitution. Why is AES considered strong enough to protect the\nworld’s data? Remember, attackers use brute force or cribs, or exploit patterns in the\nciphertext. AES has excellent defenses against all of these attack methods.\nWith AES, brute force means running the ciphertext through the decryption process\nwith every possible key until the plaintext is produced. In AES, keys have 128, 192, or\n256 bits. Even the smallest key size offers around\n300,000,000,000,000,000,000,000,000,000,000,000,000 possible keys, and a brute-force\nattack would need to try about half of these before it could expect to hit the right one. An\nattacker with a computer that could try a million keys per second could, in a day, try\n1,000,000 keys × 60 seconds × 60 minutes × 24 hours = 86,400,000,000 keys. In a year,\nthe attacker could try 31,536,000,000,000 keys. Although that’s a large number, it’s not\neven a billionth of a billionth of the possible combinations. An attacker might acquire\nmore computing power, but trying that many keys still doesn’t seem feasible—and that’s\njust for the 128-bit version.\nAES also makes using cribs or finding exploitable patterns difficult. During each\nencryption round, AES rotates the bytes in each row of the grid and combines the bytes in\neach column. After many rounds of this, the bytes are thoroughly mixed together so the\nfinal value of any one byte in the ciphertext grid depends on the initial plaintext values of\nall the bytes in a grid. This encryption property is called diffusion.\nWOW! eBook\nwww.wowebook.org\nFurthermore, passing the bytes through the S-box, round after round, amplifies the\neffect of diffusion, and block chaining passes the diffusion effects of each block on to the\nnext. Together, these operations give AES the avalanche property, in which small changes\nin the plaintext result in sweeping changes throughout the ciphertext.\nAES thwarts attackers no matter how much they know about the general layout of the\nplaintext. For example, a company may send emails to customers based on a common\ntemplate, in which the only variables are the customers’ account numbers and outstanding\nbalances. With diffusion, avalanches, and block chaining, the ciphertexts of these emails\nwill be very different. Diffusion and avalanches also reduce patterns that could be\nexploited through frequency analysis. Even a huge plaintext file consisting of the same 16-\nbyte block repeated over and over would result in a random-looking jumble of bits when\nrun through AES encryption with block chaining.\nPossible AES Attacks\nAES appears to be strong against conventional encryption attacks, but are there hidden\nweaknesses that offer shortcuts to finding the right cipher key? The answer is unclear\nbecause proving a negative is difficult. Stating that no shortcuts, or cracks, are known to\nexist is one thing; proving they couldn’t exist is another. Cryptography is a science, and\nscience is always expanding its boundaries. We simply don’t understand cryptography and\nits underlying mathematics to a point where we can say what’s impossible.\nPart of the difficulty in analyzing the vulnerabilities of an open standard like AES is\nthat programmers implementing the standard in code may unwittingly introduce security\nflaws. For example, some AES implementations are vulnerable to a timing attack, in\nwhich an attacker gleans information about the data being encrypted by measuring how\nlong the encryption takes. The attacker must have access to the specific computer on\nwhich the encryption is performed, however, so this isn’t really a flaw in the underlying\nencryption, but that’s no comfort if security is compromised.\nThe best-understood vulnerability of AES is known as a related-key attack. When two\nkeys are mathematically related in a specific way, an attacker can sometimes use\nknowledge gathered from messages encrypted using one key to recover a message\nencrypted using the other key. Researchers have discovered a way to recover the AES\nencryption key for a particular ciphertext in less time than a brute-force attack, but the\nmethod requires ciphertexts of the same plaintext encrypted with keys that are related to\nthe original key in very specific ways.\nAlthough this shortcut counts as a crack, it may not be of practical value to attackers.\nFirst of all, although it greatly reduces the amount of work to recover the original key, it\nmay not be feasible for any existing computer or network of computers. Second, it’s not\neasy to obtain the other ciphertexts that have been encrypted with the related keys; it\nrequires a breakdown in the implementation or use of the cipher. Therefore, this crack is\ncurrently considered theoretical, not a practical weakness of the system.\nPerhaps the most worrying aspect of this crack is that it’s believed to work only for the\nsupposedly stronger 256-bit-key version of AES, not the simpler 128-bit-key version\ndescribed in this chapter. This demonstrates perhaps the greatest weakness of modern\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "",
    "summary": "The text discusses the limitations of private-key encryption like AES, which is only useful for securing personal data and not for transmitting information securely. It explains how passwords are transformed into binary numbers using hashing, which is essential for secure authentication and encryption. The text also covers how hash functions like MD5 work, their properties, and the challenges they face, such as collision attacks, and introduces methods like hash chaining and salting to improve password security.",
    "output": "encryption techniques: their complexity. Flaws can go undetected for years despite the\nefforts of expert reviewers; small changes in the design can have large ramifications for\nsecurity; and features intended to increase security may have the opposite effect.\nThe Limits of Private-Key Encryption\nThe real limitation of an encryption method like AES, though, has nothing to do with a\npotential hidden flaw.\nAll the encryption methods in this chapter, AES included, are known as symmetric-key\nmethods—this means the key that encrypts a message or file is the same key that is used to\ndecrypt it. If you want to use AES to encrypt a file on your desktop’s hard drive or the\ncontact list in your phone, that’s not a problem; only you are locking and unlocking the\ndata. But what happens when you need to secure a data transmission, as when you enter\nyour credit card number on a retail website? You could encrypt the data with AES and\nsend it to the website, but the software on the website couldn’t decrypt the ciphertext\nwithout the key.\nThis is the shared key problem, and it’s one of the central problems of cryptography.\nWithout a secure way to share keys, symmetric key encryption, by itself, is only useful for\nlocking one’s own private data. Encrypting data for transmission requires a different\napproach, using different keys for encryption and decryption—you’ll see how this is done\nin Chapter 3.\nBut there’s another problem we need to tackle first. AES requires an enormous binary\nnumber as a key, but users can’t be expected to memorize a string of 128 bits. Instead, we\nmemorize passwords. As it turns out, the secure storage and use of passwords presents its\nown quandaries. Those are the subject of the next chapter.\nWOW! eBook\nwww.wowebook.org\n2\nPasswords\nOne of software’s most crucial tasks is the protection of passwords. That may be\nsurprising. After all, aren’t passwords part of systems that provide protection? Don’t\npasswords secure our accounts with banks, web retailers, and online games?\nThe truth is, while passwords are the keystones of computer security, they can become\nthe targets of attacks. If a remote computer accepts your identity based on your password,\na process known as authentication, it must have a list of user passwords to compare\nagainst. That password list is a tempting target for attackers. Recent years have seen a\nnumber of large-scale thefts of customer account data. How does this happen, and what\ncan be done to make breaches less likely? That’s what this chapter is about.\nBefore you learn how passwords are protected, though, you’ll see how they are\ntransformed into binary numbers, a process that has important implications for both\npassword storage and encryption.\nTransforming a Password into a Number\nIn Chapter 1, you saw how an individual character could be replaced by a number from\nthe ASCII table. Here, you’ll see how a string of characters can be replaced by one big\nnumber, such as the 128-bit key we need for AES. In computing, transforming something\ninto a number in a specified range is called hashing, and the resulting number is called a\nhash code, hash value, or just plain hash.\nHere, the word hash means chopping something up and then cramming the pieces back\ntogether, as with hash browns. A particular hashing method is known as a hash function.\nHashing a password always begins by converting each character in the password to a\nnumber using an encoding system such as ASCII. Hash functions differ in how they\ncombine those numbers; the hash functions used in encryption and authentication systems\nmust be carefully designed or security may be compromised.\nProperties of Good Hash Functions\nDeveloping a good hash function is no easy task. To understand what hash functions are\nup against, consider the short password dog. That word contains 3 ASCII bytes, or a mere\nWOW! eBook\nwww.wowebook.org\n24 bits of data, while an AES key is a minimum of 128 bits. Therefore a good hash\nfunction must be capable of transforming those 24 bits into a 128-bit hash code with the\nfollowing properties.\nFull Use of All Bits\nA major strength of a computer-based encryption system like AES is the key size, the sheer\nnumber of possible keys facing an attacker. This strength disappears, however, if all the\npossible keys aren’t actually being used. A good hash function must produce results across\nthe full range of possible hash codes. Even for our short dog password, all 128 bits of the\nresulting hash code must be influenced by the original 24 bits of the password.\nNo Reversibility\nIn Chapter 1, you learned that an encryption method has to be reversible. A good hash\nfunction, in contrast, should not be reversible. I’ll discuss why this is important later in the\nchapter. For now, know that for a given hash code, there should be no direct way to\nrecover a password that produced it. I say a password and not the password because\nmultiple passwords may produce the same hash code, which is known as a hash collision.\nBecause there are more possible passwords than hash codes, collisions are inevitable. A\ngood hash function should make it difficult for attackers to find any password that\nproduces a given hash code.\nAvalanche\nThe avalanche property that’s vital to encryption is just as important in hashing. Small\nchanges in the password should result in large changes in the hash code—especially since\nmany people, when required to choose a new password, choose a slight variation of their\nold one. The hash code produced for dog should be very different from those produced by\nsimilar passwords such as doge, Dog, or odg.\nThe MD5 Hash Function\nMeeting all these criteria is not easy. Good hash functions solve this problem in a clever\nway. They start with a jumble of bits and use the bit patterns of the password to modify\nthis jumble further. That’s the method of the widely used hash function called MD5—the\nfifth version of the Message Digest hash function.\nEncoding the Password\nTo get started, MD5 converts the password to a 512-bit block; I’ll call this the encoded\npassword. The first part of this encoding consists of the ASCII codes of the characters in\nthe password. For example, if the password is BigFunTime, the first character is a B,\nwhich has an ASCII byte of 01000010, so the first 8 bits of the encoded password are\n01000010; the next 8 bits are the byte for i, which is 01101001; and so on. Thus, the 10\nletters in our sample BigFunTime password will take up 80 bits out of 512.\nNow the rest of the bits have to be filled up. The next bit is set to 1, and all the bits up\nWOW! eBook\nwww.wowebook.org\nto the last 64 are set to 0. The final 64 bits store a binary representation of the length, in\nbits, of the original password. In this case, the password is 10 characters, or 80 bits, long.\nThe 64-bit binary representation of 80 is:\n00000000 00000000 00000000 00000000 00000000 00000000 00000000 01010000\nClearly, we don’t need 64 bits to store the length of a password. Using 64 bits for the\nlength allows MD5 to hash inputs of arbitrary length—the benefit of which we’ll see later.\nFigure 2-1 shows the encoding of the sample password, organized into 16 numbered\nrows of 32 bits each.\nFigure 2-1: The password BigFunTime transformed into the 512 bits used as input to the\nMD5 hash function\nThis encoded password is full of zeros and therefore doesn’t meet the “fully uses all the\nbits” property of a good function, but that’s okay because this is not the hash code; it’s just\nthe starting point.\nBitwise Operations\nThe MD5 hash function uses a few operations I haven’t discussed before. Let’s go through\nthese briefly.\nBinary Addition\nThe first new operation is binary addition. Binary addition is much like the decimal\naddition you already know but with binary numbers. For example, the 32-bit\nrepresentation of the number 5 is:\n00000000 00000000 00000000 00000101\nThe 32-bit representation of 46 is:\n00000000 00000000 00000000 00101110\nIf we add 5 and 46 together, the result is 51. Likewise, the addition of those two binary\nWOW! eBook\nwww.wowebook.org\nrepresentations results in the binary representation of 51:\n00000000 00000000 00000000 00110011\nUnlike normal addition, though, where sometimes the result has more digits than the\noperands, in binary addition the number of bits is fixed. If the result of adding two 32-bit\nbinary numbers is greater than 32 bits, we ignore the “carry” at the left side of the result\nand keep only the 32 bits on the right. It’s like working with a cheap calculator that has\njust a two-digit display, so when you add 75 and 49, instead of displaying 124, it displays\nonly the last two digits, 24.\nBitwise NOT\nThe next new operation is called “not,” often written in all uppercase as NOT. As\ndemonstrated in Figure 2-2, NOT “flips” all of the bits, replacing each 1 with a 0 and each\n0 with a 1.\nFigure 2-2: The bitwise NOT operation. All bits are inverted. The 1 bits are highlighted\nfor clarity.\nBitwise OR\nUp next is OR, sometimes called inclusive-OR to distinguish it from the exclusive-or\n(XOR) that you saw in Chapter 1. The OR operation lines up two binary numbers with the\nsame number of bits. In each position of the resulting binary number, you get a 1 if there’s\na 1 in the first number or in the second number; otherwise, you get a 0, as shown in Figure\n2-3.\nFigure 2-3: The bitwise OR operation. Bit positions are 1 in the result if they are 1 in\neither of the two inputs\nNotice that unlike XOR, you can’t apply OR twice and get the original byte back. It’s a\none-way trip.\nBitwise AND\nThe last of the new operations is AND. Two binary numbers are aligned, and in each\nposition, the result is 1 wherever both bits are 1 in that position; otherwise, the result is 0.\nWOW! eBook\nwww.wowebook.org\nSo a 1 in the result means there was a 1 in that position in the first number and the second\nnumber, as seen in Figure 2-4. As with OR, the AND operation isn’t reversible.\nFigure 2-4: The bitwise AND operation. Bit positions are 1 in the result if they are 1 in\nboth of the two inputs.\nMD5 Hashing Rounds\nNow we’re ready for some hashing. Pieces of the encoded password make only brief\nappearances in the MD5 process, but those appearances make all the difference. The MD5\nprocess always starts with the same 128 bits, conceptually split into four 32-bit sections,\nlabeled A through D, as shown in Figure 2-5.\nFigure 2-5: The starting configuration of the 128 bits of an MD5 hash code\nFrom here, it’s all about shifting these bits around and flipping them, in a process that\nrepeats a whopping 64 times. In this respect, the process is a lot like AES but with even\nmore rounds. Figure 2-6 is a broad diagram of one of the 64 rounds.\nFigure 2-6: One round of the MD5 hash function. In the result, three of the sections are\ntransposed, while all four sections are combined to make a new section.\nAs shown, sections B, C, and D are simply transposed, so that the D section of one\nround becomes the A section of the next. The main action of MD5 occurs in the “extra\nscrambling” of each round, which creates a new section from the bits of all four sections\nWOW! eBook\nwww.wowebook.org\nof the previous round. The extra scrambling uses the irreversible operations AND, OR,\nand NOT to combine the bits of all four sections with one of the rows of the encoded\npassword. Different rows of the encoded password are used in different rounds, so that\neventually all the rows of the encoded password are used multiple times. Because of the\ntransposition, the process needs just four rounds to replace each of the four original\nsections with the result of the extra scrambling. After the complete 64-round process, the\noriginal bits of the sections will have been thoroughly sifted together with the encoded\npassword.\nMeeting the Criteria of a Good Hash Function\nBecause MD5 starts with an assortment of bits, then alters these bits over and over, adding\nin pieces of the encoded password, we can be sure that all the bits are affected along the\nway, giving us a true 128-bit hash code. The sheer number of operations that are\nirreversible—and remember, the actions described occur 64 times—means the hash\nfunction as a whole is not reversible. This rotation and alteration of the bits in the “extra\nscrambling” each round, combined with the rotation of the sections themselves, distribute\nthe bits and bytes and create the desired avalanche.\nMD5 meets all the baseline requirements for a good hash function. It does have a few\nsubtle weaknesses, however, as you’ll soon see.\nDigital Signatures\nHash functions serve other purposes in security besides creating keys from passwords.\nOne of the most important is the creation of file signatures. As stated earlier, MD5 can\nprocess any size of input. If the input is larger than 512 bits, it’s first divided into multiple\n512-bit blocks. The MD5 process is then applied once per block. The first block starts\nwith the initial 128 bits and each subsequent block starts with the hash code produced by\nthe previous block. In this way, we could run the entire text of this book, an audio file, a\nvideo, or any other digital file through the function and get a single 128-bit hash code in\nreturn. This hash code would become the file’s signature.\nWhy does a file need a signature? Suppose you have decided to download FreeWrite, a\n(fictional) freeware word processor application. You’re wary, though, because of a bad\nexperience in which you downloaded a freeware program that turned out to be bogus and\nriddled with malware. To avoid this, you want to be sure the FreeWrite file that you\ndownload is the same file that the developers uploaded. The developers could hash the file\nwith MD5 and post the resulting hash code—the file signature—on their website,\nfreewrite.com. This allows you to run the file through an MD5 hash program and compare\nthe result to the code on the developer site. If the new result doesn’t match the signature,\nsomething has changed: the file, the signature, or both.\nThe Problem of Identity\nUnfortunately, matching the posted hash code proves the FreeWrite file is legitimate only\nif the hash code was actually published by the developers. But what if an attacker copies\nWOW! eBook\nwww.wowebook.org\nthe developer’s freewrite.com site to a similarly named domain like free-write.com, and\nthen posts a compromised file along with the hash of that compromised file? A digital\nsignature is only as trustworthy as its provider. We’ll explore this problem in further detail\nin Chapter 3.\nCollision Attacks\nEven with a matching hash code from a legitimate source, though, a file might be trouble.\nMany different files will produce the same hash code, which means an attacker trying to\nmodify a file for nefarious purposes can avoid detection if the new, modified file produces\nthe same hash code.\nIt’s not too difficult to produce two files with the same hash code, which is known as a\ncollision attack: just randomly generate files until two hash codes match. Finding a second\nfile to match the particular hash code of another file is much harder. To be of any real use\nto an attacker, the file with the matching code can’t be a bunch of random bytes; it has to\nbe a program that does something malicious on the attacker’s behalf.\nUnfortunately, there are methods to produce a second file with the same MD5 code that\nis very similar to the first file. The discovery of this flaw in the MD5 hash function has led\nresearchers to suggest that other hash functions be used for signatures. These more\nadvanced hash functions usually have longer hash codes (up to 512 bits), more hashing\nrounds, and more complicated binary math during each round. As with encryption,\nthough, there are no guarantees that flaws won’t be discovered in the more complicated\nhash functions as well. Proper use of signatures means staying one step ahead of known\ndesign flaws because attackers will exploit flaws mercilessly. Digital security is a cat-and-\nmouse game in which the good guys are the mice, trying to avoid being eaten, never able\nto defeat the cats, and only hoping to stay alive a little longer.\nPasswords in Authentication Systems\nNowhere is this cat-and-mouse game more evident than in authentication systems. Every\nplace where you enter your password has to have a list of passwords to compare against,\nand properly securing the list requires great care.\nThe Dangers of Password Tables\nLet’s look at the most straightforward way passwords could be stored in a table. In this\nexample, Northeast Money Bank (NEMB) stores the username and password of each of its\ncustomers, along with the account number and current balance. An excerpt from the\npassword table is shown in Table 2-1.\nTable 2-1: Poorly Designed Password Table\nUsername Password Account number Balance\nrichguy22 ilikemoney 21647365 $27.21\nWOW! eBook\nwww.wowebook.org\nmrgutman falcon 32846519 $10,000.00\nsquire yes90125 70023193 $145,398.44\nburgomeister78 taco999 74766333 $732.23\nJust as Kerckhoffs’s principle says we can’t rely on encryption methods remaining\nsecret, we shouldn’t rely on the password list remaining a secret, either. A disgruntled\nemployee in the NEMB information technology department might easily acquire the file\ncontaining the list, or determined attackers on the outside might worm their way through\nthe company defenses.\nThis is what’s known as a single point of defense, meaning that once anyone lays eyes\non this table, the game is over. First, this table shows the account numbers and balances of\nall of the customers, so at the very least, that’s a major loss of privacy. What’s even worse\nis that each password is stored in the form entered by the user. Accessing this password\nlist will allow attackers to log on as any customer—a disaster in the making.\nFortunately, the problems with this storage system are easily remedied. Knowing that,\nand knowing how dangerous the system is, you would think that it would never be used.\nSadly, you would be wrong. Real companies are storing user passwords just like this.\nSome extremely large companies that probably spent a great deal of money on their\nwebsites have been caught following this practice.\nHashing Passwords\nIf Table 2-1 shows the wrong thing to do, what’s the right thing to do? One improvement\nis leaving the password out of the table and instead storing the hash code of the password,\nas shown by Table 2-2. (In the examples that follow, I show hash codes as decimal\nnumbers to keep their length manageable.)\nTable 2-2: Password Table with Hashed Passwords\nAccount\nUsername Hash of password Balance\nnumber\nrichguy22 330,711,060,038,684,200,901,827,278,633,002,791,087 21647365$27.21\nmrgutman 332,375,033,828,033,552,423,319,316,163,101,084,85032846519$10,000.00\nsquire 295,149,488,455,763,164,542,524,060,437,757,020,45370023193$145,398.44\nburgomeister78 133,039,589,388,270,767,475,032,770,360,311,206,892 74766333$732.23\nWhen a user tries to log in, the submitted password is hashed and the result compared\nto the stored hash code. If they match, the user is logged in. Because the hash function\nWOW! eBook\nwww.wowebook.org\nisn’t reversible, getting access to the table isn’t the same as getting access to the\npasswords. An attacker can’t log on to an account with the hash code.\nThe account number and balance are still stored as plaintext, though, and it would be a\ngood idea to encrypt them, making a table with only hash codes and ciphertext. The\nproblem is if we used the hash of the password as our cipher key, then encrypting the data\nprovides no additional protection because anyone who acquires this table will be able to\ndecrypt the ciphertext.\nThere are several ways to solve this problem. One solution is to use one hash function\nto transform the password for authentication and another hash function to transform the\npassword into a cipher key to encrypt the account number and balance. As long as the\nhash functions are not reversible, this solution would provide security for the account data\neven if an attacker got access to the table.\nDictionary Attacks\nHashing the passwords is a good defense against attackers, but it’s not enough.\nAuthentication systems are still vulnerable to dictionary attacks.\nIn a basic dictionary attack, the attacker has no access to the password table and must\nguess the password. The attacker could just try random jumbles of characters but will have\nmuch more success with a dictionary, which in the world of software is simply a list of\nwords. In this case, the dictionary is a list of the most common passwords, and it begins\nsomething like this:\n• password\n• 123456\n• football\n• mypassword\n• abcdef\nTo foil the basic dictionary attack, most sites count the number of failed logins and,\nafter a certain number (perhaps as few as three), temporarily prevent further login attempts\nfrom a particular computer. This renders the attack impractical by increasing the time\nrequired to find the right password.\nA different form of dictionary attack is used when an attacker has acquired a copy of a\nhashed and encrypted password table. In this case, the attacker hashes each password in\nthe dictionary and compares it to each of the hash codes in the stolen table. When a match\nis discovered, the attacker knows the password that generates that user’s hash code. To\nsave time, the attacker can run all the passwords in the dictionary through a selected hash\nfunction once and store the results in a dictionary like in Table 2-3.\nTable 2-3: Dictionary with Hash Codes\nPassword MD5 hash code\nWOW! eBook\nwww.wowebook.org\npassword 126,680,608,771,750,945,340,162,210,354,335,764,377\n123456 299,132,688,689,127,175,738,334,524,183,350,839,358\nfootball 74,046,754,153,250,065,911,729,167,268,259,247,040\nmypassword 69,792,856,232,803,413,714,004,936,714,872,372,804\nabcdef 308,439,634,705,511,765,949,277,356,614,095,247,246\nDictionaries demonstrate why it is important for users to choose passwords that aren’t\nobvious. The more obscure a password, the less likely it will be in an attacker’s dictionary.\nHash Tables\nUnfortunately, an attacker can dispense with the dictionary altogether and build a table of\nrandomly generated passwords and their corresponding hash codes, which I’ll call a\nprecomputed hash table. Of course, the number of potential passwords is enormous, so if\nthe attacker wants a decent chance of getting a match, the hash table needs to be huge.\nBuilding a precomputed hash table takes a lot of computing power and time, but it only\nhas to be built once, and then it can be used over and over again.\nOne weakness of the table is that its sheer size can make searching for a match\nextremely slow. When you consider how fast a word processor can find a particular word\nin a large document, this may seem surprising, but these precomputed tables are much\nlarger than any file on your computer. Suppose an attacker has a table of all passwords\ncomposed of 10 or fewer uppercase and lowercase letters and digits. Even with these\nrestrictions, the number of potential passwords is 6210, which is 839,299,365,868,340,224.\nThe precomputed hash table won’t need every one of these potential passwords as entries,\nbut it would need to have a sizable fraction. The table would be so large, though, it\ncouldn’t fit in a computer’s internal memory. It couldn’t even fit on a hard drive—or just\nto get to the point, it’s so big it might need to be split across a million hard drives. And\nthat’s just the storage problem. Unless you have the distributed computing power of\nGoogle, it’s not practical to search a table that large. (And searching a huge mass of data\nisn’t easy even for Google; we’ll explore searching in detail in Chapter 7.)\nHash Chaining\nBecause a precomputed hash table is too large to store and search, attackers use a clever\ntechnique called hash chaining to drastically reduce the number of entries in the table\nwithout reducing its effectiveness. This technique uses a different type of function called a\nreduction function that does the same sorts of mathematical gyrations as a hash function\nbut with the opposite purpose. Instead of creating a hash code from a password, it creates\na password from a hash code—not the password that produced the hash, but simply a\nsequence of characters with the form of a valid password.\nWOW! eBook\nwww.wowebook.org\nHere’s an example of hash chaining. When glopp26taz is hashed using MD5, it\nproduces this hash code:\n22,964,925,579,257,552,835,515,378,304,344,866,835\nA reduction function transforms this hash code into another valid password, say,\n7HGupp2tss. This, in turn, is sent through the hash function, producing another hash code,\nwhich is sent through the reduction function to generate another password, and so on. An\nalternating series of passwords and hash codes, such as that shown in Figure 2-7, is a hash\nchain.\nFigure 2-7: In a hash chain, a hash function (H) alternates with a reduction function (R)\nthat produces an arbitrary password from a hash code.\nInstead of a table of passwords and hash codes, the attacker generates a series of hash\nchains, each of the same length, storing only the first and last links of each chain. The\nchain in Figure 2-7 is shown as the third entry in Table 2-4. This table has 5 entries, but\neach entry is a chain of 3 password/hash pairs, making this the equivalent of a plain table\nof 15 entries.\nTable 2-4: Hash Chain Table\nStart End\nsop3H4Yzai 302,796,960,148,170,554,741,517,711,430,674,339,836\n5jhfHTeu4y 333,226,570,587,833,594,170,987,787,116,324,792,461\nglopp26taz 33,218,269,111,507,728,124,938,049,521,416,301,013\nYYhs9j2a22 145,483,602,575,738,705,325,298,600,400,764,586,970\nWOW! eBook\nwww.wowebook.org\nPr2u912mn1 737,08,819,301,203,417,973,443,363,267,460,459,460\nFigure 2-8 shows an example of using the table. Our attacker is trying to recover the\npassword for the target hash code 117,182,660,124,686,473,\n413,705,332,853,526,309,255. The attacker must determine which chain in the table, if\nany, contains the target hash code. First, the target code is compared against every number\nin the End column of the table. In this case, no match is found, so the attacker runs the\ntarget hash code through the reduction function to make a new password, runs that result\nthrough the hashing function, and then searches for this new hash code in the End column\nof the table. This process will continue until a match is found, or after the process is run\nthree times (the length of the chains in this table).\nIn this case, the initial target hash value is reduced to the password pRh7T63y, which,\nin turn, is hashed, and this new hash value appears in the third entry of the table, in the\nchain with the starting password glopp26taz. That identifies the hash chain in which the\ntarget password may appear, but the attacker must obtain the password by iterating\nthrough this chain. The starting password in that chain is hashed; the resulting hash value\nis not a match for the initial hash value, so it is reduced to a new password, 7HGupp2tss,\nand hashed again. This hash code does match, which means 7HGupp2tss is the password.\nHash code chains dramatically shrink the table while still providing the same amount\nof searchable data. For example, if a chain has 100 passwords and 100 hash codes, then\nthe password matching any of those hash codes can be indirectly retrieved using that\nchain, even though the chain has only one password and hash code in the table. Therefore,\na table with chains that long has the power of a regular precomputed hash table 100 times\nlarger.\nThere are some potential snags, though. For one, searching takes more computational\neffort with hash chains. Also, because of collisions—multiple passwords that produce the\nsame hash code—a matching chain doesn’t necessarily contain the searched-for hash code\nand its matching password, a problem known as chain merging. These are small\nconsolations for those of us worried about our data security, however. There are methods\nfor reducing the chain merging problem, but even without them, it’s clear that effective\nprecomputed tables can be made for particular hash functions, rendering the passwords\nthat use them vulnerable.\nWOW! eBook\nwww.wowebook.org\nFigure 2-8: Using a hash chain table to find a password that produces a particular hash\ncode. Neither the password nor the hash code is listed in the table.\nIterative Hashing\nOne way to thwart the creation of precomputed hash tables is to apply the hash function\nmore than once. Because the output of a hash function can itself be hashed, the original\npassword can pass through the same hash function any number of times. This technique,\nunhelpfully, is also known as hash chaining, but to avoid confusion, I will refer to it as\niterative hashing. Figure 2-9 shows a five-deep iterative hashing of the password football.\nWOW! eBook\nwww.wowebook.org\nFigure 2-9: Applying a hash function repeatedly\nWith this technique, passwords are repeatedly hashed when the password is stored and\nwhen the user logs in. To thwart this, the attacker has to produce a table based on the same\nidea, running the chosen hash code function the same number of times. From Kerchkoffs’s\nprinciple, we know that cryptographic systems shouldn’t depend on keeping their methods\nsecret. The goal of iterative hashing isn’t to disguise how many times the password is\nhashed, but to make the creation of the attacker’s precomputed hash table as difficult as\npossible. In the example, the password runs through the hash function five times. That\nwould multiply the time needed to create the attacker’s table by five as well. In real-world\nuse, passwords can be run through hash functions hundreds or thousands of times. Is this\nenough to prevent the creation of useful precomputed hash tables? Maybe. Computers get\nfaster every day. For the most part, this is wonderful, but the downside to ever-increasing\ncomputational power is that it keeps pushing the boundary of practical limitations, and so\nmuch of our information security is based on these practical limitations.\nSomeone setting up a password system based on iterative hashing has to choose the\nnumber of iterations. It’s fairly easy to choose a number that provides good security today.\nWhat’s difficult is predicting the number of iterations required a year from now, or 2\nyears, or 10.\nYou might think the best choice is some impossibly large number to guard against the\npower of future computers. The problem is that today’s computers would have real trouble\nprocessing legitimate logins. Would you be willing to wait five minutes to access one of\nyour online accounts?\nSalting Passwords\nAuthentication systems need a way to strengthen hashing without a performance-crushing\nnumber of hash iterations; that is, they need a method of storing passwords that requires\nan impractical time investment from attackers without creating an equally unrealistic time\nWOW! eBook\nwww.wowebook.org\nburden on legitimate access. That method is called salt. Salt is an apt term for this concept,\nand I commend whoever came up with it. In culinary usage, a pinch of salt profoundly\nchanges the flavor of a dish. In cryptography, a small quantity of salt sprinkled on a\npassword dramatically changes its hash code.\nHere’s how it works: when a new user signs up for an account and selects a username\nand password, the system automatically generates the salt for that account. The salt is a\nstring of characters, like a short, random password, that is combined with the user’s\npassword before hashing. For example, user mrgutman chooses falcon as his password,\nand the system generates h38T2 as the salt.\nThe salt and password can be combined in various ways, but the simplest is appending\nthe salt to the end of the password, resulting in falconh38T2 in this example. This\ncombination is then hashed, and the hash code stored in the authentication table along with\nthe username and the salt, as shown in Table 2-5.\nTable 2-5: Password Table Using Salt\nUsername Salt Hash of password + salt\nrichguy22 7Pmnq 106,736,954,704,360,738,602,545,963,558,770,944,412\nmrgutman h38T2 142,858,562,082,404,032,402,440,010,972,328,251,653\nsquire 93ndy 122,446,997,766,728,224,659,318,737,810,478,984,316\nburgomeister78 HuOw2 64,383,697,378,169,783,622,186,691,431,070,835,777\nEach time a user requests access, the salt is added to the end of the entered password\nbefore hashing. An attacker who acquires a copy of this authentication table can’t get\nmuch use out of a precomputed hash table. Although the table might have a password that\nhashes to the given code, that password won’t produce the right code when combined with\nthe salt. Instead, the attacker would need to create a table for a specific salt. That could be\ndone, but remember that the salt is randomly chosen. If there are, say, 100,000 users in a\nstolen authentication table, and the salts are numerous enough that no salt is duplicated in\nthe table, the attacker will need to create 100,000 tables. At this point, we can’t even call\nthem precomputed tables because the attacker is creating them for each attack.\nAre Password Tables Safe?\nSalting and iterative hashing are typically used together, creating real headaches for an\nattacker. Iterative hashing increases the time requirement for creating a single\nprecomputed hash table, and salting means an attacker has to make a multitude of tables.\nBut is this combination enough?\nThere is no definitive answer to that question. Cryptography researchers and security\nexperts continue to develop new defenses against unauthorized access. At the same time,\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "How does public-key cryptography solve the shared key problem in secure data transmission?",
    "summary": "The text discusses the challenges of securing passwords and data on the web, highlighting how attackers continuously find new ways to breach defenses. It explains that while users can't always know if a site uses the best security practices, password storage services can help by using a master password to encrypt other passwords, making them secure even if the server is compromised. The text then delves into RSA encryption, a public-key cryptography method that uses a trapdoor function to securely transmit data and authenticate messages. It also covers how HTTPS uses RSA and AES together to create a secure, authenticated connection, and notes that while web security is complex, it's an ongoing process requiring constant updates and best practices to stay ahead of attackers.",
    "output": "though, attackers continue to find new methods to penetrate defenses. Advances in\ncomputational power and programming theory help whichever side takes advantage of\nthem first.\nPerhaps the most important lesson of this discussion is that security is often out of the\nuser’s hands. There will always be vulnerabilities, but there’s no way for a user to know if\na particular site or service is employing the best security practices. The salt technique, for\nexample, benefits only systems that use it, and not every system does.\nPassword Storage Services\nThat’s how passwords are stored on remote authentication systems. What about on the\nuser end? How do we safely store our passwords?\nA long time ago, I had so few passwords that I could safely entrust them to my\nmemory, but eventually I knew I had to store passwords outside of my head. Writing the\npasswords on a piece of paper, though, is just a different kind of security liability. For a\nwhile, I had an elaborate homebrew solution involving a .txt file encrypted with AES and\nstored on a memory card that was kept in a metal box that was probably not 100 percent\nfireproof. This arrangement worked, except that every time I needed to look up a\npassword, I had to go to the box, get the memory card, slot it into my computer, double-\nclick the file, type the password (the one password I had to remember), and find the\ndesired entry in my table.\nEventually I threw in the towel and signed up for a web-based password storage\nservice. When I created an account with the service, I chose a master password. I then\nstored all my other passwords and usernames on this website. This information is stored in\na way that renders it of little use to anyone who gains access to the raw data, so if my\npassword at Amazon is chickenfat (it isn’t), then the word chickenfat isn’t stored anywhere\non the password storage server. Instead, the passwords are encrypted by a program on my\nbrowser before being sent to the password storage site, using my chosen master password\nto generate the encryption key. Therefore, even if the server were breached, the attacker\nwouldn’t be able to retrieve my individual passwords without the master password.\nThe master password itself is not stored on the password storage site, either. When the\nencryption key is needed to encrypt or decrypt an individual login, the master password is\nsalted and then hashed repeatedly, for as many iterations as I specify.\nAlthough using a password storage service puts all of my eggs in one basket, so to\nspeak, this frees me to use best practices for individual logins. Whereas previously I might\nhave created passwords that were collages of words and numbers I thought I could\nremember, now my passwords are lengthy random jumbles. And they are all different\nbecause I no longer need to remember them all.\nA Final Thought\nIn all of this talk about authentication systems, I’ve avoided a crucial detail.\nAuthentication systems compare stored user passwords to passwords provided during\nlogons, but how does the remote computer doing the authentication get the users’ chosen\nWOW! eBook\nwww.wowebook.org\npasswords in the first place? Secure transmission requires encryption, which implies the\nusers would have had to encrypt the passwords—but how could the remote system decrypt\nthe encrypted passwords without having the passwords already? This brings us back to the\nshared key problem—none of what we talked about in this chapter can work unless that\nproblem is solved. So that’s what we’ll do next.\nWOW! eBook\nwww.wowebook.org\n3\nWeb Security\nYou may not have realized it before, but the Internet as we know it couldn’t exist without\na solution to the shared key problem. Think about a typical situation: you’re buying\nsomething at an online retailer that you’ve never purchased from before. At some point\nyou will be asked for your credit card data. Your browser tells you that your data is secure,\nperhaps by displaying a “lock” icon in the corner. But for the browser to protect your card\nnumber using AES, both your system and the retailer must use the same encryption key.\nHow do two systems securely transmit data without getting together beforehand to\nexchange a key?\nSolving this shared key problem is essential to providing any security on the Web.\nWe’ll explore the solution to the shared key problem in this chapter, which uses all the\ntechniques we’ve seen in the previous two chapters, plus a new special ingredient: public-\nkey cryptography.\nHow Public-Key Cryptography Solves the Shared Key\nProblem\nIn the world of physical security, the shared key problem has a straightforward solution\nbecause locks and keys are two separate things. Suppose person A needs to ship\nconfidential physical documents to person B. Person B could buy a strongbox and a keyed\nlock and then mail the box and lock to person A while keeping the key. Then person A\nputs the documents in the box, locks the box with B’s lock, and ships the box back to B.\nBecause B has the only key to the lock, this is a secure delivery method.\nThis is the desired situation for transmitting data digitally as well. We need to separate\nthe methods for locking and unlocking data, so that knowing how to encrypt data won’t\nprovide the means to decrypt the resulting ciphertext.\nIn Chapter 1, we learned about AES, which is a symmetric-key encryption method,\nmeaning the same key is used for encryption and decryption. For transmission, we need an\nasymmetric-key encryption method, with one key for encryption and another key for\ndecryption. The encryption key is known as the public key, because it can be freely\ndistributed with no ill effects if it falls into the hands of an attacker; for this reason,\nasymmetric-key encryption is also known as public-key cryptography. The decryption key\nWOW! eBook\nwww.wowebook.org\nis known only to the recipient, so it’s known as the private key. These relationships are\nshown in Figure 3-1.\nFigure 3-1: Asymmetric-key encryption, with a public key for encryption and a private key\nfor decryption. Only the receiver has the private key.\nMath Tools for Public-Key Cryptography\nWhat public-key cryptography requires, then, is an encryption method that’s reversible but\nnot with the cipher key that was used in the encryption. The basic tools of the encryption\nmethods we’ve seen so far won’t work for public-key cryptography. The most common\noperation in AES, for example, is exclusive-or, which is used precisely because when\nsomething is XORed twice with the same binary number, you get the same number you\nstarted with. Reversible operations such as XOR inevitably lead to having the same key\nfor encryption and decryption.\nPublic-key encryption, therefore, requires a new technique. As it turns out, the secrets\nto public-key encryption lie in the hidden relationships between numbers. In order to\nexplain what those relationships are and how they can be exploited for cryptography, we\nneed to go over a few pieces of math terminology.\nInvertible Functions\nBroadly stated, a function describes any situation where each numerical input results in a\nsingle numerical output. The current Celsius temperature, for example, is a function of the\ncurrent Fahrenheit temperature. For any particular temperature in Fahrenheit degrees,\nthere is exactly one matching temperature in Celsius degrees.\nIn the same way, the monetary value of a pile of coins is a function of the number of\ncoins of each type. A pile containing three quarters, two nickels, a dime, and four pennies\nhas a monetary value of 99 cents. This pile of coins cannot be worth any other amount.\nSometimes a function can be reversed to produce another function. If we know a\ntemperature in degrees Fahrenheit, we also know it in degrees Celsius, and the reverse is\ntrue: if we know a temperature in Celsius, we can also figure it out in Fahrenheit. In\nmathematical terms, we would say that the Celsius-to-Fahrenheit function is the inversion\nof the Fahrenheit-to-Celsius function, and that the original function is invertible. The coin\nWOW! eBook\nwww.wowebook.org\nexample, though, is not invertible. The same total monetary value can be produced by\nmultiple combinations of coins. If the coins in my pocket are worth 99 cents, I might have\nthree quarters, two nickels, a dime, and four pennies, or I might have nine dimes and nine\npennies, or some other combination.\nOne-Way Functions\nFor some invertible functions, computing in one direction may be a lot easier than the\nother. For example, the mathematical concepts of square and square root are\ncomplementary functions. Suppose you have a square room in your home that is covered\nin black-and-white tiles, as shown in Figure 3-2. To find the total surface area of the floor,\nyou multiply 12 by 12 to get 144.\nWe say that 144 is the square of 12. Going in the other direction, we say that 12 is the\nsquare root of 144. These are both functions; each number has one square and one square\nroot. The difficulty of computing these two functions is very different, though. Figuring\nout a number’s square is easy: you just multiply the number by itself. Figuring out the\nsquare root is hard. Unless you have a table of values to help you, computing a square root\nis effectively a trial-and-error process. You make a guess at what the root might be,\nmultiply that guess by itself, see if your guess was too high or too low, and then adjust\nyour next guess accordingly, repeating the process until you find the exact square root or\nget close enough that you are willing to stop. When a function is invertible but its inverse\nis much harder to compute, it is called a one-way function.\nFigure 3-2: A square room with walls 12 feet long has a total area of 144 feet.\nTrapdoor Functions\nAsymmetric encryption requires a one-way function so that the encryption key can be\npublic—the encryption will be easy, but the decryption will be so hard as to be infeasible.\nThe problem is, we shouldn’t make the decryption infeasible for the intended recipient as\nwell. So any old one-way function isn’t going to do the trick. We need what’s known as a\ntrapdoor function, a one-way function where the inverse function is hard in general, but\neasy when some secret value is known.\nWOW! eBook\nwww.wowebook.org\nPrime Numbers\nThe particular trapdoor function we’ll discuss involves prime numbers. A number is prime\nif it is greater than 1 and can only be divided (without a remainder) by itself and 1. For\nexample, 5 is prime because it can be divided only by itself and 1. It cannot be evenly\ndivided into 2, 3, or 4 parts. The number 6, though, can be divided by 2 and 3 in addition\nto 1 and itself. It is therefore a nonprime, or composite, number. Smaller numbers that\ndivide into a larger number are known as the larger number’s factors. Every number is\ndivisible by itself and by 1, but we call these trivial factors and tend to ignore them when\ndiscussing factors. A prime number has only trivial factors.\nCoprime Numbers\nIn a related concept, two numbers are said to be coprime if they share only 1 as a factor.\nEither number may or may not be prime itself, but each can be thought of as prime as far\nas the other number knows. For example, the composite numbers 9 and 4 are coprime\nbecause there is no number that divides them both except for 1. In contrast, 6 isn’t coprime\nwith either 9 or 4, because 6 shares factors with both. These relationships are\ndemonstrated in Table 3-1.\nTable 3-1: Showing that 9 and 4 Are Coprime, but 6 Is Not Coprime with 9 or 4\nDivisor Remainder from 9 Remainder from 6 Remainder from 4\n9 (trivial)\n8 1\n7 2\n6 3 (trivial)\n5 4 1\n4 1 2 (trivial)\n3 0 0 1\n2 1 0 0\n1 (trivial) (trivial) (trivial)\nAlthough 1 is not a prime number, it’s considered to be coprime with every other\nnumber.\nPrime Factors\nWOW! eBook\nwww.wowebook.org\nNow we are getting close to the hidden relationships that make public-key encryption\nwork. If we multiply two prime numbers, the resulting product has only those two prime\nnumbers as factors (again, not counting itself and 1). For example, 5 and 3 are prime\nnumbers. The product of 3 and 5 is 15, and 15 has only 3 and 5 as factors, as shown in\nTable 3-2.\nTable 3-2: The Product of Prime Numbers 3 and 5 Is 15, and 15 Has Only 3 and 5 as\nFactors\nDivide 15 by Result Remainder\n15 0 0 (trivial)\n14 1 1\n13 1 2\n12 1 3\n11 1 4\n10 1 5\n9 1 6\n8 1 7\n7 2 1\n6 2 3\n5 3 0\n4 3 3\n3 5 0\n2 7 1\n1 15 0 (trivial)\nThis is a one-way function. If I give you two prime numbers, you can easily multiply\nthem together, although you might use a calculator if the numbers are large. The inverse of\nthis function would mean starting with the product of two prime numbers and finding the\ntwo original primes. That’s considerably harder.\nWOW! eBook\nwww.wowebook.org\nLet’s take 18,467 as an example. This number is indeed the product of two primes—\nbut which two primes? To answer this question, you would need to divide 18,467 by every\nprime number starting from 2. Eventually you would discover that 18,467 divided by 59 is\n313, which means that 59 and 313 are the two prime factors.\nFinding the prime factors is very difficult if all you have is the product. However, when\nyou have the product and one of the two factors, finding the other factor is simple, because\nall you have to do is divide the first prime into the product. That makes it a trapdoor\nfunction—easy in one direction, hard in another unless you have the extra piece of\ninformation. If the prime numbers are large enough, finding the factors is infeasible\nwithout the trapdoor.\nThe RSA Encryption Method\nThis trapdoor function is at the heart of the RSA public-key encryption system, named\nafter the initials of its inventors: Rivest, Shamir, and Adleman. In actual practice, this\nsystem uses very large numbers to prevent a simple brute-force attack, but I’ll use small\nnumbers in a simplified example to more easily demonstrate how it works.\nSuppose that siblings Zed and Abigail share a bank account but live apart. Zed has just\nchanged the account’s four-digit PIN to 1482 and needs to send this new number to\nAbigail via email. Because email transmissions pass through many potentially insecure\ncomputers, the PIN must be encrypted in some way, but Zed and Abigail haven’t\npreviously shared a cipher key that would allow the use of a method like AES. Instead,\nZed will securely transmit the new PIN using RSA.\nCreating the Keys\nAlthough Zed has the confidential data to transmit in this example, the RSA procedure\nbegins with Abigail, who must produce a public key before Zed can encrypt the PIN.\nStep 1\nAbigail begins by choosing two prime numbers; let’s say she chooses 97 and 113.\nStep 2\nAbigail multiplies these two numbers together to get 10,961. To keep things straight, I’ll\ncall this number the prime-product.\nStep 3\nNext Abigail must compute a totient (which is pronounced TOE-shent, to rhyme with\nquotient). For a number N, the totient is the amount of numbers that are less than N and\ncoprime with N. For example, the number 15 is coprime with 1, 2, 4, 7, 8, 11, 13, or 14, as\nshown in Figure 3-3. Because there are eight numbers coprime with 15, the totient of 15 is\n8.\nWOW! eBook\nwww.wowebook.org\nFigure 3-3: The eight circled numbers have no factors in common with 15. Therefore the\ntotient of 15 is 8.\nComputing the totient of a number normally requires checking every smaller number\nfor common factors, and therefore it’s a lot of work—for huge numbers, finding the totient\nis practically impossible. However, if the number in question is the product of two prime\nnumbers, there’s a shortcut: simply subtract 1 from each of the two prime numbers and\nmultiply the results together. For example, 15 is the product of two primes, 3 and 5. If we\nsubtract 1 from each of the two primes, we get 2 and 4; if we multiply 2 and 4 we get 8,\nthe totient of 15.\nThis shortcut greatly aids Abigail, whose next step is computing the totient of the\nprime-product, 10,961. Since that is the product of the primes 97 and 113, the totient of\n10,961 is 96 × 112, or 10,752.\nStep 4\nNow Abigail selects a number that meets the following criteria:\n• Greater than 1\n• Less than the totient\n• Coprime with the totient\nLet’s say she picks 5. This is acceptable because it is greater than 1, it is less than 10,752,\nand there is no number other than 1 that divides both 5 and 10,752. Abigail is going to\nshare this number with Zed, so we’ll call it the public key.\nStep 5\nThe chosen public key determines Abigail’s private key, the number she has to keep\nsecret. For any given public key and totient, there is just one number that can serve as the\nprivate key, and we can identify it by testing successive multiples of the totient. For each\nWOW! eBook\nwww.wowebook.org\nmultiple, we add 1 and see if the result is divisible by the public key. When it is, the result\nof this division is the private key.\nThe process is demonstrated in Table 3-3. The first multiple of 10,752 is 10,752 itself;\nAbigail adds 1 to make 10,753, then divides by 5, getting 2,150 with a remainder of 3. She\ntries the second multiple, 21,504, and when she adds 1 and divides by 5, she gets 4,301\nand no remainder, so her private key is 4,301.\nTable 3-3: Finding the Private Key\nMultiple Multiply by 10,752 Add 1 Divide by 5 Remainder\n1 10,752 10,753 2,150 3\n2 21,504 21,505 4,301 0\nOf course, with larger numbers it may take a lot more multiples to find the private key,\nbut there is always one number that will pass the test. The number of multiples tested will\nalways be less than the public key (in our example, Abigail knows she’ll find the private\nkey in four tries or less). In any case, now that Abigail has her private key, the actual\nencryption can begin.\nEncrypting Data with RSA\nAbigail emails both her prime-product (10,961) and public key (5) to Zed. Because these\nnumbers don’t allow anyone to decrypt the resulting ciphertext, it doesn’t matter who else\nreads the email before it reaches Zed.\nThe actual encryption of the new PIN takes just two steps.\nStep 1\nZed raises the PIN, 1,482, to the power of the public key, 5—that is, 1,482 is multiplied by\nitself five times:\n1,482 × 1,482 × 1,482 × 1,482 × 1,482 = 7,148,929,565,430,432\nStep 2\nThe second step is to find the remainder of dividing the result of step 1 by the prime-\nproduct. In this case, 10,961 goes into 7,148,929,565,430,432 about 652 billion times, but\nall Zed cares about is that the remainder of that division is 2,122. Zed sends this remainder\nto Abigail.\nStep 3\nOn the receiving end, Abigail performs two similar steps to decrypt the ciphertext. She\nstarts by raising the ciphertext number, 2,122, to the power of the private key, 4,301.\nBecause 2,1224,301 is enormous—over 14,000 digits—I won’t show it here.\nWOW! eBook\nwww.wowebook.org\nStep 4\nAbigail finds the remainder of dividing the enormous number from step 3 by the prime-\nproduct. The remainder of that division is exactly 1,482, revealing Zed’s PIN.\nRSA Effectiveness\nRemember that the goal of RSA, like any encryption system, is making encryption easy,\ndecryption easy for the intended recipient, and decryption very hard for anyone else. A\nsummary of our RSA example is shown in Figure 3-4.\nEven using much larger primes, encryption and authorized decryption are easy with the\naid of the computer, as a review of the steps in our example will show.\n1. Abigail picked two prime numbers and multiplied them together to produce her prime-\nproduct. Multiplying two numbers together is easy.\n2. Abigail computed the totient of the prime-product by subtracting one from each of the\ntwo prime numbers before multiplying. Subtraction and multiplication are easy.\n3. Abigail chose a public key, a number that shares no factors with the totient. For large\nnumbers, this would be impractical to find by hand, but for a computer, this is easy.\n4. Abigail found the appropriate value for her private key, which should, when multiplied\nby the number chosen for her public key, produce a number that’s 1 more than a\nmultiple of the totient. This is a chore to do by hand, but for a computer, this too is\neasy.\n5. Abigail sent Zed the prime-product and public key.\n6. Zed raised the PIN to the power of the public key. For a computer, this is relatively\neasy.\n7. Zed divided the result from the previous step by the prime-product and took the\nremainder. Division is easy.\n8. Zed sent the remainder to Abigail.\n9. Abigail raised the number Zed sent to the power of the private key. Easy.\n10. Abigail divided the result of the previous step by the prime-product and took the\nremainder, revealing Zed’s PIN. Easy.\nWOW! eBook\nwww.wowebook.org\nFigure 3-4: A summary of the RSA example. The box in the middle shows Zed’s\nresponsibilities; the rest are Abigail’s.\nRSA encryption and decryption by authorized parties is easy work for a computer, but\nunauthorized decryption is maddeningly difficult. To decrypt, an attacker must have both\nthe prime-product, which Abigail gives out freely, and the private key, which she keeps to\nherself. How could an attacker compute the private key? Finding that number means first\nfinding the totient of the prime-product, but remember, Abigail was only able to compute\nthe totient quickly because she knows the two prime numbers that created the prime-\nproduct. Without those two prime numbers, an attacker must find the totient the hard way\n—by checking every number less than the prime-product to find all the coprimes.\nWOW! eBook\nwww.wowebook.org\nIn our example, the prime-product is small, so it’s feasible for a computer to find the\ntotient in this brute-force manner. In actual practice, though, prime-products are huge, and\nfinding their totients isn’t feasible at all. In fact, an attacker would be better off searching\nfor the two primes that make the prime-product, to use the shortcut method of making the\ntotient. That still requires checking all numbers up to the square root of the prime-product,\nthough, so for large numbers this is as infeasible as finding the totient the long way.\nThe RSA encryption method therefore creates our desired digital equivalent of a\n“lockbox.” Encryption and decryption no longer share the same secrets, so knowing how\nto lock the data doesn’t provide the ability to unlock it.\nRSA Use in the Real World\nOur simplified example demonstrates the basics of RSA encryption, but for real-world\nuse, we have to consider a few other details.\nBidirectional Transmission\nThe system shown in the example allows for Zed to securely transmit to Abigail, but not\nthe other way around. If they wanted to send secure messages in either direction, Zed\nwould have to go through all the steps that Abigail did, making his own prime-product,\ntotient, public key, and private key, and sending the prime-product and public key to\nAbigail.\nKey Size\nIn RSA, the last step of either encryption or decryption is taking the remainder of division\nwith the prime-product, which means the plaintext number must be less than the prime-\nproduct. In the example with Abigail and Zed, then, the largest possible plaintext number\nis 14,960. That’s not a problem for Zed and his four-digit PIN, but for general use larger\nranges are needed.\nJust as important, the larger the value of the prime-product, the more difficult it will be\nfor an attacker to find the two prime factors. In other words, the size of the prime-product\ndirectly affects the security of encryption. In current practice, primes are chosen to\nproduce a prime-product with a minimum of 1,024 bits. As you may recall, the Advanced\nEncryption Standard described in Chapter 1 used only 128 or 256 bits for the key. So we\nare talking about a truly humongous number—1,024 bits is equivalent to a decimal\nnumber of over 300 digits.\nLong Plaintexts and Performance\nA 1,024-bit key allows the encryption of very large numbers. But a typical text, image, or\naudio file is a long series of small numbers, not one big number. How do we transmit a\nlong series of numbers using RSA? With AES, long files would be chopped up into as\nmany 128-bit blocks as necessary. In theory, we could do the same with RSA, chopping up\nfiles into a multitude of 1,024-bit blocks and applying RSA to each block. The problem is\nthat RSA encryption is much slower than AES.\nAES has more steps than the RSA Encryption Standard, but even so, AES is high-\nWOW! eBook\nwww.wowebook.org\nperformance because the steps themselves are so simple. The most common operations are\nXOR and shifting bits around, and these operations are individually trivial. You can grasp\nthis by working out the result of these operations in your head, as shown in Figure 3-5.\nFigure 3-5: Computing XOR or rotating bits to new positions is easy.\nIn contrast, the RSA process has only a few steps, but the reliance on exponentiation\nmeans more work overall. Consider a relatively small exponent: 1716. Written out, that’s\n…\n17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17 × 17\nTry working that out in your head, and you see the problem. Now imagine exponents\ninvolving numbers with hundreds of digits. Although a computer can handle these\ncalculations, exponents are clearly a lot more work than simple XORs. Because exponents\ntake so much time, using RSA for large amounts of data is impractical.\nCombining Systems\nThe solution to the RSA performance problem is simple: don’t transmit large amounts of\ndata with RSA. Instead, use RSA to transmit an encryption key for another, faster method,\nsuch as AES.\nReturning to Abigail and Zed, suppose Zed needs to send Abigail a long document that\nhe has already converted to a series of numbers using the ASCII table. Zed would prefer to\nencrypt the document using AES rather than take on the hard work of RSA. To use AES,\nthough, Zed and Abigail would both need to share an AES encryption key. RSA provides\nthe means to share that key safely. Zed can create the AES key himself, then encrypt it\nwith RSA using Abigail’s public key. Then Zed can encrypt the long document using\nAES, and Abigail can decrypt the resulting ciphertext using the key they now share. This\nprocess is illustrated in Figure 3-6.\nWOW! eBook\nwww.wowebook.org\nFigure 3-6: Combining RSA and AES to produce an asymmetric public-key system with\nhigh performance\nIn this figure, the A-lock symbol means “encrypted with AES” while the R-lock means\n“encrypted with RSA.” By sending both the AES-encrypted document and the AES key\nencrypted with her public RSA key, Abigail has everything necessary to decrypt the\ndocument, but an attacker intercepting the transmission won’t be able to decrypt the\ndocument without Abigail’s private key.\nBy combining the two encryption methods, we combine their strengths to get the high\nperformance of AES and the shared keys of RSA. Public-key encryption is typically used\nthis way, to initiate a symmetric-key encryption process that would otherwise be\nimpossible.\nRSA for Authentication\nPublic-key cryptography creates an authentication problem. Because the public key is just\nthat—public—anyone can send an encrypted message to the private key owner; therefore,\nthe recipient of a transmission cannot be certain of the sender’s identity. This problem\nWOW! eBook\nwww.wowebook.org\ndoesn’t occur with symmetric-key encryption, because the secrecy of the one key, when it\ncan be shared, ensures not only the security of the message but also that the message\noriginated with the other person who has the key. Luckily, public-key cryptography can be\nalso be used to authenticate.\nAuthentication Using RSA\nIn our RSA example, Abigail has her prime-product of 10,961 and her private key of\n4,301, while Zed has the prime-product and Abigail’s public key of 5. This allows Zed to\nsend a secure message to Abigail, but it also allows Abigail to send an authenticated\nmessage to Zed.\nSuppose Abigail wants to send that same PIN, 1482, back to Zed to acknowledge its\nreceipt, and in such a way that Zed can be sure the acknowledgment comes from Abigail.\nAbigail takes the PIN, 1,482, and raises it to the power of her private key (instead of\nthe public key used for encryption). 1,4824,301 is another huge number—it has over 13,000\ndigits—so I’m not going to write it here, but when that huge number is divided by the\nprime-product of 10,961, the remainder is 8,742. Abigail sends an email with that\nremainder to Zed. Zed now raises that 8,742 to the power of Abigail’s public key, 5, which\nresults in 51,056,849,256,616,667,232. Finally, Zed divides that number by the prime-\nproduct, getting a remainder of 1,482. Zed recognizes this number as the PIN, and knows\nit must have been transformed using Abigail’s private key, proving the number came from\nAbigail. The relationship between security and authentication in RSA is shown in Figure\n3-7.\nFigure 3-7: The RSA process provides either encryption or authentication.\nWe can authenticate entire files by applying this authentication process to the\nencryption key of a system like AES and sending the encrypted file and the authenticated\nkey to the recipient.\nThe RSA process can therefore produce an authenticated message or a secure message,\ndepending on whether we encrypt with a private key or a public key. Ideally we’d like\nmessages to be both authenticated and secure. We can accomplish this by applying both\nvariations of the process to the same message. In our example, illustrated in Figure 3-8,\nAbigail could encrypt the number she wants to transmit with her private key, then encrypt\nWOW! eBook\nwww.wowebook.org\nthe result with Zed’s public key. Upon receipt, Zed would reverse the procedures, first\ndecrypting with his private key, then again with Abigail’s public key.\nFigure 3-8: Applying the RSA with the sender’s private key and the recipient’s public key\nprovides authentication and security.\nIdentity Authorities\nYou may have noticed that authentication introduces a subtler version of the shared key\nproblem. Zed knew the email came from Abigail because he recognized the PIN produced\nwhen he transformed the number using Abigail’s public key, which means the sender must\nhave the matching private key. But if Zed is worried about someone pretending to be\nAbigail, how exactly does he know that the public key was sent by Abigail in the first\nplace, not by an imposter who has hacked Abigail’s email account?\nThe solution to this problem is an authority, a third party that helps verify identities. As\nyou’ll see, authorities provide the digital equivalent of ID cards. When two computers\ninitiate a secure, authenticated transmission through the exchange of public keys, they\nshow their IDs, which assures each computer of the identity of the other. Of course, this\nassumes each computer trusts the authority providing the ID, so in the end, authentication\nrequires having implicit faith in someone. One either trusts that the transmission comes\nfrom the entity that claims to have sent it, or one trusts some third party to identify the\nsender. Identity authorities form a crucial component of the ultimate subject of this\nchapter, web security.\nSecurity on the Web: HTTPS\nWeb pages are transferred using HTTP, which stands for Hypertext Transfer Protocol.\nWhen this data is transferred securely, it is called HTTPS, where the S stands for secure.\nThis is why you’ll see https at the beginning of your browser’s address bar when you are\ntransferring sensitive data—or I hope you do. Web security is something most people take\nfor granted, but it’s an amazing feat to instantly create trust and security between two\nautomated parties who may have just been introduced, requiring all the tricks and\ntechniques you’ve seen so far.\nWOW! eBook\nwww.wowebook.org\nFor this discussion, suppose you’re purchasing from a retail website using a computer\nor phone. In this scenario, your computer is known as the client. The computer running the\nwebsite for the retailer is the server. This is the first time you’ve made a purchase from\nthis retailer, so you have to provide shipping and billing information such as your address\nand credit card number. This situation cries out for security, but it requires authentication\nas well.\nTo see why, you have to remember that your computer is not directly connected to the\nserver. Your data will be passed along from system to system, through computers managed\nby your Internet service provider (ISP) and those managed by the retailer’s ISP, and\npossibly through intermediate systems managed by neither. It’s possible for any of these\nsystems to be compromised by attackers such that the infected system would intercept\ntransmissions headed for the retailer, responding in its place. If this happens, when you\nplace your order, you’re giving your data away to attackers, not to the retailer. Although\nthe data is encrypted, it is encrypted with the key provided by the compromised system, so\nthe encryption ensures only that no one else eavesdrops on the data you are sending to the\nattackers. This sort of impersonation is known as a man-in-the-middle attack, and is foiled\nby good authentication.\nHandshaking\nSecure transmission of data occurs in sessions. A session is the web equivalent of a phone\ncall: an extended conversation that begins when you first load a page on a site and ends\nafter you have not interacted with the site for some predetermined amount of time.\nBefore the transmission can begin, your client and the server must successfully\nperform a ritual called handshaking. The name implies that it’s just two computers saying\nhowdy, but it’s more like a tense scene in a crime show where one guy doesn’t want to\nshow the “stuff” in the back of the van until the other guy shows the cash in the briefcase.\nThe handshaking phase, if successful, authenticates the server to the client, and creates the\nkey that will be used for encrypting the data throughout the session. As with Abigail and\nZed, a public-key encryption system is used just long enough to share the keys needed for\nthe better-performing private-key encryption system.\nStep 1\nThe client tells the server which encryption methods it supports. The HTTPS protocol\nallows computers to choose from a suite of acceptable methods for encryption, which\nmeans that different secure websites that you access may use different encryption\ntechniques providing higher or lower levels of security. In addition to the encryption\nsupport information, the client also provides a randomly generated number—the purpose\nof which you’ll soon see.\nStep 2\nThe server responds with its own list of supported encryption methods and also its\ncertificate. The server certificate contains several pieces of data, including the domain\nname of the site (such as amazon.com) and the name of the certificate issuer (the authority\nWOW! eBook\nwww.wowebook.org\nthat will verify the site’s identity). It also contains the server’s public key. HTTPS can use\nseveral different public-key cryptographic systems, but RSA is common. The server uses\nthe same certificate for every client it transacts with, so the public-and-private key pair\nonly has to be created once for each certificate. Although this means the server uses the\nsame RSA keys for all clients, as you’ll see, the RSA keys are used only during this\nhandshaking phase.\nThe server certificate also contains a signature. As discussed in Chapter 2, digital\nsignatures are hash codes. In this case, the server hashes the certificate data and encrypts\nthe hash code using the server’s private key.\nIn addition, the server also sends a random number to the client, just as the client has\nsent a random number to the server.\nStep 3\nThe client validates the certificate. There are two aspects to the validation. First, the client\napplies the server’s public key to the hash code in the certificate, then hashes the\ncertificate itself and compares the two hash codes. If the codes match, the certificate is\ninternally valid, but it doesn’t prove this is the actual certificate for the site.\nNow the client must check with the issuer of the certificate, a certification authority\nwith built-in trust with your browser. If you drill down into your browser’s options, you\nwill find a list of issuers under a heading such as “Trusted root certification authorities.”\nThe issuer provides a copy of the site’s certificate; when this matches the certificate\nprovided by the server, the client is assured of the identity of the server.\nStep 4\nThe client generates another random number, 48 bytes long, or 384 bits, known as the\npremaster secret. As the name implies, this number must remain a secret. However, the\nclient needs to send it to the server, so the client encrypts it using the server’s public key.\nStep 5\nThe client and server independently create the 384-bit master secret by hashing a\ncombination of the premaster secret and the two random numbers that were exchanged in\nthe first two steps. Once the master secret is created, the premaster secret and the other\ntwo random numbers are discarded.\nNote that the master secret is not exchanged between client and server. By this stage,\nboth the client and the server have all the numbers needed to create the master secret.\nThey independently run the numbers through the same process to produce the same result.\nA summary of the handshaking process is shown in Figure 3-9.\nWOW! eBook\nwww.wowebook.org\nFigure 3-9: The HTTPS handshaking procedure\nTransmitting Data Under HTTPS\nNow the client and server can begin sending actual data—web pages and media from the\nserver, and user data from the client. The 384 bits of the master secret are divided into\nthree 128-bit sections, each providing a different aspect of security.\nData Encryption\nThe first section of the master secret is used as the key for a private-key encryption system\nsuch as AES. Each of the subsequent data transmissions during the secure session will be\nencrypted using this cipher key.\nBlock Chaining\nBecause web pages have standard header formats that could provide cribs to attackers, a\nmethod such as block chaining (discussed in Chapter 1) is employed. As you may recall,\nsuch systems need a starting value to encrypt the first block of the transmission; the\nmiddle 128-bit section of the master secret is used as this starting value.\nMessage Authentication Code\nThe final 128-bit section of the master secret is used to create a message authentication\ncode, or MAC, for each transmission. In this case, we’re not trying to authenticate the\nWOW! eBook\nwww.wowebook.org\nidentity of the sender—that was already handled in the handshaking phase. Instead, the\nMAC ensures that data isn’t altered during transmission.\nIn this process, each transmission is hashed through a function like MD5, but first the\ntransmission data is combined with the remaining 128-bit section of the master secret.\nThis is known as keyed hashing, and the 128-bit section in this context is known as a MAC\nkey. Using a keyed hash helps foil man-in-the-middle attacks. An attacker who wishes to\npass a fake transmission to the receiver will need the MAC key to produce a hash code\nthat will be accepted as genuine by the receiver.\nThe hashing occurs before the encryption, so that both the original message and the\nhash code are encrypted.\nThe Shared Key Problem Solved?\nSo that’s how data is securely transmitted over the Web. As you can see, solving the\nshared key problem requires just about every trick in the cryptography toolkit. Public-key\nencryption creates the secure channel for initial communications. Private-key encryption is\nused to secure individual transmissions of data. Hashing authenticates both the session and\nindividual messages. If the site uses passwords to authenticate users, then all of the\npassword techniques from Chapter 2 would come into play as well.\nWeb security is a complex system of techniques. And therein lies a potential problem:\nthe complexity of computer security can hide weaknesses. Just as a machine with more\nparts has more parts that can break down, the layering of so many intricate methods and\ntechniques can mask undiscovered vulnerabilities. Sometimes the vulnerability is not\nwithin any one part, but in how the parts are connected. Although methods like RSA and\nAES are currently considered safe, clever attackers may find ways to break the security\nwithout breaking the underlying encryption methods.\nFor example, earlier versions of HTTPS were vulnerable to a particular man-in-the-\nmiddle attack that arose from the observation that most secure sessions begin with a user\nclicking on a link. Suppose, for example, that you have received an email from the bank\nthat issues your credit card with a link to your most recent account statement. The link is\nan HTTPS address, which means that when you click it, your browser will launch and\nrequest a secure connection with the bank’s server. However, this request itself is not\nsecure. An attacker’s program could intercept this request and pass it along to the bank\nserver as a request for a plain unencrypted HTTP connection, and then eavesdrop on all\nthe unencrypted traffic that followed. The user might be tipped off by the prefix in the\naddress bar, but how many users would think to check that? To cover this security hole,\nweb servers can now tell browsers that all connections must be made through HTTPS—\nbut that solution doesn’t foil an attacker who can intercept the announcement as well. The\nultimate solution may be to require HTTPS for all web communications.\nUndoubtedly new vulnerabilities will be found in the future, requiring the invention of\nnew defenses. Computer security is a moving target. We’ll never be able to declare our\ndata entirely safe, but relying on best practices may keep us one step ahead of attackers.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "How does software create digital images that mimic traditional cel animation?",
    "summary": "Computer-generated imagery (CGI) has revolutionized filmmaking by allowing the creation of complex scenes and characters that were previously impossible with traditional methods. It uses digital images made up of pixels, each defined by numerical data, to produce smooth animations and realistic visuals. Software now mimics traditional cel animation by numerically defining drawings, automatically generating in-between frames through interpolation, and using anti-aliasing techniques to smooth edges and blend into any background. These techniques are fundamental to 2D graphics and are widely used in computing for animations, video games, and user interfaces, but they form the basis for more advanced 3D CGI.",
    "output": "4\nMovie CGI\nSome of software’s most impressive work can be seen in movie theaters. Images that in\nearlier eras were painstakingly produced with models, matte paintings, elaborate\ncostumes, and trick photography are now created by computers. More than merely\nsimplifying the filmmaking process, computer-generated imagery (CGI) produces images\nthat would have been impossible before. For many filmgoers, movies changed forever\nwhen they saw Jurassic Park. When Steven Spielberg was developing the movie, he\nexpected to create his dinosaurs using old-school effects like automated puppets and\nanimated miniatures, but once he saw some computer-animated test footage, he decided to\nuse CGI for many of the dinosaur shots. The result left viewers astounded by images like\nthe panorama shown in Figure 4-1. For comparison, the old way to put a dinosaur in a\nmovie is shown in Figure 4-2.\nFigure 4-1: CGI dinosaurs visit the watering hole in Jurassic Park (Universal\nPictures/Amblin Entertainment, 1993).\nWOW! eBook\nwww.wowebook.org\nFigure 4-2: The Beast from 20,000 Fathoms (Jack Dietz Productions, 1953) munches on\nConey Island.\nAmazing as they were, films like Jurassic Park were just the beginning of the CGI\nrevolution. Now movies like Avatar create whole worlds using CGI, so that viewers are\nnever sure what parts of a shot are physically real, if any. With enough time and money, it\nseems like filmmakers can produce anything imaginable.\nBefore computers blew our minds with dinosaurs and lush alien planets, though, they\nwere transforming the world of traditionally animated movies. Using computers not only\nradically altered the process of traditional animation, but as you’ll discover, the concepts\nand techniques employed are the foundation for almost everything in computer graphics.\nThis is where the story of CGI begins.\nSoftware for Traditional Animation\nA movie is a series of still images, or frames, presented to the eye in rapid succession, like\na high-speed slideshow. Each frame lingers on the retina for a moment after it disappears\nfrom the screen, effectively blending with the next frame to provide the illusion of\ncontinuous motion—a phenomenon known as persistence of vision. Traditionally, movies\nare shown at a rate of 24 frames per second (fps). Making a movie means producing 24\nimages for every second of the film.\nA live-action movie uses a camera to collect images in real time. A traditionally\nanimated film like Lady and the Tramp, though, is created a bit differently: each frame of\nthe movie is an individually photographed, hand-crafted work of art.\nTraditional animation is a huge undertaking requiring a large team of artists. Typically,\neach character in an animated film is assigned a lead animator, but the lead animator does\nnot draw the character on every frame in which he or she appears, because that’s too much\nwork for one person. Instead, the lead animator draws only as many keyframes as are\nWOW! eBook\nwww.wowebook.org\nneeded to suggest the action—perhaps one out of every few dozen frames of a finished\nanimation sequence. Other animators draw the in-between frames to complete the\nsequence, a process known as tweening. At this stage, the animation is still just a series of\npencil drawings on paper. The drawings must be transferred to transparent cellulose\nsheets, which is why this style of animation is also known as cel animation. Then comes\nwhat animators call “ink and paint”: the faint pencil lines are traced over with black ink,\nand the cel is colored. Then the sheets are placed in front of a separately painted\nbackground and photographed.\nAs you might expect, tweening, inking, and painting are tedious, time-intensive jobs.\nBeginning around 1990, computer imagery has been used to mimic the cel animation style\nwith far less manual labor.\nHow Digital Images Work\nIn a traditional animated film, each frame is a photograph of physical art, but computer\nanimation works with digital images—pictures defined by numerical data.\nWhen you look at a video display such as a television, a smartphone screen, or a\ndigitally projected theater screen, the image that reaches your eyes is made up of dots of\nvarying colors, known as pixels. Figure 4-3 depicts a tree against a blue sky as a grid of\npixels. Each of the 100 pixels in this 10×10 grid is assigned a color, here specified by\nname.\nFigure 4-3: A tree made of pixels\nAlthough we can think of each pixel as a solid color, the underlying reality is a bit\ndifferent. For example, at home you might watch a movie on a common liquid crystal\ndisplay (LCD) television in which pixel colors are determined by electrically controlled\ncrystals. On the back of an LCD screen is a light source, either a fluorescent lamp or a\nseries of light-emitting diodes (LEDs). The light source itself is white. In front of the light\nis a translucent panel with bars in the three primary colors—red, green, and blue—as\nshown in Figure 4-4.\nWOW! eBook\nwww.wowebook.org\nFigure 4-4: Three bars of pure primary colors create one LCD pixel.\nA layer of liquid crystals lying between the light source and the color panel puts an\nindividually controlled crystal behind each of the translucent bars. You can think of these\ncrystals as electrically operated doors, and the degree to which each crystal door is open\ndetermines how much light gets through. By varying the amount of red, green, or blue,\nany one of millions of colors can be produced by each pixel. This is additive color mixing,\nin which adding more color makes the result brighter. If we want a particular pixel to\ncome across as bright yellow, for example, we would set the levels of red and green high,\nand the level of blue low. If we wanted a dark gray, we would set each of the color bars to\nthe same low intensity. All three colors at maximum intensity produce pure white. Later in\nthis chapter, we’ll see an example of subtractive color mixing, which is what you might\nremember from art class, where adding more color makes the result darker.\nHow Colors Are Defined\nThe most common way to define a pixel’s color is with the RGB system, which uses three\nnumbers to represent the intensity of red, green, and blue in the pixel. The numbers\ntypically range from 0 to 255 to match the range of an eight-bit byte. This means that each\nRGB pixel is specified by three bytes of data.\nAs far as software is concerned, a digital image such as that shown in Figure 4-3 is just\na list of bytes of color data, three bytes for each pixel. This block of bytes is known as the\nimage’s bitmap. The first three bytes in the bitmap are the red, green, and blue levels of\nthe pixel in the upper-left corner of the image, and so on. The width and height of an\nimage or bitmap in pixels is known as its resolution; for instance, Figure 4-3’s resolution\nis 10×10. A bitmap called a display buffer stores the colors of each pixel of a digital\ndisplay like an LCD television; ultimately, computer graphics methods are about setting\nthe numbers in a display buffer.\nThe location of a particular pixel in a bitmap is specified by two coordinates, an x-\ncoordinate for horizontal position and a y-coordinate for vertical position. The (0,0)\ncoordinate, known as the origin, can be located in a corner or in the center; it varies\namong different coordinate systems. When positioning pixels on a physical display, we\nrefer to coordinates as screen coordinates. Screen coordinate systems commonly set the\norigin at the upper-left pixel, so a 1920×1080 screen would locate pixels as shown in\nWOW! eBook\nwww.wowebook.org\nFigure 4-5. Here, the y-axis increases moving down the image, the x-axis increases\nmoving right across the image, and the center location is (960, 540).\nFigure 4-5: Locating pixels on a 1920×1080 screen\nCoordinate systems are a ubiquitous part of computer graphics and, as you’ll see in this\nchapter and the next, much of the work of producing graphics involves converting\ncoordinates from one system to another.\nHow Software Makes Cel Animations\nNow that you understand what’s inside a digital image, you’re ready to see how software\ncan make digital images that look like traditional cels. The first step is getting the artist’s\nwork inside the computer.\nTransforming Drawings into Models\nSoftware-generated cel animation starts the same way as traditional animation: with an\nartist sketching a character. Instead of drawing on paper, though, the artist draws with a\nmouse or an electronic stylus and the drawings are recorded by software. In order to\nultimately produce a bitmapped image, we need a system that defines the artist’s strokes\nnumerically, producing a model of the drawing. Locations within a model are called local\ncoordinates. Figure 4-6 shows a drawing of a bug-man within a box that defines the local\ncoordinate space.\nWOW! eBook\nwww.wowebook.org\nFigure 4-6: A bug-man drawing inside a box defining coordinate limits\nEach line and curve in this model is defined in terms of these local coordinates.\nStraight line segments, like the antennae and legs of our character, can be defined by the\ncoordinates of the points at either end of the line, as shown in Figure 4-7. Note that the\ncoordinates here have fractional parts to increase precision.\nFigure 4-7: Defining straight line segments using the coordinates of the end points\nFor curves, control points are needed in addition to end points to define the direction\nand amount of curvature. Imagine that the control point is attached to the curve so that\nmoving it controls the degree of curvature, as illustrated by the simple curves in Figure 4-\n8. If you’ve ever worked with a vector graphics application, you’ve likely worked with\ncurves like this.\nFigure 4-8: Curves defined by two end points and one control point\nSimple curves can be represented by just two end points and one control point, but\nlonger, more complicated curves are made up of sequences of simple curves, as shown\nwith the bug-man’s shoe in Figure 4-9.\nWOW! eBook\nwww.wowebook.org\nThe lines and curves define just the outline of a character or other drawing; the colors\ninside the outline are defined using a system such as RGB. The character model, then, is a\nnumerical representation of all the lines, curves, and color data.\nFigure 4-9: A complicated curve made of simple curves\nAutomatic Tweening\nNumerically defining drawings allows for automatic tweening. The animator draws one\nframe of a character’s animation sequence, then creates succeeding keyframes by moving\nthe control points of the curves in the previous frames. The animation software can then\ngenerate the other frames through interpolation. The concept is demonstrated in Figure 4-\n10. Here, the coordinates of the middle point are calculated as the average of the\ncoordinates of the other points. The x-coordinate of the interpolated point, 20, is halfway\nbetween 10 and 30; the y-coordinate, 120, is halfway between 100 and 140. In this\nexample, all the points lie on a line, but the interpolation path can be a curve as well.\nFigure 4-10: Computing a middle point between two keyframe points via interpolation\nFigure 4-11 shows how interpolation creates new frames of animation. The leftmost\nface is the original model; the second face shows some of the control points; and the third\nhas a wide mouth created by repositioning two of the control points downward. The\nrightmost face was created through linear interpolation, placing each control point halfway\nbetween the two keyframe positions. Animation software can create as many in-between\npositions as necessary to fill the gap between keyframes.\nWOW! eBook\nwww.wowebook.org\nFigure 4-11: From left: a model, the model with selected control points, the model with\ntwo of the control points moved, and a tweened model created by interpolation between\nthe positions of the previous two models\nAlthough basic interpolation tweening can be a huge time-saver, adjusting the positions\nof lots of little points remains tedious. More advanced animation software can treat a\ncharacter drawing as a complete, interconnected body, in which rigid connections and\njoints are specified. This means that an animator need only position the feet for each\nkeyframe to make our bug-man walk, and the software positions the rest of the legs\naccordingly. The software might even handle real-world physics, so that a sequence of\nimages of our bug-man falling over a log could be animated entirely by the software.\nPositioning and Scaling\nNumerical modeling also allows the drawings to be placed anywhere in a frame at any\nsize. Changing the size of a model is called scaling, and is accomplished by multiplying or\ndividing the coordinates for each of the points. Figure 4-12 shows the bug-man model of\nFigure 4-6 scaled down to a quarter of its original area by dividing each of the coordinates\nin half. One point on his antenna is highlighted to show the idea.\nPlacing a model in a particular location on the screen is called translation, and is\naccomplished by increasing or decreasing coordinates by fixed amounts. In Figure 4-13,\nthe shrunken bug-man from Figure 4-12 is translated to the middle of the screen by adding\n700 to each x-coordinate and 200 to each y-coordinate.\nWOW! eBook\nwww.wowebook.org\nFigure 4-12: Scaling a model means multiplying or dividing each of the coordinates.\nFigure 4-13: Translating a model means adding to or subtracting from coordinates.\n“Ink and Paint” for Digital Images\nNow that the points on the models are mapped to screen coordinates, it’s time to transform\neach frame into a bitmap. This is the software version of cel animation’s “ink and paint.”\nTo keep things simple, let’s look at how just the right arm of our bug-man model would be\nconverted to a bitmap, or rasterized, when displayed over a solid white background.\nFigure 4-14 shows the arm over a pixel grid, with circles marking the pixel centers.\nWOW! eBook\nwww.wowebook.org\nWith the model mathematically defined, the software can place the arm at any position\non the bitmap and then apply the indicated color—in this case, black—to the appropriate\npixels. Right away we see there’s a problem, though: the contours of the arm don’t match\nthe borders of pixels, so how do we determine which pixels to color? A simple rule is to\ncolor pixels when their centers are covered. Figure 4-15 shows the result of pixel-center\ncoloring.\nFigure 4-14: The right arm of the bug-man superimposed over a pixel grid\nFigure 4-15: Coloring pixels solid black based on pixel centers\nAs you can see, though, this result is rather ugly. Because the pixels are square, this\ncoloring rule replaces the gracefully curving border of the model with a jagged edge,\nwhich is why this problem is known as the jaggies. The general problem is that the model\nis smooth and continuous, while the bitmap is made with square black-and-white pixels.\nThe bitmap is just an approximation of the model. The discrepancy between continuous\nmodels and their bitmap approximations is known as aliasing, and is the source of many\nvisual anomalies in computer graphics.\nTo avoid the jaggies, we need to color pixels using an anti-aliasing technique. In our\nexample, instead of coloring the pixels black and white, we’ll use a range of grays to\nproduce a better approximation of the model. Each pixel will be colored based on how\nmuch of it is covered by the arm.\nIn order to put this idea into action, instead of checking only the center of each pixel,\nlet’s test several points in each pixel to see how many of them lie within the model. In\nWOW! eBook\nwww.wowebook.org\nFigure 4-16, 7 of the 10 testing points scattered around the pixel area are covered by the\nshape, meaning this is 70 percent coverage.\nThe percentage of each pixel covered by the model determines the gray level. The\nresult for our bug-man’s arm is shown in Figure 4-17. Although this example might not\nlook like much, if you hold the page at arm’s length and squint, the edges should appear to\nsmoothly blend into the white background, producing the illusion of a graceful curve.\nFigure 4-16: A close-up of one pixel at the end of the bug-man’s arm, with a scattering of\n10 points to estimate the area covered by the model\nFigure 4-17: Using grayscale to anti-alias, shown with and without the pixel grid.\nBlending into Any Background\nWe need to generalize the technique just described in order for it to work with a\nbackground other than solid white. Consider Figure 4-18. On the left is the bug-man\nmodel, and in the middle is the background for the shot in which he’ll appear: a close-up\nof a setting sun over a rocky terrain. On the right is the complete image with the model\nsuperimposed over the background.\nWOW! eBook\nwww.wowebook.org\nFigure 4-18: The bug-man model, a background, and the model superimposed over the\nbackground\nThis book is printed in black and white, but in this image the sun would be shades of\nreddish-orange and the ground would be shades of brown. As before, pixels along the\nmodel’s edge will appear jagged unless we use an anti-aliasing technique. But using the\nprevious technique to color pixels in gray tones won’t help the black edge blend into a\nbackground of red-orange and brown pixels.\nA more general anti-aliasing technique calculates an alpha level for each pixel based\non the percentage of the pixel that’s covered by the model. You can think of an alpha level\nas a measure of opacity. Like the color levels, an alpha level is typically defined in the\nrange of 0–255. In Figure 4-19, a black bar is superimposed over a tree at different alpha\nlevels. At an alpha level of 255, the bar is entirely opaque, while at 25 the bar is barely\nvisible. An alpha level of 0 would make the bar completely invisible.\nThe alpha levels of all the pixels in a bitmap are collectively referred to as its alpha\nchannel. The process of making an alpha channel for a model is similar to how we anti-\naliased the black arm against the white background, only rather than assigning a shade of\ngray based on the pixel’s coverage percentage, we assign an alpha value for the pixel\ninstead. Each model is thus conceptually transformed into both a bitmap, showing the\ncolor of each pixel covered by the model, and an alpha channel, showing the opacity of\neach pixel. Figure 4-20 shows the color bitmap (here, just black pixels) and the alpha\nchannel of the bug-man arm separately.\nFigure 4-19: A tree covered by five black bars of varying alpha level\nFigure 4-20: The arm of the bug-man model with its corresponding color bitmap and\nWOW! eBook\nwww.wowebook.org\nalpha channel\nNow the model can be applied to any background. The final color of each pixel is a\nblend of the color in the background and the model’s color bitmap, with the alpha level\ndetermining how much of each color goes into the mix. In the bug-man scene of Figure 4-\n18, if a black bug-man pixel with 30 percent alpha were placed on top of a red-orange\nsunset background pixel, the result would be a darker red-orange, as shown in Figure 4-21.\nThe resulting amount of each color component lies somewhere between the two mixed\ncolors, but because the black pixel is only 30 percent alpha, the red-orange background\ncolor dominates. For pixels completely covered by the model, the alpha level is 100\npercent and the color in the final image is the same as in the model’s color bitmap. In this\nway, a bitmap with an alpha channel can be smoothly blended into any background.\nFigure 4-21: The red, green, and blue components of three colors: the black of the model,\nthe red-orange of the background pixel, and the result of mixing these two colors if the\nblack has 30% alpha\nFrom Cel Animation Software to Rendered 2D Graphics\nThese techniques are now the default way to produce cel-style animation, and software is\nas common a tool for animation studios as brushes and paper were in earlier generations.\nWhile some animation studios use programs they developed themselves, most direct-to-\nvideo or television animation and some feature films are made with off-the-shelf software.\nOne such program, Toon Boom, has been used for television shows such as The Simpsons\nand Phineas and Ferb, while the artists at Studio Ghibli use a program called Toonz to\nanimate such movies as Spirited Away.\nThe usefulness of these techniques is not limited to filmmaking, though. More\ngenerally, the software techniques used to mimic traditional cel-style animation are called\ntwo-dimensional graphics, or 2D graphics, because the control points for models are\nlocated with two coordinates, x and y. The general task of transforming models into final\nimages is called rendering, and the software that performs the task is the renderer.\nRendered 2D graphics are used throughout computing. Many video games, such as Angry\nBirds, use the cel-animation look. These rendering techniques are also used to display\nfonts and icons in applications such as browsers and word processors.\nAlthough rendered 2D graphics are ubiquitous in computing and can make great cel-\nstyle animations, creating the mind-blowing visuals of films like Avatar requires\nextending these ideas to three dimensions.\nSoftware for 3D CGI\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What are the key differences between 2D and 3D graphics in terms of how they are described and rendered?",
    "summary": "CGI in films like Avatar uses 3D graphics, which involve three coordinates (x, y, z) for animation models. These models are rendered into bitmaps, and movie-quality rendering requires complex processing to achieve realism. 3D scenes are described using world coordinates, allowing models to be placed and viewed from multiple angles. Lighting in CGI is crucial for realism, with effects like direct, diffuse, and specular reflections, as well as global illumination, playing key roles. Ray tracing is used to simulate light paths and real-world effects like shadows and transparency, but it is computationally intensive. To overcome these limitations, filmmakers often use simplified techniques or combine CGI with live-action footage through digital composition.",
    "output": "Breathtaking CGI in films like Avatar use 3D graphics. The “3D” here doesn’t refer to\nsimulated depth perception, like in a 3D movie, but rather to the three coordinates of each\ncontrol point in the animation models: x- and y-coordinates for horizontal and vertical\npositioning and a z-coordinate to indicate depth. Figure 4-22 shows a three-dimensional\nmodel of a box with a highlighted point defined by x-, y-, and z-coordinates.\nFigure 4-22: A box in three-dimensional space\nAs with 2D graphics, 3D graphics are all about rendering models into bitmaps. The\nrendering methods that produce the most realistic results require the most processing time.\nMovie CGI is impressive largely because the renderer can process each frame for a very\nlong time, resulting in the high-quality result that I’ll call movie-quality rendering. We’ll\ndiscuss the keys to movie-quality rendering in this chapter. Then, in Chapter 5, we’ll talk\nabout graphics for video games, and see how many of the techniques shown here have to\nbe modified, faked, or scrapped altogether when images must be produced in real time in\nresponse to user interaction.\nHow 3D Scenes Are Described\n3D models are built out of lines and curves just like 2D models, but these lines and curves\nstretch across three dimensions instead of two. The box in Figure 4-22 is a very simple\nmodel defined by eight points; the models used in movie CGI tend to be complex, defined\nby hundreds, thousands, or even tens of thousands of points. As with 2D rendering,\nmodels in 3D rendering are defined by local coordinates. The points at the corners of the\nbox in Figure 4-22, for example, are defined relative to the local origin at the bottom of\nthe box.\nWhile 2D rendering can directly map from local coordinates to screen coordinates, 3D\nmodels are first placed into scenes in a virtual world that has its own coordinate space\ncalled world coordinates. Designing a 3D scene is the CGI equivalent of building a movie\nset. We can place as many models as we want in the virtual world, of any size and at any\nlocation, and the renderer can figure out the world coordinates for all the locations on the\nmodels.\nWOW! eBook\nwww.wowebook.org\nIntroducing another coordinate system might seem like an unnecessary complication,\nbut world coordinates actually make 3D graphics much easier in the long run. For\nexample, an artist can model a dining room chair independently of the other models for\nthe scene in which it will be used. Then the artist can copy the single chair model to make\nas many seats as needed for the dining room scene. Also, a scene, like a movie set, isn’t\nbuilt to produce a single image but to create a space that will be shown in many images\nfrom many different angles, as we’ll see in the next section.\nThe Virtual Camera\nWith the scenery in place, a viewpoint is needed. On a movie set, a cinematographer\ndetermines what image is captured by placing the camera and choosing a lens. For CGI,\nthe viewpoint determines how the three-dimensional scene is transformed into a two-\ndimensional rendered image.\nTransformation from three dimensions to two is known as projection. To better\nunderstand projection, consider Figure 4-23, in which an imaginary pyramid originates\nfrom the eye of a viewer looking at a table. A translucent grid lies in the pyramid between\nthe viewer and the scene. Looking through the grid, the viewer can map each visible\nlocation on the three-dimensional table to a particular square on the two-dimensional grid.\nThat’s projection, but instead of a grid of squares, it’s a grid of pixels in a bitmap.\nFigure 4-23: Projecting a three-dimensional scene onto a flat display is like viewing a\nreal-world scene through a translucent grid.\nDirect Lighting\nThere are many different methods of projection, but projection methods in movie-quality\nrendering are part of the larger issue of lighting. Although we don’t often realize it, our\nperception of an object’s color is determined not only by the object itself but also by the\nlighting under which we view the object. Knowing this, filmmakers carefully light their\nscenes for dramatic effect, but the problem of lighting in CGI is more fundamental.\nWOW! eBook\nwww.wowebook.org\nWithout an accurate model of scene lighting, the resulting images won’t look realistic at\nall.\nTo understand why this is true, let’s take a simple scene of a yellow metal table in a\ngreen room, as shown in Figure 4-24.\nFigure 4-24: A 3D scene\nFrom this viewpoint, some of the pixels will be “table” pixels and the others will be\n“wall” or “floor” pixels. A simple renderer might color every table pixel the same shade of\nyellow, while coloring all the other pixels an identical green. But because this coloring\nignores the effect of lighting, the resulting image would be flat and unrealistic. (The\nblocks of solid color would make the image resemble an animation cel—an interesting\neffect, but not realistic.) A movie-quality renderer needs a lighting model so that the colors\nin our scenes are influenced by virtual light sources.\nThe essential real-world lighting effects modeled by CGI renderers include distance,\ndiffuse reflection, and specular reflection.\nThe Distance Effect\nTo understand the distance effect, imagine a lamp emitting pure white light hanging\ndirectly over the middle of the table, as in Figure 4-25.\nThe closer this light is to the table, the brighter the table appears. In the physical world,\nthis effect is caused by the beam of light widening as it gets farther from its source. The\nmore narrowly focused a light source is, the less the light diminishes with distance—\nwhich explains why the highly focused light of a laser hardly diminishes at all.\nWOW! eBook\nwww.wowebook.org\nFigure 4-25: The closer a light is to a surface, the brighter the surface appears.\nRenderers can model the distance effect realistically, but they also allow unrealistic\ndistance effects in order to create a particular look or mood. For example, in a scene where\na character carries a torch through a cave, a lighting designer will decide whether the\ntorchlight extends a long way or barely penetrates the gloom.\nAll of the lighting effects we’ll discuss allow these kinds of adjustments. Although it\nmay seem strange to intentionally create unrealistic light when the whole point of the\nlighting model is to make a realistic scene, there’s a subtle but important distinction\nbetween reality and viewers’ expectations of reality. Using light in unrealistic ways is an\nold cinematic trick. For example, when a character in a darkened bedroom turns on a\nlamp, a stage light in the ceiling of the set also turns on, so that the entire scene is softly\nlit. Without the extra, unrealistic light, the scene won’t look right—it will appear too dark.\nIn the same way, CGI lighting models allow their controls to be tweaked to produce\nresults that are a little wrong, but feel right.\nThe Diffuse Reflection Effect\nLight that strikes a surface head-on appears brighter than light that strikes a surface at a\nsharp angle. In Figure 4-26, the center of the table seems brighter, or yellower, than the\ncorners.\nWOW! eBook\nwww.wowebook.org\nFigure 4-26: Diffuse lighting depends on the angle at which light strikes a surface.\nThis is due in part to the distance effect—the center is closer to the lamp than the\ncorners—but is mostly due to the diffuse reflection effect, a change in brightness caused\nby variation in the light’s angle of incidence. In Figure 4-27, the solid lines show the\nincident light rays, while the dashed lines are reflections. As you can see, the light strikes\npoint B at a much larger angle than at point A, and therefore point B appears brighter than\npoint A. But note that the viewing angle, or angle of reflectance, makes no difference in\nthe diffuse reflection effect. Therefore, point A will look the same to both viewers, and so\nwill point B.\nFigure 4-27: Diffuse lighting varies based on the angle at which the light strikes the\nsurface, but is the same for all viewpoints.\nThe Specular Reflection Effect\nBecause the metal tabletop is highly reflective, it partially acts as a mirror. As with any\nWOW! eBook\nwww.wowebook.org\nmirror, what you see in it depends on what lies on the opposite angle to your point of view.\nFigure 4-28 shows a shiny spot on the table where the hanging light is at the opposite\nangle from our viewpoint, approximately midway between the center of the table and the\nclosest edge. Because this spot is a mirror-like reflection of the white light bulb, the spot\nwill be white.\nFigure 4-28: Specular lighting depends on both the angle at which the light strikes the\nsurface and the view angle.\nThese shiny spots are known as specular reflections, and appear where the light’s angle\nof incidence matches the angle of reflectance. Figure 4-29 shows the location of specular\nreflections for two different viewpoints; notice that each ray rebounds at the same angle\nthat it struck the table. Both viewers see a shiny spot on the table, but they see the spot in\ndifferent places.\nIn the real world, some materials reflect differently than others. A shiny material like\nplastic has a high level of specular reflection, while a dull material like cotton cloth has\nmore diffuse reflection. CGI lighting models allow artists to set different reflection\nproperties for each surface on a model to match the appearance of real-world materials.\nWOW! eBook\nwww.wowebook.org\nFigure 4-29: The specular light on the table appears in different places for different\nviewpoints.\nGlobal Illumination\nSo far we’ve been discussing direct lighting, the result of light flowing directly from a\nsource to a surface. In reality, the color of every object in the physical world is influenced\nby the color of every other object nearby. A light-brown sofa in a room with white walls\nlooks very different than it does in a room with blue walls, because the sofa gains a subtle\ntint from the reflected light of the walls. This is indirect lighting, and for a computer-\ngenerated image to look realistic, it must account for this effect. A lighting model that\naccounts for all of the light in the scene, both direct and indirect, is known as a global\nillumination model.\nAn example of indirect lighting is shown in Figure 4-30. Let’s assume the light bulb\nemits pure white light. The beam first hits a wall that is painted cyan (a light blue). The\nlight reflecting from the wall is likewise cyan, and when the reflected cyan light strikes the\nyellow rug, the resulting reflected light is green. The bouncing colors therefore result in a\nsubtle greenish tint in the yellow rug. This sequence of color changes is caused by\nsubtractive color, where mixing colors results in a darker shade, the way a color inkjet\nmakes different shades by mixing cyan, yellow, and magenta ink. Subtractive color is the\nopposite of the additive RGB system we discussed early in the chapter, in which mixing\nresults in a brighter color.\nWOW! eBook\nwww.wowebook.org\nFigure 4-30: Light bouncing off multiple surfaces influences apparent color.\nHow Light Is Traced\nA global illumination model seems to require following the paths of light beams as they\nbounce around the scene. A naive renderer, then, would use three-dimensional coordinate\nmath to trace the path of every beam of light from each light source as it bounces from\nsurface to surface. This would waste a lot effort, though, because it would deduce the\ncolor of every surface in the scene—including surfaces the viewer can’t actually see\nbecause they lie outside of the viewpoint’s field of view, are obscured by other objects, or\nare facing away from the viewpoint.\nWhy Light Is Traced Backward\nRenderers avoid this inefficiency by tracing beams backward from the viewpoint into the\nscene, a technique known as ray tracing. In ray tracing, an imaginary line is traced from\nthe viewpoint through the center of each square in a pixel grid, as shown in Figure 4-31.\nThe geometry of each model in the scene is compared with the imaginary line to see if the\ntwo intersect. The closest point of intersection to the viewpoint indicates the visible\nsurface that will color the pixel. Note that this method of projection closely follows the\nexplanation of Figure 4-23.\nNext, more lines are traced outward from this known visible point. The goal is to\ndiscover which lines end at light sources, either directly or after bouncing off other\nobjects. As shown in Figure 4-31, specular reflections trace only the rebound at the same\nangle of each impact, but diffuse reflections trace a number of lines in random directions.\nAs the diffuse beams strike other objects, they will spawn more diffuse reflections, which\nmeans the number of paths to trace keeps multiplying the more the process continues.\nRenderers apply a cut-off to limit the number of bounces for each beam.\nWOW! eBook\nwww.wowebook.org\nFigure 4-31: Tracing a beam of light from a viewpoint, through the center of the shaded\npixel, until it reaches a model in the scene. To determine specular lighting, the tracing\nrebounds at the same angle as impact; for diffuse lighting, it rebounds at several random\nangles.\nHow Ray Tracing Models Real-World Effects\nAlthough ray tracing is a lot of work for even a network of computers, the method can\naccurately model many real-world visual effects.\nOne such effect is translucency. Although a bitmap can be made translucent by\nassigning low alpha values to pixels, that’s not the whole story for transparent materials\nlike glass. A glass tumbler, for example, doesn’t merely allow light to pass through it, but\nalso distorts whatever is behind it, as shown in Figure 4-32.\nFigure 4-32: The distortion of curved glass\nA ray tracing renderer can refract light beams according to the laws of optics as they\npass through translucent materials. This will not only allow the renderer to model glass in\nCGI, but will also help to reproduce the distorting effects of transparent materials and\nliquids like water.\nRay tracing can also be extended to simulate camera lenses. Normally, all objects in a\ncomputer-generated image are perfectly in focus. In images shot by a movie camera,\nthough, only objects at a certain distance from the camera are in focus, leaving other\nobjects less focused the farther they are from that distance. While one might consider\nWOW! eBook\nwww.wowebook.org\nhaving everything in focus an advantage of computer-generated imagery, skilled\ncinematographers use selective focus to help tell their stories. In Figure 4-33, Jimmy\nStewart and Grace Kelly are in focus in the foreground, while the apartments in the\nbackground are blurry; the viewer’s attention is drawn to the actors, but the distant, open\nbackground is a subtle reminder of how visible the apartments in this courtyard are from\neach other—an important detail in the film. Because movie viewers have grown\naccustomed to receiving depth information about scenes through the use of focus,\ncomputer-generated images and movies often must simulate the use of photography lenses\nto match viewer expectations.\nFigure 4-33: Focus depth in Rear Window (Paramount Pictures/Patron Inc., 1954)\nShadows are another key component of a realistic computer-generated image. Ray\ntracing produces shadows naturally, as shown in Figure 4-34. Because no beam of light\ncan reach the shadowed area, no beam traced back from the viewpoint can reach the light,\nso the area will remain dark.\nFigure 4-34: Tracing beams of light renders shadows naturally.\nRay tracing can also model highly reflective surfaces simply by setting a very high\nspecular reflection property on the material. For example, when you’re standing inside a\nwell-lit room when it’s dark outside, the room in which you stand is clearly reflected in the\nwindow.\nSo although ray tracing is computationally intense, adding these real-world effects\ndoesn’t add much extra work, and the effects add greatly to the realism of the final image.\nIn the next chapter, you’ll see the tricks video games use to render reflective surfaces and\nWOW! eBook\nwww.wowebook.org\nshadowing in real time, when ray tracing isn’t an option. Some effects, like glass\ndistortion, are usually not even attempted in real-time rendering; there’s simply not\nenough time.\nFull-Scene Anti-Aliasing\nWhile the images rendered by ray tracing can be stunning, they can suffer from the same\naliasing problems we saw with 2D graphics. Whenever one object is in front of another,\neach projected light beam will either hit the foreground object or miss and hit what lies\nbehind the object. Figure 4-35 shows a chair on a rug as seen from a particular viewpoint.\nBeams traced from this viewpoint near the edge of the chair seat hit either the chair or the\nrug, which assigns the associated pixel the color of one surface or the other. This causes a\njagged edge like those we saw for 2D images.\nThe renderer can avoid the jaggies by applying anti-aliasing to the whole image. There\nare many methods for full-screen anti-aliasing, but with ray tracing, a direct way to anti-\nalias the entire scene is to project more beams from the viewpoint than necessary. For\nexample, rather than just sending out a beam at the center of every pixel, the renderer\nmight also send out beams into the spaces between the pixel centers. After the color for\nevery beam is determined, the final color of each pixel is blended from the colors of the\ncenter beam and the beams at the neighboring corners. Pixels that lie along an edge in the\nimage are thereby assigned intermediate colors, avoiding the jagged “staircase” effect.\nFigure 4-35: In the highlighted area, each light beam trace ends on the chair or the rug,\nresulting in jaggies.\nFigure 4-36 demonstrates this idea. Each circle represents a beam projected into a\nscene. The pixels are colored based on the average of colors in the center and corners of\neach pixel, which results in the anti-aliased edge shown on the right. More beams can be\ntraced for even better results, at the expense of more processing time.\nWOW! eBook\nwww.wowebook.org\nFigure 4-36: Each pixel’s final color is a blend of five beams traced into the scene, one at\nthe center of the pixel, and four at the corners.\nCombining the Real and the Fake\nIn a completely computer-animated film, rendering is the final step in producing each\nframe, but when CGI is integrated into live-action films, there’s more work to be done.\nImagine, for example, a scene in which a computer-generated Tyrannosaurus rex stalks\nthrough a real field of grass.\nTo make this happen, we first need two sequences of digital images. One sequence\nshows the grass field, and has either been shot on a digital camera or on a traditional film\ncamera and then subsequently scanned. Either way, the movements of the camera are\ncomputer controlled, which allows the camera movement to match up precisely with the\nmovement of the virtual camera in the other sequence, the computer-generated animation\nof the dinosaur.\nNext, the two sequences are combined, frame-by-frame, in a process called digital\ncomposition. Although the dinosaur sequence was produced from 3D models, at this point\nboth sequences are simply two-dimensional bitmaps and are combined using the same\nmethod used to place our bugman on top of the sunset back in Figure 4-18. Through the\nuse of alpha blending, the edges of the dinosaur in each frame are smoothly blended with\nthe field-of-grass background. Without this blending, the dinosaur will have a shimmering\nedge like that of a weatherman standing in front of the five-day forecast.\nDigital composition is used throughout modern moviemaking, even when no computer-\ngenerated imagery is involved, such as for dissolves (a transition where one scene\nsmoothly fades into the next). Formerly, dissolves were produced by a device known as an\noptical printer, which pointed a camera at a screen onto which several projectors were\naimed. The camera would make a new film that combined the images of the projected\nfilms. A dissolve was accomplished by turning down the light in one projector while\nturning up the light on another. The results were acceptable, but you could always spot an\noptical printer sequence in a movie because the second-generation images would be blurry\ncompared to the rest of the film. Now, dissolves, superimposed titles, and all sorts of other\nmovie effects that you might not really think of as “effects” are performed with digital\ncomposition.\nWOW! eBook\nwww.wowebook.org\nThe Ideal of Movie-Quality Rendering\nWhen all the advanced rendering techniques described in this chapter come together, the\nresults can be stunningly realistic, highly stylized, or anything in between. The only real\nlimitation on CGI is time, but that’s a big limitation. The truth is, what I’ve been calling\nmovie-quality rendering can be an unattainable ideal even for Hollywood. Although films\ncan be in production for several years, there’s only so much time that can be allotted for\neach frame. Consider the computer-animated Pixar film WALL-E. With a running time of\n98 minutes, the film required the rendering of over 140,000 high-resolution computer\nimages. If Pixar wanted to produce all of the images for WALL-E in two years, it would\nhave to render images, on average, every eight minutes.\nEven on a networked “render farm,” eight minutes is not sufficient to use ray tracing,\nglobal illumination, glass refraction, and all the other high-end techniques for every single\nimage. Faced with these practical constraints, filmmakers pick and choose which\ntechniques to use on each sequence to maximize visual impact. When ideal rendering is\nrequired, the time is spent, but when the best effects won’t be missed or the budget won’t\nallow it, they aren’t used. The renderer used at Pixar—a program called RenderMan that\nwas originally developed at Lucasfilm—can forgo ray tracing and its massive associated\ncomputational effort, but that means many of the realism-enhancing effects have to be\nproduced some other way.\nBut how is that done? What kinds of tricks are needed to render images without ray\ntracing—images that may not be perfectly realistic but are still amazing? To answer this\nquestion, we’ll turn from Hollywood to the world of video games, where rendering is\nunder an extreme time limitation. How extreme? If eight minutes isn’t enough time to\nproduce an ideal render, imagine trying to render an image in under 20 milliseconds. In the\nnext chapter, we’ll see how video games produce great graphics in a hurry.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What are the key techniques used in real-time game graphics to achieve smooth and realistic visuals without using ray tracing?",
    "summary": "Video game graphics have evolved from pre-rendered bitmaps to real-time rendering using advanced hardware. Early games used simple, low-resolution graphics, while modern games rely on GPUs with many cores to handle complex, real-time visuals efficiently. Real-time rendering faces challenges like lighting, shadows, and anti-aliasing, but techniques such as depth buffering, bump mapping, and tessellation help create realistic images without the computational cost of ray tracing. Despite hardware improvements, game developers must balance quality and performance, often using post-process methods like FXAA for efficient anti-aliasing. The future of game graphics depends on both hardware advancements and the creativity of programmers in making visually appealing results.",
    "output": "5\nGame Graphics\nA modern video game is like a modern movie—a big production that requires expertise in\nmany different technical areas. Teams of programmers develop code for audio, artificial\nintelligence, network connectivity, and so on. Still, the first thing you notice about a video\ngame is the graphics.\nEarly video game systems like the Atari 2600 and Sega Genesis relied on premade\nbitmap graphics; that is, there was no rendering, not even the 2D rendering described in\nthe previous chapter. Instead, if a video game needed to show the game’s hero walking, an\nartist would draw several bitmaps to be shown in a repeating sequence. Backgrounds, too,\nwere hand-drawn. Displays were low resolution and offered only a few choices for pixel\ncolors.\nAs the quality of displays improved, game developers turned to other techniques to\nproduce their bitmaps. Fighting games like Mortal Kombat would scan photographs of\nstunt actors in costume or at least use them for reference. Some games in this era would\nactually use rendered graphics, but not real-time rendering; instead they would prerender\nthe bitmaps on more powerful systems over a longer period of time. The 3D game as we\nknow it today was unknown outside of a few early experiments.\nThat started to change in the mid-1990s. Game consoles like the Sony PlayStation were\nbuilt around 3D graphics capabilities instead of bitmaps. PC gamers began to purchase\nwhat were then called graphics accelerators— plug-in hardware to assist in the creation of\n3D graphics. Those early 3D games were crude, both graphically and otherwise, compared\nto games today. Also, few 3D games were made for the PC because Microsoft had yet to\nbuild DirectX, a standardized interface between game software and graphics hardware,\nwhich meant that games had to include different code to match each manufacturer’s\ngraphics accelerator.\nEven so, gamers were hooked on the new 3D gaming, and each succeeding generation\nof graphics hardware blew away the capabilities of the previous one. Nowhere was this\ngenerational leap more apparent than in cut scenes—short, prerendered videos shown at\nthe beginning of the game to set the scene, or at critical points during the game to advance\nthe plot. Because these videos were prerendered on expensive hardware, just like the\nmovie CGI we discussed in Chapter 4, early cut scenes were much more impressive than\nthe graphics during actual gameplay. As the hardware advanced, though, gameplay visuals\nWOW! eBook\nwww.wowebook.org\nbegan to match or even exceed the cut scenes of earlier games.\nThese days, few games use prerendered cut scenes. Although the game may still\ninclude noninteractive “movie” sequences to set up or advance the plot, they’re much\nmore likely to be rendered in real time, just like the rest of the game. That’s because the\nreal-time rendering looks so good, it’s not worth it for game developers to do anything\nelse.\nAnd that, I think, is why I find video game graphics so amazing. They look as good as\nor better than the prerendered graphics I saw in earlier video games, or even in early CGI\nmovies, and they’re being produced in real time. Those two words—real time—look\ninnocent enough, but they encapsulate an enormous challenge for a game renderer. To put\nit into numbers: if your typical gamer wants a refresh rate of 60 frames per second, each\nimage must be rendered in a mere 1/ of a second.\n60\nHardware for Real-Time Graphics\nThe increasing quality of real-time graphics is tied to advancements in graphics hardware.\nToday’s graphics hardware is powerful and optimized for the tasks involved in 3D\ngraphical rendering. Although this book is about software, a brief discussion of hardware\nis necessary to understand why game graphics work the way they do.\nThe main processor inside a computer or video game console is the central processing\nunit (CPU). These processors might have multiple cores, or independent processing\nsubunits. Think of a core as an office worker. The cores inside a CPU are like fast, widely\ntrained workers. They are good at doing just about any task, and doing it very quickly.\nHowever, they are so expensive that you can afford to have only a few of them, usually\neight or fewer in a typical desktop processor, although this number will continue to rise.\nBy contrast, a graphics processing unit (GPU) will have hundreds or even thousands of\ncores. These cores are much simpler, and individually slower, than the cores in a CPU.\nThink of them as workers who can do only a few tasks well, and don’t do those tasks\nespecially fast, but they are so affordable that you can have an army of them. This\nhardware approach for GPUs was adopted because there’s only so much improvement that\ncan be made to the speed of individual cores. Even though the raw speed of cores\nincreased with each generation, that wasn’t nearly enough to close the performance gap to\nallow high-quality real-time rendering; the only solution was more cores.\nCPUs, then, are great at tasks with steps that have to be completed in a specified order,\nlike filling in a tax form. GPUs, though, are better at tasks that can be easily divided\namong many workers, like painting the outside of a house. Game renderers are designed to\nkeep all of the GPU cores as busy as possible.\nWhy Games Don’t Ray Trace\nWe saw in the preceding chapter how ray tracing can produce amazing graphics. But\ngames don’t ray trace, because it’s too slow for real-time rendering. There are several\nreasons for this.\nWOW! eBook\nwww.wowebook.org\nOne reason is that ray tracing doesn’t match up well with the “army of workers” GPU\ndesign. For example, ray tracing sends out a beam of light for each pixel, determines\nwhere that beam strikes, and from that point of impact, sends out a bunch more light\nbeams, determines where they strike, and so on. This job is better suited for a CPU,\nbecause the renderer must determine each point of impact before it knows what beams to\ncheck next.\nMore broadly, realtime renders should expend computational effort where the result\nmakes a difference to the viewer. Consider a computer-generated scene in which you face\na chair in the middle of a polished wooden floor. A ray tracer, pinballing light around the\nroom, would still indirectly determine the color of every point on the back of the chair,\nbecause that data is necessary for proper global illumination of the floor. A game renderer,\nthough, could never afford the luxury of coloring a surface that won’t be directly seen.\nAll Lines and No Curves\nTo understand how a video game renders without ray tracing, we start with the basic\nbuilding block of game graphics: the triangle. In the previous chapter we learned how CGI\nmodels in movies are made of lines and curves. In game rendering, models are normally\nmade exclusively of lines. If you remember graphing parabolas in high school algebra,\nyou’ll recall that the math for describing curves is a lot more complicated than the math\nfor describing lines, and there’s just not enough time to deal with curves in a game. That’s\nwhy game renderers use lines, and this means that the surfaces defined by the control\npoints are flat. The simplest flat surface is a triangle, defined by three points in space.\nTriangles are ubiquitous in games. In a game, whatever you think you’re looking at,\nyou’re actually looking at millions of triangles, joined at angles to create surfaces and\nshapes. Triangles used in rendering are often generically called polygons, even though\nalmost all the polygons are simple triangles.\nGames simulate curved surfaces by using lots and lots of triangles. A round tumbler,\nfor example, can be approximated as a ring of interlocking triangles, as shown in Figure 5-\n1. On the right, the outlines of each triangle are shown for clarity.\nFigure 5-1: A curved tumbler approximated with triangles\nWOW! eBook\nwww.wowebook.org\nProjection Without Ray Tracing\nTo render the triangles in the scene models, the renderer must project the control points\nthat define the triangle to locate these points on the screen. Ray tracing projects by\nfollowing an imaginary beam of light through the center of each pixel, but in this case we\nhave to do something different.\nThe good news is that a direct mathematical relationship exists between world\ncoordinates and screen coordinates, and this makes mapping the points fairly\nstraightforward. We know the location—the x, y, and z world coordinates—of the\nviewpoint and of the point on the model we want to project. We also know the location of\nthe virtual projection screen. Figure 5-2 shows how we use these locations to determine\nthe exact y-coordinate where the line aimed at the model point crosses the projection\nscreen. In this example, the depth (the distance from the viewpoint along the z-coordinate)\nof the projection screen is four-tenths of the depth from the viewpoint to the point on the\nmodel, as shown by the large blocks along the bottom. Knowing this proportion, we can\ncalculate the x- and y-coordinates of the projected point. The y-coordinate of the projected\npoint is four-tenths of the distance between the y-coordinate of the viewpoint and the y-\ncoordinate of the point on the model, as shown by the shaded boxes on the projection\nscreen. Also, though we can’t see this from the perspective of Figure 5-2, the x-coordinate\nof the projected point will be four-tenths of the distance between the x-coordinates of the\nviewpoint and model point.\nFigure 5-2: Projecting a point in the virtual world to the screen\nNote that the position of the imaginary projection screen in the virtual world affects the\nresulting projection. To see this effect, make a rectangle using the forefinger and thumb of\nboth hands and look through it while moving your hands close and then farther away. The\nfarther away your hands are from your eyes, the narrower your field of view. In the same\nway, games can adjust field of view by altering the distance between the viewpoint and the\nprojection screen in the virtual world. For example, games that let you look through\nbinoculars or a gun scope accomplish the zoom effect by moving the projection screen\ndeeper into the scene.\nRendering Triangles\nWith all three points of a triangle located in screen space, rendering a triangle follows the\nsame rasterization process we saw in Chapter 4 to make a bitmap out of a 2D model. In\nWOW! eBook\nwww.wowebook.org\nFigure 5-3, the pixel centers inside the triangle boundaries are colored gray.\nFrom reading the previous chapter, you probably have some objections to this simple\nmethod of triangle rendering. First, how can we just color every pixel the same—what\nabout all those lighting effects? And second, look at those jaggies— how do we get rid of\nthem?\nFigure 5-3: With the vertices of a triangle located on the screen, the triangle can be\nrendered.\nThese questions will be answered, but first we have to deal with a more fundamental\nproblem. Simply determining where every triangle is located on the screen and coloring its\npixels doesn’t work because every pixel on the screen will probably be inside more than\none triangle. Consider the image shown in Figure 5-4. The flowerpot is behind a cube,\nwhich is behind a tall cup. Pixel A lies within four different triangles: one on the front of\nthe cup, one on the back of the cup, one on the front of the cube, and one on the side of the\ncube. Likewise, four triangles enclose pixel B. In each case, only one triangle should\nactually determine the color of the pixel. In order to render the image correctly, the\nrenderer must always map each pixel to the model surface in the scene that is closest to the\nviewpoint. Ray tracing already finds the closest intersection point between the light beam\nand a model in the scene, so this problem is handled without any additional effort. Without\nray tracing, though, what should the renderer do?\nFigure 5-4: Three overlapping models in a scene\nWOW! eBook\nwww.wowebook.org\nThe Painter’s Algorithm\nA simple solution is known as the painter’s algorithm. First, all of the triangles in the\nscene are ordered according to their distance from the viewpoint. Then the models are\n“painted” back to front, the way Bob Ross would paint a landscape on The Joy of\nPainting. This algorithm is easy for the programmer to implement, but it has several\nproblems.\nFirst, it’s highly inefficient: the renderer will wind up coloring the same pixel over and\nover again as foreground models are rendered over previous background models, which is\na huge waste of effort.\nSecond, it doesn’t allow for easy subdivision to keep the army of workers busy on the\nGPU. The painter’s algorithm requires the models to be drawn in a certain order, so it’s\ndifficult to effectively divide the work among separate processing units.\nThird, there’s not always an easy way to determine which of two triangles is farther\nway from the viewpoint. Figure 5-5 shows a perspective view of two triangles, with\nnumbers indicating the depth of each vertex. The top view makes it clear which triangle is\nin front, but because the depths of one triangle’s vertices are between those of the other\ntriangle, there’s no easy way to figure out which triangle is closer by direct comparison of\nthe vertex depths.\nFigure 5-5: Perspective and top views of two triangles\nDepth Buffering\nBecause of all the deficiencies of the painter’s algorithm, the most common solution to\nprojection in games is a method known as depth buffering. As introduced in the previous\nchapter, computer graphics require a bitmap called a display buffer to store the color of\neach pixel in a display. This technique also uses a corresponding depth buffer to track the\ndepth of each pixel—how far away it is from the viewpoint. Of course, a screen is flat, so\npixels don’t really have depth. What the depth buffer actually stores is the depth of the\npoint in the scene that was used to determine the color of that pixel. This allows the\nrenderer to process the objects in the scene in any order.\nWOW! eBook\nwww.wowebook.org\nHere’s how depth buffering would work with the example scene from Figure 5-4.\nInitially, the depth of each pixel would be set to some maximal value that’s greater than\nthe depth of any actual object in the scene—let’s say 100,000 virtual feet. If the cup is\ndrawn first, the depth of those pixels in the depth buffer is set to the corresponding\ndistances from the viewpoint. Suppose the flowerpot is drawn next; the renderer then sets\nthe depth of its pixels. We can picture the depth buffer as a grayscale image, where pixels\nare darker the closer they are to the viewpoint. The depth buffer at this stage is shown in\nFigure 5-6.\nThe depth buffer solves the problem of projecting the right point onto the pixel. Before\nrendering a pixel, the renderer checks the depth buffer value for that pixel’s location to see\nif the new pixel would be in front of or behind the pixel that’s already in the display\nbuffer. When a new pixel appears behind the pixel in that location in the display buffer, the\nrenderer skips it and moves on. Continuing with our example, when the cube is drawn, the\npixels on the left side of the cube that overlap with the cup are not drawn, because the\nvalues in the depth buffer show that the cup’s pixels are in front of the cube. The cube\nwould overwrite the pixels of the flowerpot, because the depth of the flowerpot pixels is\ngreater than those of the cube.\nFigure 5-6: A depth buffer with two objects drawn. Darker colors are closer to the\nviewpoint.\nDepth buffering is an efficient solution to projection because less work is thrown away.\nModels can be roughly preordered so that they are painted approximately front to back, to\nminimize overwritten pixels. Also, because depth buffers allow for rendering models in\nany order, work can more easily be divided among the cores of the graphics processor. In\nour example, different cores can be working on the cup, cube, and flowerpot at the same\ntime, and the right model will be projected to each pixel in the final rendered image.\nReal-Time Lighting\nNow that the renderer knows which triangle each pixel belongs to, the pixel must be\ncolored. In real-time rendering this is known as pixel shading. Once a particular pixel has\npassed the depth buffer test, all the data needed to color the pixel is processed by an\nalgorithm called a pixel shader. Because each pixel can be independently colored, pixel\nshading is a great way to keep the army of workers busy inside the GPU.\nWOW! eBook\nwww.wowebook.org\nThe data needed by the shader will vary based on the complexity of the lighting model,\nincluding the location, direction, and color of the lights in the scene. Without a method\nlike ray tracing, a full global illumination model, in which reflections from near surfaces\ncolor each other, isn’t possible. However, shaders can include the basic effects of distance,\ndiffuse reflections, and specular reflections.\nIn Figure 5-7, a beam of light represented by the solid arrow reflects from a triangle.\nThe dashed arrow represents the normal (or surface normal) of the triangle in that\nlocation; a normal is simply a perpendicular line pointing away from the surface. In\nChapter 4 we learned how the angles between light beams, surfaces, and viewpoints affect\ndiffuse and specular reflections. The normal is used by the pixel shader for these\ncalculations; so, for example, in Figure 5-7, if the dark arrow represents a light beam, this\nwould have high diffuse reflection because the angle between the light and the normal is\nsmall.\nFigure 5-7: A triangle with a surface normal (dashed arrow) perpendicular to the triangle\nsurface, and a light beam (dark arrow) striking the surface.\nIn Figure 5-7, the normal points straight up, meaning it is perpendicular to the plane of\nthe triangle. Triangles with straight-up normals for every point on the surface are\ncompletely flat, which makes the individual triangles clearly visible in the rendering. For\nexample, with straight-up normals, the tumbler in Figure 5-8 appears faceted like a\ngemstone.\nFor a more rounded appearance, the normals are bent as shown in Figure 5-9. Here, the\nnormals at the corners are bent outward, and the normal at any location inside the triangle\nis a weighted average of the normals at the corner. Because the normal at the point of\nimpact for the light beam no longer points straight up, the light beam reflects more\nsharply. If this were part of a diffuse lighting calculation, the resulting color would be\nbrighter.\nWOW! eBook\nwww.wowebook.org\nFigure 5-8: If the normals for each location on a triangle point the same way, this model\nwill be rendered as a series of flat triangles.\nFigure 5-9: The normal at the point of light impact is affected by the bent corner normals,\nwhich changes the angle of reflection.\nBending normals allows the flat triangle to reflect light as though it were the bent\ntriangle shown in Figure 5-10.\nFigure 5-10: Bending the normals gives the triangle a bent shape so far as the lighting\ncalculations are concerned.\nThis goes only so far in fixing the problem, though, because the underlying shape is\nunchanged. Bending normals doesn’t affect which pixels are matched to which triangle; it\naffects only the lighting calculations in the pixel shader. Therefore, the illusion breaks\ndown along the edges of a model. With our tumbler, bending normals helps the sides of\nthe tumbler to appear smooth, but it doesn’t affect the tumbler’s silhouette, and the rim is\nstill a series of straight lines. Smoother model renderings require additional techniques\nthat we’ll see later in this chapter.\nWOW! eBook\nwww.wowebook.org\nShadows\nShadowing plays an important part in convincing the viewer to accept the reality of an\nimage by giving models weight and realism. Producing shadows requires tracing beams of\nlight; a shadow is, after all, the outline of an object between a light source and a surface.\nGame renderers don’t have time for full ray tracing, so they use clever shortcuts to\nproduce convincing shadow effects.\nConsider the scene outline shown in Figure 5-11. This scene will be rendered in a\nnighttime environment, so the lamppost on the left will cast strong shadows. To render the\nshadows properly, the renderer must determine which pixels visible from this viewpoint\nwould be illuminated by the lamppost and which will be lit only by other light sources. In\nthis example, the renderer must determine that the point labeled Scene-A is not visible\nfrom the lamppost, but Scene-B is.\nFigure 5-11: The light from the lamppost should cast shadows in this scene.\nA common solution to this problem in games is a shadow map, a quickly rendered\nimage from the point of view of a light source looking into the scene that calculates only\nthe depth buffer, not the display buffer. Figure 5-12 is a shadow map for the lamppost in\nFigure 5-11, showing the distance from the lamppost to every point in the scene; as with\nthe depth buffer, this is shown in grayscale with closer pixels colored darker.\nFigure 5-12: The depth buffer from a rendering of the viewpoint of the lamppost\nShadow maps are created for each light source before scene pixels are colored. When\nWOW! eBook\nwww.wowebook.org\ncoloring a pixel, the pixel shader checks each light’s shadow map to determine if the point\nbeing rendered is visible from that light. Consider the points Scene-A and Scene-B in\nFigure 5-11. The shader computes the distance from each of these points to the top of the\nlamppost and compares this distance to the depth of the same points projected onto the\nshadow map, labeled Shadow-A and Shadow-B in Figure 5-12. In this case, the depth of\nShadow-A in Figure 5-12 is less than the distance between Scene-A and the lamppost in\nFigure 5-11, which means something is blocking that light from reaching Scene-A. In\ncontrast, the depth of Shadow-B matches the distance from Scene-B to the lamppost. So\nScene-A is in shadow, but Scene-B is not.\nI deliberately gave the shadow map in Figure 5-12 a blocky appearance; to improve\nperformance, shadow maps are often created at lower resolutions, making blocky\nshadows. If a game offers a “shadow quality” setting, this setting most likely controls the\nresolution of the shadow maps.\nAmbient Light and Ambient Occlusion\nThe simpler lighting model in real-time rendering tends to produce images that are too\ndark. It’s easy to overlook the effect of indirect lighting in the world around us. For\nexample, standing outside in the daytime, you’ll have enough light to read even if you\nstand in a solid shadow, because of indirect sunlight bouncing off nearby surfaces.\nTo produce images with natural-looking light levels, a game renderer will typically\napply a simple ambient light model. This lighting is omnipresent, illuminating the surface\nof every model without regard to light beams or angles of incidence, so that even surfaces\nmissed by in-scene lighting are not totally dark. Ambient lighting is used throughout\ngames, even for indoor scenes. This is a situation where a little fakery produces a more\nrealistic result.\nAmbient lighting can also be used to adjust the mood of a scene. When you leave\nbehind a golden, autumnal field to enter a dusky forest in an open-world game like World\nof Warcraft, a large part of the effect is the ambient lighting changing from bright yellow\nto dim blue.\nAlthough the simple ambient lighting model keeps the rendering from being too dark,\nthe method doesn’t produce any shadows, which hurts a scene’s realism. Ambient\nocclusion methods fake shadows from ambient light by following the observation that\nsuch shadows should occur in crevices, cracks, holes, and the like. Figure 5-13 shows the\nkey idea. Point A is much less occluded than point B because the angle through which\nlight can reach the point is much larger, letting more light through. Therefore, ambient\nlight should have a greater influence on point A than point B.\nFor a renderer to measure the occlusion precisely, though, it would have to send out\nlight beams in every direction, much like the scattering of light from diffuse lighting, but\nwe already know that tracing light beams is not an option for real-time rendering. Instead,\na technique called screen space ambient occlusion (SSAO) approximates the amount of\nocclusion for each pixel after the main rendering is over, using data that was already\ncomputed earlier in the rendering process.\nWOW! eBook\nwww.wowebook.org\nIn Figure 5-14 we see SSAO approximation in action. Note that the viewpoint is\nlooking straight down at the surface. The dashed arrow is the normal for the point on the\nsurface. The gray area is a hemisphere aligned with that normal, shown as a semicircle in\nthis 2D representation. The shader examines a scattering of points inside the hemisphere.\nEach point is projected into screen coordinates, just like the projection of the model point\nshown back in Figure 5-2. Then the depth of the point is compared to he depth buffer for\nthe pixel location, which tells the shader whether the point is in front of (shown in white)\nor behind (black) the model surface. The percentage of points behind the surface is a good\napproximation of the amount of ambient occlusion.\nFigure 5-13: Measuring the occlusion at given points\nFigure 5-14: Screen space ambient occlusion approximates the degree of occlusion by the\npercentage of points behind the model surface.\nSSAO is heavy work for the renderer because it requires projecting and examining a lot\nof extra points—at least 16 per pixel for acceptable results. However, the calculations for\neach pixel are independent, which allows the work to be easily divided among the army of\nworker cores. If a gamer has the hardware to handle it, SSAO produces believable ambient\nshadowing.\nTexture Mapping\nThroughout these discussions of graphics, we have discussed models as though their\nsurfaces were one solid color, but that describes few surfaces in the actual world. Tigers\nhave stripes, rugs have patterns, wood has grain, and so on. To reproduce surfaces with\ncomplex coloring, pixel shaders employ texture mapping, which conceptually wraps a flat\nimage onto the surface of a model, much like an advertising wrap on the side of a city bus.\nTo be clear, texture mapping is not just for game rendering; movie CGI employs it\nextensively, too. But texture mapping is a special problem for games, in which textures\nhave to be applied in milliseconds. The sheer number of textures and texture operations\nWOW! eBook\nwww.wowebook.org\nneeded for a single frame presents one of the greatest challenges of game rendering.\nFigure 5-15 shows a texture bitmap (an image of a zigzag pattern) and a scene in which\nthe pattern has been applied. Bitmap images used for texture mapping are called textures.\nIn this case, the surface of the rug rectangle is covered by a single large texture, although\nfor regular patterns like the one on this rug, a smaller texture can be applied repeatedly to\ntile the surface.\nThe pixel shader is responsible for choosing the base color of the pixel using the\nassociated texture; this base color is later modified by the lighting model. Because the\ntextured surface is an arbitrary distance from the viewpoint, and at an arbitrary orientation,\nthere’s not a one-to-one correspondence between pixels in the texture and pixels on the\nmodel’s surface. Choosing pixel colors in a textured area based on the applied texture is\nknown as sampling.\nFigure 5-15: Texture mapping. The zigzag texture on top is applied to the rug object under\nthe chair.\nTo illustrate the decisions involved in sampling, let’s start with a bitmap of a robot with\na hat, shown in Figure 5-16. The pixels in a texture are called texels. This 20×20 texture\nhas 400 texels.\nIn this example, this texture will appear as a painting in the frame on the wall in Figure\n5-17.\nSuppose that the area inside the frame fills a 10×10 block of pixels in the rendered\nimage. The texture will be applied head-on without any adjustment for perspective, which\nWOW! eBook\nwww.wowebook.org\nmeans all the renderer has to do is shrink the 20×20 block of texels to fit the 10×10 block\nof pixels in the final image.\nFigure 5-16: A texture of a robot wearing a hat\nFigure 5-17: In this scene, the texture of Figure 5-16 will be applied inside the picture\nframe on the wall.\nNearest-Neighbor Sampling\nBecause 10×10 pixels are needed to fill the textured area, let’s imagine a grid of 100\nsample points overlaying the texture. Figure 5-18 shows a closeup section of the original\nrobot texture from Figure 5-16. Here, the centers of the texels are shown as squares, and\nthe crosses represent the sample points for the pixels in the scene. Sampling resolves this\nmismatch of pixels to texels.\nThe simplest method of sampling is choosing the color of the nearest texel, an\napproach known as nearest-neighbor sampling. This approach is easy to implement and\nfast to compute, but tends to look horrible. In this example, each of four texels is equally\nclose to the pixel centers, so I’ve arbitrarily chosen the texel in the lower right of each\npixel center. Figure 5-19 shows the texels chosen by this sampling method, and the 10×10-\npixel block that would appear in the final image.\nWOW! eBook\nwww.wowebook.org\nAs you can see, the result looks more like a skeletal aerobics instructor than a robot\nwith a hat. If you’ve ever looked closely at an oil painting, you may guess why the\nnearest-neighbor technique produces such an unattractive result. Up close, an oil painting\nreveals a wealth of detail, a multitude of individual brushstrokes. Take a few steps back,\nthough, and the strokes vanish as the colors blend together in the eye. In the same way,\nwhen a texture is represented with fewer pixels, the colors of neighboring texels should\nblend. Nearest-neighbor sampling, though, simply picks the color of one texel with no\nblending; in our example, three out of four texels have no influence on the result at all.\nFigure 5-18: A close-up section of the Figure 5-16 texture. Squares are texel centers;\ncrosses are sample points.\nFigure 5-19: The result of 10×10 nearest-neighbor sampling on Figure 5-16. On the left\nare the selected texels of the original texture, and on the right is the resulting bitmap.\nWhen a texture is expanded to fill a larger area, the results are just as ugly. In this case,\nsome of the texels will simply be repeated in the textured area, producing a blocky result.\nTo see the problem, let’s start with a triangle and its representation as a 16×16 anti-aliased\ntexture, as shown in Figure 5-20.\nWOW! eBook\nwww.wowebook.org\nFigure 5-20: A triangle and its representation as an anti-aliased 16×16-pixel texture.\nNow suppose this texture is applied over a 32×32 area. Ideally, it should look smoother\nthan the original, smaller texture; the greater resolution offers the opportunity for a finer\nedge. As shown in Figure 5-21, though, nearest-neighbor sampling puts four sample points\nin each texel, so every texel in the original 16×16 texture simply becomes four identically\ncolored pixels at the larger size.\nFigure 5-21: When used to enlarge textures, nearest-neighbor sampling merely duplicates\npixels.\nBilinear Filtering\nA better-looking sampling method is bilinear filtering. Instead of taking the color of the\nnearest texel, each texture sample is a proportional blend of the four nearest texels. The\nmethod is called bilinear because it uses the position of the sample point along two axes\nwithin the square formed by the four nearest texels. For example, in Figure 5-22, the\nsample point toward the bottom and just left of center results in the mixing percentages\nshown. The final color of this sample is computed from the colors of the texels at the\ngiven percentages.\nFigure 5-23 shows the robot texture after reduction via bilinear filtering. With only a\nfourth of the original pixels, the reduced version necessarily lacks detail, but if you hold\nthe original at arm’s length and compare to the reduced version held close, you’ll see the\nreduction is a good representation, and much better than the nearest-neighbor result.\nWOW! eBook\nwww.wowebook.org\nFigure 5-22: Bilinear filtering measures the position of a sample point vertically and\nhorizontally within the square of neighboring texels, and uses these positions to determine\nthe percentage that each texel influences the sample color.\nFigure 5-23: The robot texture reduced through bilinear filtering\nFigure 5-24 shows a 32×32 area blown up from the 16×16 triangle texture using\nbilinear filtering—a clear improvement over the chunky nearest-neighbor sampling.\nFigure 5-24: The triangle texture expanded through bilinear filtering\nMipmaps\nWOW! eBook\nwww.wowebook.org\nThe examples in the previous section show the limit of what is possible with bilinear\nfiltering. For bilinear filtering to look good, the texture needs to be at least half, but no\nmore than twice, the resolution of the textured area. If the texture is any smaller, bilinear\nfiltering still produces blocky results. If the texture is too large, even though four texels\nare used per sample, some texels won’t contribute to any samples.\nAvoiding these problems requires a set of different-sized bitmaps for each texture: a\nlarge, full-resolution version for viewing up close, and smaller versions for when the\ntextured area is also small. This collection of progressively smaller textures is known as a\nmipmap. An example is shown in Figure 5-25. Each texture in the mipmap is one-quarter\nof the area of the next larger texture.\nFigure 5-25: A mipmap is a collection of textures, each one-quarter the size of the\nprevious.\nWith a mipmap, the renderer can always find a texture that will produce good results\nwith bilinear filtering. If a 110×110 texture is needed, for example, the 128×128 texture is\nshrunk. If a 70×70 texture is required, the 64×64 texture is magnified.\nTrilinear Filtering\nWhile bilinear filtering and mipmaps work reasonably well, they introduce a distracting\nvisual anomaly when transitioning from one mipmap texture to another. Suppose, in a\nfirst-person game, you’re running toward a brick wall that uses a mipmapped texture. As\nyou get closer to the wall, the smaller texture will get blown up more and more until you\nreach the point where you get a shrunk-down version of the next larger texture in the\nmipmap. Unfortunately, a larger texture that has been reduced through bilinear filtering\ndoesn’t quite match a smaller version of the same texture that has been expanded, so at the\nmoment of this transition the texture will “pop.” The problem can also occur with no\nmovement at all on a surface that stretches out to the distance, such as a long rug in a\ncorridor, that has been tiled with a repeating texture; because the parts of rug at different\ndistances are covered by different textures in the mipmap, seams will be clearly visible\nwhere the textures touch.\nTo smooth over the texture transition, the renderer can blend samples from different\ntextures in addition to blending between texels in a texture. Suppose the area to be\ntextured is 70×70, a size that falls between the 64×64 and 128×128 textures in a mipmap.\nInstead of just using bilinear filtering on the nearer-sized 64×64 texture, the renderer can\nuse bilinear filtering on both the larger and smaller textures, then blend the two resulting\nsamples. As with the bilinear filtering itself, this final step is proportional: in our example,\nthe color would be mostly determined by the result from the 64×64 texture, with a little of\nWOW! eBook\nwww.wowebook.org\nthe 128×128 result mixed in. Because we are filtering in two dimensions on each texture,\nthen blending the results, this technique is known as trilinear filtering. It is demonstrated\nin Figure 5-26.\nTrilinear filtering eliminates popping and seaming between textures in a mipmap, but\nbecause it requires two bilinear samples and then a final blend, it does over twice as much\nwork as bilinear filtering.\nFigure 5-26: Trilinear filtering takes bilinear samples from the larger and smaller textures\nin a mipmap and blends the results.\nReflections\nAs discussed in Chapter 4, ray tracing naturally captures all the effects of light reflecting\nfrom one surface to another. Unfortunately, the subtle influence of colors of nearby\nsurfaces is nearly impossible to capture without ray tracing, but game renderers do have a\nway to fake what I’ll call clear reflections: the more obvious, mirror-like reflections on\nsuch surfaces as polished countertops, windows, and of course mirrors themselves.\nGames limit which surfaces produce clear reflections. Having just a few objects with\nsuch reflections maintains the realism of the scene at a much lower computational cost. To\nreduce the workload further, renderers use environment mapping, in which shiny objects\nare conceptually placed inside cubes that are texture-mapped with a previously rendered\nimage of the object’s surroundings.\nFigure 5-27 shows a sample situation: a shiny sports car on a showroom turntable. To\ncompute the effect of clear reflections, the renderer conceptually places the car in a cube;\nthe cube itself is not rendered, but used only to map reflections. The inside of the cube is\ntexture-mapped with an image of the showroom interior, as shown in Figure 5-28.\nBecause the reflected images will be somewhat distorted anyway by the surface of the car\nbody, viewers won’t notice that the reflections don’t perfectly match the rendered world in\nwhich the car is placed.\nWOW! eBook\nwww.wowebook.org\nFigure 5-27: For realism, the shiny car body should reflect the showroom.\nFigure 5-28: For the purpose of mapping reflections, the car is considered to be in a cube,\nthe insides of which are covered by a bitmap image of the showroom.\nInstead of tracing light as it pinballs around the scene, mapping reflections becomes an\nindirect texture-map reference, a relatively simple calculation. Of course, the surface of\nthe car is probably also texture-mapped, which means that adding reflections is at least\ndoubling the per-pixel effort, but the gain in realism is usually worth the extra work.\nThe job becomes harder when a reflecting model is moving, as would happen if our car\nwere racing down a desert road in a driving game. The renderer can’t simply paste a static\nimage of a desert inside a cube and expect this to fool the viewer. Because the viewpoint\nwill be moving with the car as the car travels down the road, the reflections must likewise\ntravel— or at least give that appearance.\nThere’s an old Hollywood trick that was used to convey the illusion of sideways\nmovement in relation to the camera. An actor would stand on a treadmill so he could walk\nwithout going anywhere. Behind him an illustration of scenery on a continuous roll would\nslide past at the same speed as the treadmill. As long as the audience didn’t notice the\nsame trees going by, it looked as though the actor was actually moving sideways.\nThe same idea can be applied inside the cube around the shiny car. A portion of a wide\ncontinuous image is selected, as shown in Figure 5-29. Sliding the selection “window”\nacross the wide image to match the movement of the car creates the illusion that the car is\nreflecting the arid mountains depicted in the scene.\nWOW! eBook\nwww.wowebook.org\nFigure 5-29: Sliding a window down a wide, continuous image creates the effect of\nmovement in mapped reflections.\nFaking Curves\nNothing in a video game destroys realism faster than a model with easily recognizable\ntriangles trying to represent a rounded shape. Early 3D games were filled with car tires\nshaped like octagons and human characters that looked like they were made of toy bricks.\nWe’ve already seen one part of the solution to this problem—bending the normals of\ntriangle vertices—but producing smooth models requires a whole set of techniques.\nDistant Impostors\nAn obvious solution to the problem of flat triangles is to break models down into so many\nsmall triangles that the individual facets are too small to be recognized. That works in\ntheory, but even though triangles are simple shapes, there’s still a limit to how many can\nbe rendered in the time allowed. Trying to design each model at the highest possible detail\nwould slow rendering to a crawl.\nA renderer could, however, use lots of extra triangles to smooth out just those models\nclosest to the viewpoint. This is the idea behind distant impostors. Here, each object in a\ngame is modeled twice—a fully detailed high-triangle model and a simplified model with\nrelatively few triangles. This simplified model is the “impostor” of the original, and is\nswapped in for the high-quality model whenever the model gets beyond a certain distance\nfrom the viewpoint.\nDistant impostors make effective use of rendering time, but because the two models are\nso dissimilar, if a player is watching a particular model while moving closer to it, the\ntransition between the models can be visually jarring. Ideally, you’d like to give the\nviewer the feeling that the distant object is revealing greater detail as it comes closer, but\nin practice the two models are so different that the replacement looks like one object\nmagically transforming into another.\nBump Mapping\nAnother technique for smoothing models keeps the triangle count the same, but alters the\nlighting calculations at each pixel to give the appearance of an irregular surface.\nTo understand why this bump mapping method can be so effective, imagine a game\nfeaturing a hacienda with stucco walls. To get the appearance of stucco, the renderer can\napply a texture made from an image of an actual stucco wall to the walls of the hacienda\nmodel. Because stucco is wavy, its undulations should be visible under the scene lighting.\nWOW! eBook\nwww.wowebook.org\nMerely applying a texture to a flat wall wouldn’t convince the eye; it would look like a flat\nwall with a picture of stucco on it.\nBump mapping allows flat surfaces to react to light as though they were wavy like\nstucco, bumpy like popcorn ceilings, crumpled, louvered, or anything else. The process\nstarts with a grayscale bitmap the same size as the texture that will be applied to the model\nsurface. This bitmap is known as a height map, because the brightness of each pixel\nindicates the height of the surface.\nThe height map allows a pixel shader to approximate the surface normal at each pixel\nlocation. This is easiest to understand in 2D. Figure 5-30 shows a row of 10 pixels. The\nnumbers at the bottom represent the height of each pixel. The 10 points are shown at\nproportionate heights, along with the surface normals. I’ve added gray lines to show how\nthe normals for the fourth and seventh points are computed. An imaginary line is drawn\nbetween the two points on either side of a chosen point; then, the normal for the chosen\npoint is set perpendicular to this line.\nFigure 5-30: A row of pixels with light calculations altered by bump mapping. The\nnumbers indicate the artificial height of each pixel. The renderer determines the normal at\neach pixel based on the heights of neighboring pixels.\nThese bent normals affect the calculations for both diffuse and specular lighting,\nallowing a flat surface to react to light as though it were rough or wavy. As with previous\ntricks that involved bending normals, though, a surface with a bump map is still a flat\nsurface. The points on the surface are not actually raised or lowered, but merely react to\nlight as though they were pointing in different directions. As a player moving through a\n3D scene passes a bump-mapped model, the lighting on the surface will change in a\nrealistic manner, but the edges of the model will still be straight, possibly giving the game\naway. Just as the rim of the tumbler back in Figure 5-8 betrayed the straight lines on the\nmodel, the outside corners of our bump-mapped hacienda will be perfectly straight when\nthey should be wavy, because bump mapping doesn’t alter the shape of the flat wall.\nTessellation\nSuppose you’re playing a fantasy game, and all your attention is focused on a huge ogre\nslowly approaching with an axe in his hands. As a gamer, you want this ogre to look as\ngood as possible even as he gets close enough to nearly fill the screen, but you don’t want\nhim made out of so many triangles that the frame rate is too low for you to effectively\nfight him.\nIf the renderer uses a distant impostor, though, there will be a jarring transition that will\nremind you that you’re just playing a game. If the renderer bump-maps the ogre model,\nWOW! eBook\nwww.wowebook.org\nthe light will reflect realistically off the rivets in his armor, but the neat lighting effect\nwon’t hide the fact that the model just has too few triangles to be viewed up close.\nA process known as tessellation solves this problem. First, each triangle in the ogre\nmodel is subdivided into more triangles. The corners of these new triangles are then\nmanipulated independently inward or outward (that is, up or down in relation to the\noriginal triangle) using a height map. Instead of merely bending normals to trick the\nlighting model as bump mapping does, tessellation actually produces a model with more\ndetail. Figure 5-31 demonstrates the process for a single triangle.\nThis method is a great way to cover up the straight lines of triangles and is a clear\nimprovement in appearance over bump mapping and distant impostors. Because the model\nis actually deformed into a new, more complicated shape, even the edges of the model are\nproperly affected, unlike with bump mapping. Also, unlike the distant impostor technique,\nthe model improves gradually as the distance from the viewpoint decreases, avoiding the\nsharp transition when models are swapped.\nFigure 5-31: A triangle is tessellated, producing a web of smaller triangles. These new\ntriangle vertices are then manipulated using a height map to produce the more complex\nsurface on the bottom.\nThough you might think that tessellation is used extensively in games, it’s not, because\nit inflicts a much larger performance hit than the simpler methods discussed earlier.\nCreating more complex models on the fly is a lot more work than accessing one of several\npremade models as in the distant impostor method, or adjusting normals in bump\nmapping.\nTessellation is therefore used where the results are most obvious. For example, in a\ngame set outdoors, the ground beneath the avatar’s feet may stretch far into the distance.\nModeling the ground in great detail would require a huge number of triangles, creating a\nperformance bottleneck, but if the ground model has a low triangle count, the ground\nWOW! eBook\nwww.wowebook.org\nclosest to the viewer will have an unrealistic, angular appearance. Tessellation can smooth\nout just the closest part of the ground.\nAnti-Aliasing in Real Time\nAll of the renderer’s hard work can go down the drain if individual pixels become clearly\nvisible through aliasing. As with movie CGI, games need some form of full-screen anti-\naliasing to smooth over the edges of models and surfaces. With ray tracing, anti-aliasing is\nconceptually simple: send out more beams than pixels and blend the results. Game\nrenderers, though, must use more efficient techniques.\nSupersampling\nThe most direct approximation to casting multiple beams is known as supersampling anti-\naliasing (SSAA). Instead of casting multiple beams per pixel, supersampling renders an\nintermediate image that is much larger than the desired final image. The color of each\npixel in the final image is a blend of a sample of pixels from the larger image.\nConsider the two white triangles covered by a gray triangle shown in Figure 5-32. Note\nthat the edges of the white triangles won’t be visible in the rendered image but are shown\nhere for clarity.\nFigure 5-32: An arrangement of three triangles\nFigure 5-33 demonstrates a basic rendering of these triangles at an 8×4 resolution.\nEach pixel is colored gray or white depending on whether the pixel center lies within the\narea of the gray triangle in the foreground.\nFigure 5-33: Coloring pixels without anti-aliasing\nTo produce an 8×4 supersampled image, the triangles are first rendered at a 16×8\nresolution as shown in Figure 5-34.\nWOW! eBook\nwww.wowebook.org\nFigure 5-34: Supersampling the three triangles. Here, each pixel in the final bitmap is\nrepresented by four subpixels with scattered sample points.\nAs you can see, each pixel in Figure 5-33 has become four smaller pixels in Figure 5-\n34. These smaller pixels are called subpixels. Using this higher-resolution rendering, the\ncolor of each pixel in the final rendering is a proportional blend of the colors of its four\nsubpixels, as shown in Figure 5-35.\nFigure 5-35: Coloring each pixel by blending subpixels\nSupersampling does a nice job of smoothing out the jaggies, but as you might expect,\nrendering the image at a much higher resolution incurs a large performance penalty.\nSampling four pixels to make one pixel in the final image is four times as much work for\nthe pixel shader. In this example, I’ve kept things simple by assigning a flat color to each\ntriangle, but in a typical game render each subpixel represents, at a minimum, a texture\nmap sample followed by lighting calculations. Although earlier generations of video\ngames commonly used SSAA, it’s rare to see this method now.\nMultisampling\nIn the previous example you can see that when all four subpixels are inside the same\ntriangle, supersampling doesn’t accomplish anything. To reduce the performance hit of\nanti-aliasing, the subpixel work can be limited to the edges of triangles where the jaggies\noccur, a technique known as multisample anti-aliasing (MSAA).\nFigure 5-36 demonstrates one version of this concept. Two pixels lie across the edge\nbetween two triangles. With supersampling, each of the eight subpixels is texture-sampled\nand individually colored by scene lighting. With multisampling, there are still eight\nsubpixels for the two pixels, but not eight samples. Instead, the renderer first determines\nwhich triangle contains each subpixel. Each of the four subpixels that lie within the same\ntriangle is given the same color, which has been sampled from a point midway between\nthe subpixel sample points. So while supersampling colors eight subpixels A through H,\nmultisampling colors only four subpixels A through D, which means substantially less\nwork in texture mapping and lighting.\nWOW! eBook\nwww.wowebook.org\nFigure 5-36: Comparing supersampling and multisampling\nWhen all four subpixels lie within the interior of the same triangle, multisampling\ncolors only one subpixel per final pixel, introducing little computational overhead.\nMultisampling puts in extra effort where it is most needed—reducing jaggies at edges—\nand thus is an efficient use of rendering time.\nPost-Process Anti-Aliasing\nPerformance can be improved even further by delaying anti-aliasing until the image is\nrendered, an idea known as post-process anti-aliasing. That is, the image is first rendered\nnormally at the desired final resolution, and then the jaggies are identified and smoothed\nover. In essence, a post-process anti-aliasing technique decides that some of the pixels in\nan image are colored incorrectly based on nothing more than the colors of the pixels\nthemselves.\nOne such method is called fast approximate anti-aliasing, or FXAA. (Why that\nwouldn’t be FAAA is perhaps a question we’re not supposed to ask.) The idea behind\nFXAA is to find pixels that are likely to be along the edge between overlapping triangles,\nand then blend neighboring pixel colors to smooth the jarring transition.\nFXAA examines each pixel in the image separately—let’s call the pixel under\nexamination the current pixel. The process starts by computing the perceived brightness of\nthe current pixel and its four immediate neighbors, similar to examining a black-and-white\nversion of the image. The brightest and dimmest pixels in the neighborhood are selected,\nas shown in Figure 5-37, and their difference is compared to a cut-off value. This test\nensures that the anti-aliasing is applied only to pixel neighborhoods of high contrast—\nareas where the difference between the brightest and dimmest pixels is large.\nFigure 5-37: Checking the level of contrast in a pixel’s neighborhood\nWOW! eBook\nwww.wowebook.org\nThese high-contrast areas likely represent jagged edges that need to be smoothed, and\neach such area is further examined as shown in Figure 5-38. The 3×3 block of pixels\ncentered on the current pixel is considered both as a set of three columns and a set of three\nrows to determine whether this is a horizontal or vertical edge. In this example, because\nthe columns are similar to each other but one row strongly contrasts with the other two,\nthis would be classified as a horizontal edge.\nFigure 5-38: Looking for contrast in the columns and rows of a pixel neighborhood\nBecause this is a horizontal edge, the next step is to compare the pixels above and\nbelow the current pixel to find which contrasts the most with the current pixel. In this\ncase, the pixel above is much brighter than the current pixel, while the pixel below is quite\nsimilar. This means the detected edge is between the current pixel and its topside neighbor.\nTo anti-alias this edge, the current pixel will be replaced by a bilinear sample between the\npixel centers, shown as the white circle in Figure 5-39. FXAA examines other pixels along\nthe edge to determine how jagged the edge is, adjusting the degree of blending by placing\nthe sample point farther from the center of the current pixel.\nFigure 5-39: To smooth this edge, FXAA will replace the color of the center pixel with a\nbilinear sample at the circle point.\nA post-process anti-aliasing method like FXAA is very fast compared to supersampling\nor even multisampling because it doesn’t create any sub-pixels at all. However, the results\nof FXAA are not always as impressive as other methods. In particular, FXAA can\nsometimes blur areas that weren’t actually aliased; unlike supersampling, post-process\nmethods like FXAA are only guessing where the edges are, so areas of high contrast\nwithin textures may fool the algorithm.\nThe Rendering Budget\nThe trade-offs that accompany different anti-aliasing techniques mean that developers of\nreal-time graphics applications must choose between best quality and best performance. Is\nWOW! eBook\nwww.wowebook.org\nFXAA good enough for this situation? Or is MSAA necessary? This choice, though, is not\nmade in isolation. More broadly, game developers must review all the techniques available\nfor real-time rendering—lighting and shadows and anti-aliasing, and lots of other\npossibilities we don’t have the space to discuss, like motion blur and particle systems—\nand select a set that maximizes the quality of the images without exceeding the time\nallowed for rendering. Within that 1/ of a second, a surprising amount of work can be\n60\ndone, but all of the best-looking techniques can’t be used, so sacrifices have to be made\nsomewhere.\nOn a console or in a mobile game, these choices are usually all made by the game\ndesigner. On PCs, a degree of choice is usually afforded to the user, who is given controls\nto raise or lower the resolution of textures, select the method of texture filtering, choose\namong anti-aliasing methods, turn shadows and reflections on or off, and tweak the\nrenderer in a host of other ways. In part, this control is given so the user can adjust the\nrender workload to match the performance of the particular system, since the PC in\nquestion might be top of the line, or an aging clunker.\nBeyond that, though, detailed rendering options reflect the truth that beauty is\nsubjective: what impresses one viewer might have no effect on another. Some gamers are\nhorrified by jagged edges, for example, and always crank up anti-aliasing to the\nmaximum, while others wouldn’t dream of devoting precious processor cycles to\nremoving jaggies when there are more realistic shadows to be had instead. In a sense,\nvideo games are all about placing ourselves inside believable illusions, and what we\nbelieve is up to us.\nWhat’s Next for Game Graphics\nSo where do game graphics go from here? We can expect game programmers to continue\nto be challenged by advancements in displays. Monitors keep increasing in resolution,\neating away some of the benefit of each new GPU generation. A special challenge will\ncome from virtual reality (VR) headsets, which combine displays mounted inside helmets\nwith sensors to track the gamer’s head movements. VR headsets can be trouble if the\ndisplay lags behind the movement—our brains don’t like conflicting information, and\nwhen our eyes are saying one thing, and our inner ear something else, the result for many\npeople is nausea. In a game played on a normal flat screen, gamers would prefer a\nconsistently high frame rate but don’t get too bent out of shape by sporadic dips in the\nnumber; with VR devices, an absolutely rock-steady frame rate is imperative.\nBeyond matching the needs of displays, it’s difficult to predict exactly how game\ngraphics will progress. Over the past decade, every time I’ve played a new AAA game (as\nthe industry calls the biggest-budget titles), I find myself thinking the graphics can’t get\nany better, that whatever improvements the next generation of hardware brings will be\ninsignificant. And every time, I’ve been proven wrong. So I’m confident that I’ll continue\nto be blown away by the advances in game graphics, even if I can’t be sure what those\nadvances will be.\nRaw hardware power is only part of the equation. Buying a new GPU with twice as\nmany cores as an older GPU means the hardware can process twice as many triangles in\nWOW! eBook\nwww.wowebook.org\nthe same allotment of time, but once triangle counts get high enough, doubling them\ndoesn’t improve the resulting images very much. Indeed, at some point, models may get\nso detailed and triangle counts so high that the average triangle will occupy less than a\none-pixel area on the screen. When that happens, it will call into question the whole idea\nof rendering the scene as a series of triangles. Rather than projecting three triangle vertices\nto determine the color of one pixel, renderers may replace triangles with single points of\nfixed volume—imagine building a sculpture out of tiny marshmallows.\nWhat ultimately drives advancements in game graphics, though, isn’t hardware, but the\ncreativity of graphics programmers. Many of the techniques in Chapter 4 are about\nmaking accurate, or at least plausible, simulations of how light and vision work in the real\nworld. Game graphics are just about making results that look good. That gives\nprogrammers enormous leeway to experiment, to find new ways to spend part of the\nprecious rendering budget, to find new tricks to put silly grins on the faces of gamers. I\ndon’t know for sure what game developers are cooking up for the next generation of\ngames, but I’m sure that they’ll continue to put my GPU to work in ways that will thrill\nand amaze.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What are the key compression techniques used in video compression, and how do they work together to reduce the amount of data required to store or transmit high-definition video?",
    "summary": "Data compression is essential for storing and streaming high-definition video efficiently. Before modern formats like Blu-ray and Netflix, earlier video storage methods such as videocassettes and LaserDiscs had significant capacity limitations. Today, techniques like run-length encoding, dictionary compression, Huffman encoding, and quantization are used to reduce video data size. JPEG compression, for example, uses YCbCr color conversion, DCT, and quantization to achieve high compression ratios while maintaining visual quality. For video, MPEG-2 and MPEG-4 use temporal compression, where frames are stored based on their similarity to previous or next frames, significantly reducing data size. However, high-definition video requires even more advanced compression to handle the increased data volume.",
    "output": "6\nData Compression\nSometimes the hard work of software is obvious to everyone, as it is with movie CGI and\nvideo game graphics. You don’t have to know anything about how computers work to be\nimpressed with the visuals in films like Avatar and games like Crysis. Sometimes, though,\nsoftware is doing its most amazing work when it looks like it’s not working hard at all.\nWatching a high-definition movie on a disc or streamed over the Internet is something\nmost of us take for granted. Isn’t that just storing and displaying images? Why would that\nrequire special techniques? To understand why we should be impressed with Blu-ray\nvideo and Netflix streaming, let’s look at what video was like before these formats came\nto be.\nVideocassettes, the earliest home video medium, recorded images on a roll of magnetic\ntape. These were analog recordings—magnetic transcriptions of the same signal that\nwould’ve been broadcast by television antennas. The video resolution was even lower than\nwhat we now call “standard definition,” and as with other analog recordings like\naudiocassettes and vinyl records, the quality of the video would degrade over time. The\none upside to videocassettes was their capacity: a longer movie merely required a longer\nspool of tape.\nNext came the LaserDisc. About the size of LP records, these discs looked like larger\nversions of today’s DVDs and Blu-ray discs, but like videocassettes, they were still storing\nthe analog broadcast-format signal. However, LaserDiscs recorded a higher-resolution\npicture that came close to standard definition, and allowed you to jump to particular places\nin the video without having to rewind or fast-forward the way you would with a\nvideocassette. For a while, the LaserDisc seemed like the future of video, but now\ncapacity was a problem. Unlike the effectively limitless capacity of a magnetic tape roll,\nLaserDiscs could hold only 60 minutes of video per side, so watching a movie meant\nflipping the disc halfway through or even switching discs.\nToday, the problem of capacity is even more serious. Our Blu-ray discs are much\nsmaller than LaserDiscs, but our videos are a much higher resolution. Let me put the\nproblem into numbers. In high-definition video each frame is a 1920×1080 bitmap, a total\nof 2,073,600 pixels. If each pixel is stored in three-byte RGB format, one frame of a high-\ndefinition movie would require 6,220,800 bytes, or about 6.2 megabytes (mega means\n“million”). Movies are recorded at 24 or 30 frames per second, which is 1,800 frames per\nWOW! eBook\nwww.wowebook.org\nminute, 108,000 frames per hour, or 216,000 frames for a two-hour film. If each frame is\n6,220,800 bytes, then 216,000 frames is 1,343,693 megabytes, or about 1,345 gigabytes\n(giga means “billion”).\nHow can all of that data fit on a Blu-ray disc? Part of the answer is the “blu-ray” itself,\na blue laser that’s narrower than the laser used on LaserDiscs or even conventional DVDs,\nallowing more data to be packed into a smaller area, just as smaller print allows more\nwords on a page. Even so, a Blu-ray can store only about 50 gigabytes(GB) of data, less\nthan 4 percent of what’s required.\nStreaming video has the same problem. If one frame of video is 6.2 megabytes (MB),\nand the video is running at 30 frames per second, then streaming requires an Internet\nconnection of 186 megabytes per second (MBps). A typical home broadband connection is\nmore like 4MBps. What’s worse, because of traffic congestion and hiccups in the network,\nyou can’t count on maintaining the full rated bandwidth over the course of a long\ntransmission. Realistically, streaming video should use no more than a couple of MBps at\nmost.\nSo how can we fit giant amounts of video data into these small containers? The answer\nis data compression—storing data in a format that requires fewer bytes than the original\nformat. Compression techniques can be broadly divided into two categories. With lossless\ncompression, the compressed data can be restored to its exact original state. In contrast,\nlossy compression accepts that the restored data may be slightly different than the original.\nVideo streaming and storage uses a combination of both types of compression. In this\nchapter, we’ll first investigate some general compression techniques using simple\nexamples. Then we’ll see how these ideas apply to video, producing highly compressed\nsequences of images that look nearly as good as the uncompressed originals.\nRun-Length Encoding\nMost of us have employed some form of lossless compression, though we wouldn’t have\ncalled it that, because many techniques for lossless compression are commonsense ideas.\nOne such method is run-length encoding. Suppose I were to show you a 27-digit number\nfor one minute to see whether you could remember it an hour later. That might sound hard,\nbut look at the number:\n777,777,777,555,555,555,222,222,222\nI suspect you wouldn’t try to remember each digit individually. Instead, you’d count\nthe occurrences of each digit, and remember it as “nine sevens, nine fives, and nine twos.”\nThat’s run-length encoding in action. Repeats of the same piece of data (in this case, a\ndigit) are called runs, and when runs are common, we can shorten the data by recording\nthe lengths of the runs rather than the whole number. Run-length encoding is lossless\ncompression, because if we remember the shorthand version of the number, we can\nreproduce the number in its original form whenever needed.\nJust by itself, run-length encoding can provide excellent compression for certain types\nof images, such as icons, logos, comic-book-style illustrations— any image with large\nblocks of solid color. When pixels have the same color as their neighbors, we can reduce\nWOW! eBook\nwww.wowebook.org\nthe storage requirements considerably. As an example, I’ll describe the system used by the\nTGA image file format. TGA is short for Truevision Graphics Adapter, an early piece of\ngraphics hardware designed for video editors. The file format, if not the adapter, is still in\nuse in the video industry, and is probably the simplest example of run-length encoding for\nimages.\nThe image data in a TGA file is compressed on a row-by-row basis. Within each row,\neach run of two or more pixels of exactly the same color is identified. The remaining\npixels are called raw pixels. Consider the selected row in the sample image in Figure 6-1.\nIn this row, there are several short runs of pixels, and several raw pixels that are different\nfrom their neighbors.\nFigure 6-1: The selected row has a mix of runs and raw pixels.\nThe TGA format organizes runs and raw pixels into packets. Each packet begins with a\none-byte header. The leftmost bit of the header byte determines whether it is a run packet\nor a raw packet. The other seven bits denote the size of the packet in pixels. Because the\nsmallest packet has one pixel, TGA encodes the packet’s size as one less than its actual\nsize; that is, a size field of 0000000 represents a size of 1, and 0000001 represents 2, and\nso on. Following the header is either the encoded color of all the pixels in the run, or for a\nraw packet, the colors of each individual pixel. Using the RGB color format, the row of\npixels from Figure 6-1 would be encoded as shown in Table 6-1.\nTable 6-1: TGA Encoding of Pixel Row\nRun/raw Size Red Green Blue Description\n1 000000111111111 11111111 11111111 Run of two white pixels\n1 000001011001100 11001100 00000000Run of three yellow pixels\n0 000000111111111 11111111 11111111 Raw packet of two pixels; first is white\n000000001000000000000000Second pixel in raw packet; dark green\n1 0000001000000000000000011111111 Run of two blue pixels\n0 000000011111111 11111111 11111111 One raw white pixel\nThis encoding requires 23 bytes versus the uncompressed size of 30 bytes. This\nWOW! eBook\nwww.wowebook.org\ncompression ratio of 30:23, or about 4:3, isn’t very high, but note that a mere 4 bytes are\nneeded to store rows where every pixel is the same color, like the top row of Figure 6-1.\nThe overall compression ratio of this bitmap in TGA format is an impressive 300:114, or\nabout 5:2.\nDictionary Compression\nJust by itself, run-length encoding can compress pictures with large blocks of solid colors,\nbut most of the images in movies aren’t like that. For photographs and other types of\ndigital images with lots of color variation, software has to work much harder to find\npatterns exploitable by compression. One of the key tools is known as dictionary\ncompression.\nThe Basic Method\nLater we’ll see how dictionary compression is used on images, but the idea is easiest to\nunderstand when it is applied to a text document, so let’s start there. An uncompressed text\ndocument is stored as a series of character codes such as ASCII.\nWe’ll compress this sample paragraph:\nThose pictures created by a computer are called computer graphics. When these pictures created by the\ncomputer are viewed in a sequence, that sequence is called an animation. An entire movie created from an\nanimation, a sequence of pictures created by a computer, is called a computer-animated movie.\nTo make this example simpler, I’ll ignore the spaces and punctuation in this text and\njust worry about the letters. There are 234 letters in this paragraph; stored as\nuncompressed ASCII text, the letters would require 234 bytes. To employ dictionary\ncompression on this text, we first need a dictionary, which in this context is a numbered\nlist of every word in the document being compressed. Table 6-2 is our list of words,\nnumbered both in decimal and binary. Note that capitalization counts: an and An are\nseparate entries.\nTable 6-2: Dictionary Compression\nPosition Binary-encoded position Word\n1 00000 a\n2 00001 an\n3 00010 An\n4 00011 animated\n5 00100 animation\n6 00101 are\nWOW! eBook\nwww.wowebook.org\n7 00110 by\n8 00111 called\n9 01000 computer\n10 01001 created\n11 01010 entire\n12 01011 from\n13 01100 graphics\n14 01101 in\n15 01110 is\n16 01111 movie\n17 10000 of\n18 10001 pictures\n19 10010 sequence\n20 10011 the\n21 10100 these\n22 10101 Those\n23 10110 viewed\n24 10111 When\nAs shown, 5 bits are sufficient to represent the range of positions used. Each word in\nthe original paragraph is replaced with its position in this table. For example, instead of\nusing eight ASCII codes (64 bits) for each appearance of the word computer, the 5-bit\ndictionary entry is used instead.\nThe dictionary itself takes up space, however, and must be included in the compressed\ndocument, so we save space only when a word appears more than once. In this example,\nthe total number of letters for all words in our dictionary is 116, requiring 116 bytes.\nReplacing each of the 48 words in the sample paragraph with a 5-bit dictionary reference\nWOW! eBook\nwww.wowebook.org\nrequires 235 bits, or about 30 bytes. The total compressed storage, then, is 146 bytes,\nwhich compared to the original 234 uncompressed bytes is a compression ratio of about\n8:5. With longer documents the savings will be even better, because the text grows much\nfaster than the dictionary. A typical novel, for example, is about 80,000 words long, but\nuses a vocabulary of only a few thousand words.\nHuffman Encoding\nIn almost every text, some words are used much more than others. A technique called\nHuffman encoding takes advantage of this fact to improve on basic dictionary\ncompression.\nTo create a Huffman code, the words in the document are ranked by frequency.\nImagine a children’s story with the 10-word vocabulary shown in Table 6-3. As with basic\ndictionary compression, each word is assigned a binary code, but here shorter codes are\nassigned to the words that appear most frequently in the story.\nTable 6-3: Huffman Code for a Children’s Story\nWord Frequency Binary code\nthe 25% 01\na 20% 000\nprincess 12% 100\ngood 11% 110\nwitch 10% 111\nevil 8% 0010\nate 7% 0011\nmagic 4% 1010\ntoadstool 2% 10110\nforevermore 1% 10111\nWith the table in place, Huffman code compression is the same as basic dictionary\ncompression: each word is replaced with its corresponding binary code. For example, the\nencoding for the princess ate a magic toadstool would start with 01 for the, then 100 for\nprincess, and so on. In full, the encoding is:\n011000011000101010110\nWOW! eBook\nwww.wowebook.org\nAs you may have noticed, the list of binary codes in Table 6-3 skips some possible\ncodes, such as 011 or 0110. Skipping codes is necessary to make this a prefix code, in\nwhich no binary code appears at the start of another. For example, because 01 is the code\nfor the, other codes that begin with 01, such as 011 or 0110, are forbidden. Because the\nindividual codes vary in length, a prefix code is necessary to know where each code ends.\nWith our example, the 01 that begins the bit sequence must be the code for the because no\nother code starts with 01; the only way to partition the whole sequence is as:\n01 100 0011 000 1010 10110\nIf we allowed a code that broke the prefix rule, the sequences could become\nambiguous. Suppose forevermore is assigned the code 00. While this is a shorter code, it\nmeans the example sequence could also be partitioned as:\n01 100 00 110 00 1010 10110\nThis would decode as the phrase the princess forevermore good forevermore magic\ntoadstool.\nBy assigning the shortest codes to the most common words, Huffman encoding can\nachieve greater compression than dictionary compression alone when data can be stored as\na relatively small set of codes and some codes are more common than others.\nReorganizing Data for Better Compression\nUnfortunately, the images we see in videos are not good candidates for Huffman encoding.\nUnlike the color-block images we compressed with the run-length technique, the pixels in\na video image vary across the full range of possible colors. With 16 million different\npossible RGB colors, it’s unlikely video images will have enough repetition to allow\nHuffman encoding to work. However, sometimes it’s possible to create repetition in varied\ndata by changing how the data is stored.\nPredictive Encoding\nFor one such approach, consider a weather station that records the temperature once per\nhour, and over the course of one day stores the following readings:\n51, 52, 53, 54, 55, 55, 56, 58, 60, 62, 65, 67, 68, 69, 71, 70, 68, 66, 63, 61, 59, 57, 54, 51\nCOMPRESSION IN ZIP FILES\nDictionary compression and Huffman encoding are at the heart of most general\ncompression schemes. The .zip archive format, for example, can choose from a half-\ndozen compression methods but usually employs an algorithm called deflate. Rather\nthan replacing duplicated data with a reference number from a list of words, this\nalgorithm employs a variation of dictionary compression called a sliding window.\nWith this method, duplicate data is replaced with numerical indicators showing\nwhere the data occurred previously. In the textual example of Figure 6-2, there are three\nduplicate runs of characters. The first member of each pair is the number of characters to\ngo back, and the second number is the length of the run. For example, the pair 5, 2\nWOW! eBook\nwww.wowebook.org\nmeans “go back five characters, and copy two characters.”\nFigure 6-2: Sliding-window compression\nThe compressed version of this text can be symbolically written as “Then t[5,2]\nscar[5,5]ed[16,4]m.” Instead of the number pairs being stored directly, though, they are\nHuffman-encoded, so the most commonly occurring pairs are assigned shorter codes.\nThe deflate method is a highly effective general compression scheme, capable of\nreducing the 3,138,473 characters in a raw text version of Tolstoy’s War and Peace to a\n.zip file of around 930,000 bytes, about a 10:3 ratio.\nIf we assume a temperature range of 120 to –50, we can store each temperature in an 8-\nbit byte, using 192 bits total. There aren’t many duplicates in this list, though, so Huffman\nencoding won’t be effective. The situation improves if we rewrite this list using predictive\nencoding. For every temperature after the first, we’ll record not the temperature itself, but\nits difference from the previous temperature. Now the list looks like this:\n(51): 1, 1, 1, 1, 0, 1, 2, 2, 2, 3, 2, 1, 1, 2, -1, -2, -2, -3, -2, -2, -2, -3, -3\nWhereas the original data had few duplicates, the predictive-encoded data has many.\nNow we can apply Huffman encoding with excellent results.\nQuantization\nAnother approach, if we are willing to accept some degradation of the data, is\nquantization, where we store the data with less precision. Suppose the weather station\nfrom the previous example also records daily rainfall amounts, taking the following\nreadings over the course of three weeks:\n0.01, 1.23, 1.21, 0.02, 0.01, 0.87, 0.57, 0.60, 0.02, 0.00, 0.03, 0.03, 2.45,\n2.41, 0.82, 0.53, 1.29, 0.02, 0.01, 0.01, 0.04\nThese readings have two decimal places, but maybe we don’t actually need this much\nprecision in the data. For one thing, any amount below 0.05 might represent condensation\non the collector rather than actual rain; likewise, condensation might also be the only\ndifference between readings like 1.23 and 1.21. So let’s leave off the last digit of every\nnumber:\n0.0, 1.2, 1.2, 0.0, 0.0, 0.8, 0.5, 0.6, 0.0, 0.0, 0.0, 0.0, 2.4, 2.4, 0.8,\n0.5, 1.2, 0.0, 0.0, 0.0, 0.0\nBy itself, this compresses the data, since storing one place after the decimal will take\nfewer bits than storing two. In addition, the quantized data also has several runs of zeros\nthat can be compressed with run-length encoding, and some duplicates that can be\ncompressed by Huffman encoding.\nThese techniques point to a general multistage approach for compression. First,\nWOW! eBook\nwww.wowebook.org\nreorganize the data to increase the runs and duplicates, by storing small differences\nbetween numbers rather than the raw numbers themselves, quantizing the data, or both.\nThen compress the data with run-length and Huffman encoding.\nJPEG Images\nWe now have almost all the tools needed to compress video. The logical first step in\ncompressing a video is to compress the individual images in the video. However, we can’t\ndirectly apply predictive encoding and quantization to digital photographs and other\nimages with lots of subtle color variation; we need to convert these pictures to another\nformat first.\nThat’s the idea behind JPEG, a common compressed-image format designed\nspecifically for digital photographs. (The name is the acronym for the Joint Photography\nExperts Group that developed the format.) The compression method for this format is\nbased on a couple of key observations of photography and human perception.\nFirst, although pixel colors may vary widely throughout an image, individual pixels\ntend to be similar to their neighbors. If you take a picture of a leafy tree against a partly\ncloudy sky, lots of green leaf pixels will be next to other green pixels, blue sky pixels will\nneighbor blue sky pixels, and gray cloud pixels will neighbor gray cloud pixels.\nSecond, among neighboring pixels, there will be more noticeable variation in\nbrightness levels than in color tone. For our tree photograph, each of the myriad leaf pixels\nwill reflect a different quantity of sunlight, but the underlying color of each pixel will be\nroughly similar. Also, although the mechanisms of human vision are not completely\nunderstood, tests indicate that we perceive differences in brightness more distinctly than\ndifferences in color.\nHigh compression of digital photographs is possible only with lossy compression; we\nhave to accept some degradation of the image. Following these key observations, though,\nallows the JPEG format to throw away the data that is least likely to be missed. In our tree\nphotograph, the most important distinctions are the broad differences between leaf and\nsky, or sky and cloud, not between two neighboring cloud pixels. After that, the most\nimportant distinction is the relative brightness of pixels, more so than relative color. The\nJPEG format therefore gives priority to broad differences over fine differences, and\nbrightness over color.\nA Different Way to Store Colors\nJPEG compression divides images into 8×8 blocks of pixels that are independently\ncompressed. To compress brightness and color differently, each pixel’s R, G, and B values\nare converted to three other numbers Y, Cb, and Cr. Here, Y is the luminance of the pixel,\nor how much light the pixel produces. Cb is the blue difference, and Cr is the red\ndifference. The simplest way to envision the YCbCr system is to imagine a dark green\nvideo screen with three knobs labeled Y, Cb, and Cr initially set to zero: turn up Y and the\nscreen is brighter; turn up Cb and the screen becomes more blue and less green; turn up Cr\nand the screen becomes more red and less green. Table 6-4 lists a few named colors in\nWOW! eBook\nwww.wowebook.org\nboth systems for comparison. (A historical note: YCbCr is derived from the color system\nused in broadcast television. In the early days of color television, the remaining black-and-\nwhite televisions could properly display color transmissions by interpreting only the Y\ncomponent of the signal.)\nTable 6-4: Select Colors in the RGB and YCbCr Color Systems\nR G B Color description Y Cb Cr\n0 255 0 Lime green 145 54 34\n255 255 255 Pure white 235 128 128\n0 255 255 Aqua 170 166 16\n128 0 0 Maroon 49 109 184\nJPEG compresses the Y, Cb, and Cr data separately, so we can think of each 8×8 block\nof pixels as becoming three 8×8 blocks of Y, Cb, and Cr data. Separating the data this way\ntakes advantage of the greater variation in brightness than in color. Under the YCbCr\nsystem, most of the differences between the pixels will be concentrated in the Y\ncomponent. The lower variance in the Cb and Cr blocks will make them easier to\ncompress, and because we’re more sensitive to variations in luminance than variations of\ncolor, the Cb and Cr blocks can be compressed more heavily.\nThe Discrete Cosine Transform\nThe conversion to YCbCr follows the observation that brightness is more important than\ncolor. To take advantage of the greater importance of broad changes over narrow changes,\nthough, we need to convert each 8×8 data blocks yet again. The discrete cosine transform\n(DCT) converts the absolute luminance and color data into relative measurements of how\nthese values differ from pixel to pixel. Although this transformation is applied to an entire\n8×8 block of numbers, I’ll first illustrate the idea with a single row of eight numbers from\nthe luminance (Y) block, shown as shades of gray in Figure 6-3.\nFigure 6-3: A row of luminance levels\nTo begin the DCT, we subtract 128 from each number, which has the effect of moving\nthe 0–255 range to a range centered around 0, so that maximum brightness is 127 and\nabsolute black is –128. The resulting luminance levels for the row are depicted as a line\nchart in Figure 6-4.\nWOW! eBook\nwww.wowebook.org\nFigure 6-4: Subtracting 128 from each luminance level centers the range of possible\nnumbers around 0.\nThe DCT produces eight new numbers that each combine the eight luminance levels in\na different way. Figure 6-5 shows the DCT of the previous figure.\nFigure 6-5: The discrete cosine transform of the data in Figure 6-4.\nNote that the numbers are labeled with a range from “coarse” to “fine.” The leftmost\nnumber in the DCT is the simplest combination of the luminance levels: their sum. Thus,\nthe first number is the overall brightness of the pixels, and will be positive for a bright row\nof pixels and negative for a dark row. The second number effectively compares the\nluminance levels on the left end of the row against those on the right, and is positive in\nthis example because our luminance levels are brighter on the left than on the right. The\nrightmost number effectively compares each luminance value against its immediate\nneighbors, and is close to 0 here because the numbers in Figure 6-4 change gradually.\nThese DCT numbers are the coefficients that result from an operation called matrix\nmultiplication. If your eyes just glazed over, don’t worry: the operation involves nothing\nmore than multiplication and addition. We produce each coefficient by multiplying the\nluminance values by a different, predetermined vector. In this context, a vector is just an\nordered list of numbers. The eight vectors used in the DCT are illustrated in Figure 6-6.\n(The numbers in each vector are related to the cosine function from trigonometry, which is\nwhere the discrete cosine transform gets its name, but we can safely ignore that for this\ndiscussion.)\nWOW! eBook\nwww.wowebook.org\nFigure 6-6: The vectors needed for our single-row DCT\nTo produce a coefficient for our luminance row, we multiply each number in a vector\nby the luminance in the same position. For example, Table 6-5 shows the computation of\nthe Vector 2 coefficient for our luminance row. Each number from the luminance row is\nmultiplied by the number in the same position in Vector 1; then, these products are\nsummed to get 157.386.\nTable 6-5: Computing the Coefficient for Vector 2\nPosition Luminance (from Figure 6-4) Vector Product\n1 76 0.49 37.24\n2 127 0.416 52.832\n3 127 0.278 35.306\n4 76 0.098 7.448\n5 25 –0.098 –2.45\n6 –26 –0.278 7.228\nWOW! eBook\nwww.wowebook.org\n7 –77 –0.416 32.032\n8 25 –0.49 –12.25\nTotal 157.386\nLooking at the vectors of Figure 6-6, you can see how each combines the luminance\nlevels differently. Because every number in Vector 1 is the same positive number, the\nVector 1 coefficient becomes a measure of overall brightness. Because Vector 2’s numbers\ngradually sweep from high to low, the second coefficient will be positive when luminance\ntends to fall off from the left to right in the pixel row, and negative when luminance tends\nto increase. Vector 3’s coefficient is a measure of how the ends of the row differ from the\nmiddle, and so on. You’ve already seen the resulting coefficients charted in Figure 6-5;\nTable 6-6 shows the result numerically.\nTable 6-6: Coefficients from the Discrete Cosine Transform of the Sample Luminance\nRow\nVector number Coefficient\n1 124.804\n2 157.296\n3 –9.758\n4 –87.894\n5 18.031\n6 –49.746\n7 23.559\n8 –13.096\nThe process is reversible: we can retrieve the original luminance numbers from Figure\n6-4 by multiplying the eight coefficients against eight different vectors, a process called\nthe inverse discrete cosine transform (IDCT). Table 6-7 shows how the second luminance\nvalue, 127, is extracted from the coefficients.\nTable 6-7: Computing the Second Luminance Value from the Coefficients\nPosition Coefficient Vector Product\nWOW! eBook\nwww.wowebook.org\n1 124.804 0.354 44.125\n2 157.296 0.416 65.393\n3 –9.758 0.191 –1.867\n4 –87.894 –0.098 8.574\n5 18.031 –0.354 –6.375\n6 –49.746 –0.49 24.395\n7 –23.559 –0.462 –10.833\n8 –13.096 –0.278 3.638\nTotal 127\nThe DCT, then, gives us a different way of storing the same numbers: as the\nrelationship between the data rather than the data itself. Why is this useful? Remember\nthat fine distinctions between pixels are less noticeable than broader distinctions. Later,\nyou’ll see how the DCT allows the JPEG format to compress the fine details more than the\nbroad.\nThe DCT for Two Dimensions\nJPEG compression works not on rows of pixels but on 8×8 pixel blocks, so now let’s see\nhow the DCT operates in two dimensions. The one-dimensional DCT multiplies eight\nvectors with the original eight numbers to produce eight coefficients. The two-dimensional\nDCT, though, requires 64 matrices, each matrix being an 8×8 table of numbers. Like the\nvectors, each matrix will multiply all 64 pieces of data in the 8×8 block.\nThe matrices themselves are two-dimensional combinations of the vectors we saw\nearlier. This is easiest to understand pictorially. Figure 6-7 shows the combination of a\nhorizontal Vector 1 and a vertical Vector 1. Because the numbers in Vector 1 are all the\nsame, the numbers in the resulting matrix are as well. In these matrix illustrations, lighter\ngray means a higher number.\nWOW! eBook\nwww.wowebook.org\nFigure 6-7: The matrix combination of Vector 1 and itself\nIn Figure 6-8, horizontal Vector 1 is combined with vertical Vector 2. The resulting\nmatrix gradually varies from top to bottom as Vector 2 gradually varies, but doesn’t vary\nleft to right because the numbers in Vector 1 don’t vary.\nFigure 6-8: The matrix combination of Vector 1 and Vector 2\nFigure 6-9 shows a last example, Vector 8 combined with Vector 8. Because Vector 8\nswings back and forth from positive to negative, the combination matrix has a\ncheckerboard quality.\nFigure 6-9: The matrix combination of Vector 8 and itself\nThe two-dimensional DCT replaces each of the 64 numbers in an 8×8 block with a\nmatrix coefficient. Figure 6-10 shows which matrices are used for a few locations. Similar\nto the one-dimensional DCT, the coefficient in the upper left, which is the same shown in\nFigure 6-7, sums all the numbers in the original block equally. As we progress downward\nand to the right, the distinctions being measured grow finer.\nWOW! eBook\nwww.wowebook.org\nFigure 6-10: Some of the matrices used in the two-dimensional DCT\nTo demonstrate the two-dimensional DCT, I’ll use just the luminance values of the\npixel block shown in Figure 6-11.\nFigure 6-11: A block of pixels and the associated luminance (Y) block\nFigure 6-12 shows the same luminance block with 128 subtracted from each number to\nmake a range from –127 to 128 centered around 0.\nWOW! eBook\nwww.wowebook.org\nFigure 6-12: The luminance block from Figure 6-11 with the range of possible values\ncentered around 0\nFigure 6-13 shows the luminance block after DCT. Each number is the coefficient\nresulting from multiplying the matrix of luminance values in Figure 6-12 with one of the\nmatrices from Figure 6-10. Remember that these numbers, too, are centered around 0. So\nthe 132 in the upper left, for example, indicates a high luminance level for the block as a\nwhole. Notice that the numbers in the upper left are largest in magnitude (furthest from 0\nin either direction), indicating that broad luminance differences are much greater than the\nfine differences in this pixel block. This result is typical of JPEG-encoded photographs.\nFigure 6-13: The DCT of the block in Figure 6-12\nCompressing the Results\nNow the real compression can begin, the first step of which is quantization. Figure 6-14\nshows the 8×8 block of divisors used for quantizing the luminance block. Each number in\nthe coefficient block of Figure 6-13 is divided by the number in the same position in\nFigure 6-14, with results rounded to the nearest whole number. This degrades the image\nthrough quantization error, but note that the divisors in Figure 6-14 are smallest in the\nWOW! eBook\nwww.wowebook.org\nupper left. Thus, the quantization error is most pronounced in the coefficients that measure\nthe finest distinctions, where the error is least likely to be noticed. The actual values of the\ndivisors varies according to the compression quality, with larger divisors used to quantize\nthe Cr and Cb blocks, but the divisor block always follows this general pattern (lower\nvalues in the upper left, higher in the bottom right).\nFigure 6-14: The divisors used to quantize luminance blocks\nThe result of quantization for our sample block is shown in Figure 6-15.\nYou can see how suitable these numbers are for run-length and Huffman encoding.\nMost of the coefficients have been quantized all the way down to 0, with many duplicate\ncoefficients among the rest.\nAfter quantization, nonzero results tend to cluster in the upper left of the matrix, so the\nquantized numbers are listed in the zigzag pattern shown in Figure 6-16.\nFigure 6-15: The quantized luminance block\nWOW! eBook\nwww.wowebook.org\nFigure 6-16: Storing coefficients in a zigzag order\nThis zigzag pattern tends to produce a very long run of zeros at the end, as it does in\nour example:\n8 10 -7 -7 6 -4 0 -2 1 -2 -1 -1 1 -1 0 0 1 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nTo encode the runs of zeros, we replace each nonzero entry in the list by a pair of\nnumbers: the number of zeros skipped (possibly none), and the coefficient itself. For\nexample, the eighth number in our list is a –2 that is preceded by one 0. This would\nbecome the number pair 1, –2. At this stage, our list looks like this:\n0, 8\n0, 10\n0, -7\n0, -7\n0, 6\n0, -4\n1, -2\n0, 1\n0, -2\n0, -1\n0, -1\n0, 1\n0, -1\n1, -1\n2, 1\n2, -1\n(all the rest are zero)\nSome of these number pairs, such as 0, –1, appear very frequently in these lists\ncompared to other pairs like 0, 10. For maximum compression, the JPEG standard defines\na Huffman encoding for every possible number pair in these lists. The common 0, –1 pair,\nfor example, becomes the short Huffman code 001, while the uncommon 0, 10 pair\nbecomes the longer code 10110010. There’s also a special code, 1010, to signal that all the\nrest of the coefficients in the list are 0. The Huffman encoding for our list is shown in\nTable 6-8.\nTable 6-8: The Huffman Encoding of the Coefficients from Figure 6-15\nWOW! eBook\nwww.wowebook.org\nZeros skipped Coefficient Huffman encoding\n0 8 10110000\n0 10 10110010\n0 –7 100111\n0 –7 100111\n0 6 100010\n0 –4 100100\n1 –2 11100110\n0 1 000\n0 –2 0110\n0 –1 001\n0 –1 001\n0 1 000\n0 –1 001\n1 –1 11001\n2 1 110110\n2 –1 110111\n(Nothing left but zeros) 1010\nAll of the bits in the rightmost column, strung together, represent the compressed\nencoding of our original luminance block. The original block represented the luminance\nlevels as 64 bytes, or 512 bits total. In contrast, the encoding in Table 6-8 uses a mere 88\nbits.\nThe two color blocks, Cr and Cb, would show even higher compression because the\ndivisors used on the color blocks are even larger, which produces smaller numbers with\nshorter Huffman codes and more zeros for the run-length encoding. Overall, JPEG images\ntypically achieve a 10:1 compression ratio. The amount of compression can be increased\nWOW! eBook\nwww.wowebook.org\nor reduced by using smaller or larger divisors than those shown in Figure 6-14. These\ndivisors are adjusted by the “quality” slider in image-manipulation programs. Sliding the\ncontrol to “low quality” increases the divisors, reducing the file size while increasing the\nquantization error.\nJPEG Picture Quality\nHigh compression is great only if the restored image is indistinguishable from the original,\nor nearly so. Typically the alterations JPEG compression makes to an image are difficult\nto see. To get a feel for the changes introduced by compression, let’s compare the original\nblock of luminance values to the block that results from compressing and decompressing,\nas shown in Figure 6-17.\nFigure 6-17: The original luminance block, and the result of compressing and\ndecompressing the block\nSince it’s tough to visually compare these two blocks of numbers, Figure 6-18 shows\nthe differences as a grayscale matrix. As you can see, most of the matrix is neutral gray,\nindicating numbers very close to the original.\nFigure 6-19: The amount of error in each location of the luminance block\nThe best evidence for the quality of JPEGs is shown in Figure 6-19. On the top is an\nuncompressed digital photograph. Because this photo is in grayscale, we don’t need RGB\nWOW! eBook\nwww.wowebook.org\npixel color, just a single byte indicating the grayscale level. At a resolution of 975×731,\nthis uncompressed photo requires just under 713 kilobytes of storage. In the middle is a\ncompressed JPEG version of the original photo, requiring just 75 kilobytes of storage,\nwhich is virtually indistinguishable from the original. The photo on the bottom is a low-\nquality JPEG using larger divisors. While the photo takes up only about 7 kilobytes,\ncompression artifacts are clearly visible. Many of the individual 8×8 pixel blocks have\nbeen reduced to solid squares of the same gray level. In general, JPEG can result in a 10:1\ncompression ratio without sacrificing visual quality.\nCompressing High-Definition Video\nThe JPEG format does a fantastic job of compressing images with only small sacrifices in\nquality, but for high-definition video we need even more compression. Remember,\nuncompressed high-definition video requires about 186MBps. Individually compressing\neach image as a JPEG would reduce that requirement to about 18MBps—a big\nimprovement, but for streaming or disc storage we need to shrink the data to just a few\nMBps per second.\nFigure 6-18: An uncompressed photo (top), high-quality JPEG compression (middle), and\nlow-quality JPEG compression (bottom)\nWOW! eBook\nwww.wowebook.org\nTemporal Redundancy\nTo hit this target, video compression techniques take advantage of similarities between\nimages in sequence. Figure 6-20 shows an image sequence from a movie’s opening\ncredits.\nFigure 6-20: A few frames of an opening title sequence\nEach of these images will be shown for several seconds; which means that the\nsequence will contain many duplicate frames in a row. Also, even as the video transitions\nfrom one image to the next, most of the picture remains unchanged. Only the area in the\ncenter varies.\nNow consider the image sequence shown in Figure 6-21. Although each frame differs\nfrom the next, the same elements are present in each frame, just in different places on the\nscreen.\nFigure 6-21: An image sequence with a moving object\nThese examples show two different forms of temporal redundancy, continuity of data\nfrom one frame to the next. Compression that exploits such redundancy is called temporal\ncompression, and as we’ll see in the next section, it’s the key to achieving the compression\nratios needed for video streaming and storage.\nMPEG-2 Video Compression\nOne method of temporal compression is employed by MPEG-2, a common video format\nsupported by Blu-ray discs and digital broadcast television. More advanced techniques\nexist, but they are extensions of the ideas demonstrated here.\nGroups of Frames\nMPEG-2 videos are divided into sequences of around 15 frames called groups of pictures\n(GOPs). Exactly one frame in each GOP is selected to be a basic JPEG-encoded image\ncalled an intracoded frame (I-Frame). This frame is the rock upon which the rest of the\nGOP is built. All of the other frames use temporal compression, which means they are\nstored not as the absolute colors of the pixels in the image, but by how those colors differ\nWOW! eBook\nwww.wowebook.org\nfrom those in another image in the GOP, as we’ll see shortly.\nThe other frames in the group are assigned one of two types, predicted frames (P-\nFrames) and bidirectional frames (B-Frames). A P-Frame stores the difference between its\npixels and those of a previous frame, while a B-Frame stores the difference between its\npixels and those of a previous and a later frame.\nA GOP is shown in Figure 6-22, with arrows indicating the frames referenced by the\ntemporal compression. As you can see, everything depends on the I-Frame. During\nplayback, it must be decoded before any other image in the GOP, after which the frames\nthat directly reference the I-Frame can be decoded, and so on.\nFigure 6-22: A GOP, or group of pictures\nGrouping pictures this way simplifies encoding and decoding, and also limits the\nlength of the reference “chain.” Just like a photocopy of a photocopy, the longer the chain\nof temporal compression, the fuzzier the image gets. The regular appearance of I-Frames\nis also what allows you to see images as you fast-forward or rewind; the video player just\npicks out the I-Frames, which can be decoded and displayed independently of the other\nframes in its GOP.\nThe MPEG specification gives encoding software wide discretion in forming GOPs.\nThe number of I-Frames, which directly determines the size of GOPs, is up to the encoder,\nas is the number of B-Frames between the other frame types. Like the divisors used in\nJPEG quantization, the ability to change the relative numbers of the three frame types\noffers a trade-off between quality and compression. In applications where compression is\nparamount, like videoconferencing, I-Frames are rare and B-Frames are common, while in\na Blu-ray, the encoder will use as many I-Frames as possible while still fitting all the video\ndata on the disc.\nTemporal Compression\nSo how does the temporal compression of P-Frames and B-Frames work? In this example,\nwe’re compressing a P-Frame by referencing an I-Frame. First, the pixels in the P-Frame\nare divided into 16×16 macroblocks. For each macroblock, the I-Frame is searched for a\nmatching block of pixels with the same color data. This matching block may not appear in\nexactly the same place in the I-Frame, though, so it is indicated by its offset: the difference\nbetween the location in the P-Frame and the location in the I-Frame, expressed in screen\ncoordinates. For example, an offset of –100, 50 indicates that the macroblock’s location in\nthe I-Frame is 100 pixels left and 50 pixels down from its location in the P-Frame, as\nshown in Figure 6-23.\nWOW! eBook\nwww.wowebook.org\nFigure 6-23: A macroblock in a P-Frame referencing a matching block of pixels in a\nprevious frame\nIn most cases, an exact match won’t be found, so in addition to storing the location of\nthe best match, the differences between the two macroblocks must also be stored. Figure\n6-24 shows a luminance block from the P-Frame and the best match in the I-Frame. (I’m\nusing 8×8 blocks instead of a full 16×16 macroblock to keep the example manageable.)\nFigure 6-24: A luminance block and its best match in a prior frame\nNext, a block of differences is computed: each number in the I-Frame block is\nsubtracted from the number in the same position in the P-Frame block. The result for our\nexample is shown in Figure 6-25.\nWOW! eBook\nwww.wowebook.org\nFigure 6-25: The difference between the two luminance blocks in Figure 6-24\nBecause the blocks are a close match, these values are all small. This is a form of\npredictive encoding, just like the list of temperatures shown earlier in the chapter. By\nstoring differences, we’ve made the range of data much smaller, and therefore more easily\ncompressed. When we apply the DCT and quantize the results, the numbers are downright\ntiny, as shown in Figure 6-26.\nFigure 6-26: The result of quantizing the block in Figure 6-25 and applying the DCT\nThis block is highly susceptible to the last stage of compression: the combination of\nrun-length and Huffman encoding. As shown in Table 6-9, the original luminance block\nhas been reduced to a mere 39 bits.\nWOW! eBook\nwww.wowebook.org\nTable 6-9: The Huffman Encoding of the Numbers in Figure 6-26\nRun length Coefficient Huffman encoding\n4 1 1110110\n1 –1 11001\n0 1 000\n0 1 000\n0 –1 001\n1 1 11000\n7 1 111110100\n(Nothing left but zeros) 1010\nNot every macroblock in the P-Frame is encoded in this way. In some cases, a\nmacroblock may not be similar enough to any block of pixels in the previous frame to\nsave any space by storing the difference. Those macroblocks can be recorded directly, like\nthe macroblocks in an I-Frame. For a B-Frame, matching macroblocks can be found in a\nprevious frame or a later frame, which improves the odds of a close match.\nVideo Quality with Temporal Compression\nTemporal compression depends upon temporal redundancy—sequences of frames with\nfew changes. For this reason, some videos compress much better than others. Movies with\nlots of camera movement, like Cloverfield or The Blair Witch Project, are difficult to\ncompress, while movies with long takes where the camera doesn’t move, like 2001: A\nSpace Odyssey, are ideal.\nUltimately, video compression is a bit of an art as well as a science. As stated earlier,\ndifferent MPEG-2 encoders can produce different results for the same sequence of images.\nShorter GOPs, with more I-Frames and fewer B-Frames, produce better-looking video\nthan longer GOPs, but longer GOPs mean better compression. An encoder can vary the\nmix of frames even within the same video, using longer GOPs when there’s high temporal\nredundancy and shorter GOPs when there isn’t. Also, good encoders will try to line up\nGOP boundaries with sharp cuts in a movie; if you’ve ever seen a video that was\nmomentarily very blocky when the scene changed, it’s likely because a GOP stretched\nover the cut.\nThere’s also the question of performance, especially if the video is being compressed in\nreal time, as with a live event. There might not be enough time to find the absolute best\nWOW! eBook\nwww.wowebook.org\nmatch for a macroblock in the other frame.\nPlayback quality can vary as well. For example, because of how frames are broken into\nindividually processed macroblocks, seams may appear along the borders of the blocks.\nTo reduce this effect, a decoder may apply a deblocking filter. This smoothes block\nboundaries by averaging pixel colors, much like the anti-aliasing methods shown in\nprevious chapters. The strength of the filter can be adjusted based on the likelihood of a\nclean boundary. In a B-Frame, for example, if one block references the previous frame\nwhile an adjacent block references the next frame, there’s a greater likelihood of a rough\nboundary, which calls for stronger filtering.\nIn other cases, the resolution of the video and the display resolution may not match.\nFor example, when you’re streaming an episode of the old cop show Adam-12 (it’s not just\nme, right?) on a high-definition television, either the television or the player has to convert\nthe original 640×480 images to fill the 1920×1080 display. This is the same problem we\nsolved in Chapter 5 with texture mapping—applying a bitmap to a larger area—and video\ndevices can employ the same sorts of techniques. Early high-definition players effectively\nused nearest-neighbor sampling, which produced poor results. Newer players employ\ntechniques similar to trilinear filtering. Instead of blending between bilinear samples from\ntwo different levels in a mipmap, however, they blend between successive frames. This is\nespecially effective in smoothing objects in motion.\nAlthough not as computationally intense as the original encoding, playing back a\ntemporally compressed video is still a lot of work for a processor. Also, the structure of a\nGOP requires decoding the frames out of order. This in turn requires that frames be\nbuffered, held in a queue prior to display. For streaming video, much larger buffers are\nused so that minor hiccups in the network don’t disrupt playback.\nThe Present and Future of Video Compression\nThe latest video compression standard, known as H.264 or MPEG-4, extends the\ntechniques used in MPEG-2 but isn’t fundamentally different. The primary differences\nimprove the quality of macroblock matching. Instead of being matched against just one or\ntwo other frames, macroblocks can be matched against 32 other frames. Also, the 16×16\nmacroblocks themselves can be broken down into separately matched 8×8 blocks.\nThrough such improvements, MPEG-4 can often achieve twice the compression ratio\nof MPEG-2 with the same quality result. For that reason, MPEG-4 is an industry standard\nfor both streaming and storage. Most Blu-ray videos use it, as do YouTube and Netflix. Its\nchief competition is a format called Theora, which uses similar compression methods but\nis freely licensed, unlike the proprietary MPEG-4.\nToday’s compression formats do an amazing job at shrinking video data, but they do so\nat a high computational cost. The next time you watch a clip on YouTube, think about a\nGOP, all the macroblocks being copied and updated from one frame to the next, and all the\nnumber crunching that goes into performing the DCT over and over again. It’s a dizzying\namount of calculation just to show a cat falling off a piano.\nEven more computational horsepower will be needed in the future. The new ultra high\nWOW! eBook\nwww.wowebook.org\ndefinition (UHD) format, seen in theaters in films like Peter Jackson’s Hobbit series, is\nstarting to trickle down to home video. UHD images are 3840×2160, which is four times\nthe number of pixels as current high definition. The frame rate will also increase, from\ntoday’s 24 or 30 fps to 48, 60, or even 120 fps. UHD video could increase the bit\nrequirements from today’s 1,400Mbps to over 23,000, which will require a corresponding\nincrease in bandwidth and disc storage capacity—unless someone clever comes up with an\neven better way for software to shrink the data.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "How do search engines efficiently find relevant web pages so quickly despite the vast size of the internet?",
    "summary": "This chapter discusses the importance of efficient searching, explaining how different methods like selection sort, quicksort, binary search, and hashing are used to find data quickly. It highlights that sorting data allows for faster searches, while hashing provides a way to store and retrieve records efficiently even when data is dynamic. The chapter also covers how search engines use indexing and web crawling to manage large data collections, and how they rank results based on factors like keyword frequency and inbound links.",
    "output": "7\nSearch\nThis chapter is about a topic that, perhaps more than any other subject covered in this\nbook, we all take for granted: finding the data we want, known as a search. Searching\nhappens so often, and so quickly, that it’s easy to miss the magic. When a word processor\nunderlines a misspelled word that you just typed, a fast search has taken place behind the\nscenes. When you enter part of a filename and get a list of matching files on your laptop’s\nhard drive, that’s another near-instant search. And then there’s the ultimate search\nachievement: the Web. The Web is so unfathomably large that we can only guess its true\nsize, and yet, web search engines can find relevant web pages in a fraction of a second.\nHow does software find what we want so fast?\nDefining the Search Problem\nLet’s start by getting our terminology straight. A collection of data is known, appropriately\nenough, as a data collection. Each item in the data collection is a record. A record is\nuniquely identified by a key (no relation to the cryptography term). A search retrieves the\nrecord that matches a given key. For a real-world example, when you use a dictionary the\nword you’re looking up is the key, and the definition of that word is the record.\nThe main goal of searching is to find the right record. But the speed of the search is\njust as important. If searches could go on indefinitely, searching would be simple. But as\nthe wait time increases, so does our frustration. The length of time we’ll wait on a search\nvaries, but it’s never very long, and in many situations, the search must appear to finish\ninstantaneously.\nPutting Data in Order\nEfficient searching requires well-organized data. When you visit a bookstore, for example,\nfinding a novel by a particular author is easy if the store has ordered the shelves by\nauthors’ last names. For one thing, you know where to start looking. Once you look at the\nfirst book on the shelf and see how close its author’s name is alphabetically to the author\nyou seek, you would have a good idea where to look next.\nIf the store didn’t shelve its books in any particular order, then finding a book would be\nWOW! eBook\nwww.wowebook.org\nhard work. The best option is to start at one end of the shelf and examine every single\nbook, which is known as a sequential search. In the worst case, the book you want isn’t\neven on the shelf, but you wouldn’t know that until you’ve looked through the whole\ncollection.\nTherefore, putting the data collection in a particular order, known as sorting, is\nessential for efficient searching. There are many different ways to sort; entire books have\nbeen written to describe different sorting algorithms for software. We’ll look at two\nmethods here.\nSelection Sort\nIf I asked you to put a list of numbers in order, you would most likely use what is known\nas a selection sort. First, you’d scan the list to find the lowest number, and then you’d\ncross the number out and copy it to a new list. You would repeat the process until all the\nnumbers were in order in the new, sorted list.\nThe first three steps of a selection sort of nine numbers are shown in Figure 7-1. In the\nfirst step, the lowest number is copied to the beginning of a new list. In the steps that\nfollow, the lowest remaining numbers are copied to the new list.\nFigure 7-1: The first three steps in a selection sort of nine numbers\nQuicksort\nWOW! eBook\nwww.wowebook.org\nWhile selection sort is easy to understand, software rarely uses it because it isn’t efficient.\nEach step requires us to process every number in the unsorted list, and for that effort all\nwe get is one number in its correct position.\nA better sorting method, called quicksort, partially orders all of the data processed\nduring each pass, reducing later effort and time. Instead of scanning the entire list for the\nlowest number, we select a number in the list to be the pivot. We use the pivot to partition\nthe list, dividing the list around the pivot. Numbers that are less than the pivot go to the\nfront of the list, and those that are greater go to the back.\nFor this example we’ll use the same list of numbers used in the selection sort. Figure 7-\n2 shows the first step of partitioning. Different versions of quicksort select the pivot in\ndifferent way; we’ll keep things simple and use the first number in the list, 47, as the\npivot. The next number, 93, is copied to the end of the new list because it is greater than\n47.\nFigure 7-2: The number 93 is more than the pivot, so it moves to the end of the new list.\nIn Figure 7-3, 56 is also greater than 47, so it’s copied to the next space on the end.\nFigure 7-3: The number 56 is more than the pivot, so it moves to the end of the new list.\nIn Figure 7-4, 33 is less than 47, so it’s copied to the front of the new list.\nFigure 7-4: The number 33 is less than the pivot, so it moves to the front of the new list.\nFigure 7-5 combines the next five steps. Three of the remaining numbers go to the\nfront of the list and two go to the back. This leaves a gap for one more number.\nWOW! eBook\nwww.wowebook.org\nFigure 7-5: The remaining numbers in the list are partitioned.\nIn Figure 7-6, this gap is filled with 47, the pivot. This completes the initial\npartitioning.\nFigure 7-6: The pivot fills the open space in the new list.\nThis new list isn’t sorted, but it’s in better shape than before. The pivot is in its correct\nsorted position, indicated by the shading. The first four numbers in the list are less than 47,\nand the last four are greater than 47. A single partitioning does more than put one number\nin its correct place, like one step of a selection sort; it also divides the remaining numbers\nin the list into sublists, as shown in Figure 7-7. These sublists can be sorted independently.\nSorting two shorter lists requires less effort than sorting one longer list. If you doubt this,\nconsider an extreme case: would you rather sort 50 short lists of 2 numbers, or 1 long list\nof 100 numbers?\nFigure 7-7: Partitioning has transformed the list into two separate, smaller lists that can\nbe sorted independently.\nThe two sublists are now independently partitioned. In Figure 7-8, the first number in\nthe sublist, 33, becomes the new pivot and the four numbers of sublist 1 are partitioned.\nThis puts 22 and 11 to the left of the 33, and 45 to the right.\nWOW! eBook\nwww.wowebook.org\nFigure 7-8: Partitioning sublist 1 of Figure 7-7\nIn Figure 7-9, sublist 2 is partitioned using 74 as a pivot.\nFigure 7-9: Partitioning sublist 2 of Figure 7-7\nThese partitions put both of their pivots in their correct sorted places in the list. The\npartitions also create four new sublists, as shown in Figure 7-10.\nFigure 7-10: Now four sublists remain. Single-number sublists are trivial.\nSublists 4 and 6 contain a single number, which means there’s nothing to partition. In\nFigure 7-11, sublists 3 and 5 are partitioned.\nFigure 7-11: Only two trivial sublists remain, which means the whole list is sorted.\nNow we have just two single-number sublists left, which means that the sort is\nWOW! eBook\nwww.wowebook.org\ncomplete.\nIn this example, the pivots evenly divided their partitions, but quicksort isn’t always so\nlucky. Sometimes the split is uneven, and in the worst case, the pivot could be the lowest\nor highest number in the list, which means the partitioning produces the same result as a\nstep in a selection sort. But most partitions will be roughly even, which tends to result in a\nmuch faster sort.\nMore generally, quicksort scales much better than selection sort. For any sorting\nmethod, sorting time increases as the size of the data collection increases, but selection\nsort slows down much more than quicksort. Let’s say a particular computer can sort\n10,000 records in around a second using either method. On the same computer, a selection\nsort of 1,000,000 records would take nearly 3 hours, while a quicksort would take only\nabout 11 minutes.\nBinary Search\nWhen data is in order, software can find a particular record easily. One simple search\nmethod for ordered data is binary search. The word binary in this case doesn’t refer to\nbinary numbers, but to choosing between two alternatives.\nFigure 7-12 shows binary search in action. The record we want has a key of 48.\nInitially, all we know is that the data in the collection is ordered on our key, so the record\ncould appear anywhere. In step 1, we examine the record in the middle of the collection. If\nthis record had a key of 48, we would we be done, but this is unlikely. However, because\nthis record has a key of 62, which is larger than 48, we know that the desired record must\nappear among the first seven records. Thus, examining one record has eliminated not just\nthat record from consideration, but also the seven records that appear later in the\ncollection.\nIn step 2, we examine the fourth record, the midpoint of the remaining seven records.\nThis record has a key of 23, which is lower than 48. Therefore the desired record must be\nin the three records between 23 and 62.\nIn step 3, we examine the middle of these remaining three records, which has a key of\n47. This tells us the desired record must be the one record between 47 and 62. If that\nrecord did not have a key of 48, it would mean the collection did not include a record with\nthat key.\nWOW! eBook\nwww.wowebook.org\nFigure 7-12: Binary search taking four steps to find a particular record in a collection of\nsize 15\nEach step in a binary search eliminates half of the records from consideration, which\nmeans binary search scales fantastically well. With a sequential search, doubling the size\nof a data collection doubles the time needed for the average search. With binary search,\ndoubling the number of records requires just one more step. If we start with 31 records, for\nexample, after examining the middle record, either we get lucky and find the desired\nrecord, or we find out whether the desired record is in the first or last 15 records. Either\nway we would now have only 15 records left to search, putting us back where we started\nin Figure 7-12. For huge data collections, the difference between binary and sequential\nsearch is dramatic. A sequential search of 1,000,000 records will examine 500,000 records\non average, while a binary search of 1,000,000 records will examine no more than 20.\nIndexing\nTo keep the figures simple, our examples to this point have used just record keys. In\npractice, though, the rest of the record has to be stored somewhere, and this can cause\nproblems. To see why, we have to understand the choice software faces when allocating\nstorage space for data, whether in main memory, on a hard drive, or anywhere else.\nFixed-size storage allocation assigns each record the same amount of space and is used\nfor data that is either always the same size or has a small maximum size. Credit card\nnumbers, for example, are always 16 digits. The names of credit card owners, on the other\nhand, vary in size, but there are only so many letters that will fit on the card. Both card\nnumbers and card-holder names could be stored in a fixed number of bytes. In Figure 7-\n13, the maximum size of a last name is 15 characters, just long enough for Hammond-\nHammond. The other names are shorter, resulting in wasted bytes, shown as shaded\nWOW! eBook\nwww.wowebook.org\nsquares. Because the space needed to store a name is small, though, this wasted space is of\nno great concern.\nFigure 7-13: Fixed allocation of storage results in wasted space\nVariable-size storage allocation exactly fits the data. Consider a collection of MP3\nfiles. Roughly speaking, the longer the song, the larger the MP3 file. A short pop song\nmight be 3 or 4MB, while a progressive-rock epic might be as large as 20MB. We\nwouldn’t want to store song data in fixed space because this would waste too much space\nfor shorter songs, and this would limit the length of a song. Instead, the data should be\nstored in just as much space as needed.\nVariable-size storage allocation uses space efficiently, but fixed-size storage allocation\nis required for software to use efficient search methods. When all the records in a\ncollection are the same size, software can quickly find a record in a particular position.\nThis is because storage locations are identified by numerical addresses. Every byte in\ndigital storage—whether in a computer’s main memory, or on a flash drive or hard drive—\ncan be precisely located by its address. If a computer has 8GB of main memory, for\nexample, those bytes are numbered from zero to just over eight trillion. Collections of\nfixed-size records are stored contiguously, which makes finding a record’s address simple.\nSuppose a collection has 100 records, each 20 bytes in size, and the collection begins at\naddress 1,000. That puts the first record at address 1,000, the second at 1,020, the third at\n1,040, and so on. We can calculate the address of any record by multiplying its position\nnumber by 20 and adding the result to 1,000. In this way, software can quickly locate any\nrecord in any collection of fixed-size records.\nFinding records quickly is essential for a method like binary search. Without fixed-size\nrecords, the only way to find a record in a particular position is to start from the beginning\nof the data collection and count the records. That’s just a sequential search, and defeats the\npoint.\nChoosing between fixed-size and variable-size storage allocation means choosing\nbetween efficient search and efficient storage. However, a technique called indexing gives\nus both. Indexing separates the keys from the rest of the records, much as a library card\ncatalog allows patrons to search for books on cards before ultimately retrieving the books\nfrom the shelves.\nAn index is a table of record keys and addresses. The addresses themselves are stored\nas binary numbers with a fixed number of bits. For example, when Microsoft releases\nversions of Windows in “32-bit” and “64-bit” editions, those bit counts refer to the size of\nthe addresses for main memory. Because the addresses are a fixed size, we can store the\naddresses and keys together in an index of fixed-size records that can be searched\nefficiently using a method like binary search. The rest of each record’s data is stored in a\nvariable-size allocation. This produces a data collection that is efficient for storage and\nWOW! eBook\nwww.wowebook.org\nsearching.\nFigure 7-14 shows an indexed data collection of four songs. On the left, the index\ncontains the song titles and the addresses for the remaining data of each song, such as the\nartist name and the encoded music. On the right is a block of memory cells numbered\nfrom 1 to 400. The arrows point to each address.\nAs shown in the example, this split data allocation allows each record to use as much\nor as little space as needed. It even allows the index and remaining data to be on different\nstorage devices. For example, the index might be kept in a computer’s fast main memory,\nwhile the encoded music data is left on its relatively slow hard drive. Because only the\nindex is needed for search, such an arrangement allows for efficient search while using the\nminimum amount of main memory.\nFigure 7-14: An indexed data collection of digital music\nWe can also have multiple indexes for the same data collection. The arrangement in\nFigure 7-14 allows individual songs to be quickly located by song title, but doesn’t help us\nsearch for a song based on artist name or album title. Data collections can have multiple\nindexes for different search criteria, and because the main record data is simply referenced\nby an address, having multiple indexes doesn’t greatly affect the total storage\nrequirements for the data collection.\nHashing\nAlthough ordered data is required for efficient searching, sorting data takes time. So far\nwe’ve discussed sorting as though data collections need to be sorted just once. Sometimes\nthat is the case; for example, a word processor needs a list of correctly spelled words for\nspell checking, but that list is created once and supplied as part of the application. A\nspellcheck word list is a static data collection, one that changes infrequently. However,\nmany of the collections we search are dynamic—records are frequently added or removed.\nBecause efficient searching requires ordered data, collections must be re-sorted following\neach addition or removal. When insertions and deletions are common, the time spent re-\nWOW! eBook\nwww.wowebook.org\nsorting the data collection can negate the benefit of a faster search. In such cases, it may\nbe better to structure the data to facilitate frequent changes.\nOne data structure that eases additions and removals of records involves hash\nfunctions, which were introduced in Chapter 2. For this example let’s imagine a hash\nfunction that produces a mere 3-bit hash, equivalent to a decimal number in the range of 0\nto 7. We can use this to store records in a hash table with slots for 8 records. A slot is a\nplace where a record could be stored.\nTo store a record in the hash table, we hash the record’s key to determine which slot to\nuse. Suppose we are storing MP3 files with song titles as the keys. Four titles and their\nassociated hash codes are shown in Table 7-1.\nTable 7-1: Hash Codes for Sample Song Titles\nSong title Hash code\nLife on Mars 6\nNite Flights 4\nSurrender 1\nThe True Wheel 4\nFigure 7-15 shows the hash table after the insertion of the first three songs from Table\n7-1. The first column in each record is a bit, which is 1 if the slot is in use and 0 if not.\nThe second column is the title, and the third column holds the address of the remaining\ndata.\nFigure 7-15: An eight-slot hash table\nThe beauty of a hash table is that a search doesn’t really require searching. We just run\nthe key through the hash function and the result tells us where the record should be. If\nthere’s no record in that slot, we know right away that the collection doesn’t contain a\nrecord with that key. Even better, hash tables avoid the effort of sorting. This makes a hash\ntable an excellent choice for a collection with frequent additions and deletions of records.\nWOW! eBook\nwww.wowebook.org\nHowever, we haven’t inserted the fourth song in the list. The song title “The True\nWheel” hashes to 4, the same number as “Nite Flights.” As you may remember from\nChapter 2, a hash function is not guaranteed to produce a different hash value for every\ninput, and indeed, some matching hash values, or collisions, are inevitable. Since we can\nput only one record in a slot, we need a rule for handling collisions. The simplest rule is to\nuse the first empty slot after the collision point. Because slot 4 is already occupied with\n“Nite Flights,” we would place “The True Wheel” in the next open slot, which is slot 5, as\nshown in Figure 7-16.\nFigure 7-16: Resolving a collision. The second song that hashes to 4 is placed in the next\nempty slot, which is slot 5.\nThis handles the collision problem, but it complicates the use of the hash table.\nWith this collision rule in place, finding a record is no longer a one-step process. Each\nsearch still starts at the slot indicated by the hash code, but then checks the slots one by\none until it finds the matching song title. If the search reaches an empty slot, the song isn’t\nin the collection.\nCollisions can also cause records to be stored far from the position indicated by the\nhash code. For example, if a title with a hash code of 5 is inserted into the table shown in\nFigure 7-16, even though no previous song title has hashed to 5, the slot is already filled\nby “The True Wheel,” and the new song would move all the way to slot 7. As a hash table\nfills, these situations become more common, degrading search performance; in effect,\nsome hash table searches become miniature sequential searches.\nCollisions also complicate the deletion of records. Suppose “Nite Flights” is removed\nfrom the hash table of Figure 7-16. The obvious way to remove a record is just to mark the\nslot “empty” again, but that doesn’t work. To see why, remember that the song title “The\nTrue Wheel” hashed to 4, and the song was stored in slot 5 only because slot 4 was\noccupied at the time. A search for “The True Wheel” will begin at slot 4 as indicated by\nthe hash code, find the slot empty, and end the search unsuccessfully. The song is still in\nthe index table, but can’t be found by a hash search.\nTo avoid this problem, we can remove the song data but keep the slot marked as\noccupied, as shown in Figure 7-17.\nSlot 4 is now what is called a tombstone. By leaving the slot marked as occupied while\ndeleting the data, we ensure that searches still work. However, tombstones waste space.\nWOW! eBook\nwww.wowebook.org\nFurthermore, because the table never really frees any record slots, the performance issues\nof congestion remain.\nFor these reasons, hash tables are periodically rehashed. Once a certain percentage of\nthe slots in a table are occupied, a new, larger table is created, and each key in the original\ntable is hashed with a new hash function, producing a fresh, sparsely populated table\nwithout any tombstones.\nFigure 7-17: Leaving slot 4 marked as occupied after deletion of its data\nWeb Search\nAll of the techniques shown in this chapter are needed for efficiently searching large data\ncollections, and no collection is larger than the Web. A search engine such as Google\ndepends upon a vast index, where the keys are search terms, the addresses are URLs, and\nthe web pages are the records. The size of the Google index is estimated at around 100\npetabytes, or 100,000,000 gigabytes. To find something in an index this large requires all\nof the best search techniques. Although these techniques help illustrate how an index this\nlarge could be searched, they don’t tell us how the index was created in the first place.\nSearch engines use robots, programs that run without direct human intervention, to\nbuild their indexes. The robots crawl all over the Web. Starting at some particular web\npage, they make a list of all the links on that page. Those linked pages are then processed\nto find links to other pages, and so on. Eventually the robot has links to most of the\ncontent on the Web.\nSome content, though, is more difficult to locate. Some pages can’t be reached from a\nsite’s home page but are instead found through the site’s own search engine. A news site,\nfor example, may not link to older articles but does provide a local search for its archives.\nThis unlinked but valuable content is known as the deep web. Incorporating deep web\ncontent into a search engine index usually requires some assistance from the site. Site\nmanagers have several ways to provide web-crawling robots a “table of contents” for all\nthe pages on the site, such as a document called a Sitemap. This document is named after\nthe site map page some sites provide for users to quickly find the content they are looking\nfor, but has a specific format that’s easy for robots to process. Sitemaps keep search\nengines updated with content changes and are especially useful for sites with deep content\nthat would otherwise be left out of search engine indexes.\nWOW! eBook\nwww.wowebook.org\nRanking Results\nAs robots gather pages, search engines mine the pages for keywords, counting how often\neach keyword appears on each page. Early search engines employed little more than a list\nof keywords along with their page counts. If you searched for cake, the page where cake\nmost often appeared would be at the top of the returned list. That’s logical enough, but a\nmere word count doesn’t produce what we now consider to be good search results.\nThe first problem is that it’s too easy for someone to exploit the system for personal\ngain. Suppose the operator of a site selling knockoff pharmaceuticals wants to get a lot of\ntraffic and doesn’t care how it’s done. When the operator discovers that legions of people\nare searching for omelette recipe, the operator might put those words on the home page as\nmany times as possible, even hiding the words in the behind-the-scenes formatting code.\nAs a result, the site might be among the first returned on searches for omelette recipes,\neven though no such recipes appear on the site. Word counts do not guarantee a match\nbetween search terms and content.\nAnother website operator might build a site that is legitimately about omelettes, but it’s\nfilled with content stolen from Wikipedia, in order to generate revenue from ads about a\nzero-cholesterol egg substitute. In this case, the word count correctly connects the search\nterm to matching content, but the quality of the content is poor.\nThe underlying issue is that the websites are self-reporting the nature and the quality of\ntheir content. What’s missing is the opinion of a disinterested viewer. Ideally, search\nengines could employ an army of reviewers to determine what pages are about and how\nwell they cover their chosen topics. The Web is so vast and ever-changing, though, that\nthis is a practical impossibility.\nInstead, search engines rely on the opinions of other websites. They acquire these\nopinions in the form of inbound links. The number of links to a particular page is a good\nmetric for how that page is regarded by the online community. In Figure 7-18, page C has\nfour inbound links, page D has none, and each of the others has one. On this basis alone,\npage C appears to be the most valued resource, while A, B, and E appear equally useful.\nWOW! eBook\nwww.wowebook.org\nFigure 7-18: The number of links pointing to a page is one factor used by search engines\nto determine ranking.\nThere’s more to the story though. A page with a high inbound link count grants more\npoints to the pages it links to. In the previous figure, three pages have only one inbound\nlink, but the quality of each link is different. Page E is linked from page C, which has a\nhigh inbound link count, while pages A and B are linked only from each other. Factoring\nthe quality of each link into the link count helps to foil link farming, in which large\nnumbers of pointless websites are created, often through free host services, for the purpose\nof increasing a target site’s inbound link count.\nIn effect, this turns the Web into a collection of self-organized expert communities.\nWhen a number of well-regarded cooking sites begin linking to a new omelette-focused\nsite, which in turn links back to omelette-related content in the established sites, the new\nsite is inducted into the online cooking community. Thereafter, the new site’s links count\nas much as the older, established sites.\nUsing the Index Effectively\nWhile building the index is the bulk of the work of making a search engine, how the index\nis used during a search is just as important. Good search results require attention to detail.\nFor one thing, a search engine cannot merely use the supplied search terms as\nkeywords. Consider the differences in word forms. You might type frozen rain in a search\nbox, but most pages with relevant information use the form freezing rain. By linking\ntogether different forms of keywords in its index, a search engine can maximize the\nusefulness of results. This idea applies to synonymous terms as well. Because the words\ninsomnia and sleeplessness mean the same thing, searching for either term produces\nsimilar results, even though some pages predominantly use one word or the other. For\nexample, the Wikipedia article on insomnia appears in the first few results for either\nsearch term, even though, at the time of this writing, the word sleeplessness appears only\ntwice in the article, while the word insomnia appears over 200 times.\nThe results from these search terms are not identical, though. A search for insomnia\nwill also include links to the 2002 film Insomnia, but these links aren’t returned by a\nsearch for sleeplessness. That result makes sense—presumably, no one searching for the\nfilm would have entered a synonym of the film’s title—but how can a search engine know\nthe two terms are linked in some ways but not others?\nTracking how search terms are combined can yield valuable clues. If searchers\nfrequently add the terms movie or film to the term insomnia, then searches for just\ninsomnia may indicate someone interested in the film and not the medical condition.\nFurthermore, the links on a search results page are not actually direct links to the listed\npages. Instead, they are pass-through links. For example, if you search Google for\ninsomnia, then click on the link for the Wikipedia entry, you’ll first be taken to the\ngoogle.com server, which will then redirect you to wikipedia.org. Google tracks which\nresult you selected, and this data, collected from countless users over time, allows Google\nto fine-tune the results, keeping the links that users actually find useful near the top.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What are the challenges and solutions associated with managing concurrency in software to prevent race conditions, deadlocks, and starvation?",
    "summary": "Search engines use location data to provide localized search results. Future improvements include using computer vision for image search and real-time indexing for faster access to social media content. Concurrency is essential for modern computing, allowing multiple processes to work together, but it can cause issues like race conditions if not managed properly. Techniques such as semaphores help prevent these problems by controlling access to shared data, but they can also introduce performance challenges if not used with appropriate granularity.",
    "output": "Search engines can also make use of the location of the person searching. For example,\nwhen you search for smiley’s pizza while you’re standing in a particular town, the search\nengine appends the town’s name to the search, so that the results are localized, instead of\nreturning the websites of the most popular pizzerias with that name in the entire world.\nWhat’s Next for Web Search\nAs impressive as current web search capabilities are, there’s still room for improvement.\nFor example, images provide unique challenges for search engines. Currently, image\nfiles are indexed based on accompanying text. A search engine might gather clues from an\nimage’s filename, or make educated guesses based on the text surrounding the image on\nthe page.\nWe can soon expect the use of computer vision techniques in web indexes. Such\nsoftware techniques transform an image into a description of the image. In some ways this\nis the reverse of the graphics techniques described in Chapters 4 and 5, where\nmathematical models were rendered into images. With computer vision, images are\nsimplified into mathematical descriptions that are then categorized by pattern. Such\nsoftware is currently used in self-governing robots, so that they can recognize an object\nthey have been sent to retrieve. Future search engines may process the Web’s images using\nthese techniques, identifying both general subjects (“clear sky,” “kittens”) and specific\nsubjects (“Eiffel Tower,” “Abraham Lincoln”) within the images.\nIndexes will also be updated faster. Currently web indexes update only when a web-\ncrawling robot passes through. In the future, indexes may be updated in near real time, so\nthat conversations quickly developing throughout social media can be indexed as they\nhappen. Eventually, real-time search may be combined with artificial intelligence to\nautomatically generate basic news stories from social media for fast-breaking events like\nnatural disasters.\nBut those are tomorrow’s marvels. The Web and its search engines are the marvel of\ntoday, a powerhouse of information unfathomable just a few decades ago.\nWOW! eBook\nwww.wowebook.org\n8\nConcurrency\nUsually we can tell when software is doing something interesting, even if we don’t know\nhow it’s done. We know that computers make graphics, encrypt our transmissions, and\nstream our videos. What we miss, though, is that these tasks often involve multiple\nprograms, multiple processors, or even multiple computers connected via a network,\naccessing the same data at the same time.\nThis overlapping access of data, known as concurrency, is a vital part of modern\ntechnology. High-performance tasks like graphics and shared resources like websites\nwouldn’t be possible without it. But concurrency causes big problems when it’s not\ncarefully managed. In this chapter, we’ll see how results can become scrambled when\nmultiple processors access the same data. Then we’ll look at the clever software (and\nhardware) techniques that keep processors from getting in each other’s way.\nWhy Concurrency Is Needed\nSituations that require concurrency fall into three basic categories: performance, multiuser\nenvironments, and multitasking.\nPerformance\nConcurrency is needed when there’s more work to do than a single processor can handle.\nUntil recently, the number of instructions a processor could execute in a second was\nsteadily increasing, but now the pace of improvement has slowed. In order to execute\nmore instructions in the same amount of time, a processor has to run faster. The faster it\nruns, the more power courses through it and the hotter it gets, which can eventually\ndamage the components.\nTo mitigate that problem, the size of the components in the processor keeps getting\nsmaller so that they draw less current and remain relatively cool. But it’s getting difficult\nto make processor components any smaller, which in turn makes it difficult to make them\nrun any faster. When a single processor can’t get the job done, the only solution is to use\nmultiple processing cores. We saw this with video game graphics in Chapter 5, but it’s not\njust high-end game graphics that need multiple processors. Even today’s basic graphics\nWOW! eBook\nwww.wowebook.org\ntasks may require multiple processor cores.\nMultiuser Environments\nConcurrency also allows networked computer systems to work together. Suppose you are\nplaying an online game such as World of Warcraft. The game tracks each player’s actions\nas well as those of the computer-controlled monsters. The game’s servers tally every spell\nand axe swing, and calculate the damage done, the monsters slain, and the loot dropped.\nConcurrency is required here because the processor in every player’s computer must\nshare the data of nearby players and computer-controlled creatures.\nMultitasking\nConcurrency can occur even in situations where only one processor is involved. Modern\ncomputers multitask, which means they are constantly switching between different\nprograms, even when we think we’re doing only one thing on the computer at a time. For\nexample, multitasking is what allows your email client to receive a new message while\nyou surf the Web. In these cases, whether or not the computer has multiple processor\ncores, it’s definitely running multiple processes—different programs with overlapping\nexecutions.\nPrinting is another typical example. When you print a recipe from a website, the\nsoftware that manages the printer, known as the driver, collects the print data in an orderly\nqueue and then passes it on to the printer as needed. This is called print spooling. Without\nprint spooling, the browser could send the data only as fast as the printer processed it,\nwhich means that you would have to wait for the print job to finish before you could do\nanything else with the browser.\nPrint spooling can’t work without concurrency. You can think of a print spool as one of\nthose carousels that sit in the window between the front counter and the kitchen in a short-\norder restaurant, like the one shown in Figure 8-1. Someone in the front puts new orders\non the carousel, and someone in the back takes down the orders as they are fulfilled. The\nshared data storage of the carousel allows the order takers and the cooks to work\nindependently.\nWOW! eBook\nwww.wowebook.org\nFigure 8-1: An order-ticket carousel\nThis arrangement is known as a shared buffer and is frequently used behind the scenes\nin software. For example, suppose you are typing an email, but your computer\nmomentarily slows down so that nothing you typed appears on screen. Then the system\ncatches up, and everything you typed is now in the email. That happens because the\nkeyboard doesn’t communicate directly with the email program, but uses the operating\nsystem as an intermediary. The operating system queues the keystrokes in a shared buffer\nso the email program can access them when ready.\nMultitasking also allows programs to sit in the background and interrupt you when\nsomething significant happens. When a new email alert appears in the corner of your\ndesktop’s screen while you are working in a word processor, or your phone signals a\nnewly received text message while you’re playing a game, that’s multitasking at work.\nBeyond the performance benefits of multiple processors and distributed processing, the\nimportance of multitasking means some form of concurrency is required to provide the\nbasic computing functionality we rely on daily.\nHow Concurrency Can Fail\nAlthough concurrency is a vital part of everyday computing, it creates enormous\nheadaches for software and can produce serious problems if proper safeguards aren’t in\nplace to prevent them.\nThe underlying issue is how data is copied when it’s used in calculations. Essentially,\nall a computer processor does is retrieve numbers from storage and either perform math\nwith them or compare them. To do these tasks, though, it must copy the numbers from\nwherever they are stored to locations inside the processor. Stored data isn’t changed\ndirectly. Instead, the computer fetches the value from main memory, or a hard drive, or\nacross a network, and delivers it to the innermost part of the processor. The processor\nperforms the math on this internal copy, and then sends the updated value back to storage\nto replace the original data.\nWOW! eBook\nwww.wowebook.org\nSuppose you’re playing a first-person shooter game. You have 300 bullets in reserve\nwhen you run over an ammo clip, picking up 20 more bullets. Figure 8-2 shows the steps\ninvolved. To update your bullet count, the processor first retrieves your current bullet\ncount and the number of bullets in the clip from their places in storage, shown in step 1.\nThese values are fed into the inputs of an “adder” circuit in the processor, as shown in step\n2, which performs the actual math. Then the result is sent back to main memory, replacing\nthe old value in the bullet count storage location, as shown in step 3.\nFigure 8-2: Three steps to update a number from 300 to 320\nThis update sequence causes problems when multiple processes attempt to make\nalterations to the same storage location. Take, for example, a massively multiplayer online\ngame (MMO). Trina Orcslayer and Skylar Rockguardian are two players. They are both\nofficers of the same “guild,” and this game allows guilds to hold shared bank accounts\nacross multiple game servers. On Friday morning, the balance of the guild account is\nexactly 10,000 gold, and Skylar and Trina each have 500 gold in their personal accounts.\nSometime that day, Skylar withdraws 300 gold from the guild account while Trina\ndeposits 200 gold into it. If these are the only transactions that happen, the final balance\nshould be 9,900 in the guild account (10,000 – 300 + 200), 800 in Skylar’s account (500 +\n300), and 300 in Trina’s account (500 – 200).\nWOW! eBook\nwww.wowebook.org\nAnd that’s what will happen if the transactions are kept separate. Suppose Skylar\nmakes the withdrawal in the morning, and Trina makes her deposit that afternoon. We\nwon’t get into programming here, but let’s consider the steps that the game software will\ntake to carry out these transactions. Let’s start with Skylar’s withdrawal:\n1. Retrieve the balance of the guild account. Call this Skylar’s copy.\n2. Subtract 300 gold from Skylar’s copy.\n3. Add 300 gold to Skylar’s personal stash.\n4. Update the guild bank balance to Skylar’s copy.\nNow suppose Trina makes the deposit in the afternoon. The steps of her transaction\nare:\n1. Retrieve the balance of the guild account. Call this Trina’s copy.\n2. Subtract 200 gold from Trina’s personal stash.\n3. Add 200 gold to Trina’s copy.\n4. Update the guild bank balance to Trina’s copy.\nIn this example everything works fine. But what happens if Skylar and Trina perform\ntheir transactions at the same time? In that case, the final balance of the guild account\ncould be incorrect. This happens if the original guild balance of 10,000 gold is retrieved\nfor calculation by both processes before either of them completes the transaction.\nTake a look at the details shown in Table 8-1. When Trina and Skylar initiate\ntransactions at the same time, the same 10,000 balance is retrieved into their separate\ncopies of the balance. Trina’s copy is increased to 10,200, while Skylar’s copy is\ndecreased to 9,700. Then both of the updated figures overwrite the guild account balance.\nIn the example shown in the table, Skylar’s updated number arrives last, which means\n9,700 is the new account balance and 200 gold has simply vanished.\nIt could have worked out the other way—Trina’s copy could have arrived after\nSkylar’s, increasing the guild’s gold balance, but of course neither result is correct. The\nonly correct final balance is 9,900 gold, the balance that corresponds to the two\ntransactions occurring separately.\nSituations similar to this example are possible whenever two or more processes use the\nsame data simultaneously. The general term for this situation is a race condition, since all\nthe processes involved are racing to complete their task first. In this case the process that\nfinishes last “wins,” because it determines the final value of the data.\nWhile this example features two different processors, Trina’s and Skyler’s, it’s\nimportant to note that race conditions can happen even with a single processor. Because\nmultitasking involves switching the processor to a different program many times a second,\nmultiple processes operating on the same data could interleave, creating a race condition.\nTable 8-1: The Danger of Overlapping Bank Transactions\nSkylar’s Trina’s Guild\nStep Description\nWOW! eBook\nwww.wowebook.org\ncopy copy balance\nTrina\nRetrieve the guild balance from the bank. 10,000 10,000\n1\nSkylar\nRetrieve the guild balance from the bank. 10,000 10,000\n1\nTrina\nSubtract 200 gold from Trina’s stash. 10,000 10,000\n2\nTrina Add 200 gold to Trina’s copy of the guild\n10,200 10,000\n3 balance.\nSkylar Subtract 300 gold from Skylar’s copy of the\n9,700 10,000\n2 guild balance.\nSkylar\nAdd 300 gold to Skylar’s stash. 9,700 10,000\n3\nTrina Send Trina’s copy of the guild balance to the\n10,200 10,200\n4 bank.\nSkylar Send Skylar’s copy of the guild balance to the\n9,700 9,700\n4 bank.\nMaking Concurrency Safe\nIn order to make concurrency useful, then, we need to prevent race conditions. This\nrequires enforcing rules on how processes can access data. The tighter the restrictions, the\neasier it is to prevent problems from occurring, but these restrictions can have an adverse\neffect on performance.\nRead-Only Data\nOne possible restriction is to allow processes to retrieve data simultaneously, but prohibit\nthem from changing it; this is known as read-only data. This eliminates the possibility of a\nrace condition but at an enormous cost. Most applications that require shared data access\nsimply can’t work without the ability to change the data. So this method is rarely\nconsidered. However, as we’ll see later, distinguishing which processes want to change\ndata from those that merely want to read data can improve the performance of\nconcurrency.\nTransaction-Based Processing\nWOW! eBook\nwww.wowebook.org\nAnother straightforward, comprehensive solution eliminates simultaneous data access\nentirely. The race condition occurs in the example because Skylar’s and Trina’s\ntransactions overlap. What if we prevent overlapping transactions? To enforce this rule,\nonce any bank transaction begins, we wait for it to signal its completion before any other\ntransaction may start. For example, the steps in Skylar’s process now might look like this:\n1. Signal Start Transaction to the bank server.\n2. Retrieve the balance of the guild account. Call this Skylar’s copy.\n3. Subtract 300 gold from Skylar’s copy.\n4. Add 300 gold to Skylar’s personal stash.\n5. Update the guild bank balance to Skylar’s copy.\n6. Signal End Transaction to the bank server.\nThe steps in Trina’s process would be likewise bracketed:\n1. Signal Start Transaction to the bank server.\n2. Retrieve the balance of the guild account. Call this Trina’s copy.\n3. Subtract 200 gold from Trina’s personal stash.\n4. Add 200 gold to Trina’s copy.\n5. Update the guild bank balance to Trina’s copy.\n6. Signal End Transaction to the bank server.\nThe bank server process enforces the transaction rules. When no transaction is under\nway, a signal to start a new transaction is immediately accepted. So if Trina’s transaction\nbegan during an idle period, it would continue. If, however, the start transaction signal\nfrom Skylar’s process arrived while Trina’s transaction was being processed, Skylar’s\ntransaction would have to wait until Trina’s transaction finished. And if other transactions\narrived during this time, the bank server would put them in a queue, to process them in the\norder in which they arrived.\nThis rule transforms the guild bank into the equivalent of a lobby with a single teller. If\na customer arrives and the teller is available, the customer gets immediate service;\notherwise, the customer must wait until the teller is free. This prevents race conditions but\nrobs the system of the performance benefit of having multiple processors. Just as having\none teller in a busy bank means a long wait for each customer, allowing only one\ntransaction through the bank server at a time means a relatively long wait for each\ntransaction.\nThe rule is much too strict. At any given time, the bank may be handling a large\nnumber of transactions, and few (if any) of them involve the same accounts. This rule\nprevents race conditions by preventing all overlapping transactions, even when the overlap\nis harmless.\nSemaphores\nWOW! eBook\nwww.wowebook.org\nAnother idea takes advantage of the fact that most of the transactions are not interacting\nwith the same data. If the transaction rule is like a bank with a single teller, a better rule\nwould be like a bank where every account has its own personal teller. Two or more\ncustomers attempting to access the same account at the same time will form a queue, but\ncustomers accessing different accounts won’t slow each other down at all.\nThe secret ingredient behind this technique is a special type of data called a semaphore.\nIn nautical language, semaphores are flags that ships hoist to signal other ships; in\nsoftware, semaphores are the numerical equivalent of flags, signaling whether or not\nlogically connected data is in use. The simplest type of semaphore has just two possible\nvalues, 0 or 1, and is called a binary semaphore.\nHow Semaphores Prevent Race Conditions\nReturning to our guild bank account, we can avoid the race condition by creating\nsemaphores on the bank server for each of the account balances. Each semaphore begins\nwith a value of 1.\nBefore requesting an account balance, a process must first acquire the semaphore\nassociated with that account. This acquire operation will check the value of the\nsemaphore. If the semaphore is 1, it means no other process is using the associated\nbalance; in this case, the semaphore changes to 0, and the process will be allowed to\ncontinue.\nIf the semaphore is already 0, though, it means another process is currently accessing\nthe associated balance. In this case, the software will have to wait.\nWhen a process completes its transaction, it releases the semaphore, which\nimmediately sets its value back to 1. This allows one of the processes waiting for the\nsemaphore to continue.\nUsing semaphores, Skylar’s process would look like this:\n1. Acquire the semaphore for the guild account.\n2. Retrieve the balance of the guild account. Call this Skylar’s copy.\n3. Subtract 300 gold from Skylar’s copy.\n4. Add 300 gold to Skylar’s personal stash.\n5. Update the guild bank balance to Skylar’s copy.\n6. Release the semaphore for the guild account.\nAnd Trina’s:\n1. Acquire the semaphore for the guild account.\n2. Retrieve the balance of the guild account. Call this Trina’s copy.\n3. Subtract 200 gold from Trina’s personal stash.\n4. Add 200 gold to Trina’s copy.\n5. Update the guild bank balance to Trina’s copy.\nWOW! eBook\nwww.wowebook.org\n6. Release the semaphore for the guild account.\nIn this way, Skylar and Trina are prevented from accessing the guild balance at the\nsame time, preventing the race condition. Additionally, neither transaction will affect any\nother transaction that doesn’t deal with this particular account.\nHow Semaphores Are Made\nNow let’s look at how semaphores are actually made. If semaphores aren’t implemented\nwith care, they can produce the very race conditions they are intended to prevent.\nAlthough the acquire operation is just one step for Skylar’s and Trina’s processes, in\nreality, it takes several steps itself:\n1. Retrieve the value of the semaphore.\n2. If the value is 0, go back to step 1 and try again.\n3. Set the semaphore to 0.\nNow consider what happens if both Skylar’s and Trina’s processes attempt to acquire\nthe guild account semaphore at the same time. If the semaphore had a value of 1, both\nprocesses could retrieve this initial value (in step 1) before either had a chance to check\nthe value and set it to 0. In this case, both processes would think that they were the only\nprocess that had acquired the semaphore, and were therefore free to do whatever they\nwanted with the accompanying bank balance. We’re right back where we started.\nTo make a semaphore, then, software needs some help from hardware. The processor\non the bank server must be able to implement the acquire and release operations in such a\nway that nothing can interrupt them. This is known as making the operations atomic,\nwhich in this sense means indivisible.\nModern processors implement a hardware operation known as test-andset. This sets a\nbyte in main memory to a particular value, while retrieving the previous value for\ninspection. Test-and-set makes semaphores possible. In the list of semaphore steps, the\nproblem is the potential interruption between steps 1 and 3. If two different processes\nexecute the first step before either reaches the third step, both will be able to alter the data\nthat the semaphore is supposed to protect. Using the atomic test-and-set operation, though,\na semaphore acquire operation can be implemented like this:\n1. Using test-and-set, set the semaphore to 0 and retrieve the old value.\n2. If the old value was 0, go back to step 1 and try again.\nNow the race condition cannot happen. If two processes attempt to acquire the same\nsemaphore at the same time, they will each execute the test-and-set in step 1. Both\noperations will set the semaphore value to 0, but only the semaphore that tests-and-sets\nfirst will retrieve a 1. The other process will retrieve a 0. One process will immediately\ncontinue, while the other will have to wait.\nThe Problem of Indefinite Waits\nA process acquiring a semaphore using this two-step plan—continuously checking the\nWOW! eBook\nwww.wowebook.org\nsemaphore’s value until it changes back to 1—is said to be in a spin lock. This is the\nsimplest way to wait for a semaphore to become available, but it has two major problems.\nFirst, it wastes processor time. A process in a spin lock is continuously executing code, but\nthe code isn’t doing anything useful. Secondly, spin locks can be unfair. In some cases,\nsome processes cannot check the semaphore as fast as others. Perhaps the process is\nexecuting on a slower processor, or perhaps the process is communicating with a server\nacross a slower network. Regardless of the reason, if a semaphore’s resource is so popular\nthat multiple processes are always waiting, a slower-checking process might never be able\nto snag the semaphore. This is known as starvation; picture the least-assertive person at a\nbusy restaurant with only one waiter, and you’ll get the idea.\nOrderly Queues\nAvoiding starvation requires a more organized approach to waiting. Banks organize the\nwait in their lobbies with cordons, forming groups of waiting customers into orderly\nqueues. Semaphores can be designed to do the same thing. Rather than waste time\ncontinually checking the value of the semaphore, many acquire operations written so that\nwhen they do not succeed immediately, they put their process to sleep, so to speak. Putting\na computer or phone to sleep means suspending all running applications in a way that\nallows the applications to be restored quickly. In the same way, if a process cannot\nimmediately acquire a semaphore, it will be suspended and flushed out of the processor,\nbut its internal data will remain in storage.\nTo accomplish this, the computer’s operating system assigns each process a unique\nidentification number. When an acquire operation has to wait, the process identifier is\nplaced at the end of that semaphore’s wait list. When the process currently holding that\nsemaphore releases it, the first process on the list is awakened. In this way, processes\nacquire the semaphore in the same order they request it. A process may have to wait to\nacquire a popular semaphore, but will eventually get to the top of the list— it won’t starve.\nStarvation from Circular Waits\nAlthough semaphores prevent race conditions when implemented and used correctly, they\ncan cause starvation when processes need to access multiple pieces of data that are\nprotected by semaphores.\nSuppose Skylar and Trina’s guild opens a second account that is accessible to lower-\nranked guild officers, so now the guild has a main account and a secondary account. The\nbanking system has implemented semaphores for each individual account, eliminating the\nchance of a race condition on any guild transactions.\nBut on a particular day, Skylar and Trina are each transferring 200 gold from one\naccount to the other in opposite directions. Both transactions involve debiting one account\nand crediting the other. Skylar’s transaction would have these steps:\n1. Acquire the semaphore of the main account balance.\n2. Retrieve the balance of the main account.\nWOW! eBook\nwww.wowebook.org\n3. Acquire the semaphore of the secondary account balance.\n4. Retrieve the balance of the secondary account.\n5. Add 200 gold to the secondary account balance.\n6. Subtract 200 gold from the main account balance.\n7. Update the secondary account balance.\n8. Update the main account balance.\n9. Release the semaphore of the secondary account.\n10. Release the semaphore of the main account.\nTrina’s transaction would run like this:\n1. Acquire the semaphore of the secondary account balance.\n2. Retrieve the balance of the secondary account.\n3. Acquire the semaphore of the main account balance.\n4. Retrieve the balance of the main account balance.\n5. Add 200 gold to the main account balance.\n6. Subtract 200 gold from the secondary account balance.\n7. Update the main account balance.\n8. Update the secondary account balance.\n9. Release the semaphore of the main account.\n10. Release the semaphore of the secondary account.\nBecause all shared value access is properly bracketed by the acquisition and release of\nassociated semaphores, no race conditions can occur from the overlapping execution of\nthese transactions. However, suppose both transactions begin around the same time and\nthe first few steps interleave as shown in Table 8-2.\nTable 8-2: Multiple Semaphores Leading to Indefinite Waiting\nMain account Secondary account\nStep Description\nsemaphore semaphore\nInitial state. 1 1\nSkylar Acquire the semaphore of the main\n0 1\n1 account balance.\nSkylar Retrieve the balance of the main\n0 1\n2 account.\nTrina Acquire the semaphore of the secondary 0 0\nWOW! eBook\nwww.wowebook.org\n1 account balance.\nTrina Retrieve the balance of the secondary\n0 0\n2 account.\nSkylar Acquire the semaphore of the secondary\n0 0\n3 account balance.\nTrina Acquire the semaphore of the main\n0 0\n3 account balance.\nI’ve shown only these steps because these are the only steps that would occur. Both\nSkylar’s and Trina’s processes would halt at step 3, because both are trying to acquire\nsemaphores that aren’t available. What’s worse is that they can never become available,\nbecause each is being held by the other process. This is like waiting for traffic to clear so\nyou can turn left on a two-lane road, but someone going the other way wants to turn left\nbehind you, as shown in Figure 8-3.\nFigure 8-3: If both white cars are waiting to turn left, traffic is stopped.\nBecause neither process in this example can continue until the other process completes,\nthis situation is known as a circular wait. In this case, the circular wait involves only two\nprocesses, but circular waits sometimes involve many processes, and is therefore difficult\nto detect or foresee. A circular wait is one form of deadlock, which describes a situation in\nwhich a process cannot be expected to continue. Circular waits are one way that\nconcurrency can cause deadlocks, and unless precautions are taken, a circular wait can\noccur whenever processes hold multiple semaphores at once. Fortunately, such\nprecautions can be easy to implement.\nOne solution is a rule by which semaphores must be acquired in some specified order.\nIn our example, the game’s bank management system can internally assign each account a\nnumber, and require processes to acquire account semaphores in numerical order. Or, put\nmore broadly, a process can acquire an account’s semaphore only when it does not\ncurrently hold a semaphore for an account with a higher number. This rule prevents the\ncircular wait in the previous example. Let’s suppose the main account is 39785 and the\nsecondary account is 87685. Because the main account number is lower, both Skylar’s and\nTrina’s processes would attempt to acquire its semaphore first. If both processes tried at\nthe same time, only one process would succeed. That process would then acquire the\nsemaphore for the secondary account and complete the transaction, at which point both\naccount semaphores would be released, allowing the other process to continue through\ncompletion.\nWOW! eBook\nwww.wowebook.org\nPerformance Issues of Semaphores\nWith the proper rules in place, semaphores enable concurrency without fear of race\nconditions, deadlock, or starvation. However, in situations where we are trying to boost\nperformance by having multiple processors work together on the same job, enforcing these\nsemaphore rules can limit the performance benefit we hoped to create. Instead of lots of\nprocessors working together, we are left instead with lots of processors waiting in line for\nan opportunity to work. Concurrent software can mitigate these performance issues by\ncreating additional rules.\nSometimes a process needs access to a piece of data but doesn’t need to change it. In\nour running guild bank example, suppose Skylar and Trina are both inspecting the main\nguild account at the same time—that is, neither player is depositing or withdrawing, but is\nmerely checking the balance. In this case, no danger arises from the simultaneous access\nof the account. Even though the processes would have potentially overlapping retrieval\noperations, as long as neither one of them updated the balance, everything would be fine.\nAllowing simultaneous access during “read-only” situations greatly improves\nmultiprocessor performance, and requires only a modification of the semaphore concept.\nInstead of having one semaphore for each piece of data to be shared, we’ll have two: a\nread semaphore and a write semaphore, subject to the following rules:\n• Acquiring the associated write semaphore allows data to be retrieved or updated, just\nlike how the semaphores worked in previous examples.\n• Acquiring the associated read semaphore allows data to be retrieved, but not updated.\n• A write semaphore can be acquired only when no process holds a semaphore (of either\ntype) for that data.\n• A read semaphore can be acquired only when no process holds a write semaphore for\nthat data.\nFollowing these rules means that at any given time, either one process will have\nacquired the write semaphore for a piece of data or one or more processes will have\nacquired read semaphores for that data. At first, this appears to be what we want. So long\nas processes are merely looking at, but not changing data, they can share access. Once a\nprocess needs to change the data, all other processes are locked out until the updating\nprocess completes its work.\nUnfortunately, these rules potentially reintroduce the starvation problem. As long as\nread-only processes keep arriving, a process that needs a write semaphore might wait\nindefinitely. To prevent this from happening, we can modify the last rule as follows: “a\nread semaphore can be acquired only when no process is holding or waiting for a write\nsemaphore.” In other words, once a process attempts to acquire a write semaphore, all\nprocesses arriving later must wait behind it.\nAnother potential concern for performance is known as granularity, which in this\ncontext refers to whether we lock up individual pieces or collections of data. For example,\nthe bank system could use semaphores to protect individual data elements, such as the\nbalance of the main guild account, or it could apply a single read/write pair for all data\nWOW! eBook\nwww.wowebook.org\nrelated to a particular guild’s finances, such as the balances of all guild accounts, the list of\nguild officers who are allowed to access that account, and so on.\nProtecting data as a group can cause more waiting, because a process that may need\nonly one or two numbers in a data group will have to lock up all the data in the group,\npotentially blocking another process that needs other, nonoverlapping data from the group.\nVery fine granularity can also hinder performance. Acquiring and releasing semaphores\ntakes time, and with lots of semaphores, it’s possible for processes to spend most of their\ntime dealing with them. Developers must therefore carefully determine the best\ngranularity for a particular application.\nWhat’s Next for Concurrency\nFor several reasons, we can expect concurrency to be an even greater concern for the\nfuture.\nThese days, multiple processing cores can be found even in our simplest computing\ndevices. The push for more processing power will continue, and until the arrival of a new\nprocessing paradigm like quantum computing, more processing power will mean more\nprocessor cores.\nMultitasking is now the norm. We expect our computing devices to run multiple\napplications at the same time, and to interrupt our foreground tasks when something\ninteresting happens in the background.\nData and devices are becoming more connected than ever. Data and processing are\nincreasingly being moved from client devices onto servers or clouds of interconnected\nservers. In computer gaming, socialization is the new paradigm, and in some games, even\nsingle-player game modes require an Internet connection.\nIn short, properly handling concurrency is becoming essential in everyday computing.\nWhat looks like a single computer running a single-user application may contain a\nmultiprocessor that provides a multitasking environment with shared cloud storage for\ndata. The vital power of concurrency is thus often invisible. As the trend toward even\ngreater concurrency continues, we may take for granted the way in which so many\nprocesses work together without running into one another. But future improvements in\ncomputing depend upon further advancements in concurrency control. We don’t know yet\nwhether current methods of preventing deadlock, starvation, and race conditions will be\nsufficient as concurrency increases. If current methods are inadequate for solving future\nchallenges, they will become the bottleneck until better methods are developed.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What is best-first search and how does it help in finding the fastest route from A to I on a directed graph?",
    "summary": "Modern navigation software, like Google Maps, can find the shortest or fastest path to a destination by using data tables instead of actual maps. It represents the map as a directed graph, where intersections are points and streets are edges with associated costs. Best-first search is a method used to find the lowest-cost path from a starting point to a destination by always selecting the best available route at each step. This method not only finds the fastest route to the destination but also provides the best routes to intermediate points, which can be reused in future searches.",
    "output": "9\nMap Routes\nBecause we can instantly get directions using sites like Google Maps, we forget that not\nlong ago people often got lost driving to unfamiliar destinations. Now software plans our\nroute for us and even alters the route mid-trip if an accident or road closure blocks our\nway.\nIn computing, this task is called finding the shortest path. Despite the name, the goal\nisn’t always to find the shortest path, but more generally to minimize the cost, where the\ndefinition of cost varies. If the cost is time, the software finds the fastest route. If the cost\nis distance, the software minimizes the mileage, truly finding the shortest path. By\nchanging how cost is defined, the same software methods can find routes to match\ndifferent goals.\nWhat a Map Looks Like to Software\nAlthough software can provide directions, it can’t actually read a map. Instead, it uses\ntables of data. To see how we get from a map to a table of data, let’s begin with Figure 9-\n1, which shows a portion of a city map for a simple routing problem. The goal is to find\nthe quickest route from the corner of 3rd Street and West Avenue to the corner of 1st\nStreet and Morris Avenue. The numbered arrows alongside the streets show the average\ndriving time in seconds between intersections. Note that 1st Street and Morris Avenue are\none-way streets.\nWOW! eBook\nwww.wowebook.org\nFigure 9-1: A simple routing problem: find the fastest route from 3rd and West to 1st and\nMorris.\nTo produce a data table that can be processed by software, we first reconceptualize the\nmap as the directed graph shown in Figure 9-2. Here, the street intersections are\nrepresented as points labeled A through I. The arrows in Figure 9-1 become connections\nbetween points on the graph, known as edges.\nWOW! eBook\nwww.wowebook.org\nFigure 9-2: The map from Figure 9-1 as a directed graph\nUsing the directed graph, we put the data into the tabular form shown in Table 9-1.\nThis table contains all of the information from the map in Figure 9-2 that software needs\nto find the fastest route. In Figure 9-2, for example, travel time from A to B is 23 seconds;\nthe same information is provided by the first row of the table. Note that travel in\nimpossible directions, such as from H to G, is not listed.\nTable 9-1: The Data from the Directed Graph of Figure 9-2 in Tabular Form\nFrom To Time\nA B 23\nA D 19\nB A 15\nB C 7\nWOW! eBook\nwww.wowebook.org\nB E 11\nC B 9\nD A 14\nD E 17\nD G 18\nE B 18\nE D 9\nE F 33\nE H 21\nF C 12\nF E 26\nG D 35\nG H 25\nH E 35\nH I 28\nI F 14\nBest-First Search\nNow we’re ready to find the quickest route on the map, which means finding the lowest-\ncost path from A to I on our graph. Many methods exist for solving this problem; the\nvariation I’ll describe is a type of algorithm called a best-first search. Calling this\nalgorithm a “search” may be a little misleading, because this method doesn’t aim for the\ndestination. Instead, at each step it finds the best new route from the starting point to any\npoint it hasn’t already routed to. Eventually, this procedure stumbles upon a route to the\ndestination, which will be the cheapest route possible from the start to the goal.\nHere’s how best-first search works for our example. All routes starting at A must first\ntravel to either B or D. The algorithm starts by comparing these two choices, as shown in\nFigure 9-3.\nWOW! eBook\nwww.wowebook.org\nFigure 9-3: The first step in our best-first search. Starting from A, we can travel either to\nB or D.\nIn these figures, black circles mark the points we’ve found the best paths to, while gray\ncircles indicate points we can reach directly from one of the marked (black) points. The\nnumbers inside the circles represent the cost of the route to that point. In each step, the\nsearch examines all edges extending from marked to unmarked points to find the edge that\nproduces the lowest-cost route. In this first step, the choice is between the A-to-B edge\nand the A-to-D edge. Because the travel time to D is less than the travel time to B, the\nlowest-cost route is from A to D, as shown in Figure 9-4.\nWe’ve just found the cheapest possible route from A to D. No matter what the rest of\nthe graph looks like, it can’t contain a lower-cost route from A to D, because this is the\nlowest-cost route of all routes starting from A. In the same way, each step will produce a\nnew route that will be the lowest-cost route possible from A to some other point.\nIn the second step, there are four edges to consider: the A-to-B edge and the three\nedges extending from D. Again, the algorithm will choose the edge that creates the fastest\nnew route. In considering the edges extending from D, we have to include the 19 seconds\nfrom A to D. For example, the time required to travel from A to E through D is the sum of\nthe A-to-D edge time (19) and the D-to-E edge time (17), which is 36 seconds.\nNote that one edge from D leads back to A. In Figure 9-4, the circle at the end of that\nedge is white to indicate that it will never be chosen. There’s no benefit in taking a round\ntrip back to our starting point. More generally, once a point has been included in a route\n(marked black in the figures), later appearances of that point are ignored, because a better\nroute to it has already been found.\nAt this stage, the lowest-cost new route is made using the A-to-B edge. This brings us\nto the stage shown in Figure 9-5. Again, because we’ve found the lowest-cost route of all\nremaining routes, that makes this A-to-B route the fastest possible way to get from A to B.\nWOW! eBook\nwww.wowebook.org\nFigure 9-4: In the second step of our search, the best new route leads to D. Marking D\nexposes three new routing possibilities, one of which leads back to our starting point.\nFigure 9-5: The third step in our best-first search finds the best route to point B.\nWe have six edges to consider next, although the edges leading back to A aren’t\ncontenders. The best choice uses the B-to-C edge to make an A-to-C route of 30 seconds,\nas shown in Figure 9-6.\nWOW! eBook\nwww.wowebook.org\nFigure 9-6: The fourth step in our search finds the best route to point C.\nFinding the fastest route to C doesn’t help us reach our ultimate goal, though. From C,\nwe can only return to B, to which we already know the fastest route.\nAt this stage, the fastest new route is the one going through B to E, as shown in Figure\n9-7.\nFigure 9-7: The fifth step in our best-first search finds the best route to E.\nThis process continues until we have reached the state shown in Figure 9-8. At this\nstage, the lowest-cost new route uses the edge from H to I, which means we’ve finally\nWOW! eBook\nwww.wowebook.org\nidentified the best route from A to I.\nFigure 9-8: The ninth and final step in our best-first search reaches point I.\nAs shown, the fastest route from A to I is A-B-E-H-I. Looking at our original map in\nFigure 9-1 and its graph equivalent in Figure 9-2, we can see that this corresponds to\ntaking 3rd Street to Kentucky Avenue, taking a left on 1st Street, and driving one block to\nour destination.\nReusing Prior Search Results\nIn this example, the best-first search found not only the fastest route from A to I, but also\nthe fastest route to every other point on the map. Although this is an unusual result, the\nbest-first process typically produces a surplus of information. At a minimum, the search\nresults will also provide the best routes between intermediate points that lie along the\nroute between the start and destination points. In our example, the best route from A to I\ncontains the best routes from B to H, and from E to I, and so on. For this reason, the\nresults of best-first searches can be stored for later use.\nWe can even use this data in searches involving points that weren’t part of the original\nmap data. To see why, consider Figure 9-9. This is the same directed graph in Figure 9-2\nexcept that it includes a new point, J, that has edges to A and B.\nWOW! eBook\nwww.wowebook.org\nFigure 9-9: The directed graph from Figure 9-2 with an additional point, J\nSuppose we need to find the fastest route from J to I. Any route from J begins by going\nto either A or B. We already know the fastest routes from A and B to I from the results in\nFigure 9-8. The fastest route from A to I takes 83 seconds. The fastest route from B to I\ntakes 60 seconds; we find this by subtracting the A-to-B edge time of 23 seconds from the\ntotal A-to-I time of 83 seconds.\nThis means that the J-to-I route that starts by heading to A takes 102 seconds—19\nseconds to reach A, and 83 seconds to follow the best route from A to I. The route that\nheads directly to B takes 96 seconds: 36 seconds to reach B, and 60 seconds from there to\nreach I. Using the previous search results makes finding the fastest J-to-I route much\nsimpler.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "How does Floyd’s algorithm work to find the fastest route between any two points on a map?",
    "summary": "Floyd’s algorithm is used to find the shortest paths between all pairs of points on a map. It starts with direct connections and iteratively improves routes by connecting them through intermediate points. The algorithm updates the grid with the best route times, and when a better route is found, it replaces the existing one. Additionally, the algorithm can track the direction of the fastest routes, allowing routing software to determine the actual path taken.",
    "output": "Finding All the Best Routes at Once\nIn general, then, storing past search results benefits future searches. This idea can be\nextended to efficiently find the best routes between any two points on a given map, which\nis known as the all-pairs shortest paths problem.\nFloyd’s Algorithm\nWe’ll solve the all-pairs shortest paths problem using Floyd’s algorithm (sometimes called\nthe Floyd-Warshall algorithm), which starts with simple routes of individual edges, then\nbuilds longer routes by connecting the existing routes using each point on the map in turn.\nThis method uses a grid, the initial state of which is shown in Figure 9-10. At each step in\nthe process, the grid contains the costs of the best routes between every pair of points. At\nthe start, the only known routes are the edges that directly connect points, the same data\nfrom Figure 9-2 and Table 9-1. For example, the 23 in row A, column B, represents the\ncost of travel from A to B. The cost is 0 where the “from” and “to” points are the same.\nFigure 9-10: The initial grid of numbers for Floyd’s algorithm. At this stage the only\nroutes in the grid are the direct connections between points.\nAs the process continues, this grid will be filled in and modified. New routes will be\nadded where none initially exist, such as from A to F. Routes with lower costs will replace\nexisting routes; if we can find a way to get from G to D in less than 35 seconds, for\nexample, we’ll replace the 35 currently in the grid.\nWe start by considering point A as a route connector. From Figure 9-10, we can see\nWOW! eBook\nwww.wowebook.org\nthat B and D have routes to A. Because A has routes back to B and D, A can connect B to\nD and D to B. These new routes are shown as gray squares in Figure 9-11.\nFigure 9-11: Discovering new routes using point A as a connector\nThe cost of new routes is the sum of the costs of the two routes we are connecting. In\nFigure 9-11, the cost of the B-to-D route (34) is the cost of the B-to-A route (15) plus the\ncost of the A-to-D route (19), as indicated by the arrows. The cost of the D-to-B route (37)\nis computed the same way, as the sum of the D-to-A route (14) and the A-to-B route (23).\nIn the next step, we use point B to connect existing routes. This produces a whopping\neight new routes, as shown in Figure 9-12.\nWOW! eBook\nwww.wowebook.org\nFigure 9-12: Discovering new routes using point B as a connector\nAs with the previous step, the cost of each new route is the sum of the costs of the two\nroutes we are connecting. For example, the cost of the new A-to-E route (34) is the sum of\nthe A-to-B cost (23) and the B-to-E cost (11).\nIn the next step, using C to connect existing routes reveals three new routes, as shown\nin Figure 9-13.\nWOW! eBook\nwww.wowebook.org\nFigure 9-13: Discovering new routes using point C as a connector\nIn the next step, we have our first instance of a better route. Previously we found a 33-\nsecond route from E to A. In this step, we discover a 23-second route from E to A through\nD, and update the grid with the lower cost. Nine new routes are also found, bringing us to\nthe state shown in Figure 9-14.\nWOW! eBook\nwww.wowebook.org\nFigure 9-14: Discovering new routes using point D as a connector\nThis process continues, using the points E through I to connect routes in turn, resulting\nin the complete grid shown in Figure 9-15. By relating the points back to the street names\non the original map, routing software can use this grid to provide the fastest time between\nany two locations on the map. If you want to know how many seconds it should take to get\nfrom the corner of 1st and West to the corner of 3rd and Morris, the software will translate\nthis into a query about the G-to-C route on the graph. Then the answer can be found right\nthere in the grid: 77 seconds.\nWOW! eBook\nwww.wowebook.org\nFigure 9-15: The complete grid produced by Floyd’s algorithm, showing the fastest time\npossible from each point to every other point\nStoring Route Directions\nWhat this grid doesn’t tell you, as you may have noticed, is what that fastest route is—\nonly how much time it takes. For example, you can see that the fastest route from A to I\ntakes 83 seconds, but does that route begin by going east or south, and where do you make\nthe first turn? In order to record the route itself, we must record the initial direction of the\nroutes when updating route times in the grid.\nFigure 9-16 shows the starting grid. As before, the grid will be used to store the costs\nof the best routes found so far, but now it will also store the initial direction of travel for\neach route. This starting grid contains just the edges of the original graph. The 23 and B in\nthe second column of the first row means the best route from A to B costs 23 and starts by\nheading toward B.\nWOW! eBook\nwww.wowebook.org\nFigure 9-16: The initial grid for Floyd’s algorithm, amended to store the direction of\ntravel for each route\nIn Figure 9-17, we use A to connect existing routes, as we did in Figure 9-11. But now,\nadding or updating a route in the grid means recording the direction as well. The new\nroute from B to D, for example, begins by going to A. The logic is: “We’ve just\ndiscovered a route from B to D that goes through A. The fastest known route from B to A\nheads directly to A. Therefore, the route from B to D must also start by going to A.”\nWOW! eBook\nwww.wowebook.org\nFigure 9-17: Discovering new routes using point A as a connector\nSkipping over the steps for B and C, Figure 9-18 shows the grid just after we’ve added\nthe routes for D. Here we’ve found a new route from B to G that takes 52 seconds.\nBecause this new route goes through D, the route must begin the same way the route to D\nbegins—by traveling to A.\nWOW! eBook\nwww.wowebook.org\nFigure 9-18: Discovering new routes using point D as a connector\nFigure 9-19 shows the completed grid, with the times removed for clarity.\nFigure 9-19: The complete routing grid produced by Floyd’s algorithm, showing the\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What are some potential improvements and additional features that future mapping software might offer beyond just providing the fastest route from one location to another?",
    "summary": "The text explains how mapping software determines the fastest route by analyzing a grid, starting at point A and moving to I through the most efficient path. It also discusses future improvements in routing software, such as using real-time traffic and weather data to provide better navigation. Additionally, it highlights that routing is part of a broader field called GIS, which can be used for various location-based tasks beyond just finding directions.",
    "output": "direction of travel. The fastest route from A to I is highlighted.\nThe fastest route from A to I is highlighted in the grid. We start at row A, column I, and\nsee the fastest route from A to I starts by going to B. So then we look at row B and see the\nfastest route from B to I heads to E. The route from E heads to H, and the route from H\nreaches I. Using this grid is like stopping at every street corner and asking, “Which way\nshould I turn?”\nThe Future of Routing\nToday’s software can provide accurate directions in an instant, so what can tomorrow’s\nmapping software possibly do better?\nImprovements in mapping will come from improvements in data. For example, if the\nsoftware has access to hourly traffic data, it can tailor directions to the time of the trip.\nReal-time traffic data may also be integrated into mapping software. For example, most\nmapping programs don’t know about traffic issues until the user requests a new route. In\nthe future, your mapping software may find out about accidents and road closures before\nyou do and route you around the problems. Weather data may also be included to provide\nmore accurate estimates of travel time, and to accommodate the preferences of drivers\nwho wish to avoid driving in heavy rain or other troubling conditions.\nRouting is just a small part of a larger area of software called geographic information\nsystems (GIS), which uses software to answer questions about maps and location-tagged\ndata. Some GIS tasks have nothing to do with routing, such as determining if an area\ncontains enough potential customers to support a new grocery store. But many interesting\nGIS projects combine the map routing concepts from this chapter with data about what’s\ninside buildings along a map’s roadways. By tracking where schoolchildren live, for\nexample, GIS software can plan the most efficient routes for school buses.\nIn the future, routing software may expand to encompass more of the abilities of\ngeneral GIS tools. When you need a route for a long drive out of town, the software may\nnot provide just the turns you need to take, but also highlight places where you might want\nto stop, like the best-priced gas stations and the restaurants that serve your favorite food.\nWOW! eBook\nwww.wowebook.org"
  },
  {
    "input": "What is the key concept discussed in the text that relates to encryption methods, their security, and how they are used in conjunction with other techniques like RSA?",
    "summary": "The text covers topics in computer graphics, encryption, and algorithms. It discusses 2D and 3D graphics, including rendering techniques like rasterization and ray tracing. It also explains encryption methods such as AES and RSA, focusing on key management, security, and performance. Additionally, it touches on compression algorithms, including lossless and lossy methods, and data structures like hash tables and semaphores for concurrency control.",
    "output": "Index\nNumbers\n2001: A Space Odyssey, 142\n2D graphics, 61–69\n3D graphics, 69. See also rendering\nA\nacquire operation, 168, 170\nadder circuit, 164\nadditive color mixing, 60\nAES (Advanced Encryption Standard), 9–18, 55\nblock chaining, 15, 55\ncombining with RSA, 48–49\ndata organization under, 11\nkey expansion, 13–14\noverview, 12\nperformance vs. RSA, 48\npossible weaknesses, 17–18\nS-box, 13, 14\nsecurity of, 16\naliasing, 66, 80, 99\nall-pairs shortest path, 183. See also Floyd’s algorithm\nalpha blending, 67–68, 82\nalpha channel, 68, 78, 82\nalpha level, 67\nambient lighting, 96–97\nambient occlusion, 96\nAmerican Standard Code for Information Interchange (ASCII), 12, 20–22, 119–120\nAND (bitwise operation), 23, 25\nangle of incidence, 74, 75\nangle of reflectance, 74\nWOW! eBook\nwww.wowebook.org\nanimation\ncel, 59\nink and paint, 59, 65\ninterpolation, 63\nanti-aliasing, 66–67\nalpha blending, 67–68\nfull-screen, 80\nFXAA, 111\nmultisampling, 111\npost-process, 111\nreal-time, 108–113\nsupersampling, 109\nASCII (American Standard Code for Information Interchange), 12, 20–22, 119–120\natomic operation, 169\nattacks, 2\nbrute-force, 5, 16, 20, 47\ncollision, 26\ndictionary, 28\nfrequency analysis, 6, 9, 15, 17\nknown-plaintext, 6\nman-in-the-middle, 52, 56\nrelated-key, 17\ntiming, 17\nauthentication, 19, 26, 34. See also RSA\nauthority, 51, 53\navalanche, 17, 21\nAvatar, 69\naxis, 61\nB\nbest-first search, 178–181\nmarked points, 178, 179, 180\nWOW! eBook\nwww.wowebook.org\nreusing results, 181–182\nsurplus information, 181\nB-frame, 139\nbidirectional frame, 139\nbilinear filtering, 101\nin FXAA, 112\nbinary, 10\nASCII, 12\nbit, 10\nbyte, 10\nsearch, 151\nbinary addition, 22\nbinary search, 151–152, 153\nbinary semaphore, 168\nbit, 10\nbitmap, 61, 116\nalpha channel, 68, 78, 82\ncoordinate, 61\ndepth buffer, 91, 95, 96\ndisplay buffer, 61\nheight map, 106\nmipmap, 102\norigin, 61\nresolution, 61\nshadow map, 95\ntexture, 97\ntranslucency, 68, 78\nbitwise operations, 11\nAND, 23, 25\nbinary addition, 22\nNOT, 23, 25\nOR, 23, 25\nWOW! eBook\nwww.wowebook.org\nrotation, 14\nXOR, 11, 14, 15\nbitwise rotation, 14\nBlair Witch Project, The, 142\nblock chaining, 15\nblue difference (Cb), 124\nBlu-ray, 116, 143\nbrute force attack, 5, 16, 20, 47\nbuffer, shared, 163\nbuffering, 143\nbump mapping, 106, 107\nbyte, 10\nC\nCb (blue difference), 124\ncel animation, 59\ncentral processing unit. See CPU (central processing unit)\ncertificate, 53\nCGI (computer-generated imagery), 57–59, 82–83. See also 3D graphics; rendering\nchain merging, 31\ncipher key. See key (encryption)\nciphertext, 2, 3, 8\ncircular wait, 172\nclear reflection, 103\nclient, 52\nCloverfield, 142\ncode book, 9\ncoefficient, 126\ncollision, 20, 26\ncollision attack, 26\ncolor\nadditive, 60\nWOW! eBook\nwww.wowebook.org\nRGB, 60, 116, 124\nsubtractive, 60, 76\nYCbCr, 124\ncomposite number, 40\ncompression, 116\ndeflate, 122\ndictionary, 118–122\nHuffman encoding, 120, 134\nof JPEG pixel blocks, 132\nlossless, 116\nlossy, 116, 124\nMPEG-2, 138\npredictive encoding, 122\nquantization, 123, 132\nrun-length encoding, 117, 123, 133, 142\nsliding window, 122\ntemporal, 138\nTGA file format, 117\n.zip file format, 122\ncompression ratio, 118\ndictionary compression, 120\nJPEG, 135\nMPEG-4, 143\nTGA, 118\n.zip file, 122\ncomputer security. See security\ncomputer vision, 160\ncomputer-generated imagery (CGI), 57–59, 82–83. See also 3D graphics; rendering\nconcurrency, 161\natomic operation, 169\ndeadlock, 172\nmultitasking, 162–163, 174\nWOW! eBook\nwww.wowebook.org\nmultiuser environments, 162\nperformance, 162\nprint spooling, 162\nproblems of, 163–166\nrace condition, 165–169\nread-only data, 166, 173\nsemaphore, 168–174\nshared buffer, 163\nstarvation, 170, 172, 173\ntransaction, 166–167\ncontrol point, 62\ncoordinates, 61\naxis, 61\ncontrol point, 62\nconversion, 61, 71, 88, 96\ninterpolation, 63\nlocal, 62\nmodel, 62\norigin, 61\nprojection, 71\nscaling, 64\nscreen, 61, 88, 96\ntranslation, 64\nworld, 70, 88\nx, 61\ny, 61\nz, 69\ncoprime number, 40\ncore, 86, 162, 174\ncost, 175, 178, 183, 184\ncomputing route cost, 179, 182\ndefining per problem, 175\nWOW! eBook\nwww.wowebook.org\nCPU (central processing unit), 86\nadder, 164\ncore, 86, 162, 174\nperformance characteristics, 86\ntest-and-set, 169\nupdating data, 163, 165\nCr (red difference), 124\ncrack, 17\ncrib, 6, 9, 16\ncut scene, 86\nD\ndata collection, 146\ndynamic, 154\nhash table, 154\nstatic, 154\ndata compression. See compression\nDCT (discrete cosine transform), 125–131, 141\ndeadlock, 172\ndeblocking filter, 143\ndecimal, 10\ndecryption, 2\ndeep web, 157\ndeflate, 122\ndepth buffer, 91, 95, 96\ndepth buffering, 91–92\ndictionary, 28\ndictionary attack, 28\ndictionary compression, 118–122\ndiffuse reflection, 74, 77, 92, 93, 107\ndiffusion, 16\ndigital composition, 82\nWOW! eBook\nwww.wowebook.org\ndigital image, 59\ndigital signature, 25–26, 53\nvalidation, 53\nweaknesses, 26\ndirect lighting, 76\ndirected graph, 176\ncoverting to table, 176\nedge, 176\npoint, 176\ndiscrete cosine transform (DCT), 125–131, 141\ndisplay buffer, 61\ndissolve, 82\ndistance effect, 72–73, 92\ndistant impostor, 106, 108\ndynamic data collection, 154\nE\nedge, 176\nencryption, 2\navalanche, 17\ncrack, 17\ndiffusion, 16\nkey. See key (encryption)\none-time pad, 9\npublic-key, 38\nRSA. See RSA\nshared key problem, 18, 37\nsubstitution, 6\nsymmetric key, 18\ntransposition, 2\nenvironment mapping, 103–105\nexclusive-or. See XOR\nWOW! eBook\nwww.wowebook.org\nF\nfactor, 40, 41\nfast approximate anti-aliasing (FXAA), 111\nfield of view, 89\nfinding the shortest path, 175\nfixed-size storage, 152, 153\nFloyd’s algorithm, 183–189\nconnecting routes, 183, 187\ngrid, 183, 186\nimproving routes, 185\nroute directions, 186–189\nfocus, 79\nfps (frames per second), 59, 116, 144\nframe, 59, 116\nbuffering, 143\nmacroblock, 139\nframe rate, 59\nframes per second (fps), 59, 116, 144\nfrequency analysis, 6, 9, 15, 17\nfull-screen anti-aliasing, 80\nfunctions, 39\nhash, 20–21\ninvertible, 39–42\none-way, 39, 42\nsquare, 39\nsquare root, 39\ntrapdoor, 40\nFXAA (fast approximate anti-aliasing), 111\nG\ngeographic information systems (GIS), 189\nglobal illumination model, 76\nWOW! eBook\nwww.wowebook.org\nGPU (graphics processing unit), 87, 90\ngranularity, 173\ngraph, directed. See directed graph\ngraphics accelerator, 86\ngraphics processing unit (GPU), 87, 90\ngroup of pictures, 138\nH\nH.264 standard, 143\nhandshaking, 52–54\nhash chaining, 29–31\nchain merging, 31\nreduction function, 29, 31\nhash table, 29, 31\nhashing, 20–23, 154–156\navalanche, 17, 21\ncollision, 20, 26\ndesirable properties, 20–21\ndigital signature. See digital signature\nencoded password, 21\nirreversibility, 20, 25\niterative, 32–33\nkeyed, 55\nMAC, 55\nMD5. See MD5\nreduction function, 29, 31\nrehashing, 156\nsalt, 34, 35\nslot, 154\ntombstone, 156\nheight map, 106\nHTTPS, 52–56\nWOW! eBook\nwww.wowebook.org\nauthority, 53\ncertificate, 53\nhandshaking, 52–54\nissuer, 53\nMAC, 55\nmaster secret, 54\npremaster secret, 53\nsecurity of, 55–56\nsession, 52\ntransmission, 54–56\nHuffman encoding, 120, 142\ncode creation, 120\nin JPEG, 134\nI\nIDCT (inverse discrete cosine transform), 127\nI-frame, 138, 139\nimages\ndigital, 51–60\nsearching for, 160\ninbound link, 158\nindexing, 152–154\nindirect lighting, 76\nink and paint, 59, 65\ninterpolation, 63\nintracoded frame, 138\ninverse discrete cosine transform (IDCT), 127\nissuer, 53\niterative hashing, 32–33\nJ\njaggies, 66, 80, 89, 109, 112\nJoint Photography Experts Group, 123\nWOW! eBook\nwww.wowebook.org\nJPEG, 123–136\nadjusting quality, 135\ncompressing pixel blocks, 132\ncompression ratio, 135\nDCT, 125\npicture quality, 135–136\nJurassic Park, 57–58\nK\nKerckhoffs’s principle, 4, 5, 27, 33\nkey (encryption), 4\nAES, 9–14\nasymmetric, 38\ncode book, 9\nexpansion, 9\nkeyed hashing, 55\nMAC, 55\nprivate, 38, 44, 45, 50\npublic, 38, 43, 44, 45, 50\nrelated-key attack, 17\nshared key problem, 18, 37\nsize, 20, 47\nsymmetric, 18\nkey (search), 146, 151\nkey expansion, 9\nkeyframe, 59\nknown-plaintext attack, 6\nL\nLady and the Tramp, 59\nLaserDisc, 116\nLCD (liquid crystal display), 60\nlight-emitting diode (LED), 60\nWOW! eBook\nwww.wowebook.org\nlighting, 71–80\nambient, 96–97\nangle of incidence, 74, 75\nangle of reflectance, 74\nbump mapping, 106, 107\ndiffuse reflection, 74, 77, 92, 93, 107\ndirect, 76\ndistance effect, 72–73, 92\nindirect, 76\nmodel, 72\nnormal, 92, 93, 107\nray tracing. See ray tracing\nreal-time, 92–97\nreflection, 80\nclear, 103\nenvironment mapping, 103–105\nshadow. See shadow\nspecular reflection, 75, 77, 92, 107\nlink farming, 159\nlinks\nfarming, 159\ninbound, 158\npass-through, 159\nliquid-crystal display (LCD), 60\nlocal coordinate, 62\nlossless compression, 116\nlossy compression, 116, 124\nluminance, 124\nM\nMAC, 55\nmacroblock, 139\nWOW! eBook\nwww.wowebook.org\ndeblocking filter, 143\nman-in-the-middle attack, 52, 56\nmap\nconverting to table, 176\ndirected graph, 176\nrouting. See routing\nmassively multiplayer online game (MMO), 164\nmaster secret, 54\nmatrix, 128\nmatrix multiplication, 126\nMD5, 21–25\ndigital signature, 25–26\nencoding password for, 21–22\nquality of, 25\nround, 24–25\nmessage authentication code, 55\nmipmap, 102\nMMO (massively multiplayer online game), 164\nmodel, 61–63, 70, 87\nambient light, 96\nbump mapping, 106\ncontrol point, 62\ndistant impostor, 106\ndrawing, transforming into, 62, 88, 93, 105\nglobal illumination, 76\ninterpolation, 63\nlighting, 72\nline, 62\nscaling, 64\ntessellation, 107–108\ntranslation, 64\nMortal Kombat, 85\nWOW! eBook\nwww.wowebook.org\nmovie-quality rendering, 70, 82–83\nMPEG-2, 138–142\nadjusting quality, 139\nB-frame, 139\nGOP, 138, 142\nI-frame, 138, 139\nmacroblock, 139\nP-frame, 139\nMPEG-4, 143\nmultisample anti-aliasing (MSAA), 110–111\nvs. supersampling, 111\nmultitasking, 162–163, 174\nN\nnearest-neighbor sampling, 99–100, 101, 143\nnormal, 92, 93, 107\nNOT (bitwise operation), 23, 25\nnumerical address, 153\nO\noffset, 139\none-time pad, 9\none-way function, 39, 42\noptical printer, 82\nOR (bitwise operation), 23, 25\norigin, 61\nP\npacket, 118\npainter’s algorithm, 90\npartition, 147\npass-through link, 159\npassword, 6, 19\nWOW! eBook\nwww.wowebook.org\ncommon, 28, 29\nencoding, 21–22\nhashing, 20–23\nsalt, 34, 35\nstorage service, 35–36\ntable, 26, 27\nperformance scaling, 150\npersistence of vision, 59\nP-frame, 139\nPhineas and Ferb, 69\npivot, 147\npixel, 59, 66\nalpha channel, 68\nalpha level, 67, 78, 82\nbitmap, 61\ncontrast, 112\ndepth, 91, 95, 96\nluminance, 124\nraw, 117\nrun, 117\nsampling, 97\nshader, 92. See also lighting\nsubpixel, 110\ntexel, 98\nvariation in photographs, 123\nplaintext, 2, 3, 4, 8, 27, 28\nknown-plaintext attack, 6\npolyalphabetic substitution, 7–9\npolygon, 88. See also triangle\npost-process anti-aliasing, 111\nprecomputed hash table, 29, 31\npredicted frame, 139\nWOW! eBook\nwww.wowebook.org\npredictive encoding, 122\nprefix code, 121\npremaster secret, 53\nprime number, 40\nas factor, 41\ncoprime, 40\nprime-product, 42, 44, 45\nprint spooling, 162\nprivate key, 38, 44, 45, 50\nprocess, 162\nprojection, 71, 88, 96\nfield of view, 89\nray tracing, 77\npublic key, 38, 43, 44, 45, 50\nQ\nquantization, 123, 132, 141\nqueue, 163, 170\nquicksort, 147–150\npartition, 147\npivot, 147\nsublist, 149\nR\nrace condition, 165–169\nrasterization, 65–68, 89\nraw pixel, 117\nray tracing, 77–81, 105\nanti-aliasing, 80\nfocus, 79\nlaws of optics, 79\nperformance, 87\nprojection, 77\nWOW! eBook\nwww.wowebook.org\nreflection, 80\nshadow, 79\nread semaphore, 173\nread-only data, 166, 173\nreal-time lighting, 92–97\nrecord, 146\nred difference (Cr), 124\nreduction function, 29, 31\nreflection, 80\nclear, 103\nenvironment mapping, 103–105\nrehashing, 156\nrelated-key attack, 17\nrelease operation, 168\nrenderer, 69\nrendering, 69\n2D, 61–69\nbudget, 113\ndepth buffering, 91–92\ndepth ordering, 89–92\nfield of view, 89\nfocus, 79\nlighting, 71–80\nmovie-quality, 70, 82–83\npixel shader, 92\npolygon, 88\nprojection, 71\nrasterization, 89\nray tracing, 77–81\nrealism, 72, 79, 94, 96, 105\nreflection, 80\ntranslucency, 78\nWOW! eBook\nwww.wowebook.org\ntriangle, 88, 90\nviewpoint, 71\nresolution, 61\nRGB color system, 60, 124\nvs. YCbCr, 124\nRivest, Shamir, and Adleman method. See RSA (Rivest, Shamir, and Adleman method)\nrobot, 157, 160\nrotation, 14\nrouting\ncost, 175, 178, 179, 182, 183, 184\ndirected graph, 176\nfinding the shortest path, 175\nusing real-time data, 189\nRSA (Rivest, Shamir, and Adleman method), 42–51\nauthentication, 49–51\nauthority, 51\nbidirectional transmission, 47\ncombining with AES, 48–49\neffectiveness, 45–47\nencryption process, 44–45\nkey creation, 42–44\nkey size, 47\nperformance, 47–48\nprime-product, 42, 44, 45\nreal-world use, 47–49\ntotient, 43, 45\nrun of pixels, 117\nrun-length encoding, 117, 123, 133, 142\nS\nsalt method, 34, 35\nsampling, 97\nWOW! eBook\nwww.wowebook.org\nbilinear filtering, 101, 112\nmipmap, 102\nnearest-neighbor, 99–100, 101, 143\ntrilinear filtering, 102–103\nS-box, 13, 14\nscaling, 64, 150\nscreen coordinate, 61, 88, 96\nscreen space ambient occlusion (SSAO), 96–97\nsearch, 29, 145\nall-pairs shortest path, 183\nbest-first, 178–181\nbinary, 151–152, 153\nengine, 157\nimages, 160\nlocation use, 160\npage ranking, 158–159\nrobot, 157, 160\nsequential, 146, 153\nSitemap, 157\nstorage requirements, 153\nterm, 159–160\nWeb, 157–160\nsecurity, 1, 17, 19, 35\nof AES, 16\nbest practices, 6, 27, 29, 34, 56\nsingle point of defense, 27\nWeb, 52–56\nselection sort, 146\nperformance scaling, 150\nsemaphore, 168–174\nacquire, 168, 170\nbinary, 168\nWOW! eBook\nwww.wowebook.org\ncircular wait, 172\ngranularity, 173\nimplementation, 169\nperformance, 172–174\nread, 173\nrelease, 168\nspin lock, 169\ntest-and-set, 169\nwait list, 170\nwrite, 173\nsequential search, 146, 153\nserver, 52\nsession, 52\nshadow, 79, 94–97\nambient occlusion, 96\nmapping, 94–95\nquality, 95\nshadow map, 95\nshared buffer, 163\nshared key problem, 18, 37\nsignature. See digital signature\nsimple substitution, 6\nSimpsons, The, 69\nsingle point of defense, 27\nSitemap, 157\nsliding window, 122\nslot, 154\nsort, 146\nquicksort, 147\nselection sort, 146\nspecular reflection, 75, 77, 92, 107\nspin lock, 169\nWOW! eBook\nwww.wowebook.org\nsquare function, 39\nsquare root function, 39\nSSAA (supersampling anti-aliasing), 109–110\nvs. multisampling, 111\nSSAO (screen space ambient occlusion), 96–97\nstarting variable, 15\nstarvation, 170, 172, 173\nstatic data collection, 154\nstorage\naddress, 153\nfixed-size, 152, 153\nrequirements for search, 153\nvariable-size, 152, 153\nsubpixel, 110\nsubstitution, 6–9\npolyalphabetic, 7\nS-box, 13\nsimple, 6\ntabula recta, 7\nsubtractive color mixing, 60, 76\nsupersampling anti-aliasing (SSAA), 109–110\nvs. multisampling, 111\nsurface normal. See normal\nsymmetric key, 18\nT\ntabula recta, 7\ntemporal compression, 138\ntemporal redundancy, 138, 142\ntessellation, 107–108\ntest-and-set, 169\ntexel, 98\nWOW! eBook\nwww.wowebook.org\ntexture mapping, 97–103, 143\nbump mapping, 106\nsampling, 97\nTGA file format, 117\ncompression ratio, 118\npacket, 118\nTheora, 143\ntiming attack, 17\ntombstone, 156\nToon Boom, 69\nToonz, 69\ntotient, 43, 45\ntransaction, 164, 166–167\ntranslation, 64\ntranslucency, 68, 78\ntransposition, 2–6\nrotation, 14\ntrapdoor function, 40\ntriangle, 88, 90, 107\ntrilinear filtering, 102–103, 143\ntrivial factor, 40\ntweening, 59\nautomatic, 63–64\nU\nultra high definition video (UHD), 144\nV\nvariable-size storage, 152, 153\nvector, 126\nvideo streaming, 116\nvideocassette, 115\nview angle, 74\nWOW! eBook\nwww.wowebook.org\nviewpoint, 71\nvirtual camera, 71\nW\nWar and Peace, 122\nweb search, 157–160\nweb session, 52\nworld coordinate, 70, 88\nwrite semaphore, 173\nX\nx-axis, 61\nx-coordinate, 61\nXOR (bitwise operation), 11, 14, 15\nY\ny-axis, 61\nYCbCr color system, 124\nvs. RGB, 124\ny-coordinate, 61\nY (luminance), 124\nZ\nz-coordinate, 69\n.zip file format, 122\nWOW! eBook\nwww.wowebook.org"
  }
]