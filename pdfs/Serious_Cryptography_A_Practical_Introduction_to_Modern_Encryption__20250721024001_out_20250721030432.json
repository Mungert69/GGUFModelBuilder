[
  {
    "input": "What is the main focus of the book \"Serious Cryptography\" by Jean-Philippe Aumasson?",
    "summary": "\"Serious Cryptography\" by Jean-Philippe Aumasson is a practical guide to modern encryption techniques. It covers essential concepts like randomness, cryptographic security, and various cipher types including block and stream ciphers. The book also explores hash functions, keyed hashing, authenticated encryption, and key exchange methods, providing a comprehensive overview of cryptographic principles and their real-world applications.",
    "output": "SERIOUS CRYPTOGRAPHY\nA Practical Introduction to Modern Encryption\nJean-Philippe Aumasson\nSan Francisco\nSERIOUS CRYPTOGRAPHY. Copyright © 2018 by Jean-Philippe Aumasson.\nAll rights reserved. No part of this work may be reproduced or transmitted in any\nform or by any means, electronic or mechanical, including photocopying, recording,\nor by any information storage or retrieval system, without the prior written permission\nof the copyright owner and the publisher.\nISBN-10: 1-59327-826-8\nISBN-13: 978-1-59327-826-7\nPublisher: William Pollock\nProduction Editor: Laurel Chun\nCover Illustration: Jonny Thomas Interior Design: Octopod Studios\nDevelopmental Editors: William Pollock, Jan Cash, and Annie Choi\nTechnical Reviewers: Erik Tews and Samuel Neves\nCopyeditor: Barton D. Reed\nCompositor: Meg Sneeringer\nProofreader: James Fraleigh\nFor information on distribution, translations, or bulk sales, please contact No Starch\nPress, Inc. directly:\nNo Starch Press, Inc.\n245 8th Street, San Francisco, CA 94103\nphone: 1.415.863.9900; sales@nostarch.com www.nostarch.com\nLibrary of Congress Control Number: 2017940486\nNo Starch Press and the No Starch Press logo are registered trademarks of No Starch\nPress, Inc. Other product and company names mentioned herein may be the\ntrademarks of their respective owners. Rather than use a trademark symbol with every\noccurrence of a trademarked name, we are using the names only in an editorial fashion\nand to the benefit of the trademark owner, with no intention of infringement of the\ntrademark.\nThe information in this book is distributed on an “As Is” basis, without warranty.\nWhile every precaution has been taken in the preparation of this work, neither the\nauthor nor No Starch Press, Inc. shall have any liability to any person or entity with\nrespect to any loss or damage caused or alleged to be caused directly or indirectly by\nthe information contained in it.\nBRIEF CONTENTS\nForeword by Matthew D. Green\nPreface\nAbbreviations\nChapter 1: Encryption\nChapter 2: Randomness\nChapter 3: Cryptographic Security\nChapter 4: Block Ciphers\nChapter 5: Stream Ciphers\nChapter 6: Hash Functions\nChapter 7: Keyed Hashing\nChapter 8: Authenticated Encryption\nChapter 9: Hard Problems\nChapter 10: RSA\nChapter 11: Diffie–Hellman\nChapter 12: Elliptic Curves\nChapter 13: TLS\nChapter 14: Quantum and Post-Quantum\nIndex"
  },
  {
    "input": "What is the main purpose and focus of the book \"Serious Cryptography\"?",
    "summary": "This book challenges the myth that cryptography is the strongest part of a system, emphasizing that real-world implementations are often flawed. It provides practical insights into cryptographic concepts, including encryption, randomness, security, and key management, with real-world examples and explanations. Written for developers and practitioners, the book aims to help them understand and apply cryptography effectively, while also covering advanced topics like TLS and post-quantum cryptography.",
    "output": "CONTENTS IN DETAIL\nFOREWORD by Matthew D. Green\nPREFACE\nThis Book’s Approach\nWho This Book Is For\nHow This Book Is Organized\nFundamentals\nSymmetric Crypto\nAsymmetric Crypto\nApplications\nAcknowledgments\nABBREVIATIONS\n1\nENCRYPTION\nThe Basics\nClassical Ciphers\nThe Caesar Cipher\nThe Vigenère Cipher\nHow Ciphers Work\nThe Permutation\nThe Mode of Operation\nWhy Classical Ciphers Are Insecure\nPerfect Encryption: The One-Time Pad\nEncrypting with the One-Time Pad\nWhy Is the One-Time Pad Secure?\nEncryption Security\nAttack Models\nSecurity Goals\nSecurity Notions\nAsymmetric Encryption\nWhen Ciphers Do More Than Encryption\nAuthenticated Encryption\nFormat-Preserving Encryption\nFully Homomorphic Encryption\nSearchable Encryption\nTweakable Encryption\nHow Things Can Go Wrong\nWeak Cipher\nWrong Model\nFurther Reading\n2\nRANDOMNESS\nRandom or Non-Random?\nRandomness as a Probability Distribution\nEntropy: A Measure of Uncertainty\nRandom Number Generators (RNGs) and Pseudorandom Number\nGenerators (PRNGs)\nHow PRNGs Work\nSecurity Concerns\nThe PRNG Fortuna\nCryptographic vs. Non-Cryptographic PRNGs\nThe Uselessness of Statistical Tests\nReal-World PRNGs\nGenerating Random Bits in Unix-Based Systems\nThe CryptGenRandom() Function in Windows\nA Hardware-Based PRNG: RDRAND in Intel Microprocessors\nHow Things Can Go Wrong\nPoor Entropy Sources\nInsufficient Entropy at Boot Time\nNon-cryptographic PRNG\nSampling Bug with Strong Randomness\nFurther Reading\n3\nCRYPTOGRAPHIC SECURITY\nDefining the Impossible\nSecurity in Theory: Informational Security\nSecurity in Practice: Computational Security\nQuantifying Security\nMeasuring Security in Bits\nFull Attack Cost\nChoosing and Evaluating Security Levels\nAchieving Security\nProvable Security\nHeuristic Security\nGenerating Keys\nGenerating Symmetric Keys\nGenerating Asymmetric Keys\nProtecting Keys\nHow Things Can Go Wrong\nIncorrect Security Proof\nShort Keys for Legacy Support\nFurther Reading\n4\nBLOCK CIPHERS\nWhat Is a Block Cipher?\nSecurity Goals\nBlock Size\nThe Codebook Attack\nHow to Construct Block Ciphers\nA Block Cipher’s Rounds\nThe Slide Attack and Round Keys\nSubstitution–Permutation Networks\nFeistel Schemes\nThe Advanced Encryption Standard (AES)\nAES Internals\nAES in Action\nImplementing AES\nTable-Based Implementations\nNative Instructions\nIs AES Secure?\nModes of Operation\nThe Electronic Codebook (ECB) Mode\nThe Cipher Block Chaining (CBC) Mode\nHow to Encrypt Any Message in CBC Mode\nThe Counter (CTR) Mode\nHow Things Can Go Wrong\nMeet-in-the-Middle Attacks\nPadding Oracle Attacks\nFurther Reading\n5\nSTREAM CIPHERS\nHow Stream Ciphers Work\nStateful and Counter-Based Stream Ciphers\nHardware-Oriented Stream Ciphers\nFeedback Shift Registers\nGrain-128a\nA5/1\nSoftware-Oriented Stream Ciphers\nRC4\nSalsa20\nHow Things Can Go Wrong\nNonce Reuse\nBroken RC4 Implementation\nWeak Ciphers Baked Into Hardware\nFurther Reading\n6\nHASH FUNCTIONS\nSecure Hash Functions\nUnpredictability Again\nPreimage Resistance\nCollision Resistance\nFinding Collisions\nBuilding Hash Functions\nCompression-Based Hash Functions: The Merkle–Damgård\nConstruction\nPermutation-Based Hash Functions: Sponge Functions\nThe SHA Family of Hash Functions\nSHA-1\nSHA-2\nThe SHA-3 Competition\nKeccak (SHA-3)\nThe BLAKE2 Hash Function\nHow Things Can Go Wrong\nThe Length-Extension Attack\nFooling Proof-of-Storage Protocols\nFurther Reading\n7\nKEYED HASHING\nMessage Authentication Codes (MACs)\nMACs in Secure Communication\nForgery and Chosen-Message Attacks\nReplay Attacks\nPseudorandom Functions (PRFs)\nPRF Security\nWhy PRFs Are Stronger Than MACs\nCreating Keyed Hashes from Unkeyed Hashes\nThe Secret-Prefix Construction\nThe Secret-Suffix Construction\nThe HMAC Construction\nA Generic Attack Against Hash-Based MACs\nCreating Keyed Hashes from Block Ciphers: CMAC\nBreaking CBC-MAC\nFixing CBC-MAC\nDedicated MAC Designs\nPoly1305\nSipHash\nHow Things Can Go Wrong\nTiming Attacks on MAC Verification\nWhen Sponges Leak\nFurther Reading\n8\nAUTHENTICATED ENCRYPTION\nAuthenticated Encryption Using MACs\nEncrypt-and-MAC\nMAC-then-Encrypt\nEncrypt-then-MAC\nAuthenticated Ciphers\nAuthenticated Encryption with Associated Data\nAvoiding Predictability with Nonces\nWhat Makes a Good Authenticated Cipher?\nAES-GCM: The Authenticated Cipher Standard\nGCM Internals: CTR and GHASH\nGCM Security\nGCM Efficiency\nOCB: An Authenticated Cipher Faster than GCM\nOCB Internals\nOCB Security\nOCB Efficiency\nSIV: The Safest Authenticated Cipher?\nPermutation-Based AEAD\nHow Things Can Go Wrong\nAES-GCM and Weak Hash Keys\nAES-GCM and Small Tags\nFurther Reading\n9\nHARD PROBLEMS\nComputational Hardness\nMeasuring Running Time\nPolynomial vs. Superpolynomial Time\nComplexity Classes\nNondeterministic Polynomial Time\nNP-Complete Problems\nThe P vs. NP Problem\nThe Factoring Problem\nFactoring Large Numbers in Practice\nIs Factoring NP-Complete?\nThe Discrete Logarithm Problem\nWhat Is a Group?\nThe Hard Thing\nHow Things Can Go Wrong\nWhen Factoring Is Easy\nSmall Hard Problems Aren’t Hard\nFurther Reading\n10\nRSA\nThe Math Behind RSA\nThe RSA Trapdoor Permutation\nRSA Key Generation and Security\nEncrypting with RSA\nBreaking Textbook RSA Encryption’s Malleability\nStrong RSA Encryption: OAEP\nSigning with RSA\nBreaking Textbook RSA Signatures\nThe PSS Signature Standard\nFull Domain Hash Signatures\nRSA Implementations\nFast Exponentiation Algorithm: Square-and-Multiply\nSmall Exponents for Faster Public-Key Operations\nThe Chinese Remainder Theorem\nHow Things Can Go Wrong\nThe Bellcore Attack on RSA-CRT\nSharing Private Exponents or Moduli\nFurther Reading\n11\nDIFFIE–HELLMAN\nThe Diffie–Hellman Function\nThe Diffie–Hellman Problems\nThe Computational Diffie–Hellman Problem\nThe Decisional Diffie–Hellman Problem\nMore Diffie–Hellman Problems\nKey Agreement Protocols\nAn Example of Non-DH Key Agreement\nAttack Models for Key Agreement Protocols\nPerformance\nDiffie–Hellman Protocols\nAnonymous Diffie–Hellman\nAuthenticated Diffie–Hellman\nMenezes–Qu–Vanstone (MQV)\nHow Things Can Go Wrong\nNot Hashing the Shared Secret\nLegacy Diffie–Hellman in TLS\nUnsafe Group Parameters\nFurther Reading\n12\nELLIPTIC CURVES\nWhat Is an Elliptic Curve?\nElliptic Curves over Integers\nAdding and Multiplying Points\nElliptic Curve Groups\nThe ECDLP Problem\nDiffie–Hellman Key Agreement over Elliptic Curves\nSigning with Elliptic Curves\nEncrypting with Elliptic Curves\nChoosing a Curve\nNIST Curves\nCurve25519\nOther Curves\nHow Things Can Go Wrong\nECDSA with Bad Randomness\nBreaking ECDH Using Another Curve\nFurther Reading\n13\nTLS\nTarget Applications and Requirements\nThe TLS Protocol Suite\nThe TLS and SSL Family of Protocols: A Brief History\nTLS in a Nutshell\nCertificates and Certificate Authorities\nThe Record Protocol\nThe TLS Handshake Protocol\nTLS 1.3 Cryptographic Algorithms\nTLS 1.3 Improvements over TLS 1.2\nDowngrade Protection\nSingle Round-Trip Handshake\nSession Resumption\nThe Strengths of TLS Security\nAuthentication\nForward Secrecy\nHow Things Can Go Wrong\nCompromised Certificate Authority\nCompromised Server\nCompromised Client\nBugs in Implementations\nFurther Reading\n14\nQUANTUM AND POST-QUANTUM\nHow Quantum Computers Work\nQuantum Bits\nQuantum Gates\nQuantum Speed-Up\nExponential Speed-Up and Simon’s Problem\nThe Threat of Shor’s Algorithm\nShor’s Algorithm Solves the Factoring Problem\nShor’s Algorithm and the Discrete Logarithm Problem\nGrover’s Algorithm\nWhy Is It So Hard to Build a Quantum Computer?\nPost-Quantum Cryptographic Algorithms\nCode-Based Cryptography\nLattice-Based Cryptography\nMultivariate Cryptography\nHash-Based Cryptography\nHow Things Can Go Wrong\nUnclear Security Level\nFast Forward: What Happens if It’s Too Late?\nImplementation Issues\nFurther Reading\nINDEX\nFOREWORD\nIf you’ve read a book or two on computer security, you may have\nencountered a common perspective on the field of cryptography.\n“Cryptography,” they say, “is the strongest link in the chain.” Strong\npraise indeed, but it’s also somewhat dismissive. If cryptography is in fact\nthe strongest part of your system, why invest time improving it when\nthere are so many other areas of the system that will benefit more from\nyour attention?\nIf there’s one thing that I hope you take away from this book, it’s that\nthis view of cryptography is idealized; it’s largely a myth. Cryptography in\ntheory is strong, but cryptography in practice is as prone to failure as any\nother aspect of a security system. This is particularly true when\ncryptographic implementations are developed by non-experts without\nsufficient care or experience, as is the case with many cryptographic\nsystems deployed today. And it gets worse: when cryptographic\nimplementations fail, they often do so in uniquely spectacular ways.\nBut why should you care, and why this book?\nWhen I began working in the field of applied cryptography nearly two\ndecades ago, the information available to software developers was often\npiecemeal and outdated. Cryptographers developed algorithms and\nprotocols, and cryptographic engineers implemented them to create\nopaque, poorly documented cryptographic libraries designed mainly for\nother experts. There was—and there has been—a huge divide between\nthose who know and understand cryptographic algorithms and those who\nuse them (or ignore them at their peril). There are a few decent textbooks\non the market, but even fewer have provided useful tools for the\npractitioner.\nThe results have not been pretty. I’m talking about compromises with\nlabels like “CVE” and “Severity: High,” and in a few alarming cases,\nattacks on slide decks marked “TOP SECRET.” You may be familiar\nwith some of the more famous examples if only because they’ve affected\nsystems that you rely on. Many of these problems occur because\ncryptography is subtle and mathematically elegant, and because\ncryptographic experts have failed to share their knowledge with the\nengineers who actually write the software.\nThankfully, this has begun to change and this book is a symptom of\nthat change.\nSerious Cryptography was written by one of the foremost experts in\napplied cryptography, but it’s not targeted at other experts. Nor, for that\nmatter, is it intended as a superficial overview of the field. On the\ncontrary, it contains a thorough and up-to-date discussion of\ncryptographic engineering, designed to help practitioners who plan to\nwork in this field do better. In these pages, you’ll learn not only how\ncryptographic algorithms work, but how to use them in real systems.\nThe book begins with an exploration of many of the key cryptographic\nprimitives, including basic algorithms like block ciphers, public\nencryption schemes, hash functions, and random number generators.\nEach chapter provides working examples of how the algorithms work and\nwhat you should or should not do. Final chapters cover advanced subjects\nsuch as TLS, as well as the future of cryptography—what to do after\nquantum computers arrive to complicate our lives.\nWhile no single book can solve all our problems, a bit of knowledge\ncan go a long way. This book contains plenty of knowledge. Perhaps\nenough to make real, deployed cryptography live up to the high\nexpectations that so many have of it.\nHappy reading.\nMatthew D. Green\nProfessor\nInformation Security Institute\nJohns Hopkins University\nPREFACE\nI wrote this book to be the one I wish I had when I started learning\ncrypto. In 2005, I was studying for my masters degree near Paris, and I\neagerly registered for the crypto class in the upcoming semester.\nUnfortunately, the class was canceled because too few students had\nregistered. “Crypto is too hard,” the students argued, and instead, they\nenrolled en masse in the computer graphics and database classes.\nI’ve heard “crypto is hard” more than a dozen times since then. But is\ncrypto really that hard? To play an instrument, master a programming\nlanguage, or put the applications of any fascinating field into practice, you\nneed to learn some concepts and symbols, but doing so doesn’t take a\nPhD. I think the same applies to becoming a competent cryptographer. I\nalso believe that crypto is perceived as hard because cryptographers\nhaven’t done a good job of teaching it.\nAnother reason why I felt the need for this book is that crypto is no\nlonger just about crypto—it has expanded into a multidisciplinary field.\nTo do anything useful and relevant in crypto, you’ll need some\nunderstanding of the concepts around crypto: how networks and\ncomputers work, what users and systems need, and how attackers can\nabuse algorithms and their implementations. In other words, you need a\nconnection to reality.\nThis Book’s Approach\nThe initial title of this book was Crypto for Real to stress the practice-\noriented, real-world, no-nonsense approach I aimed to follow. I didn’t\nwant to make cryptography approachable by dumbing it down, but\ninstead tie it to real applications. I provide source code examples and\ndescribe real bugs and horror stories.\nAlong with a clear connection to reality, other cornerstones of this\nbook are its simplicity and modernity. I focus on simplicity in form more\nthan in substance: I present many non-trivial concepts, but without the\ndull mathematical formalism. Instead, I attempt to impart an\nunderstanding of cryptography’s core ideas, which are more important\nthan remembering a bunch of equations. To ensure the book’s\nmodernity, I cover the latest developments and applications of\ncryptography, such as TLS 1.3 and post-quantum cryptography. I don’t\ndiscuss the details of obsolete or insecure algorithms such as DES or\nMD5. An exception to this is RC4, but it’s only included to explain how\nweak it is and to show how a stream cipher of its kind works.\nSerious Cryptography isn’t a guide for crypto software, nor is it a\ncompendium of technical specifications—stuff that you’ll easily find\nonline. Instead, the foremost goal of this book is to get you excited about\ncrypto and to teach you its fundamental concepts along the way.\nWho This Book Is For\nWhile writing, I often imagined the reader as a developer who’d been\nexposed to crypto but still felt clueless and frustrated after attempting to\nread abstruse textbooks and research papers. Developers often need—and\nwant—a better grasp of crypto to avoid unfortunate design choices, and I\nhope this book will help.\nBut if you aren’t a developer, don’t worry! The book doesn’t require\nany coding skills, and is accessible to anyone who understands the basics\nof computer science and college-level math (notions of probabilities,\nmodular arithmetic, and so on).\nThis book can nonetheless be intimidating, and despite its relative\naccessibility, it requires some effort to get the most out of it. I like the\nmountaineering analogy: the author paves the way, providing you with\nropes and ice axes to facilitate your work, but you make the ascent\nyourself. Learning the concepts in this book will take an effort, but there"
  },
  {
    "input": "What is the structure and content of the book as outlined in the text?",
    "summary": "This book is organized into fourteen chapters divided into four parts, with Chapter 9 serving as a foundation for the following three. It covers fundamental concepts of cryptography, symmetric encryption methods like block and stream ciphers, hash functions, and cryptographic security. The latter half explores asymmetric cryptography, including public-key encryption, and applications such as TLS and quantum-resistant cryptography.",
    "output": "will be a reward at the end.\nHow This Book Is Organized\nThe book has fourteen chapters, loosely split into four parts. The\nchapters are mostly independent from one another, except for Chapter 9,\nwhich lays the foundations for the three subsequent chapters. I also\nrecommend reading the first three chapters before anything else.\nFundamentals\nChapter 1: Encryption introduces the notion of secure encryption,\nfrom weak pen-and-paper ciphers to strong, randomized encryption.\nChapter 2: Randomness describes how a pseudorandom generator\nworks, what it takes for one to be secure, and how to use one\nsecurely.\nChapter 3: Cryptographic Security discusses theoretical and\npractical notions of security, and compares provable security with\nprobable security.\nSymmetric Crypto\nChapter 4: Block Ciphers deals with ciphers that process messages\nblock per block, focusing on the most famous one, the Advanced\nEncryption Standard (AES).\nChapter 5: Stream Ciphers presents ciphers that produce a stream\nof random-looking bits that are XORed with messages to be\nencrypted.\nChapter 6: Hash Functions is about the only algorithms that\ndon’t work with a secret key, which turn out to be the most\nubiquitous crypto building blocks.\nChapter 7: Keyed Hashing explains what happens if you combine a\nhash function with a secret key, and how this serves to authenticate\nmessages.\nChapter 8: Authenticated Encryption shows how some algorithms\ncan both encrypt and authenticate a message with examples, such as\nthe standard AES-GCM.\nAsymmetric Crypto\nChapter 9: Hard Problems lays out the fundamental concepts\nbehind public-key encryption, using notions from computational\ncomplexity.\nChapter 10: RSA leverages the factoring problem in order to build\nsecure encryption and signature schemes with a simple arithmetic\noperation.\nChapter 11: Diffie–Hellman extends asymmetric cryptography to\nthe notion of key agreement, wherein two parties establish a secret\nvalue using only non-secret values.\nChapter 12: Elliptic Curves provides a gentle introduction to\nelliptic curve cryptography, which is the fastest kind of asymmetric\ncryptography.\nApplications\nChapter 13: TLS focuses on Transport Layer Security (TLS),\narguably the most important protocol in network security.\nChapter 14: Quantum and Post-Quantum concludes with a note\nof science fiction by covering the concepts of quantum computing\nand a new kind of cryptography.\nAcknowledgments\nI’d like to thank Jan, Annie, and the rest of the No Starch staff who\ncontributed to this book, especially Bill for believing in this project from\nthe get-go, for his patience digesting difficult topics, and for turning my\nclumsy drafts into readable pages. I am also thankful to Laurel for making\nthe book look so nice and for handling my many correction requests.\nOn the technical side, the book would contain many more errors and\ninaccuracies without the help of the following people: Jon Callas, Bill\nCox, Niels Ferguson, Philipp Jovanovic, Samuel Neves, David Reid,\nPhillip Rogaway, Erik Tews, as well as all readers of the early access\nversion who reported errors. Finally, thanks to Matt Green for writing\nthe foreword.\nI’d also like to thank my employer, Kudelski Security, for allowing me\ntime to work on this book. Finally, I offer my deepest thanks to Alexandra\nand Melina for their support and patience.\nLausanne, 05/17/2017 (three prime numbers)\nABBREVIATIONS\nAE authenticated encryption\nAEAD authentication encryption with associated data\nAES Advanced Encryption Standard\nAES-NI AES native instructions\nAKA authenticated key agreement\nAPI application program interface\nARX add-rotate-XOR\nASIC application-specific integrated circuit\nCA certificate authority\nCompetition for Authenticated Encryption: Security,\nCAESAR\nApplicability, and Robustness\nCBC cipher block chaining\nCCA chosen-ciphertext attackers\nCDH computational Diffie–Hellman\nCMAC cipher-based MAC\nCOA ciphertext-only attackers\nCPA chosen-plaintext attackers\nCRT Chinese remainder theorem\nCTR counter mode\nCVP closest vector problem\nDDH decisional Diffie–Hellman\nDES Data Encryption Standard\nDH Diffie–Hellman\nDLP discrete logarithm problem\nDRBG deterministic random bit generator\nECB electronic codebook\nECC elliptic curve cryptography\nECDH elliptic curve Diffie–Hellman\nECDLP elliptic-curve discrete logarithm problem\nECDSA elliptic-curve digital signature algorithm\nFDH Full Domain Hash\nFHE fully homomorphic encryption\nFIPS Federal Information Processing Standards\nFPE format-preserving encryption\nFPGA field-programmable gate array\nFSR feedback shift register\nGCD greatest common divisor\nGCM Galois Counter Mode\nGNFS general number field sieve\nHKDF HMAC-based key derivation function\nHMAC hash-based message authentication code\nHTTPS HTTP Secure\nIND indistinguishablity\nIP Internet Protocol\nIV initial value\nKDF key derivation function\nKPA known-plaintext attackers\nLFSR linear feedback shift register\nLSB least significant bit\nLWE learning with errors\nMAC messsage authentication code\nMD message digest\nMitM meet-in-the-middle\nMQ multivariate quadratics\nMQV Menezes–Qu–Vanstone\nMSB most significant bit\nMT Mersenne Twister\nNFSR nonlinear feedback shift register\nNIST National Institute of Standards and Technology\nNM non-malleability\nNP nondeterministic polynomial-time\nOAEP Optimal Asymmetric Encryption Padding\nOCB offset codebook\nP polynomial time\nPLD programmable logic device\nPRF pseudorandom function\nPRNG pseudorandom number generator\nPRP pseudorandom permutation\nPSK pre-shared key\nPSS Probabilistic Signature Scheme\nQR quarter-round\nQRNG quantum random number generator\nRFC request for comments\nRNG random number generator\nRSA Rivest–Shamir–Adleman\nSHA Secure Hash Algorithm\nSIS short integer solution\nSIV synthetic IV\nSPN substitution–permutation network\nSSH Secure Shell\nSSL Secure Socket Layer\nTE tweakable encryption\nTLS Transport Layer Security\nTMTO time-memory trade-off\nUDP User Datagram Protocol\nUH universal hash\nWEP Wireless Encrypted Protocol\nWOTS Winternitz one-time signature\nXOR exclusive OR"
  },
  {
    "input": "What is the difference between symmetric and asymmetric encryption?",
    "summary": "Encryption is the main use of cryptography, making data unreadable to ensure confidentiality. It uses a cipher and key, with the key being essential for decryption. Symmetric encryption, which uses the same key for both encryption and decryption, is discussed, along with classical ciphers like Caesar and Vigenère, which are simple but insecure. Modern ciphers are more complex and secure, while the one-time pad is the most secure encryption method, using a random key of the same length as the plaintext. However, it is impractical due to the need for a key as long as the message.",
    "output": "1\nENCRYPTION\nEncryption is the principal application of cryptography; it makes data\nincomprehensible in order to ensure its confidentiality. Encryption uses an\nalgorithm called a cipher and a secret value called the key; if you don’t\nknow the secret key, you can’t decrypt, nor can you learn any bit of\ninformation on the encrypted message—and neither can any attacker.\nThis chapter will focus on symmetric encryption, which is the simplest\nkind of encryption. In symmetric encryption, the key used to decrypt is the\nsame as the key used to encrypt (unlike asymmetric encryption, or public-key\nencryption, in which the key used to decrypt is different from the key used\nto encrypt). You’ll start by learning about the weakest forms of symmetric\nencryption, classical ciphers that are secure against only the most illiterate\nattacker, and then move on to the strongest forms that are secure forever.\nThe Basics\nWhen we’re encrypting a message, plaintext refers to the unencrypted\nmessage and ciphertext to the encrypted message. A cipher is therefore\ncomposed of two functions: encryption turns a plaintext into a ciphertext,\nand decryption turns a ciphertext back into a plaintext. But we’ll often say\n“cipher” when we actually mean “encryption.” For example, Figure 1-1\nshows a cipher, E, represented as a box taking as input a plaintext, P, and\na key, K, and producing a ciphertext, C, as output. I’ll write this relation\nas C = E(K, P). Similarly, when the cipher is in decryption mode, I’ll write\nD(K, C).\nFigure 1-1: Basic encryption and decryption\nNOTE\nFor some ciphers, the ciphertext is the same size as the plaintext; for some\nothers, the ciphertext is slightly longer. However, ciphertexts can never be\nshorter than plaintexts.\nClassical Ciphers\nClassical ciphers are ciphers that predate computers and therefore work\non letters rather than on bits. They are much simpler than a modern\ncipher like DES—for example, in ancient Rome or during WWI, you\ncouldn’t use a computer chip’s power to scramble a message, so you had\nto do everything with only pen and paper. There are many classical\nciphers, but the most famous are the Caesar cipher and Vigenère cipher.\nThe Caesar Cipher\nThe Caesar cipher is so named because the Roman historian Suetonius\nreported that Julius Caesar used it. It encrypts a message by shifting each\nof the letters down three positions in the alphabet, wrapping back around\nto A if the shift reaches Z. For example, ZOO encrypts to CRR,\nFDHVDU decrypts to CAESAR, and so on, as shown in Figure 1-2.\nThere’s nothing special about the value 3; it’s just easier to compute in\none’s head than 11 or 23.\nThe Caesar cipher is super easy to break: to decrypt a given ciphertext,\nsimply shift the letters three positions back to retrieve the plaintext. That\nsaid, the Caesar cipher may have been strong enough during the time of\nCrassus and Cicero. Because no secret key is involved (it’s always 3), users\nof Caesar’s cipher only had to assume that attackers were illiterate or too\nuneducated to figure it out—an assumption that’s much less realistic\ntoday. (In fact, in 2006, the Italian police arrested a mafia boss after\ndecrypting messages written on small scraps of paper that were encrypted\nusing a variant of the Caesar cipher: ABC was encrypted to 456 instead of\nDEF, for example.)\nFigure 1-2: The Caesar cipher\nCould the Caesar cipher be made more secure? You can, for example,\nimagine a version that uses a secret shift value instead of always using 3,\nbut that wouldn’t help much because an attacker could easily try all 25\npossible shift values until the decrypted message makes sense.\nThe Vigenère Cipher\nIt took about 1500 years to see a meaningful improvement of the Caesar\ncipher in the form of the Vigenère cipher, created in the 16th century by\nan Italian named Giovan Battista Bellaso. The name “Vigenère” comes\nfrom the Frenchman Blaise de Vigenère, who invented a different cipher\nin the 16th century, but due to historical misattribution, Vigenère’s name\nstuck. Nevertheless, the Vigenère cipher became popular and was later\nused during the American Civil War by Confederate forces and during\nWWI by the Swiss Army, among others.\nThe Vigenère cipher is similar to the Caesar cipher, except that letters\naren’t shifted by three places but rather by values defined by a key, a\ncollection of letters that represent numbers based on their position in the\nalphabet. For example, if the key is DUH, letters in the plaintext are\nshifted using the values 3, 20, 7 because D is three letters after A, U is 20\nletters after A, and H is seven letters after A. The 3, 20, 7 pattern repeats\nuntil you’ve encrypted the entire plaintext. For example, the word\nCRYPTO would encrypt to FLFSNV using DUH as the key: C is shifted\nthree positions to F, R is shifted 20 positions to L, and so on. Figure 1-3\nillustrates this principle when encrypting the sentence THEY DRINK\nTHE TEA.\nFigure 1-3: The Vigenère cipher\nThe Vigenère cipher is clearly more secure than the Caesar cipher, yet\nit’s still fairly easy to break. The first step to breaking it is to figure out\nthe key’s length. For example, take the example in Figure 1-3, wherein\nTHEY DRINK THE TEA encrypts to WBLBXYLHRWBLWYH with\nthe key DUH. (Spaces are usually removed to hide word boundaries.)\nNotice that in the ciphertext WBLBXYLHRWBLWYH, the group of\nthree letters WBL appears twice in the ciphertext at nine-letter intervals.\nThis suggests that the same three-letter word was encrypted using the\nsame shift values, producing WBL each time. A cryptanalyst can then\ndeduce that the key’s length is either nine or a value divisible by nine\n(that is, three). Furthermore, they may guess that this repeated three-\nletter word is THE and therefore determine DUH as a possible\nencryption key.\nThe second step to breaking the Vigenère cipher is to determine the\nactual key using a method called frequency analysis, which exploits the\nuneven distribution of letters in languages. For example, in English, E is\nthe most common letter, so if you find that X is the most common letter\nin a ciphertext, then the most likely plaintext value at this position is E.\nDespite its relative weakness, the Vigenère cipher may have been good\nenough to securely encrypt messages when it was used. First, because the\nattack just outlined needs messages of at least a few sentences, it wouldn’t\nwork if the cipher was used to encrypt only short messages. Second, most\nmessages needed to be secret only for short periods of time, so it didn’t\nmatter if ciphertexts were eventually decrypted by the enemy. (The 19th-\ncentury cryptographer Auguste Kerckhoffs estimated that most encrypted\nwartime messages required confidentiality for only three to four hours.)\nHow Ciphers Work\nBased on simplistic ciphers like the Caesar and Vigenère ciphers, we can\ntry to abstract out the workings of a cipher, first by identifying its two\nmain components: a permutation and a mode of operation. A permutation\nis a function that transforms an item (in cryptography, a letter or a group\nof bits) such that each item has a unique inverse (for example, the Caesar\ncipher’s three-letter shift). A mode of operation is an algorithm that uses a\npermutation to process messages of arbitrary size. The mode of the\nCaesar cipher is trivial: it just repeats the same permutation for each\nletter, but as you’ve seen, the Vigenère cipher has a more complex mode,\nwhere letters at different positions undergo different permutations.\nIn the following sections, I discuss in more detail what these are and\nhow they relate to a cipher’s security. I use each component to show why\nclassical ciphers are doomed to be insecure, unlike modern ciphers that\nrun on high-speed computers.\nThe Permutation\nMost classical ciphers work by replacing each letter with another letter—\nin other words, by performing a substitution. In the Caesar and Vigenère\nciphers, the substitution is a shift in the alphabet, though the alphabet or\nset of symbols can vary: instead of the English alphabet, it could be the\nArabic alphabet; instead of letters, it could be words, numbers, or\nideograms, for example. The representation or encoding of information is\na separate matter that is mostly irrelevant to security. (We’re just\nconsidering Latin letters because that’s what classical ciphers use.)\nA cipher’s substitution can’t be just any substitution. It should be a\npermutation, which is a rearrangement of the letters A to Z, such that\neach letter has a unique inverse. For example, a substitution that\ntransforms the letters A, B, C, and D, respectively to C, A, D, and B is a\npermutation, because each letter maps onto another single letter. But a\nsubstitution that transforms A, B, C, D to D, A, A, C is not a permutation,\nbecause both B and C map onto A. With a permutation, each letter has\nexactly one inverse.\nStill, not every permutation is secure. In order to be secure, a cipher’s\npermutation should satisfy three criteria:\nThe permutation should be determined by the key, so as to keep\nthe permutation secret as long as the key is secret. In the Vigenère\ncipher, if you don’t know the key, you don’t know which of the 26\npermutations was used; hence, you can’t easily decrypt.\nDifferent keys should result in different permutations.\nOtherwise, it becomes easier to decrypt without the key: if different\nkeys result in identical permutations, that means there are fewer\ndistinct keys than distinct permutations, and therefore fewer\npossibilities to try when decrypting without the key. In the Vigenère\ncipher, each letter from the key determines a substitution; there are\n26 distinct letters, and as many distinct permutations.\nThe permutation should look random, loosely speaking. There\nshould be no pattern in the ciphertext after performing a\npermutation, because patterns make a permutation predictable for an\nattacker, and therefore less secure. For example, the Vigenère\ncipher’s substitution is pretty predictable: if you determine that A\nencrypts to F, you could conclude that the shift value is 5 and you\nwould also know that B encrypts to G, that C encrypts to H, and so\non. However, with a randomly chosen permutation, knowing that A\nencrypts to F would only tell you that B does not encrypt to F.\nWe’ll call a permutation that satisfies these criteria a secure permutation.\nBut as you’ll see next, a secure permutation is necessary but not sufficient\non its own for building a secure cipher. A cipher will also need a mode of\noperation to support messages of any length.\nThe Mode of Operation\nSay we have a secure permutation that transforms A to X, B to M, and N\nto L, for example. The word BANANA therefore encrypts to MXLXLX,\nwhere each occurrence of A is replaced by an X. Using the same\npermutation for all the letters in the plaintext thus reveals any duplicate\nletters in the plaintext. By analyzing these duplicates, you might not learn\nthe entire message, but you’ll learn something about the message. In the\nBANANA example, you don’t need the key to guess that the plaintext has\nthe same letter at the three X positions and another same letter at the two\nL positions. So if you know, for example, that the message is a fruit’s\nname, you could determine that it’s BANANA rather than CHERRY,\nLYCHEE, or another six-letter fruit.\nThe mode of operation (or just mode) of a cipher mitigates the exposure\nof duplicate letters in the plaintext by using different permutations for\nduplicate letters. The mode of the Vigenère cipher partially addresses\nthis: if the key is N letters long, then N different permutations will be\nused for every N consecutive letters. However, this can still result in\npatterns in the ciphertext because every Nth letter of the message uses the\nsame permutation. That’s why frequency analysis works to break the\nVigenère cipher, as you saw earlier.\nFrequency analysis can be defeated if the Vigenère cipher only encrypts\nplaintexts that are of the same length as the key. But even then, there’s\nanother problem: reusing the same key several times exposes similarities\nbetween plaintexts. For example, with the key KYN, the words TIE and\nPIE encrypt to DGR and ZGR, respectively. Both end with the same two\nletters (GR), revealing that both plaintexts share their last two letters as\nwell. Finding these patterns shouldn’t be possible with a secure cipher.\nTo build a secure cipher, you must combine a secure permutation with\na secure mode. Ideally, this combination prevents attackers from learning\nanything about a message other than its length.\nWhy Classical Ciphers Are Insecure\nClassical ciphers are doomed to be insecure because they’re limited to\noperations you can do in your head or on a piece of paper. They lack the\ncomputational power of a computer and are easily broken by simple\ncomputer programs. Let’s see the fundamental reason why that simplicity\nmakes them insecure in today’s world.\nRemember that a cipher’s permutation should look random in order to\nbe secure. Of course, the best way to look random is to be random—that\nis, to select every permutation randomly from the set of all permutations.\nAnd there are many permutations to choose from. In the case of the 26-\nletter English alphabet, there are approximately 288 permutations:\n26! = 403291461126605635584000000 ≈ 288\nHere, the exclamation point (!) is the factorial symbol, defined as\nfollows:\nn! = n × (n − 1) × (n – 2) × . . . × 3 × 2\n(To see why we end up with this number, count the permutations as\nlists of reordered letters: there are 26 choices for the first possible letter,\nthen 25 possibilities for the second, 24 for the third, and so on.) This\nnumber is huge: it’s of the same order of magnitude as the number of\natoms in the human body. But classical ciphers can only use a small\nfraction of those permutations—namely, those that need only simple\noperations (such as shifts) and that have a short description (like a short\nalgorithm or a small look-up table). The problem is that a secure\npermutation can’t accommodate both of these limitations.\nYou can get secure permutations using simple operations by picking a\nrandom permutation, representing it as a table of 25 letters (enough to\nrepresent a permutation of 26 letters, with the 26th one missing), and\napplying it by looking up letters in this table. But then you wouldn’t have\na short description. For example, it would take 250 letters to describe 10\ndifferent permutations, rather than just the 10 letters used in the\nVigenère cipher.\nYou can also produce secure permutations with a short description.\nInstead of just shifting the alphabet, you could use more complex\noperations such as addition, multiplication, and so on. That’s how\nmodern ciphers work: given a key of typically 128 or 256 bits, they\nperform hundreds of bit operations to encrypt a single letter. This\nprocess is fast on a computer that can do billions of bit operations per\nsecond, but it would take hours to do by hand, and would still be\nvulnerable to frequency analysis.\nPerfect Encryption: The One-Time Pad\nEssentially, a classical cipher can’t be secure unless it comes with a huge\nkey, but encrypting with a huge key is impractical. However, the one-\ntime pad is such a cipher, and it is the most secure cipher. In fact, it\nguarantees perfect secrecy: even if an attacker has unlimited computing\npower, it’s impossible to learn anything about the plaintext except for its\nlength.\nIn the next sections, I’ll show you how a one-time pad works and then\noffer a sketch of its security proof.\nEncrypting with the One-Time Pad\nThe one-time pad takes a plaintext, P, and a random key, K, that’s the\nsame length as P and produces a ciphertext C, defined as\nC = P ⊕ K\nwhere C, P, and K are bit strings of the same length and where ⊕ is the\nbitwise exclusive OR operation (XOR), defined as 0 ⊕ 0 = 0, 0 ⊕ 1 = 1, 1 ⊕\n0 = 1, 1 ⊕ 1 = 0.\nNOTE\nI’m presenting the one-time pad in its usual form, as working on bits, but it\ncan be adapted to other symbols. With letters, for example, you would end up\nwith a variant of the Caesar cipher with a shift index picked at random for\neach letter.\nThe one-time pad’s decryption is identical to encryption; it’s just an\nXOR: P = C ⊕ K. Indeed, we can verify C ⊕ K = P ⊕ K ⊕ K = P because\nXORing K with itself gives the all-zero string 000 . . . 000. That’s it—\neven simpler than the Caesar cipher.\nFor example, if P = 01101101 and K = 10110100, then we can calculate\nthe following:\nC = P ⊕ K = 01101101 ⊕ 10110100 = 11011001\nDecryption retrieves P by computing the following:\nP = C ⊕ K = 11011001 ⊕ 10110100 = 01101101\nThe important thing is that a one-time pad can only be used one time:\neach key K should be used only once. If the same K is used to encrypt P\n1\nand P to C and C , then an eavesdropper can compute the following:\n2 1 2\nC ⊕ C = (P ⊕ K) ⊕ (P ⊕ K) = P ⊕ P ⊕ K ⊕ K = P ⊕ P\n1 2 1 2 1 2 1 2\nAn eavesdropper would thus learn the XOR difference of P and P ,\n1 2\ninformation that should be kept secret. Moreover, if either plaintext\nmessage is known, then the other message can be recovered.\nOf course, the one-time pad is utterly inconvenient to use because it\nrequires a key as long as the plaintext and a new random key for each new\nmessage or group of data. To encrypt a one-terabyte hard drive, you’d\nneed another one-terabyte drive to store the key! Nonetheless, the one-\ntime pad has been used throughout history. For example, it was used by"
  },
  {
    "input": "What is the significance of the one-time pad in cryptography and why is it considered secure?",
    "summary": "The one-time pad is theoretically unbreakable due to its use of a key as long as the message and random generation, but it's impractical for real-world use. Modern encryption relies on probabilistic methods and attack models like CPA and CCA to balance security and usability. Randomness is crucial in cryptography, with PRNGs and hardware-based generators providing reliable random bits, though they must be used carefully to avoid security issues. Poor entropy sources or incorrect implementation can lead to vulnerabilities, as seen in past examples like the Netscape SSL and MediaWiki's use of non-cryptographic PRNGs.",
    "output": "the British Special Operations Executive during WWII, by KGB spies, by\nthe NSA, and is still used today in specific contexts. (I’ve heard of Swiss\nbankers who couldn’t agree on a cipher trusted by both parties and ended\nup using one-time pads, but I don’t recommend doing this.)\nWhy Is the One-Time Pad Secure?\nAlthough the one-time pad is not practical, it’s important to understand\nwhat makes it secure. In the 1940s, American mathematician Claude\nShannon proved that the one-time pad’s key must be at least as long as\nthe message to achieve perfect secrecy. The proof’s idea is fairly simple.\nYou assume that the attacker has unlimited power, and thus can try all the\nkeys. The goal is to encrypt such that the attacker can’t rule out any\npossible plaintext given some ciphertext.\nThe intuition behind the one-time pad’s perfect secrecy goes as\nfollows: if K is random, the resulting C looks as random as K to an\nattacker because the XOR of a random string with any fixed string yields\na random string. To see this, consider the probability of getting 0 as the\nfirst bit of a random string (namely, a probability of 1/2). What’s the\nprobability that a random bit XORed with the second bit is 0? Right, 1/2\nagain. The same argument can be iterated over bit strings of any length.\nThe ciphertext C thus looks random to an attacker that doesn’t know K,\nso it’s literally impossible to learn anything about P given C, even for an\nattacker with unlimited time and power. In other words, knowing the\nciphertext gives no information whatsoever about the plaintext except its\nlength—pretty much the definition of a secure cipher.\nFor example, if a ciphertext is 128 bits long (meaning the plaintext is\n128 bits as well), there are 2128 possible ciphertexts; therefore, there\nshould be 2128 possible plaintexts from the attacker’s point of view. But if\nthere are fewer than 2128 possible keys, the attacker can rule out some\nplaintexts. If the key is only 64 bits, for example, the attacker can\ndetermine the 264 possible plaintexts and rule out the overwhelming\nmajority of 128-bit strings. The attacker wouldn’t learn what the\nplaintext is, but they would learn what the plaintext is not, which makes\nthe encryption’s secrecy imperfect.\nAs you can see, you must have a key as long as the plaintext to achieve\nperfect security, but this quickly becomes impractical for real-world use.\nNext, I’ll discuss the approaches taken in modern-day encryption to\nachieve the best security that’s both possible and practical.\nPROBABILITY IN CRYPTOGRAPHY\nA probability is a number that expresses the\nlikelihood, or chance, of some event happening. It’s\nexpressed as a number between 0 and 1, where 0\nmeans “never” and 1 means “always.” The higher\nthe probability, the greater the chance. You’ll find\nmany explanations of probability, usually in terms of\nwhite balls and red balls in a bag and the probability\nof picking a ball of either color.\nCryptography often uses probabilities to measure\nan attack’s chances of success, by 1) counting the\nnumber of successful events (for example, the event\n“find the one correct secret key”) and 2) counting\nthe total number of possible events (for example, the\nn\ntotal number of keys is 2 if we deal with n-bit keys).\nIn this example, the probability that a randomly\nn\nchosen key is the correct one is 1/2 , or the count of\nsuccessful events (1 secret key) and the count of\nn n\npossible events (2 possible keys). The number 1/2\nis negligibly small for common key lengths such as\n128 and 256.\nThe probability of an event not happening is 1 – p,\nif the event’s probability is p. The probability of\ngetting a wrong key in our previous example is\nn\ntherefore 1 – 1/2 , a number very close to 1,\nmeaning almost certainty.\nEncryption Security\nYou’ve seen that classical ciphers aren’t secure and that a perfectly secure\ncipher like the one-time pad is impractical. We’ll thus have to give a little\nin terms of security if we want secure and usable ciphers. But what does\n“secure” really mean, besides the obvious and informal “eavesdroppers\ncan’t decrypt secure messages”?\nIntuitively, a cipher is secure if, even given a large number of plaintext–\nciphertext pairs, nothing can be learned about the cipher’s behavior when\napplied to other plaintexts or ciphertexts. This opens up new questions:\nHow does an attacker come by these pairs? How large is a “large\nnumber”? This is all defined by attack models, assumptions about\nwhat the attacker can and cannot do.\nWhat could be “learned” and what “cipher’s behavior” are we talking\nabout? This is defined by security goals, descriptions of what is\nconsidered a successful attack.\nAttack models and security goals must go together; you can’t claim that\na system is secure without explaining against whom or from what it’s safe.\nA security notion is thus the combination of some security goal with some\nattack model. We’ll say that a cipher achieves a certain security notion if\nany attacker working in a given model can’t achieve the security goal.\nAttack Models\nAn attack model is a set of assumptions about how attackers might\ninteract with a cipher and what they can and can’t do. The goals of an\nattack model are as follows:\nTo set requirements for cryptographers who design ciphers, so that\nthey know what attackers and what kinds of attacks to protect\nagainst.\nTo give guidelines to users, about whether a cipher will be safe to\nuse in their environment.\nTo provide clues for cryptanalysts who attempt to break ciphers, so\nthey know whether a given attack is valid. An attack is only valid if\nit’s doable in the model considered.\nAttack models don’t need to match reality exactly; they’re an\napproximation. As the statistician George E. P. Box put it, “all models are\nwrong; the practical question is how wrong do they have to be to not be\nuseful.” To be useful in cryptography, attack models should at least\nencompass what attackers can actually do to attack a cipher. It’s okay and\na good thing if a model overestimates attackers’ capabilities, because it\nhelps anticipate future attack techniques—only the paranoid\ncryptographers survive. A bad model underestimates attackers and\nprovides false confidence in a cipher by making it seem secure in theory\nwhen it’s not secure in reality.\nKerckhoffs’s Principle\nOne assumption made in all models is the so-called Kerckhoffs’s principle,\nwhich states that the security of a cipher should rely only on the secrecy\nof the key and not on the secrecy of the cipher. This may sound obvious\ntoday, when ciphers and protocols are publicly specified and used by\neveryone. But historically, Dutch linguist Auguste Kerckhoffs was\nreferring to military encryption machines specifically designed for a given\narmy or division. Quoting from his 1883 essay “La Cryptographie\nMilitaire,” where he listed six requirements of a military encryption\nsystem: “The system must not require secrecy and can be stolen by the\nenemy without causing trouble.”\nBlack-Box Models\nLet’s now consider some useful attack models expressed in terms of what\nthe attacker can observe and what queries they can make to the cipher. A\nquery for our purposes is the operation that sends an input value to some\nfunction and gets the output in return, without exposing the details of\nthat function.\nAn encryption query, for example, takes a plaintext and returns a\ncorresponding ciphertext, without revealing the secret key.\nWe call these models black-box models, because the attacker only sees\nwhat goes in and out of the cipher. For example, some smart card chips\nsecurely protect a cipher’s internals as well as its keys, yet you’re allowed\nto connect to the chip and ask it to decrypt any ciphertext. The attacker\nwould then receive the corresponding plaintext, which may help them\ndetermine the key. That’s a real example where decryption queries are\npossible.\nThere are several different black-box attack models. Here, I list them\nin order from weakest to strongest, describing attackers’ capabilities for\neach model:\nCiphertext-only attackers (COA) observe ciphertexts but don’t know\nthe associated plaintexts, and don’t know how the plaintexts were\nselected. Attackers in the COA model are passive and can’t perform\nencryption or decryption queries.\nKnown-plaintext attackers (KPA) observe ciphertexts and do know the\nassociated plaintexts. Attackers in the KPA model thus get a list of\nplaintext–ciphertext pairs, where plaintexts are assumed to be\nrandomly selected. Again, KPA is a passive attacker model.\nChosen-plaintext attackers (CPA) can perform encryption queries for\nplaintexts of their choice and observe the resulting ciphertexts. This\nmodel captures situations where attackers can choose all or part of\nthe plaintexts that are encrypted and then get to see the ciphertexts.\nUnlike COA or KPA, which are passive models, CPA are active\nattackers, because they influence the encryption processes rather\nthan passively eavesdropping.\nChosen-ciphertext attackers (CCA) can both encrypt and decrypt; that\nis, they get to perform encryption queries and decryption queries.\nThe CCA model may sound ludicrous at first—if you can decrypt,\nwhat else do you need?—but like the CPA model, it aims to\nrepresent situations where attackers can have some influence on the\nciphertext and later get access to the plaintext. Moreover, decrypting\nsomething is not always enough to break a system. For example,\nsome video-protection devices allow attackers to perform encryption\nqueries and decryption queries using the device’s chip, but in that\ncontext attackers are interested in the key in order to redistribute it;\nin this case, being able to decrypt “for free” isn’t sufficient to break\nthe system.\nIn the preceding models, ciphertexts that are observed as well as\nqueried don’t come for free. Each ciphertext comes from the\ncomputation of the encryption function. This means that generating 2n\nplaintext–ciphertext pairs through encryption queries takes about as much\ncomputation as trying 2n keys, for example. The cost of queries should be\ntaken into account when you’re computing the cost of an attack.\nGray-Box Models\nIn a gray-box model, the attacker has access to a cipher’s implementation.\nThis makes gray-box models more realistic than black-box models for\napplications such as smart cards, embedded systems, and virtualized\nsystems, to which attackers often have physical access and can thus\ntamper with the algorithms’ internals. By the same token, gray-box\nmodels are more difficult to define than black-box ones because they\ndepend on physical, analog properties rather than just on an algorithm’s\ninput and outputs, and crypto theory will often fail to abstract the\ncomplexity of the real world.\nSide-channel attacks are a family of attacks within gray-box models. A\nside channel is a source of information that depends on the\nimplementation of the cipher, be it in software or hardware. Side-channel\nattackers observe or measure analog characteristics of a cipher’s\nimplementation but don’t alter its integrity; they are noninvasive. For pure\nsoftware implementations, typical side channels are the execution time\nand the behavior of the system that surrounds the cipher, such as error\nmessages, return values, branches, and so on. In the case of\nimplementations on smart cards, for example, typical side-channel\nattackers measure power consumption, electromagnetic emanations, or\nacoustic noise.\nInvasive attacks are a family of attacks on cipher implementations that\nare more powerful than side-channel attacks, and more expensive because\nthey require sophisticated equipment. You can run basic side-channel\nattacks with a standard PC and an off-the-shelf oscilloscope, but invasive\nattacks require tools such as a high-resolution microscopes and a\nchemical lab. Invasive attacks thus consist of a whole set of techniques\nand procedures, from using nitric acid to remove a chip’s packaging to\nmicroscopic imagery acquisition, partial reverse engineering, and possible\nmodification of the chip’s behavior with something like laser fault\ninjection.\nSecurity Goals\nI’ve informally defined the goal of security as “nothing can be learned\nabout the cipher’s behavior.” To turn this idea into a rigorous\nmathematical definition, cryptographers define two main security goals\nthat correspond to different ideas of what it means to learn something\nabout a cipher’s behavior:\nIndistinguishability (IND) Ciphertexts should be indistinguishable\nfrom random strings. This is usually illustrated with this hypothetical\ngame: if an attacker picks two plaintexts and then receives a ciphertext\nof one of the two (chosen at random), they shouldn’t be able to tell\nwhich plaintext was encrypted, even by performing encryption queries\nwith the two plaintexts (and decryption queries, if the model is CCA\nrather than CPA).\nNon-malleability (NM) Given a ciphertext C = E(K, P ), it should be\n1 1\nimpossible to create another ciphertext, C , whose corresponding\n2\nplaintext, P , is related to P in a meaningful way (for example, to\n2 1\ncreate a P that is equal to P ⊕ 1 or to P ⊕ X for some known value X).\n2 1 1\nSurprisingly, the one-time pad is malleable: given a ciphertext C = P\n1 1\n⊕ K, you can define C = C ⊕ 1, which is a valid ciphertext of P = P ⊕\n2 1 2 1\n1 under the same key K. Oops, so much for our perfect cipher.\nNext, I’ll discuss these security goals in the context of different attack\nmodels.\nSecurity Notions\nSecurity goals are only useful when combined with an attack model. The\nconvention is to write a security notion as GOAL-MODEL. For example,\nIND-CPA denotes indistinguishability against chosen-plaintext attackers,\nNM-CCA denotes nonmalleability against chosen-ciphertext attackers,\nand so on. Let’s start with the security goals for an attacker.\nSemantic Security and Randomized Encryption: IND-CPA\nThe most important security notion is IND-CPA, also called semantic\nsecurity. It captures the intuition that ciphertexts shouldn’t leak any\ninformation about plaintexts as long as the key is secret. To achieve IND-\nCPA security, encryption must return different ciphertexts if called twice\non the same plaintext; otherwise, an attacker could identify duplicate\nplaintexts from their ciphertexts, contradicting the definition that\nciphertexts shouldn’t reveal any information.\nOne way to achieve IND-CPA security is to use randomized encryption.\nAs the name suggests, it randomizes the encryption process and returns\ndifferent ciphertexts when the same plaintext is encrypted twice.\nEncryption can then be expressed as C = E(K, R, P), where R is fresh\nrandom bits. Decryption remains deterministic, however, because given\nE(K, R, P), you should always get P, regardless of the value of R.\nWhat if encryption isn’t randomized? In the IND game introduced in\n“Security Goals” on page 12, the attacker picks two plaintexts, P and P ,\n1 2\nand receives a ciphertext of one of the two, but doesn’t know which\nplaintext the ciphertext corresponds to. That is, they get C = E(K, P ) and\ni i\nhave to guess whether i is 1 or 2. In the CPA model, the attacker can\nperform encryption queries to determine both C = E(K, P ) and C =\n1 1 2\nE(K, P ). If encryption isn’t randomized, it suffices to see if C is equal to\n2 i\nC or to C in order to determine which plaintext was encrypted and\n1 2\nthereby win the IND game. Therefore, randomization is key to the IND-\nCPA notion.\nNOTE\nWith randomized encryption, ciphertexts must be slightly longer than\nplaintexts in order to allow for more than one possible ciphertext per\nplaintext. For example, if there are 264 possible ciphertexts per plaintext,\nciphertexts must be at least 64 bits longer than plaintexts.\nAchieving Semantically Secure Encryption\nOne of the simplest constructions of a semantically secure cipher uses a\ndeterministic random bit generator (DRBG), an algorithm that returns\nrandom-looking bits given some secret value:\nE(K, R, P) = (DRBG(K R) ⊕ P, R)\nHere, R is a string randomly chosen for each new encryption and given\nto a DRBG along with the key (K || R denotes the string consisting of K\nfollowed by R). This approach is reminiscent of the one-time pad: instead\nof picking a random key of the same length as the message, we leverage a\nrandom bit generator to get a random-looking string.\nThe proof that this cipher is IND-CPA secure is simple, if we assume\nthat the DRBG produces random bits. The proof works ad absurdum: if\nyou can distinguish ciphertexts from random strings, which means that\nyou can distinguish DRBG(K || R) ⊕ P from random, then this means\nthat you can distinguish DRBG(K || R) from random. Remember that\nthe CPA model lets you get ciphertexts for chosen values of P, so you can\nXOR P to DRBG(K, R) ⊕ P and get DRBG(K, R). But now we have a\ncontradiction, because we started by assuming that DRBG(K, R) can’t be\ndistinguished from random, producing random strings. So we conclude\nthat ciphertexts can’t be distinguished from random strings, and therefore\nthat the cipher is secure.\nNOTE\nAs an exercise, try to determine what other security notions are satisfied by\nthe above cipher E(K, R, P) = (DRBG(K || R) ⊕ P, R). Is it NM-CPA?\nIND-CCA? You’ll find the answers in the next section.\nComparing Security Notions\nYou’ve learned that attack models such as CPA and CCA are combined\nwith security goals such as NM and IND to build the security notions\nNM-CPA, NM-CCA, IND-CPA, and IND-CCA. How are these\nnotions related? Can we prove that satisfying notion X implies satisfying\nnotion Y?\nSome relations are obvious: IND-CCA implies IND-CPA, and NM-\nCCA implies NM-CPA, because anything a CPA attacker can do, a CCA\nattacker can do as well. That is, if you can’t break a cipher by performing\nchosen-ciphertext and chosen-plaintext queries, you can’t break it by\nperforming chosen-plaintext queries only.\nA less obvious relation is that IND-CPA does not imply NM-CPA. To\nunderstand this, observe that the previous IND-CPA construction\n(DRBG(K, R) ⊕ P, R) is not NM-CPA: given a ciphertext (X, R), you can\ncreate the ciphertext (X ⊕ 1, R), which is a valid ciphertext of P ⊕ 1, thus\ncontradicting the notion of non-malleability.\nBut the opposite relation does hold: NM-CPA implies IND-CPA. The\nintuition is that IND-CPA encryption is like putting items in a bag: you\ndon’t get to see them, but you can rearrange their positions in the bag by\nshaking it up and down. NM-CPA is more like a safe: once inside, you\ncan’t interact with what you put in there. But this analogy doesn’t work\nfor IND-CCA and NM-CCA, which are equivalent notions that each\nimply the presence of the other. I’ll spare you the proof, which is pretty\ntechnical.\nTWO TYPES OF ENCRYPTION APPLICATIONS\nThere are two main types of encryption\napplications. In-transit encryption protects data sent\nfrom one machine to another: data is encrypted\nbefore being sent and decrypted after being\nreceived, as in encrypted connections to e-\ncommerce websites. At-rest encryption protects data\nstored on an information system. Data is encrypted\nbefore being written to memory and decrypted\nbefore being read. Examples include disk encryption\nsystems on laptops as well as virtual machine\nencryption for cloud virtual instances. The security\nnotions we’ve seen apply to both types of\napplications, but the right notion to consider may\ndepend on the application.\nAsymmetric Encryption\nSo far we’ve considered only symmetric encryption, where two parties\nshare a key. In asymmetric encryption, there are two keys: one to encrypt\nand another to decrypt. The encryption key is called a public key and is\ngenerally considered publicly available to anyone who wants to send you\nencrypted messages. The decryption key, however, must remain secret\nand is called a private key.\nThe public key can be computed from the private key, but obviously\nthe private key can’t be computed from the public key. In other words,\nit’s easy to compute in one direction, but not in the other—and that’s the\npoint of public-key cryptography, whose functions are easy to compute in\none direction but practically impossible to invert.\nThe attack models and security goals for asymmetric encryption are\nabout the same as for symmetric encryption, except that because the\nencryption key is public, any attacker can make encryption queries by\nusing the public key to encrypt. The default model for asymmetric\nencryption is therefore the chosen-plaintext attacker (CPA).\nSymmetric and asymmetric encryption are the two main types of\nencryption, and they are usually combined to build secure\ncommunication systems. They’re also used to form the basis of more\nsophisticated schemes, as you’ll see next.\nWhen Ciphers Do More Than Encryption\nBasic encryption turns plaintexts into ciphertexts and ciphertexts into\nplaintexts, with no requirements other than security. However, some\napplications often need more than that, be it extra security features or\nextra functionalities. That’s why cryptographers created variants of\nsymmetric and asymmetric encryption. Some are well-understood,\nefficient, and widely deployed, while others are experimental, hardly used,\nand offer poor performance.\nAuthenticated Encryption\nAuthenticated encryption (AE) is a type of symmetric encryption that\nreturns an authentication tag in addition to a ciphertext. Figure 1-4 shows\nauthenticated encryption sets AE(K, P) = (C, T), where the authentication\ntag T is a short string that’s impossible to guess without the key.\nDecryption takes K, C, and T and returns the plaintext P only if it verifies\nthat T is a valid tag for that plaintext–ciphertext pair; otherwise, it aborts\nand returns some error.\nFigure 1-4: Authenticated encryption\nThe tag ensures the integrity of the message and serves as evidence that\nthe ciphertext received is identical to the one sent in the first place by a\nlegitimate party that knows the key K. When K is shared with only one\nother party, the tag also guarantees that the message was sent by that\nparty; that is, it implicitly authenticates the expected sender as the actual\ncreator of the message.\nNOTE\nI use “creator” rather than “sender” here because an eavesdropper can record\nsome (C, T) pairs sent by party A to party B and then send them again to B,\npretending to be A. This is called a replay attack, and it can be prevented, for\nexample, by including a counter number in the message. When a message is\ndecrypted, its counter i is increased by one: i + 1. In this way, one could check\nthe counter to see if a message has been sent twice, indicating that an attacker\nis attempting a replay attack by resending the message. This also enables the\ndetection of lost messages.\nAuthenticated encryption with associated data (AEAD) is an extension of\nauthenticated encryption that takes some cleartext and unencrypted data\nand uses it to generate the authentication tag AEAD(K, P, A) = (C, T). A\ntypical application of AEAD is used to protect protocols’ datagrams with\na cleartext header and an encrypted payload. In such cases, at least some\nheader data has to remain in the clear; for example, destination addresses\nneed to be clear in order to route network packets.\nFor more on authenticated encryption, jump to Chapter 8.\nFormat-Preserving Encryption\nA basic cipher takes bits and returns bits; it doesn’t care whether bits\nrepresents text, an image, or a PDF document. The ciphertext may in\nturn be encoded as raw bytes, hexadecimal characters, base64, and other\nformats. But what if you need the ciphertext to have the same format as\nthe plaintext, as is sometimes required by database systems that can only\nrecord data in a prescribed format?\nFormat-preserving encryption (FPE) solves this problem. It can create\nciphertexts that have the same format as the plaintext. For example, FPE\ncan encrypt IP addresses to IP addresses (as shown in Figure 1-5), ZIP\ncodes to ZIP codes, credit card numbers to credit card numbers with a\nvalid checksum, and so on.\nFigure 1-5: Format-preserving encryption for IP addresses\nFully Homomorphic Encryption\nFully homomorphic encryption (FHE) is the holy grail to cryptographers: it\nenables its users to replace a ciphertext, C = E(K, P), with another\nciphertext, C′ = E(K, F(P)), for F(P) can be any function of P, and without\never decrypting the initial ciphertext C. For example, P can be a text\ndocument, and F can be the modification of part of the text. You can\nimagine a cloud application that stores your encrypted data, but where\nthe cloud provider doesn’t know what the data is or the type of changes\nmade when you change that data. Sounds amazing, doesn’t it?\nBut there’s a flip side: this type of encryption is slow—so slow that even\nthe most basic operation would take an unacceptably long time. The first\nFHE scheme was created in 2009, and since then more efficient variants\nappeared, but it remains unclear whether FHE will ever be fast enough to\nbe useful.\nSearchable Encryption\nSearchable encryption enables searching over an encrypted database without\nleaking the searched terms by encrypting the search query itself. Like\nfully homomorphic encryption, searchable encryption could enhance the\nprivacy of many cloud-based applications by hiding your searches from\nyour cloud provider. Some commercial solutions claim to offer searchable\nencryption, though they’re mostly based on standard cryptography with a\nfew tricks to enable partial searchability. As of this writing, however,\nsearchable encryption remains experimental within the research\ncommunity.\nTweakable Encryption\nTweakable encryption (TE) is similar to basic encryption, except for an\nadditional parameter called the tweak, which aims to simulate different\nversions of a cipher (see Figure 1-6). The tweak might be a unique per-\ncustomer value to ensure that a customer’s cipher can’t be cloned by\nother parties using the same product, but the main application of TE is\ndisk encryption. However, TE is not bound to a single application and is a\nlower-level type of encryption used to build other schemes, such as\nauthentication encryption modes.\nFigure 1-6: Tweakable encryption\nIn disk encryption, TE encrypts the content of storage devices such as\nhard drives or solid-state drives. (Randomized encryption can’t be used\nbecause it increases the size of the data, which is unacceptable for files on\nstorage media.) To make encryption unpredictable, TE uses a tweak\nvalue that depends on the position of the data encrypted, which is usually\na sector number or a block index.\nHow Things Can Go Wrong\nEncryption algorithms or implementations thereof can fail to protect\nconfidentiality in many ways. This can be due to a failure to match the\nsecurity requirements (such as “be IND-CPA secure”) or to set\nrequirements matching reality (if you target only IND-CPA security\nwhen attackers can actually perform chosen-ciphertext queries). Alas,\nmany engineers don’t even think about cryptographic security\nrequirements and just want to be “secure” without understanding what\nthat actually means. That’s usually a recipe for disaster. Let’s look at two\nexamples.\nWeak Cipher\nOur first example concerns ciphers that can be attacked using\ncryptanalysis techniques, as occurred with the 2G mobile communication\nstandard. Encryption in 2G mobile phones used a cipher called A5/1 that\nturned out to be weaker than expected, enabling the interception of calls\nby anyone with the right skills and tools. Telecommunication operators\nhad to find workarounds to prevent the attack.\nNOTE\nThe 2G standard also defined A5/2, a cipher for areas other than the EU\nand US. A5/2 was purposefully weaker to prevent the use of strong\nencryption everywhere.\nThat said, attacking A5/1 isn’t trivial, and it took more than 10 years\nfor researchers to come up with an effective cryptanalysis method.\nFurthermore, the attack is a time-memory trade-off (TMTO), a type of\nmethod that first runs computations for days or weeks in order to build\nlarge look-up tables, which are subsequently used for the actual attack.\nFor A5/1, the precomputed tables are more than 1TB. Later standards\nfor mobile encryption, such as 3G and LTE, specify stronger ciphers, but\nthat doesn’t mean that their encryption won’t be compromised; rather, it\nsimply means that the encryption won’t be compromised by breaking the\nsymmetric cipher that’s part of the system.\nWrong Model\nThe next example concerns an invalid attack model that overlooked some\nside channels.\nMany communication protocols that use encryption ensure that they\nuse ciphers considered secure in the CPA or CCA model. However, some\nattacks don’t require encryption queries, as in the CPA model, nor do\nthey require decryption queries, as in the CCA model. They simply need\nvalidity queries to tell whether a ciphertext is valid, and these queries are\nusually sent to the system responsible for decrypting ciphertexts. Padding\noracle attacks are an example of such attacks, wherein an attacker learns\nwhether a ciphertext conforms to the required format.\nSpecifically, in the case of padding oracle attacks, a ciphertext is valid\nonly if its plaintext has the proper padding, a sequence of bytes appended\nto the plaintext to simplify encryption. Decryption fails if the padding is\nincorrect, and attackers can often detect decryption failures and attempt\nto exploit them. For example, the presence of the Java exception\njavax.crypto.BadPaddingException would indicate that an incorrect padding\nwas observed.\nIn 2010, researchers found padding oracle attacks in several web\napplication servers. The validity queries consisted of sending a ciphertext\nto some system and observing whether it threw an error. Thanks to these\nqueries, they could decrypt otherwise secure ciphertexts without knowing\nthe key.\nCryptographers often overlook attacks like padding oracle attacks\nbecause they usually depend on an application’s behavior and on how\nusers can interact with the application. But if you don’t anticipate such\nattacks and fail to include them in your model when designing and\ndeploying cryptography, you may have some nasty surprises.\nFurther Reading\nWe discuss encryption and its various forms in more detail throughout\nthis book, especially how modern, secure ciphers work. Still, we can’t\ncover everything, and many fascinating topics won’t be discussed. For\nexample, to learn the theoretical foundations of encryption and gain a\ndeeper understanding of the notion of indistinguishability (IND), you\nshould read the 1982 paper that introduced the idea of semantic security,\n“Probabilistic Encryption and How to Play Mental Poker Keeping Secret\nAll Partial Information” by Goldwasser and Micali. If you’re interested in\nphysical attacks and cryptographic hardware, the proceedings of the\nCHES conference are the main reference.\nThere are also many more types of encryption than those presented in\nthis chapter, including attribute-based encryption, broadcast encryption,\nfunctional encryption, identity-based encryption, message-locked\nencryption, and proxy re-encryption, to cite but a few. For the latest\nresearch on those topics, you should check https://eprint.iacr.org/, an\nelectronic archive of cryptography research papers.\n2\nRANDOMNESS\nRandomness is found everywhere in cryptography: in the generation of\nsecret keys, in encryption schemes, and even in the attacks on\ncryptosystems. Without randomness, cryptography would be impossible\nbecause all operations would become predictable, and therefore insecure.\nThis chapter introduces you to the concept of randomness in the\ncontext of cryptography and its applications. We discuss pseudorandom\nnumber generators and how operating systems can produce reliable\nrandomness, and we conclude with real examples showing how flawed\nrandomness can impact security.\nRandom or Non-Random?\nYou’ve probably already heard the phrase “random bits,” but strictly\nspeaking there is no such thing as a series of random bits. What is\nrandom is actually the algorithm or process that produces a series of\nrandom bits; therefore, when we say “random bits,” we actually mean\nrandomly generated bits.\nWhat do random bits look like? For example, to most people, the 8-bit\nstring 11010110 is more random than 00000000, although both have the\nsame chance of being generated (namely, 1/256). The value 11010110\nlooks more random than 00000000 because it has the signs typical of a\nrandomly generated value. That is, 11010110 has no obvious pattern.\nWhen we see the string 11010110, our brain registers that it has about\nas many zeros (three) as it does ones (five), just like 55 other 8-bit strings\n(11111000, 11110100, 11110010, and so on), but only one 8-bit string has\neight zeros. Because the pattern three-zeros-and-five-ones is more likely\nto occur than the pattern eight-zeros, we identify 11010110 as random\nand 00000000 as non-random, and if a program produces the bits\n11010110, you may think that it’s random, even if it’s not. Conversely, if\na randomized program produces 00000000, you’ll probably doubt that it’s\nrandom.\nThis example illustrates two types of errors people often make when\nidentifying randomness:\nMistaking non-randomness for randomness Thinking that an\nobject was randomly generated simply because it looks random.\nMistaking randomness for non-randomness Thinking that patterns\nappearing by chance are there for a reason other than chance.\nThe distinction between random-looking and actually random is\ncrucial. Indeed, in crypto, non-randomness is often synonymous with\ninsecurity.\nRandomness as a Probability Distribution\nAny randomized process is characterized by a probability distribution,\nwhich gives all there is to know about the randomness of the process. A\nprobability distribution, or simply distribution, lists the outcomes of a\nrandomized process where each outcome is assigned a probability.\nA probability measures the likelihood of an event occurring. It’s\nexpressed as a real number between 0 and 1 where a probability 0 means\nimpossible and a probability of 1 means certain. For example, when\ntossing a two-sided coin, each side has a probability of landing face up of\n1/2, and we usually assume that landing on the edge of the coin has\nprobability zero.\nA probability distribution must include all possible outcomes, such that\nthe sum of all probabilities is 1. Specifically, if there are N possible events,\nthere are N probabilities p , p , . . . , p with p + p + . . . + p = 1. In the\n1 2 N 1 2 N\ncase of the coin toss, the distribution is 1/2 for heads and 1/2 for tails.\nThe sum of both probabilities is equal to 1/2 + 1/2 = 1, because the coin\nwill fall on one of its two faces.\nA uniform distribution occurs when all probabilities in the distribution\nare equal, meaning that all outcomes are equally likely to occur. If there\nare N events, then each event has probability 1/N. For example, if a 128-\nbit key is picked uniformly at random—that is, according to a uniform\ndistribution—then each of the 2128 possible keys should have a\nprobability of 1/2128.\nIn contrast, when a distribution is non-uniform, probabilities aren’t all\nequal. A coin toss with a non-uniform distribution is said to be biased,\nand may yield heads with probability 1/4 and tails with probability 3/4,\nfor example.\nEntropy: A Measure of Uncertainty\nEntropy is the measure of uncertainty, or disorder in a system. You might\nthink of entropy as the amount of surprise found in the result of a\nrandomized process: the higher the entropy, the less the certainty found\nin the result.\nWe can compute the entropy of a probability distribution. If your\ndistribution consists of probabilities p , p , . . . , p , then its entropy is the\n1 2 N\nnegative sum of all probabilities multiplied by their logarithm, as shown\nin this expression:\n−p × log(p ) − p × log(p ) − ... p × log(p )\n1 1 2 2 N N\nHere the function log is the binary logarithm, or logarithm in base two.\nUnlike the natural logarithm, the binary logarithm expresses the\ninformation in bits and yields integer values when probabilities are\npowers of two. For example, log(1/2) = –1, log(1/4) = –2, and more\ngenerally log(1/2 ) = –n. (That’s why we actually take the negative sum, in\nN\norder to end up with a positive number.) Random 128-bit keys produced\nusing a uniform distribution therefore have the following entropy:\n2128 × (−2−128 × log(2−128)) = −log(2−128) = 128 bits\nIf you replace 128 by any integer n you will find that the entropy of a\nuniformly distributed n-bit string will be n bits.\nEntropy is maximized when the distribution is uniform because a\nuniform distribution maximizes uncertainty: no outcome is more likely\nthan the others. Therefore, n-bit values can’t have more than n bits of\nentropy.\nBy the same token, when the distribution is not uniform, entropy is\nlower. Consider the coin toss example. The entropy of a fair toss is the\nfollowing:\n−(1/2) × log (1/2) − (1/2) × log (1/2) = 1/2 + 1/2 = 1 bit\nWhat if one side of the coin has a higher probability of landing face up\nthan the other? Say heads has a probability of 1/4 and tails 3/4 (remember\nthat the sum of all probabilities should be 1).\nThe entropy of such a biased toss is this:\n−(3/4) × log(3/4) − (1/4) × log(1/4) ≈ −(3/4) × (−0.415) − (1/4) × (−2) ≈ 0.81\nbit\nThe fact that 0.81 is less than the 1-bit entropy of a fair toss tells us\nthat the more biased the coin, the less uniform the distribution and the\nlower the entropy. Taking this example further, if heads has a probability\nof 1/10, the entropy is 0.469; if the probability drops to 1/100, the\nentropy drops to 0.081.\nNOTE\nEntropy can also be viewed as a measure of information. For example, the\nresult of a fair coin toss gives you exactly one bit of information—heads or\ntails—and you’re unable to predict the result of the toss in advance. In the\ncase of the unfair coin toss, you know in advance that tails is more probable,\nso you can usually predict the outcome of the toss. The result of the coin toss\ngives you the information needed to predict the result with certainty.\nRandom Number Generators (RNGs) and Pseudorandom\nNumber Generators (PRNGs)\nCryptosystems need randomness to be secure and therefore need a\ncomponent from which to get their randomness. The job of this\ncomponent is to return random bits when requested to do so. How is this\nrandomness generation done? You’ll need two things:\nA source of uncertainty, or source of entropy, provided by random\nnumber generators (RNGs).\nA cryptographic algorithm to produce high-quality random bits from\nthe source of entropy. This is found in pseudorandom number\ngenerators (PRNGs).\nUsing RNGs and PRNGs is the key to making cryptography practical\nand secure. Let’s briefly look at how RNGs work before exploring\nPRNGs in depth.\nRandomness comes from the environment, which is analog, chaotic,\nuncertain, and hence unpredictable. Randomness can’t be generated by\ncomputer-based algorithms alone. In cryptography, randomness usually\ncomes from random number generators (RNGs), which are software or\nhardware components that leverage entropy in the analog world to\nproduce unpredictable bits in a digital system. For example, an RNG\nmight directly sample bits from measurements of temperature, acoustic\nnoise, air turbulence, or electrical static. Unfortunately, such analog\nentropy sources aren’t always available, and their entropy is often difficult\nto estimate.\nRNGs can also harvest the entropy in a running operating system by\ndrawing from attached sensors, I/O devices, network or disk activity,\nsystem logs, running processes, and user activities such as key presses and\nmouse movement. Such system- and human-generated activities can be a\ngood source of entropy, but they can be fragile and manipulated by an\nattacker. Also, they’re slow to yield random bits.\nQuantum random number generators (QRNGs) are a type of RNG that\nrelies on the randomness arising from quantum mechanical phenomena\nsuch as radioactive decay, vacuum fluctuations, and observing photons’\npolarization. These can provide real randomness, rather than just\napparent randomness. However, in practice, QRNGs may be biased and\ndon’t produce bits quickly; like the previously cited entropy sources, they\nneed an additional component to produce reliably at high speed.\nPseudorandom number generators (PRNGs) address the challenge we face\nin generating randomness by reliably producing many artificial random\nbits from a few true random bits. For example, an RNG that translates\nmouse movements to random bits would stop working if you stop moving\nthe mouse, whereas a PRNG always returns pseudorandom bits when\nrequested to do so.\nPRNGs rely on RNGs but behave differently: RNGs produce true\nrandom bits relatively slowly from analog sources, in a nondeterministic\nway, and with no guarantee of high entropy. In contrast, PRNGs produce\nrandom-looking bits quickly from digital sources, in a deterministic way,\nand with maximum entropy. Essentially, PRNGs transform a few\nunreliable random bits into a long stream of reliable pseudorandom bits\nsuitable for crypto applications, as shown in Figure 2-1.\nFigure 2-1: RNGs produce few unreliable bits from analog sources, whereas PRNGs\nexpand those bits to a long stream of reliable bits.\nHow PRNGs Work\nA PRNG receives random bits from an RNG at regular intervals and uses\nthem to update the contents of a large memory buffer, called the entropy\npool. The entropy pool is the PRNG’s source of entropy, just like the\nphysical environment is to an RNG. When the PRNG updates the\nentropy pool, it mixes the pool’s bits together to help remove any\nstatistical bias.\nIn order to generate pseudorandom bits, the PRNG runs a\ndeterministic random bit generator (DRBG) algorithm that expands some\nbits from the entropy pool into a much longer sequence. As its name\nsuggests, a DRBG is deterministic, not randomized: given one input you\nwill always get the same output. The PRNG ensures that its DRBG never\nreceives the same input twice, in order to generate unique pseudorandom\nsequences.\nIn the course of its work, the PRNG performs three operations, as\nfollows:\ninit() Initializes the entropy pool and the internal state of the PRNG\nrefresh(R) Updates the entropy pool using some data, R, usually\nsourced from an RNG\nnext(N) Returns N pseudorandom bits and updates the entropy pool\nThe init operation resets the PRNG to a fresh state, reinitializes the\nentropy pool to some default value, and initializes any variables or\nmemory buffers used by the PRNG to carry out the refresh and next\noperations.\nThe refresh operation is often called reseeding, and its argument R is\ncalled a seed. When no RNG is available, seeds may be unique values\nhardcoded in a system. The refresh operation is typically called by the\noperating system, whereas next is typically called or requested by\napplications. The next operation runs the DRBG and modifies the\nentropy pool to ensure that the next call will yield different\npseudorandom bits.\nSecurity Concerns\nLet’s talk briefly about the way that PRNGs address some high-level\nsecurity concerns. Specifically, PRNGs should guarantee backtracking\nresistance and prediction resistance. Backtracking resistance (also called\nforward secrecy) means that previously generated bits are impossible to\nrecover, whereas prediction resistance (backward secrecy) means that future\nbits should be impossible to predict.\nIn order to achieve backtracking resistance, the PRNG should ensure\nthat the transformations performed when updating the state through the\nrefresh and next operations are irreversible so that if an attacker\ncompromises the system and obtains the entropy pool’s value, they can’t\ndetermine the previous values of the pool or the previously generated\nbits. To achieve prediction resistance, the PRNG should call refresh\nregularly with R values that are unknown to an attacker and that are\ndifficult to guess, thus preventing an attacker from determining future\nvalues of the entropy pool, even if the whole pool is compromised. (Even\nif the list of R values used were known, you’d need to know the order in\nwhich refresh and next calls were made in order to reconstruct the pool.)\nThe PRNG Fortuna\nFortuna is a PRNG construction used in Windows originally designed in\n2003 by Niels Ferguson and Bruce Schneier. Fortuna superseded Yarrow,\na 1998 design by Kelsey and Schneier now used in the macOS and iOS\noperating systems. I won’t provide the Fortuna specification here or show\nyou how to implement it, but I will try to explain how it works. You’ll\nfind a complete description of Fortuna in Chapter 9 of Cryptography\nEngineering by Ferguson, Schneier, and Kohno (Wiley, 2010).\nFortuna’s internal memory includes the following:\nThirty-two entropy pools, P , P , . . . , P , such that P is used every\n1 2 32 i\n2i reseeds.\nA key, K, and a counter, C (both 16 bytes). These form the internal\nstate of Fortuna’s DRBG.\nIn simplest terms, Fortuna works like this:\ninit() sets K and C to zero and empties the 32 entropy pools P , where\ni\ni = 1 . . . 32.\nrefresh(R) appends the data, R, to one of the entropy pools. The\nsystem chooses the RNGs used to produce R values, and it should\ncall refresh regularly.\nnext(N) updates K using data from one or more entropy pools, where\nthe choice of the entropy pools depends mainly on how many\nupdates of K have already been done. The N bits requested are then\nproduced by encrypting C using K as a key. If encrypting C is not\nenough, Fortuna encrypts C + 1, then C + 2, and so on, to get\nenough bits.\nAlthough Fortuna’s operations look fairly simple, implementing them\ncorrectly is hard. For one thing, you need to get all the details of the\nalgorithm right—namely, how entropy pools are chosen, the type of\ncipher to be used in next, how to behave when no entropy is received, and\nso on. Although the specs define most of the details, they don’t include a\ncomprehensive test suite to check that an implementation is correct,\nwhich makes it difficult to ensure that your implementation of Fortuna\nwill behave as expected.\nEven if Fortuna is correctly implemented, security failures may occur\nfor reasons other than the use of an incorrect algorithm. For example,\nFortuna might not notice if the RNGs fail to produce enough random\nbits, and as a result Fortuna will produce lower-quality pseudorandom\nbits, or it may stop delivering pseudorandom bits altogether.\nAnother risk inherent in Fortuna implementations lies in the possibility\nof exposing associated seed files to attackers. The data in Fortuna seed files\nis used to feed entropy to Fortuna through refresh calls when an RNG is\nnot immediately available, such as immediately after a system reboot and\nbefore the system’s RNGs have recorded any unpredictable events.\nHowever, if an identical seed file is used twice, then Fortuna will produce\nthe same bit sequence twice. Seed files should therefore be erased after\nbeing used to ensure that they aren’t reused.\nFinally, if two Fortuna instances are in the same state because they are\nsharing a seed file (meaning they are sharing the same data in the entropy\npools, including the same C and K), then the next operation will return\nthe same bits in both instances.\nCryptographic vs. Non-Cryptographic PRNGs\nThere are both cryptographic and non-cryptographic PRNGs. Non-\ncrypto PRNGs are designed to produce uniform distributions for\napplications such as scientific simulations or video games. However, you\nshould never use non-crypto PRNGs in crypto applications, because\nthey’re insecure—they’re only concerned with the quality of the bits’\nprobability distribution and not with their predictability. Crypto PRNGs,\non the other hand, are unpredictable, because they’re also concerned with\nthe strength of the underlying operations used to deliver well-distributed\nbits.\nUnfortunately, most PRNGs exposed by programming languages, such\nas libc’s rand and drand48, PHP’s rand and mt_rand, Python’s random\nmodule, Ruby’s Random class, and so on, are non-cryptographic. Defaulting\nto a non-crypto PRNG is a recipe for disaster because it often ends up\nbeing used in crypto applications, so be sure to use only crypto PRNGs in\ncrypto applications.\nA Popular Non-Crypto PRNG: Mersenne Twister\nThe Mersenne Twister (MT) algorithm is a non-cryptographic PRNG\nused (at the time of this writing) in PHP, Python, R, Ruby, and many\nother systems. MT will generate uniformly distributed random bits\nwithout statistical bias, but it’s predictable: given a few bits produced by\nMT, it’s easy enough to tell which bits will follow.\nLet’s look under the hood to see what makes the Mersenne Twister\ninsecure. The MT algorithm is much simpler than that of crypto\nPRNGs: its internal state is an array, S, consisting of 624 32-bit words.\nThis array is initially set to S , S , . . . , S and evolves to S , . . . , S ,\n1 2 624 2 625\nthen S , . . . , S , and so on, according to this equation:\n3 626\nS = S ⊕ A((S ∧ 0x80000000) ∨ (S ∧ 0xfffffff))\nk + 624 k + 397 k k + 1\nHere, ⊕ denotes the bitwise XOR (^ in the C programming language),\n∧ denotes the bitwise AND (& in C), ∨ denotes the bitwise OR (| in C),\nand A is a function that transforms some 32-bit word, x, to (x >> 1), if x’s\nmost significant bit is 0, or to (x >> 1) ⊕ 0x9908b0df otherwise.\nNotice in this equation that bits of S interact with each other only\nthrough XORs. The operators ∧ and ∨ never combine two bits of S\ntogether, but just bits of S with bits from the constants 0x80000000 and\n0x7fffffff. This way, any bit from S can be expressed as an XOR of bits\n625\nfrom S , S , and S , and any bit from any future state can be expressed\n398 1 2\nas an XOR combination of bits from the initial state S , . . . , S . (When\n1 624\nyou express, say, S = S as a function of S , S , and S , you\n228 + 624 852 625 228 229\ncan in turn replace S by its expression in terms of S , S , and S .)\n625 398 1 2\nBecause there are exactly 624 × 32 = 19,968 bits in the initial state (or\n624 32-bit words), any output bit can be expressed as an equation with at\nmost 19,969 terms (19,968 bits plus one constant bit). That’s just about\n2.5 kilobytes of data. The converse is also true: bits from the initial state\ncan be expressed as an XOR of output bits.\nLinearity Insecurity\nWe call an XOR combination of bits a linear combination. For example, if\nX, Y, and Z are bits, then the expression X ⊕ Y ⊕ Z is a linear combination,\nwhereas (X ∧ Y) ⊕ Z is not because there’s an AND (∧). If you flip a bit\nof X in X ⊕ Y ⊕ Z, then the result changes as well, regardless of the value\nof the Y and Z. In contrast, if you flip a bit of X in (X ∧ Y) ⊕ Z, the result\nchanges only if Y’s bit at the same position is 1. The upshot is that linear\ncombinations are predictable, because you don’t need to know the value\nof the bits in order to predict how a change in their value will affect the\nresult.\nFor comparison, if the MT algorithm were cryptographically strong, its\nequations would be nonlinear and would involve not only single bits but\nalso AND-combinations (products) of bits, such as S S S or\n1 15 182\nS S S S S S . Although linear combinations of those bits\n17 256 257 354 498 601\ninclude at most 624 variables, nonlinear combinations allow for up to 2624\nvariables. It would be impossible to solve, let alone write down the whole\nof these equations. (Note that 2305, a much smaller number, is the\nestimated information capacity of the observable universe.)\nThe key here is that linear transformations lead to short equations\n(comparable in size to the number of variables), which are easy to solve,\nwhereas nonlinear transformations give rise to equations of exponential\nsize, which are practically unsolvable. The game of cryptographers is thus\nto design PRNG algorithms that emulate such complex nonlinear\ntransformations using only a small number of simple operations.\nNOTE\nLinearity is just one of many security criteria. Although necessary,\nnonlinearity alone does not make a PRNG cryptographically secure.\nThe Uselessness of Statistical Tests\nStatistical test suites like TestU01, Diehard, or the National Institute of\nStandards and Technology (NIST) test suite are one way to test the\nquality of pseudorandom bits. These tests take a sample of pseudorandom\nbits produced by a PRNG (say, one megabyte worth), compute some\nstatistics on the distribution of certain patterns in the bits, and compare\nthe results with the typical results obtained for a perfect, uniform\ndistribution. For example, some tests count the number of 1 bits versus\nthe number of 0 bits, or the distribution of 8-bit patterns. But statistical\ntests are largely irrelevant to cryptographic security, and it’s possible to\ndesign a cryptographically weak PRNG that will fool any statistical test.\nWhen you run statistical tests on randomly generated data, you will\nusually see a bunch of statistical indicators as a result. These are typically\np-values, a common statistical indicator. These results aren’t always easy\nto interpret, because they’re rarely as simple as passed or failed. If your\nfirst results seem abnormal, don’t worry: they may be the result of some\naccidental deviation, or you may be testing too few samples. To ensure\nthat the results you see are normal, compare them with those obtained for\nsome reliable sample of identical size; for example, one generated with\nthe OpenSSL toolkit using the following command:\n$ openssl rand <number of bytes> -out <output file>\nReal-World PRNGs\nLet’s turn our attention to how to implement PRNGs in the real world.\nYou’ll find crypto PRNGs in the operating systems (OSs) of most\nplatforms, from desktops and laptops to embedded systems such as\nrouters and set-top boxes, as well as virtual machines, mobile phones, and\nso on. Most of these PRNGs are software based, but some are pure\nhardware. Those PRNGs are used by applications running on the OS,\nand sometimes other PRNGs running on top of cryptographic libraries\nor applications.\nNext we’ll look at the most widely deployed PRNGs: the one for\nLinux, Android, and many other Unix-based systems; the one in\nWindows; and the one in recent Intel microprocessors, which is hardware\nbased.\nGenerating Random Bits in Unix-Based Systems\nThe device file /dev/urandom is the userland interface to the crypto\nPRNG of common *nix systems, and it’s what you will typically use to\ngenerate reliable random bits. Because it’s a device file, requesting\nrandom bits from /dev/urandom is done by reading it as a file. For\nexample, the following command uses /dev/urandom to write 10MB of\nrandom bits to a file:\n$ dd if=/dev/urandom of=<output file> bs=1M count=10\nThe Wrong Way to Use /dev/urandom\nYou could write a naive and insecure C program like the one shown in\nListing 2-1 to read random bits, and hope for the best, but that would be\na bad idea.\nint random_bytes_insecure(void *buf, size_t len)\n{\nint fd = open(\"/dev/urandom\", O_RDONLY);\nread(fd, buf, len);\nclose(fd);\nreturn 0;\n}\nListing 2-1: Insecure use of /dev/urandom\nThis code is insecure; it doesn’t even check the return values of open()\nand read(), which means your expected random buffer could end up filled\nwith zeroes, or left unchanged.\nA Safer Way to Use /dev/urandom\nListing 2-2, copied from LibreSSL, shows a safer way to use\n/dev/urandom.\nint random_bytes_safer(void *buf, size_t len)\n{\nstruct stat st;\nsize_t i;\nint fd, cnt, flags;\nint save_errno = errno;\nstart:\nflags = O_RDONLY;\n#ifdef O_NOFOLLOW\nflags |= O_NOFOLLOW;\n#endif\n#ifdef O_CLOEXEC\nflags |= O_CLOEXEC;\n#endif\nfd = ❶open(\"/dev/urandom\", flags, 0);\nif (fd == -1) {\nif (errno == EINTR)\ngoto start;\ngoto nodevrandom;\n}\n#ifndef O_CLOEXEC\nfcntl(fd, F_SETFD, fcntl(fd, F_GETFD) | FD_CLOEXEC);\n#endif\n/* Lightly verify that the device node looks sane */\nif (fstat(fd, &st) == -1 || !S_ISCHR(st.st_mode)) {\nclose(fd);\ngoto nodevrandom;\n}\nif (ioctl(fd, RNDGETENTCNT, &cnt) == -1) {\nclose(fd);\ngoto nodevrandom;\n}\nfor (i = 0; i < len; ) {\nsize_t wanted = len - i;\nssize_t ret = ❷read(fd, (char *)buf + i, wanted);\nif (ret == -1) {\nif (errno == EAGAIN || errno == EINTR)\ncontinue;\nclose(fd);\ngoto nodevrandom;\n}\ni += ret;\n}\nclose(fd);\nif (gotdata(buf, len) == 0) {\nerrno = save_errno;\nreturn 0; /* satisfied */\n}\nnodevrandom:\nerrno = EIO;\nreturn -1;\n}\nListing 2-2: Safe use of /dev/urandom\nUnlike Listing 2-1, Listing 2-2 makes several sanity checks. Compare,\nfor example, the call to open() at ❶ and the call to read() at ❷ with those\nin Listing 2-1: you’ll notice that the safer code checks the return values of\nthose functions, and upon failure closes the file descriptor and returns –1.\nDifferences Between /dev/urandom and /dev/random on\nLinux\nDifferent Unix versions use different PRNGs. The Linux PRNG,\ndefined in drivers/char/random.c in the Linux kernel, mainly uses the hash\nfunction SHA-1 to turn raw entropy bits into reliable pseudorandom bits.\nThe PRNG harvests entropy from various sources (including the\nkeyboard, mouse, disk, and interrupt timings) and has a primary entropy\npool of 512 bytes, as well as a non-blocking pool for /dev/urandom and a\nblocking pool for /dev/random.\nWhat’s the difference between /dev/urandom and /dev/random? The\nshort story is that /dev/random attempts to estimate the amount of\nentropy and refuses to return bits if the level of entropy is too low.\nAlthough this may sound like a good idea, it’s not. For one thing, entropy\nestimators are notoriously unreliable and can be fooled by attackers\n(which is one reason why Fortuna ditched Yarrow’s entropy estimation).\nFurthermore, /dev/random runs out of estimated entropy pretty quickly,\nwhich can produce a denial-of-service condition, slowing applications\nthat are forced to wait for more entropy. The upshot is that in practice,\n/dev/random is no better than /dev/urandom and creates more problems\nthan it solves.\nEstimating the Entropy of /dev/random\nYou can observe how /dev/random’s entropy estimate evolves by reading\nits current value in bits in /proc/sys/kernel/random/entropy_avail on Linux.\nFor example, the shell script shown in Listing 2-3 first minimizes the\nentropy estimate by reading 4KB from /dev/random, waits until it reaches\nan estimate of 128 bits, reads 64 bits from /dev/random, and then shows\nthe new estimate. When running the script, notice how user activity\naccelerates entropy recovery (bytes read are printed to stdout encoded in\nbase64).\n#!/bin/sh\nESTIMATE=/proc/sys/kernel/random/entropy_avail\ntimeout 3s dd if=/dev/random bs=4k count=1 2> /dev/null | base64\nent=`cat $ESTIMATE`\nwhile [ $ent -lt 128 ]\ndo\nsleep 3\nent=`cat $ESTIMATE`\necho $ent\ndone\ndd if=/dev/random bs=8 count=1 2> /dev/null | base64\ncat $ESTIMATE\nListing 2-3: A script showing the evolution of /dev/urandom’s entropy estimate\nA sample run of Listing 2-3 gave the output shown in Listing 2-4.\n(Guess when I started randomly moving the mouse and hitting the\nkeyboard to gather entropy.)\nxFNX/f2R87/zrrNJ6Ibr5R1L913tl+F4GNzKb60BC+qQnHQcyA==\n2\n18\n19\n27\n28\n72\n124\n193\njq8XWCt8\n129\nListing 2-4: A sample execution of the entropy estimate evolution script in Listing\n2-3\nAs you can see in Listing 2-4, we have 193 − 64 = 129 bits of entropy\nleft in the pool, as per /dev/random’s estimator. Does it make sense to\nconsider a PRNG as having N less entropy bits just because N bits were\njust read from the PRNG? (Spoiler: it does not.)\nNOTE\nLike /dev/random, Linux’s getrandom() system call blocks if it hasn’t\ngathered enough initial entropy. However, unlike /dev/random, it won’t\nattempt to estimate the entropy in the system and will never block after its\ninitialization stage. And that’s fine. (You can force getrandom() to use\n/dev/random and to block by tweaking its flags, but I don’t see why you’d\nwant to do that.)\nThe CryptGenRandom() Function in Windows\nIn Windows, the legacy userland interface to the system’s PRNG is the\nCryptGenRandom() function from the Cryptography application\nprogramming interface (API). The CryptGenRandom() function has been\nreplaced in recent Windows versions with the BcryptGenRandom() function\nin the Cryptography API: Next Generation (CNG) API. The Windows\nPRNG takes entropy from the kernel mode driver cng.sys (formerly\nksecdd.sys), whose entropy collector is loosely based on Fortuna. As is\nusually the case in Windows, the process is complicated.\nListing 2-5 shows a typical C++ invocation of CryptGenRandom() with the\nrequired checks.\nint random_bytes(unsigned char *out, size_t outlen)\n{\nstatic HCRYPTPROV handle = 0; /* only freed when the program ends */\nif(!handle) {\nif(!CryptAcquireContext(&handle, 0, 0, PROV_RSA_FULL,\nCRYPT_VERIFYCONTEXT | CRYPT_SILENT)) {\nreturn -1;\n}\n}\nwhile(outlen > 0) {\nconst DWORD len = outlen > 1048576UL ? 1048576UL : outlen;\nif(!CryptGenRandom(handle, len, out)) {\nreturn -2;\n}\nout += len;\noutlen -= len;\n}\nreturn 0;\n}\nListing 2-5: Using the Windows CryptGenRandom() PRNG interface\nNotice in Listing 2-5 that prior to calling the actual PRNG, you need\nto declare a cryptographic service provider (HCRYPTPROV) and then acquire a\ncryptographic context with CryptAcquireContext(), which increases the\nchances of things going wrong. For instance, the final version of the\nTrueCrypt encryption software was found to call CryptAcquireContext() in\na way that could silently fail, leading to suboptimal randomness without\nnotifying the user. Fortunately, the newer BCryptGenRandom() interface for\nWindows is much simpler and doesn’t require the code to explicitly open\na handle (or at least makes it much easier to use without a handle).\nA Hardware-Based PRNG: RDRAND in Intel\nMicroprocessors\nWe’ve discussed only software PRNGs so far, so let’s have a look at a\nhardware one. The Intel Digital Random Number Generator is a hardware\nPRNG introduced in 2012 in Intel’s Ivy Bridge microarchitecture, and\nit’s based on NIST’s SP 800-90 guidelines with the Advanced Encryption\nStandard (AES) in CTR_DRBG mode. Intel’s PRNG is accessed through\nthe RDRAND assembly instruction, which offers an interface independent of\nthe operating system and is in principle faster than software PRNGs.\nWhereas software PRNGs try to collect entropy from unpredictable\nsources, RDRAND has a single entropy source that provides a serial stream of\nentropy data as zeroes and ones. In hardware engineering terms, this\nentropy source is a dual differential jamb latch with feedback; essentially,\na small hardware circuit that jumps between two states (0 or 1) depending\non thermal noise fluctuations, at a frequency of 800 MHz. This kind of\nthing is usually pretty reliable.\nThe RDRAND assembly instruction takes as an argument a register of 16,\n32, or 64 bits and then writes a random value. When invoked, RDRAND sets\nthe carry flag to 1 if the data set in the destination register is a valid\nrandom value, and to 0 otherwise, which means you should be sure to\ncheck the CF flag if you write assembly code directly. Note that the C\nintrinsics available in common compilers don’t check the CF flag but do\nreturn its value.\nNOTE\nIntel’s PRNG framework provides an assembly instruction other than\nRDRAND: the RDSEED assembly instruction returns random bits\ndirectly from the entropy source, after some conditioning or cryptographic\nprocessing. It’s intended to be able to seed other PRNGs.\nIntel’s PRNG is only partially documented, but it’s built on known\nstandards, and has been audited by the well-regarded company\nCryptography Research (see their report titled “Analysis of Intel’s Ivy\nBridge Digital Random Number Generator”). Nonetheless, there have\nbeen some concerns about its security, especially following Snowden’s\nrevelations about cryptographic backdoors, and PRNGs are indeed the\nperfect target for sabotage. If you’re concerned but still wish to use RDRAND\nor RDSEED, just mix them with other entropy sources. Doing so will\nprevent effective exploitation of a hypothetical backdoor in Intel’s\nhardware or in the associated microcode in all but the most far-fetched\nscenarios.\nHow Things Can Go Wrong\nTo conclude, I’ll present a few examples of randomness failures. There\nare countless examples to choose from, but I’ve chosen four that are\nsimple enough to understand and illustrate different problems.\nPoor Entropy Sources\nIn 1996, the SSL implementation of the Netscape browser was\ncomputing 128-bit PRNG seeds according to the pseudocode shown in\nListing 2-6, copied from Goldberg and Wagner’s page at\nhttp://www.cs.berkeley.edu/~daw/papers/ddj-netscape.html.\nglobal variable seed;\nRNG_CreateContext()\n(seconds, microseconds) = time of day; /* Time elapsed since 1970\n*/\npid = process ID; ppid = parent process ID;\na = mklcpr(microseconds);\n➊ b = mklcpr(pid + seconds + (ppid << 12));\nseed = MD5(a, b); /* Derivation of a 128-bit value using the hash\nMD5 */\nmklcpr(x) /* not cryptographically significant; shown for completeness\n*/\nreturn ((0xDEECE66D * x + 0x2BBB62DC) >> 1);\nMD5() /* a very good standard mixing function, source omitted */\nListing 2-6: Pseudocode of the Netscape browser’s generation of 128-bit PRNG\nseeds\nThe problem here is that the PIDs and microseconds are guessable\nvalues. Assuming that you can guess the value of seconds, microseconds has\nonly 106 possible values and thus an entropy of log(106), or about 20 bits.\nThe process ID (PID) and parent process ID (PPID) are 15-bit values, so\nyou’d expect 15 + 15 = 30 additional entropy bits. But if you look at how b\nis computed at ❶, you’ll see that the overlap of three bits yields an\nentropy of only about 15 + 12 = 27 bits, for a total entropy of only 47 bits,\nwhereas a 128-bit seed should have 128 bits of entropy.\nInsufficient Entropy at Boot Time\nIn 2012, researchers scanned the whole internet and harvested public keys\nfrom TLS certificates and SSH hosts. They found that a handful of\nsystems had identical public keys, and in some cases very similar keys\n(namely, RSA keys with shared prime factors): in short, two numbers, n =\npq and n′ = p′q′, with p = p′, whereas normally all ps and qs should be\ndifferent in distinct modulus values.\nAfter further investigation, it turned out that many devices generated\ntheir public key early, at first boot, before having collected enough\nentropy, despite using an otherwise decent PRNG (typically\n/dev/urandom). PRNGs in different systems ended up producing identical\nrandom bits due to a same base entropy source (for example, a hardcoded\nseed).\nAt a high level, the presence of identical keys is due to key-generation\nschemes like the following, in pseudocode:\nprng.seed(seed)\np = prng.generate_random_prime()\nq = prng.generate_random_prime()\nn = p*q\nIf two systems run this code given an identical seed, they’ll produce the\nsame p, the same q, and therefore the same n.\nThe presence of shared primes in different keys is due to key-\ngeneration schemes where additional entropy is injected during the\nprocess, as shown here:\nprng.seed(seed)\np = prng.generate_random_prime()\nprng.add_entropy()\nq = prng.generate_random_prime()\nn = p*q\nIf two systems run this code with the same seed, they’ll produce the\nsame p, but the injection of entropy through prng.add_entropy() will\nensure distinct qs.\nThe problem with shared prime factors is that given n = pq and n′ = pq′,\nit’s trivial to recover the shared p by computing the greatest common divisor\n(GCD) of n and n′. For the details, see the paper “Mining Your Ps and\nQs” by Heninger, Durumeric, Wustrow, and Halderman, available at\nhttps://factorable.net/.\nNon-cryptographic PRNG\nEarlier we discussed the difference between crypto and non-crypto\nPRNGs and why the latter should never be used for crypto applications.\nAlas, many systems overlook that detail, so I thought I should give you at\nleast one such example.\nThe popular MediaWiki application runs on Wikipedia and many other\nwikis. It uses randomness to generate things like security tokens and\ntemporary passwords, which of course should be unpredictable.\nUnfortunately, a now obsolete version of MediaWiki used a non-crypto\nPRNG, the Mersenne Twister, to generate these tokens and passwords.\nHere’s a snippet from the vulnerable MediaWiki source code. Look for\nthe function called to get a random bit, and be sure to read the\ncomments.\n/**\n* Generate a hex-y looking random token for various uses.\n* Could be made more cryptographically sure if someone cares.\n* @return string\n*/\nfunction generateToken( $salt = '' ) {\n$token = dechex(mt_rand()).dechex(mt_rand());\nreturn md5( $token . $salt );\n}\nDid you notice mt_rand() in the preceding code? Here, mt stands for\nMersenne Twister, the non-crypto PRNG discussed earlier. In 2012,\nresearchers showed how to exploit the predictability of Mersenne Twister\nto predict future tokens and temporary passwords, given a couple of\nsecurity tokens. MediaWiki was patched in order to use a crypto PRNG.\nSampling Bug with Strong Randomness\nThe next bug shows how even a strong crypto PRNG with sufficient\nentropy can produce a biased distribution. The chat program Cryptocat\nwas designed to offer secure communication. It used a function that\nattempted to create a uniformly distributed string of decimal digits—\nnamely, numbers in the range 0 through 9. However, just taking random\nbytes modulo 10 doesn’t yield a uniform distribution, because when\ntaking all numbers between 0 and 255 and reducing them modulo 10, you\ndon’t get an equal number of values in 0 to 9.\nCryptocat did the following to address that problem and obtain a\nuniform distribution:\nCryptocat.random = function() {\nvar x, o = '';\nwhile (o.length < 16) {\nx = state.getBytes(1);\nif (x[0] <= 250) {\no += x[0] % 10;\n}\n}\nreturn parseFloat('0.' + o)\n}\nAnd that was almost perfect. By taking only the numbers up to a\nmultiple of 10 and discarding others, you’d expect a uniform distribution\nof the digits 0 through 9. Unfortunately, there was an off-by-one error in\nthe if condition. I’ll leave the details to you as an exercise. You should\nfind that the values generated had an entropy of 45 instead of\napproximately 53 bits (hint: <= should have been < instead).\nFurther Reading\nI’ve just scratched the surface of randomness in cryptography in this\nchapter. There is much more to learn about the theory of randomness,\nincluding topics such as different entropy notions, randomness extractors,\nand even the power of randomization and derandomization in complexity\ntheory. To learn more about PRNGs and their security, read the classic\n1998 paper “Cryptanalytic Attacks on Pseudorandom Number\nGenerators” by Kelsey, Schneier, Wagner, and Hall. Then look at the\nimplementation of PRNGs in your favorite applications and try to find\ntheir weaknesses. (Search online for “random generator bug” to find\nplenty of examples.)\nWe’re not done with randomness, though. We’ll encounter it again\nand again throughout this book, and you’ll discover the many ways it\nhelps to construct secure systems."
  },
  {
    "input": "What are the key differences between informational security and computational security in cryptography, and how do they relate to the practical strength of a cryptographic algorithm?",
    "summary": "Cryptographic security differs from general software security in that it can be quantified. It focuses on making well-defined problems practically unsolvable, often using computational security, which measures the effort required to break a cipher. Informational security is theoretical and assumes no computational limits, while computational security considers realistic resource constraints. Security levels are often measured in bits, with higher bit counts indicating greater resistance to attacks. However, actual attack costs depend on factors like parallelism, memory usage, and the number of targets, which can significantly affect real-world security.",
    "output": "3\nCRYPTOGRAPHIC SECURITY\nCryptographic definitions of security are not the same as those that apply\nto general computer security. The main difference between software\nsecurity and cryptographic security is that the latter can be quantified.\nUnlike in the software world, where applications are usually seen as either\nsecure or insecure, in the cryptographic world it’s often possible to\ncalculate the amount of effort required to break a cryptographic\nalgorithm. Also, whereas software security focuses on preventing\nattackers from abusing a program’s code, the goal of cryptographic\nsecurity is to make well-defined problems impossible to solve.\nCryptographic problems involve mathematical notions, but not\ncomplex math—or at least not in this book. This chapter walks you\nthrough some of these security notions and how they’re applied to solve\nreal-world problems. In the following sections, I discuss how to quantify\ncrypto security in ways that are both theoretically sound and practically\nrelevant. I discuss the notions of informational versus computational\nsecurity, bit security versus full attack cost, provable versus heuristic\nsecurity, and symmetric versus asymmetric key generation. I conclude the\nchapter with actual examples of failures in seemingly strong\ncryptography.\nDefining the Impossible\nIn Chapter 1, I described a cipher’s security relative to an attacker’s\ncapabilities and goals, and deemed a cipher secure if it was impossible to\nreach these goals given an attacker’s known capabilities. But what does\nimpossible mean in this context?\nTwo notions define the concept of impossible in cryptography:\ninformational security and computational security. Roughly speaking,\ninformational security is about theoretical impossibility whereas\ncomputational security is about practical impossibility. Informational\nsecurity doesn’t quantify security because it views a cipher as either secure\nor insecure, with no middle ground; it’s therefore useless in practice,\nalthough it plays an important role in theoretical cryptography.\nComputational security is the more relevant and practical measure of the\nstrength of a cipher.\nSecurity in Theory: Informational Security\nInformational security is based not on how hard it is to break a cipher,\nbut whether it’s conceivable to break it at all. A cipher is informationally\nsecure only if, even given unlimited computation time and memory, it\ncannot be broken. Even if a successful attack on a cipher would take\ntrillions of years, such a cipher is informationally insecure.\nFor example, the one-time pad introduced in Chapter 1 is\ninformationally secure. Recall that the one-time pad encrypts a plaintext,\nP, to a ciphertext, C = P ⊕ K, where K is a random bit string that is unique\nto each plaintext. The cipher is informationally secure because given a\nciphertext and unlimited time to try all possible keys, K, and compute the\ncorresponding plaintext, P, you would still be unable to identify the right\nK because there are as many possible Ps as there are Ks.\nSecurity in Practice: Computational Security\nUnlike informational security, computational security views a cipher as\nsecure if it cannot be broken within a reasonable amount of time, and with\nreasonable resources such as memory, hardware, budget, energy, and so\non. Computational security is a way to quantify the security of a cipher or\nany crypto algorithm.\nFor example, consider a cipher, E, for which you know a plaintext–\nciphertext pair (P, C) but not the 128-bit key, K, that served to compute C\n= E(K, P). This cipher is not informationally secure because you could\nbreak it after trying the 2128 possible 128-bit Ks until you find the one\nthat satisfies E(K, P) = C. But in practice, even testing 100 billion keys per\nsecond, it would take more than 100,000,000,000,000,000,000 years. In\nother words, reasonably speaking, this cipher is computationally secure\nbecause it’s practically impossible to break.\nComputational security is sometimes expressed in terms of two values:\nt, which is a limit on the number of operations that an attacker will\ncarry out\nε (called “epsilon”), which is a limit on the probability of success of\nan attack\nWe then say that a cryptographic scheme is (t, ε)-secure if an attacker\nperforming at most t operations—whatever those operations are—has a\nprobability of success that is no higher than ε, where ε is at least 0 and at\nmost 1. Computational security gives a limit on how hard it is to break a\ncryptographic algorithm.\nHere it’s important to know that t and ε are just limits: if a cipher is (t,\nε)-secure, then no attacker performing fewer than t operations will succeed\n(with probability ε). But that doesn’t imply that an attacker doing exactly\nt operations will succeed, and it doesn’t tell you how many operations are\nneeded, which may be much larger than t. We say that t is a lower bound\non the computation effort needed, because you’d need at least t\noperations to compromise security.\nWe sometimes know precisely how much effort it takes to break a\ncipher; in such cases we say that a (t, ε)-security gives us a tight bound when\nan attack exists that breaks the cipher with probability ε and exactly t\noperations.\nFor example, consider a symmetric cipher with a 128-bit key. Ideally,\nthis cipher should be (t, t/2128)-secure for any value of t between 1 and\n2128. The best attack should be brute force (trying all keys until you find\nthe correct one). Any better attack would have to exploit some\nimperfection in the cipher, so we strive to create ciphers where brute\nforce is the best possible attack.\nGiven the statement (t, t/2128)-secure, let’s examine the probability of\nsuccess of three possible attacks:\nIn the first case, t = 1, an attacker tries one key and succeeds with a\nprobability of ε = 1/2128.\nIn the second case, t = 2128, an attacker tries all 2128 keys and one\nsucceeds. Thus, the probability ε = 1 (if the attacker tries all keys,\nobviously the right one must be one of them).\nIn the third case, an attacker tries only t = 264 keys, and succeeds\nwith a probability of ε = 264/2128 = 2−64. When an attacker only tries\na fraction of all keys, the success probability is proportional to the\nnumber of keys tried.\nWe can conclude that a cipher with a key of n bits is at best (t, t/2n)-\nsecure, for any t between 1 and 2n, because no matter how strong the\ncipher, a brute-force attack against it will always succeed. The key thus\nneeds be long enough to blunt brute-force attacks in practice.\nNOTE\nIn this example, we are counting the number of evaluations of the cipher, not\nthe absolute time or number of processor clock cycles. Computational security\nis technology agnostic, which is good: a cipher that is (t, ε)-secure today will\nbe (t, ε)-secure tomorrow, but what’s considered secure in practice today\nmight not be considered secure tomorrow.\nQuantifying Security\nWhen an attack is found, the first thing you want to know is how efficient\nit is in theory, and how practical it is, if at all. Likewise, given a cipher\nthat’s allegedly secure, you want to know what amount of work it can\nwithstand. To address those questions, I’ll explain how cryptographic\nsecurity can be measured in bits (the theoretical view) and what factors\naffect the actual cost of an attack.\nMeasuring Security in Bits\nWhen speaking of computational security, we say that a cipher is t-secure\nwhen a successful attack needs at least t operations. We thus avoid the\nunintuitive (t, ε) notation by assuming a success probability of ε close to\n1, or what we care about in practice. We then express security in bits,\nwhere “n-bit security” means that about 2 operations are needed to\nN\ncompromise some particular security notion.\nIf you know approximately how many operations it takes to break a\ncipher, you can determine its security level in bits by taking the binary\nlogarithm of the number of operations: if it takes 1000000 operations, the\nsecurity level is log (1000000), or about 20 bits (that is, 1000000 is\n2\napproximately equal to 220). Recall that an n-bit key will give at most n-\nbit security because a brute-force attack with all 2n possible keys will\nalways succeed. But the key size doesn’t always match the security level—\nit just gives an upper bound, or the highest possible security level.\nA security level may be smaller than the key size for one of two reasons:\nAn attack broke the cipher in fewer operations than expected—for\nexample, using a method that recovers the key by trying not all 2n\nkeys, but only a subset of those.\nThe cipher’s security level intentionally differs from its key size, as\nwith most public key algorithms. For example, the RSA algorithm\nwith a 2048-bit secret key provides less than 100-bit security.\nBit security proves useful when comparing ciphers’ security levels but\ndoesn’t provide enough information on the actual cost of an attack. It is\nsometimes too simple an abstraction because it just assumes that an n-bit-\nsecure cipher takes 2n operations to break, whatever these operations are.\nTwo ciphers with the same bit security level can therefore have vastly\ndifferent real-world security levels when you factor in the actual cost of\nan attack to a real attacker.\nSay we have two ciphers, each with a 128-bit key and 128-bit security.\nEach must be evaluated 2128 times in order to be broken, except that the\nsecond cipher is 100 times slower than the first. Evaluating the second\ncipher 2128 times thus takes the same time as 100 × 2128 ≈ 2134.64\nevaluations of the first. If we count in terms of the first, fast cipher, then\nbreaking the slower one takes 2134.64 operations. If we count in terms of\nthe second, slow cipher, it only takes 2128 operations. Should we then say\nthat the second cipher is stronger than the first? In principle, yes, but we\nrarely see such a hundred-fold performance difference between\ncommonly used ciphers.\nThe inconsistent definition of an operation raises more difficulties\nwhen comparing the efficiency of attacks. Some attacks claim to reduce a\ncipher’s security because they perform 2120 evaluations of some operation\nrather than 2128 evaluations of the cipher, but the speed of each type of\nattack is left out of the analysis. The 2120-operation attack won’t always\nbe faster than a 2128 brute-force attack.\nNevertheless, bit security remains a useful notion as long as the\noperation is reasonably defined—meaning about as fast as an evaluation\nof the cipher. After all, in real life, all it takes to determine whether a\nsecurity level is sufficient is an order of magnitude.\nFull Attack Cost\nBit security expresses the cost of the fastest attack against a cipher by\nestimating the order of magnitude of the number of operations it needs to\nsucceed. But other factors affect the cost of an attack, and these must be\ntaken into account when estimating the actual security level. I’ll explain\nthe four main ones: parallelism, memory, precomputation, and the\nnumber of targets.\nParallelism\nThe first factor to consider is computational parallelism. For example,\nconsider two attacks of 256 operations each. The difference between the\ntwo is that the second attack can be parallelized but not the first: the first\nattack performs 256 sequentially dependent operations, such as x = f (x )\ni + 1 i i\nfor some x and some functions f (with i from 1 to 256), whereas the\n0 i\nsecond performs 256 independent operations, such as x = f (x) for some x\ni i\nand i from 1 to 256, which can be executed in parallel. Parallel processing\ncan be orders of magnitude faster than sequential processing. For\nexample, if you had 216 = 65536 processors available, you could divide the\nworkload of the parallel attacks into 216 independent tasks, each\nperforming 256 / 216 = 240 operations. The first attack, however, cannot\nbenefit from having multiple cores available because each operation relies\non the previous operation’s result. Therefore, the parallel attack will\ncomplete 65536 times faster than the sequential one, even though they\nperform the same number of operations.\nNOTE\nAlgorithms that become N times faster to attack when N cores are available\nare called embarrassingly parallel, and we say that their execution times\nscale linearly with respect to the number of computing cores.\nMemory\nThe second factor when determining the cost of an attack is memory.\nCryptanalytic attacks should be evaluated with respect to their use of time\nand space: how many operations do they perform over time, how much\nmemory or space do they consume, how do they use the space they\nconsume, and what’s the speed of the available memory? Unfortunately,\nbit security is concerned only with the time it takes to perform an attack.\nConcerning the way space is used, it’s important to consider how many\nmemory lookups are required as part of an attack, the speed of memory\naccesses (which may differ between reads and writes), the size of the data\naccessed, the access pattern (contiguous or random memory addresses),\nand how data is structured in memory. For example, on one of today’s\ngeneral-purpose CPUs, reading from a register takes one cycle, whereas\nreading from the CPU’s cache memory takes around 20 cycles (for the L3\ncache), and reading from DRAM usually takes at least 100 cycles. A factor\nof 100 can make the difference between one day and three months.\nPrecomputation\nPrecomputation operations are those that need to be performed only\nonce and can be reused over subsequent executions of the attack.\nPrecomputation is sometimes called the offline stage of an attack.\nFor example, consider the time-memory trade-off attack. When\nperforming this kind of attack, the attacker performs one huge\ncomputation that produces large lookup tables that are then stored and\nreused to perform the actual attack. For example, one attack on 2G\nmobile encryption took two months to build two terabytes’ worth of\ntables, which were then used to break the encryption in 2G and recover a\nsecret session key in only a few seconds.\nNumber of Targets\nFinally, we come to the number of targets of the attack. The greater the\nnumber of targets, the greater the attack surface, and the more attackers\ncan learn about the keys they’re after.\nFor example, consider a brute-force key search: if you target a single n-\nbit key, it will take 2n attempts to find the correct key with certainty. But\nif you target multiple n-bit keys—say, a number M—and if for a single P\nyou have M distinct ciphertexts, where C = E(K, P) for each of the M keys\n(K) that you’re after, it will again take 2n attempts to find each key. But if\nyou’re only interested in at least one of the M keys and not in every one, it\nwould take on average 2n / M attempts to succeed. For example, to break\none 128-bit key of 216 = 65536 target keys, it will take on average 2128 − 16\n= 2112 evaluations of the cipher. That is, the cost (and speed) of the attack\ndecreases as the number of targets increases.\nChoosing and Evaluating Security Levels\nChoosing a security level often involves selecting between 128-bit and\n256-bit security because most standard crypto algorithms and\nimplementations are available in one of these two security levels. Below\n128 bits you’ll find schemes with 64- or 80-bit security, but these are\ngenerally not secure enough for real-world use.\nAt a high level, 128-bit security means that you’d need to carry out\napproximately 2128 operations to break that crypto system. To give you a\nsense of what this number means, consider the fact that the universe is\napproximately 288 nanoseconds old (there’s a billion nanoseconds in a\nsecond). Since testing a key with today’s technology takes no less than a\nnanosecond, you’d need several times the age of the universe for an attack\nto succeed (240 times to be precise) if it takes exactly one nanosecond to\ntest a key.\nBut can’t parallelism and multiple targets dramatically reduce the time\nit takes to complete a successful attack? Not exactly. Say you’re interested\nin breaking any of a million targets, and that you have a million parallel\ncores available. That brings the search time down from 2128 to (2128 / 220)\n/ 220 = 288, which is equivalent to only one universe lifetime.\nAnother thing to consider when evaluating security levels is the\nevolution of technology. Moore’s law posits that computing efficiency\ndoubles roughly every two years. We can think of this as a loss of one bit\nof security every two years: if today a $1000 budget allows you to break,\nsay, a 40-bit key in one hour, then Moore’s law says that two years later,\nyou could break a 41-bit key in one hour for the same $1000 budget (I’m\nsimplifying). We can extrapolate from this to say that, according to\nMoore’s law, we’ll have 40 fewer bits of security in 80 years compared to\ntoday. In other words, in 80 years doing 2128 operations may cost as much\nas doing 288 operations today. Accounting for parallelism and multiple\ntargets, as discussed earlier, we’re down to 248 nanoseconds of\ncomputation, or about three days. But this extrapolation is highly\ninaccurate, because Moore’s law won’t and can’t scale that much. Still,\nyou get the idea: what looks infeasible today may be realistic in a century.\nThere will be times when a security level lower than 128 bits is\njustified. For example, when you need security for only a short time\nperiod and when the costs of implementing a higher security level will\nnegatively impact the cost or usability of a system. A real-world example\nis that of pay TV systems, wherein encryption keys are either 48 or 64\nbits. This sounds ridiculously low, but that’s a sufficient security level\nbecause the key is refreshed every 5 or 10 seconds.\nNevertheless, to ensure long-term security, you should choose 256-bit\nsecurity or a bit less. Even in a worst-case scenario—the existence of\nquantum computers, see Chapter 14—a 256-bit secure scheme is unlikely\nto be broken in the foreseeable future. More than 256 bits of security is\npractically unnecessary, except as a marketing device.\nAs NIST cryptographer John Kelsey once put it, “The difference\nbetween 80 bits and 128 bits of key search is like the difference between a\nmission to Mars and a mission to Alpha Centauri. As far as I can see,\nthere is no meaningful difference between 192-bit and 256-bit keys in\nterms of practical brute-force attacks; impossible is impossible.”\nAchieving Security\nOnce you’ve chosen a security level, it’s important to guarantee that your\ncryptographic schemes will stick to it. In other words, you want confidence,\nnot just hope and uncertainty, that things will work as planned, all the\ntime.\nWhen building confidence in the security of a crypto algorithm, you\ncan rely on mathematical proofs, an approach called provable security, or\non evidence of failed attempts to break the algorithm, which I’ll call\nheuristic security (though it’s sometimes called probable security). These\ntwo approaches are complementary and neither is better than the other,\nas you’ll see.\nProvable Security\nProvable security is about proving that breaking your crypto scheme is at\nleast as hard as solving another problem known to be hard. Such a security\nproof guarantees that the crypto remains safe as long as the hard problem\nremains hard. This type of proof is called a reduction, and it comes from\nthe field of complexity theory. We say that breaking some cipher is\nreducible to problem X if any method to solve problem X also yields a\nmethod to break the cipher.\nSecurity proofs come in two flavors, depending on the type of\npresumably hard problem used: proofs relative to a mathematical\nproblem and proofs relative to a cryptographic problem.\nProofs Relative to a Mathematical Problem\nMany security proofs (such as those for public-key crypto) show that\nbreaking a crypto scheme is at least as hard as solving some hard\nmathematical problem. We’re talking of problems for which a solution is\nknown to exist, and is easy to verify once it’s known, but is\ncomputationally hard to find.\nNOTE\nThere’s no real proof that seemingly hard math problems are actually hard.\nIn fact, proving this for a specific class of problems is one of the greatest\nchallenges in the field of complexity theory, and as I write this there is a\n$1,000,000 bounty for anyone who can solve it, awarded by the Clay\nMathematics Institute. This is discussed in more detail in Chapter 9.\nFor example, consider the challenge of solving the factoring problem,\nwhich is the best-known math problem in crypto: given a number that\nyou know is the product of two prime numbers (n = pq), find the said\nprimes. For example, if n = 15, the answer is 3 and 5. That’s easy for a\nsmall number, but it becomes exponentially harder as the size of the\nnumber grows. For example, if a number, n, is 3000 bits long (about 900\ndecimal digits) or more, factoring is believed to be practically infeasible.\nRSA is the most famous crypto scheme to rely on the factoring\nproblem: RSA encrypts a plaintext, P, seen as a large number, by\ncomputing C = Pe mod n, where the number e and n = pq are the public\nkey. Decryption recovers a plaintext from a ciphertext by computing P =\nCd mod n, where d is the private key associated to e and n. If we can factor\nn, then we can break RSA (by recovering the private key from the public\nkey), and if we can obtain the private key, then we can factor n; in other\nwords, recovering an RSA private key and factoring n are equivalently\nhard problems. That’s the kind of reduction we’re looking for in provable\nsecurity. However, there is no guarantee that recovering an RSA plaintext\nis as hard as factoring n, since the knowledge of a plaintext doesn’t reveal\nthe private key.\nProofs Relative to Another Crypto Problem\nInstead of comparing a crypto scheme to a math problem, you can\ncompare it to another crypto scheme and prove that you can only break\nthe second if you can break the first. Security proofs for symmetric\nciphers usually follow this approach.\nFor example, if all you have is a single permutation algorithm, then you\ncan build symmetric ciphers, random bit generators, and other crypto\nobjects such as hash functions by combining calls to the permutations\nwith various types of inputs (as you’ll see in Chapter 6). Proofs then show\nthat the newly created schemes are secure if the permutation is secure. In\nother words, we know for sure that the newly created algorithm is not\nweaker than the original one. Such proofs usually work by crafting an\nattack on the smaller component given an attack on the larger one—that\nis, by showing a reduction.\nWhen you’re proving that a crypto algorithm is no weaker than\nanother, the main benefit is that of a reduced attack surface: instead of\nanalyzing both the core algorithm and the combination, you can simply\nlook at the new cipher’s core algorithm. Specifically, if you write a cipher\nthat uses a newly developed permutation and a new combination, you\nmay prove that the combination doesn’t weaken security compared to the\ncore algorithm. Therefore, to break the combination, you need to break\nthe new permutation.\nCaveats\nCryptography researchers rely heavily on security proofs, whether with\nrespect to math problem schemes or to other crypto schemes. But the\nexistence of a security proof does not guarantee that a cryptographic\nscheme is perfect, nor is it an excuse for neglecting the more practical\naspects of implementation. After all, as cryptographer Lars Knudsen once\nsaid, “If it’s provably secure, it’s probably not,” meaning that a security\nproof shouldn’t be taken as an absolute guarantee of security. Worse,\nthere are multiple reasons why a “provably secure” scheme may lead to a\nsecurity failure.\nOne issue is with the phrase “proof of security” itself. In mathematics, a\nproof is the demonstration of an absolute truth, but in crypto, a proof is\nonly the demonstration of a relative truth. For example, a proof that your\ncipher is as hard to break as it is to compute discrete logarithms—finding\nthe number x given g and gx mod n—guarantees that if your cipher fails, a\nwhole lot of other ciphers will fail as well, and nobody will blame you if\nthe worst happens.\nAnother caveat is that security proofs are usually proven with respect to\na single notion of security. For example, you might prove that recovering\nthe private key of a cipher is as hard as the factoring problem. But if you\ncan recover plaintexts from ciphertext without the key, you’ll bypass the\nproof, and recovering the key hardly matters.\nThen again, proofs are not always correct, and it may be easier to break\nan algorithm than originally thought.\nNOTE\nUnfortunately, few researchers carefully check security proofs, which\ncommonly span dozens of pages, thus complicating quality control. That said,\ndemonstrating that a proof is incorrect doesn’t necessarily imply that the\nproof’s goal is completely wrong; if the result is correct, the proof may be\nsalvaged by correcting its errors.\nAnother important consideration is that hard math problems\nsometimes turn out to be easier to solve than expected. For example,\ncertain weak parameters make breaking RSA easy. Or the math problem\nmay be hard in certain cases, but not on average, as often happens when\nthe reference problem is new and not well understood. That’s what\nhappened when the 1978 knapsack encryption scheme by Merkle and\nHellman was later totally broken using lattice reduction techniques.\nFinally, although the proof of an algorithm’s security may be fine, the\nimplementation of the algorithm can be weak. For example, attackers\nmay exploit side-channel information such as power consumption or\nexecution time to learn about an algorithm’s internal operations in order\nto break it, thus bypassing the proof. Or implementers may misuse the\ncrypto scheme: if the algorithm is too complicated with too many knobs\nto configure, chances are higher that the user or developer will get a\nconfiguration wrong, which may render the algorithm completely\ninsecure.\nHeuristic Security\nProvable security is a great tool to gain confidence in a crypto scheme,\nbut it doesn’t apply to all kinds of algorithms. In fact, most symmetric\nciphers don’t have a security proof. For example, every day we rely on the\nAdvanced Encryption Standard (AES) to securely communicate using our\nmobile phones, laptops, and desktop computers, but AES is not provably\nsecure; there’s no proof that it’s as hard to break as some well-known\nproblem. AES can’t be related to a math problem or to another algorithm\nbecause it is the hard problem itself.\nIn cases where provable security doesn’t apply, the only reason to trust\na cipher is because many skilled people tried to break it and failed. This is\nsometimes called heuristic security.\nWhen can we be sure that a cipher is secure then? We can never be\nsure, but we can be pretty confident that an algorithm won’t be broken\nwhen hundreds of experienced cryptanalysts have each spent hundreds of\nhours trying to break it and published their findings—usually by\nattempting attacks on simplified versions of a cipher (often versions with\nfewer operations, or fewer rounds, which are short series of operations\nthat ciphers iterate in order to mix bits together).\nWhen analyzing a new cipher, cryptanalysts first try to break one\nround, then two, three, or as many as they can. The security margin is then\nthe difference between the total number of rounds and the number of\nrounds that were successfully attacked. When after years of study a\ncipher’s security margin is still high, we become confident that it’s\n(probably) secure.\nGenerating Keys\nIf you plan to encrypt something, you’ll have to generate keys, whether\nthey are temporary “session keys” (like the ones generated when browsing\nan HTTPS site) or long-term public keys. Recall from Chapter 2 that\nsecret keys are the crux of cryptographic security and should be randomly\ngenerated so that they are unpredictable and secret.\nFor example, when you browse an HTTPS website, your browser\nreceives the site’s public key and uses it to establish a symmetric key that’s\nonly valid for the current session, and that site’s public key and its\nassociated private key may be valid for years. Therefore, it’d better be\nhard to find for an attacker. But generating a secret key isn’t always as\nsimple as dumping enough\npse udo​\nrandom bits. Cryptographic keys may be generated in one of three ways:\nRandomly, using a pseudorandom number generator (PRNG) and,\nwhen needed, a key-generation algorithm\nFrom a password, using a key derivation function (KDF), which\ntransforms the user-supplied password into a key\nThrough a key agreement protocol, which is a series of message\nexchanges between two or more parties that ends with the\nestablishment of a shared key\nFor now, I’ll explain the simplest method: randomized generation.\nGenerating Symmetric Keys\nSymmetric keys are secret keys shared by two parties, and they are the\nsimplest to generate. They are usually the same length as the security\nlevel they provide: a 128-bit key provides 128-bit security, and any of the\n2128 possible keys is a valid one that can do the job as well as any other\nkey.\nTo generate a symmetric key of n bits using a cryptographic PRNG,\nyou simply ask it for n pseudorandom bits and use those bits as the key.\nThat’s it. You can, for example, use the OpenSSL toolkit to generate a\nrandom symmetric key by dumping pseudorandom bytes, as in the\nfollowing command (obviously, your result will differ from mine):\n$ openssl rand 16 -hex\n65a4400ea649d282b855bd2e246812c6\nGenerating Asymmetric Keys\nUnlike symmetric keys, asymmetric keys are usually longer than the\nsecurity level they provide. But that’s not the main problem. Asymmetric\nkeys are trickier to generate than symmetric ones because you can’t just\ndump n bits from your PRNG and get away with the result. Asymmetric\nkeys aren’t just raw bit sequences; instead, they represent a specific type\nof object, such as a large number with specific properties (in RSA, a\nproduct of two primes). A random bit string value (and thus a random\nnumber) is unlikely to have the specific properties needed, and therefore\nwon’t be a valid key.\nTo generate an asymmetric key, you send pseudorandom bits as a seed\nto a key-generation algorithm. This key-generation algorithm takes as input\na seed value that’s at least as long as the intended security level and then\nconstructs from it a private key and its respective public key, ensuring\nthat both satisfy all the necessary criteria. For example, a naive key-\ngeneration algorithm for RSA would generate a number, n = pq, by using\nan algorithm to generate two random primes of about the same length.\nThat algorithm would pick random numbers until one happens to be\nprime—so you’d also need an algorithm to test whether a number is\nprime.\nTo save yourself the burden of manually implementing the key-\ngeneration algorithm, you can use OpenSSL to generate a 4096-bit RSA\nprivate key, like this:\n$ openssl genrsa 4096\nGenerating RSA private key, 4096 bit long modulus\n..............................................................................\n...............................++\n...............................................++\ne is 65537 (0x10001)\n-----BEGIN RSA PRIVATE KEY-----\nMIIJKQIBAAKCAgEA3Qgm6OjMy61YVstaGawk22A9LyMXhiQUU4N8F5QZXEef2Pjq\nvTtAIA1hzpK2AJsv16INpNkYcTjNmechAJ0xHraftO6cp2pZFP85dvknsMfUoe8u\nbtKXZiYvJwpS0fQQ4tzlDtH45Gj8sMHcwFxTO3HSIx0XV0owfJTLMzZbSE3TDlN+\nJdW8d9Xd5UVB+o9gUCI8tSfnOjF2dHlLNiOhlfT4w0Rf+G35USIyUJZtOQ0Dh8M+\n--snip--\nzO/dbYtqRkMT8Ubb/0Q1IW0q8e0WnFetzkwPzAIjwZGXT0kWJu3RYj1OXbTYDr2c\nxBRVC/ujoDL6O3NaqPxkWY5HJVmkyKIE5pC04RFNyaQ8+o4APyobabPMylQq5Vo5\nN5L2c4mhy1/OH8fvKBRDuvCk2oZinjdoKUo8ZA5DOa4pdvIQfR+b4/4Jjsx4\n-----END RSA PRIVATE KEY-----\nNotice that the key comes in a specific format—namely, base64-\nencoded data between the BEGIN RSA PRIVATE KEY and END RSA PRIVATE KEY\nmarkers. That’s a standard encoding format supported by most systems,\nwhich then convert this representation to raw bytes of data. The dot\nsequences at the beginning are a kind of progress bar, and e is 65537\n(0x10001) indicates the parameter to use when encrypting (remember that\nRSA encrypts by computing C = Pe mod n).\nProtecting Keys\nOnce you have a secret key, you need to keep it secret, yet available when\nyou need it. There are three ways to address this problem.\nKey wrapping (encrypting the key using a second key)\nThe problem with this approach is that the second key must be\navailable when you need to decrypt the protected key. In practice, this\nsecond key is often generated from a password supplied by the user\nwhen he needs to use the protected key. That’s how private keys for\nthe Secure Shell (SSH) protocol are usually protected.\nOn-the-fly generation from a password\nHere, no encrypted file needs to be stored because the key comes\nstraight out from the password. Modern systems like miniLock use this\nmethod. Although this method is more direct than key wrapping, it’s\nless widespread, in part because it’s more vulnerable to weak\npasswords. Say, for example, that an attacker captured some encrypted\nmessage: if key wrapping was used, the attacker first needs to get the\nprotected key file, which is usually stored locally on the user’s file\nsystem and therefore not easy to access. But if on-the-fly generation\nwas used, the attacker can directly search for the correct password by\nattempting to decrypt the encrypted message with candidate\npasswords. And if the password is weak, the key is compromised.\nStoring the key on a hardware token (smart card or USB dongle)\nIn this approach, the key is stored in secure memory and remains safe\neven if the computer is compromised. This is the safest approach to\nkey storage, but also the costliest and least convenient because it\nrequires you to carry the hardware token with you and run the risk of\nlosing it. Smart cards and USB dongles usually require you to enter a\npassword to unlock the key from the secure memory.\nNOTE\nWhatever method you use, make sure not to mistake the private key for the\npublic one when exchanging keys, and don’t accidentally publish the private\nkey through email or source code. (I’ve actually found private keys on\nGitHub.)\nTo test key wrapping, run the OpenSSL command shown here with\nthe argument -aes128 to tell OpenSSL to encrypt the key with the cipher\nAES-128 (AES with a 128-bit key):\n$ openssl genrsa -aes128 4096\nGenerating RSA private key, 4096 bit long modulus\n..........++\n.............................................................................................................................++\ne is 65537 (0x10001)\nEnter pass phrase:\nThe passphrase requested will be used to encrypt the newly created\nkey.\nHow Things Can Go Wrong\nCryptographic security can go wrong in many ways. The biggest risk is\nwhen we have a false sense of security thanks to security proofs or to well-\nstudied protocols, as illustrated by the following two examples.\nIncorrect Security Proof\nEven proofs of security by renowned researchers may be wrong. One of\nthe most striking examples of a proof gone terribly wrong is that of\nOptimal Asymmetric Encryption Padding (OAEP), a method of secure\nencryption that used RSA and was implemented in many applications.\nYet, an incorrect proof of OAEP’s security against chosen-ciphertext\nattackers was accepted as valid for seven years, until a researcher found\nthe flaw in 2001. Not only was the proof wrong, the result was wrong as\nwell. A new proof later showed that OAEP is only almost secure against\nchosen-ciphertext attackers. We now have to trust the new proof and\nhope that it’s flawless. (For further details, see the 2001 paper “OAEP\nReconsidered” by Victor Shoup.)\nShort Keys for Legacy Support\nIn 2015, researchers found that some HTTPS sites and SSH servers\nsupported public-key cryptography with shorter keys than expected:\nnamely, 512 bits instead of at least 2048 bits. Remember, with public-key\nschemes, the security level isn’t equal to the key size, and in the case of\nHTTPS, keys of 512 bits offer a security level of approximately 60 bits.\nThese keys could be broken after only about two weeks of computation\nusing a cluster of 72 processors. Many websites were affected, including\nthe FBI’s. Although the software was ultimately fixed (thanks to patches\nfor OpenSSL and for other software), the problem was quite an\nunpleasant surprise.\nFurther Reading\nTo learn more about provable security for symmetric ciphers, read the\nsponge functions documentation (http://sponge.noekeon.org/). Sponge\nfunctions introduced the permutation-based approach in symmetric\ncrypto, which describes how to construct a bunch of different\ncryptographic functions using only one permutation.\nSome must-reads on the real cost of attacks include Bernstein’s 2005\npaper “Understanding Brute Force” and Wiener’s 2004 paper “The Full\nCost of Cryptanalytic Attacks,” both available online for free.\nTo determine the security level for a given key size, visit\nhttp://www.keylength.com/. This site also offers an explanation on how\nprivate keys are protected in common cryptographic utilities, such as\nSSH, OpenSSL, GnuPG, and so on.\nFinally, as an exercise, pick an application (such as a secure messaging\napplication) and identify its crypto schemes, key length, and respective\nsecurity levels. You’ll often find surprising inconsistencies, such as a first\nscheme providing a 256-bit security level but a second scheme providing\nonly 100-bit security. The security of the whole system is often only as\nstrong as that of its weakest component."
  },
  {
    "input": "What is a block cipher and how does it differ from other types of ciphers?",
    "summary": "Block ciphers, like DES, AES, and GOST 28147-89, use a core algorithm to encrypt data in fixed-size blocks. AES, chosen as a successor to DES, is widely used and secure due to its efficient design and resistance to attacks. However, the security of block ciphers depends not only on their core algorithms but also on their modes of operation, which can be vulnerable to attacks such as meet-in-the-middle and padding oracle attacks. AES is secure because its components ensure strong diffusion and confusion, making it resistant to most known attacks.",
    "output": "4\nBLOCK CIPHERS\nDuring the Cold War, the US and Soviets developed their own ciphers.\nThe US government created the Data Encryption Standard (DES), which\nwas adopted as a federal standard from 1979 to 2005, while the KGB\ndeveloped GOST 28147-89, an algorithm kept secret until 1990 and still\nused today. In 2000, the US-based National Institute of Standards and\nTechnology (NIST) selected the successor to DES, called the Advanced\nEncryption Standard (AES), an algorithm developed in Belgium and now\nfound in most electronic devices. AES, DES, and GOST 28147-89 have\nsomething in common: they’re all block ciphers, a type of cipher that\ncombines a core algorithm working on blocks of data with a mode of\noperation, or a technique to process sequences of data blocks.\nThis chapter reviews the core algorithms that underlie block ciphers,\ndiscusses their modes of operation, and explains how they all work\ntogether. It also discusses how AES works and concludes with coverage of\na classic attack tool from the 1970s, the meet-in-the-middle attack, and a\nfavorite attack technique of the 2000s—padding oracles.\nWhat Is a Block Cipher?\nA block cipher consists of an encryption algorithm and a decryption\nalgorithm:\nThe encryption algorithm (E) takes a key, K, and a plaintext block, P,\nand produces a ciphertext block, C. We write an encryption\noperation as C = E(K, P).\nThe decryption algorithm (D) is the inverse of the encryption\nalgorithm and decrypts a message to the original plaintext, P. This\noperation is written as P = D(K, C).\nSince they’re the inverse of each other, the encryption and decryption\nalgorithms usually involve similar operations.\nSecurity Goals\nIf you’ve followed earlier discussions about encryption, randomness, and\nindistinguishability, the definition of a secure block cipher will come as\nno surprise. Again, we’ll define security as random-lookingness, so to\nspeak.\nIn order for a block cipher to be secure, it should be a pseudorandom\npermutation (PRP), meaning that as long as the key is secret, an attacker\nshouldn’t be able to compute an output of the block cipher from any\ninput. That is, as long as K is secret and random from an attacker’s\nperspective, they should have no clue about what E(K, P) looks like, for\nany given P.\nMore generally, attackers should be unable to discover any pattern in\nthe input/output values of a block cipher. In other words, it should be\nimpossible to tell a block cipher from a truly random permutation, given\nblack-box access to the encryption and decryption functions for some\nfixed and unknown key. By the same token, they should be unable to\nrecover a secure block cipher’s secret key; otherwise, they would be able\nto use that key to tell the block cipher from a random permutation. Of\ncourse that also implies that attackers can’t predict the plaintext that\ncorresponds to a given ciphertext produced by the block cipher.\nBlock Size\nTwo values characterize a block cipher: the block size and the key size.\nSecurity depends on both values. Most block ciphers have either 64-bit or\n128-bit blocks—DES’s blocks have 64 (26) bits, and AES’s blocks have\n128 (27) bits. In computing, lengths that are powers of two simplify data\nprocessing, storage, and addressing. But why 26 and 27 and not 24 or 216\nbits?\nFor one thing, it’s important that blocks are not too large in order to\nminimize both the length of ciphertext and the memory footprint. With\nregard to the length of the ciphertext, block ciphers process blocks, not\nbits. This means that in order to encrypt a 16-bit message when blocks\nare 128 bits, you’ll first need to convert the message into a 128-bit block,\nand only then will the block cipher process it and return a 128-bit\nciphertext. The wider the blocks, the longer this overhead. As for the\nmemory footprint, in order to process a 128-bit block, you need at least 128\nbits of memory. This is small enough to fit in the registers of most CPUs\nor to be implemented using dedicated hardware circuits. Blocks of 64,\n128, or even 512 bits are short enough to allow for efficient\nimplementations in most cases. But larger blocks (for example, several\nkilobytes long) can have a noticeable impact on the cost and performance\nof implementations.\nWhen ciphertexts’ length or memory footprint is critical, you may have\nto use 64-bit blocks, because these will produce shorter ciphertexts and\nconsume less memory. Otherwise, 128-bit or larger blocks are better,\nmainly because 128-bit blocks can be processed more efficiently than 64-\nbit ones on modern CPUs and are also more secure. In particular, CPUs\ncan leverage special CPU instructions in order to efficiently process one\nor more 128-bit blocks in parallel—for example, the Advanced Vector\nExtensions (AVX) family of instructions in Intel CPUs.\nThe Codebook Attack\nWhile blocks shouldn’t be too large, they also shouldn’t be too small;\notherwise, they may be susceptible to codebook attacks, which are attacks\nagainst block ciphers that are only efficient when smaller blocks are used.\nThe codebook attack works like this with 16-bit blocks:\n1. Get the 65536 (216) ciphertexts corresponding to each 16-bit\nplaintext block.\n2. Build a lookup table—the codebook—mapping each ciphertext block\nto its corresponding plaintext block.\n3. To decrypt an unknown ciphertext block, look up its corresponding\nplaintext block in the table.\nWhen 16-bit blocks are used, the lookup table needs only 216 × 16 = 220\nbits of memory, or 128 kilobytes. With 32-bit blocks, memory needs\ngrow to 16 gigabytes, which is still manageable. But with 64-bit blocks,\nyou’d have to store 270 bits (a zetabit, or 128 exabytes), so forget about it.\nCodebook attacks won’t be an issue for larger blocks.\nHow to Construct Block Ciphers\nThere are hundreds of block ciphers but only a handful of techniques to\nconstruct one. First, a block cipher used in practice isn’t a gigantic\nalgorithm but a repetition of rounds, a short sequence of operations that is\nweak on its own but strong in number. Second, there are two main\ntechniques to construct a round: substitution–permutation networks (as\nin AES) and Feistel schemes (as in DES). In this section, we look at how\nthese work, after viewing an attack that works when all rounds are\nidentical to each other.\nA Block Cipher’s Rounds\nComputing a block cipher boils down to computing a sequence of rounds.\nIn a block cipher, a round is a basic transformation that is simple to\nspecify and to implement, and which is iterated several times to form the\nblock cipher’s algorithm. This construction, consisting of a small\ncomponent repeated many times, is simpler to implement and to analyze\nthan a construction that would consist of a single huge algorithm.\nFor example, a block cipher with three rounds encrypts a plaintext by\ncomputing C = R (R (R (P))), where the rounds are R , R , and R and P\n3 2 1 1 2 3\nis a plaintext. Each round should also have an inverse in order to make it\npossible for a recipient to compute back to plaintext. Specifically, P =\niR (iR (iR (C))), where iR is the inverse of R , and so on.\n1 2 3 1 1\nThe round functions—R , R , and so on—are usually identical\n1 2\nalgorithms, but they are parameterized by a value called the round key.\nTwo round functions with two distinct round keys will behave differently,\nand therefore will produce distinct outputs if fed with the same input.\nRound keys are keys derived from the main key, K, using an algorithm\ncalled a key schedule. For example, R takes the round key K , R takes the\n1 1 2\nround key K , and so on.\n2\nRound keys should always be different from each other in every round.\nFor that matter, not all round keys should be equal to the key K.\nOtherwise, all the rounds would be identical and the block cipher would\nbe less secure, as described next.\nThe Slide Attack and Round Keys\nIn a block cipher, no round should be identical to another round in order\nto avoid a slide attack. Slide attacks look for two plaintext/ciphertext pairs\n(P , C ) and (P , C ), where P = R(P ) if R is the cipher’s round (see\n1 1 2 2 2 1\nFigure 4-1). When rounds are identical, the relation between the two\nplaintexts, P = R(P ), implies the relation C2 = R(C ) between their\n2 1 1\nrespective ciphertexts. Figure 4-1 shows three rounds, but the relation C2\n= R(C ) will hold no matter the number of rounds, be it 3, 10, or 100.\n1\nThe problem is that knowing the input and output of a single round often\nhelps recover the key. (For details, read the 1999 paper by Biryukov and\nWagner called “Advanced Slide Attacks,” available at\nhttps://www.iacr.org/archive/eurocrypt2000/1807/18070595-new.pdf)\nThe use of different round keys as parameters ensures that the rounds\nwill behave differently and thus foil slide attacks.\nFigure 4-1: The principle of the slide attack, against block ciphers with identical\nrounds\nNOTE\nOne potential byproduct and benefit of using round keys is protection against\nside-channel attacks, or attacks that exploit information leaked from the\nimplementation of a cipher (for example, electromagnetic emanations). If the\ntransformation from the main key, K, to a round key, K , is not invertible,\ni\nthen if an attacker finds K , they can’t use that key to find K. Unfortunately,\ni\nfew block ciphers have a one-way key schedule. The key schedule of AES\nallows attackers to compute K from any round key, K , for example.\ni\nSubstitution–Permutation Networks\nIf you’ve read textbooks about cryptography, you’ll undoubtedly have\nread about confusion and diffusion. Confusion means that the input\n(plaintext and encryption key) undergoes complex transformations, and\ndiffusion means that these transformations depend equally on all bits of\nthe input. At a high level, confusion is about depth whereas diffusion is\nabout breadth. In the design of a block cipher, confusion and diffusion\ntake the form of substitution and permutation operations, which are\ncombined within substitution–permutation networks (SPNs).\nSubstitution often appears in the form of S-boxes, or substitution boxes,\nwhich are small lookup tables that transform chunks of 4 or 8 bits. For\nexample, the first of the eight S-boxes of the block cipher Serpent is\ncomposed of the 16 elements (3 8 f 1 a 6 5 b e d 4 2 7 0 9 c), where each\nelement represents a 4-bit nibble. This particular S-box maps the 4-bit\nnibble 0000 to 3 (0011), the 4-bit nibble 0101 (5 in decimal) to 6 (0110),\nand so on.\nNOTE\nS-boxes must be carefully chosen to be cryptographically strong: they should be\nas nonlinear as possible (inputs and outputs should be related with complex\nequations) and have no statistical bias (meaning, for example, that flipping\nan input bit should potentially affect any of the output bits).\nThe permutation in a substitution–permutation network can be as\nsimple as changing the order of the bits, which is easy to implement but\ndoesn’t mix up the bits very much. Instead of a reordering of the bits,\nsome ciphers use basic linear algebra and matrix multiplications to mix up\nthe bits: they perform a series of multiplication operations with fixed\nvalues (the matrix’s coefficients) and then add the results. Such linear\nalgebra operations can quickly create dependencies between all the bits\nwithin a cipher and thus ensure strong diffusion. For example, the block\ncipher FOX transforms a 4-byte vector (a, b, c, d) to (a′, b′, c′, d′), defined\nas follows:\nIn the above equations, the numbers 2 and 253 are interpreted as\nbinary polynomials rather than integers; hence, additions and\nmultiplications are defined a bit differently than what we’re used to. For\nexample, instead of having 2 + 2 = 4, we have 2 + 2 = 0. Regardless, the\npoint is that each byte in the initial state affects all 4 bytes in the final\nstate.\nFeistel Schemes\nIn the 1970s, IBM engineer Horst Feistel designed a block cipher called\nLucifer that works as follows:\n1. Split the 64-bit block into two 32-bit halves, L and R.\n2. Set L to L ⊕ F(R), where F is a substitution–permutation round.\n3. Swap the values of L and R.\n4. Go to step 2 and repeat 15 times.\n5. Merge L and R into the 64-bit output block.\nThis construction became known as a Feistel scheme, as shown in Figure\n4-2. The left side is the scheme as just described; the right side is a\nfunctionally equivalent representation where, instead of swapping L and\nR, rounds alternate the operations L = L ⊕ F(R) and R = R ⊕ F(L).\nFigure 4-2: The Feistel scheme block cipher construction in two equivalent forms\nI’ve omitted the keys from Figure 4-2 to simplify the diagrams, but\nnote that the first F takes a first round key, K , and the second F takes\n1\nanother round key, K . In DES, the F functions take a 48-bit round key,\n2\nwhich is derived from the 56-bit key, K.\nIn a Feistel scheme, the F function can be either a pseudorandom\npermutation (PRP) or a pseudorandom function (PRF). A PRP yields\ndistinct outputs for any two distinct inputs, whereas a PRF will have\nvalues X and Y for which F(X) = F(Y). But in a Feistel scheme, that\ndifference doesn’t matter as long as F is cryptographically strong.\nHow many rounds should there be in a Feistel scheme? Well, DES\nperforms 16 rounds, whereas GOST 28147-89 performs 32 rounds. If the\nF function is as strong as possible, four rounds are in theory sufficient,\nbut real ciphers use more rounds to defend against potential weaknesses\nin F.\nThe Advanced Encryption Standard (AES)\nAES is the most-used cipher in the universe. Prior to the adoption of\nAES, the standard cipher in use was DES, with its ridiculous 56-bit\nsecurity, as well as the upgraded version of DES known as Triple DES, or\n3DES.\nAlthough 3DES provides a higher level of security (112-bit security),\nit’s inefficient because the key needs to be 168 bits long in order to get\n112-bit security, and it’s slow in software (DES was created to be fast in\nintegrated circuits, not on mainstream CPUs). AES fixes both issues.\nNIST standardized AES in 2000 as a replacement for DES, at which\npoint it became the world’s de facto encryption standard. Most\ncommercial encryption products today support AES, and the NSA has\napproved it for protecting top-secret information. (Some countries do\nprefer to use their own cipher, largely because they don’t want to use a\nUS standard, but AES is actually more Belgian than it is American.)\nNOTE\nAES used to be called Rijndael (a portmanteau for its inventors’ names,\nRijmen and Daemen, pronounced like “rain-dull”) when it was one of the 15\ncandidates in the AES competition, the process held by NIST from 1997 to\n2000 to specify “an unclassified, publicly disclosed encryption algorithm\ncapable of protecting sensitive government information well into the next\ncentury,” as stated in the 1997 announcement of the competition in the\nFederal Register. The AES competition was kind of a “Got Talent”\ncompetition for cryptographers, where anyone could participate by submitting\na cipher or breaking other contestants’ ciphers.\nAES Internals\nAES processes blocks of 128 bits using a secret key of 128, 192, or 256\nbits, with the 128-bit key being the most common because it makes\nencryption slightly faster and because the difference between 128- and\n256-bit security is meaningless for most applications.\nFigure 4-3: The internal state of AES viewed as a 4 × 4 array of 16 bytes\nWhereas some ciphers work with individual bits or 64-bit words, AES\nmanipulates bytes. It views a 16-byte plaintext as a two-dimensional array\nof bytes (s = s , s , . . . , s ), as shown in Figure 4-3. (The letter s is used\n0 1 15\nbecause this array is called the internal state, or just state.) AES transforms\nthe bytes, columns, and rows of this array to produce a final value that is\nthe ciphertext.\nIn order to transform its state, AES uses an SPN structure like the one\nshown in Figure 4-4, with 10 rounds for 128-bit keys, 12 for 192-bit keys,\nand 14 for 256-bit keys.\nFigure 4-4: The internal operations of AES\nFigure 4-4 shows the four building blocks of an AES round (note that\nall but the last round are a sequence of SubBytes, ShiftRows,\nMixColumns, and AddRoundKey):\nAddRoundKey XORs a round key to the internal state.\nSubBytes Replaces each byte (s , s , . . . , s ) with another byte\n0 1 15\naccording to an S-box. In this example, the S-box is a lookup table of\n256 elements.\nShiftRows Shifts the ith row of i positions, for i ranging from 0 to 3\n(see Figure 4-5).\nMixColumns Applies the same linear transformation to each of the\nfour columns of the state (that is, each group of cells with the same\nshade of gray, as shown on the left side of Figure 4-5).\nRemember that in an SPN, the S stands for substitution and the P for\npermutation. Here, the substitution layer is SubBytes and the\npermutation layer is the combination of ShiftRows and MixColumns.\nThe key schedule function KeyExpansion, shown in Figure 4-4, is the\nAES key schedule algorithm. This expansion creates 11 round keys (K ,\n0\nK , . . . , K ) of 16 bytes each from the 16-byte key, using the same S-box\n1 10\nas SubBytes and a combination of XORs. One important property of\nKeyExpansion is that given any round key, K , an attacker can determine\ni\nall other round keys as well as the main key, K, by reversing the\nalgorithm. The ability to get the key from any round key is usually seen\nas an imperfect defense against side-channel attacks, where an attacker\nmay easily recover a round key.\nFigure 4-5: ShiftRows rotates bytes within each row of the internal state.\nWithout these operations, AES would be totally insecure. Each\noperation contributes to AES’s security in a specific way:\nWithout KeyExpansion, all rounds would use the same key, K, and\nAES would be vulnerable to slide attacks.\nWithout AddRoundKey, encryption wouldn’t depend on the key;\nhence, anyone could decrypt any ciphertext without the key.\nSubBytes brings nonlinear operations, which add cryptographic\nstrength. Without it, AES would just be a large system of linear\nequations that is solvable using high-school algebra.\nWithout ShiftRows, changes in a given column would never affect\nthe other columns, meaning you could break AES by building four\n232-element codebooks for each column. (Remember that in a secure\nblock cipher, flipping a bit in the input should affect all the output\nbits.)\nWithout MixColumns, changes in a byte would not affect any other\nbytes of the state. A chosen-plaintext attacker could then decrypt any\nciphertext after storing 16 lookup tables of 256 bytes each that hold\nthe encrypted values of each possible value of a byte.\nNotice in Figure 4-4 that the last round of AES doesn’t include the\nMixColumns operation. That operation is omitted in order to save\nuseless computation: because MixColumns is linear (meaning,\npredictable), you could cancel its effect in the very last round by\ncombining bits in a way that doesn’t depend on their value or the key.\nSubBytes, however, can’t be inverted without the state’s value being\nknown prior to AddRoundKey.\nTo decrypt a ciphertext, AES unwinds each operation by taking its\ninverse function: the inverse lookup table of SubBytes reverses the\nSubBytes transformation, ShiftRow shifts in the opposite direction,\nMixColumns’s inverse is applied (as in the matrix inverse of the matrix\nencoding its operation), and AddRoundKey’s XOR is unchanged because\nthe inverse of an XOR is another XOR.\nAES in Action\nTo try encrypting and decrypting with AES, you can use Python’s\nc rypto​\ngraphy library, as in Listing 4-1.\n#!/usr/bin/env python\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms,\nmodes\nfrom cryptography.hazmat.backends import default_backend\nfrom binascii import hexlify as hexa\nfrom os import urandom\n# pick a random 16-byte key using Python's crypto PRNG\nk = urandom(16)\nprint \"k = %s\" % hexa(k)\n# create an instance of AES-128 to encrypt a single block\ncipher = Cipher(algorithms.AES(k), modes.ECB(), backend =\ndefault_backend())\naes_encrypt = cipher.encryptor()\n# set plaintext block p to the all-zero string\np = '\\x00'*16\n# encrypt plaintext p to ciphertext c\nc = aes_encrypt.update(p) + aes_encrypt.finalize()\nprint \"enc(%s) = %s\" % (hexa(p), hexa(c))\n# decrypt ciphertext c to plaintext p\naes_decrypt = cipher.decryptor()\np = aes_decrypt.update(c) + aes_decrypt.finalize()\nprint \"dec(%s) = %s\" % (hexa(c), hexa(p))\nListing 4-1: Trying AES with Python’s cryptography library\nRunning this script produces something like the following output:\n$ ./aes_block.py\nk = 2c6202f9a582668aa96d511862d8a279\nenc(00000000000000000000000000000000) = 12b620bb5eddcde9a07523e59292a6d7\ndec(12b620bb5eddcde9a07523e59292a6d7) = 00000000000000000000000000000000\nYou’ll get different results because the key is randomized at every new\nexecution.\nImplementing AES\nReal AES software works differently than the algorithm shown in Figure\n4-4. You won’t find production-level AES code calling a SubBytes()\nfunction, then a ShiftRows() function, and then a MixColumns() function\nbecause that would be inefficient. Instead, fast AES software uses special\ntechniques called table-based implementations and native instructions.\nTable-Based Implementations\nTable-based implementations of AES replace the sequence SubBytes-\nShiftRows-MixColumns with a combination of XORs and lookups in\ntables hardcoded into the program and loaded in memory at execution\ntime. This is possible because MixColumns is equivalent to XORing four\n32-bit values, where each depends on a single byte from the state and on\nSubBytes. Thus, you can build four tables with 256 entries each, one for\neach byte value, and implement the sequence SubBytes-MixColumns by\nlooking up four 32-bit values and XORing them together.\nFor example, the table-based C implementation in the OpenSSL\ntoolkit looks like Listing 4-2.\n/* round 1: */\nt0 = Te0[s0 >> 24] ^ Te1[(s1 >> 16) & 0xff] ^ Te2[(s2 >> 8) & 0xff] ^ Te3[s3 &\n0xff] ^ rk[ 4];\nt1 = Te0[s1 >> 24] ^ Te1[(s2 >> 16) & 0xff] ^ Te2[(s3 >> 8) & 0xff] ^ Te3[s0 &\n0xff] ^ rk[ 5];\nt2 = Te0[s2 >> 24] ^ Te1[(s3 >> 16) & 0xff] ^ Te2[(s0 >> 8) & 0xff] ^ Te3[s1 &\n0xff] ^ rk[ 6];\nt3 = Te0[s3 >> 24] ^ Te1[(s0 >> 16) & 0xff] ^ Te2[(s1 >> 8) & 0xff] ^ Te3[s2 &\n0xff] ^ rk[ 7];\n/* round 2: */\ns0 = Te0[t0 >> 24] ^ Te1[(t1 >> 16) & 0xff] ^ Te2[(t2 >> 8) & 0xff] ^ Te3[t3 &\n0xff] ^ rk[ 8];\ns1 = Te0[t1 >> 24] ^ Te1[(t2 >> 16) & 0xff] ^ Te2[(t3 >> 8) & 0xff] ^ Te3[t0 &\n0xff] ^ rk[ 9];\ns2 = Te0[t2 >> 24] ^ Te1[(t3 >> 16) & 0xff] ^ Te2[(t0 >> 8) & 0xff] ^ Te3[t1 &\n0xff] ^ rk[10];\ns3 = Te0[t3 >> 24] ^ Te1[(t0 >> 16) & 0xff] ^ Te2[(t1 >> 8) & 0xff] ^ Te3[t2 &\n0xff] ^ rk[11];\n--snip--\nListing 4-2: The table-based C implementation of AES in OpenSSL\nA basic table-based implementation of AES encryption needs four\nkilobytes’ worth of tables because each table stores 256 32-bit values,\nwhich occupy 256 × 32 = 8192 bits, or one kilobyte. Decryption requires\nanother four tables, and thus four more kilobytes. But there are tricks to\nreduce the storage from four kilobytes to one, or even fewer.\nAlas, table-based implementations are vulnerable to cache-timing attacks,\nwhich exploit timing variations when a program reads or writes elements\nin cache memory. Depending on the relative position in cache memory of\nthe elements accessed, access time varies. Timings thus leak information\nabout which element was accessed, which in turn leaks information on the\nsecrets involved.\nCache-timing attacks are difficult to avoid. One obvious solution would\nbe to ditch lookup tables altogether by writing a program whose\nexecution time doesn’t depend on its inputs, but that’s almost impossible\nto do and still retain the same speed, so chip manufacturers have opted\nfor a radical solution: instead of relying on potentially vulnerable\nsoftware, they rely on hardware.\nNative Instructions\nAES native instructions (AES-NI) solve the problem of cache-timing\nattacks on AES software implementations. To understand how AES-NI\nworks, you need to think about the way software runs on hardware: to run\na program, a microprocessor translates binary code into a series of\ninstructions executed by integrated circuit components. For example, a\nMUL assembly instruction between two 32-bit values will activate the\ntransistors implementing a 32-bit multiplier in the microprocessor. To\nimplement a crypto algorithm, we usually just express a combination of\nsuch basic operations—additions, multiplications, XORs, and so on—and\nthe microprocessor activates its adders, multipliers, and XOR circuits in\nthe prescribed order.\nAES native instructions take this to a whole new level by providing\ndevelopers with dedicated assembly instructions that compute AES.\nInstead of coding an AES round as a sequence of assembly instructions,\nwhen using AES-NI, you just call the instruction AESENC and the chip will\ncompute the round for you. Native instructions allow you to just tell the\nprocessor to run an AES round instead of requiring you to program\nrounds as a combination of basic operations.\nA typical assembly implementation of AES using native instructions\nlooks like Listing 4-3.\nPXOR %xmm5, %xmm0\nAESENC %xmm6, %xmm0\nAESENC %xmm7, %xmm0\nAESENC %xmm8, %xmm0\nAESENC %xmm9, %xmm0\nAESENC %xmm10, %xmm0\nAESENC %xmm11, %xmm0\nAESENC %xmm12, %xmm0\nAESENC %xmm13, %xmm0\nAESENC %xmm14, %xmm0\nAESENCLAST %xmm15, %xmm0\nListing 4-3: AES native instructions\nThis code encrypts the 128-bit plaintext initially in the register xmm0,\nassuming that registers xmm5 to xmm15 hold the precomputed round keys,\nwith each instruction writing its result into xmm0. The initial PXOR\ninstruction XORs the first round key prior to computing the first round,\nand the final AESENCLAST instruction performs the last round slightly\ndifferent from the others (MixColumns is omitted).\nNOTE\nAES is about ten times faster on platforms that implement native\ninstructions, which as I write this, are virtually all laptop, desktop, and\nserver microprocessors, as well as most mobile phones and tablets. In fact, on\nthe latest Intel microarchitecture the AESENC instruction has a latency of\nfour cycles with a reciprocal throughput of one cycle, meaning that a call to\nAESENC takes four cycles to complete and that a new call can be made every\ncycle. To encrypt a series of blocks consecutively it thus takes 4 × 10 = 40\ncycles to complete the 10 rounds or 40 / 16 = 2.5 cycles per byte. At 2 GHz (2\n× 10 9 cycles per second), that gives a throughput of about 736 megabytes per\nsecond. If the blocks to encrypt or decrypt are independent of each other, as\ncertain modes of operation allow, then four blocks can be processed in parallel\nto take full advantage of the AESENC circuit in order to reach a latency of\n10 cycles per block instead of 40, or about 3 gigabytes per second.\nIs AES Secure?\nAES is as secure as a block cipher can be, and it will never be broken.\nFundamentally, AES is secure because all output bits depend on all input\nbits in some complex, pseudorandom way. To achieve this, the designers\nof AES carefully chose each component for a particular reason—\nMixColumns for its maximal diffusion properties and SubBytes for its\noptimal non-linearity—and they have shown that this composition\nprotects AES against whole classes of cryptanalytic attacks.\nBut there’s no proof that AES is immune to all possible attacks. For\none thing, we don’t know what all possible attacks are, and we don’t\nalways know how to prove that a cipher is secure against a given attack.\nThe only way to really gain confidence in the security of AES is to\ncrowdsource attacks: have many skilled people attempt to break AES and,\nhopefully, fail to do so.\nAfter more than 15 years and hundreds of research publications, the\ntheoretical security of AES has only been scratched. In 2011 cryptanalysts\nfound a way to recover an AES-128 key by performing about 2126\noperations instead of 2128, a speed-up of a factor four. But this “attack”\nrequires an insane amount of plaintext–ciphertext pairs—about 288 bits\nworth. In other words, it’s a nice finding but not one you need to worry\nabout.\nThe upshot is that you should care about a million things when\nimplementing and deploying crypto, but AES security is not one of those.\nThe biggest threat to block ciphers isn’t in their core algorithms but in\ntheir modes of operation. When an incorrect mode is chosen, or when\nthe right one is misused, even a strong cipher like AES won’t save you.\nModes of Operation\nIn Chapter 1, I explained how encryption schemes combine a\npermutation with a mode of operation to handle messages of any length.\nIn this section, I’ll cover the main modes of operations used by block\nciphers, their security and function properties, and how (not) to use them.\nI’ll begin with the dumbest one: electronic codebook.\nThe Electronic Codebook (ECB) Mode\nFigure 4-6: The ECB mode\nThe simplest of the block cipher encryption modes is electronic\ncodebook (ECB), which is barely a mode of operation at all. ECB takes\nplaintext blocks P , P , . . . , P and processes each independently by\n1 2 N\ncomputing C = E(K, P ), C = E(K, P ), and so on, as shown in Figure 4-\n1 1 2 2\n6. It’s a simple operation but also an insecure one. I repeat: ECB is\ninsecure and you should not use it!\nMarsh Ray, a cryptographer at Microsoft, once said, “Everybody knows\nECB mode is bad because we can see the penguin.” He was referring to a\nfamous illustration of ECB’s insecurity that uses an image of Linux’s\nmascot, Tux, as shown in Figure 4-7. You can see the original image of\nTux on the left, and the image encrypted in ECB mode using AES\n(though the underlying cipher doesn’t matter) on the right. It’s easy to\nsee the penguin’s shape in the encrypted version because all the blocks of\none shade of gray in the original image are encrypted to the same new\nshade of gray in the new image; in other words, ECB encryption just\ngives you the same image but with different colors.\nFigure 4-7: The original image (left) and the ECB-encrypted image (right)\nThe Python program in Listing 4-4 also shows ECB’s insecurity. It\npicks a pseudorandom key and encrypts a 32-byte message p containing\ntwo blocks of null bytes. Notice that encryption yields two identical\nblocks and that repeating encryption with the same key and the same\nplaintext yields the same two blocks again.\n#!/usr/bin/env python\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms,\nmodes\nfrom cryptography.hazmat.backends import default_backend\nfrom binascii import hexlify as hexa\nfrom os import urandom\nBLOCKLEN = 16\ndef blocks(data):\nsplit = [hexa(data[i:i+BLOCKLEN]) for i in range(0, len(data),\nBLOCKLEN)]\nreturn ' '.join(split)\nk = urandom(16)\nprint 'k = %s' % hexa(k)\n# create an instance of AES-128 to encrypt and decrypt\ncipher = Cipher(algorithms.AES(k), modes.ECB(),\nbackend=default_backend())\naes_encrypt = cipher.encryptor()\n# set plaintext block p to the all-zero string\np = '\\x00'*BLOCKLEN*2\n# encrypt plaintext p to ciphertext c\nc = aes_encrypt.update(p) + aes_encrypt.finalize()\nprint 'enc(%s) = %s' % (blocks(p), blocks(c))\nListing 4-4: Using AES in ECB mode in Python\nRunning this script gives ciphertext blocks like this, for example:\n$ ./aes_ecb.py\nk = 50a0ebeff8001250e87d31d72a86e46d\nenc(00000000000000000000000000000000 00000000000000000000000000000000) =\n5eb4b7af094ef7aca472bbd3cd72f1ed 5eb4b7af094ef7aca472bbd3cd72f1ed\nAs you can see, when the ECB mode is used, identical ciphertext blocks\nreveal identical plaintext blocks to an attacker, whether those are blocks\nwithin a single ciphertext or across different ciphertexts. This shows that\nblock ciphers in ECB mode aren’t semantically secure.\nAnother problem with ECB is that it only takes complete blocks of\ndata, so if blocks were 16 bytes, as in AES, you could only encrypt chunks\nof 16 bytes, 32 bytes, 48 bytes, or any other multiple of 16 bytes. There\nare a few ways to deal with this, as you’ll see with the next mode, CBC. (I\nwon’t tell you how these tricks work with ECB because you shouldn’t be\nusing ECB in the first place.)\nThe Cipher Block Chaining (CBC) Mode\nCipher block chaining (CBC) is like ECB but with a small twist that\nmakes a big difference: instead of encrypting the ith block, P , as C = E(K,\ni i\nP ), CBC sets C = E(K, P ⊕ C ), where C is the previous ciphertext\ni i i i − 1 i − 1\nblock—thereby chaining the blocks C and C . When encrypting the\ni − 1 i\nfirst block, P , there is no previous ciphertext block to use, so CBC takes\n1\na random initial value (IV), as shown in Figure 4-8.\nFigure 4-8: The CBC mode\nThe CBC mode makes each ciphertext block dependent on all the\nprevious blocks, and ensures that identical plaintext blocks won’t be\nidentical ciphertext blocks. The random initial value guarantees that two\nidentical plaintexts will encrypt to distinct ciphertexts when calling the\ncipher twice with two distinct initial values.\nListing 4-5 illustrates these two benefits. This program takes an all-\nzero, 32-byte message (like the one in Listing 4-4), encrypts it twice with\nCBC, and shows the two ciphertexts. The line iv = urandom(16), shown in\nbold, picks a new random IV for each new encryption.\n#!/usr/bin/env python\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.backends import default_backend\nfrom binascii import hexlify as hexa\nfrom os import urandom\nBLOCKLEN = 16\n# the blocks() function splits a data string into space-separated blocks\ndef blocks(data):\nsplit = [hexa(data[i:i+BLOCKLEN]) for i in range(0, len(data), BLOCKLEN)]\nreturn ' '.join(split)\nk = urandom(16)\nprint 'k = %s' % hexa(k)\n# pick a random IV\niv = urandom(16)\nprint 'iv = %s' % hexa(iv)\n# pick an instance of AES in CBC mode\naes = Cipher(algorithms.AES(k), modes.CBC(iv),\nbackend=default_backend()).encryptor()\np = '\\x00'*BLOCKLEN*2\nc = aes.update(p) + aes.finalize()\nprint 'enc(%s) = %s' % (blocks(p), blocks(c))\n# now with a different IV and the same key\niv = urandom(16)\nprint 'iv = %s' % hexa(iv)\naes = Cipher(algorithms.AES(k), modes.CBC(iv),\nbackend=default_backend()).encryptor()\nc = aes.update(p) + aes.finalize()\nprint 'enc(%s) = %s' % (blocks(p), blocks(c))\nListing 4-5: Using AES in CBC mode\nThe two plaintexts are the same (two all-zero blocks), but the\nencrypted blocks should be distinct, as in this example execution:\n$ ./aes_cbc.py\nk = 9cf0d31ad2df24f3cbbefc1e6933c872\niv = 0a75c4283b4539c094fc262aff0d17af\nenc(00000000000000000000000000000000 00000000000000000000000000000000) =\n370404dcab6e9ecbc3d24ca5573d2920 3b9e5d70e597db225609541f6ae9804a\niv = a6016a6698c3996be13e8739d9e793e2\nenc(00000000000000000000000000000000 00000000000000000000000000000000) =\n655e1bb3e74ee8cf9ec1540afd8b2204 b59db5ac28de43b25612dfd6f031087a\nAlas, CBC is often used with a constant IV instead of a random one,\nwhich exposes identical plaintexts and plaintexts that start with identical\nblocks. For example, say the two-block plaintext P || P is encrypted in\n1 2\nCBC mode to the two-block ciphertext C || C . If P || P ′ is encrypted\n1 2 1 2\nwith the same IV, where P ′ is some block distinct from P , then the\n2 2\nciphertext will look like C || C ′, with C ′ different from C but with the\n1 2 2 2\nsame first block C . Thus, an attacker can guess that the first block is the\n1\nsame for both plaintexts, even though they only see the ciphertexts.\nNOTE\nIn CBC mode, decryption needs to know the IV used to encrypt, so the IV is\nsent along with the ciphertext, in the clear.\nWith CBC, decryption can be much faster than encryption due to\nparallelism. While encryption of a new block, P , needs to wait for the\ni\nprevious block, C , decryption of a block computes P = D(K, C ) ⊕ C\ni − 1 i i i −\n, where there’s no need for the previous plaintext block, P . This\n1 i − 1\nmeans that all blocks can be decrypted in parallel simultaneously, as long\nas you also know the previous ciphertext block, which you usually do.\nHow to Encrypt Any Message in CBC Mode\nLet’s circle back to the block termination issue and look at how to process\na plaintext whose length is not a multiple of the block length. For\nexample, how would we encrypt an 18-byte plaintext with AES-CBC\nwhen blocks are 16 bytes? What do we do with the two bytes left? We’ll\nlook at two widely used techniques to deal with this problem. The first\none, padding, makes the ciphertext a bit longer than the plaintext, while\nthe second one, ciphertext stealing, produces a ciphertext of the same\nlength as the plaintext.\nPadding a Message\nPadding is a technique that allows you to encrypt a message of any\nlength, even one smaller than a single block. Padding for block ciphers is\nspecified in the PKCS#7 standard and in RFC 5652, and is used almost\neverywhere CBC is used, such as in some HTTPS connections.\nPadding is used to expand a message to fill a complete block by adding\nextra bytes to the plaintext. Here are the rules for padding 16-byte blocks:\nIf there’s one byte left—for example, if the plaintext is 1 byte, 17\nbytes, or 33 bytes long—pad the message with 15 bytes 0f (15 in\ndecimal).\nIf there are two bytes left, pad the message with 14 bytes 0e (14 in\ndecimal).\nIf there are three bytes left, pad the message with 13 bytes 0d (13 in\ndecimal).\nIf there are 15 plaintext bytes and a single byte missing to fill a block,\npadding adds a single 01 byte. If the plaintext is already a multiple of 16,\nthe block length, add 16 bytes 10 (16 in decimal). You get the idea. The\ntrick generalizes to any block length up to 255 bytes (for larger blocks, a\nbyte is too small to encode values greater than 255).\nDecryption of a padded message works like this:\n1. Decrypt all the blocks as with unpadded CBC.\n2. Make sure that the last bytes of the last block conform to the\npadding rule: that they finish with at least one 01 byte, at least two\n02 bytes, or at least three 03 bytes, and so on. If the padding isn’t\nvalid—for example, if the last bytes are 01 02 03—the message is\nrejected. Otherwise, decryption strips the padding bytes and returns\nthe plaintext bytes left.\nOne downside of padding is that it makes ciphertext longer by at least\none byte and at most a block.\nCiphertext Stealing\nCiphertext stealing is another trick used to encrypt a message whose\nlength isn’t a multiple of the block size. Ciphertext stealing is more\ncomplex and less popular than padding, but it offers at least three\nbenefits:\nPlaintexts can be of any bit length, not just bytes. You can, for\nexample, encrypt a message of 131 bits.\nCiphertexts are exactly the same length as plaintexts.\nCiphertext stealing is not vulnerable to padding oracle attacks,\npowerful attacks that sometimes work against CBC with padding (as\nwe’ll see in “Padding Oracle Attacks” on page 74).\nIn CBC mode, ciphertext stealing extends the last incomplete plaintext\nblock with bits from the previous ciphertext block, and then encrypts the\nresulting block. The last, incomplete ciphertext block is made up of the\nfirst blocks from the previous ciphertext block; that is, the bits that have\nnot been appended to the last plaintext block.\nFigure 4-9: Ciphertext stealing for CBC-mode encryption\nIn Figure 4-9, we have three blocks, where the last block, P , is\n3\nincomplete (represented by a zero). P is XORed with the last bits from\n3\nthe previous ciphertext block, and the encrypted result is returned as C .\n2\nThe last ciphertext block, C , then consists of the first bits from the\n3\nprevious ciphertext block. Decryption is simply the inverse of this\noperation.\nThere aren’t any major problems with ciphertext stealing, but it’s\ninelegant and hard to get right, especially when NIST’s standard specifies\nthree different ways to implement it (see Special Publication 800-38A).\nThe Counter (CTR) Mode\nTo avoid the troubles and retain the benefits of ciphertext stealing, you\nshould use counter mode (CTR). CTR is hardly a block cipher mode: it\nturns a block cipher into a stream cipher that just takes bits in and spits\nbits out and doesn’t embarrass itself with the notion of blocks. (I’ll discuss\nstream ciphers in detail in Chapter 5.)\nFigure 4-10: The CTR mode\nIn CTR mode (see Figure 4-10), the block cipher algorithm won’t\ntransform plaintext data. Instead, it will encrypt blocks composed of a\ncounter and a nonce. A counter is an integer that is incremented for each\nblock. No two blocks should use the same counter within a message, but\ndifferent messages can use the same sequence of counter values (1, 2, 3, . .\n.). A nonce is a number used only once. It is the same for all blocks in a\nsingle message, but no two messages should use the same nonce.\nAs shown in Figure 4-10, in CTR mode, encryption XORs the\nplaintext and the stream taken from “encrypting” the nonce, N, and\ncounter, Ctr. Decryption is the same, so you only need the encryption\nalgorithm for both encryption and decryption. The Python script in\nListing 4-6 gives you a hands-on example.\n#!/usr/bin/env python\nfrom Crypto.Cipher import AES\nfrom Crypto.Util import Counter\nfrom binascii import hexlify as hexa\nfrom os import urandom\nfrom struct import unpack\nk = urandom(16)\nprint 'k = %s' % hexa(k)\n# pick a starting value for the counter\nnonce = unpack('<Q', urandom(8))[0]\n# instantiate a counter function\nctr = Counter.new(128, initial_value=nonce)\n# pick an instance of AES in CTR mode, using ctr as counter\naes = AES.new(k, AES.MODE_CTR, counter=ctr)\n# no need for an entire block with CTR\np = '\\x00\\x01\\x02\\x03'\n# encrypt p\nc = aes.encrypt(p)\nprint 'enc(%s) = %s' % (hexa(p), hexa(c))\n# decrypt using the encrypt function\nctr = Counter.new(128, initial_value=nonce)\naes = AES.new(k, AES.MODE_CTR, counter=ctr)\np = aes.encrypt(c)\nprint 'enc(%s) = %s' % (hexa(c), hexa(p))\nListing 4-6: Using AES in CTR mode\nThe example execution encrypts a 4-byte plaintext and gets a 4-byte\nciphertext. It then decrypts that ciphertext using the encryption function:\n$ ./aes_ctr.py\nk = 130a1aa77fa58335272156421cb2a3ea\nenc(00010203) = b23d284e\nenc(b23d284e) = 00010203\nAs with the initial value in CBC, CTR’s nonce is supplied by the\nencrypter and sent with the ciphertext in the clear. But unlike CBC’s\ninitial value, CTR’s nonce doesn’t need to be random, it simply needs to\nbe unique. A nonce should be unique for the same reason that a one-time\npad shouldn’t be reused: when calling the pseudorandom stream, S, if you\nencrypt P to C = P ⊕ S and P to C = P ⊕ S using the same nonce,\n1 1 1 2 2 2\nthen C ⊕ C reveals P ⊕ P .\n1 2 1 2\nA random nonce will do the trick only if it’s long enough; for example,\nif the nonce is n bits, chances are that after 2N/ 2 encryptions and as many\nnonces you’ll run into duplicates. Sixty-four bits are therefore insufficient\nfor a random nonce, since you can expect a repetition after approximately\n232 nonces, which is an unacceptably low number.\nThe counter is guaranteed unique if it’s incremented for every new\nplaintext, and if it’s long enough; for example, a 64-bit counter.\nOne particular benefit to CTR is that it can be faster than in any other\nmode. Not only is it parallelizable, but you can also start encrypting even\nbefore knowing the message by picking a nonce and computing the\nstream that you’ll later XOR with the plaintext.\nHow Things Can Go Wrong\nThere are two must-know attacks on block ciphers: meet-in-the-middle\nattacks, a technique discovered in the 1970s but still used in many\ncryptanalytic attacks (not to be confused with man-in-the-middle attacks),\nand padding oracle attacks, a class of attacks discovered in 2002 by\nacademic cryptographers, then mostly ignored, and finally rediscovered a\ndecade later along with several vulnerable applications.\nMeet-in-the-Middle Attacks\nThe 3DES block cipher is an upgraded version of the 1970s standard\nDES that takes a key of 56 × 3 = 168 bits (an improvement on DES’s 56-\nbit key). But the security level of 3DES is 112 bits instead of 168 bits,\nbecause of the meet-in-the-middle (MitM) attack.\nAs you can see in Figure 4-11, 3DES encrypts a block using the DES\nencryption and decryption functions: first encryption with a key, K , then\n1\ndecryption with a key, K , and finally encryption with another key, K . If\n2 3\nK = K , the first two calls cancel themselves out and 3DES boils down to\n1 2\na single DES with key K . 3DES does encrypt-decrypt-encrypt rather\n3\nthan encrypting thrice to allow systems to emulate DES when necessary\nusing the new 3DES interface.\nFigure 4-11: The 3DES block cipher construction\nWhy use triple DES and not just double DES, that is, E(K , E(K , P))?\n1 2\nIt turns out that the MitM attack makes double DES only as secure as\nsingle DES. Figure 4-12 shows the MitM attack in action.\nFigure 4-12: The meet-in-the-middle attack\nThe meet-in-the-middle attack works as follows to attack double DES:\n1. Say you have P and C = E(K , E(K , P)) with two unknown 56-bit\n2 1\nkeys, K and K . (DES takes 56-bit keys, so double DES takes 112\n1 2\nkey bits in total.) You build a key–value table with 256 entries of\nE(K , P), where E is the DES encryption function and K is the value\n1 1\nstored.\n2. For all 256 values of K , compute D(K , C) and check whether the\n2 2\nresulting value appears in the table as an index (thus as a middle\nvalue, represented by a question mark in Figure 4-12).\n3. If a middle value is found as an index of the table, you fetch the\ncorresponding K from the table and verify that the (K , K ) found is\n1 1 2\nthe right one by using other pairs of P and C. Encrypt P using K and\n1\nK and then check that the ciphertext obtained is the given C.\n2\nThis method recovers K and K by performing about 257 instead of\n1 2\n2112 operations: step 1 encrypts 256 blocks and then step 2 decrypts at\nmost 256 blocks, for 256 + 256 = 257 operations in total. You also need to\nstore 256 elements of 15 bytes each, or about 128 petabytes. That’s a lot,\nbut there’s a trick that allows you to run the same attack with only\nnegligible memory (as you’ll see in Chapter 6).\nAs you can see, you can apply the MitM attack to 3DES in almost the\nsame way you would to double DES, except that the third stage will go\nthrough all 2112 values of K and K . The whole attack thus succeeds after\n2 3\nperforming about 2112 operations, meaning that 3DES gets only 112-bit\nsecurity despite having 168 bits of key material.\nPadding Oracle Attacks\nLet’s conclude this chapter with one of the simplest and yet most\ndevastating attacks of the 2000s: the padding oracle attack. Remember\nthat padding fills the plaintext with extra bytes in order to fill a block. A\nplaintext of 111 bytes, for example, is a sequence of six 16-byte blocks\nfollowed by 15 bytes. To form a complete block, padding adds a 01 byte.\nFor a 110-byte plaintext, padding adds two 02 bytes, and so on.\nA padding oracle is a system that behaves differently depending on\nwhether the padding in a CBC-encrypted ciphertext is valid. You can see\nit as a black box or an API that returns either a success or an error value. A\npadding oracle can be found in a service on a remote host sending error\nmessages when it receives malformed ciphertexts. Given a padding oracle,\npadding oracle attacks record which inputs have a valid padding and\nwhich don’t, and exploit this information to decrypt chosen ciphertext\nvalues.\nFigure 4-13: Padding oracle attacks recover X by choosing C and checking the\n1\nvalidity of padding.\nSay you want to decrypt ciphertext block C . I’ll call X the value you’re\n2\nlooking for, namely D(K, C ), and P the block obtained after decrypting\n2 2\nin CBC mode (see Figure 4-13). If you pick a random block C and send\n1\nthe two-block ciphertext C || C to the oracle, decryption will only\n1 2\nsucceed if C ⊕ P = X ends with valid padding—a single 01 byte, two 02\n1 2\nbytes, or three 03 bytes, and so on.\nBased on this observation, padding oracle attacks on CBC encryption\ncan decrypt a block C like this (bytes are denoted in array notation: C [0]\n2 1\nis C ’s first byte, C [1] its second byte, and so on up to C [15], C ’s last\n1 1 1 1\nbyte):\n1. Pick a random block C and vary its last byte until the padding oracle\n1\naccepts the ciphertext as valid. Usually, in a valid ciphertext, C [15] ⊕\n1\nX[15] = 01, so you’ll find X[15] after trying around 128 values of\nC [15].\n1\n2. Find the value X[14] by setting C [15] to X[15] ⊕ 02 and searching\n1\nfor the C [14] that gives correct padding. When the oracle accepts\n1\nthe ciphertext as valid, it means you have found C [14] such that\n1\nC [14] ⊕ X[14] = 02.\n1\n3. Repeat steps 1 and 2 for all 16 bytes.\nThe attack needs on average 128 queries to the oracle for each of the\n16 bytes, which is about 2000 queries in total. (Note that each query must\nuse the same initial value.)\nNOTE\nIn practice, implementing a padding oracle attack is a bit more complicated\nthan what I’ve described, because you have to deal with wrong guesses at step\n1. A ciphertext may have valid padding not because P ends with a single 01\n2\nbut because it ends with two 02 bytes or three 03 bytes. But that’s easily\nmanaged by testing the validity of ciphertexts where more bytes are modified.\nFurther Reading\nThere’s a lot to say about block ciphers, be it in how algorithms work or\nin how they can be attacked. For instance, Feistel networks and SPNs\naren’t the only ways to build a block cipher. The block ciphers IDEA and\nFOX use the Lai–Massey construction, and Threefish uses ARX\nnetworks, a combination of addition, word rotations, and XORs.\nThere are also many more modes than just ECB, CBC, and CTR.\nSome modes are folklore techniques that nobody uses, like CFB and\nOFB, while others are for specific applications, like XTS for tweakable\nencryption or GCM for authenticated encryption.\nI’ve discussed Rijndael, the AES winner, but there were 14 other\nalgorithms in the race: CAST-256, CRYPTON, DEAL, DFC, E2,\nFROG, HPC, LOKI97, Magenta, MARS, RC6, SAFER+, Serpent, and\nTwofish. I recommend that you look them up to see how they work, how\nthey were designed, how they have been attacked, and how fast they are.\nIt’s also worth checking out the NSA’s designs (Skipjack, and more\nrecently, SIMON and SPECK) and more recent “lightweight” block\nciphers such as KATAN, PRESENT, or PRINCE."
  },
  {
    "input": "What is the difference between stateful and counter-based stream ciphers, and how do they relate to the security and efficiency of cryptographic implementations?",
    "summary": "Stream ciphers generate pseudorandom bits (keystream) and use XOR to encrypt and decrypt data, unlike block ciphers. They come in two main types: stateful and counter-based, and are often used in hardware due to their efficiency. However, they can be insecure if not properly designed, as seen in cases like A5/1 and RC4. Modern secure stream ciphers, such as Grain-128a and Salsa20, use nonlinear functions and careful key scheduling to enhance security. Despite historical concerns, secure stream ciphers are now widely used in protocols like TLS and Bluetooth. RC4, though once popular, has known vulnerabilities that have made it insecure, while Salsa20 is considered much more secure. Poor implementation, such as the XOR-swap in RC4, can also lead to weaknesses. Additionally, stream ciphers used in hardware, like those in satellite phones, may be less secure than their software counterparts.",
    "output": "5\nSTREAM CIPHERS\nSymmetric ciphers can be either block ciphers or stream ciphers. Recall\nfrom Chapter 4 that block ciphers mix chunks of plaintext bits together\nwith key bits to produce chunks of ciphertext of the same size, usually 64\nor 128 bits. Stream ciphers, on the other hand, don’t mix plaintext and\nkey bits; instead, they generate pseudorandom bits from the key and\nencrypt the plaintext by XORing it with the pseudorandom bits, in the\nsame fashion as the one-time pad explained in Chapter 1.\nStream ciphers are sometimes shunned because historically they’ve\nbeen more fragile than block ciphers and are more often broken—both\nthe experimental ones designed by amateurs and the ciphers deployed in\nsystems used by millions, including mobile phones, Wi-Fi, and public\ntransport smart cards. But that’s all history. Fortunately, although it has\ntaken 20 years, we now know how to design secure stream ciphers, and\nwe trust them to protect things like Bluetooth connections, mobile 4G\ncommunications, TLS connections, and more.\nThis chapter first presents how stream ciphers work and discusses the\ntwo main classes of stream ciphers: stateful and counter-based ciphers.\nWe’ll then study hardware- and software-oriented stream ciphers and\nlook at some insecure ciphers (such as A5/1 in GSM mobile\ncommunications and RC4 in TLS) and some secure, state-of-the-art ones\n(such as Grain-128a for hardware and Salsa20 for software).\nHow Stream Ciphers Work\nStream ciphers are more akin to deterministic random bit generators\n(DRBGs) than they are to full-fledged pseudorandom number generators\n(PRNGs) because, like DRBGs, stream ciphers are deterministic. Stream\nciphers’ determinism allows you to decrypt by regenerating the\npseudorandom bits used to encrypt. With a PRNG, you could encrypt\nbut never decrypt—which is secure, but useless.\nWhat sets stream ciphers apart from DRBGs is that DRBGs take a\nsingle input value whereas stream ciphers take two values: a key and a\nnonce. The key should be secret and is usually 128 or 256 bits. The\nnonce doesn’t have to be secret, but it should be unique for each key and\nis usually between 64 and 128 bits.\nFigure 5-1: How stream ciphers encrypt, taking a secret key, K, and a public nonce,\nN\nStream ciphers produce a pseudorandom stream of bits called the\nkeystream. The keystream is XORed to a plaintext to encrypt it and then\nXORed again to the ciphertext to decrypt it. Figure 5-1 shows the basic\nstream cipher encryption operation, where SC is the stream cipher\nalgorithm, KS the keystream, P the plaintext, and C the ciphertext.\nA stream cipher computes KS = SC(K, N), encrypts as C = P ⊕ KS, and\ndecrypts as P = C ⊕ KS. The encryption and decryption functions are the\nsame because both do the same thing—namely, XOR bits with the\nkeystream. That’s why, for example, certain cryptographic libraries\nprovide a single encrypt function that’s used for both encryption and\ndecryption.\nStream ciphers allow you to encrypt a message with key K and nonce\n1\nN and then encrypt another message with key K and nonce N that is\n1 1 2\ndifferent from N , or with key K , which is different from K and nonce\n1 2 1\nN . However, you should never again encrypt with K and N , because\n1 1 1\nyou would then use twice the same keystream KS. You would then have a\nfirst ciphertext C = P ⊕ KS, a second ciphertext C = P ⊕ KS, and if you\n1 1 2 2\nknow P , then you could determine P = C ⊕ C ⊕ P .\n1 2 1 2 1\nNOTE\nThe name nonce is actually short for number used only once. In the\ncontext of stream ciphers, it’s sometimes called the IV, for initial value.\nStateful and Counter-Based Stream Ciphers\nFrom a high-level perspective, there are two types of stream ciphers:\nstateful and counter based. Stateful stream ciphers have a secret internal\nstate that evolves throughout keystream generation. The cipher initializes\nthe state from the key and the nonce and then calls an update function to\nupdate the state value and produce one or more keystream bits from the\nstate, as shown in Figure 5-2. For example, the famous RC4 is a stateful\ncipher.\nFigure 5-2: The stateful stream cipher\nCounter-based stream ciphers produce chunks of keystream from a key, a\nnonce, and a counter value, as shown in Figure 5-3. Unlike stateful\nstream ciphers, such as Salsa20, no secret state is memorized during\nkeystream generation.\nFigure 5-3: The counter-based stream cipher\nThese two approaches define the high-level architecture of the stream\ncipher, regardless of how the core algorithms work. The internals of the\nstream cipher also fall into two categories, depending on the target\nplatform of the cipher: hardware oriented and software oriented.\nHardware-Oriented Stream Ciphers\nWhen cryptographers talk about hardware, they mean application-\nspecific integrated circuits (ASICs), programmable logic devices (PLDs),\nand field-programmable gate arrays (FPGAs). A cipher’s hardware\nimplementation is an electronic circuit that implements the cryptographic\nalgorithm at the bit level and that can’t be used for anything else; in other\nwords, the circuit is dedicated hardware. On the other hand, software\nimplementations of cryptographic algorithms simply tell a\nmicroprocessor what instructions to execute in order to run the\nalgorithm. These instructions operate on bytes or words and then call\npieces of electronic circuit that implement general-purpose operations\nsuch as addition and multiplication. Software deals with bytes or words of\n32 or 64 bits, whereas hardware deals with bits. The first stream ciphers\nworked with bits in order to save complex word-wise operations and thus\nbe more efficient in hardware, their target platform at the time.\nThe main reason why stream ciphers were commonly used for\nhardware implementations is that they were cheaper than block ciphers.\nStream ciphers needed less memory and fewer logical gates than block\nciphers, and therefore occupied a smaller area on an integrated circuit,\nwhich reduced fabrication costs. For example, counting in gate-\nequivalents, the standard area metric for integrated circuits, you could\nfind stream ciphers taking less than 1000 gate-equivalents; by contrast,\ntypical software-oriented block ciphers needed at least 10000 gate-\nequivalents, making crypto an order of magnitude more expensive than\nwith stream ciphers.\nToday, however, block ciphers are no longer more expensive than\nstream ciphers—first, because there are now hardware-friendly block\nciphers about as small as stream ciphers, and second, because the cost of\nhardware has plunged. Yet stream ciphers are often associated with\nhardware because they used to be the best option.\nIn the next section, I’ll explain the basic mechanism behind hardware\nstream ciphers, called feedback shift registers (FSRs). Almost all hardware\nstream ciphers rely on FSRs in some way, whether that’s the A5/1 cipher\nused in 2G mobile phones or the more recent cipher Grain-128a.\nNOTE\nThe first standard block cipher, the Data Encryption Standard (DES), was\noptimized for hardware rather than for software. When the US government\nstandardized DES in the 1970s, most target applications were hardware\nimplementations. It’s therefore no surprise that the S-boxes in DES are\nsmall and fast to compute when implemented as a logical circuit in hardware\nbut inefficient in software. Unlike DES, the current Advanced Encryption\nStandard (AES) deals with bytes and is therefore more efficient in software\nthan DES.\nFeedback Shift Registers\nCountless stream ciphers have used FSRs because they’re simple and well\nunderstood. An FSR is simply an array of bits equipped with an update\nfeedback function, which I’ll denote as f. The FSR’s state is stored in the\narray, or register, and each update of the FSR uses the feedback function\nto change the state’s value and to produce one output bit.\nIn practice, an FSR works like this: if R is the initial value of the FSR,\n0\nthe next state, R , is defined as R left-shifted by 1 bit, where the bit\n1 0\nleaving the register is returned as output, and where the empty position is\nfilled with f(R ).\n0\nThe same rule is repeated to compute the subsequent state values R ,\n2\nR , and so on. That is, given R , the FSR’s state at time t, the next state, R\n3 t t\n, is the following:\n+ 1\nR = (R << 1)|f(R )\ni + 1 t t\nIn this equation, | is the logical OR operator and << is the shift\noperator, as used in the C language. For example, given the 8-bit string\n00001111, we have this:\nThe bit shift moves the bits to the left, losing the leftmost bit in order\nto retain the state’s bit length, and zeroing the rightmost bit. The update\noperation of an FSR is identical, except that instead of being set to 0, the\nrightmost bit is set to f(R ).\nt\nConsider, for example, a 4-bit FSR whose feedback function f XORs all\n4 bits together. Initialize the state to the following:\n1 1 0 0\nNow shift the bits to the left, where 1 is output and the rightmost bit is\nset to the following:\nf(1100) = 1 ⊕ 1 ⊕ 0 ⊕ 0 = 0\nNow the state becomes this:\n1 0 0 0\nThe next update outputs 1, left-shifts the state, and sets the rightmost\nbit to the following:\nf(1000) = 1 ⊕ 0 ⊕ 0 ⊕0 = 1\nNow the state is this:\n0 0 0 1\nThe next three updates return three 0 bits and give the following state\nvalues:\nWe thus return to our initial state of 1100 after five iterations, and we\ncan see that updating the state five times from any of the values observed\nthroughout this cycle will return us to this initial value. We say that 5 is\nthe period of the FSR given any one of the values 1100, 1000, 0001, 0011,\nor 0110. Because the period of this FSR is 5, clocking the register 10\ntimes will yield twice the same 5-bit sequence. Likewise, if you clock the\nregister 20 times, starting from 1100, the output bits will be\n11000110001100011000, or four times the same 5-bit sequence of 11000.\nIntuitively, such repeating patterns should be avoided, and a longer\nperiod is better for security.\nNOTE\nIf you plan to use an FSR in a stream cipher, avoid using one with short\nperiods, which make the output more predictable. Some types of FSRs make it\neasy to figure out their period, but it’s almost impossible to do so with others.\nFigure 5-4 shows the structure of this cycle, along with the other cycles\nof that FSR, with each cycle shown as a circle whose dots represent a state\nof the register.\nFigure 5-4: Cycles of the FSR whose feedback function XORs the 4 bits together\nIndeed, this particular FSR has two other period-5 cycles—namely,\n{0100, 1001, 0010, 0101, 1010} and {1111, 1110, 1101, 1011, 0111}. Note\nthat any given state can belong to only one cycle of states. Here, we have\nthree cycles of five states each, covering 15 of all the 24 = 16 possible\nvalues of our 4-bit register. The 16th possible value is 0000, which, as\nFigure 5-4 shows, is a period-1 cycle because the FSR will transform\n0000 to 0000.\nYou’ve seen that an FSR is essentially a register of bits, where each\nupdate of the register outputs a bit (the leftmost bit of the register) and\nwhere a function computes the new rightmost bit of the register. (All\nother bits are left-shifted.) The period of an FSR, from some initial state,\nis the number of updates needed until the FSR enters the same state\nagain. If it takes N updates to do so, the FSR will produce the same N bits\nagain and again.\nLinear Feedback Shift Registers\nLinear feedback shift registers (LFSRs) are FSRs with a linear feedback\nfunction—namely, a function that’s the XOR of some bits of the state,\nsuch as the example of a 4-bit FSR in the previous section and its\nfeedback function returning the XOR of the register’s 4 bits. Recall that\nin cryptography, linearity is synonymous with predictability and\nsuggestive of a simple underlying mathematical structure. And, as you\nmight expect, thanks to this linearity, LFSRs can be analyzed using\nnotions like linear complexity, finite fields, and primitive polynomials—\nbut I’ll skip the math details and just give you the essential facts.\nThe choice of which bits are XORed together is crucial for the period\nof the LFSR and thus for its cryptographic value. The good news is that\nwe know how to select the position of the bits in order to guarantee a\nmaximal period, of 2n – 1. Specifically, we take the indices of the bits,\nfrom 1 for the rightmost to n for the leftmost, and write the polynomial\nexpression 1 + X + X 2 + . . . + X n, where the term X i is only included if\nthe ith bit is one of the bits XORed in the feedback function. The period\nis maximal if and only if that polynomial is primitive. To be primitive, the\npolynomial must have the following qualities:\nThe polynomial must be irreducible, meaning that it can’t be\nfactorized; that is, written as a product of smaller polynomials. For\nexample, X + X 3 is not irreducible because it’s equal to (1 + X)(X +\nX2):\n(1 + X)(X + X2) = X + X2 + X2 + X3 = X + X3\nThe polynomial must satisfy certain other mathematical properties\nthat cannot be easily explained without nontrivial mathematical\nnotions but are easy to test.\nNOTE\nThe maximal period of an n-bit LFSR is 2n – 1, not 2n, because the all-zero\nstate always loops on itself infinitely. Because the XOR of any number of\nzeros is zero, new bits entering the state from the feedback functions will\nalways be zero; hence, the all-zero state is doomed to stay all zeros.\nFor example, Figure 5-5 shows a 4-bit LFSR with the feedback\npolynomial 1 + X + X 3 + X 4 in which the bits at positions 1, 3, and 4 are\nXORed together to compute the new bit set to L . However, this\n1\npolynomial isn’t primitive because it can be factorized into (1 + X 3)(1 +\nX).\n3 4\nFigure 5-5: An LFSR with the feedback polynomial 1 + X + X + X\nIndeed, the period of the LFSR shown in Figure 5-5 isn’t maximal. To\nprove that, start from the state 0001.\n0 0 0 1\nNow left-shift by 1 bit and set the new bit to 0 + 0 + 1 = 1:\n0 0 1 1\nRepeating the operation four times gives the following state values:\nAnd as you can see, the state after five updates is the same as the initial\none, demonstrating that we’re in a period-5 cycle and proving that the\nLFSR’s period isn’t the maximal value of 15.\nNow, by way of contrast, consider the LFSR shown in Figure 5-6.\n3 4\nFigure 5-6: An LFSR with the feedback polynomial 1 + X + X , a primitive\npolynomial, ensuring a maximal period\nThis feedback polynomial is a primitive polynomial described by 1 + X\n3 + X 4, and you can verify that its period is indeed maximal (namely 15).\nSpecifically, from an initial value, the state evolves as follows:\nThe state spans all possible values except 0000 with no repetition until\nit eventually loops. This demonstrates that the period is maximal and\nproves that the feedback polynomial is primitive.\nAlas, using an LFSR as a stream cipher is insecure. If n is the LFSR’s\nbit length, an attacker needs only n output bits to recover the LFSR’s\ninitial state, allowing them to determine all previous bits and predict all\nfuture bits. This attack is possible because the Berlekamp–Massey\nalgorithm can be used to solve the equations defined by the LFSR’s\nmathematical structure to find not only the LFSR’s initial state but also\nits feedback polynomial. In fact, you don’t even need to know the exact\nlength of the LFSR to succeed; you can repeat the Berlekamp–Massey\nalgorithm for all possible values of n until you hit the right one.\nThe upshot is that LFSRs are cryptographically weak because they’re\nlinear. Output bits and initial state bits are related by simple and short\nequations that can be easily solved with high-school linear algebra\ntechniques.\nTo strengthen LFSRs, let’s thus add a pinch of nonlinearity.\nFiltered LFSRs\nFigure 5-7: A filtered LFSR\nTo mitigate the insecurity of LFSRs, you can hide their linearity by\npassing their output bits through a nonlinear function before returning\nthem to produce what is called a filtered LFSR (see Figure 5-7).\nThe g function in Figure 5-7 must be a nonlinear function—one that\nboth XORs bits together and combines them with logical AND or OR\noperations. For example, L L + L L is a nonlinear function (I’ve omitted\n1 2 3 4\nthe multiply sign, so L L means L × L , or L & L using C syntax).\n1 2 1 2 1 2\nNOTE\nYou can write feedback functions either directly in terms of an FSR’s bits,\nlike L L + L L , or using the equivalent polynomial notation 1 + XX 2 +\n1 2 3 4\nX3 X4. The direct notation is easier to grasp, but the polynomial notation\nbetter serves the mathematical analysis of an FSR’s properties. We’ll now\nstick to the direct notation unless we care about the mathematical properties.\nFiltered LFSRs are stronger than plain LFSRs because their nonlinear\nfunction thwarts straightforward attacks. Still, more complex attacks such\nas the following will break the system:\nAlgebraic attacks will solve the nonlinear equation systems deduced\nfrom the output bits, where unknowns in the equations are bits from\nthe LFSR state.\nCube attacks will compute derivatives of the nonlinear equations in\norder to reduce the degree of the system down to one and then solve\nit efficiently like a linear system.\nFast correlation attacks will exploit filtering functions that, despite\ntheir nonlinearity, tend to behave like linear functions.\nThe lesson here, as we’ve seen in previous examples, is that Band-Aids\ndon’t fix bullet holes. Patching a broken algorithm with a slightly\nstronger layer won’t make the whole thing secure. The problem has to be\nfixed at the core.\nNonlinear FSRs\nNonlinear FSRs (NFSRs) are like LFSRs but with a nonlinear feedback\nfunction instead of a linear one. That is, instead of just bitwise XORs, the\nfeedback function can include bitwise AND and OR operations—a\nfeature with both pros and cons.\nOne benefit of the addition of nonlinear feedback functions is that they\nmake NFSRs cryptographically stronger than LFSRs because the output\nbits depend on the initial secret state in a complex fashion, according to\nequations of exponential size. The LFSRs’ linear function keeps the\nrelations simple, with at most n terms (N , N , . . . , N , if the N s are the\n1 2 n i\nNFSR’s state bits). For example, a 4-bit NFSR with an initial secret state\n(N , N , N , N ) and a feedback function (N + N + N N + N N ) will\n1 2 3 4 1 2 1 2 3 4\nproduce a first output bit equal to the following:\nN + N + N N + N N\n1 2 1 2 3 4\nThe second iteration replaces the N value with that new bit.\n1\nExpressing the second output bit in terms of the initial state, we get the\nfollowing equation:\nThis new equation has algebraic degree 3 (the highest number of bits\nmultiplied together, here in N N N ) rather than degree 2 of the\n1 3 4\nfeedback function, and it has six terms instead of four. As a result,\niterating the nonlinear function quickly yields unmanageable equations\nbecause the size of the output grows exponentially. Although you’ll never\ncompute those equations when running the NFSR, an attacker would\nhave to solve them in order to break the system.\nOne downside to NFSRs is that there’s no efficient way to determine\nan NFSR’s period, or simply to know whether its period is maximal. For\nan NFSR of n bits, you’d need to run close to 2n trials to verify that its\nperiod is maximal. This calculation is impossible for large NFSRs of 80\nbits or more.\nFortunately, there’s a trick to using an NFSR without worrying about\nshort periods: you can combine LFSRs and NFSRs to get both a\nguaranteed maximal period and the cryptographic strength—and that’s\nexactly how Grain-128a works.\nGrain-128a\nRemember the AES competition discussed in Chapter 4, in the context of\nthe AES block cipher? The stream cipher Grain is the offspring of a\nsimilar project called the eSTREAM competition. This competition\nclosed in 2008 with a shortlist of recommended stream ciphers, which\nincluded four hardware-oriented ciphers and four software-oriented ones.\nGrain is one of these hardware ciphers, and Grain-128a is an upgraded\nversion from the original authors of Grain. Figure 5-8 shows the action\nmechanism of Grain-128a.\nFigure 5-8: The mechanism of Grain-128a, with a 128-bit NFSR and a 128-bit\nLFSR\nAs you can see in Figure 5-8, Grain-128a is about as simple as a stream\ncipher can be, combining a 128-bit LFSR, a 128-bit NFSR, and a filter\nfunction, h. The LFSR has a maximal period of 2128 – 1, which ensures\nthat the period of the whole system is at least 2128 – 1 to protect against\npotential short cycles in the NFSR. At the same time, the NFSR and the\nnonlinear filter function h add cryptographic strength.\nGrain-128a takes a 128-bit key and a 96-bit nonce. It copies the 128\nkey bits into the NFSR’s 128 bits and copies the 96 nonce bits into the\nfirst 96 LFSR bits, filling the 32 bits left with ones and a single zero bit at\nthe end. The initialization phase updates the whole system 256 times\nbefore returning the first keystream bit. During initialization, the bit\nreturned by the h function is thus not output as a keystream, but instead\ngoes into the LFSR to ensure that its subsequent state depends on both\nthe key and the nonce.\nGrain-128a’s LFSR feedback function is\nf(L) = L + L + L + L + L + L\n32 47 58 90 121 128\nwhere L , L , . . . , L are the bits of the LFSR. This feedback function\n1 2 128\ntakes only 6 bits from the 128-bit LFSR, but that’s enough to get a\nprimitive polynomial that guarantees a maximal period. The small\nnumber of bits minimizes the cost of a hardware implementation.\nHere is the feedback polynomial of Grain-128a’s NFSR (N , . . . ,\n1\nN ):\n128\nThis function was carefully chosen to maximize its cryptographic\nstrength while minimizing its implementation cost. It has an algebraic\ndegree of 4 because its term with the most variables has four variables\n(namely, N N N N ). Moreover, g can’t be approximated by a linear\n33 35 36 40\nfunction because it is highly nonlinear. Also, in addition to g, Grain-128a\nXORs the bit coming out from the LFSRs to feed the result back as the\nNFSR’s new, rightmost bit.\nThe filter function h is another nonlinear function; it takes 9 bits from\nthe NFSR and 7 bits from the LFSR and combines them in a way that\nensures good cryptographic properties.\nAs I write this, there is no known attack on Grain-128a, and I’m\nconfident that it will remain secure. Grain-128a is used in some low-end\nembedded systems that need a compact and fast stream cipher—typically\nindustrial proprietary systems—which is why Grain-128a is little known\nin the open-source software community.\nA5/1\nA5/1 is a stream cipher that was used to encrypt voice communications in\nthe 2G mobile standard. The A5/1 standard was created in 1987 but only\npublished in the late 1990s after it was reverse engineered. Attacks\nappeared in the early 2000s, and A5/1 was eventually broken in a way that\nallows actual (rather than theoretical) decryption of encrypted\ncommunications. Let’s see why and how.\nA5/1’s Mechanism\nA5/1 relies on three LFSRs and uses a trick that looks clever at first\nglance but actually fails to be secure (see Figure 5-9).\nFigure 5-9: The A5/1 cipher\nAs you can see in Figure 5-9, A5/1 uses LFSRs of 19, 22, and 23 bits,\nwith the polynomials for each as follows:\nHow could this be seen as secure with only LFSRs and no NFSR? The\ntrick lies in A5/1’s update mechanism. Instead of updating all three\nLFSRs at each clock cycle, the designers of A5/1 added a clocking rule\nthat does the following:\n1. Checks the value of the ninth bit of LFSR 1, the 11th bit of LFSR 2,\nand the 11th bit of LFSR 3, called the clocking bits. Of those three\nbits, either all have the same value (1 or 0) or exactly two have the\nsame value.\n2. Clocks the registers whose clocking bits are equal to the majority\nvalue, 0 or 1. Either two or three LFSRs are clocked at each update.\nWithout this simple rule, A5/1 would provide no security whatsoever,\nand bypassing this rule is enough to break the cipher. However, that is\neasier said than done, as you’ll see.\nNOTE\nIn A5/1’s irregular clocking rule, each register is clocked with a probability of\n3/4 at any update. Namely, the probability that at least one other register\nhas the same bit value is 1 – (1/2)2, where (1/2)2 is the chance that both of\nthe other two registers have a different bit value.\n2G communications use A5/1 with a key of 64 bits and a 22-bit nonce,\nwhich is changed for every new data frame. Attacks on A5/1 recover the\n64-bit initial state of the system (the 19 + 22 + 23 LFSR initial value),\nthus in turn revealing the nonce (if it was not already known) and the key,\nby unwinding the initialization mechanism. The attacks are referred to as\nknown-plaintext attacks (KPAs) because part of the encrypted data is\nknown, which allows attackers to determine the corresponding keystream\nparts by XORing the ciphertext with the known plaintext chunks.\nThere are two main types of attacks on A5/1:\nSubtle attacks Exploit the internal linearity of A5/1 and its simple\nirregular clocking system\nBrutal attacks Only exploit the short key of A5/1 and the invertibility\nof the frame number injection\nLet’s see how these attacks work.\nSubtle Attacks\nIn a subtle attack called a guess-and-determine attack, an attacker guesses\ncertain secret values of the state in order to determine others. In\ncryptanalysis, “guessing” means brute-forcing: for each possible value of\nLFSRs 1 and 2, and all possible values of LFSR 3’s clocking bit during\nthe first 11 clocks, the attack reconstructs LFSR 3’s bits by solving\nequations that depend on the bits guessed. When the guess is correct, the\nattacker gets the right value for LFSR 3.\nThe attack’s pseudocode looks like this:\n19\nFor all 2 values of LFSR 1's initial state\n22\nFor all 2 values of LFSR 2's initial state\n11\nFor all 2 values of LFSR 3's clocking bit during the first 11\nclocks\nReconstruct LFSR 3's initial state\nTest whether guess is correct; if yes, return; else continue\nHow efficient is this attack compared to the 264-trial brute-force search\ndiscussed in Chapter 3? This attack makes at most 219 × 222 × 211 = 252\noperations in the worst case, when the algorithm only succeeds at the\nvery last test. That’s 212 (or about 4000) times faster than in the brute-\nforce search, assuming that the last two operations in the above\npseudocode require about as much computation as testing a 64-bit key in\na brute-force search. But is this assumption correct?\nRecall our discussion of the full attack cost in Chapter 3. When\nevaluating the cost of an attack, we need to consider not only the amount\nof computation required to perform the attack but also parallelism and\nmemory consumption. Neither are issues here: as with any brute-force\nattack, the guess-and-determine attack is embarrassingly parallel (or N\ntimes faster when run on N cores) and doesn’t need more memory than\njust running the cipher itself.\nOur 252 attack cost estimate is inaccurate for another reason. In fact,\neach of the 252 operations (testing a key candidate) takes about four times\nas many clock cycles as does testing a key in a brute-force attack. The\nupshot is that the real cost of this particular attack is closer to 4 × 252 =\n254 operations, when compared to a brute-force attack.\nThe guess-and-determine attack on A5/1 can decrypt encrypted mobile\ncommunications, but it takes a couple of hours to recover the key when\nrun on a cluster of dedicated hardware devices. In other words, it’s\nnowhere near real-time decryption. For that, we have another type of\nattack.\nBrutal Attacks\nThe time-memory trade-off (TMTO) attack is the brutal attack on A5/1.\nThis attack doesn’t care about A5/1’s internals; it cares only that its state\nis 64 bits long. The TMTO attack sees A5/1 as a black box that takes in a\n64-bit value (the state) and spits out a 64-bit value (the first 64 keystream\nbits).\nThe idea behind the attack is to reduce the cost of a brute-force search\nin exchange for using lots of memory. The simplest type of TMTO is the\ncodebook attack. In a codebook attack, you precompute a table of 264\nelements containing a combination of key and value pairs (key:value), and\nstore the output value for each of the 264 possible keys. To use this\nprecomputed table for the attack, you simply collect the output of an\nA5/1 instance and then look up in the table which key corresponds to that\noutput. The attack itself is fast—taking only the amount of time necessary\nto look up a value in memory—but the creation of the table takes 264\ncomputations of A5/1. Worse, codebook attacks require an insane\namount of memory: 264 × (64 + 64) bits, which is 268 bytes or 256\nexabytes. That’s dozens of data centers, so we can forget about it.\nTMTO attacks reduce the memory required by a codebook attack at\nthe price of increased computation during the online phase of the attack;\nthe smaller the table, the more computations required to crack a key.\nRegardless, it will still cost about 264 operations to prepare the table, but\nthat needs to be done only once.\nIn 2010, researchers took about two months to generate two terabytes’\nworth of tables, using graphics processing units (GPUs) and running\n100000 instances of A5/1 in parallel. With the help of such large tables,\ncalls encrypted with A5/1 could be decrypted almost in real time.\nTelecommunication operators have implemented workarounds to\nmitigate the attack, but a real solution came with the later 3G and 4G\nmobile telephony standards, which ditched A5/1 altogether.\nSoftware-Oriented Stream Ciphers\nSoftware stream ciphers work with bytes or 32- or 64-bit words instead of\nindividual bits, which proves to be more efficient on modern CPUs where\ninstructions can perform arithmetic operations on a word in the same\namount of time as on a bit. Software stream ciphers are therefore better\nsuited than hardware ciphers for servers or browsers running on personal\ncomputers, where powerful general-purpose processors run the cipher as\nnative software.\nToday, there is considerable interest in software stream ciphers for a\nfew reasons. First, because many devices embed powerful CPUs and\nhardware has become cheaper, there’s less of a need for small bit-oriented\nciphers. For example, the two stream ciphers in the mobile\ncommunications standard 4G (the European SNOW3G and the Chinese\nZUC) work with 32-bit words and not bits, unlike the older A5/1.\nSecond, stream ciphers have gained popularity in software at the\nexpense of block ciphers, notably following the fiasco of the padding\noracle attack against block ciphers in CBC mode. In addition, stream\nciphers are easier to specify and to implement than block ciphers: instead\nof mixing message and key bits together, stream ciphers just ingest key\nbits as a secret. In fact, one of the most popular stream ciphers is actually\na block cipher in disguise: AES in counter mode (CTR).\nOne software stream cipher design, used by SNOW3G and ZUC,\ncopies hardware ciphers and their FSRs, replacing bits with bytes or\nwords. But these aren’t the most interesting designs for a cryptographer.\nAs of this writing, the two designs of most interest are RC4 and Salsa20,\nwhich are used in numerous systems, despite the fact that one is\ncompletely broken.\nRC4\nDesigned in 1987 by Ron Rivest of RSA Security, then reverse\nengineered and leaked in 1994, RC4 has long been the most widely used\nstream cipher. RC4 has been used in countless applications, most\nfamously in the first Wi-Fi encryption standard Wireless Equivalent\nPrivacy (WEP) and in the Transport Layer Security (TLS) protocol used\nto establish HTTPS connections. Unfortunately, RC4 isn’t secure\nenough for most applications, including WEP and TLS. To understand\nwhy, let’s see how RC4 works.\nHow RC4 Works\nRC4 is among the simplest ciphers ever created. It doesn’t perform any\ncrypto-like operations, and it has no XORs, no multiplications, no S-\nboxes . . . nada. It simply swaps bytes. RC4’s internal state is an array, S,\nof 256 bytes, first set to S[0] = 0, S[1] = 1, S[2] = 2, . . . , S[255] = 255, and\nthen initialized from an n-byte K using its key scheduling algorithm (KSA),\nwhich works as shown in the Python code in Listing 5-1.\nj = 0\n# set S to the array S[0] = 0, S[1] = 1, . . . , S[255] = 255\nS = range(256)\n# iterate over i from 0 to 255\nfor i in range(256):\n# compute the sum of v\nj = (j + S[i] + K[i % n]) % 256\n# swap S[i] and S[j]\nS[i], S[j] = S[j], S[i]\nListing 5-1: The key scheduling algorithm of RC4\nOnce this algorithm completes, array S still contains all the byte values\nfrom 0 to 255, but now in a random-looking order. For example, with the\nall-zero 128-bit key, the state S (from S[0] to S[255]) becomes this:\n0, 35, 3, 43, 9, 11, 65, 229, (. . .), 233, 169, 117, 184, 31, 39\nHowever, if I flip the first key bit and run the KSA again, I get a totally\ndifferent, apparently random state:\n32, 116, 131, 134, 138, 143, 149, (. . .), 152, 235, 111, 48, 80, 12\nGiven the initial state S, RC4 generates a keystream, KS, of the same\nlength as the plaintext, P, in order to compute a ciphertext: C = P ⊕ KS.\nThe bytes of the keystream KS are computed from S according to the\nPython code in Listing 5-2, if P is m bytes long.\ni = 0\nj = 0\nfor b in range(m):\ni = (i + 1) % 256\nj = (j + S[i]) % 256\nS[i], S[j] = S[j], S[i]\nKS[b] = S[(S[i] + S[j]) % 256]\nListing 5-2: The keystream generation of RC4, where S is the state initialized in\nListing 5-1\nIn Listing 5-2, each iteration of the for loop modifies up to 2 bytes of\nRC4’s internal state S: the S[i] and S[j] whose values are swapped. That is,\nif i = 0 and j = 4, and if S[0] = 56 and S[4] = 78, then the swap operation\nsets S[0] to 78 and S[4] to 56. If j equals i, then S[i] isn’t modified.\nThis looks too simple to be secure, yet it took 20 years for cryptanalysts\nto find exploitable flaws. Before the flaws were revealed, we only knew\nRC4’s weaknesses in specific implementations, as in the first Wi-Fi\nencryption standard, WEP.\nRC4 in WEP\nWEP, the first generation Wi-Fi security protocol, is now completely\nbroken due to weaknesses in the protocol’s design and in RC4.\nIn its WEP implementation, RC4 encrypts payload data of 802.11\nframes, the datagrams (or packets) that transport data over the wireless\nnetwork. All payloads delivered in the same session use the same secret\nkey of 40 or 104 bits but have what is a supposedly unique 3-byte nonce\nencoded in the frame header (the part of the frame that encodes metadata\nand comes before the actual payload). See the problem?\nThe problem is that RC4 doesn’t support a nonce, at least not in its\nofficial specification, and a stream cipher can’t be used without a nonce.\nThe WEP designers addressed this limitation with a workaround: they\nincluded a 24-bit nonce in the wireless frame’s header and prepended it\nto the WEP key to be used as RC4’s secret key. That is, if the nonce is\nthe bytes N[0], N[1], N[2] and the WEP key is K[0], K[1], K[2], K[3], K[4],\nthe actual RC4 key is N[0], N[1], N[2], K[0], K[1], K[2], K[3], K[4]. The\nnet effect is to have 40-bit secret keys yield 64-bit effective keys, and 104-\nbit keys yield 128-bit effective keys. The result? The advertised 128-bit\nWEP protocol actually offers only 104-bit security, at best.\nBut here are the real problems with WEP’s nonce trick:\nThe nonces are too small at only 24 bits. This means that if a\nnonce is chosen randomly for each new message, you’ll have to wait\nabout 224/2 = 212 packets, or a few megabytes’ worth of traffic, until\nyou can find two packets encrypted with the same nonce, and thus\nthe same keystream. Even if the nonce is a counter running from 0\nto 224 – 1, it will take a few gigabytes’ worth of data until a rollover,\nwhen the repeated nonce can allow the attacker to decrypt packets.\nBut there’s a bigger problem.\nCombining the nonce and key in this fashion helps recover the\nkey. WEP’s three non-secret nonce bytes let an attacker determine\nthe value of S after three iterations of the key scheduling algorithm.\nBecause of this, cryptanalysts found that the first keystream byte\nstrongly depends on the first secret key byte—the fourth byte\ningested by the KSA—and that this bias can be exploited to recover\nthe secret key.\nExploiting those weaknesses requires access to both ciphertexts and the\nkeystream; that is, known or chosen plaintexts. But that’s easy enough:\nknown plaintexts occur when the Wi-Fi frames encapsulate data with a\nknown header, and chosen plaintexts occur when the attacker injects\nknown plaintext encrypted with the target key. The upshot is that the\nattacks work in practice, not just on paper.\nFollowing the appearance of the first attacks on WEP in 2001,\nresearchers found faster attacks that required fewer ciphertexts. Today,\nyou can even find tools such as aircrack-ng that implement the entire\nattack, from network sniffing to cryptanalysis.\nWEP’s insecurity is due to both weaknesses in RC4, which takes a\nsingle one-use key instead of a key and nonce (as in any decent stream\ncipher), and weaknesses in the WEP design itself.\nNow let’s look at the second biggest failure of RC4.\nRC4 in TLS\nTLS is the single most important security protocol used on the internet.\nIt is best known for underlying HTTPS connections, but it’s also used to\nprotect some virtual private network (VPN) connections, as well as email\nservers, mobile applications, and many others. And sadly, TLS has long\nsupported RC4.\nUnlike WEP, the TLS implementation doesn’t make the same blatant\nmistake of tweaking the RC4 specs in order to use a public nonce.\nInstead, TLS just feeds RC4 a unique 128-bit session key, which means\nit’s a bit less broken than WEP.\nThe weakness in TLS is due only to RC4 and its inexcusable flaws:\nstatistical biases, or non-randomness, which we know is a total deal\nbreaker for a stream cipher. For example, the second keystream byte\nproduced by RC4 is zero, with a probability of 1/128, whereas it should\nbe 1/256 ideally. (Recall that a byte can take 256 values from 0 to 255;\nhence, a truly random byte is zero with a chance of 1/256.) Crazier still is\nthe fact that most experts continued to trust RC4 as late as 2013, even\nthough its statistical biases have been known since 2001.\nRC4’s known statistical biases should have been enough to ditch the\ncipher altogether, even if we didn’t know how to exploit the biases to\ncompromise actual applications. In TLS, RC4’s flaws weren’t publicly\nexploited until 2011, but the NSA allegedly managed to exploit RC4’s\nweaknesses to compromise TLS’s RC4 connections well before then.\nAs it turned out, not only was RC4’s second keystream byte biased, but\nall of the first 256 bytes were biased as well. In 2011, researchers found\nthat the probability that one of those bytes comes to zero equals 1/256 +\nc/2562, for some constant, c, taking values between 0.24 and 1.34. It’s not\njust for the byte zero but for other byte values as well. The amazing thing\nabout RC4 is that it fails where even many noncryptographic PRNGs\nsucceed—namely, at producing uniformly distributed pseudorandom\nbytes (that is, where each of the 256 bytes has a chance of 1/256 of\nshowing up).\nEven the weakest attack model can be used to exploit RC4’s flawed\nTLS implementation: basically, you collect ciphertexts and look for the\nplaintext, not the key. But there’s a caveat: you’ll need many ciphertexts,\nencrypting the same plaintext several times using different secret keys.\nThis attack model is sometimes called the broadcast model, because it’s\nakin to broadcasting the same message to multiple recipients.\nFor example, say you want to decrypt the plaintext byte P given many\n1\nciphertext bytes obtained by intercepting the different ciphertexts of the\nsame message. The first four ciphertext bytes will therefore look like this:\nBecause of RC4’s bias, keystream bytes KS i are more likely to be zero\n1\nthan any other byte value. Therefore, C i bytes are more likely to be\n1\nequal to P than to any other value. In order to determine P given the\n1 1\nC i bytes, you simply count the number of occurrences of each byte value\n1\nand return the most frequent one as P . However, because the statistical\n1\nbias is very small, you’ll need millions of values to get it right with any\ncertainty.\nThe attack generalizes to recover more than one plaintext byte and to\nexploit more than one biased value (zero here). The algorithm just\nbecomes a bit more complicated. However, this attack is hard to put into\npractice because it needs to collect many ciphertexts encrypting the same\nplaintext but using different keys. For example, the attack can’t break all\nTLS-protected connections that use RC4 because you need to trick the\nserver into encrypting the same plaintext to many different recipients, or\nmany times to the same recipient with different keys.\nSalsa20\nSalsa20 is a simple, software-oriented cipher optimized for modern CPUs\nthat has been implemented in numerous protocols and libraries, along\nwith its variant, ChaCha. Its designer, respected cryptographer Daniel J.\nBernstein, submitted Salsa20 to the eSTREAM competition in 2005 and\nwon a place in eSTREAM’s software portfolio. Salsa20’s simplicity and\nspeed have made it popular among developers.\nFigure 5-10: Salsa20’s encryption scheme for a 512-bit plaintext block\nSalsa20 is a counter-based stream cipher—it generates its keystream by\nrepeatedly processing a counter incremented for each block. As you can\nsee in Figure 5-10, the Salsa20 core algorithm transforms a 512-bit block\nusing a key (K), a nonce (N), and a counter value (Ctr). Salsa20 then adds\nthe result to the original value of the block to produce a keystream block.\n(If the algorithm were to return the core’s permutation directly as an\noutput, Salsa20 would be totally insecure, because it could be inverted.\nThe final addition of the initial secret state K || N || Ctr makes the\ntransform key-to-keystream-block non-invertible.)\nThe Quarter-Round Function\nSalsa20’s core permutation uses a function called quarter-round (QR) to\ntransform four 32-bit words (a, b, c, and d), as shown here:\nThese four lines are computed from top to bottom, meaning that the\nnew value of b depends on a and d, the new value of c depends on a and on\nthe new value of b (and thus d as well), and so on.\nThe operation <<< is wordwise left-rotation by the specified number of\nbits, which can be any value between 1 and 31 (for 32-bit words). For\nexample, <<< 8 rotates a word’s bits of eight positions toward the left, as\nshown in these examples:\nTransforming Salsa20’s 512-bit State\nSalsa20’s core permutation transforms a 512-bit internal state viewed as a\n4 × 4 array of 32-bit words. Figure 5-11 shows the initial state, using a\nkey of eight words (256 bits), a nonce of two words (64 bits), a counter of\ntwo words (64 bits), and four fixed constant words (128 bits) that are\nidentical for each encryption/decryption and all blocks.\nTo transform the initial 512-bit state, Salsa20 first applies the QR\ntransform to all four columns independently (known as the column-round)\nand then to all four rows independently (the row-round), as shown in\nFigure 5-12. The sequence column-round/row-round is called a double-\nround. Salsa20 repeats 10 double-rounds, for 20 rounds in total, thus the\n20 in Salsa20.\nFigure 5-11: The initialization of Salsa20’s state\nFigure 5-12: Columns and rows transformed by Salsa20’s quarter-round (QR)\nfunction\nThe column-round transforms the four columns like so:\nThe row-round transforms the rows by doing the following:\nNotice that in a column-round, each QR takes x arguments ordered\ni\nfrom the top to the bottom line, whereas a row-round’s QR takes as a\nfirst argument the words on the diagonal (as shown in the array on the\nright in Figure 5-12) rather than words from the first column.\nEvaluating Salsa20\nListing 5-3 shows Salsa20’s initial states for the first and second blocks\nwhen initialized with an all-zero key (00 bytes) and an all-one nonce (ff\nbytes). These two states differ in only one bit, in the counter, as shown in\nbold: specifically, 0 for the first block and 1 for the second.\n61707865 00000000 00000000 00000000 61707865 00000000 00000000\n00000000\n00000000 3320646e ffffffff ffffffff 00000000 3320646e ffffffff\nffffffff\n00000000 00000000 79622d32 00000000 00000001 00000000 79622d32\n00000000\n00000000 00000000 00000000 6b206574 00000000 00000000 00000000\n6b206574\nListing 5-3: Salsa20’s initial states for the first two blocks with an all-zero key and\nan all-one nonce\nYet, despite only a one-bit difference, the respective internal states\nafter 10 double-rounds are totally different from each other, as Listing 5-\n4 shows.\ne98680bc f730ba7a 38663ce0 5f376d93 1ba4d492 c14270c3 9fb05306\nff808c64\n85683b75 a56ca873 26501592 64144b6d b49a4100 f5d8fbbd 614234a0\ne20663d1\n6dcb46fd 58178f93 8cf54cfe cfdc27d7 12e1e116 6a61bc8f 86f01bcb\n2efead4a\n68bbe09e 17b403a1 38aa1f27 54323fe0 77775a13 d17b99d5 eb773f5b\n2c3a5e7d\nListing 5-4: The states from Listing 5-3 after 10 Salsa20 double-rounds\nBut remember, even though word values in the keystream block may\nlook random, we’ve seen that it’s far from a guarantee of security. RC4’s\noutput looks random, but it has blatant biases. Fortunately, Salsa20 is\nmuch more secure than RC4 and doesn’t have statistical biases.\nDifferential Cryptanalysis\nTo demonstrate why Salsa20 is more secure than RC4, let’s have a look at\nthe basics of differential cryptanalysis, the study of the differences between\nstates rather than their actual values. For example, the two initial states in\nFigure 5-13 differ by one bit in the counter, or by the word x in the\n8\nSalsa20 state array. The bitwise difference between these two states is\nthus shown in this array:\nThe difference between the two states is actually the XOR of these\nstates. The 1 bit shown in bold corresponds to a 1-bit difference between\nthe two states. In the XOR of the two states, any nonzero bits indicate\ndifferences.\nTo see how fast changes propagate in the initial state as a result of\nSalsa20’s core algorithm, let’s look at the difference between two states\nthroughout the rounds iteration. After one round, the difference\npropagates across the first column to two of the three other words in that\ncolumn:\nAfter two rounds, differences further propagate across the rows that\nalready include a difference, which is all but the second row. At this point\nthe differences between the states are rather sparse; not many bits have\nchanged within a word as shown here:\nAfter three rounds, the differences between the states become more\ndense, though the many zero nibbles indicate that many bit positions are\nstill not affected by the initial difference:\nAfter four rounds, differences look random to a human observer, and\nthey are also almost random statistically as well, as shown here:\nSo after only four rounds, a single difference propagates to most of the\nbits in the 512-bit state. In cryptography, this is called full diffusion.\nWe’ve seen that differences propagate quickly throughout Salsa20\nrounds. But not only do differences propagate across all states, they also\ndo so according to complex equations that make future differences hard\nto predict because highly nonlinear relations drive the state’s evolution,\nthanks to the mix of XOR, addition, and rotation. If only XORs were\nused, we’d still have many differences propagating, but the process would\nbe linear and therefore insecure.\nAttacking Salsa20/8\nSalsa20 makes 20 rounds by default, but it’s sometimes used with only 12\nrounds, in a version called Salsa20/12, to make it faster. Although\nSalsa20/12 uses eight fewer rounds than Salsa20, it’s still significantly\nstronger than the weaker Salsa20/8, another version with eight rounds,\nwhich is more rarely used.\nBreaking Salsa20 should ideally take 2256 operations, thanks to its use\nof a 256-bit key. If the key can be recovered by performing any fewer\nthan 2256 operations, the cipher is in theory broken. That’s exactly the\ncase with Salsa20/8.\nThe attack on Salsa20/8 (published in the 2008 paper New Features of\nLatin Dances: Analysis of Salsa, ChaCha, and Rumba, of which I’m a co-\nauthor, and for which we won a cryptanalysis prize from Daniel J.\nBernstein) exploits a statistical bias in Salsa’s core algorithm after four\nrounds to recover the key of eight-round Salsa20. In reality, this is mostly\na theoretical attack: we estimate its complexity at 2251 operations of the\ncore function—impossible, but less so than breaking the expected 2256\ncomplexity.\nThe attack exploits not only a bias over the first four rounds of\nSalsa20/8, but also a property of the last four rounds: knowing the nonce,\nN, and the counter, Ctr (refer back to Figure 5-10), the only value needed\nto invert the computation from the keystream back to the initial state is\nthe key, K. But as shown in Figure 5-13, if you only know some part of K,\nyou can partially invert the computation up until the fourth round and\nobserve some bits of that intermediate state—including the biased bit!\nYou’ll only observe the bias if you have the correct guess of the partial\nkey; hence, the bias serves as an indicator that you’ve got the correct key.\nFigure 5-13: The principle of the attack on Salsa20/8\nIn the actual attack on Salsa20/8, in order to determine the correct\nguess, we need to guess 220 bits of the key, and we need 231 pairs of\nkeystream blocks, all with the same specific difference in the nonce. Once\nwe’ve singled out the correct 220 bits, we simply need to brute-force 36\nbits. The brute-forcing takes 236 operations, a computation that dwarfs\nthe unrealistic 2220 × 231 = 2251 trials needed to find the 220 bits to\ncomplete the first part of the attack.\nHow Things Can Go Wrong\nAlas, many things can go wrong with stream ciphers, from brittle,\ninsecure designs to strong algorithms incorrectly implemented. I’ll\nexplore each category of potential problems in the following sections.\nNonce Reuse\nThe most common failure seen with stream ciphers is an amateur\nmistake: it occurs when a nonce is reused more than once with the same\nkey. This produces identical keystreams, allowing you to break the\nencryption by XORing two ciphertexts together. The keystream then\nvanishes, and you’re left with the XOR of the two plaintexts.\nFor example, older versions of Microsoft Word and Excel used a\nunique nonce for each document, but the nonce wasn’t changed once the\ndocument was modified. As a result, the clear and encrypted text of an\nolder version of a document could be used to decrypt later encrypted\nversions. If even Microsoft made this kind of blunder, you can imagine\nhow large the problem might be.\nCertain stream ciphers designed in the 2010s tried to mitigate the risk\nof nonce reuse by building “misuse-resistant” constructions, or ciphers\nthat remain secure even if a nonce is used twice. However, achieving this\nlevel of security comes with a performance penalty, as we’ll see in\nChapter 8 with the SIV mode.\nBroken RC4 Implementation\nThough it’s already weak, RC4 can become even weaker if you blindly\noptimize its implementation. For example, consider the following entry\nin the 2007 Underhanded C Contest, an informal competition where\nprogrammers write benign-looking code that actually includes a\nmalicious function.\nHere’s how it works. The naive way to implement the line swap(S[i],\nS[j]) in RC4’s algorithm is to do the following, as expressed in this\nPython code:\nbuf = S[i]\nS[i] = S[j]\nS[j] = buf\nThis way of swapping two variables obviously works, but you need to\ncreate a new variable, buf. To avoid this, programmers often use the\nXOR-swap trick, shown here, to swap the values of the variables x and y:\nx = x ⊕ y\ny = x ⊕ y\nx = x ⊕ y\nThis trick works because the second line sets y to x ⊕ y ⊕ y = x, and the\nthird line sets x to x ⊕ y ⊕ x ⊕ y ⊕ y = y. Using this trick to implement RC4\ngives the implementation shown in Listing 5-5 (adapted from Wagner\nand Biondi’s program submitted to the Underhanded C Contest, and\nonline at http://www.underhanded-c.org/_page_id_16.html).\n# define TOBYTE(x) (x) & 255\n# define SWAP(x,y) do { x^=y; y^=x; x^=y; } while (0)\nstatic unsigned char S[256];\nstatic int i=0, j=0;\nvoid init(char *passphrase) {\nint passlen = strlen(passphrase);\nfor (i=0; i<256; i++)\nS[i] = i;\nfor (i=0; i<256; i++) {\nj = TOBYTE(j + S[TOBYTE(i)] + passphrase[j % passlen]);\nSWAP(S[TOBYTE(i)], S[j]);\n}\ni = 0; j = 0;\n}\nunsigned char encrypt_one_byte(unsigned char c) {\nint k;\ni = TOBYTE(i+1);\nj = TOBYTE(j + S[i]);\nSWAP(S[i], S[j]);\nk = TOBYTE(S[i] + S[j]);\nreturn c ^ S[k];\n}\nListing 5-5: Incorrect C implementation of RC4, due to its use of an XOR swap\nNow stop reading, and try to spot the problem with the XOR swap in\nListing 5-5.\nThings will go south when i = j. Instead of leaving the state\nunchanged, the XOR swap will set S[i] to S[i] ⊕ S[i] = 0. In effect, a byte\nof the state will be set to zero each time i equals j in the key schedule or\nduring encryption, ultimately leading to an all-zero state and thus to an\nall-zero keystream. For example, after 68KB of data have been processed,\nmost of the bytes in the 256-byte state are zero, and the output keystream\nlooks like this:\n00 00 00 00 00 00 00 53 53 00 00 00 00 00 00 00 00 00 00 00 13 13 00 5c 00\na5 00 00 . . .\nThe lesson here is to refrain from over-optimizing your crypto\nimplementations. Clarity and confidence always trump performance in\ncryptography.\nWeak Ciphers Baked Into Hardware\nWhen a cryptosystem fails to be secure, some systems can quickly\nrespond by silently updating the affected software remotely (as with some\npay-TV systems) or by releasing a new version and prompting the users\nto upgrade (as with mobile applications). Some other systems are not so\nlucky and need to stick to the compromised cryptosystem for a while\nbefore upgrading to a secure version, as is the case with certain satellite\nphones.\nIn the early 2000s, US and European telecommunication\nstandardization institutes (TIA and ETSI) jointly developed two\nstandards for satellite phone (satphone) communications. Satphones are\nlike mobile phones, except that their signal goes through satellites rather\nthan terrestrial stations. The advantage is that you can use them pretty\nmuch everywhere in the world. Their downsides are the price, quality,\nlatency, and, as it turns out, security.\nGMR-1 and GMR-2 are the two satphone standards adopted by most\ncommercial vendors, such as Thuraya and Inmarsat. Both include stream\nciphers to encrypt voice communications. GMR-1’s cipher is hardware\noriented, with a combination of four LFSRs, similar to A5/2, the\ndeliberately insecure cipher in the 2G mobile standard aimed at non-\nWestern countries. GMR-2’s cipher is software oriented, with an 8-byte\nstate and the use of S-boxes. Both stream ciphers are insecure, and will\nonly protect users against amateurs, not against state agencies.\nThis story should remind us that stream ciphers used to be easier to\nbreak than block ciphers and that they’re easier to sabotage. Why? Well,\nif you design a weak stream cipher on purpose, when the flaw is found,\nyou can still blame it on the weakness of stream ciphers and deny any\nmalicious intent.\nFurther Reading\nTo learn more about stream ciphers, begin with the archives of the\neSTREAM competition at http://www.ecrypt.eu.org/stream/project.html,\nwhere you’ll find hundreds of papers on stream ciphers, including details\nof more than 30 candidates and many attacks. Some of the most\ninteresting attacks are the correlation attacks, algebraic attacks, and cube\nattacks. See in particular the work of Courtois and Meier for the first two\nattack types and that of Dinur and Shamir for cube attacks.\nFor more information on RC4, see the work of Paterson and his team\nat http://www.isg.rhul.ac.uk/tls/ on the security of RC4 as used in TLS and\nWPA. Also see Spritz, the RC4-like cipher created in 2014 by Rivest,\nwho designed RC4 in the 1980s.\nSalsa20’s legacy deserves your attention, too. The stream cipher\nChaCha is similar to Salsa20, but with a slightly different core\npermutation that was later used in the hash function BLAKE, as you’ll see\nin Chapter 6. These algorithms all leverage Salsa20’s software\nimplementation techniques using parallelized instructions, as discussed at\nhttps://cr.yp.to/snuffle.html."
  },
  {
    "input": "What are the key security properties of hash functions and how do they differ between cryptographic and noncryptographic hash functions?",
    "summary": "Hash functions like MD5, SHA-1, SHA-256, SHA-3, and BLAKE2 are essential in cryptography for ensuring data integrity and security in various applications. They produce a shorter output from a longer input and are used in digital signatures, password protection, and more. While secure hash functions are unpredictable and resistant to collisions and preimage attacks, they can be compromised if misused. SHA-1 is no longer considered secure due to vulnerabilities, but SHA-2 and BLAKE2 are currently recommended. SHA-3, based on the sponge construction, offers a more secure and flexible alternative. BLAKE2 is particularly fast and secure, making it a popular choice for modern applications.",
    "output": "6\nHASH FUNCTIONS\nHash functions—such as MD5, SHA-1, SHA-256, SHA-3, and BLAKE2\n—comprise the cryptographer’s Swiss Army Knife: they are used in\ndigital signatures, public-key encryption, integrity verification, message\nauthentication, password protection, key agreement protocols, and many\nother cryptographic protocols. Whether you’re encrypting an email,\nsending a message on your mobile phone, connecting to an HTTPS\nwebsite, or connecting to a remote machine through IPSec or SSH,\nthere’s a hash function somewhere under the hood.\nHash functions are by far the most versatile and ubiquitous of all crypto\nalgorithms. There are many examples of their use in the real world: cloud\nstorage systems use them to identify identical files and to detect modified\nfiles; the Git revision control system uses them to identify files in a\nrepository; host-based intrusion detection systems (HIDS) use them to\ndetect modified files; network-based intrusion detection systems (NIDS)\nuse hashes to detect known-malicious data going through a network;\nforensic analysts use hash values to prove that digital artifacts have not\nbeen modified; Bitcoin uses a hash function in its proof-of-work systems\n—and there are many more.\nFigure 6-1: A hash function’s input and output\nUnlike stream ciphers, which create a long output from a short one,\nhash functions take a long input and produce a short output, called a hash\nvalue or digest (see Figure 6-1).\nThis chapter revolves around two main topics. First, security: what\ndoes it mean for a hash function to be secure? To that end, I introduce\ntwo essential notions—namely, collision resistance and preimage\nresistance. The second big topic revolves around hash functions\nconstruction. We look at the high-level techniques used by modern hash\nfunctions and then review the internals of the most common hash\nfunctions: SHA-1, SHA-2, SHA-3, and BLAKE2. Lastly, we see how\nsecure hash functions can behave insecurely if misused.\nNOTE\nDo not confuse cryptographic hash functions with noncryptographic ones.\nNoncryptographic hash functions are used in data structures such as hash\ntables or to detect accidental errors, and they provide no security whatsoever.\nFor example, cyclic redundancy checks (CRCs) are noncryptographic hashes\nused to detect accidental modifications of a file.\nSecure Hash Functions\nFigure 6-2: A hash function in a digital signature scheme. The hash acts as a proxy\nfor the message.\nThe notion of security for hash functions is different from what we’ve\nseen thus far. Whereas ciphers protect data confidentiality in an effort to\nguarantee that data sent in the clear can’t be read, hash functions protect\ndata integrity in an effort to guarantee that data—whether sent in the\nclear or encrypted—hasn’t been modified. If a hash function is secure,\ntwo distinct pieces of data should always have different hashes. A file’s\nhash can thus serve as its identifier.\nConsider the most common application of a hash function: digital\nsignatures, or just signatures. When digital signatures are used, applications\nprocess the hash of the message to be signed rather than the message\nitself, as shown in Figure 6-2. The hash acts as an identifier for the\nmessage. If even a single bit is changed in the message, the hash of the\nmessage will be totally different. The hash function thus helps ensure that\nthe message has not been modified. Signing a message’s hash is as secure\nas signing the message itself, and signing a short hash of, say, 256 bits is\nmuch faster than signing a message that may be very large. In fact, most\nsignature algorithms can only work on short inputs such as hash values.\nUnpredictability Again\nAll of the cryptographic strength of hash functions stems from the\nunpredictability of their outputs. Take the 256-bit hexadecimal values\nshown next; these hashes are computed using the NIST standard hash\nfunction SHA-256 with the ASCII letters a, b, and c as inputs. As you can\nsee, though the values a, b, and c differ by only one or two bits (a is the bit\nsequence 01100001, b is 01100010, and c is 01100011), their hash values\nare completely different.\nGiven only these three hashes, it would be impossible to predict the\nvalue of the SHA-256 hash of d or any of its bits. Why? Because hash\nvalues of a secure hash function are unpredictable. A secure hash function\nshould be like a black box that returns a random string each time it\nreceives an input.\nThe general, theoretical definition of a secure hash function is that it\nbehaves like a truly random function (sometimes called a random oracle).\nSpecifically, a secure hash function shouldn’t have any property or\npattern that a random function wouldn’t have. This definition is helpful\nfor theoreticians, but in practice we need more specific notions: namely,\npreimage resistance and collision resistance.\nPreimage Resistance\nA preimage of a given hash value, H, is any message, M, such that\nHash(M) = H. Preimage resistance describes the security guarantee that\ngiven a random hash value, an attacker will never find a preimage of that\nhash value. Indeed, hash functions are sometimes called one-way functions\nbecause you can go from the message to its hash, but not the other way.\nFirst, note that a hash function can’t be inverted, even given unlimited\ncomputing power. For example, suppose that I hash some message using\nthe SHA-256 hash function and get this 256-bit hash value:\nf67a58184cef99d6dfc3045f08645e844f2837ee4bfcc6c949c9f7674367adfd\nEven given unlimited computing power, you would never be able to\ndetermine the message that I picked to produce this particular hash, since\nthere are many messages hashing to the same value. You would therefore\nfind some messages that produce this hash value (possibly including the\none I picked), but would be unable to determine the message that I used.\nFor example, there are 2256 possible values of a 256-bit hash (a typical\nlength with hash functions used in practice), but there are many more\nvalues of, say, 1024-bit messages (namely, 21024 possible values).\nTherefore, it follows that, on average, each possible 256-bit hash value\nwill have 21024 / 2256 = 21024 – 256 = 2768 preimages of 1024 bits each.\nIn practice, we must be sure that it is practically impossible to find any\nmessage that maps to a given hash value, not just the message that was\nused, which is what preimage resistance actually stands for. Specifically,\nwe speak of first-preimage and second-preimage resistance. First-preimage\nresistance (or just preimage resistance) describes cases where it is practically\nimpossible to find a message that hashes to a given value. Second-preimage\nresistance, on the other hand, describes the case that when given a\nmessage, M , it’s practically impossible to find another message, M , that\n1 2\nhashes to the same value that M does.\n1\nThe Cost of Preimages\nGiven a hash function and a hash value, you can search for first preimages\nby trying different messages until one hits the target hash. You would do\nthis using an algorithm similar to find-preimage() in Listing 6-1.\nfind-preimage(H) {\nrepeat {\nM = random_message()\nif Hash(M) == H then return M\n}\n}\nListing 6-1: The optimal preimage search algorithm for a secure hash function\nIn Listing 6-1, random_message() generates a random message (say, a\nrandom 1024-bit value). Obviously, find-preimage() will never complete if\nthe hash’s bit length, n, is large enough, because it will take on average 2n\nattempts before finding a preimage. That’s a hopeless situation when\nworking with n = 256, as in modern hashes like SHA-256 and BLAKE2.\nWhy Second-Preimage Resistance Is Weaker\nI claim that if you can find first preimages, you can find second preimages\nas well (for the same hash function). As proof, if the algorithm solve-\npreimage() returns a preimage of a given hash value, you can use the\nalgorithm in Listing 6-2 to find a second preimage of some message, M.\nsolve-second-preimage(M) {\nH = Hash(M)\nreturn solve-preimage(H)\n}\nListing 6-2: How to find second preimages if you can find first preimages\nThat is, you’ll find the second preimage by seeing it as a preimage\nproblem and applying the preimage attack. It follows that any second-\npreimage resistant hash function is also preimage resistant. (Were it not,\nit wouldn’t be second preimage resistant either, per the preceding solve-\nsecond-preimage algorithm.) In other words, the best attack we can use to\nfind second preimages is almost identical to the best attack we can use to\nfind first preimages (unless the hash function has some defect that allows\nfor more efficient attacks). Also note that a preimage search attack is\nessentially the same as a key recovery attack on a block cipher or stream\ncipher—namely, a brute-force search for a single magic value.\nCollision Resistance\nWhatever hash function you choose to use, collisions will inevitably exist\ndue to the pigeonhole principle, which states that if you have m holes and n\npigeons to put into those holes, and if n is greater than m, at least one\nhole must contain more than one pigeon.\nNOTE\nThis can be generalized to other items and containers as well. For example,\nany 27-word sequence in the US Constitution includes at least two words\nthat start with the same letter. In the world of hash functions, holes are the\nhash values, and pigeons are the messages. Because we know that there are\nmany more possible messages than hash values, collisions must exist.\nHowever, despite the inevitable, collisions should be as hard to find as\nthe original message in order for a hash function to be considered collision\nresistant—in other words, attackers shouldn’t be able to find two distinct\nmessages that hash to the same value.\nThe notion of collision resistance is related to the notion of second-\npreimage resistance: if you can find second preimages for a hash function,\nyou can also find collisions, as shown in Listing 6-3.\nsolve-collision() {\nM = random_message()\nreturn (M, solve-second-preimage(M))\n}\nListing 6-3: The naive collision search algorithm\nThat is, any collision-resistant hash is also second preimage resistant. If\nthis were not the case, there would be an efficient solve-second-preimage\nalgorithm that could be used to break collision resistance.\nFinding Collisions\nIt’s faster to find collisions than it is to find preimages, on the order of\nabout 2N/2 operations instead of 2n, thanks to the birthday attack, whose\nkey idea is the following: given N messages and as many hash values, you\ncan produce a total of N × (N – 1) / 2 potential collisions by considering\neach pair of two hash values (a number of the same order of magnitude as\nN2). It’s called birthday attack because it’s usually illustrated using the so-\ncalled birthday paradox, or the fact that a group of only 23 persons will\ninclude two persons having the same birth date with probability 1/2.\nNOTE\nN × (N – 1) / 2 is the count of pairs of two distinct messages, where we\ndivide by 2 because we view (M , M ) and (M , M ) as a same pair. In\n1 2 2 1\nother words, we don’t care about the ordering.\nFor the sake of comparison, in the case of a preimage search, N\nmessages only get you N candidate preimages, whereas the same N\nmessages give approximately N 2 potential collisions, as just discussed.\nWith N 2 instead of N, we say that there are quadratically more chances to\nfind a solution. The complexity of the search is in turn quadratically\nlower: in order to find a collision, you’ll need to use the square root of 2n\nmessages; that is, 2n/2 instead of 2n.\nThe Naive Birthday Attack\nHere’s the simplest way to carry out the birthday attack in order to find\ncollisions:\n1. Compute 2n/2 hashes of 2n/2 arbitrarily chosen messages and store all\nthe message/hash pairs in a list.\n2. Sort the list with respect to the hash value to move any identical hash\nvalues next to each other.\n3. Search the sorted list to find two consecutive entries with the same\nhash value.\nUnfortunately, this method requires a lot of memory (enough to store\n2 /2 message/hash pairs), and sorting lots of elements slows down the\nN\nsearch, requiring about n2 basic operations on average using even the\nN\nquicksort algorithm.\nLow-Memory Collision Search: The Rho Method\nThe Rho method is an algorithm for finding collisions that, unlike the\nnaive birthday attack, requires only a small amount of memory. It works\nlike this:\n1. Given a hash function with n-bit hash values, pick some random hash\nvalue (H ), and define H = H′ .\n1 1 1\n2. Compute H = Hash(H ), and H′ = Hash(Hash(H′ )); that is, in the\n2 1 2 1\nfirst case we apply the hash function once, while in the second case\nwe apply it twice.\n3. Iterate the process and compute H = Hash(H ), H′ =\ni + 1 i i + 1\nHash(Hash(H′ )), until you reach i such that H = H′ .\ni i + 1 i + 1\nFigure 6-3 will help you to visualize the attack, where an arrow from,\nsay, H to H means H = Hash(H ). Observe that the sequence of H s\n1 2 2 1 i\neventually enters a loop, also called a cycle, which resembles the Greek\nletter rho (ρ) in shape. The cycle starts at H and is characterized by the\n5\ncollision Hash(H ) = Hash(H ) = H . The key observation here is that in\n4 10 5\norder to find a collision, you simply need to find such a cycle. The\nalgorithm above allows an attacker to detect the position of the cycle, and\ntherefore to find the collision.\nFigure 6-3: The structure of the Rho hash function. Each arrow represents an\nevaluation of the hash function. The cycle beginning at H corresponds to a\n5\ncollision, Hash(H ) = Hash(H ) = H .\n4 10 5\nAdvanced collision-finding techniques work by first detecting the start\nof the cycle and then finding the collision, without storing numerous\nvalues in memory and without needing to sort a long list. The Rho\nmethod takes about 2n/2 operations to succeed. Indeed, Figure 6-3 has\nmany fewer hash values than would an actual function with digests of 256\nbits or more. On average, the cycle and the tail (the part that extends\nfrom H to H in Figure 6-3) each include about 2 /2 hash values, where\n1 5 N\nn is the bit length of the hash values. Therefore, you’ll need at least 2n/2 +\n2n/2 evaluations of the hash to find a collision.\nBuilding Hash Functions\nIn the 1980s, cryptographers realized that the simplest way to hash a\nmessage is to split it into chunks and process each chunk consecutively\nusing a similar algorithm. This strategy is called iterative hashing, and it\ncomes in two main forms:\nIterative hashing using a compression function that transforms an input\nto a smaller output, as shown in Figure 6-4. This technique is also\nknown as the Merkle–Damgård construction (named after the\ncryptographers Ralph Merkle and Ivan Damgård).\nIterative hashing using a function that transforms an input to an\noutput of the same size, such that any two different inputs give two\ndifferent outputs (that is, a permutation), as shown in Figure 6-7.\nSuch functions are called sponge functions.\nWe’ll now discuss how these constructions actually work and how\ncompression functions look in practice.\nCompression-Based Hash Functions: The Merkle–Damgård\nConstruction\nAll hash functions developed from the 1980s through the 2010s are based\non the Merkle–Damgård (M–D) construction: MD4, MD5, SHA-1, and\nthe SHA-2 family, as well as the lesser-known RIPEMD and Whirlpool\nhash functions. The M–D construction isn’t perfect, but it is simple and\nhas proven to be secure enough for many applications.\nNOTE\nIn MD4, MD5, and RIPEMD, the MD stands for message digest, not\nMerkle–Damgård.\nTo hash a message, the M–D construction splits the message into\nblocks of identical size and mixes these blocks with an internal state using\na compression function, as shown in Figure 6-4. Here, H is the initial\n0\nvalue (denoted IV) of the internal state, the values H , H , . . . are called\n1 2\nthe chaining values, and the final value of the internal state is the message’s\nhash value.\nFigure 6-4: The Merkle–Damgård construction using a compression function called\nCompress\nThe message blocks are usually 512 or 1024 bits, but they can, in\nprinciple, be of any size. However, the block length is fixed for a given\nhash function. For example, SHA-256 works with 512-bit blocks and\nSHA-512 works with 1024-bit blocks.\nPadding Blocks\nWhat happens if you want to hash a message that can’t be split into a\nsequence of complete blocks? For example, if blocks are 512 bits, then a\n520-bit message will consist of one 512-bit block plus 8 bits. In such a\ncase, the M–D construction forms the last block as follows: take the\nchunk of bits left (8 in our example), append 1 bit, then append 0 bits, and\nfinally append the length of the original message, encoded on a fixed\nnumber of bits. This padding trick guarantees that any two distinct\nmessages will give a distinct sequence of blocks, and thus a distinct hash\nvalue.\nFor example, if you hash the 8-bit string 10101010 using SHA-256,\nwhich is a hash function with 512-bit message blocks, the first and only\nblock will appear, in bits, as follows:\nHere, the message bits are the first eight bits (10101010), and the\npadding bits are all the subsequent bits (shown in italic). The 1000 at the\nend of the block (underlined) is the message’s length, or 8 encoded in\nbinary. The padding thus produces a 512-bit message composed of a\nsingle 512-bit block, ready to be processed by SHA-256’s compression\nfunction.\nSecurity Guarantees\nThe Merkle–Damgård construction is essentially a way to turn a secure\ncompression function that takes small, fixed-length inputs into a secure\nhash function that takes inputs of arbitrary lengths. If a compression\nfunction is preimage and collision resistant, then a hash function built on\nit using the M–D construction will also be preimage and collision\nresistant. This is true because any successful preimage attack for the M–D\nhash could be turned into a successful preimage attack for the\ncompression function, as Merkle and Damgård both demonstrated in\ntheir 1989 papers (see “Further Reading” on page 126). The same is true\nfor collisions: an attacker can’t break the hash’s collision resistance\nwithout breaking the underlying compression function’s collision\nresistance; hence, the security of the latter guarantees the security of the\nhash.\nNote that the converse argument is wrong, because a collision for the\ncompression function doesn’t necessarily give a collision for the hash. A\ncollision, Compress(X, M ) = Compress(Y, M ), for chaining values X\n1 2\nand Y, both distinct from H , won’t get you a collision for the hash\n0\nbecause you can’t plug the collision into the iterative chain of hashes—\nexcept if one of the chaining values happens to be X and the other Y, but\nthat’s unlikely to happen.\nFinding Multicollisions\nA multicollision occurs when a set of three or more messages hash to the\nsame value. For example, the triplet (X, Y, Z), such that Hash(X) =\nHash(Y) = Hash(Z) is called a 3-collision. Ideally, multicollisions should be\nmuch harder to find than collisions, but there is a simple trick for finding\nthem at almost the same cost as that of a single collision. Here’s how it\nworks:\n1. Find a first collision: Compress(H , M ) = Compress(H , M ) =\n0 1.1 0 1.2\nH . Now you have a 2-collision, or two messages hashing to the\n1\nsame value.\n2. Find a second collision with H as a starting chaining value:\n1\nCompress(H , M ) = Compress(H , M ) = H . Now you have a\n1 2.1 1 2.2 2\n4-collision, with four messages hashing to the same value H : M\n2 1.1\n|| M , M || M , M || M , and M || M .\n2.1 1.1 2.2 1.2 2.1 1.2 2.2\n3. Repeat and find N times a collision, and you’ll have 2n N-block\nmessages hashing to the same value, or a 2n-collision, at the cost of\n“only” about N2n hash computations.\nIn practice, this trick isn’t all that practical because it requires you to\nfind a basic 2-collision in the first place.\nBuilding Compression Functions: The Davies–Meyer\nConstruction\nFigure 6-5: The Davies–Meyer construction. The dark triangle shows where the\nblock cipher's key is input.\nAll compression functions used in real hash functions such as SHA-256\nand BLAKE2 are based on block ciphers, because that is the simplest way\nto build a compression function. Figure 6-5 shows the most common of\nthe block cipher–based compression functions, the Davies–Meyer\nconstruction.\nGiven a message block, M , and the previous chaining value H , the\ni i − 1\nDavies–Meyer compression function uses a block cipher, E, to compute\nthe new chaining value as\nH = E(M , H ) ⊕ H\ni i i − 1 i − 1\nThe message block M acts as the block cipher key, and the chaining\ni\nvalue H acts as its plaintext block. As long as the block cipher is\ni – 1\nsecure, the resulting compression function is secure as well as collision\nand preimage resistant. Without the XOR of the preceding chaining\nvalue (⊕ H ), Davies–Meyer would be insecure because you could invert\ni – 1\nit, going from the new chaining value to the previous one using the block\ncipher’s decryption function.\nNOTE\nThe Davies–Meyer construction has a surprising property: you can find fixed\npoints, or chaining values, that are unchanged after applying the\ncompression function with a given message block. It suffices to take H =\ni – 1\nD(M , 0) as a chaining value, where D is the decryption function\ni\ncorresponding to E. The new chaining value H is therefore equal to the\ni\noriginal H :\ni – 1\nWe get H = H because plugging the decryption of zero into the\ni i – 1\nencryption function yields zero—the term E(M , D(M , 0))—leaving only\ni i\nthe ⊕ H part of the equation in the expression of the compression\ni – 1\nfunction’s output. You can then find fixed points for the compression functions\nof the SHA-2 functions, as with the standards MD5 and SHA-1, which are\nalso based on the Davies–Meyer construction. Fortunately, fixed points aren’t\na security risk.\nThere are many block cipher–based compression functions other than\nDavies–Meyer, such as those shown in Figure 6-6, but they are less\npopular because they’re more complex or require the message block to be\nthe same length as the chaining value.\nFigure 6-6: Other secure block cipher–based compression function constructions\nPermutation-Based Hash Functions: Sponge Functions\nAfter decades of research, cryptographers know everything there is to\nknow about block cipher–based hashing techniques. Still, shouldn’t there\nbe a simpler way to hash? Why bother with a block cipher, an algorithm\nthat takes a secret key, when hash functions don’t take a secret key? Why\nnot build hash functions with a fixed-key block cipher, a single\npermutation algorithm?\nThose simpler hash functions are called sponge functions, and they use\na single permutation instead of a compression function and a block cipher\n(see Figure 6-7). Instead of using a block cipher to mix message bits with\nthe internal state, sponge functions just do an XOR operation. Sponge\nfunctions are not only simpler than Merkle–Damgård functions, they’re\nalso more versatile. You will find them used as hash functions and also as\ndeterministic random bit generators, stream ciphers, pseudorandom\nfunctions (see Chapter 7), and authenticated ciphers (see Chapter 8). The\nmost famous sponge function is Keccak, also known as SHA-3.\nFigure 6-7: The sponge construction\nA sponge function works as follows:\n1. It XORs the first message block, M , to H , a predefined initial value\n1 0\nof the internal state (for example, the all-zero string). Message blocks\nare all the same size and smaller than the internal state.\n2. A permutation, P, transforms the internal state to another value of\nthe same size.\n3. It XORs block M and applies P again, and then repeats this for the\n2\nmessage blocks M , M , and so on. This is called the absorbing phase.\n3 4\n4. After injecting all the message blocks, it applies P again and extracts\na block of bits from the state to form the hash. (If you need a longer\nhash, apply P again and extract a block.) This is called the squeezing\nphase.\nThe security of a sponge function depends on the length of its internal\nstate and the length of the blocks. If message blocks are r-bit long and the\ninternal state is w-bit long, then there are c = w – r bits of the internal\nstate that can’t be modified by message blocks. The value of c is called a\nsponge’s capacity, and the security level guaranteed by the sponge function\nis c/2. For example, to reach 256-bit security with 64-bit message blocks,\nthe internal state should be w = 2 × 256 + 64 = 576 bits. Of course, the\nsecurity level also depends on the length, n, of the hash value. The\ncomplexity of a collision attack is therefore the smallest value between\n2n/2 and 2c/2, while the complexity of a second preimage attack is the\nsmallest value between 2n and 2c/2.\nTo be secure, the permutation P should behave like a random\npermutation, without statistical bias and without a mathematical structure\nthat would allow an attacker to predict outputs. As in compression\nfunction–based hashes, sponge functions also pad messages, but the\npadding is simpler because it doesn’t need to include the message’s\nlength. The last message bit is simply followed by a 1 bit and as many\nzeroes as necessary.\nThe SHA Family of Hash Functions\nThe Secure Hash Algorithm (SHA) hash functions are standards defined\nby NIST for use by non-military federal government agencies in the US.\nThey are considered worldwide standards, and only certain non-US\ngovernments opt for their own hash algorithms (such as China’s SM3,\nRussia’s Streebog, and Ukraine’s Kupyna) for reasons of sovereignty\nrather than a lack of trust in SHA’s security. The US SHAs have been\nmore extensively reviewed by cryptanalysts than the non-US ones.\nNOTE\nMessage Digest 5 (MD5) was the most popular hash function from 1992\nuntil it was broken around 2005, and many applications then switched to one\nof the SHA hash functions. MD5 processes 512-bit block messages and\nupdates a 128-bit internal state to produce a 128-bit hash, thus providing at\nbest 128-bit preimage security and 64-bit collision security. In 1996,\ncryptanalysts warned of a collision for MD5’s compression function, but their\nwarning went unheeded until 2005 when a team of Chinese cryptanalysts\ndiscovered how to compute collisions for the full MD5 hash. As I write this, it\ntakes only seconds to find a collision for MD5, yet many systems still use or\nsupport MD5, often for reasons of backward compatibility.\nSHA-1\nThe SHA-1 standard arose from a failure in the NSA’s original SHA-0\nhash function. In 1993, NIST standardized the NSA’s SHA-0 hash\nalgorithm, but in 1995 the NSA released SHA-1 to fix an unidentified\nsecurity issue in SHA-0. The reason for the tweak became clear when in\n1998 two researchers discovered how to find collisions for SHA-0 in\nabout 260 operations instead of the 280 expected for 160-bit hash\nfunctions such as SHA-0 and SHA-1. Later attacks reduced the\ncomplexity to around 233 operations, leading to actual collisions in less\nthan an hour for SHA-0.\nSHA-1 Internals\nSHA-1 combines a Merkle–Damgård hash function with a Davies–Meyer\ncompression function based on a specially crafted block cipher,\nsometimes called SHACAL. That is, SHA-1 works by iterating the\nfollowing operation over 512-bit message blocks (M):\nH = E(M, H) + H\nHere, the use of a plus sign (+) rather than ⊕ (XOR) is intentional.\nE(M, H) and H are viewed as arrays of 32-bit integers, and each two\nwords at a same position are added together: the first 32-bit word of E(M,\nH) with the first 32-bit word of H, and so on. The initial value of H is\nconstant for any message, then H is modified as per the above equation,\nand the final value of H after processing all blocks is returned as the hash\nof the message.\nOnce the block cipher is run using the message block as a key and the\ncurrent 160-bit chaining value as a plaintext block, the 160-bit result is\nseen as an array of five 32-bit words, each of which is added to its 32-bit\ncounterpart in the initial H value.\nListing 6-4 shows SHA-1’s compression function, SHA1-compress():\nSHA1-compress(H, M) {\n(a0, b0, c0, d0, e0) = H // parsing H as five 32-bit big endian\nwords\n(a, b, c, d, e) = SHA1-blockcipher(a0, b0, c0, d0, e0, M)\nreturn (a + a0, b + b0, c + c0, d + d0, e + e0)\n}\nListing 6-4: SHA-1’s compression function\nSHA-1’s block cipher SHA1-blockcipher(), shown in bold in Listing 6-5,\ntakes a 512-bit message block, M, as a key and transforms the five 32-bit\nwords (a, b, c, d, and e) by iterating 80 steps of a short sequence of\noperations to replace the word a with a combination of all five words. It\nthen shifts the other words in the array, as in a shift register.\nSHA1-blockcipher(a, b, c, d, e, M) {\nW = expand(M)\nfor i = 0 to 79 {\nnew = (a <<< 5) + f(i, b, c, d) + e + K[i] + W[i]\n(a, b, c, d, e) = (new, a, b >>> 2, c, d)\n}\nreturn (a, b, c, d, e)\n}\nListing 6-5: SHA-1’s block cipher\nThe expand() function shown in Listing 6-6 creates an array of eighty\n32-bit words, W, from the 16-word message block by setting W’s first 16\nwords to M and the subsequent ones to an XOR combination of previous\nwords, rotated one bit to the left.\nexpand(M) {\n// the 512-bit M is seen as an array of sixteen 32-bit words\nW = empty array of eighty 32-bit words\nfor i = 0 to 79 {\nif i < 16 then W[i] = M[i]\nelse\nW[i] = (W[i – 3] ⊕ W[i – 8] ⊕ W[i – 14] ⊕ W[i – 16]) <<< 1\n}\nreturn W\n}\nListing 6-6: SHA-1’s expand() function\nThe <<< 1 operation in Listing 6-6 is the only difference between the\nSHA-1 and SHA-0 functions.\nFinally, the f() function (see Listing 6-7) in SHA1-blockcipher() is a\nsequence of basic bitwise logical operations (a Boolean function) that\ndepends on the round number.\nf(i, b, c, d) {\nif i < 20 then return ((b & c) ⊕ (~b & d))\nif i < 40 then return (b ⊕ c ⊕ d)\nif i < 60 then return ((b & c) ⊕ (b & d) ⊕ (c & d))\nif i < 80 then return (b ⊕ c ⊕ d)\n}\nListing 6-7: SHA-1’s f() function.\nThe second and fourth Boolean functions in Listing 6-7 simply XOR\nthe three input words together, which is a linear operation. In contrast,\nthe first and third functions use the non-linear & operator (logical AND)\nto protect against differential cryptanalysis, which as you recall, exploits\nthe predictable propagation of bitwise difference. Without the &\noperator (in other words, if f() were always b ⊕ c ⊕ d, for example), SHA-1\nwould be easy to break by tracing patterns within its internal state.\nAttacks on SHA-1\nThough more secure than SHA-0, SHA-1 is still insecure, which is why\nthe Chrome browser marks websites using SHA-1 in their HTTPS\nconnection as insecure. Although its 160-bit hash should grant it 80-bit\ncollision resistance, in 2005 researchers found weaknesses in SHA-1 and\nestimated that finding a collision would take approximately 263\ncalculations. (That number would be 280 if the algorithm were flawless.)\nA real SHA-1 collision only came twelve years later when after years of\ncryptanalysis, Marc Stevens and other researchers presented two colliding\nPDF documents through a joint work with Google researchers (see\nhttps://shattered.io/).\nThe upshot is that you should not use SHA-1. As mentioned, internet\nbrowsers now mark SHA-1 as insecure, and SHA-1 is no longer\nrecommended by NIST. Use SHA-2 hash functions instead, or BLAKE2\nor SHA-3.\nSHA-2\nSHA-2, the successor to SHA-1, was designed by the NSA and\nstandardized by NIST. SHA-2 is a family of four hash functions: SHA-\n224, SHA-256, SHA-384, and SHA-512, of which SHA-256 and SHA-\n512 are the two main algorithms. The three-digit numbers represent the\nbit lengths of each hash.\nSHA-256\nThe initial motivation behind the development of SHA-2 was to generate\nlonger hashes and thus deliver higher security levels than SHA-1. For\nexample, whereas SHA-1 has 160-bit chaining values, SHA-256 has 256-\nbit chaining values or eight 32-bit words. Both SHA-1 and SHA-256 have\n512-bit message blocks; however, whereas SHA-1 makes 80 rounds,\nSHA-256 makes 64 rounds, expanding the 16-word message block to a\n64-word message block using the expand256() function shown in Listing\n6-8.\nexpand256(M) {\n// the 512-bit M is seen as an array of sixteen 32-bit words\nW = empty array of sixty-four 32-bit words\nfor i = 0 to 63 {\nif i < 16 then W[i] = M[i]\nelse {\n// the \">>\" shifts instead of a \">>>\" rotates and is not a\ntypo\ns0 = (W[i – 15] >>> 7) ⊕ (W[i – 15] >>> 18) ⊕ (W[i – 15] >>\n3)\ns1 = (W[i – 2] >>> 17) ⊕ (W[i – 2] >>> 19) ⊕ (W[i – 2] >> 10)\nW[i] = W[i – 16] + s0 + W[i – 7] + s1\n}\n}\nreturn W\n}\nListing 6-8: SHA-256’s expand256() function\nNote how SHA-2’s expand256() message expansion is more complex\nthan SHA-1’s expand(), shown previously in Listing 6-6, which in contrast\nsimply performs XORs and a 1-bit rotation. The main loop of SHA-256’s\ncompression function is also more complex than that of SHA-1,\nperforming 26 arithmetic operations per iteration compared to 11 for\nSHA-1. Again, these operations are XORs, logical ANDs, and word\nrotations.\nOther SHA-2 Algorithms\nThe SHA-2 family includes SHA-224, which is algorithmically identical\nto SHA-256 except that its initial value is a different set of eight 32-bit\nwords, and its hash value length is 224 bits, instead of 256 bits, and is\ntaken as the first 224 bits of the final chaining value.\nThe SHA-2 family also includes the algorithms SHA-512 and SHA-\n384. SHA-512 is similar to SHA-256 except that it works with 64-bit\nwords instead of 32-bit words. As a result, it uses 512-bit chaining values\n(eight 64-bit words) and ingests 1024-bit message blocks (sixteen 64-bit\nwords), and it makes 80 rounds instead of 64. The compression function\nis otherwise almost the same as that of SHA-256, though with different\nrotation distances to cope with the wider word size. (For example, SHA-\n512 includes the operation a >>> 34, which wouldn’t make sense with\nSHA-256’s 32-bit words.) SHA-384 is to SHA-512 what SHA-224 is to\nSHA-256—namely, the same algorithm but with a different initial value\nand a final hash truncated to 384 bits.\nSecurity-wise, all four SHA-2 versions have lived up to their promises\nso far: SHA-256 guarantees 256-bit preimage resistance, SHA-512\nguarantees about 256-bit collision resistance, and so on. Still, there is no\ngenuine proof that SHA-2 functions are secure; we’re talking about\nprobable security.\nThat said, after practical attacks on MD5 and on SHA-1, researchers\nand NIST grew concerned about SHA-2’s long-term security due to its\nsimilarity to SHA-1, and many believed that attacks on SHA-2 were just a\nmatter of time. As I write this, though, we have yet to see a successful\nattack on SHA-2. Regardless, NIST developed a backup plan: SHA-3.\nThe SHA-3 Competition\nAnnounced in 2007, the NIST Hash Function Competition (the official\nname of the SHA-3 competition) began with a call for submissions and\nsome basic requirements: hash submissions were to be at least as secure\nand as fast as SHA-2, and they should be able to do at least as much as\nSHA-2. SHA-3 candidates also shouldn’t look too much like SHA-1 and\nSHA-2 in order to be immune to attacks that would break SHA-1 and\npotentially SHA-2. By 2008, NIST had received 64 submissions from\naround the world, including from universities and large corporations (BT,\nIBM, Microsoft, Qualcomm, and Sony, to name a few). Of these 64\nsubmissions, 51 matched the requirements and entered the first round of\nthe competition.\nDuring the first weeks of the competition, cryptanalysts mercilessly\nattacked the submissions. In July 2009, NIST announced 14 second-\nround candidates. After spending 15 months analyzing and evaluating the\nperformance of these candidates, NIST chose five finalists:\nBLAKE An enhanced Merkle–Damgård hash whose compression\nfunction is based on a block cipher, which is in turn based on the core\nfunction of the stream cipher ChaCha, a chain of additions, XORs, and\nword rotations. BLAKE was designed by a team of academic\nresearchers based in Switzerland and the UK, including myself.\nGrøstl An enhanced Merkle–Damgård hash whose compression\nfunction uses two permutations (or fixed-key block ciphers) based on\nthe core function of the AES block cipher. Grøstl was designed by a\nteam of seven academic researchers from Denmark and Austria.\nJH A tweaked sponge function construction wherein message blocks\nare injected before and after the permutation rather than just before.\nThe permutation also performs operations similar to a substitution–\npermutation block cipher (as discussed in Chapter 4). JH was designed\nby a cryptographer from a university in Singapore.\nKeccak A sponge function whose permutation performs only bitwise\noperations. Keccak was designed by a team of four cryptographers\nworking for a semiconductor company based in Belgium and Italy, and\nincluded one of the two designers of AES.\nSkein A hash function based on a different mode of operation than\nMerkle–Damgård, and whose compression function is based on a novel\nblock cipher that uses only integer addition, XOR, and word rotation.\nSkein was designed by a team of eight cryptographers from academia\nand industry, all but one of whom is based in the US, including the\nrenowned Bruce Schneier.\nAfter extensive analysis of the five finalists, NIST announced a winner:\nKeccak. NIST’s report rewarded Keccak for its “elegant design, large\nsecurity margin, good general performance, excellent efficiency in\nhardware, and its flexibility.” Let’s see how Keccak works.\nKeccak (SHA-3)\nOne of the reasons that NIST chose Keccak is that it’s completely\ndifferent from SHA-1 and SHA-2. For one thing, it’s a sponge function.\nKeccak’s core algorithm is a permutation of a 1600-bit state that ingests\nblocks of 1152, 1088, 832, or 576 bits, producing hash values of 224, 256,\n384, or 512 bits, respectively—the same four lengths produced by SHA-2\nhash functions. But unlike SHA-2, SHA-3 uses a single core algorithm\nrather than two algorithms for all four hash lengths.\nAnother reason is that Keccak is more than just a hash. The SHA-3\nstandard document FIPS 202 defines four hashes—SHA3-224, SHA3-\n256, SHA3-384, and SHA3-512—and two algorithms called SHAKE128\nand SHAKE256. (The name SHAKE stands for Secure Hash Algorithm\nwith Keccak.) These two algorithms are extendable-output functions (XOFs),\nor hash functions that can produce hashes of variable length, even very\nlong ones. The numbers 128 and 256 represent the security level of each\nalgorithm.\nThe FIPS 202 standard itself is lengthy and hard to parse, but you’ll\nfind open-source implementations that are reasonably fast and make the\nalgorithm easier to understand than the specifications. For example, the\nMIT-licensed tiny_sha3 (https://github.com/mjosaarinen/tiny_sha3/) by\nMarkku-Juhani O. Saarinen, explains Keccak’s core algorithm in 19 lines\nof C, as partially reproduced in Listing 6-9.\nstatic void sha3_keccakf(uint64_t st[25], int rounds)\n{\n(⊕)\nfor (r = 0; r < rounds; r++) {\n❶ // Theta\nfor (i = 0; i < 5; i++)\nbc[i] = st[i] ^ st[i + 5] ^ st[i + 10] ^ st[i + 15] ^ st[i +\n20];\nfor (i = 0; i < 5; i++) {\nt = bc[(i + 4) % 5] ^ ROTL64(bc[(i + 1) % 5], 1);\nfor (j = 0; j < 25; j += 5)\nst[j + i] ^= t;\n}\n❷ // Rho Pi\nt = st[1];\nfor (i = 0; i < 24; i++) {\nj = keccakf_piln[i];\nbc[0] = st[j];\nst[j] = ROTL64(t, keccakf_rotc[i]);\nt = bc[0];\n}\n❸ // Chi\nfor (j = 0; j < 25; j += 5) {\nfor (i = 0; i < 5; i++)\nbc[i] = st[j + i];\nfor (i = 0; i < 5; i++)\nst[j + i] ^= (~bc[(i + 1) % 5]) & bc[(i + 2) % 5];\n}\n❹ // Iota\nst[0] ^= keccakf_rndc[r];\n}\n(⊕)\n}\nListing 6-9: The tiny_sha3 implementation\nThe tiny_sha3 program implements the permutation, P, of Keccak, an\ninvertible transformation of a 1600-bit state viewed as an array of twenty-\nfive 64-bit words. As you review the code, notice that it iterates a series of\nrounds, where each round consists of four main steps (as marked by ❶, ❷,\n❸, and ❹):\nThe first step, Theta ❶, includes XORs between 64-bit words or a 1-\nbit rotated value of the words (the ROTL64(w, 1) operation left-rotates\na word w of 1 bit).\nThe second step, Rho Pi ❷, includes rotations of 64-bit words by\nconstants hardcoded in the keccakf_rotc[] array.\nThe third step, Chi ❸, includes more XORs, but also logical ANDs\n(the & operator) between 64-bit words. These ANDs are the only\nnonlinear operations in Keccak, and they bring with them\ncryptographic strength.\nThe fourth step, Iota ❹, includes a XOR with a 64-bit constant,\nhardcoded in the keccakf_rndc[].\nThese operations provide SHA-3 with a strong permutation algorithm\nfree of any bias or exploitable structure. SHA-3 is the product of more\nthan a decade of research, and hundreds of skilled cryptanalysts have\nfailed to break it. It’s unlikely to be broken anytime soon.\nThe BLAKE2 Hash Function\nSecurity may matter most, but speed comes second. I’ve seen many cases\nwhere a developer wouldn’t switch from MD5 to SHA-1 simply because\nMD5 is faster, or from SHA-1 to SHA-2 because SHA-2 is noticeably\nslower than SHA-1. Unfortunately, SHA-3 isn’t faster than SHA-2, and\nbecause SHA-2 is still secure, there are few incentives to upgrade to\nSHA-3. So how to hash faster than SHA-1 and SHA-2 and be even more\nsecure? The answer lies in the hash function BLAKE2, released after the\nSHA-3 competition.\nNOTE\nFull disclosure: I’m a designer of BLAKE2, together with Samuel Neves,\nZooko Wilcox-O’Hearn, and Christian Winnerlein.\nBLAKE2 was designed with the following ideas in mind:\nIt should be least as secure as SHA-3, if not stronger.\nIt should be faster than all previous hash standards, including MD5.\nIt should be suited for use in modern applications, and able to hash\nlarge amounts of data either as a few large messages or many small\nones, with or without a secret key.\nIt should be suited for use on modern CPUs supporting parallel\ncomputing on multicore systems as well as instruction-level\nparallelism within a single core.\nThe outcome of the engineering process is a pair of main hash\nfunctions:\nBLAKE2b (or just BLAKE2), optimized for 64-bit platforms,\nproduces digests ranging from 1 to 64 bytes.\nBLAKE2s, optimized for 8- to 32-bit platforms, can produce digests\nranging from 1 to 32 bytes.\nEach function has a parallel variant that can leverage multiple CPU\ncores. The parallel counterpart of BLAKE2b, BLAKE2bp, runs on four\ncores, whereas BLAKE2sp runs on eight cores. The former is the fastest\non modern server and laptop CPUs and can hash at close to 2 Gbps on a\nlaptop CPU. In fact, BLAKE2 is the fastest secure hash available today,\nand its speed and features have made it the most popular non-NIST-\nstandard hash. BLAKE2 is used in countless software applications and has\nbeen integrated into major cryptography libraries such as OpenSSL and\nSodium.\nNOTE\nYou can find BLAKE2’s specifications and reference code at\nhttps://blake2.net/, and you can download optimized code and libraries\nfrom https://github.com/BLAKE2/. The reference code also provides\nBLAKE2X, an extension of BLAKE2 that can produce hash values of\narbitrary length.\nFigure 6-8: BLAKE2’s compression function. The two halves of the state are XORed\ntogether after the block cipher.\nBLAKE2’s compression function, shown in Figure 6-8, is a variant of\nthe Davies–Meyer construction that takes parameters as additional input\n—namely, a counter (which ensures that each compression function\nbehaves like a different function) and a flag (which indicates whether the\ncompression function is processing the last message block, for increased\nsecurity).\nThe block cipher in BLAKE2’s compression function is based on the\nstream cipher ChaCha, itself a variant of the Salsa20 stream cipher\ndiscussed in Chapter 5. Within this block cipher, BLAKE2b’s core\noperation is composed of the following chain of operations, which\ntransforms a state of four 64-bit words using two message words, M and\ni\nM:\nj\nBLAKE2s’s core operation is similar but works with 32-bit instead of\n64-bit words (and thus uses different rotation values).\nHow Things Can Go Wrong\nDespite their apparent simplicity, hash functions can cause major security\ntroubles when used at the wrong place or in the wrong way—for example,\nwhen weak checksum algorithms like CRCs are used instead of a crypto\nhash to check file integrity in applications transmitting data over a\nnetwork. However, this weakness pales in comparison to some others,\nwhich can cause total compromise in seemingly secure hash functions.\nWe’ll see two examples of failures: the first one applies to SHA-1 and\nSHA-2, but not to BLAKE2 or SHA-3, whereas the second one applies to\nall of these four functions.\nThe Length-Extension Attack\nThe length-extension attack, shown in Figure 6-9, is the main threat to the\nMerkle–Damgård construction.\nFigure 6-9: The length-extension attack\nBasically, if you know Hash(M) for some unknown message, M,\ncomposed of blocks M and M (after padding), you can determine\n1 2\nHash(M || M || M ) for any block, M . Because the hash of M || M\n1 2 3 3 1 2\nis the chaining value that follows immediately after M , you can add\n2\nanother block, M , to the hashed message, even though you don’t know\n3\nthe data that was hashed. What’s more, this trick generalizes to any\nnumber of blocks in the unknown message (M || M here) or in the\n1 2\nsuffix (M ).\n3\nThe length-extension attack won’t affect most applications of hash\nfunctions, but it can compromise security if the hash is used a bit too\ncreatively. Unfortunately, SHA-2 hash functions are vulnerable to the\nlength-extension attack, even though the NSA designed the functions and\nNIST standardized them while both were well aware of the flaw. This\nflaw could have been avoided simply by making the last compression\nfunction call different from all others (for example, by taking a 1 bit as an\nextra parameter while the previous calls take a 0 bit). And that is in fact\nwhat BLAKE2 does.\nFooling Proof-of-Storage Protocols\nCloud computing applications have used hash functions within proof-of-\nstorage protocols—that is, protocols where a server (the cloud provider)\nproves to a client (a user of a cloud storage service) that the server does in\nfact store the files that it’s supposed to store on behalf of the client.\nIn 2007, the paper “SafeStore: A Durable and Practical Storage\nSystem” (https://www.cs.utexas.edu/~lorenzo/papers/p129-kotla.pdf) by\nRamakrishna Kotla, Lorenzo Alvisi, and Mike Dahlin proposed a proof-\nof-storage protocol to verify the storage of some file, M, as follows:\n1. The client picks a random value, C, as a challenge.\n2. The server computes Hash(M || C) as a response and sends the result\nto the client.\n3. The client also computes Hash(M || C) and checks that it matches\nthe value received from the server.\nThe premise of the paper is that the server shouldn’t be able to fool the\nclient because if the server doesn’t know M, it can’t guess Hash(M || C).\nBut there’s a catch: in reality, Hash will be an iterated hash that processes\nits input block by block, computing intermediate chaining values between\neach block. For example, if Hash is SHA-256 and M is 512 bits long (the\nsize of a block in SHA-256), the server can cheat. How? The first time\nthe server receives M, it computes H = Compress(H , M ), the chaining\n1 0 1\nvalue obtained from SHA-256’s initial value, H , and from the 512-bit M.\n0\nIt then records H in memory and discards M, at which point it no longer\n1\nstores M.\nNow when the client sends a random value, C, the server computes\nCompress(H , C), after adding the padding to C to fill a complete block,\n1\nand returns the result as Hash(M || C). The client then believes that,\nbecause the server returned the correct value of Hash(M || C), it holds\nthe complete message—except that it may not, as you’ve seen.\nThis trick will work for SHA-1, SHA-2, as well as SHA-3 and\nBLAKE2. The solution is simple: ask for Hash(C || M) instead of\nHash(M || C).\nFurther Reading\nTo learn more about hash functions, read the classics from the 1980s and\n90s: research articles like Ralph Merkle’s “One Way Hash Functions and\nDES” and Ivan Damgård’s “A Design Principle for Hash Functions.”\nAlso read the first thorough study of block cipher-based hashing, “Hash\nFunctions Based on Block Ciphers: A Synthetic Approach” by Preneel,\nGovaerts, and Vandewalle.\nFor more on collision search, read the 1997 paper “Parallel Collision\nSearch with Cryptanalytic Applications” by van Oorschot and Wiener.\nTo learn more about the theoretical security notions that underpin\npreimage resistance and collision resistance, as well as length-extension\nattacks, search for indifferentiability.\nFor more recent research on hash functions, see the archives of the\nSHA-3 competition, which include all the different algorithms and how\nthey were broken. You’ll find many references on the SHA-3 Zoo at\nhttp://ehash.iaik.tugraz.at/wiki/The_SHA-3_Zoo, and on NIST’s page,\nhttp://csrc.nist.gov/groups/ST/hash/sha-3/.\nFor more on the SHA-3 winner Keccak and sponge functions, see\nhttp://keccak.noekeon.org/ and http://sponge.noekeon.org/, the official pages of\nthe Keccak designers.\nLast but not least, research these two real exploitations of weak hash\nfunctions:\nThe nation-state malware Flame exploited an MD5 collision to make\na counterfeit certificate and appear to be a legitimate piece of\nsoftware.\nThe Xbox game console used a weak block cipher (called TEA) to\nbuild a hash function, which was exploited to hack the console and\nrun arbitrary code on it."
  },
  {
    "input": "What is the difference between pseudorandom functions (PRFs) and message authentication codes (MACs) in terms of their security requirements and usage in cryptographic algorithms?",
    "summary": "Keyed hashing involves using a secret key to generate hash values, forming the basis for message authentication codes (MACs) and pseudorandom functions (PRFs). MACs ensure message integrity and authenticity, while PRFs produce random-looking outputs. Both are crucial in cryptography, with PRFs being stronger as they must be indistinguishable from random values. Keyed hashes can be constructed from block ciphers or hash functions, but certain methods like secret-prefix are vulnerable to attacks. HMAC and CMAC are secure constructions, with Poly1305 and SipHash being efficient MACs designed for different use cases. SipHash is particularly useful for short messages and is resistant to side-channel attacks.",
    "output": "7\nKEYED HASHING\nThe hash functions discussed in Chapter 6 take a message and return its\nhash value—typically a short string of 256 or 512 bits. Anyone can\ncompute the hash value of a message and verify that a particular message\nhashes to a particular value because there’s no secret value involved, but\nsometimes you don’t want to let just anyone do that. That’s where keyed\nhash functions come in, or hashing with secret keys.\nKeyed hashing forms the basis of two types of important cryptographic\nalgorithms: message authentication codes (MACs), which authenticate a\nmessage and protect its integrity, and pseudorandom functions (PRFs),\nwhich produce random-looking hash-sized values. We’ll look at how and\nwhy MACs and PRFs are similar in the first section of this chapter; then\nwe’ll review how real MACs and PRFs work. Some MACs and PRFs are\nbased on hash functions, some are based on block ciphers, and still others\nare original designs. Finally, we’ll review examples of attacks on otherwise\nsecure MACs.\nMessage Authentication Codes (MACs)\nA MAC protects a message’s integrity and authenticity by creating a value\nT = MAC(K, M), called the authentication tag of the message, M (often\nconfusingly called the MAC of M). Just as you can decrypt a message if\nyou know a cipher’s key, you can validate that a message has not been\nmodified if you know a MAC’s key.\nFor example, say Alex and Bill share a key, K, and Alex sends a message,\nM, to Bill along with its authentication tag, T = MAC(K, M). Upon\nreceiving the message and its authentication tag, Bill recomputes\nMAC(K, M) and checks that it is equal to the authentication tag received.\nBecause only Alex could have computed this value, Bill knows that the\nmessage wasn’t corrupted in transit (confirming integrity), whether\naccidentally or maliciously, and that Alex sent that message (confirming\nauthenticity).\nMACs in Secure Communication\nSecure communication systems often combine a cipher and a MAC to\nprotect a message’s confidentiality, integrity, and authenticity. For\nexample, the protocols in Internet Protocol Security (IPSec), Secure Shell\n(SSH), and Transport Layer Security (TLS) generate a MAC for each\nnetwork packet transmitted.\nNot all communication systems use MACs. Sometimes an\nauthentication tag can add unacceptable overhead to each packet,\ntypically in the range of 64 to 128 bits. For example, the 3G and 4G\nmobile telephony standards encrypt packets encoding voice calls but they\ndon’t authenticate them. An attacker can modify the encrypted audio\nsignal and the recipient wouldn’t notice. Thus, if an attacker damages an\nencrypted voice packet, it will decrypt to noise, which would sound like\nstatic.\nForgery and Chosen-Message Attacks\nWhat does it mean for a MAC to be secure? First of all, as with a cipher,\nthe secret key should remain secret. If a MAC is secure, an attacker\nshouldn’t be able to create a tag of some message if they don’t know the\nkey. Such a made-up message/tag pair is called a forgery, and recovering a\nkey is just a specific case of a more general class of attacks called forgery\nattacks. The security notion that posits that forgeries should be impossible\nto find is called unforgeability. Obviously, it should be impossible to\nrecover the secret key from a list of tags; otherwise, attackers could forge\ntags using the key.\nWhat can an attacker do to break a MAC? In other words, what’s the\nattack model? The most basic model is the known-message attack, which\npassively collects messages and their associated tags (for example, by\neavesdropping on a network). But real attackers often launch more\npowerful attacks because they can often choose the messages to be\nauthenticated, and therefore get the MAC of the message they want. The\nstandard model is therefore that of chosen-message attacks, wherein\nattackers get tags for messages of their choice.\nReplay Attacks\nMACs aren’t safe from attacks involving replays of tags. For example, if\nyou were to eavesdrop on Alex and Bill’s communications, you could\ncapture a message and its tag sent by Alex to Bill, and later send them\nagain to Bill pretending to be Alex. To prevent such replay attacks,\nprotocols include a message number in each message. This number is\nincremented for each new message and authenticated along with the\nmessage. The receiving party gets messages numbered 1, 2, 3, 4, and so\non. Thus, if an attacker tries to send message number 1 again, the\nreceiver will notice that this message is out of order and that it’s a\npotential replay of the earlier message number 1.\nPseudorandom Functions (PRFs)\nA PRF is a function that uses a secret key to return PRF(K, M), such that\nthe output looks random. Because the key is secret, the output values are\nunpredictable to an attacker.\nUnlike MACs, PRFs are not meant to be used on their own but as part\nof a cryptographic algorithm or protocol. For example, PRFs can be used\nto create block ciphers within the Feistel construction discussed in “How\nto Construct Block Ciphers” on page 55. Key derivation schemes use\nPRFs to generate cryptographic keys from a master key or a password,\nand identification schemes use PRFs to generate a response from a\nrandom challenge. (Basically, a server sends a random challenge message,\nM, and the client returns PRF(K, M) in its response to prove that it\nknows K.) The 4G telephony standard uses a PRF to authenticate a SIM\ncard and its service provider, and a similar PRF also serves to generate the\nencryption key and MAC key to be used during a phone call. The TLS\nprotocol uses a PRF to generate key material from a master secret as well\nas session-specific random values. There’s even a PRF in the\nnoncryptographic hash() function built into the Python language to\ncompare objects.\nPRF Security\nIn order to be secure, a pseudorandom function should have no pattern\nthat sets its outputs apart from truly random values. An attacker who\ndoesn’t know the key, K, shouldn’t be able to distinguish the outputs of\nPRF(K, M) from random values. Viewed differently, an attacker shouldn’t\nhave any means of knowing whether they’re talking to a PRF algorithm\nor to a random function. The erudite phrase for that security notion is\nindistinguishability from a random function. (To learn more about the\ntheoretical foundations of PRFs, see Volume 1, Section 3.6 of\nGoldreich’s Foundations of Cryptography.)\nWhy PRFs Are Stronger Than MACs\nPRFs and MACs are both keyed hashes, but PRFs are fundamentally\nstronger than MACs, largely because MACs have weaker security\nrequirements. Whereas a MAC is considered secure if tags can’t be\nforged—that is, if the MAC’s outputs can’t be guessed—a PRF is only\nsecure if its outputs are indistinguishable random strings, which is a\nstronger requirement. If a PRF’s outputs can’t be distinguished from\nrandom strings, the implication is that their values can’t be guessed; in\nother words, any secure PRF is also a secure MAC.\nThe converse is not true, however: a secure MAC isn’t necessarily a\nsecure PRF. For example, say you start with a secure PRF, PRF1, and\nyou want to build a second PRF, PRF2, from it, like this:\nPRF2(K, M) = PRF1(K, M) || 0\nBecause PRF2’s output is defined as PRF1’s output followed by one 0\nbit, it doesn’t look as random as a true random string, and you can\ndistinguish its outputs by that last 0 bit. Hence, PRF2 is not a secure\nPRF. However, because PRF1 is secure, PRF2 would still make a secure\nMAC. Why? Because if you were able to forge a tag, T = PRF2(K, M), for\nsome M, then you’d also be able to forge a tag for PRF1, which we know\nto be impossible in the first place because PRF1 is a secure MAC. Thus,\nPRF2 is a keyed hash that’s a secure MAC but not a secure PRF.\nBut don’t worry: you won’t find such MAC constructions in real\napplications. In fact, many of the MACs deployed or standardized are also\nsecure PRFs and are often used as either. For example, TLS uses the\nalgorithm HMAC-SHA-256 both as a MAC and as a PRF.\nCreating Keyed Hashes from Unkeyed Hashes\nThroughout the history of cryptography, MACs and PRFs have rarely\nbeen designed from scratch but rather have been built from existing\nalgorithms, usually hash functions of block ciphers. One seemingly\nobvious way to produce a keyed hash function would be to feed an\n(unkeyed) hash function a key and a message, but that’s easier said than\ndone, as I discuss next.\nThe Secret-Prefix Construction\nThe first technique we’ll examine, called the secret-prefix construction,\nturns a normal hash function into a keyed hash one by prepending the\nkey to the message and returning Hash(K || M). Although this approach\nis not always wrong, it can be insecure when the hash function is\nvulnerable to length-extension attacks (as discussed in “The Length-\nExtension Attack” on page 125) and when the hash supports keys of\ndifferent lengths.\nInsecurity Against Length-Extension Attacks\nRecall from Chapter 6 that hash functions of the SHA-2 family allow\nattackers to compute the hash of a partially unknown message when given\na hash of a shorter version of that message. In formal terms, the length-\nextension attack allows attackers to compute Hash(K || M || M ) given\n1 2\nonly Hash(K || M ) and neither M nor K. These functions allow\n1 1\nattackers to forge valid MAC tags for free because they’re not supposed\nto be able to guess the MAC of M || M given only the MAC of M .\n1 2 1\nThis fact makes the secret-prefix construction as insecure as a MAC and\nPRF when, for example, it’s used with SHA-256 or SHA-512. It is a\nweakness of Merkle–Damgård to allow length-extension attacks, and\nnone of the SHA-3 finalists do. The ability to thwart length-extension\nattacks was mandatory for SHA-3 submissions.\nInsecurity with Different Key Lengths\nThe secret-prefix construction is also insecure when it allows the use of\nkeys of different lengths. For example, if the key K is the 24-bit\nhexa​\ndecimal string 123abc and M is def00, then Hash() will process the value\nK || M = 123abcdef00. If K is instead the 16-bit string 123a and M is\nbcdef000, then Hash() will process K || M = 123abcdef00, too.\nTherefore, the result of the secret-prefix construction Hash(K || M) will\nbe the same for both keys.\nThis problem is independent of the underlying hash and can be fixed\nby hashing the key’s length along with the key and the message, for\nexample, by encoding the key’s bit length as a 16-bit integer, L, and then\nhashing Hash(L || K || M). But you shouldn’t have to do this. Modern\nhash functions such as BLAKE2 and SHA-3 include a keyed mode that\navoids those pitfalls and yields a secure PRF, and thus a secure MAC as\nwell.\nThe Secret-Suffix Construction\nInstead of hashing the key before the message as in the secret-prefix\nconstruction, we can hash it after. And that’s exactly how the secret-suffix\nconstruction works: by building a PRF from a hash function as Hash(M ||\nK).\nPutting the key at the end makes quite a difference. For one thing, the\nlength-extension attack that works against secret-prefix MACs won’t\nwork against the secret suffix. Applying length extension to a secret-suffix\nMAC, you’d get Hash(M || K || M ) from Hash(M || K), but that\n1 2 1\nwouldn’t be a valid attack because Hash(M || K || M ) isn’t a valid\n1 2\nsecret-suffix MAC; the key needs to be at the end.\nHowever, the secret-suffix construction is weaker against another type\nof attack. Say you’ve got a collision for the hash Hash(M ) = Hash(M ),\n1 2\nwhere M and M are two distinct messages, possibly of different sizes. In\n1 2\nthe case of a hash function such as SHA-256, this implies that Hash(M\n1\n|| K) and Hash(M || K) will be equal too, because internally K will be\n2\nprocessed based on the data hashed previously, namely Hash(M ), equal\n1\nto Hash(M ). Hence, you’d get the same hash value whether you hash K\n2\nafter M or after M , regardless of the value of K.\n1 2\nTo exploit this property, an attacker would:\n1. Find two colliding messages, M and M\n1 2\n2. Request the MAC tag of M Hash(M || K)\n1 1\n3. Guess that Hash(M || K) is the same, thereby forging a valid tag\n2\nand breaking the MAC’s security\nThe HMAC Construction\nThe hash-based MAC (HMAC) construction allows us to build a MAC\nfrom a hash function, which is more secure than either secret prefix or\nsecret suffix. HMAC yields a secure PRF as long as the underlying hash is\ncollision resistant, but even if that’s not the case, HMAC will still yield a\nsecure PRF if the hash’s compression function is a PRF. The secure\ncommunication protocols IPSec, SSH, and TLS have all used HMAC.\n(You’ll find HMAC specifications in NIST’s FIPS 198-1 standard and in\nRFC 2104.)\nHMAC uses a hash function, Hash, to compute a MAC tag, as shown\nin Figure 7-1 and according to the following expression:\nHash((K ⊕ opad) Hash((K ⊕ ipad) M))\nThe term opad (outer padding) is a string (5c5c5c . . . 5c) that is as long\nas Hash’s block size. The key, K, is usually shorter than one block that is\nfilled with 00 bytes and XORed with opad. For example, if K is the 1-byte\nstring 00, then K ⊕ opad = opad. (The same is true if K is the all-zero string\nof any length up to a block’s length.) K ⊕ opad is the first block processed\nby the outer call to Hash—namely, the leftmost Hash in the preceding\nequation, or the bottom hash in Figure 7-1.\nThe term ipad (inner padding) is a string (363636 . . . 36) that is as long\nas the Hash’s block size and that is also completed with 00 bytes. The\nresulting block is the first block processed by the inner call to Hash—\nnamely, the rightmost Hash in the equation, or the top hash in Figure 7-\n1.\nFigure 7-1: The HMAC hash-based MAC construction\nNOTE\nThe envelope method is an even more secure construction than secret prefix\nand secret suffix. It’s expressed as Hash(K || M || K), something called a\nsandwich MAC, but it’s theoretically less secure than HMAC.\nIf SHA-256 is the hash function used as Hash, then we call the HMAC\ninstance HMAC-SHA-256. More generally, we call HMAC-Hash an\nHMAC instance using the hash function Hash. That means if someone\nasks you to use HMAC, you should always ask, “Which hash function?”\nA Generic Attack Against Hash-Based MACs\nThere is one attack that works against all MACs based on an iterated hash\nfunction. Recall the attack in “The Secret-Suffix Construction” on page\n131 where we used a hash collision to get a collision of MACs. You can\nuse the same strategy to attack a secret-prefix MAC or HMAC, though\nthe consequences are less devastating.\nTo illustrate the attack, consider the secret-prefix MAC Hash(K || M),\nas shown in Figure 7-2. If the digest is n bits, you can find two messages,\nM and M , such that Hash(K || M ) = Hash(K || M ), by requesting\n1 2 1 2\napproximately 2n/2 MAC tags to the system holding the key. (Recall the\nbirthday attack from Chapter 6.) If the hash lends itself to length\nextension, as SHA-256 does, you can then use M and M to forge MACs\n1 2\nby choosing some arbitrary data, M , and then querying the MAC oracle\n3\nfor Hash(K || M || M ), which is the MAC of message M || M . As it\n1 3 1 3\nturns out, this is also the MAC of message M || M , because the hash’s\n2 3\ninternal state of M and M and M and M is the same, and you’ve\n1 3 2 3\nsuccessfully forged a MAC tag. (The effort becomes infeasible as n grows\nbeyond, say, 128 bits.)\nFigure 7-2: The principle of the generic forgery attack on hash-based MACs\nThis attack will work even if the hash function is not vulnerable to\nlength extension, and it will work for HMAC, too. The cost of the attack\ndepends on both the size of the chaining value and the MAC’s length: if a\nMAC’s chaining value is 512 bits and its tags are 128 bits, a 264\ncomputation would find a MAC collision but probably not a collision in\nthe internal state, since finding such a collision would require 2512/2 = 2256\noperations on average.\nCreating Keyed Hashes from Block Ciphers: CMAC\nRecall from Chapter 6 that the compression functions in many hash\nfunctions are built on block ciphers. For example, HMAC-SHA-256 PRF\nis a series of calls to SHA-256’s compression function, which itself is a\nblock cipher that repeats a sequence of rounds. In other words, HMAC-\nSHA-256 is a block cipher inside a compression function inside a hash\ninside the HMAC construction. So why not use a block cipher directly\nrather than build such a layered construction?\nCMAC (which stands for cipher-based MAC) is such a construction: it\ncreates a MAC given only a block cipher, such as AES. Though less\npopular than HMAC, CMAC is deployed in many systems, including the\nInternet Key Exchange (IKE) protocol, which is part of the IPSec suite.\nIKE, for example, generates key material using a construction called\nAES-CMAC-PRF-128 as a core algorithm (or CMAC based on AES with\n128-bit output). CMAC is specified in RFC 4493.\nBreaking CBC-MAC\nCMAC was designed in 2005 as an improved version of CBC-MAC, a\nsimpler block cipher–based MAC derived from the cipher block chaining\n(CBC) block cipher mode of operation (see “Modes of Operation” on\npage 65).\nCBC-MAC, the ancestor of CMAC, is simple: to compute the tag of a\nmessage, M, given a block cipher, E, you encrypt M in CBC mode with\nan all-zero initial value (IV) and discard all but the last ciphertext block.\nThat is, you compute C = E(K, M ), C = E(K, M ⊕ C ), C = E(K, M ⊕\n1 1 2 2 1 3 3\nC ), and so on for each of M’s blocks and keep only the last C , your\n2 i\nCBC-MAC tag for M—simple, and simple to attack.\nTo understand why CBC-MAC is insecure, consider the CBC-MAC\ntag, T = E(K, M ), of a single-block message, M , and the tag, T = E(K,\n1 1 1 2\nM ), of another single-block message, M . Given these two pairs, (M ,\n2 2 1\nT ) and (M , T ), you can deduce that T is also the tag of the two-block\n1 2 2 2\nmessage M || (M ⊕ T ). Indeed, if you apply CBC-MAC to M || (M\n1 2 1 1 2\n⊕ T ) and compute C = E(K, M ) = T followed by C = E(K, (M ⊕ T ) ⊕\n1 1 1 1 2 2 1\nT ) = E(K, M ) = T , you can create a third message/tag pair from two\n1 2 2\nmessage/tag pairs without knowing the key. That is, you can forge CBC-\nMAC tags, thereby breaking CBC-MAC’s security.\nFixing CBC-MAC\nCMAC fixes CBC-MAC by processing the last block using a different key\nfrom the preceding blocks. To do this, CMAC first derives two keys, K\n1\nand K , from the main key, K, such that K, K , and K will be distinct. In\n2 1 2\nCMAC, the last block is processed using either K or K , while the\n1 2\npreceding blocks use K.\nTo determine K and K , CMAC first computes a temporary value, L =\n1 2\nE(0, K), where 0 acts as the key of the block cipher and K acts as the\nplaintext block. Then CMAC sets the value of K equal to (L << 1) if L’s\n1\nmost significant bit (MSB) is 0, or equal to (L << 1) ⊕ 87 if L’s MSB is 1.\n(The number 87 is carefully chosen for its mathematical properties when\ndata blocks are 128 bits; a value other than 87 is needed when blocks\naren’t 128 bits.)\nThe value of K is set equal to (K << 1) if K ’s MSB is 0, or K = (K <<\n2 1 1 2 1\n1) ⊕ 87 otherwise.\nGiven K and K , CMAC works like CBC-MAC, except for the last\n1 2\nblock. If the final message chunk M is exactly the size of a block, CMAC\nn\nreturns the value E(K, M ⊕ C ⊕ K ) as a tag, as shown in Figure 7-3.\nN n − 1 1\nBut if M has fewer bits than a block, CMAC pads it with a 1 bit and\nN\nzeros, and returns the value E(K, M ⊕ C ⊕ K ) as a tag, as shown in\nn n − 1 2\nFigure 7-4. Notice that the first case uses only K and the second only K ,\n1 2\nbut both use only the main key K to process the message chunks that\nprecede the final one.\nFigure 7-3: The CMAC block cipher–based MAC construction when the message is a\nsequence of integral blocks\nFigure 7-4: The CMAC block cipher–based MAC construction when the last block of\nthe message has to be padded with a 1 bit and zeros to fill a block\nNote that unlike the CBC encryption mode, CMAC does not take an\nIV as a parameter and is deterministic: CMAC will always return the\nsame tag for a given message, M, because the computation of CMAC(M)\nis not randomized—and that’s fine, because unlike encryption, MAC\ncomputation doesn’t have to be randomized to be secure, which\neliminates the burden of having to choose random IV.\nDedicated MAC Designs\nYou’ve seen how to recycle hash functions and block ciphers to build\nPRFs that are secure as long as their underlying hash or cipher is secure.\nSchemes such as HMAC and CMAC simply combine available hash\nfunctions or block ciphers to yield a secure PRF or MAC. Reusing\navailable algorithms is convenient, but is it the most efficient approach?\nIntuitively, PRFs and MACs should require less work than unkeyed\nhash functions in order to be secure—their use of a secret key prevents\nattackers from playing with the algorithm because they don’t have the\nkey. Also, PRFs and MACs only expose a short tag to attackers, unlike\nblock ciphers, which expose a ciphertext that is as long as the message.\nHence, PRFs and MACs should not need the whole power of hash\nfunctions or block ciphers, which is the point of dedicated design—that is,\nalgorithms created solely to serve as PRFs and/or MACs.\nThe sections that follow focus on two such algorithms that are widely\nused: Poly1305 and SipHash. I’ll explain their design principles and why\nthey are likely secure.\nPoly1305\nThe Poly1305 algorithm (pronounced poly-thirteen-o-five) was designed in\n2005 by Daniel J. Bernstein (creator of the Salsa20 stream cipher\ndiscussed in Chapter 5 and the ChaCha cipher that inspired the BLAKE\nand BLAKE2 hash functions discussed in Chapter 6). Poly1305 is\noptimized to be super fast on modern CPUs, and as I write this, it is used\nby Google to secure HTTPS (HTTP over TLS) connections and by\nOpenSSH, among many other applications. Unlike Salsa20, the design of\nPoly1305 is built on techniques dating back to the 1970s—namely,\nuniversal hash functions and the Wegman–Carter construction.\nUniversal Hash Functions\nThe Poly1305 MAC uses a universal hash function internally that is much\nweaker than a cryptographic hash function, but also much faster.\nUniversal hash functions don’t have to be collision resistant, for example.\nThat means less work is required to achieve their security goals.\nLike a PRF, a universal hash is parameterized by a secret key: given a\nmessage, M, and key, K, we write UH(K, M), which is the computation of\nthe output of a universal hash function, denoted UH. A universal hash\nfunction has only one security requirement: for any two messages, M\n1\nand M , the probability that UH(K, M ) = UH(K, M ) must be negligible\n2 1 2\nfor a random key, K. Unlike a PRF, a universal hash doesn’t need to be\npseudorandom; there simply should be no pair (M , M ) that gives the\n1 2\nsame hash for many different keys. Because their security requirements\nare easier to satisfy, fewer operations are required and therefore universal\nhash functions are considerably faster than PRFs.\nYou can use a universal hash as a MAC to authenticate no more than\none message, however. For example, consider the universal hash used in\nPoly1305, called a polynomial-evaluation hash. (See the seminal 1974\narticle “Codes Which Detect Deception” by Gilbert, MacWilliams, and\nSloane for more on this notion.) This kind of polynomial-evaluation hash\nis parameterized by a prime number, p, and takes as input a key consisting\nof two numbers, R and K, in the range [1, p] and a message, M, consisting\nof n blocks (M , M , . . . , M ). The output of the universal hash is then\n1 2 n\ncomputed as the following:\nUH(R, K, M) = R + M K + M K2 + M K3 + ... + M Kn mod p\n1 3 3 n\nThe plus sign (+) denotes the addition of positive integers, K i is the\nnumber K raised to the power i, and “mod p” denotes the reduction\nmodulo p of the result (that is, the remainder of the division of the result\nby p; for example, 12 mod 10 = 2, 10 mod 10 = 0, 8 mod 10 = 8, and so\non).\nBecause we want the hash to be as fast as possible, universal hash-based\nMACs often work with message blocks of 128 bits and with a prime\nnumber, p, that is slightly larger than 2128, such as 2128 + 51. The 128-bit\nwidth allows for very fast implementations by efficiently using the 32-\nand 64-bit arithmetic units of common CPUs.\nPotential Vulnerabilities\nUniversal hashes have one weakness: because a universal hash is only able\nto securely authenticate one message, an attacker could break the\npreceding polynomial-evaluation MAC by requesting the tags of only two\nmessages. Specifically, they could request the tags for a message where\nM = M = . . . = 0 (that is, whose tag is UH(R, K, 0) = R) and then use the\n1 2\ntags to find the secret value R. Alternatively, they could request the tags\nfor a message where M = 1 and where M = M = . . . = 0 (that is, whose\n1 2 3\ntag is T = R + K), which would allow them to find K by subtracting R from\nT. Now the attacker knows the whole key (R, K) and they can forge\nMACs for any message.\nFortunately, there’s a way to go from single-message security to multi-\nmessage security.\nWegman–Carter MACs\nThe trick to authenticating multiple messages using a universal hash\nfunction arrived thanks to IBM researchers Wegman and Carter and\ntheir 1981 paper “New Hash Functions and Their Use in Authentication\nand Set Equality.” The so-called Wegman–Carter construction builds a\nMAC from a universal hash function and a PRF, using two keys, K and\n1\nK , and it returns\n2\nMAC(K , K , N, M) = UH(K , M) + PRF(K , N)\n1 2 1 2\nwhere N is a nonce that should be unique for each key, K , and where\n2\nPRF’s output is as large as that of the universal hash function UH. By\nadding these two values, PRF’s strong pseudorandom output masks the\ncryptographic weakness of UH. You can see this as the encryption of the\nuniversal hash’s result, where the PRF acts as a stream cipher and\nprevents the preceding attack by making it possible to authenticate\nmultiple messages with the same key, K .\n1\nTo recap, the Wegman–Carter construction UH(K , M) + PRF(K , N)\n1 2\ngives a secure MAC if we assume the following:\nUH is a secure universal hash.\nPRF is a secure PRF.\nEach nonce N is used only once for each key K .\n2\nThe output values of UH and PRF are long enough to ensure high\nenough security.\nNow let’s see how Poly1305 leverages the Wegman–Carter\nconstruction to build a secure and fast MAC.\nPoly1305-AES\nPoly1305 was initially proposed as Poly1305-AES, combining the\nPoly1305 universal hash with the AES block cipher. Poly1305-AES is\nmuch faster than HMAC-based MACs, or even than CMACs, since it\nonly computes one block of AES and processes the message in parallel\nthrough a series of simple arithmetic operations.\nGiven a 128-bit K , K , and N, and message, M, Poly1305-AES returns\n1 2\nthe following:\nPoly 1305(K , M) + AES(K , N) mod 2128\n1 2\nThe mod 2128 reduction ensures that the result fits in 128 bits. The\nmessage M is parsed as a sequence of 128-bit blocks (M , M , . . . , M ),\n1 2 n\nand a 129th bit is appended to each block’s most significant bit to make\nall blocks 129 bits long. (If the last block is smaller than 16 bytes, it’s\npadded with a 1 bit followed by 0 bits before the final 129th bit.) Next,\nPoly1305 evaluates the polynomial to compute the following:\nPoly 1305(K , M) = M K i + M K n − 1 + ... +M K mod 2130 − 5\n1 1 1 2 1 n 1\nThe result of this expression is an integer that is at most 129-bits long.\nWhen added to the 128-bit value AES(K , N), the result is reduced\n2\nmodulo 2128 to produce a 128-bit MAC.\nNOTE\nAES isn’t a PRF; instead, it’s a pseudorandom permutation (PRP).\nHowever, that doesn’t matter much here because the Wegman–Carter\nconstruction works with a PRP as well as with a PRF. This is because if\nyou’re given a function that is either a PRF of a PRP, it’s hard to determine\nwhether it’s a PRF of a PRP just by looking at the function’s output values.\nThe security analysis of Poly1305-AES (see “The Poly1305-AES\nMessage-Authentication Code” at http://cr.yp.to/mac/poly1305-\n20050329.pdf) shows that Poly1305-AES is 128-bit secure as long as AES\nis a secure block cipher—and, of course, as long as everything is\nimplemented correctly, as with any cryptographic algorithm.\nThe Poly1305 universal hash can be combined with algorithms other\nthan AES. For example, Poly1305 was used with the stream cipher\nChaCha (see RFC 7539, “ChaCha20 and Poly1305 for IETF Protocols”).\nThere’s no doubt that Poly1305 will keep being used wherever a fast\nMAC is needed.\nSipHash\nAlthough Poly1305 is fast and secure, it has several downsides. For one,\nits polynomial evaluation is difficult to implement efficiently, especially in\nthe hands of many who are unfamiliar with the associated mathematical\nnotions. (See examples at https://github.com/floodyberry/poly1305-donna/).\nSecond, on its own, it’s secure for only one message unless you use the\nWegman–Carter construction. But in that case, it requires a nonce, and if\nthe nonce is repeated, the algorithm becomes insecure. Finally, Poly1305\nis optimized for long messages, but it’s overkill if you process only small\nmessages (say, fewer than 128 bytes). In such cases, SipHash is the\nsolution.\nI designed SipHash in 2012 with Dan Bernstein initially to address a\nnoncryptographic problem: denial-of-service attacks on hash tables. Hash\ntables are data structures used to efficiently store elements in\nprogramming languages. Prior to the advent of SipHash, hash tables\nrelied on noncryptographic keyed hash functions for which collisions\nwere easy to find, and it was easy to exploit a remote system using a hash\ntable by slowing it down with a denial-of-service attack. We determined\nthat a PRF would address this problem and thus set out to design\nSipHash, a PRF suitable for hash tables. Because hash tables process\nmostly short inputs, SipHash is optimized for short messages. However,\nSipHash can be used for more than hash tables: it’s a full-blown PRF and\nMAC that shines where most inputs are short.\nHow SipHash Works\nSipHash uses a trick that makes it more secure than basic sponge\nfunctions: instead of XORing message blocks only once before the\npermutation, SipHash XORs them before and after the permutation, as\nshown in Figure 7-5. The 128-bit key of SipHash is seen as two 64-bit\nwords, K and K , XORed to a 256-bit fixed initial state that is seen as\n1 2\nfour 64-bit words. Next, the keys are discarded, and computing SipHash\nboils down to iterating through a core function called SipRound and then\nXORing message chunks to modify the four-word internal state. Finally,\nSipHash returns a 64-bit tag by XORing the four-state words together.\nFigure 7-5: SipHash-2-4 processing a 15-byte message (a block, M , of 8 bytes\n1\nand a block, M , of 7 bytes, plus 1 byte of padding)\n2\nThe SipRound function uses a bunch of XORs together with additions\nand word rotations to make the function secure. SipRound transforms a\nstate of four 64-bit words (a, b, c, d) by performing the following\noperations, top to bottom. The operations on the left and right are\nindependent and can be carried out in parallel:\nHere, a += b is shorthand for a = a + b, and b <<< = 13 is shorthand for b\n= b <<< 13 (the 64-bit word b left-rotated 13 bits.)\nThese simple operations on 64-bit words are almost all you need to\nimplement in order to compute SipHash—although you won’t have to\nimplement it yourself. You can find readily available implementations in\nmost languages, including C, Go, Java, JavaScript, and Python.\nNOTE\nWe write SipHash-x-y as the SipHash version, meaning it makes x\nSipRounds between each message block injection and then y rounds. More\nrounds require more operations, which slows down operations but also\nincreases security. The default version is SipHash-2-4 (simply noted as\nSipHash), and it has so far resisted cryptanalysis. However, you may want to\nbe conservative and opt for SipHash-4-8 instead, which makes twice as many\nrounds and is therefore twice as slow.\nHow Things Can Go Wrong\nLike ciphers and unkeyed hash functions, MACs and PRFs that are\nsecure on paper can be vulnerable to attacks when used in a real setting,\nagainst realistic attackers. Let’s see two examples.\nTiming Attacks on MAC Verification\nSide-channel attacks target the implementation of a cryptographic\nalgorithm rather than the algorithm itself. In particular, timing attacks use\nan algorithm’s execution time to determine secret information, such as\nkeys, plaintext, and secret random values. As you might imagine, variable-\ntime string comparison induces vulnerabilities not only in MAC\nverification, but also in many other cryptographic and security\nfunctionalities.\nMACs can be vulnerable to timing attacks when a remote system\nverifies tags in a period of time that depends on the tag’s value, thereby\nallowing an attacker to determine the correct message tag by trying many\nincorrect ones to determine the one that takes the longest amount of time\nto complete. The problem occurs when a server compares the correct tag\nwith an incorrect one by comparing the two strings byte per byte, in\norder, until the bytes differ. For example, the Python code in Listing 7-1\ncompares two strings byte per byte, in variable time: if the first bytes\ndiffer, the function will return after only one comparison; if the strings x\nand y are identical, the function will make n comparisons against the\nlength of the strings.\ndef compare_mac(x, y, n):\nfor i in range(n):\nif x[i] != y[i]:\nreturn False\nreturn True\nListing 7-1: Comparison of two n-byte strings, taking variable time\nTo demonstrate the vulnerability of the verify_mac() function, let’s\nwrite a program that measures the execution time of 100000 calls to\nverify_mac(), first with identical 10-byte x and y values and then with x\nand y values that differ in their third byte. We should expect the latter\ncomparison to take noticeably less time than the former because\nverify_mac() will compare fewer bytes than the identical x and y would, as\nshown in Listing 7-2.\nfrom time import time\nMAC1 = '0123456789abcdef'\nMAC2 = '01X3456789abcdef'\nTRIALS = 100000\n# each call to verify_mac() will look at all eight bytes\nstart = time()\nfor i in range(TRIALS):\ncompare_mac(MAC1, MAC1, len(MAC1))\nend = time()\nprint('%0.5f' % (end-start))\n# each call to verify_mac() will look at three bytes\nstart = time()\nfor i in range(TRIALS):\ncompare_mac(MAC1, MAC2, len(MAC1))\nend = time()\nprint('%0.5f' % (end-start))\nListing 7-2: Measuring timing differences when executing compare_mac() from\nListing 7-1\nIn my test environment, typical execution of the program in Listing 7-\n2 prints execution times of around 0.215 and 0.095 seconds, respectively.\nThat difference is significant enough for you to identify what’s happening\nwithin the algorithm. Now move the difference to other offsets in the\nstring, and you’ll observe different execution times for different offsets. If\nMAC1 is the correct MAC tag and MAC2 is the one tried by the attacker, you\ncan easily identify the position of the first difference, which is the number\nof correctly guessed bytes.\nOf course, if execution time doesn’t depend on a secret timing, timing\nattacks won’t work, which is why implementers strive to write constant-\ntime implementations—that is, code that takes exactly the same time to\ncomplete for any secret input value. For example, the C function in\nListing 7-3 compares two buffers of size bytes in constant time: the\ntemporary variable result will be nonzero if and only if there’s a\ndifference somewhere in the two buffers.\nint cmp_const(const void *a, const void *b, const size_t size)\n{\nconst unsigned char *_a = (const unsigned char *) a;\nconst unsigned char *_b = (const unsigned char *) b;\nunsigned char result = 0;\nsize_t i;\nfor (i = 0; i < size; i++) {\nresult |= _a[i] ^ _b[i];\n}\nreturn result; /* returns 0 if *a and *b are equal, nonzero otherwise\n*/\n}\nListing 7-3: Constant-time comparison of two buffers, for safer MAC verification\nWhen Sponges Leak\nPermutation-based algorithms like SHA-3 and SipHash are simple, easy\nto implement, and come with compact implementations, but they’re\nfragile in the face of side-channel attacks that recover a snapshot of the\nsystem’s state. For example, if a process can read the RAM and registers’\nvalues at any time, or read a core dump of the memory, an attacker can\ndetermine the internal state of SHA-3 in MAC mode, or the internal\nstate of SipHash, and then compute the reverse of the permutation to\nrecover the initial secret state. They can then forge tags for any message,\nbreaking the MAC’s security.\nFortunately, this attack will not work against compression function–\nbased MACs such as HMAC-SHA-256 and keyed BLAKE2 because the\nattacker would need a snapshot of memory at the exact time when the key\nis used. The upshot is that if you’re in an environment where parts of a\nprocess’s memory may leak, you can use a MAC based on a noninvertible\ntransform compression function rather than a permutation.\nFurther Reading\nThe venerable HMAC deserves more attention than I have space for\nhere, and even more for the train of thought that led to its wide adoption,\nand eventually to its demise when combined with a weak hash function. I\nrecommend the 1996 paper “Keying Hash Functions for Message\nAuthentication” by Bellare, Canetti, and Krawczyk, which introduced\nHMAC and its cousin NMAC, and the 2006 follow-up paper by Bellare\ncalled “New Proofs for NMAC and HMAC: Security Without Collision-\nResistance,” which proves that HMAC doesn’t need a collision-resistant\nhash, but only a hash with a compression function that is a PRF. On the\noffensive side, the 2007 paper “Full Key-Recovery Attacks on\nHMAC/NMAC-MD4 and NMAC-MD5” by Fouque, Leurent, and\nNguyen shows how to attack HMAC and NMAC when they’re built on\ntop of a brittle hash function such as MD4 or MD5. (By the way,\nHMAC-MD5 and HMAC-SHA-1 aren’t totally broken, but the risk is\nhigh enough.)\nThe Wegman–Carter MACs are also worth more attention, both for\ntheir practical interest and underlying theory. The seminal papers by\nWegman and Carter are available at http://cr.yp.to/bib/entries.html. Other\nstate-of-the-art designs include UMAC and VMAC, which are among the\nfastest MACs on long messages.\nOne type of MAC not discussed in this chapter is Pelican, which uses\nthe AES block cipher reduced to four rounds (down from 10 in the full\nblock cipher) to authenticate chunks of messages within a simplistic\nconstruction, as described in https://eprint.iacr.org/2005/088/. Pelican is\nmore of a curiosity, though, and it’s rarely used in practice.\nLast but not least, if you’re interested in finding vulnerabilities in\ncryptographic software, look for uses of CBC-MAC, or for weaknesses\ncaused by HMAC handling keys of arbitrary sizes—taking Hash(K) as the\nkey rather than K if K is too long, thus making K and Hash(K) equivalent\nkeys. Or just look for systems than don’t use MAC when they should—a\nfrequent occurrence.\nIn Chapter 8, we’ll look at how to combine MACs with ciphers to\nprotect a message’s authenticity, integrity, and confidentiality. We’ll also\nlook at how to do it without MACs, thanks to authenticated ciphers,\nwhich are ciphers that combine the functionality of a basic cipher with\nthat of a MAC by returning a tag along with each ciphertext."
  },
  {
    "input": "What are the key differences between the three main authenticated encryption methods (encrypt-and-MAC, MAC-then-encrypt, and encrypt-then-MAC), and which one is considered the most secure?",
    "summary": "This chapter discusses authenticated encryption, which combines confidentiality and authenticity. It covers different methods like encrypt-and-MAC, MAC-then-encrypt, and encrypt-then-MAC, with encrypt-then-MAC being the most secure. It also introduces AES-GCM, a widely used authenticated cipher, and OCB, which is faster but less adopted due to licensing issues. Additionally, it explains permutation-based authenticated ciphers, which are secure and efficient but not parallelizable. The chapter highlights the importance of secure key management and the risks associated with nonce reuse, emphasizing the need for careful design to ensure the security of authenticated ciphers.",
    "output": "8\nAUTHENTICATED ENCRYPTION\nThis chapter is about a type of algorithm that protects not only a\nmessage’s confidentiality but also its authenticity. Recall from Chapter 7\nthat message authentication codes (MACs) are algorithms that protect a\nmessage’s authenticity by creating a tag, which is a kind of signature. Like\nMACs, the authenticated encryption (AE) algorithms we’ll discuss in this\nchapter produce an authentication tag, but they also encrypt the message.\nIn other words, a single AE algorithm offers the features of both a normal\ncipher and a MAC.\nCombining a cipher and a MAC can achieve varying levels of\nauthenticated encryption, as you’ll learn throughout this chapter. I’ll\nreview several possible ways to combine MACs with ciphers, explain\nwhich methods are the most secure, and introduce you to ciphers that\nproduce both a ciphertext and an authentication tag. We’ll then look at\nfour important authenticated ciphers: three block cipher–based\nconstructions, with a focus on the popular Advanced Encryption Standard\nin Galois Counter Mode (AES-GCM), and a cipher that uses only a\npermutation algorithm.\nAuthenticated Encryption Using MACs\nAs shown in Figure 8-1, MACs and ciphers can be combined in one of\nthree ways to both encrypt and authenticate a plaintext: encrypt-and-\nMAC, MAC-then-encrypt, and encrypt-then-MAC.\nFigure 8-1: Cipher and MAC combinations\nThe three combinations differ in the order in which encryption is\napplied and the authentication tag is generated. However, the choice of a\nspecific MAC or cipher algorithm is unimportant as long as each is secure\nin its own right, and the MAC and cipher use distinct keys.\nAs you can see in Figure 8-1, in the encrypt-and-MAC composition,\nthe plaintext is encrypted and an authentication tag is generated from the\nplaintext directly, such that the two operations (encryption and\nauthentication) are independent of each other and can therefore be\ncomputed in parallel. In the MAC-then-encrypt scheme, the tag is\ngenerated from the plaintext first, and then the plaintext and MAC are\nencrypted together. In contrast, in the case of the encrypt-then-MAC\nmethod, the plaintext is encrypted first, and then the tag is generated\nfrom the ciphertext.\nAll three approaches are about equally resource intensive. Let’s see\nwhich method is likely to be the most secure.\nEncrypt-and-MAC\nThe encrypt-and-MAC approach computes a ciphertext and a MAC tag\nseparately. Given a plaintext (P), the sender computes a ciphertext C =\nE(K , P), where E is an encryption algorithm and C is the resulting\n1\nciphertext. The authentication tag (T) is calculated from the plaintext as\nT = MAC(K , P). You can compute C and T first or in parallel.\n2\nOnce the ciphertext and authentication tag have been generated, the\nsender transmits both to the intended recipient. When the recipient\nreceives C and T, they decrypt C to obtain the plaintext P by computing P\n= D(K , C). Next, they compute MAC(K , P) using the decrypted\n1 2\nplaintext and compare the result to the T received. This verification will\nfail if either C or T was corrupted, and the message will be deemed\ninvalid.\nAt least in theory, encrypt-and-MAC is the least secure MAC and\ncipher composition because even a secure MAC could leak information\non P, which would make P easier to recover. Because the goal of using\nMACs is simply to make tags unforgeable, and because tags aren’t\nnecessarily random looking, the authentication tag (T) of a plaintext (P)\ncould still leak information even though the MAC is considered secure!\n(Of course, if the MAC is a pseudorandom function, the tag won’t leak\nanything on P.)\nStill, despite its relative weakness, encrypt-and-MAC continues to be\nsupported by many systems, including the secure transport layer protocol\nSSH, wherein each encrypted packet C is followed by the tag T =\nMAC(K, N || P) sent in the unencrypted plaintext packet P. N in this\nequation is a 32-bit sequence number that is incremented for each sent\npacket, in order to help ensure that the received packets are processed in\nthe right order. In practice, encrypt-and-MAC has proven good enough\nfor use with SSH, thanks to the use of strong MAC algorithms like\nHMAC-SHA-256 that don’t leak information on P.\nMAC-then-Encrypt\nThe MAC-then-encrypt composition protects a message, P, by first\ncomputing the authentication tag T = MAC(K , P). Next, it creates the\n2\nciphertext by encrypting the plaintext and tag together, according to C =\nE(K , P || T).\n1\nOnce these steps have been completed, the sender transmits only C,\nwhich contains both the encrypted plaintext and tag. Upon receipt, the\nrecipient decrypts C by computing P || T = D(K , C) to obtain the\n1\nplaintext and tag T. Next, the recipient verifies the received tag T by\ncomputing a tag directly from the plaintext according to MAC(K , P) in\n2\norder to confirm that the computed tag is equal to the tag T.\nAs with encrypt-and-MAC, when MAC-then-encrypt is used, the\nrecipient must decrypt C before they can determine whether they are\nreceiving corrupted packets—a process that exposes potentially corrupted\nplaintexts to the receiver. Nevertheless, MAC-then-encrypt is more\nsecure than encrypt-and-MAC because it hides the plaintext’s\nauthentication tag, thus preventing the tag from leaking information on\nthe plaintext.\nMAC-then-encrypt has been used in the TLS protocol for years, but\nTLS 1.3 replaced MAC-then-encrypt with authenticated ciphers (see\nChapter 13 for more on TLS 1.3).\nEncrypt-then-MAC\nThe encrypt-then-MAC composition sends two values to the recipient:\nthe ciphertext produced by C = E(K , P) and a tag based on the ciphertext,\n1\nT = MAC(K , C). The receiver computes the tag using MAC(K , C) and\n2 2\nverifies that it equals the T received. If the values are equal, the plaintext\nis computed as P = D(K , C); if they are not equal, the plaintext is\n1\ndiscarded.\nOne advantage with this method is that the receiver only needs to\ncompute a MAC in order to detect corrupt messages, meaning that there\nis no need to decrypt a corrupt ciphertext. Another advantage is that\nattackers can’t send pairs of C and T to the receiver to decrypt unless they\nhave broken the MAC, which makes it harder for attackers to transmit\nmalicious data to the recipient.\nThis combination of features makes encrypt-then-MAC stronger than\nthe encrypt-and-MAC and MAC-then-encrypt approaches. This is one\nreason why the widely used IPSec secure communications protocol suite\nuses it to protect packets (for example, within VPN tunnels).\nBut then why don’t SSH and TLS use encrypt-then-MAC? The simple\nanswer is that when SSH and TLS were created, other approaches\nappeared adequate—not because theoretical weaknesses didn’t exist but\nbecause theoretical weaknesses don’t necessarily become actual\nvulnerabilities.\nAuthenticated Ciphers\nAuthenticated ciphers are an alternative to the cipher and MAC\ncombinations. They are like normal ciphers except that they return an\nauthentication tag together with the ciphertext.\nThe authenticated cipher encryption is represented as AE(K, P) = (C,\nT). The term AE stands for authenticated encryption, which as you can see\nfrom this equation is based on a key (K) and a plaintext (P) and returns a\nciphertext (C) and a generated authentication tag pair (T). In other words,\na single authenticated cipher algorithm does the same job as a cipher and\nMAC combination, making it simpler, faster, and often more secure.\nAuthenticated cipher decryption is represented by AD(K, C, T) = P.\nHere, AD stands for authenticated decryption, which returns a plainte (P)\ngiven a ciphertext (C), tag (T), and key (K). If either or both C and T are\ninvalid, AD will return an error to prevent the recipient from processing\na plaintext that may have been forged. By the same token, if AD returns a\nplaintext, you can be sure that it has been encrypted by someone or\nsomething that knows the secret key.\nThe basic security requirements of an authenticated cipher are simple:\nits authentication should be as strong as a MAC’s, meaning that it should\nbe impossible to forge a ciphertext and tag pair (C, T) that the decryption\nfunction AD will accept and decrypt.\nAs far as confidentiality is concerned, an authenticated cipher is\nfundamentally stronger than a basic cipher because systems holding the\nsecret key will only decrypt a ciphertext if the authentication tag is valid.\nIf the tag is invalid, the plaintext will be discarded. This characteristic\nprevents attackers from performing chosen-ciphertext queries, an attack\nwhere they create ciphertexts and ask for the corresponding plaintext.\nAuthenticated Encryption with Associated Data\nCryptographers define associated data as any data processed by an\nauthenticated cipher such that the data is authenticated (thanks to the\nauthentication tag) but not encrypted. Indeed, by default, all plaintext\ndata fed to an authenticated cipher is encrypted and authenticated.\nBut what if you simply want to authenticate all of a message, including\nits unencrypted parts, but not encrypt the entire message? That is, you\nwant to authenticate and transmit data in addition to an encrypted\nmessage. For example, if a cipher processes a network packet composed\nof a header followed by a payload, you might choose to encrypt the\npayload to hide the actual data transmitted, but not encrypt the header\nsince it contains information required to deliver the packet to its final\nrecipient. At the same time, you might still like to authenticate the\nheader’s data to make sure that it is received from the expected sender.\nIn order to accomplish these goals, cryptographers have created the\nnotion of authenticated encryption with associated data (AEAD). An\nAEAD algorithm allows you to attach cleartext data to a ciphertext in\nsuch a way that if the cleartext data is corrupted, the authentication tag\nwill not validate and the ciphertext will not be decrypted.\nWe can write an AEAD operation as AEAD(K, P, A) = (C, A, T). Given\na key (K), plaintext (P), and associated data (A), AEAD returns the\nciphertext, the unencrypted associated data A, and an authentication tag.\nAEAD leaves the unencrypted associated data unchanged, and the\nciphertext is the encryption of plaintext. The authentication tag depends\non both P and A, and will only be verified as valid if neither C nor A has\nbeen modified.\nBecause the authenticated tag depends on A, decryption with associated\ndata is computed by ADAD(K, C, A, T) = (P, A). Decryption requires the\nkey, ciphertext, associated data, and tag in order to compute the plaintext\nand associated data, and it will fail if either C or A has been corrupted.\nOne thing to note when using AEAD is that you can leave A or P\nempty. If the associated data A is empty, AEAD becomes a normal\nauthenticated cipher; if P is empty, it’s just a MAC.\nNOTE\nAs of this writing, AEAD is the current norm for authenticated encryption.\nBecause nearly all authenticated ciphers in use today support associated data,\nwhen referring to authenticated ciphers throughout this book, I am referring\nto AEAD unless stated otherwise. When discussing AEAD operations of\nencryption and decryption, I’ll refer to them as AE and AD, respectively.\nAvoiding Predictability with Nonces\nRecall from Chapter 1 that in order to be secure, encryption schemes\nmust be unpredictable and return different ciphertexts when called\nrepeatedly to encrypt the same plaintext—otherwise, an attacker can\ndetermine whether the same plaintext was encrypted twice. In order to be\nunpredictable, block ciphers and stream ciphers feed the cipher an extra\nparameter: the initial value (IV) or nonce—a number that can be used\nonly once. Authenticated ciphers use the same trick. Thus, authenticated\nencryption can be expressed as AE(K, P, A, N), where N is a nonce. It’s up\nto the encryption operation to pick a nonce that has never been used\nbefore with the same key.\nAs with block and stream ciphers, decryption with an authenticated\ncipher requires the nonce used for encryption in order to perform\ncorrectly. We can thus express decryption as AD(K, C, A, T, N) = (P, A),\nwhere N is the nonce used to create C and T.\nWhat Makes a Good Authenticated Cipher?\nResearchers have been struggling since the early 2000s to define what\nmakes a good authenticated cipher, and as I write this, the answer is still\nelusive. Because of AEAD’s many inputs that play different roles, it’s\nharder to define a notion of security than it is for basic ciphers that only\nencrypt a message. Nevertheless, in this section, I’ll summarize the most\nimportant criteria to consider when evaluating the security, performance,\nand functionality of an authenticated cipher.\nSecurity Criteria\nThe most important criteria used to measure the strength of an\nauthenticated cipher are its ability to protect the confidentiality of data\n(that is, the secrecy of the plaintext) and the authenticity and integrity of\nthe communication (as with the MAC’s ability to detect corrupted\nmessages). An authenticated cipher must compete in both leagues: its\nconfidentiality must be as strong as that of the strongest cipher, and its\nauthenticity as strong as that of the best MAC. In other words, if you\nremove the authentication part in an AEAD, you should get a secure\ncipher, and if you remove the encryption part, you should get a strong\nMAC.\nAnother measure of the strength of an authenticated cipher’s security is\nbased on something a bit more subtle—namely, its fragility when faced\nwith repeated nonces. For example, if a nonce is reused, can an attacker\ndecrypt ciphertexts or learn the difference between plaintexts?\nResearchers call this notion of robustness misuse resistance, and have\ndesigned misuse-resistant authenticated ciphers to weigh the impact of a\nrepeated nonce and attempt to determine whether confidentiality,\nauthenticity, or both would be compromised in the face of such an attack,\nas well as what information about the encrypted data would likely be\nleaked.\nPerformance Criteria\nAs with every cryptographic algorithm, the throughput of an\nauthenticated cipher can be measured in bits processed per second. This\nspeed depends on the number of operations performed by the cipher’s\nalgorithm and on the extra cost of the authentication functionality. As\nyou might imagine, the extra security features of authenticated ciphers\ncome with a performance hit. However, the measure of a cipher’s\nperformance isn’t just about pure speed. It’s also about parallelizability,\nstructure, and whether the cipher is streamable. Let’s examine these\nnotions more closely.\nA cipher’s parallelizability is a measure of its ability to process multiple\ndata blocks simultaneously without waiting for the previous block’s\nprocessing to complete. Block cipher–based designs can be easily\nparallelizable when each block can be processed independently of the\nother blocks. For example, the CTR block cipher mode discussed in\nChapter 4 is parallelizable, whereas the CBC encryption mode is not,\nbecause blocks are chained.\nThe internal structure of an authenticated cipher is another important\nperformance criteria. There are two main types of structure: one-layer\nand two-layer. In a two-layer structure (for example, in the widely used\nAES-GCM), one algorithm processes the plaintext and then a second\nalgorithm processes the result. Typically, the first layer is the encryption\nlayer and the second is the authentication layer. But as you might expect,\na two-layer structure complicates implementation and tends to slow down\ncomputations.\nAn authenticated cipher is streamable (also called an online cipher) when\nit can process a message block-by-block and discard any already-\nprocessed blocks. In contrast, nonstreamable ciphers must store the entire\nmessage, typically because they need to make two consecutive passes over\nthe data: one from the start to the end, and the other from the end to the\nstart of the data obtained from the first pass.\nDue to potentially high memory requirements, some applications won’t\nwork with nonstreamable ciphers. For example, a router could receive an\nencrypted block of data, decrypt it, and then return the plaintext block\nbefore moving on to decrypt the subsequent block of the message, though\nthe recipient of the decrypted message would still have to verify the\nauthentication tag sent at the end of the decrypted data stream.\nFunctional Criteria\nFunctional criteria are the features of a cipher or its implementation that\ndon’t directly relate to either security or performance. For example, some\nauthenticated ciphers only allow associated data to precede the data to be\nencrypted (because they need access to it in order to start encryption).\nOthers require associated data to follow the data to be encrypted or\nsupport the inclusion of associated data anywhere—even between chunks\nof plaintext. This last case is the best, because it enables users to protect\ntheir data in any possible situation, but it’s also the hardest to design\nsecurely: as always, more features often bring more complexity—and\nmore potential vulnerabilities.\nAnother piece of functional criteria to consider relates to whether you\ncan use the same core algorithm for both encryption and decryption. For\nexample, many authenticated ciphers are based on the AES block cipher,\nwhich specifies the use of two similar algorithms for encrypting and\ndecrypting a block. As discussed in Chapter 4, the CBC block cipher\nmode requires both algorithms, but the CTR mode requires only the\nencryption algorithm. Likewise, authenticated ciphers may not need both\nalgorithms. Although the extra cost of implementing both encryption and\ndecryption algorithms won’t impact most software, it’s often noticeable\non low-cost dedicated hardware, where implementation cost is measured\nin terms of logic gates, or the silicon area occupied by the cryptography.\nAES-GCM: The Authenticated Cipher Standard\nAES-GCM is the most widely used authenticated cipher. AES-GCM is,\nof course, based on the AES algorithm, and the Galois counter mode\n(GCM) of operation is essentially a tweak of the CTR mode that\nincorporates a small and efficient component to compute an\nauthentication tag. As I write this, AES-GCM is the only authenticated\ncipher that is a NIST standard (SP 800-38D). AES-GCM is also part of\nNSA’s Suite B and of the Internet Engineering Task Force (IETF) for\nthe secure network protocols IPSec, SSH, and TLS 1.2.\nNOTE\nAlthough GCM works with any block cipher, you’ll probably only see it used\nwith AES. Some people don’t want to use AES because it’s American, but\nthey won’t use GCM either, for the same reason. Therefore, GCM is rarely\npaired with other ciphers.\nGCM Internals: CTR and GHASH\nFigure 8-2: The AES-GCM mode, applied to one associated data block, A , and two\n1\nplaintext blocks, P and P . The circled multiplication sign represents polynomial\n1 2\nmultiplication by H, the authentication key derived from K.\nFigure 8-2 shows how AES-GCM works: AES instances parameterized\nby a secret key (K) transform a block composed of the nonce (N)\nconcatenated with a counter (starting here at 1, then incremented to 2, 3,\nand so on) and then XOR the result with a plaintext block to obtain a\nciphertext block. So far, that’s nothing new compared to the CTR mode.\nNext, the ciphertext blocks are mixed using a combination of XORs\nand multiplications (as you’ll see next). You can see AES-GCM as doing\n1) an encryption in CTR mode and 2) a MAC over the ciphertext blocks.\nTherefore, AES-GCM is essentially an encrypt-then-MAC construction,\nwhere AES-CTR encrypts using a 128-bit key (K) and a 96-bit nonce (N),\nwith the minor difference that the counter starts from 1, not 0, as in\nnormal CTR mode (which doesn’t matter, as far as security is concerned).\nTo authenticate the ciphertext, GCM uses a Wegman–Carter MAC\n(see Chapter 7) to authenticate the ciphertext, which XORs the value\nAES(K, N || 0) with the output of a universal hash function called\nGHASH. In Figure 8-2, GHASH corresponds to the series of operations\n“⊗ ” followed by the XOR with len(A) || len(C), or the bit length of A\nH\n(the associated data) followed by the bit length of C (the ciphertext).\nWe can thus express the authentication tag’s value as T = GHASH(H,\nC) ⊕ AES(K, N || 0), where C is the ciphertext and H is the hash key, or\nauthentication key. This key is determined as H = AES(K, 0), which is the\nencryption of the block equal to a sequence of null bytes (this step does\nnot appear in Figure 8-2, for clarity).\nNOTE\nIn GCM, GHASH doesn’t use K directly in order to ensure that if\nGHASH’s key is compromised, the master key K remains secret. Given K,\nyou can get H by computing AES(K, 0), but you can’t recover K from that\nvalue since K acts here as AES’s key.\nAs Figure 8-2 shows, GHASH uses polynomial notation to multiply each\nciphertext block with the authentication key H. This use of polynomial\nmultiplication makes GHASH fast in hardware as well as in software,\nthanks to a special polynomial multiplication instruction available in\nmany common microprocessors (CLMUL, for carry-less multiplication).\nAlas, GHASH is far from ideal. For one thing, its speed is suboptimal.\nEven when the CLMUL instruction is used, the AES-CTR layer that\nencrypts the plaintext remains faster than the GHASH MAC. Second,\nGHASH is painful to implement correctly. In fact, even the experienced\ndevelopers of the OpenSSL project, by far the most-used cryptographic\npiece of software in the world, got AES-GCM’s GHASH wrong. One\ncommit had a bug in a function called gcm_ghash_clmul that allowed\nattackers to forge valid MACs for the AES-GCM. (Fortunately, the error\nwas spotted by Intel engineers before the bug entered the next OpenSSL\nrelease.)\nPOLYNOMIAL MULTIPLICATION\nWhile clearly more complicated for us than classic\ninteger arithmetic, polynomial multiplication is\nsimpler for computers because there are no carries.\nFor example, say we want to compute the product of\n2 3\nthe polynomials (1 + X + X ) and (X + X ). We first\n2\nmultiply the two polynomials (1 + X + X ) and (X +\n3\nX ) as though we were doing normal polynomial\nmultiplication, thus giving us the following (the two\n3\nterms X cancel each other out):\n(1 + X + X2) ⊕ (X + X3) = X + X3 + X2 + X4 + X3 + X5 = X + X2 + X4 +\nX5\n2\nWe now apply modulo reduction, reducing X + X\n4 5 3 4 2\n+ X + X modulo 1 + X +X to give us X , because\n2 4 5 2 4 5\nX + X + X + X can be written as X + X + X + X\n= X ⊗ (1 + X 3 + X 4 ) + X 2 . In more general terms, A +\nBC modulo B is equal to A, by definition of modular\nreduction.\nGCM Security\nAES-GCM’s biggest weakness is its fragility in the face of nonce\nrepetition. If the same nonce N is used twice in an AES-GCM\nimplementation, an attacker can get the authentication key H and use it\nto forge tags for any ciphertext, associated data, or combination thereof.\nA look at the basic algebra behind AES-GCM’s computations (as\nshown in Figure 8-2) will help make this fragility clear. Specifically, a tag\n(T) is computed as T = GHASH(H, A, C) ⊕ AES(K, N || 0), where\nGHASH is a universal hash function with linearly related inputs and\noutputs.\nNow what happens if you get two tags, T and T , computed with the\n1 2\nsame nonce N ? Right, the AES part will vanish. If we have two tags, T =\n1\nGHASH(H, A , C ) ⊕ AES(K, N || 0) and T = GHASH(H, A , C ) ⊕\n1 1 2 1 1\nAES(K, N || 0), then XORing them together gives the following:\nIf the same nonce is used twice, an attacker can thus recover the value\nGHASH(H, A , C ) ⊕ GHASH(H, A , C ) for some known A , C , A ,\n1 1 2 2 1 1 2\nand C . The linearity of GHASH then allows an attacker to easily\n2\ndetermine H. (It would have been worse if GHASH had used the same\nkey K as the encryption part, but because H = AES(K, 0), there’s no way\nto find K from H.)\nAs recently as 2016, researchers scanned the internet for instances of\nAES-GCM exposed through HTTPS servers, in search of systems with\nrepeating nonces (see https://eprint.iacr.org/2016/475/). They found 184\nservers with repeating nonces, including 23 that always used the all-zero\nstring as a nonce.\nGCM Efficiency\nOne advantage of GCM mode is that both GCM encryption and\ndecryption are parallelizable, allowing you to encrypt or decrypt different\nplaintext blocks independently. However, the AES-GCM MAC\ncomputation isn’t parallelizable, because it must be computed from the\nbeginning to the end of the ciphertext once GHASH has processed any\nassociated data. This lack of parallelizability means that any system that\nreceives the plaintext first and then the associated data will have to wait\nuntil all associated data is read and hashed before hashing the first\nciphertext block.\nNevertheless, GCM is streamable: since the computations in its two\nlayers can be pipelined, there’s no need to store all ciphertext blocks\nbefore computing GHASH because GHASH will process each block as\nit’s encrypted. In other words, P is encrypted to C , then GHASH\n1 1\nprocesses C while P is encrypted to C , then P and C are no longer\n1 2 2 1 1\nneeded, and so on.\nOCB: An Authenticated Cipher Faster than GCM\nThe acronym OCB stands for offset codebook (though its designer, Phil\nRogaway, prefers to simply call it OCB). First developed in 2001, OCB\npredates GCM, and like GCM it produces an authenticated cipher from a\nblock cipher, though it does so faster and more simply. Then why hasn’t\nOCB seen wider adoption? Unfortunately, until 2013, all uses of OCB\nrequired a license from the inventor. Fortunately, as I write this, Rogaway\ngrants free licenses for nonmilitary software implementations (see\nhttp://web.cs.ucdavis.edu/~rogaway/ocb/license.htm). Therefore, although\nOCB is not yet a formal standard, perhaps we will begin to see wider\nadoption.\nUnlike GCM, OCB blends encryption and authentication into one\nprocessing layer that uses only one key. There’s no separate\nauthentication component, so OCB gets you authentication mostly for\nfree and performs almost as many block cipher calls as a non-\nauthenticated cipher. Actually, OCB is almost as simple as the ECB mode\n(see Chapter 4), except that it’s secure.\nOCB Internals\nFigure 8-3 shows how OCB works: OCB encrypts each plaintext block P\nto a ciphertext block C = E(K, P ⊕ O) ⊕ O, where E is a block cipher\nencryption function. Here, O (called the offset) is a value that depends on\nthe key and the nonce incremented for each new block processed.\nTo produce the authentication tag, OCB first XORs the plaintext\nblocks together to compute S = P ⊕ P ⊕ P ⊕ . . . (that is, the XOR of all\n1 2 3\nplaintext blocks). The authentication tag is then T = E(K, S ⊕ O*), where\nO* is an offset value computed from the offset of the last plaintext block\nprocessed.\nFigure 8-3: The OCB encryption process when run on two plaintext blocks, with no\nassociated data\nLike AES-GCM, OCB also supports associated data as a series of\nblocks, A , A , and so on. When an OCB encrypted message contains\n1 2\nassociated data, the authentication tag is calculated according to the\nformula\nT = E(K, S ⊕ O*) ⊕ E(K, A ⊕ O ) ⊕ E(K, A ⊕ O ) ⊕ ...\n1 1 2 2\nwhere OCB specifies offset values that are different from those used to\nencrypt P.\nUnlike GCM and encrypt-then-MAC, which create an authentication\ntag by combining ciphertext, OCB calculates the authentication tag by\ncombining plaintext data. There’s nothing wrong with this approach, and\nOCB is backed by solid security proofs.\nNOTE\nFor more on how to implement OCB correctly, see either RFC 7253 or the\n2011 paper “The Software Performance of Authenticated-Encryption\nModes” by Krovetz and Rogaway, which covers the latest and best version of\nOCB, OCB3. For further details on OCB, see the OCB FAQ at\nhttp://web.cs.ucdavis.edu/~rogaway/ocb/ocb-faq.htm.\nOCB Security\nOCB is a bit less fragile than GCM against repeated nonces. For example,\nif a nonce is used twice, an attacker that sees the two ciphertexts will\nnotice that, say, the third plaintext block of the first message is identical\nto the third plaintext block of the second message. With GCM, attackers\ncan find not only duplicates but also XOR differences between blocks at\nthe same position. The impact of repeated nonces is therefore worse with\nGCM than it is with OCB.\nAs with GCM, repeated nonces can break the authenticity of OCB,\nthough less effectively. For example, an attacker could combine blocks\nfrom two messages authenticated with OCB to create another encrypted\nmessage with the same checksum and tag as one of the original two\nmessages, but the attacker would not be able to recover a secret key as\nwith GCM.\nOCB Efficiency\nOCB and GCM are about equally fast. Like GCM, OCB is parallelizable\nand streamable. In terms of raw efficiency, GCM and OCB will make\nabout as many calls to the underlying block cipher (usually AES), but\nOCB is slightly more efficient than GCM because it simply XORs the\nplaintext rather than performing something like the relatively expensive\nGHASH computation. (In earlier generations of Intel microprocessors,\nAES-GCM used to be more than three times slower than AES-OCB\nbecause AES and GHASH instructions had to compete for CPU\nresources and couldn’t be run in parallel.)\nOne important difference between OCB and GCM implementations is\nthat OCB needs both the block cipher’s encryption and decryption\nfunctions in order to encrypt and decrypt, which increases the cost of\nhardware implementations when only limited silicon is available for\ncrypto components. In contrast, GCM uses only the encryption function\nfor both encryption and decryption.\nSIV: The Safest Authenticated Cipher?\nSynthetic IV, also known as SIV, is an authenticated cipher mode typically\nused with AES. Unlike GCM and OCB, SIV is secure even if you use the\nsame nonce twice: if an attacker gets two ciphertexts encrypted using the\nsame nonce, they’ll only be able to learn whether the same plaintext was\nencrypted twice. Unlike with messages encrypted with GCM or OCB,\nthe attacker would be unable to tell whether the first block of the two\nmessages is the same because the nonce used to encrypt is first computed\nas a combination of the given nonce and the plaintext.\nThe SIV construction specification is more general than that of GCM.\nInstead of specifying detailed internals as with GCM’s GHASH, SIV\nsimply tells you how to combine a cipher (E) and a pseudorandom\nfunction (PRF) to get an authenticated cipher. Specifically, you compute\nthe tag T = PRF(K , N || P) and then compute the ciphertext C = E(K ,\n1 2\nT, P), where T acts as the nonce of E. Thus, SIV needs two keys (K and\n1\nK ) and a nonce (N).\n2\nThe major problem with SIV is that it’s not streamable: after\ncomputing T, it must keep the entire plaintext P in memory. In other\nwords, in order to encrypt a 100GB plaintext with SIV, you must first\nstore the 100GB of plaintext so that SIV encryption can read it.\nThe document RFC 5297, based on the 2006 paper “Deterministic\nAuthenticated-Encryption” by Rogaway and Shrimpton, specifies SIV as\nusing CMAC-AES (a MAC construction using AES) as a PRF and AES-\nCTR as a cipher. In 2015, a more efficient version of SIV was proposed,\ncalled GCM-SIV, that combines GCM’s fast GHASH function and SIV’s\nmode and is nearly as fast as GCM. Like the original SIV, however,\nGCM-SIV isn’t streamable. (For more information, see\nhttps://eprint.iacr.org/2015/102/.)\nPermutation-Based AEAD\nNow for a totally different approach to building an authenticated cipher:\ninstead of building a mode of operation around a block cipher like AES,\nwe’ll look at a cipher that builds a mode around a permutation. A\npermutation simply transforms an input to an output of the same size,\nreversibly, without using a key, that’s the simplest component imaginable.\nBetter still, the resulting AEAD is fast, provably secure, and more\nresistant to nonce reuse than GCM and OCB.\nFigure 8-4 shows how a permutation-based AEAD works: from some\nfixed initial state H , you XOR the key K followed by the nonce N to the\n0\ninternal state, to obtain a new value of the internal state that is the same\nsize as the original. You then transform the new state with P and get\nanother new value of the state. Now you XOR the first plaintext block P\n1\nto the current state and take the resulting value as the first ciphertext\nblock C , where P and C are equal in size but smaller than the state.\n1 1 1\nTo encrypt a second block, you transform the state with P, XOR the\nnext plaintext block P to the current state, and take the resulting value as\n2\nC . You then iterate over all plaintext blocks and, following the last call to\n2\nP, take bits from the internal state as the authentication tag T, as shown\nat the right of Figure 8-4.\nFigure 8-4: Permutation-based authenticated cipher\nNOTE\nThe mode shown in Figure 8-4 can be adapted to support associated data, but\nthe process is a bit more complicated, so we’ll skip its description.\nDesigning permutation-based authenticated ciphers has certain\nrequirements in order to ensure security. For one thing, note that you\nonly XOR input values to a part of the state: the larger this part, the more\ncontrol a successful attacker has on the internal state, and thus the lower\nthe cipher’s security. Indeed, all security relies on the secrecy of the\ninternal state.\nAlso, blocks must be padded properly with extra bits, in a way that\nensures that any two different messages will yield different results. As a\ncounterexample, if the last plaintext block is shorter than a complete\nblock, it should not just be padded with zeroes; otherwise, a plaintext\nblock of, say, two bytes (0000) would result in a complete plaintext block\n(0000 . . . 0000), as would a block of three bytes (000000). As a result,\nyou’d get the same tag for both messages, although they differ in size.\nWhat if a nonce is reused in such a permutation-based cipher? The\ngood news is that the impact isn’t as bad as with GCM or OCB—the\nstrength of the authentication tag won’t be compromised. If a nonce is\nrepeated, a successful attacker would only be able to learn whether the\ntwo encrypted messages begin with the same value, as well as the length\nof this common value, or prefix. For example, although encrypting the\ntwo six-block messages ABCXYZ and ABCDYZ (each letter symbolizing a\nblock here) with the same nonce might yield the two ciphertexts JKLTUV\nand JKLMNO, which have identical prefixes, attackers would not be able\nto learn that the two plaintexts shared the same final two blocks (YZ).\nIn terms of performance, permutation-based ciphers offer the benefits\nof a single layer of operations, streamable processing, and the use of a\nsingle core algorithm for encryption and decryption. However, they are\nnot parallelizable like GCM or OCB because new calls to P need to wait\nfor the previous call to complete.\nNOTE\nIf you’re tempted to pick your favorite permutation and make up your own\nauthenticated cipher, don’t. You’re likely to get the details wrong and end up\nwith an insecure cipher. Read the specifications written by experienced\ncryptographers for algorithms such as Keyak (an algorithm derived from\nKeccak) and NORX (designed by Philipp Jovanovic, Samuel Neves, and\nmyself), and you’ll see that permutation-based ciphers are way more complex\nthan they may first appear.\nHow Things Can Go Wrong\nAuthenticated ciphers have a larger attack surface than hash functions or\nblock ciphers because they aim to achieve both confidentiality and\nauthenticity. They take several different input values, and must remain\nsecure regardless of the input—whether that contains only associated data\nand no encrypted data, extremely large plaintexts, or different key sizes.\nThey must also be secure for all nonce values against attackers who\ncollect numerous message/tag pairs and, to some extent, against\naccidental repetition of nonces.\nThat’s a lot to ask, and as you’ll see next, even AES-GCM has several\nimperfections.\nAES-GCM and Weak Hash Keys\nOne of AES-GCM’s weaknesses is found in its authentication algorithm\nGHASH: certain values of the hash key H greatly simplify attacks against\nGCM’s authentication mechanism. Specifically, if the value H belongs to\nsome specific, mathematically defined subgroups of all 128-bit strings,\nattackers might be able to guess a valid authentication tag for some\nmessage simply by shuffling the blocks of a previous message.\nIn order to understand this weakness, let’s look at how GHASH works.\nGHASH Internals\nAs you saw in Figure 8-2, GHASH starts with a 128-bit value, H, initially\nset to AES(K, 0), and then repeatedly computes\nX = (X ⊕ C ) ⊗ H\ni i − 1 i\nstarting from X = 0 and processing ciphertext blocks C , C , and so on.\n0 1 2\nThe final X is returned by GHASH to compute the final tag.\ni\nNow say for the sake of simplicity that all C values are equal to 1, so\ni\nthat for any i we have this:\nC ⊗ = 1 ⊗ H = H\ni\nNext, from the GHASH equation\nX = (X ⊕ C ) ⊗ H\ni i − 1 i\nwe derive\nX = (X ⊕ C ) ⊕ H = (0 ⊕ 1) ⊗ H = H\n1 0 1\nsubstituting X with 0 and C with 1, to yield the following:\n0 1\n(0 ⊕ 1) = 1\nThanks to the distributive property of ⊗ over ⊕, we substitute X with H\nand C with 1 and then compute the next value X as\n2 2\nX = (X ⊕ X ) ⊗ H = (H ⊕ 1) ⊗ H = H2 ⊕ H\n2 1 2\nwhere H2 is H squared, or H ⊗ H.\nNow we derive X by substituting X for its derivation, and obtain the\n3 2\nfollowing:\nX = (X ⊕ C ) ⊗ H = (H2 ⊕ H ⊕ 1) ⊗ H = H3 ⊕ H2 ⊕ H\n3 2 3\nNext, we derive X to be X = H 4 ⊕ H 3 ⊕ H 2 ⊕ H, and so on, and\n4 4\neventually the last X is this:\ni\nX = Hn ⊕ Hn − 1 ⊕ Hn − 2 ⊕ ... ⊕ H2 ⊕ H\nn\nRemember that we set all blocks C equal to 1. If instead those values\ni\nwere arbitrary values, we would end up with the following:\nX = C ⊕ Hn ⊕ C ⊕ Hn − 1 ⊕ C Hn − 2 ⊕ ... ⊕ C H2 ⊕ C ⊕ H\nn 1 2 3 n − 1 n\nGHASH then would XOR the message’s length to this last X ,\nn\nmultiply the result by H, and then XOR this value with AES(K, N || 0)\nto create the final authentication tag, T.\nWhere Things Break\nWhat can go wrong from here? Let’s look first at the two simplest cases:\nIf H = 0, then X = 0 regardless of the C values, and thus regardless\nn i\nof the message. That is, all messages will have the same\nauthentication tag if H is 0.\nIf H = 1, then the tag is just an XOR of the ciphertext blocks, and\nreordering the ciphertext blocks will give the same authentication\ntag.\nOf course, 0 and 1 are only two values of 2128 possible values of H, so\nthere is only a 2/2128 = 1/2127 chance of these occurring. But there are\nother weak values as well—namely, all values of H that belong to a short\ncycle when raised to ith powers. For example, the value H =\n10d04d25f93556e69f58ce2f8d035a4 belongs to a cycle of length five, as it\nsatisfies H 5 = H, and therefore He = H for any e that is a multiple of five\n(the very definition of cycle with respect to fifth powers). Consequently,\nin the preceding expression of the final GHASH value X , swapping the\nn\nblocks C (multiplied to H) and the block C (multiplied to H 5) will\nn n – 4\nleave the authentication tag unchanged, which amounts to a forgery. An\nattacker may exploit this property to construct a new message and its\nvalid tag without knowing the key, which should be impossible for a\nsecure authenticated cipher.\nThe preceding example is based on a cycle of length five, but there are\nmany cycles of greater length and therefore many values of H that are\nweaker than they should be. The upshot is that, in the unlikely case that\nH belongs to a short cycle of values and attackers can forge as many\nauthentication tags as they want, unless they know H or K, they cannot\ndetermine H’s cycle length. So although this vulnerability can’t be\nexploited, it could have been avoided by more carefully choosing the\npolynomial used for modulo reductions.\nNOTE\nFor further details on this attack, read “Cycling Attacks on GCM, GHASH\nand Other Polynomial MACs and Hashes” by Markku-Juhani O. Saarinen,\navailable at https://eprint.iacr.org/2011/202/.\nAES-GCM and Small Tags\nIn practice, AES-GCM usually returns 128-bit tags, but it can produce\ntags of any length. Unfortunately, when shorter tags are used, the\nprobability of forgery increases significantly.\nWhen a 128-bit tag is used, an attacker who attempts a forgery should\nsucceed with a probability of 1/2128 because there are 2128 possible 128-\nbit tags. (Generally, with an n-bit tag, the probability of success should be\n1/2n, where 2 is the number of possible values of an n-bit tag.) But when\nN\nshorter tags are used, the probability of forgery is much higher than 1/2n\ndue to weaknesses in the structure of GCM that are beyond the scope of\nthis discussion. For example, a 32-bit tag will allow an attacker who\nknows the authentication tag of some 2MB message to succeed with a\nchance of 1/216 instead of 1/232.\nGenerally, with n-bit tags, the probability of forgery isn’t 1/2n but\nrather 2m/2n, where 2m is the number of blocks of the longest message for\nwhich a successful attacker observed the tag. For example, if you use 48-\nbit tags and process messages of 4GB (or 228 blocks of 16 bytes each), the\nprobability of a forgery will be 228/248 = 1/220, or about one chance in a\nmillion. That’s a relatively high chance as far as cryptography is\nconcerned. (For more information on this attack, see the 2005 paper\n“Authentication Weaknesses in GCM” by Niels Ferguson.)\nFurther Reading\nTo learn more about authenticated ciphers, visit the home page of\nCAESAR, the Competition for Authenticated Encryption: Security,\nApplicability, and Robustness (http://competitions.cr.yp.to/caesar.html).\nBegun in 2012, CAESAR is a crypto competition in the style of the AES\nand SHA-3 competitions, though it isn’t organized by NIST.\nThe CAESAR competition has attracted an impressive number of\ninnovative designs: from OCB-like modes to permutation-based modes,\nas well as new core algorithms. Examples include the previously\nmentioned NORX and Keyak permutation-based authenticated ciphers;\nAEZ (as in AEasy), which is built on a nonstreamable two-layer mode\nthat makes it misuse resistant; AEGIS, a beautifully simple authenticated\ncipher that leverages AES’s round function.\nIn this chapter, I’ve focused on GCM, but a handful of other modes are\nused in real applications as well. Specifically, the counter with CBC-MAC\n(CCM) and EAX modes competed with GCM for standardization in the\nearly 2000s, and although GCM was selected, the two competitors are\nused in a few applications. For example, CCM is used in the WPA2 Wi-\nFi encryption protocol. You may want to read these ciphers’\nspecifications and review their relative security and performance merits.\nThis concludes our discussion of symmetric-key cryptography! You’ve\nseen block ciphers, stream ciphers, (keyed) hash functions, and now\nauthenticated ciphers—or all the main cryptography components that\nwork with a symmetric key, or no key at all. Before we move to\nasymmetric cryptography, Chapter 9 will focus more on computer science\nand math, to provide background for asymmetric schemes such as RSA\n(Chapter 10) and Diffie–Hellman (Chapter 11)."
  },
  {
    "input": "What are the computational problems that form the basis of cryptographic security and why are they considered hard?",
    "summary": "Hard computational problems are central to cryptography, as they are simple to describe but practically impossible to solve. These problems form the basis of public-key schemes like RSA and Diffie-Hellman, which rely on the difficulty of tasks such as factoring large numbers or solving discrete logarithms. While these problems are not NP-complete, they are considered computationally hard and are used to ensure cryptographic security. However, their actual difficulty depends on the size and structure of the input, and smaller or specially structured problems can be easily solved, making it crucial to choose appropriate parameters for secure encryption.",
    "output": "9\nHARD PROBLEMS\nHard computational problems are the cornerstone of modern\ncryptography. They’re problems that are simple to describe yet\npractically impossible to solve. These are problems for which even the\nbest algorithm wouldn’t find a solution before the sun burns out.\nIn the 1970s, the rigorous study of hard problems gave rise to a new\nfield of science called computational complexity theory, which would\ndramatically impact cryptography and many other fields, including\neconomics, physics, and biology. In this chapter, I’ll give you the\nconceptual tools from complexity theory necessary to understand the\nfoundations of cryptographic security, and I’ll introduce the hard\nproblems behind public-key schemes such as RSA encryption and Diffie–\nHellman key agreement. We’ll touch on some deep concepts, but I’ll\nminimize the technical details and only scratch the surface. Still, I hope\nyou’ll see the beauty in the way cryptography leverages computational\ncomplexity theory to maximize security.\nComputational Hardness\nA computational problem is a question that can be answered by doing\nenough computation, for example, “Is 2017 a prime number?” or “How\nmany i letters are there in incomprehensibilities?” Computational hardness is\nthe property of computational problems for which there is no algorithm\nthat will run in a reasonable amount of time. Such problems are also\ncalled intractable problems and are often practically impossible to solve.\nSurprisingly, computational hardness is independent of the type of\ncomputing device used, be it a general-purpose CPU, an integrated\ncircuit, or a mechanical Turing machine. Indeed, one of the first findings\nof computational complexity theory is that all computing models are\nequivalent. If a problem can be solved efficiently with one computing\ndevice, it can be solved efficiently on any other device by porting the\nalgorithm to the other device’s language—an exception is quantum\ncomputers, but these do not exist (yet). The upshot is that we won’t need\nto specify the underlying computing device or hardware when discussing\ncomputational hardness; instead, we’ll just discuss algorithms.\nTo evaluate hardness, we’ll first find a way to measure the complexity\nof an algorithm, or its running time. We’ll then categorize running times\nas hard or easy.\nMeasuring Running Time\nMost developers are familiar with computational complexity, or the\napproximate number of operations done by an algorithm as a function of\nits input size. The size is counted in bits or in the number of elements\ntaken as input. For example, take the algorithm shown in Listing 9-1,\nwritten in pseudocode. It searches for a value, x, within an array of n\nelements and then returns its index position.\nsearch(x, array, n):\nfor i from 1 to n {\nif (array[i] == x) {\nreturn i;\n}\n}\nreturn 0;\n}\nListing 9-1: A simple search algorithm, written in pseudocode, of complexity linear\nwith respect to the array length n. The algorithm returns the index where the value x\nis found in [1, n], or 0 if x isn’t found in the array.\nIn this algorithm, we use a for loop to find a specific value, x, by\niterating through an array. On each iteration, we assign the variable i a\nnumber starting with 1. Then we check whether the value of position i in\narray is equal to the value of x. If it is, we return the position i. Otherwise,\nwe increment i and try the next position until we reach n, the length of\nthe array, at which point we return 0.\nFor this kind of algorithm, we count complexity as the number of\niterations of the for loop: 1 in the best case (if x is equal to array[1]), n in\nthe worst case (if x is equal to array[n] or if x is not in found in array), and\nn/2 on average if x is randomly distributed in one of the n cells of the\narray. With an array 10 times as large, the algorithm will be 10 times as\nslow. Complexity is therefore proportional to n, or “linear” in n. A\ncomplexity linear in n is considered fast, as opposed to complexities\nexponential in n. Although processing larger input values will be slower, it\nwill make a difference of at most just seconds for most practical uses.\nBut many useful algorithms are slower than that and have a complexity\nhigher than linear. The textbook example is sorting algorithms: given a\nlist of n values in a random order, you’ll need on average n × log n basic\noperations to sort the list, which is sometimes called linearithmic\ncomplexity. Since n × log n grows faster than n, sorting speed will slow\ndown faster than proportionally to n. Yet such sorting algorithms will\nremain in the realm of practical computation, or computation that can be\ncarried out in a reasonable amount of time.\nAt some point, we’ll hit the ceiling of what’s feasible even for relatively\nsmall input lengths. Take the simplest example from cryptanalysis: the\nbrute-force search for a secret key. Recall from Chapter 1 that given a\nplaintext P and a ciphertext C = E(K, P), it takes at most 2n attempts to\nrecover an n-bit symmetric key because there are 2n possible keys—an\nexample of a complexity that grows exponentially. For complexity\ntheorists, exponential complexity means a problem that is practically\nimpossible to solve, because as n grows, the effort very rapidly becomes\ninfeasible.\nYou may object that we’re comparing oranges and apples here: in the\nsearch() function in Listing 9-1, we counted the number of if (array[i]\n== x) operations, whereas key recovery counts the number of encryptions,\neach thousands of times slower than a single == comparison. This\ninconsistency can make a difference if you compare two algorithms with\nvery similar complexities, but most of the time it won’t matter because\nthe number of operations will have a greater impact than the cost of an\nindividual operation. Also, complexity estimates ignore constant factors:\nwhen we say that an algorithm takes time in the order of n3 operations\n(which is quadratic complexity), it may actually take 41 × n3 operations, or\n12345 × n3 operations—but again, as n grows, the constant factors lose\nsignificance to the point that we can ignore them. Complexity analysis is\nabout theoretical hardness as a function of the input size; it doesn’t care\nabout the exact number of CPU cycles it will take on your computer.\nYou’ll often find the O() notation (“big O”) used to express\ncomplexities. For example, O(n3) means that complexity grows no faster\nthan n3, ignoring potential constant factors. O() denotes the upper bound\nof an algorithm’s complexity. The notation O(1) means that an algorithm\nruns in constant time—that is, the running time doesn’t depend on the\ninput length! For example, the algorithm that determines an integer’s\nparity by looking at its least significant bit (LSB) and returning “even” if\nit’s zero and “odd” otherwise will do the same thing at the same cost\nwhatever the integer’s length.\nTo see the difference between linear, quadratic, and exponential time\ncomplexities, look at how complexity grows for O(n) (linear) versus O(n2)\n(quadratic) versus O(2n) (exponential) in Figure 9-1.\nFigure 9-1: Growth of exponential, quadratic, and linear complexities, from the\nfastest to the slowest growing\nExponential complexity means the problem is practically impossible to\nsolve, and linear complexity means the solution is feasible, whereas\nquadratic complexity is somewhere between the two.\nPolynomial vs. Superpolynomial Time\nThe O(n2) complexity discussed in the last section (the middle curve in\nFigure 9-1) is a special case of the broader class of polynomial\ncomplexities, or O(nk), where k is some fixed number such as 3, 2.373,\n7/10, or the square root of 17. Polynomial-time algorithms are eminently\nimportant in complexity theory and in crypto because they’re the very\ndefinition of practically feasible. When an algorithm runs in polynomial\ntime, or polytime for short, it will complete in a decent amount of time\neven if the input is large. That’s why polynomial time is synonymous with\n“efficient” for complexity theorists and cryptographers.\nIn contrast, algorithms running in superpolynomial time—that is, in\nO(f(n)), where f(n) is any function that grows faster than any\npoly​\nnomial—are viewed as impractical. I’m saying superpolynomial, and not\njust exponential, because there are complexities in between polynomial\nand the well-known exponential complexity O(2n), such as O(nlog(n)), as\nFigure 9-2 shows.\nn log(n) 2\nFigure 9-2: Growth of the 2 , n , and n functions, from the fastest to the\nslowest growing\nNOTE\nExponential complexity O(2n) is not the worst you can get. Some complexities\ngrow even faster and thus characterize algorithms even slower to compute—\nfor example, the complexity O(nn) or the exponential factorial O(nf(n – 1)),\nwhere for any x, the function f is here recursively defined as f(x) = xf(x – 1). In\npractice, you’ll never encounter algorithms with such preposterous\ncomplexities.\nO(n2) or O(n3) may be efficient, but O(n99999999999) obviously isn’t. In\nother words, polytime is fast as long as the exponent isn’t too large.\nFortunately, all polynomial-time algorithms found to solve actual\nproblems do have small exponents. For example, O(n1.465) is the time for\nmultiplying two n-bit integers, or O(n2.373) for multiplying two n × n\nmatrices. The 2002 breakthrough polytime algorithm for identifying\nprime numbers initially had a complexity O(n12), but it was later\nimproved to O(n6). Polynomial time thus may not be the perfect\ndefinition of a practical time for an algorithm, but it’s the best we have.\nBy extension, a problem that can’t be solved by a polynomial-time\nalgorithm is considered impractical, or hard. For example, for a\nstraightforward key search, there’s no way to beat the O(2n) complexity\nunless the cipher is somehow broken.\nWe know for sure that there’s no way to beat the O(2 ) complexity of a\nN\nbrute-force key search (as long as the cipher is secure), but we don’t\nalways know what the fastest way to solve a problem is. A large portion of\nthe research in complexity theory is about proving complexity bounds on\nthe running time of algorithms solving a given problem. To make their\njob easier, complexity theorists have categorized computational problems\nin different groups, or classes, according to the effort needed to solve\nthem.\nComplexity Classes\nIn mathematics, a class is a group of objects with some similar attribute.\nFor example, all computational problems solvable in time O(n2), which\ncomplexity theorists simply denote TIME(n2), are one class. Likewise,\nTIME(n3) is the class of problems solvable in time O(n3), TIME(2 ) is\nN\nthe class of problems solvable in time O(2 ), and so on. For the same\nN\nreason that a supercomputer can compute whatever a laptop can\ncompute, any problem solvable in O(n2) is also solvable in O(n3). Hence,\nany problem in the class TIME(n2) also belongs to the class TIME(n3),\nwhich both also belong to the class TIME(n4), and so on. The union of\nall these classes of problems, TIME(nk), where k is a constant, is called P,\nwhich stands for polynomial time.\nIf you’ve ever programmed a computer, you’ll know that seemingly fast\nalgorithms may still crash your system by eating all its memory resources.\nWhen selecting an algorithm, you should not only consider its time\ncomplexity but also how much memory it uses, or its space complexity. This\nis especially important because a single memory access is usually orders of\nmagnitudes slower than a basic arithmetic operation in a CPU.\nFormally, you can define an algorithm’s memory consumption as a\nfunction of its input length, n, in the same way we defined time\ncomplexity. The class of problems solvable using f(n) bits of memory is\nSPACE(f(n)). For example, SPACE(n3) is the class of problems solvable\nusing of the order of n3 bits of memory. Just as we had P as the union of\nall TIME(nk), the union of all SPACE(nk) problems is called PSPACE.\nObviously, the lower the memory the better, but a polynomial amount\nof memory doesn’t necessarily imply that an algorithm is practical. Why?\nWell, take for example a brute-force key search: again, it takes only\nnegligible memory but is slow as hell. More generally, an algorithm can\ntake forever, even if it uses just a few bytes of memory.\nAny problem solvable in time f(n) needs at most f(n) memory, so\nTIME(f(n)) is included in SPACE(f(n)). In time f(n), you can only write\nup to f(n) bits, and no more, because writing (or reading) 1 bit is assumed\nto take one unit of time; therefore, any problem in TIME(f(n)) can’t use\nmore than f(n) space. As a consequence, P is a subset of PSPACE.\nNondeterministic Polynomial Time\nNP is the second most important complexity class, after the class P of all\npolynomial-time algorithms. No, NP doesn’t stand for non-polynomial\ntime, but for nondeterministic polynomial time. What does that mean?\nNP is the class of problems for which a solution can be verified in\npolynomial time—that is, efficiently—even though the solution may be\nhard to find. By verified, I mean that given a potential solution, you can\nrun some polynomial-time algorithm that will verify whether you’ve\nfound an actual solution. For example, the problem of recovering a secret\nkey with a known plaintext is in NP, because given P, C = E(K, P), and\nsome candidate key K , you can check that K is the correct key by\n0 0\nverifying that E(K , P) equals C. The process of finding a potential key\n0\n(the solution) can’t be done in polynomial time, but checking whether the\nkey is correct is done using a polynomial-time algorithm.\nNow for a counterexample: what about known-ciphertext attacks? This\ntime, you only get some E(K, P) values for random unknown plaintext Ps.\nIf you don’t know what the Ps are, then there’s no way to verify whether a\npotential key, K , is the right one. In other words, the key-recovery\n0\nproblem under known-ciphertext attacks is not in NP (let alone in P).\nAnother example of a problem not in NP is that of verifying the absence\nof a solution to a problem. Verifying that a solution is correct boils down\nto computing some algorithm with the candidate solution as an input and\nthen checking the return value. However, to verify that no solution exists,\nyou may need to go through all possible inputs. And if there’s an\nexponential number of inputs, you won’t be able to efficiently prove that\nno solution exists. The absence of a solution is hard to show for the\nhardest problems in the class NP—the so-called NP-complete problems,\nwhich we’ll discuss next.\nNP-Complete Problems\nThe hardest problems in the class NP are called NP-complete; we don’t\nknow how to solve these problems in polynomial time. And as complexity\ntheorists discovered in the 1970s when they developed the theory of NP-\ncompleteness, NP’s hardest problems are all equally hard. This was\nproven by showing that any efficient solution to any of the NP-complete\nproblems can be turned into an efficient solution for any of the other\nNP-complete problems. In other words, if you can solve any NP-\ncomplete problem efficiently, you can solve all of them, as well as all\nproblems in NP. How can this be?\nNP-complete problems come in different disguises, but they’re\nfundamentally similar from a mathematical perspective. In fact, you can\nreduce any NP-complete problem to any other NP-complete problem\nsuch that solving the first one depends on solving the second.\nHere are some examples of NP-complete problems:\nThe traveling salesman problem Given a set of points on a map\n(cities, addresses, or other geographic locations) and the distances\nbetween each point from each other point, find a path that visits every\npoint such that the total distance is smaller than a given distance of x.\nThe clique problem Given a number, x, and a graph (a set of nodes\nconnected by edges, as in Figure 9-3), determine if there’s a set of x\npoints or less such that all points are connected to each other.\nThe knapsack problem Given two numbers, x and y, and a set of\nitems, each of a known value and weight, can we pick a group of items\nsuch that the total value is at least x and the total weight at most y?\nFigure 9-3: A graph containing a clique of four points. The general problem of\nfinding a clique (set of nodes all connected to each other) of given size in a graph is\nNP-complete.\nSuch NP-complete problems are found everywhere, from scheduling\nproblems (given jobs of some priority and duration, and one or more\nprocessors, assign jobs to the processors by respecting the priority while\nminimizing total execution time) to constraint-satisfaction problems\n(determine values that satisfy a set of mathematical constraints, such as\nlogical equations). Even the task of winning in certain video games can\nsometimes be proven to be NP-complete (for famous games including\nTetris, Super Mario Bros., Pokémon, and Candy Crush Saga). For example,\nthe article “Classic Nintendo Games Are (Computationally) Hard”\n(https://arxiv.org/abs/1203.1895) considers “the decision problem of\nreachability” to determine the possibility of reaching the goal point from\na particular starting point.\nSome of these video game problems are actually even harder than NP-\ncomplete and are called NP-hard. We say that a problem is NP-hard\nwhen it’s at least as hard as NP-complete problems. More formally, a\nproblem is NP-hard if what it takes to solve it can be proven to also solve\nNP-complete problems.\nI have to mention an important caveat. Not all instances of NP-\ncomplete problems are actually hard to solve. Some specific instances,\nbecause they’re small or because they have a specific structure, may be\nsolved efficiently. Take, for example, the graph in Figure 9-3. By just\nlooking at it for a few seconds you’ll spot the clique, which is the top four\nconnected nodes—even though the aforementioned clique problem is\nNP-hard, there’s nothing hard here. So being NP-complete doesn’t\nmean that all instances of a given problem are hard, but that as the\nproblem size grows, many of them are.\nThe P vs. NP Problem\nIf you could solve the hardest NP problems in polynomial time, then you\ncould solve all NP problems in polynomial time, and therefore NP would\nequal P. That sounds preposterous; isn’t it obvious that there are\nproblems for which a solution is easy to verify but hard to find? For\nexample, isn’t it obvious that exponential-time brute force is the fastest\nway to recover the key of a symmetric cipher, and therefore that the\nproblem can’t be in P? It turns out that, as crazy as it sounds, no one has\nproved that P is different from NP, despite a bounty of literally one\nmillion dollars.\nThe Clay Mathematics Institute will award this bounty to anyone who\nproves that either P ≠ NP or P = NP. This problem, known as P vs. NP,\nwas called “one of the deepest questions that human beings have ever\nasked” by renowned complexity theorist Scott Aaronson. Think about it:\nif P were equal to NP, then any easily checked solution would also be\neasy to find. All cryptography used in practice would be insecure, because\nyou could recover symmetric keys and invert hash functions efficiently.\nFigure 9-4: The classes NP, P, and the set of NP-complete problems\nBut don’t panic: most complexity theorists believe P isn’t equal to NP,\nand therefore that P is instead a strict subset of NP, as Figure 9-4 shows,\nwhere NP-complete problems are another subset of NP not overlapping\nwith P. In other words, problems that look hard actually are hard. It’s just\ndifficult to prove this mathematically. While proving that P = NP would\nonly need a polynomial-time algorithm for an NP-complete problem,\nproving the nonexistence of such an algorithm is fundamentally harder.\nBut this didn’t stop wacky mathematicians from coming up with simple\nproofs that, while usually obviously wrong, often make for funny reads;\nfor an example, see “The P-versus-NP page”\n(https://www.win.tue.nl/~gwoegi/P-versus-NP.htm).\nNow if we’re almost sure that hard problems do exist, what about\nleveraging them to build strong, provably secure crypto? Imagine a proof\nthat breaking some cipher is NP-complete, and therefore that the cipher\nis unbreakable as long as P isn’t equal to NP. But reality is disappointing:\nNP-complete problems have proved difficult to use for crypto purposes\nbecause the very structure that makes them hard in general can make\nthem easy in specific cases—cases that sometimes occur in crypto.\nInstead, cryptography often relies on problems that are probably not NP-\nhard.\nThe Factoring Problem\nThe factoring problem consists of finding the prime numbers p and q\ngiven a large number, N = p × q. The widely used RSA algorithms are\nbased on the fact that factoring a number is difficult. In fact, the hardness\nof the factoring problem is what makes RSA encryption and signature\nschemes secure. But before we see how RSA leverages the factoring\nproblem in Chapter 10, I’d like to convince you that this problem is\nindeed hard, yet probably not NP-complete.\nFirst, some kindergarten math. A prime number is a number that isn’t\ndivisible by any other number but itself and 1. For example, the numbers\n3, 7, and 11 are prime; the numbers 4 = 2 × 2, 6 = 2 × 3, and 12 = 2 × 2 × 3\nare not prime. A fundamental theorem of number theory says that any\ninteger number can be uniquely written as a product of primes, a\nrepresentation called the factorization of that number. For example, the\nfactorization of 123456 is 26 × 3 × 643; the factorization of 1234567 is =\n127 × 9721; and so on. Any integer has a unique factorization, or a unique\nway to write it as a product of prime numbers. But how do we know that\na given factorization contains only prime numbers or that a given number\nis prime? The answer is found through polynomial-time primality testing\nalgorithms, which allow us to efficiently test whether a given number is\nprime. Getting from a number to its prime factors, however, is another\nmatter.\nFactoring Large Numbers in Practice\nSo how do we go from a number to its factorization—namely, its\ndecomposition as a product of prime numbers? The most basic way to\nfactor a number, N, is to try dividing it by all the numbers lower than it\nuntil you find a number, x, that divides N. Then attempt to divide N with\nthe next number, x + 1, and so on. You’ll end up with a list of factors of\nN. What’s the time complexity of this? First, remember that we express\ncomplexities as a function of the input’s length. The bit length of the\nnumber N is n = log N. By the basic definition of logarithm, this means\n2\nthat N = 2 . Because all the numbers less than N/2 are reasonable guesses\nN\nfor possible factors of N, there are about N/2 = 2 /2 values to try. The\nN\ncomplexity of our naive factoring algorithm is therefore O(2 ), ignoring\nN\nthe 1/2 coefficient in the O() notation.\nOf course, many numbers are easy to factor by first finding any small\nfactors (2, 3, 5, and so on) and then iteratively factoring any other\nnonprime factors. But here we’re interested in numbers of the form N = p\n× q, where p and q are large, as found in cryptography.\nLet’s be a bit smarter. We don’t need to test all numbers lower than\nN/2, but rather only the prime numbers, and we can start by trying only\nthose smaller than the square root of N. Indeed, if N is not a prime\nnumber, then it has to have at least one factor lower than its square root\n√N. This is because if both of N’s factors p and q are greater than √N,\nthen their product would be greater than √N × √N = N, which is\nimpossible. For example, if we say N = 100, then its factors p and q can’t\nboth be greater than 10 because that would result in a product greater\nthan 100. Either p or q has to be smaller than √N.\nSo what’s the complexity of testing only the primes less than √N? The\nprime number theorem states that there are approximately N/log N primes\nless than N. Hence, there are approximately √N/log √N primes less than\n√N. Expressing this value, we get approximately 2n/2/n possible prime\nfactors and therefore a complexity of O(2n/2/n), since √N = 2n/2 and\n1/log√N = 1/(n/2) = 2n. This is faster than testing all prime numbers, but\nit’s still painfully slow—on the order of 2120 operations for a 256-bit\nnumber. That’s quite an impractical computational effort.\nThe fastest factoring algorithm is the general number field sieve (GNFS),\nwhich I won’t describe here because it requires the introduction of several\nadvanced mathematical concepts. A rough estimate of GNFS’s\ncomplexity is exp(1.91 × n1/3 (log n)2/3), where exp(. . .) is just a different\nnotation for the exponential function ex, with e the exponential constant\napproximately equal to 2.718. However, it’s difficult to get an accurate\nestimate of GNFS’s actual complexity for a given number size.\nTherefore, we have to rely on heuristical complexity estimates, which\nshow how security increases with a longer n. For example:\nFactoring a 1024-bit number, which would have two prime factors\nof approximately 500 bits each, will take on the order of 270 basic\noperations.\nFactoring a 2048-bit number, which would have two prime factors\nof approximately 1000 bits each, will take on the order of 290 basic\noperations, which is about a million times slower than for a 1024-bit\nnumber.\nAnd we estimate that at least 4096 bits are needed to reach 128-bit\nsecurity. Note that these values should be taken with a grain of salt, and\nresearchers don’t always agree on these estimates. Take a look at these\nexperimental results to see the actual cost of factoring:\nIn 2005, after about 18 months of computation—and thanks to the\npower of a cluster of 80 processors, with a total effort equivalent to\n75 years of computation on a single processor—a group of\nresearchers factored a 663-bit (200-decimal digit) number.\nIn 2009, after about two years and using several hundred processors,\nwith a total effort equivalent to about 2,000 years of computation on\na single processor, another group of researchers factored a 768-bit\n(232-decimal digit) number.\nAs you can see, the numbers actually factored by academic researchers\nare shorter than those in real applications, which are at least 1024-bit and\noften more than 2048-bit. As I write this, no one has reported the\nfactoring of a 1024-bit number, but many speculate that well-funded\norganizations such as the NSA can do it.\nIn sum, 1024-bit RSA should be viewed as insecure, and RSA should be\nused with at least a 2048-bit value—and preferably a 4096-bit one to\nensure higher security.\nIs Factoring NP-Complete?\nWe don’t know how to factor large numbers efficiently, which suggests\nthat the factoring problem doesn’t belong to P. However, factoring is\nclearly in NP, because given a factorization, we can verify the solution by\nchecking that all factors are prime numbers, thanks to the\naforementioned primality testing algorithm, and that when multiplied\ntogether, the factors do give the expected number. For example, to check\nthat 3 × 5 is the factorization of 15, you’ll check that both 3 and 5 are\nprime and that 3 times 5 equals 15.\nSo we have a problem that is in NP and that looks hard, but is it as\nhard as the hardest NP problems? In other words, is factoring NP-\ncomplete? Spoiler alert: probably not.\nThere’s no mathematical proof that factoring isn’t NP-complete, but\nwe have a few pieces of soft evidence. First, all known NP-complete\nproblems can have one solution, but can also have more than one\nsolution, or no solution at all. In contrast, factoring always has exactly one\nsolution. Also, the factoring problem has a mathematical structure that\nallows for the GNFS algorithm to significantly outperform a naive\nalgorithm, a structure that NP-complete problems don’t have. Factoring\nwould be easy if we had a quantum computer, a computing model that\nexploits quantum mechanical phenomena to run different kinds of\nalgorithms and that would have the capability to factor large numbers\nefficiently (not because it’d run the algorithm faster, but because it could\nrun a quantum algorithm dedicated to factoring large numbers). A\nquantum computer doesn’t exist yet, though—and might never exist.\nRegardless, a quantum computer would be useless in tackling NP-\ncomplete problems because it’d be no faster than a classical one (see\nChapter 14).\nFactoring may then be slightly easier than NP-complete in theory, but\nas far as cryptography is concerned, it’s hard enough, and even more\nreliable than NP-complete problems. Indeed, it’s easier to build\ncryptosystems on top of the factoring problem than NP-complete\nproblems, because it’s hard to know exactly how hard it is to break a\ncryptosystem based on some NP-complete problems—in other words,\nhow many bits of security you’d get.\nThe factoring problem is just one of several problems used in\ncryptography as a hardness assumption, which is an assumption that some\nproblem is computationally hard. This assumption is used when proving\nthat breaking a cryptosystem’s security is at least as hard as solving said\nproblem. Another problem used as a hardness assumption, the discrete\nlogarithm problem (DLP), is actually a family of problems, which we’ll\ndiscuss next.\nThe Discrete Logarithm Problem\nThe DLP predates the factoring problem in the official history of\ncryptography. Whereas RSA appeared in 1977, a second cryptographic\nbreakthrough, the Diffie–Hellman key agreement (covered in Chapter\n11), came about a year earlier, grounding its security on the hardness of\nthe DLP. Like the factoring problem, the DLP deals with large numbers,\nbut it’s a bit less straightforward—it will take you a few minutes rather\nthan a few seconds to get it and requires a bit more math than factoring.\nSo let me introduce the mathematical notion of a group in the context of\ndiscrete logarithms.\nWhat Is a Group?\nIn mathematical context, a group is a set of elements (typically, numbers)\nthat are related to each other according to certain well-defined rules. An\nexample of a group is the set of nonzero integers (between 1 and p – 1)\nmodulo some prime number p, which we write Z *. For p = 5, we get the\np\ngroup Z * = {1,2,3,4}. In the group Z *, operations are carried out modulo\n5 5\n5; hence, we don’t have 3 × 4 = 12 but instead have 3 × 4 = 2, because 12\nmod 5 = 2. We nonetheless use the same sign (×) that we use for normal\ninteger multiplication. Likewise, we also use the exponent notation to\ndenote a group element’s multiplication with itself mod p, a common\noperation in cryptography. For example, in the context of Z *, 23 = 2 × 2\n5\n× 2 = 3 rather than 8, because 8 mod 5 is equal to 3.\nTo be a group, a mathematical set should have the following\ncharacteristics, called group axioms:\nClosure For any two x and y in the group, x × y is in the group too. In\nZ *, 2 × 3 = 1 (because 6 = 1 mod 5), 2 × 4 = 3, and so on.\n5\nAssociativity For any x, y, z in the group, (x × y) × z = x × (y × z). In\nZ *, (2 × 3) × 4 = 1 × 4 = 2 × (3 × 4) = 2 × 2 = 4.\n5\nIdentity existence There’s an element e such that e × x = x × e = x. In\nany Z *, the identity element is 1.\np\nInverse existence For any x in the group, there’s a y such that x × y = y\n× x = e. In Z *, the inverse of 2 is 3, and the inverse of 3 is 2, while 4 is\n5\nits own inverse because 4 × 4 = 16 = 1 mod 5.\nIn addition, a group is called commutative if x × y = y × x for any group\nelements x and y. That’s also true for any multiplicative group of integers\nZ *. In particular, Z * is commutative: 3 × 4 = 4 × 3, 2 × 3 = 3 × 2, and so\np 5\non.\nA group is called cyclic if there’s at least one element g such that its\npowers (g1, g2, g3, and so on) mod p span all distinct group elements. The\nelement g is then called a generator of the group. Z * is cyclic and has two\n5\ngenerators, 2 and 3, because 21 = 2, 22 = 4, 23 = 3, 24 = 1, and 31 = 3, 32 =\n4, 33 = 2, 34 = 1.\nNote that I’m using multiplication as a group operator, but you can\nalso get groups from other operators. For example, the most\nstraightforward group is the set of all integers, positive and negative, with\naddition as a group operation. Let’s check that the group axioms hold\nwith addition, in the preceding order: clearly, the number x + y is an\ninteger if x and y are integers (closure); (x + y) + z = x + (y + z) for any x, y,\nand z (associativity); zero is the identity element; and the inverse of any\nnumber x in the group is –x because x + (–x) = 0 for any integer x. A big\ndifference, though, is that this group of integers is of infinite size,\nwhereas in crypto we’ll only deal with finite groups, or groups with a finite\nnumber of elements. Typically, we’ll use groups Z *, where p is thousands\np\nof bits long (that is, groups that contain on the order of 2 numbers).\np\nThe Hard Thing\nThe DLP consists of finding the y for which gy = x, given a base number g\nwithin some group Z *, where p is a prime number, and given a group\np\nelement x. The DLP is called discrete because we’re dealing with integers\nas opposed to real numbers (continuous), and it’s called a logarithm\nbecause we’re looking for the logarithm of x in base g. (For example, the\nlogarithm of 256 in base 2 is 8 because 28 = 256.)\nPeople often ask me whether factoring or a discrete logarithm is more\nsecure—or in other words, which problem is the hardest? My answer is\nthat they’re about equally hard. In fact, algorithms to solve DLP bear\nsimilarities with those factoring integers, and you get about the same\nsecurity level with n-bit hard-to-factor numbers as with discrete\nlogarithms in an n-bit group. And for the same reason as factoring, DLP\nisn’t NP-complete. (Note that there are certain groups where the DLP is\neasier to solve, but here I’m only referring to the case of DLP groups\nconsisting of a number modulo a prime.)\nHow Things Can Go Wrong\nMore than 40 years later, we still don’t know how to efficiently factor\nlarge numbers or solve discrete logarithms. Amateurs may argue that\nsomeone may eventually break factoring—and we have no proof that it’ll\nnever be broken—but we also don’t have proof that P ≠ NP. Likewise,\nyou can speculate that P may be equal to NP; however, according to\nexperts, that surprise is unlikely. So there’s no need to worry. And indeed\nall the public-key crypto deployed today relies on either factoring (RSA)\nor DLP (Diffie–Hellman, ElGamal, elliptic curve cryptography).\nHowever, although math may not fail us, real-world concerns and human\nerror can sneak in.\nWhen Factoring Is Easy\nFactoring large numbers isn’t always hard. For example, take the 1024-bit\nnumber N, which is equal to the following:\nFor 1024-bit numbers used in RSA encryption or signature schemes\nwhere N = pq, we expect the best factoring algorithms to need around 270\noperations, as we discussed earlier. But you can factor this sample number\nin seconds using SageMath, a piece of Python-based mathematical\nsoftware. Using SageMath’s factor() function on my 2015 MacBook, it\ntook less than five seconds to find the following factorization:\nRight, I cheated. This number isn’t of the form N = pq because it\ndoesn’t have just two large prime factors but rather five, including very\nsmall ones, which makes it easy to factor. First, you’ll identify the 2800 ×\n641 × 6700417 part by trying small primes from a precomputed list of\nprime numbers, which leaves you with a 192-bit number that’s much\neasier to factor than a 1024-bit number with two large factors.\nBut factoring can be easy not only when n has no small prime factors,\nbut also when N or its factors p and q have particular forms—for example,\nwhen N = pq with p and q both close to some 2b, when N = pq and some\nbits of p or q are known, or when N is of the form N = prqs and r is greater\nthan log p. However, detailing the reasons for these weaknesses is way too\ntechnical for this book.\nThe upshot here is that the RSA encryption and signature algorithms\n(covered in Chapter 10) will need to work with a value of N = pq, where p\nand q are carefully chosen, to avoid easy factorization of N, which can\nresult in security disaster.\nSmall Hard Problems Aren’t Hard\nComputationally hard problems become easy when they’re small enough,\nand even exponential-time algorithms become practical as the problem\nsize shrinks. A symmetric cipher may be secure in the sense that there’s\nno faster attack than the 2n-time brute force, but if the key length is n =\n32, you’ll break the cipher in minutes. This sounds obvious, and you’d\nthink that no one would be naive enough to use small keys, but in reality\nthere are plenty of reasons why this could happen. The following are two\ntrue stories.\nSay you’re a developer who knows nothing about crypto but has some\nAPI to encrypt with RSA and has been told to encrypt with 128-bit\nsecurity. What RSA key size would you pick? I’ve seen real cases of 128-\nbit RSA, or RSA based on a 128-bit number N = pq. However, although\nfactoring is impractically hard for an N thousands of bits long, factoring a\n128-bit number is easy. Using the SageMath software, the commands\nshown in Listing 9-2 complete instantaneously.\nsage: p = random_prime(2**64)\nsage: q = random_prime(2**64)\nsage: factor(p*q)\n6822485253121677229 * 17596998848870549923\nListing 9-2: Generating an RSA modulus by picking two random prime numbers and\nfactoring it instantaneously\nListing 9-2 shows that a 128-bit number taken randomly as the product\nof two 64-bit prime numbers can be easily factored on a typical laptop.\nHowever, if I chose 1024-bit prime numbers instead by using p =\nrandom_prime(2**1024), the command factor(p*q) would never complete, at\nleast not in my lifetime.\nTo be fair, the tools available don’t help prevent the naive use of\ninsecurely short parameters. For example, the OpenSSL toolkit lets you\ngenerate RSA keys as short as 31 bits without any warning; obviously,\nsuch short keys are totally insecure, as shown in Listing 9-3.\n$ openssl genrsa 31\nGenerating RSA private key, 31 bit long modulus\n.+++++++++++++++++++++++++++\n.+++++++++++++++++++++++++++\ne is 65537 (0x10001)\n-----BEGIN RSA PRIVATE KEY-----\nMCsCAQACBHHqFuUCAwEAAQIEP6zEJQIDANATAgMAjCcCAwCSBwICTGsCAhpp\n-----END RSA PRIVATE KEY-----\nListing 9-3: Generating an insecure RSA private key using the OpenSSL toolkit\nWhen reviewing cryptography, you should not only check the type of\nalgorithms used, but also their parameters and the length of their secret\nvalues. However, as you’ll see in the following story, what’s secure\nenough today may be insecure tomorrow.\nIn 2015, researchers discovered that many HTTPS servers and email\nservers still supported an older, insecure version of the Diffie–Hellman\nkey agreement protocol. Namely, the underlying TLS implementation\nsupported Diffie–Hellman within a group, Z *, defined by a prime\np\nnumber, p, of only 512 bits, where the discrete logarithm problem was no\nlonger practically impossible to compute.\nNot only did servers support a weak algorithm, but attackers could\nforce a benign client to use that algorithm by injecting malicious traffic\nwithin the client’s session. Even better for attackers, the largest part of\nthe attack could be carried out once and recycled to attack multiple\nclients. After about a week of computations to attack a specific group, Z *,\np\nit took only 70 seconds to break individual sessions of different users.\nA secure protocol is worthless if it’s undermined by a weakened\nalgorithm, and a reliable algorithm is useless if sabotaged by weak\nparameters. In cryptography, you should always read the fine print.\nFor more details about this story, check the research article “Imperfect\nForward Secrecy: How Diffie–Hellman Fails in Practice”\n(https://weakdh.org/imperfect-forward-secrecy-ccs15.pdf).\nFurther Reading\nI encourage you to look deeper into the foundational aspects of\ncomputation in the context of computability (what functions can be\ncomputed?) and complexity (at what cost?), and how they relate to\ncryptography. I’ve mostly talked about the classes P and NP, but there\nare many more classes and points of interest for cryptographers. I highly\nrecommend the book Quantum Computing Since Democritus by Scott\nAaronson (Cambridge University Press, 2013). It’s in large part about\nquantum computing, but its first chapters brilliantly introduce complexity\ntheory and cryptography.\nIn the cryptography research literature you’ll also find other hard\ncomputational problems. I’ll mention them in later chapters, but here are\nsome examples that illustrate the diversity of problems leveraged by\ncryptographers:\nThe Diffie–Hellman problem (given gx and g y, find gxy) is a variant\nof the discrete logarithm problem, and is widely used in key\nagreement protocols.\nLattice problems, such as the shortest vector problem (SVP) and the\nlearning with errors (LWE) problem, are the only examples of NP-\nhard problems successfully used in cryptography.\nCoding problems rely on the hardness of decoding error-correcting\ncodes with insufficient information, and have been studied since the\nlate 1970s.\nMultivariate problems are about solving nonlinear systems of\nequations and are potentially NP-hard, but they’ve failed to provide\nreliable cryptosystems because hard versions are too big and slow,\nand practical versions were found to be insecure.\nIn Chapter 10, we’ll keep talking about hard problems, especially\nfactoring and its main variant, the RSA problem."
  },
  {
    "input": "What is the core concept behind the RSA cryptosystem and how does it ensure secure encryption and digital signatures?",
    "summary": "RSA is a public-key encryption system that uses two keys: a public key for encryption and a private key for decryption. It relies on the difficulty of factoring large numbers and involves a trapdoor permutation based on modular exponentiation. RSA is also used for digital signatures, where the private key signs a message and the public key verifies it. However, naive implementations of RSA are insecure due to vulnerabilities like malleability, and more secure methods like OAEP or PSS are recommended. Additionally, RSA's security depends on the size of the modulus, the choice of primes, and the use of padding schemes to prevent attacks.",
    "output": "10\nRSA\nThe Rivest–Shamir–Adleman (RSA) cryptosystem revolutionized\ncryptography when it emerged in 1977 as the first public-key encryption\nscheme; whereas classical, symmetric-key encryption schemes use the\nsame secret key to encrypt and decrypt messages, public-key encryption\n(also called asymmetric encryption) uses two keys: one is your public key,\nwhich can be used by anyone who wants to encrypt messages for you, and\nthe other is your private key, which is required in order to decrypt\nmessages encrypted using the public key. This magic is the reason why\nRSA came as a real breakthrough, and 40 years later, it’s still the paragon\nof public-key encryption and a workhorse of internet security. (One year\nprior to RSA, Diffie and Hellman had introduced the concept of public-\nkey cryptography, but their scheme was unable to perform public-key\nencryption.)\nRSA is above all an arithmetic trick. It works by creating a\nmathematical object called a trapdoor permutation, a function that\ntransforms a number x to a number y in the same range, such that\ncomputing y from x is easy using the public key, but computing x from y\nis practically impossible unless you know the private key—the trapdoor.\n(Think of x as a plaintext and y as a ciphertext.)\nIn addition to encryption, RSA is also used to build digital signatures,\nwherein the owner of the private key is the only one able to sign a\nmessage, and the public key enables anyone to verify the signature’s\nvalidity.\nIn this chapter, I explain how the RSA trapdoor permutation works,\ndiscuss RSA’s security relative to the factoring problem (discussed in\nChapter 9), and then explain why the RSA trapdoor permutation alone\nisn’t enough to build secure encryption and signatures. I also discuss ways\nto implement RSA and demonstrate how to attack it.\nWe begin with an explanation of the basic mathematical notions\nbehind RSA.\nThe Math Behind RSA\nWhen encrypting a message, RSA sees the message as a big number, and\nencryption consists essentially of multiplications of big numbers.\nTherefore, in order to understand how RSA works, we need to know\nwhat kind of big numbers it manipulates and how multiplication works on\nthose numbers.\nRSA sees the plaintext that it’s encrypting as a positive integer between\n1 and n – 1, where n is a large number called the modulus. More precisely,\nRSA works on the numbers less than n that are co-prime with n and\ntherefore that have no common prime factor with n. Such numbers, when\nmultiplied together, yield another number that satisfies these criteria. We\nsay that these numbers form a group, denoted Z *, and call the\nN\nmultiplicative group of integers modulo n. (See the mathematical\ndefinition of a group in “What Is a Group?” on page 174.)\nFor example, consider the group Z * of integers modulo 4. Recall from\n4\nChapter 9 that a group must include an identity element (that is, 1) and\nthat each number x in the group must have an inverse, a number y such\nthat x × y = 1. How do we determine that set that makes up Z *? Based on\n4\nour definitions, we know that 0 is not in the group Z * because\n4\nmultiplying any number by 0 can never give 1, so 0 has no inverse. By the\nsame token, the number 1 belongs to Z * because 1 × 1 = 1, so 1 is its own\n4\ninverse. However, the number 2 does not belong in this group because we\ncan’t obtain 1 by multiplying 2 with another element of Z * (the reason is\n4\nthat 2 isn’t co-prime with 4, because 4 and 2 share the factor of 2.) The\nnumber 3 belongs in the group Z * because it is its own inverse within\n4\nZ *. Thus, we have Z * = {1, 3}.\n4 4\nNow consider Z *, the multiplicative group of integers modulo 5.\n5\nWhat numbers does this set contain? The number 5 is prime, and 1, 2, 3,\nand 4 are all co-prime with 5, so the set of Z * is {1, 2, 3, 4}. Let’s verify\n5\nthis: 2 × 3 mod 5 = 1, therefore, 2 is 3’s inverse, and 3 is 2’s inverse; note\nthat 4 is its own inverse because 4 × 4 mod 5 = 1; finally, 1 is again its own\ninverse in the group.\nIn order to find the number of elements in a group Z * when n isn’t\nn\nprime, we use Euler’s totient function, which is written as φ(n), with φ\nrepresenting the Greek letter phi. This function gives the number of\nelements co-prime with n, which is the number of elements in Z *. As a\nn\nrule, if n is a product of prime numbers n = p × p × . . . × p , the number\n1 2 m\nof elements in the group Z * is the following:\nn\nφ(n) = (p − 1) × (p − 1) × ... × (p − 1)\n1 2 m\nRSA only deals with numbers n that are the product of two large\nprimes, usually noted as n = pq. The associated group Z * will then\nN\ncontain φ(n) = (p – 1)(q – 1) elements. By expanding this expression, we\nget the equivalent definition φ(n) = n – p – q + 1, or φ(n) = (n + 1) – (p +\nq), which expresses more intuitively the value of φ(n) relative to n. In\nother words, all but (p + q) numbers between 1 and n – 1 belong to Z *\nN\nand are “valid numbers” in RSA operations.\nThe RSA Trapdoor Permutation\nThe RSA trapdoor permutation is the core algorithm behind RSA-based\nencryption and signatures. Given a modulus n and number e, called the\npublic exponent, the RSA trapdoor permutation transforms a number x\nfrom the set Z * into a number y = xe mod n. In other words, it calculates\nn\nthe value that’s equal to x multiplied by itself e times modulo n and then\nreturns the result. When we use the RSA trapdoor permutation to\nencrypt, the modulus n and the exponent e make up the RSA public key.\nIn order to get x back from y, we use another number, denoted d, to\ncompute the following:\nyd mod n = (xe)d mod n = xed mod n = x\nBecause d is the trapdoor that allows us to decrypt, it is part of the\nprivate key in an RSA key pair, and, unlike the public key, it should\nalways be kept secret. The number d is also called the secret exponent.\nObviously, d isn’t just any number; it’s the number such that e\nmultiplied by d is equivalent to 1, and therefore such that xed mod n = x\nfor any x. More precisely, we must have ed = 1 mod φ(n) in order to get\nxed = x1 = x and to decrypt the message correctly. Note that we compute\nmodulo φ(n) and not modulo n here because exponents behave like the\nindexes of elements of Z * rather than as the elements themselves.\nn\nBecause Z * has φ(n) elements, the index must be less than φ(n).\nn\nThe number φ(n) is crucial to RSA’s security. In fact, finding φ(n) for\nan RSA modulus n is equivalent to breaking RSA, because the secret\nexponent d can easily be derived from φ(n) and e, by computing e’s\ninverse. Hence p and q should also be secret, since knowing p or q gives\nφ(n) by computing (p – 1)(q – 1) = φ(n).\nNOTE\nφ(n) is also called the order of the group Z *; the order is an important\nn\ncharacteristic of a group, which is also essential to other public-key systems\nsuch as Diffie–Hellman and elliptic curve cryptography.\nRSA Key Generation and Security\nKey generation is the process by which an RSA key pair is created, namely\na public key (modulus n and public exponent e) and its private key (secret\nexponent d). The numbers p and q (such that n = pq) and the order φ(n)\nshould also be secret, so they’re often seen as part of the private key.\nIn order to generate an RSA key pair, we first pick two random prime\nnumbers, p and q, and then compute φ(n) from these, and we compute d\nas the inverse of e. To show how this works, Listing 10-1 uses SageMath\n(http://www.sagemath.org/), an open-source Python-like environment that\nincludes many mathematical packages.\n❶ sage: p = random_prime(2^32); p\n1103222539\n❷ sage: q = random_prime(2^32); q\n17870599\n❸ sage: n = p*q; n\nc\n❹ sage: phi = (p-1)*(q-1); phi\n36567230045260644\n❺ sage: e = random_prime(phi); e\n13771927877214701\n❻ sage: d = xgcd(e, phi)[1]; d\n15417970063428857\n❼ sage: mod(d*e, phi)\n1\nListing 10-1: Generating RSA parameters using SageMath\nNOTE\nIn order to avoid multiple pages of output, I’ve used a 64-bit modulus n in\nListing 10-1, but in practice an RSA modulus should be at least 2048 bits.\nWe use the random_prime() function to pick random primes p ❶ and q ❷,\nwhich are lower than a given argument. Next, we multiply p and q to get\nthe modulus n ❸ and φ(n), which is the variable phi ❹. We then generate\na random public exponent, e ❺, by picking a random prime less than phi\nin order to ensure that e will have an inverse modulo phi. We then\ngenerate the associated private exponent d by using the xgcd() function\nfrom Sage ❻. This function computes the numbers s and t given two\nnumbers, a and b, with the extended Euclidean algorithm such that as + bt\n= GCD(a, b). Finally, we check that ed mod φ(n) = 1 ❼, to ensure that d\nwill work correctly to invert the RSA permutation.\nNow we can apply the trapdoor permutation, as shown in Listing 10-2.\n❶ sage: x = 1234567\n❷ sage: y = power_mod(x, e, n); y\n19048323055755904\n❸ sage: power_mod(y, d, n)\n1234567\nListing 10-2: Computing the RSA trapdoor permutation back and forth\nWe assign the integer 1234567 to x ❶ and then use the function\npower_mod(x, e, n), the exponentiation modulo n, or xe mod n in equation\nform, to calculate y ❷. Having computed y = xe mod n, we compute yd\nmod n ❸ with the trapdoor d to return the original x.\nBut how hard is it to find x without the trapdoor d? An attacker who\ncan factor big numbers can break RSA by recovering p and q and then\nφ(n) in order to compute d from e. But that’s not the only risk. Another\nrisk to RSA lies in an attacker’s ability to compute x from xe mod n, or e\nth roots modulo n, without necessarily factoring n. Both risks seem\nclosely connected, though we don’t know for sure whether they are\nequivalent.\nAssuming that factoring is indeed hard and that finding e th roots is\nabout as hard, RSA’s security level depends on three factors: the size of n,\nthe choice of p and q, and how the trapdoor permutation is used. If n is\ntoo small, it could be factored in a realistic amount of time, revealing the\nprivate key. To be safe, n should at least be 2048 bits long (a security level\nof about 90 bits, requiring a computational effort of about 290\noperations), but preferably 4096 bits long (a security level of\napproximately 128 bits). The values p and q should be unrelated random\nprime numbers of similar size. If they are too small, or too close together,\nit becomes easier to determine their value from n. Finally, the RSA\ntrapdoor permutation should not be used directly for encryption or\nsigning, as I’ll discuss shortly.\nEncrypting with RSA\nTypically, RSA is used in combination with a symmetric encryption\nscheme, where RSA is used to encrypt a symmetric key that is then used\nto encrypt a message with a cipher such as the Advanced Encryption\nStandard (AES). But encrypting a message or symmetric key with RSA is\nmore complicated than simply converting the target to a number x and\ncomputing xe mod n.\nIn the following subsections, I explain why a naive application of the\nRSA trapdoor permutation is insecure, and how strong RSA-based\nencryption works.\nBreaking Textbook RSA Encryption’s Malleability\nTextbook RSA encryption is the phrase used to describe the simplistic RSA\nencryption scheme wherein the plaintext contains only the message you\nwant to encrypt. For example, to encrypt the string RSA, we would first\nconvert it to a number by concatenating the ASCII encodings of each of\nthe three letters as a byte: R (byte 52), S (byte 53), and A (byte 41). The\nresulting byte string 525341 is equal to 5395265 when converted to\ndecimal, which we might then encrypt by computing 5395265e mod n.\nWithout knowing the secret key, there would be no way to decrypt the\nmessage.\nHowever, textbook RSA encryption is deterministic: if you encrypt the\nsame plaintext twice, you’ll get the same ciphertext twice. That’s one\nproblem, but there’s a bigger problem—given two textbook RSA\nciphertexts y = x e mod n and y = x e mod n, you can derive the\n1 1 2 2\nciphertext of x × x by multiplying these two ciphertexts together, like\n1 2\nthis:\ny × y mod n = x e × x e mod n = (x × x )e mod n\n1 2 1 2 1 2\nThe result is (x × x )e mod n, the ciphertext of the message x × x mod\n1 2 1 2\nn. Thus an attacker could create a new valid ciphertext from two RSA\nciphertexts, allowing them to compromise the security of your encryption\nby letting them deduce information about the original message. We say\nthat this weakness makes textbook RSA encryption malleable. (Of course,\nif you know x and x , you can compute (x × x )e mod n, too, but if you\n1 2 1 2\nonly know y and y , you should not be able to multiply ciphertexts and\n1 2\nget a ciphertext of the multiplied plaintexts.)\nStrong RSA Encryption: OAEP\nIn order to make RSA ciphertexts nonmalleable, the ciphertext should\nconsist of the message data and some additional data called padding, as\nshown in Figure 10-1. The standard way to encrypt with RSA in this\nfashion is to use Optimal Asymmetric Encryption Padding (OAEP),\ncommonly referred to as RSA-OAEP. This scheme involves creating a bit\nstring as large as the modulus by padding the message with extra data and\nrandomness before applying the RSA function.\nFigure 10-1: Encrypting a symmetric key, K, with RSA using (n, e) as a public key\nNOTE\nOAEP is referred to as RSAES-OAEP in official documents such as the\nPKCS#1 standard by the RSA company and NIST’s Special Publication\n800-56B. OAEP improves on the earlier method now called PKCS#1 v1.5,\nwhich is one of the first in a series of Public-Key Cryptography Standards\n(PKCS) created by RSA. It is markedly less secure than OAEP, yet is still\nused in many systems.\nOAEP’s Security\nOAEP uses a pseudorandom number generator (PRNG) to ensure the\nindistinguishability and nonmalleability of ciphertexts by making the\nencryption probabilistic. It has been proven secure as long as the RSA\nfunction and the PRNG are secure and, to a lesser extent, as long as the\nhash functions aren’t too weak. You should use OAEP whenever you\nneed to encrypt with RSA.\nHow OAEP Encryption Works\nIn order to encrypt with RSA in OAEP mode, you need a message\n(typically a symmetric key, K), a PRNG, and two hash functions. To\ncreate the ciphertext, you use a given modulus n long of m bytes (that is,\n8m bits, and therefore an n lower than 28m). To encrypt K, the encoded\nmessage is formed as M = H || 00 . . . 00 || 01 || K, where H is an h-byte\nconstant defined by the OAEP scheme, followed by as many 00 bytes as\nneeded and a 01 byte. This encoded message, M, is then processed as\ndescribed next and as depicted in Figure 10-2.\nFigure 10-2: Encrypting a symmetric key, K, with RSA-OAEP, where H is a fixed\nparameter and R is random bits\nNext, you generate an h-byte random string R and set M = M ⊕\nHash1(R), where Hash1(R) is as long as M. You then set R = R ⊕\nHash2(M), where Hash2(M) is as long as R. Now you use these new\nvalues of M and R to form an m-byte string P = 00 || M || R, which is as\nlong as the modulus n and which can be converted to an integer number\nless than n. The result of this conversion is the number x, which is then\nused to compute the RSA function xe mod n to get the ciphertext.\nTo decrypt a ciphertext y, you would first compute x = yd mod n and,\nfrom this, recover the final values of M and R. Next, you would retrieve\nM’s initial value by computing M ⊕ Hash1(R ⊕ Hash2(M)). Finally, you\nwould verify that M is of the form H || 00 . . . 00 || 01 || K, with an h-\nbyte H and 00 bytes followed by a 01 byte.\nIn practice, the parameters m and h (the length of the modulus and the\nlength of Hash2’s output, respectively) are typically m = 256 bytes (for\n2048-bit RSA) and h = 32 (using SHA-256 as Hash2). This leaves m – h –\n1 = 223 bytes for M, of which up to m – 2h – 2 = 190 bytes are available\nfor K (the “– 2” is due to the separator 01 byte in M). The Hash1 hash\nvalue is then composed of m – h – 1 = 223 bytes, which is longer than the\nhash value of any common hash function.\nNOTE\nIn order to build a hash with such an unusual output length, the RSA\nstandard documents specify the use of the mask generating function\ntechnique to create hash functions that return arbitrarily large hash values\nfrom any hash function.\nSigning with RSA\nDigital signatures can prove that the holder of the private key tied to a\nparticular digital signature signed some message and that the signature is\nauthentic. Because no one other than the private key holder knows the\nprivate exponent d, no one can compute a signature y = xd mod n from\nsome value x, but everyone can verify ye mod n = x given the public\nexponent e. That verified signature can be used in a court of law to\ndemonstrate that the private-key holder did sign some particular message\n—a property of undeniability called nonrepudiation.\nIt’s tempting to see RSA signatures as the converse of encryption, but\nthey are not. Signing with RSA is not the same as encrypting with the\nprivate key. Encryption provides confidentiality whereas a digital\nsignature is used to prevent forgeries. The most salient example of this\ndifference is that it’s okay for a signature scheme to leak information on\nthe message signed, because the message is not secret. For example, a\nscheme that reveals parts of the messages could be a secure signature\nscheme but not a secure encryption scheme.\nDue to the processing overhead required, public-key encryption can\nonly process short messages, which are usually secret keys rather than\nactual messages. A signature scheme, however, can process messages of\narbitrary sizes by using their hash values Hash(M) as a proxy, and it can\nbe deterministic yet secure. Like RSA-OAEP, RSA-based signature\nschemes can use a padding scheme, but they can also use the maximal\nmessage space allowed by the RSA modulus.\nBreaking Textbook RSA Signatures\nWhat we call a textbook RSA signature is the method that signs a message,\nx, by directly computing y = xd mod n, where x can be any number\nbetween 0 and n – 1. Like textbook encryption, textbook RSA signing is\nsimple to specify and implement but also insecure in the face of several\nattacks. One such attack involves a trivial forgery: upon noticing that 0d\nmod n = 0, 1d mod n = 1, and (n – 1)d mod n = n – 1, regardless of the\nvalue of the private key d, an attacker can forge signatures of 0, 1, or n – 1\nwithout knowing d.\nMore worrying is the blinding attack. For example, say you want to get a\nthird party’s signature on some incriminating message, M, that you know\nthey would never knowingly sign. To launch this attack, you could first\nfind some value, R, such that ReM mod n is a message that your victim\nwould knowingly sign. Next, you would convince them to sign that\nmessage and to show you their signature, which is equal to S = (R eM)d\nmod n, or the message raised to the power d. Now, given that signature,\nyou can derive the signature of M, namely M d, with the aid of some\nstraightforward computations.\nHere’s how this works: because S can be written as (R eM)d = RedM d,\nand because Red = R is equal to Red = R (by definition), we have S = (R eM)d\n= RM d. To obtain M d, we simply divide S by R, as follows, to obtain the\nsignature:\nS/R = RM d/R = M d\nAs you can see, this is a practical and powerful attack.\nThe PSS Signature Standard\nThe RSA Probabilistic Signature Scheme (PSS) is to RSA signatures what\nOAEP is to RSA encryption. It was designed to make message signing\nmore secure, thanks to the addition of padding data.\nAs shown in Figure 10-3, PSS combines a message narrower than the\nmodulus with some random and fixed bits before RSAing the results of\nthis padding process.\nFigure 10-3: Signing a message, M, with RSA and with the PSS standard, where (n,\nd) is the private key\nLike all public-key signature schemes, PSS works on a message’s hash\nrather than on the message itself. Signing Hash(M) is secure as long as\nthe hash function is collision resistant. One particular benefit of PSS is\nthat you can use it to sign messages of any length, because after hashing a\nmessage, you’ll obtain a hash value of the same length regardless of the\nmessage’s original length. The hash’s length is typically 256 bits, with the\nhash function SHA-256.\nWhy not sign by just running OAEP on Hash(M)? Unfortunately, you\ncan’t. Although similar to PSS, OAEP has only been proven secure for\nencryption, not for signature.\nLike OAEP, PSS also requires a PRNG and two hash functions. One,\nHash1, is a typical hash with h-byte hash values such as SHA-256. The\nother, Hash2, is a wide-output hash like OAEP’s Hash2.\nThe PSS signing procedure for message M works as follows (where h is\nHash1’s output length):\n1. Pick an r-byte random string R using the PRNG.\n2. Form an encoded message M′ = 0000000000000000 || Hash1(M)\n|| R, long of h + r + 8 bytes (with eight zero bytes at the beginning).\n3. Compute the h-byte string H = Hash1(M′).\n4. Set L = 00 . . . 00 || 01 || R, or a sequence of 00 bytes followed by a\n01 byte and then R, with a number of 00 bytes such that L is long of\nm – h – 1 bytes (the byte width m of the modulus minus the hash\nlength h minus 1).\n5. Set L = L ⊕ Hash2(H), thus replacing the previous value of L with a\nnew value.\n6. Convert the m-byte string P = L || H || BC to a number, x, lower\nthan n. Here, the byte BC is a fixed value appended after H.\n7. Given the value of x just obtained, compute the RSA function xd\nmod n to obtain the signature.\nTo verify a signature given a message, M, you compute Hash1(M) and\nuse the public exponent e to retrieve L and H and then M′ from the\nsignature, checking the padding’s correctness at each step.\nIn practice, the random string R (called a salt in the RSA-PSS standard)\nis usually as long as the hash value. For example, if you use n = 2048 bits\nand SHA-256 as the hash, the value L is long of m – h – 1 = 256 – 32 – 1\n=223 bytes, and the random string R would typically be 32 bytes.\nLike OAEP, PSS is provably secure, standardized, and widely\ndeployed. Also like OAEP, it looks needlessly complex and is prone to\nimplementation errors and mishandled corner cases. But unlike RSA\nencryption, there’s a way to get around this extra complexity with a\nsignature scheme that doesn’t even need a PRNG, thus reducing the risk\nof insecure RSA signatures caused by an insecure PRNG, as discussed\nnext.\nFull Domain Hash Signatures\nFull Domain Hash (FDH) is the simplest signature scheme you can\nimagine. To implement it, you simply convert the byte string Hash(M) to\na number, x, and create the signature y = xd mod n, as shown in Figure\n10-4.\nFigure 10-4: Signing a message with RSA using the Full Domain Hash technique\nSignature verification is straightforward, too. Given a signature that is a\nnumber y, you compute x = ye mod n and compare the result with\nHash(M). It’s boringly simple, deterministic, yet secure. So why bother\nwith the complexity of PSS?\nThe main reason is that PSS was released after FDH, in 1996, and it\nhas a security proof that inspires more confidence than FDH.\nSpecifically, its proof offers slightly higher security guarantees than the\nproof of FDH, and its use of randomness helped strengthen that proof.\nThese stronger theoretical guarantees are the main reason\ncryptographers prefer PSS over FDH, but most applications using PSS\ntoday could switch to FDH with no meaningful security loss. In some\ncontexts, however, a viable reason to use PSS instead of FDH is that\nPSS’s randomness protects it from some attacks on its implementation,\nsuch as the fault attacks we’ll discuss in “How Things Can Go Wrong”\non page 196.\nRSA Implementations\nI sincerely hope you’ll never have to implement RSA from scratch. If\nyou’re asked to, run as fast as you can and question the sanity of the\nperson who asked you to do so. It took decades for cryptographers and\nengineers to develop RSA implementations that are fast, sufficiently\nsecure, and hopefully free of debilitating bugs, so you really don’t want to\nreinvent RSA. Even with all the documentation available, it would take\nmonths to complete this daunting task.\nTypically, when implementing RSA, you’ll use a library or API that\nprovides the necessary functions to carry out RSA operations. For\nexample, the Go language has the following function in its crypto package\n(from https://www.golang.org/src/crypto/rsa/rsa.go):\nfunc EncryptOAEP(hash hash.Hash, random io.Reader, pub *PublicKey, msg\n[]byte,\nlabel []byte) (out []byte, err error)\nThe function EncryptOAEP() takes a hash value, a PRNG, a public key, a\nmessage, and a label (an optional parameter of OAEP), and returns a\nsignature and an error code. When you call EncryptOAEP(), it calls\nencrypt() to compute the RSA function given the padded data, as shown\nin Listing 10-3.\nfunc encrypt(c *big.Int, pub *PublicKey, m *big.Int) *big.Int {\ne := big.NewInt(int64(pub.E))\nc.Exp(m, e, pub.N)\nreturn c\n}\nListing 10-3: Implementing the core RSA encryption function from the Go language\ncryptography library\nThe main operation shown in Listing 10-3 is c.Exp(m, e, pub.N), which\nraises a message, m, to the power e modulo pub.N, and assigns the result to\nthe variable c.\nIf you choose to implement RSA instead of using a readily available\nlibrary function, be sure to rely on an existing big-number library, which is\na set of functions and types that allow you to define and compute\narithmetic operations on large numbers thousands of bits long. For\nexample, you might use the GNU Multiple Precision (GMP) arithmetic\nlibrary in C, or Go’s big package. (Believe me, you don’t want to\nimplement big-number arithmetic yourself.)\nEven if you just use a library function when implementing RSA, be sure\nthat you understand how the internals work in order to measure the risks.\nFast Exponentiation Algorithm: Square-and-Multiply\nThe operation of raising x to the power e, when computing xe mod n, is\ncalled exponentiation. When we’re working with big numbers, as with\nRSA, this operation can be extremely slow if naively implemented. But\nhow do we do this efficiently?\nThe naive way to compute xe mod n takes e – 1 multiplications, as\nshown in the pseudocode algorithm in Listing 10-4.\nexpModNaive(x, e, n) {\ny = x\nfor i = 1 to e – 1 {\ny = y * x mod n\n}\nreturn y\n}\nListing 10-4: A naive exponentiation algorithm in pseudocode\nThis algorithm is simple but highly inefficient. One way to get the\nsame result exponentially faster is to square rather than multiply\nexponents until the correct value is reached. This family of methods is\ncalled square-and-multiply, or exponentiation by squaring or binary\nexponentiation.\nFor example, say that we want to compute 365537 mod\n36567232109354321. (The number 65537 is the public exponent used in\nmost RSA implementations.) We could multiply the number 3 by itself\n65536 times, or we could approach this problem with the understanding\nthat 65537 can be written as 216 + 1 and use a series of squaring\noperations. Essentially, we do the following:\nInitialize a variable, y = 3, and then compute the following squaring (y2)\noperations:\n1. Set y = y2 mod n (now y = 32 mod n).\n2. Set y = y2 mod n (now y = (32)2 mod n = 34 mod n).\n3. Set y = y2 mod n (now y = (34)2 = 38 mod n).\n4. Set y = y2 mod n (now y = (38)2 = 316 mod n).\n5. Set y = y2 mod n (now y = (316)2= 332 mod n).\nAnd so on until y = 365536, by performing 16 squarings.\nTo get the final result, we return 3 × y mod n = 365537 mod n =\n26652909283612267. In other words, we compute the result with only 17\nmultiplications rather than 65536 with the naive method.\nMore generally, a square-and-multiply method works by scanning the\nexponent’s bits one by one, from left to right, computing the square for\neach exponent’s bit to double the exponent’s value, and multiplying by\nthe original number for each bit with a value of 1 encountered. In the\npreceding example, the exponent 65537 is 10000000000000001 in binary,\nand we squared y for each new bit and multiplied by the original number\n3 only for the very first and last bits.\nListing 10-5 shows how this would work as a general algorithm in\npseudocode to compute xe mod n when the exponent e consists of bits e\nm –\ne . . . e e , where e is the least significant bit.\n1 m – 2 1 0 0\nexpMod(x, e, n) {\ny = x\nfor i = m – 1 to 0 {\ny = y * y mod n\nif e == 1 then\ni\ny = y * x mod n\n}\nreturn y\n}\nListing 10-5: A fast exponentiation algorithm in pseudocode\nThe expMod() algorithm shown in Listing 10-5 runs in time O(m),\nwhereas the naive algorithm runs in time O(2m), where m is the bit length\nof the exponent. Here, O() is the asymptotic complexity notation\nintroduced in Chapter 9.\nReal systems often implement variants of this simplest square-and-\nmultiply method. One such variant is the sliding window method, which\nconsiders blocks of bits rather than individual bits to perform a given\nmultiplication operation. For example, see the function expNN() of the Go\nlanguage, whose source code is available at\nhttps://golang.org/src/math/big/nat.go.\nHow secure are these square-and-multiply exponentiation algorithms?\nUnfortunately, the tricks to speed the process up often result in increased\nvulnerability against some attacks. Let’s see what can go wrong.\nThe weakness in these algorithms is due to the fact that the\nexponentiation operations are heavily dependent on the exponent’s value.\nThe if operation shown in Listing 10-5 takes a different branch based on\nwhether an exponent’s bit is 0 or 1. If a bit is 1, an iteration of the for\nloop will be slower than it will be for 0, and attackers who monitor the\nexecution time of the RSA operation can exploit this time difference to\nrecover a private exponent. This is called a timing attack. Attacks on\nhardware can distinguish 1 bit from 0 bits by monitoring the device’s\npower consumption and observing which iterations perform an extra\nmultiplication to reveal which bits of the private exponent are 1.\nOnly a minority of cryptographic libraries implement effective defenses\nagainst timing attacks, let alone against such power-analysis attacks.\nSmall Exponents for Faster Public-Key Operations\nBecause an RSA computation is essentially the computation of an\nexponentiation, its performance depends on the value of the exponents\nused. Smaller exponents require fewer multiplications and therefore can\nmake the exponentiation computation much faster.\nThe public exponent e can in principle be any value between 3 and φ(n)\n– 1, as long as e and φ(n) are co-prime. But in practice you’ll only find\nsmall values of e, and most of the time e = 65537 due to concerns with\nencryption and signature verification speed. For example, the Microsoft\nWindows CryptoAPI only supports public exponents that fit in a 32-bit\ninteger. The larger the e, the slower it is to compute xe mod n.\nUnlike the size of the public exponent, the private exponent d will be\nabout as large as n, making decryption much slower than encryption, and\nsigning much slower than verification. Indeed, because d is secret, it must\nbe unpredictable and therefore can’t be restricted to a small value. For\nexample, if e is fixed to 65537, the corresponding d will usually be of the\nsame order of magnitude as the modulus n, which would be close to 22048\nif n is 2048 bits long.\nAs discussed in “Fast Exponentiation Algorithm: Square-and-Multiply”\non page 192, raising a number to the power 65537 will only take 17\nmultiplications, whereas raising a number to the power of some 2048-bit\nnumber will take on the order of 3000 multiplications.\nOne way to determine the actual speed of RSA is to use the OpenSSL\ntoolkit. For example, Listing 10-6 shows the results of 512-, 1024-, 2048-\n, and 4096-bit RSA operations on my MacBook, which is equipped with\nan Intel Core i5-5257U clocked at 2.7 GHz.\n$ openssl speed rsa512 rsa1024 rsa2048 rsa4096\nDoing 512 bit private rsa's for 10s: 161476 512 bit private RSA's in\n9.59s\nDoing 512 bit public rsa's for 10s: 1875805 512 bit public RSA's in 9.68s\nDoing 1024 bit private rsa's for 10s: 51500 1024 bit private RSA's in\n8.97s\nDoing 1024 bit public rsa's for 10s: 715835 1024 bit public RSA's in\n8.45s\nDoing 2048 bit private rsa's for 10s: 13111 2048 bit private RSA's in\n9.65s\nDoing 2048 bit public rsa's for 10s: 288772 2048 bit public RSA's in\n9.68s\nDoing 4096 bit private rsa's for 10s: 1273 4096 bit private RSA's in\n9.71s\nDoing 4096 bit public rsa's for 10s: 63987 4096 bit public RSA's in 8.50s\nOpenSSL 1.0.2g 1 Mar 2016\n--snip--\nsign verify sign/s verify/s\nrsa 512 bits 0.000059s 0.000005s 16838.0 193781.5\nrsa 1024 bits 0.000174s 0.000012s 5741.4 84714.2\nrsa 2048 bits 0.000736s 0.000034s 1358.7 29831.8\nrsa 4096 bits 0.007628s 0.000133s 131.1 7527.9\nListing 10-6: Benchmarks of RSA operations using the OpenSSL toolkit\nHow much slower is verification compared to signature generation? To\nget an idea, we can compute the ratio of the verification time over\nsignature time. The benchmarks in Listing 10-6 show that I’ve got\nverification-over-signature speed ratios of approximately 11.51, 14.75,\n21.96, and 57.42 for 512-, 1024-, 2048-, and 4096-bit moduli sizes,\nrespectively. The gap grows with the modulus size because the number of\nmultiplications for e operations will remain constant with respect to the\nmodulus size (for example, 17 when e = 65537), while private-key\noperations will always need more multiplications for a greater modulus\nbecause d will grow accordingly.\nBut if small exponents are so nice, why use 65537 and not something\nlike 3? It would actually be fine (and faster) to use 3 as an exponent when\nimplementing RSA with a secure scheme such as OAEP, PSS, or FDH.\nCryptographers avoid doing so, however, because when e = 3, less secure\nschemes make certain types of mathematical attacks possible. The\nnumber 65537 is large enough to avoid such low-exponent attacks, and it\nhas just one instance in which a bit is 1, thanks to its low Hamming\nweight, which decreases the computational time. 65537 is also special for\nmathematicians: it’s the fourth Fermat number, or a number of the form\n2(2n) + 1\nbecause it’s equal to 216 + 1, where 16 = 24, but that’s just a curiosity\nmostly irrelevant for cryptographic engineers.\nThe Chinese Remainder Theorem\nThe most common trick to speed up decryption and signature verification\n(that is, the computation of yd mod n) is the Chinese remainder theorem\n(CRT). It makes RSA about four times faster.\nThe Chinese remainder theorem allows for faster decryption by\ncomputing two exponentiations, modulo p and modulo q, rather than\nsimply modulo n. Because p and q are much smaller than n, it’s faster to\nperform two “small” exponentiations than a single “big” one.\nThe Chinese remainder theorem isn’t specific to RSA. It’s a general\narithmetic result that, in its simplest form, states that if n = n n n . . . ,\n1 2 3\nwhere the n s are pairwise co-prime (that is, GCD(n , n) = 1 for any\ni i j\ndistinct i and j), then the value x mod n can be computed from the values\nx mod n , x mod n , x mod n , . . . . For example, say we have n = 1155,\n1 2 3\nwhich we write as the product of prime factors 3 × 5 × 7 × 11. We want to\ndetermine the number x that satisfies x mod 3 = 2, x mod 5 = 1, x mod 7 =\n6, and x mod 11 = 8. (I’ve chosen 2, 1, 6, and 8 arbitrarily.)\nTo find x using the Chinese remainder theorem, we can compute the\nsum P(n ) + P(n ) + . . . , where P(n ) is defined as follows:\n1 2 i\nP(n ) = (x mod n ) × n / n × (1 / (n / n ) mod n ) mod n\ni i i i i\nNote that the second term, n/n , is equal to the product of all other\ni\nfactors than this n .\ni\nTo apply this formula to our example and recover our x mod 1155, we\ntake the arbitrary values 2, 1, 6, and 8; we compute P(3), P(5), P(7), and\nP(8); and then we add them together to get the following expression:\nHere, I’ve just applied the preceding definition of P(n ). (The math\ni\nbehind the way each number was found is straightforward, but I won’t\ndetail it here.) This expression can then be reduced to [770 + 231 + 1980\n+ 1680] mod n = 41, and indeed 41 is the number I had picked for this\nexample, so we’ve got the correct result.\nApplying the CRT to RSA is simpler than the previous example,\nbecause there are only two factors for each n (namely p and q). Given a\nciphertext y to decrypt, instead of computing yd mod n, you use the CRT\nto compute x = ys mod p, where s = d mod (p – 1) and x = yt mod q, where\np q\nt = d mod (q – 1). You now combine these two expressions and compute x\nto be the following:\nx = x × q × (1/q mod p) + x × p × (1/p mod q) mod n\np q\nAnd that’s it. This is faster than square-and-multiply because the\nmultiplication-heavy operations are carried out on modulo p and q,\nnumbers that are twice as small as n.\nNOTE\nIn the final operation, the two numbers q × (1/q mod p) and p × (1/p mod\nq) can be computed in advance, which means only two multiplications and an\naddition of modulo n need to be computed to find x.\nUnfortunately, there’s a security caveat attached to these techniques, as\nI’ll discuss next.\nHow Things Can Go Wrong\nEven more beautiful than the RSA scheme itself is the range of attacks\nthat work either because the implementation leaks (or can be made to\nleak) information on its internals or because RSA is used insecurely. I\ndiscuss two classic examples of these types of attacks in the sections that\nfollow.\nThe Bellcore Attack on RSA-CRT\nThe Bellcore attack on RSA is one of the most important attacks in the\nhistory of RSA. When first discovered in 1996, it stood out because it\nexploited RSA’s vulnerability to fault injections—attacks that force a part\nof the algorithm to misbehave and thus yield incorrect results. For\nexample, hardware circuits or embedded systems can be temporarily\nperturbed by suddenly altering their voltage supply or by beaming a laser\npulse to a carefully chosen part of a chip. Attackers can then exploit the\nresulting faults in an algorithm’s internal operation by observing the\nimpact on the final result. For example, comparing the correct result with\na faulty one can provide information on the algorithm’s internal values,\nincluding secret values.\nThe Bellcore attack is such a fault attack. It works on RSA signature\nschemes that use the Chinese remainder theorem and that are\ndeterministic—meaning that it works on FDH, but not on PSS, which is\nprobabilistic.\nTo understand how the Bellcore attack works, recall from the previous\nsection that with CRT, the result that is equal to xd mod n is obtained by\ncomputing the following, where x = ys mod p and x = yt mod q:\np q\nx = x × q × (1/q mod p) + x × p × (1/p mod q) mod n\np q\nNow assume that an attacker induces a fault in the computation of x so\nq\nthat you end up with some incorrect value, which differs from the actual\nx . Let’s call this incorrect value x ′ and call the final result obtained x′.\nq q\nThe attacker can then subtract the incorrect signature x′ from the correct\nsignature x to factor n, which results in the following:\nx − x′ = (x − x ) × p × (1/p mod q) mod n\nq q′\nThe value x – x′ is therefore a multiple of p, so p is a divisor of x – x′.\nBecause p is also a divisor of n, the greatest common divisor of n and x – x\n′ yields p, GCD(x – x′, n) = p. We can then compute q = n/p and d,\nresulting in a total break of RSA signatures.\nA variant of this attack works when you don’t know the correct\nsignature but only know the message is signed. There’s also a similar fault\nattack on the modulus value, rather than on the CRT values computation,\nbut I won’t go into detail on that here.\nSharing Private Exponents or Moduli\nNow I’ll show you why your public key shouldn’t have the same modulus\nn as that of someone else.\nDifferent private keys belonging to different systems or persons should\nobviously have different private exponents, d, even if the keys use\ndifferent moduli, or you could try your own value of d to decrypt\nmessages encrypted for other entities, until you hit one that shares the\nsame d. By the same token, different key pairs should have different n\nvalues, even if they have different ds, because p and q are usually part of\nthe private key. Hence, if we share the same n and thus the same p and q,\nI can compute your private key from your public key e using p and q.\nWhat if my private key is simply the pair (n, d ), and your private key is\n1\n(n, d ) and your public key is (n, e )? Say that I know n but not p and q, so\n2 2\nI can’t directly compute your private exponent d from your public\n2\nexponent e . How would you compute p and q from a private exponent d\n2\nonly? The solution is a bit technical, but elegant.\nRemember that d and e satisfy ed = kφ(n) + 1, where φ(n) is secret and\ncould give us p and q directly. We don’t know k or φ(n), but we can\ncompute kφ(n) = ed – 1.\nWhat can we do with this value kφ(n)? A first observation is that,\naccording to Euler’s theorem, we know that for any number a co-prime\nwith n, aφ( ) = 1 mod n. Therefore, modulo n we have the following:\nN\nakφ(n) = (aφ(n))k = 1k = 1\nA second observation is that, because kφ(n) is an even number, we can\nwrite it as 2st for some numbers s and t. That is, we’ll be able to write\nakφ(n) = 1 mod n under the form x2 = 1 mod n for some x easily computed\nfrom kφ(n). Such an x is called a root of unity.\nThe key observation is that x2 = 1 mod n is equivalent to saying that the\nvalue x2 – 1 = (x – 1)(x + 1) divides n. In other words, x – 1 or x + 1 must\nhave a common factor with n, which can give us the factorization of n.\nListing 10-7 shows a Python implementation of this method where, in\norder to find the factors p and q from n and d, we use small, 64-bit\nnumbers for the sake of simplicity.\nfrom math import gcd\nn = 36567232109354321\ne = 13771927877214701\nd = 15417970063428857\n❶ kphi = d*e - 1\nt = kphi\n❷ while t % 2 == 0:\nt = divmod(t, 2)[0]\n❸ a = 2\nwhile a < 100:\n❹ k = t\nwhile k < kphi:\nx = pow(a, k, n)\n❺ if x ! = 1 and x ! = (n - 1) and pow(x, 2, n) == 1:\n❻ p = gcd(x - 1, n)\nbreak\nk = k*2\na = a + 2\nq = n//p\n❼ assert (p*q) == n\nprint('p = ', p)\nprint('q = ', q)\nListing 10-7: A python program that computes the prime factors p and q from the\nprivate exponent d\nThis program determines kφ(n) from e and d ❶ by finding the number\nt such that kφ(n) = 2st, for some s ❷. Then it looks for a and k such that\n(ak)2 = 1 mod n ❸, using t as a starting point for k ❹. When this condition\nis satisfied ❺, we’ve found a solution. It then determines the factor p ❻\nand verifies ❼ that the value of pq equals the value of n. It then prints the\nresulting values of p and q:\np = 2046223079\nq = 17870599\nThe program correctly returns the two factors.\nFurther Reading\nRSA deserves a book by itself. I had to omit many important and\ninteresting topics, such as Bleichenbacher’s padding oracle attack on\nOAEP’s predecessor (the standard PKCS#1 v1.5), an attack similar in\nspirit to the padding oracle attack on block ciphers seen in Chapter 4.\nThere’s also Wiener’s attack on RSA with low private exponents, and\nattacks using Coppersmith’s method on RSA with small exponents that\npotentially also have insecure padding.\nTo see research results related to side-channel attacks and defenses,\nview the CHES workshop proceedings that have run since 1999 at\nhttp://www.chesworkshop.org/. One of the most useful references while\nwriting this chapter was Boneh’s “Twenty Years of Attacks on the RSA\nCryptosystem,” a survey that reviews and explains the most important\nattacks on RSA. For reference specifically on timing attacks, the paper\n“Remote Timing Attacks Are Practical” by Brumley and Boneh, is a\nmust-read, both for its analytical and experimental contributions. To\nlearn more about fault attacks, read the full version of the Bellcore attack\npaper “On the Importance of Eliminating Errors in Cryptographic\nComputations” by Boneh, DeMillo, and Lipton.\nThe best way to learn how RSA implementations work, though\nsometimes painful and frustrating, is to review the source code of widely\nused implementations. For example, see RSA and its underlying big-\nnumber arithmetic implementations in OpenSSL, in NSS (the library\nused by the Mozilla Firefox browser), in Crypto++, or in other popular\nsoftware, and examine their implementations of arithmetic operations as\nwell as their defenses against timing and fault attacks."
  },
  {
    "input": "What is the Diffie-Hellman (DH) protocol and how does it enable secure key agreement between two parties?",
    "summary": "The Diffie-Hellman (DH) protocol, introduced in 1976, allows two parties to securely establish a shared secret over an insecure channel. It relies on the difficulty of solving the discrete logarithm problem and is used in key agreement protocols to create symmetric keys for encryption and authentication. However, DH is vulnerable to attacks if its parameters are not carefully chosen, and its security depends on the hardness of the computational Diffie-Hellman (CDH) and decisional Diffie-Hellman (DDH) problems.",
    "output": "11\nDIFFIE–HELLMAN\nIn November 1976, Stanford researchers Whitfield Diffie and Martin\nHellman published a research paper titled “New Directions in\nCryptography” that revolutionized cryptography forever. In their paper,\nthey introduced the notion of public-key encryption and signatures,\nthough they didn’t actually have any of those schemes; they simply had\nwhat they termed a public-key distribution scheme, a protocol that allows\ntwo parties to establish a shared secret by exchanging information visible\nto an eavesdropper. This protocol is now known as the Diffie–Hellman\n(DH) protocol.\nPrior to Diffie–Hellman, establishing a shared secret required\nperforming tedious procedures such as manually exchanging sealed\nenvelopes. Once communicating parties have established a shared secret\nvalue with the DH protocol, that secret can be used to establish a secure\nchannel by turning the secret into one or more symmetric keys that are\nthen used to encrypt and authenticate subsequent communication. The\nDH protocol—and its variants—are therefore called key agreement\nprotocols.\nIn the first part of this chapter, I review the mathematical foundations\nof the Diffie–Hellman protocol, including the computational problems\nthat DH relies on to perform its magic. I then describe different versions\nof the Diffie–Hellman protocol used to create secure channels in the\nsecond part of this chapter. Finally, because Diffie–Hellman schemes are\nonly secure when their parameters are well chosen, I conclude the chapter\nby examining scenarios where Diffie–Hellman can fail.\nNOTE\nDiffie and Hellman received the prestigious Turing Award in 2015 for their\ninvention of public-key cryptography and digital signatures, but others\ndeserve credit as well. In 1974, two years before the seminal Diffie–Hellman\npaper, computer scientist Ralph Merkle introduced the idea of public-key\ncryptography with what are now called Merkle’s puzzles. Around that same\nyear, researchers at GCHQ (Government Communications Headquarters),\nthe British equivalent of the NSA, had also discovered the principles behind\nRSA and Diffie–Hellman key agreement, though that fact would only be\ndeclassified decades later.\nThe Diffie–Hellman Function\nIn order to understand DH key agreement protocols, you must first\nunderstand their core operation, the DH function. The DH function will\nusually work with groups denoted Z *. Recall from Chapter 9 that these\np\ngroups are formed of nonzero integer numbers modulo a prime number,\ndenoted p. Another public parameter is the base number, g. All arithmetic\noperations are performed modulo p.\nThe DH function involves two private values chosen randomly by the\ntwo communicating parties from the group Z *, denoted a and b. A\np\nprivate value a has a public value associated with A = ga mod p, or g raised\nto the power a modulo p. This value is sent to the other party through a\nmessage that is visible to eavesdroppers. The public value associated with\nb is B = gb mod p, or g raised to the power b modulo p, which is sent to the\nowner of a through a publicly readable message.\nDH works its magic by combining either public value with the other\nprivate value, such that the result is the same in both cases: Ab = (ga)b = gab\nand B a = (gb)a = gba = gab. The resulting value, gab, is the shared secret; it is\nthen passed to a key derivation function (KDF) in order to generate one or\nmore shared symmetric keys. A KDF is a kind of hash function that will\nreturn a random-looking string the size of the desired key length.\nAnd that’s it. Like many great scientific discoveries (gravity, relativity,\nquantum computing, or RSA), the Diffie–Hellman trick is terribly simple\nin hindsight.\nDiffie–Hellman’s simplicity can be deceiving, however. For one thing,\nit won’t work with just any prime p or base number g. For example, some\nvalues of g will restrict the shared secrets gab to a small subset of possible\nvalues, whereas you’d expect to have about as many possible values as\nelements in Z *, and therefore as many possible values for the shared\np\nsecret. To ensure the highest security, safe DH parameters should work\nwith a prime p such that (p – 1) / 2 is also prime. Such a safe prime\nguarantees that the group doesn’t have small subgroups that would make\nDH easier to break. With a safe prime, DH can notably work with g = 2,\nwhich makes computations slightly faster. But generating a safe prime p\ntakes more time than generating a totally random prime.\nFor example, the dhparam command of the OpenSSL toolkit will only\ngenerate safe DH parameters, but the extra checks built into the\nalgorithm result increase the execution time considerably, as shown in\nListing 11-1.\n$ time openssl dhparam 2048\nGenerating DH parameters, 2048 bit long safe prime, generator 2\nThis is going to take a long time\n--snip--\n-----BEGIN DH PARAMETERS-----\nMIIBCAKCAQEAoSIbyA9e844q7V89rcoEV8vd/l2svwhIIjG9EPwWWr7FkfYhYkU9\nfRNttmilGCTfxc9EDf+4dzw+AbRBc6oOL9gxUoPnOd1/G/YDYgyplF5M3xeswqea\nSD+B7628pWTaCZGKZham7vmiN8azGeaYAucckTkjVWceHVIVXe5fvU74k7+C2wKk\niiyMFm8th2zm9W/shiKNV2+SsHtD6r3ZC2/hfu7XdOI4iT6ise83YicU/cRaDmK6\nzgBKn3SlCjwL4M3+m1J+Vh0UFz/nWTJ1IWAVC+aoLK8upqRgApOgHkVqzP/CgwBw\nXAOE8ncQqroJ0mUSB5eLqfpAvyBWpkrwQwIBAg==\n-----END DH PARAMETERS-----\nopenssl dhparam 2048 154.53s user 0.86s system 99% cpu 2:36.85 total\nListing 11-1: Measuring the execution time of generating 2048-bit Diffie–Hellman\nparameters with the OpenSSL toolkit\nAs you can see in Listing 11-1, it took 154.53 seconds to generate the\nDH parameters using the OpenSSL toolkit. Now, for the sake of\ncomparison, Listing 11-2 shows how long it takes on the same system to\ngenerate RSA parameters of the same size (that is, two prime numbers, p\nand q, each half the size of the p used for DH).\n$ time openssl genrsa 2048\nGenerating RSA private key, 2048 bit long modulus\n...................................................+++\n.............................................................+++\ne is 65537 (0x10001)\n-----BEGIN RSA PRIVATE KEY-----\n--snip--\n-----END RSA PRIVATE KEY-----\nopenssl genrsa 2048 0.16s user 0.01s system 95% cpu 0.171 total\nListing 11-2: Generating 2048-bit RSA parameters while measuring the execution\ntime\nGenerating DH parameters took about 1000 times longer than\ngenerating RSA parameters of the same security level, mainly due to the\nextra constraint imposed on the prime generated to create DH\nparameters.\nThe Diffie–Hellman Problems\nThe security of DH protocols relies on the hardness of computational\nproblems, especially on that of the discrete logarithm problem (DLP)\nintroduced in Chapter 9. Clearly, DH can be broken by recovering the\nprivate value a from its public value ga, which boils down to solving a\nDLP instance. But we don’t care only about the discrete logarithm\nproblem when using DH to compute shared secrets. We also care about\ntwo DH-specific problems, as explained next.\nThe Computational Diffie–Hellman Problem\nThe computational Diffie–Hellman (CDH) problem is that of computing\nthe shared secret gab given only the public values ga and gb, and not any of\nthe secret values a or b. The motivation is obviously to ensure that even if\nan eavesdropper captures ga and gb, they should not be able to determine\nthe shared secret gab.\nIf you can solve DLP, then you can also solve CDH; to put it simply, if\nyou can solve DLP, then given ga and gb, you’ll be able to derive a and b\nto compute gab. In other words, DLP is at least as hard as CDH. But we\ndon’t know for sure whether CDH is at least as hard as DLP, which\nwould make the problems equally hard. In other words, DLP is to CDH\nwhat the factoring problem is to the RSA problem. (Recall that factoring\nallows you to solve the RSA problem, but not necessarily the converse.)\nDiffie–Hellman shares another similarity with RSA in that DH will\ndeliver the same security level as RSA for a given modulus size. For\nexample, the DH protocol with a 2048-bit prime p will get you about the\nsame security that RSA with a 2048-bit modulus n offers, which is about\n90 bits. Indeed, the fastest way we know to break CDH is to solve DLP\nusing an algorithm called the number field sieve, a method similar but not\nidentical to the fastest one that breaks RSA by factoring its modulus: the\ngeneral number field sieve (GNFS).\nThe Decisional Diffie–Hellman Problem\nSometimes we need something stronger than CDH’s hardness\nassumption. For example, imagine that an attacker can compute the first\n32 bits of gab given the 2048-bit values of ga and gb, but that they can’t\ncompute all 2048 bits. Although CDH would still be unbroken because\n32 bits aren’t enough to completely recover gab, the attacker would still\nhave learned something about the shared secret, which might still allow\nthem to compromise an application’s security.\nTo ensure that an attacker can’t learn anything about the shared secret\ngab, this value needs only to be indistinguishable from a random group\nelement, just as an encryption scheme is secure when ciphertexts are\nindistinguishable from random strings. The computational problem\nformalizing this intuition is called the decisional Diffie–Hellman (DDH)\nproblem. Given ga, gb, and a value that is either gab or gc for some random\nc (each of the two with a chance of 1/2), the DDH problem consists of\ndetermining whether gab (the shared secret corresponding to ga and gb)\nwas chosen. The assumption that no attacker can solve DDH efficiently is\ncalled the decisional Diffie–Hellman assumption.\nIf DDH is hard, then CDH is also hard, and you can’t learn anything\nabout gab. But if you can solve CDH, you can also solve DDH: given a\ntriplet (ga, gb, gc), you would be able to derive gab from ga and gb and check\nwhether the result is equal to the given gc. The bottom line is that DDH\nis fundamentally less hard than CDH, yet DDH hardness is a prime\nassumption in cryptography, and one of the most studied. We can be\nconfident that both CDH and DDH are hard when Diffie–Hellman\nparameters are well chosen.\nMore Diffie–Hellman Problems\nSometimes cryptographers devise new schemes and prove that they are at\nleast as hard to break as it is to solve some problem related to CDH or\nDDH but not identical to either of these. Ideally, we’d like to\ndemonstrate that breaking a cryptosystem is as hard as solving CDH or\nDDH, but this isn’t always possible with advanced cryptographic\nmechanisms, typically because such schemes involve more complex\noperations than basic Diffie–Hellman protocols.\nFor example, in one DH-like problem, given ga, an attacker would\nattempt to compute g1 / a, where 1 / a is the inverse of a in the group\n(typically Z * for some prime p). In another, an attacker might distinguish\np\nthe pairs (ga, gb) from the pairs (ga, g1 / a) for random a and b. Finally, in\nwhat is called the twin Diffie–Hellman problem, given ga, gb, and gc, an\nattacker would attempt to compute the two values gab and gac. Sometimes\nsuch DH variants turn out to be as hard as CDH or DDH, and\nsometimes they’re fundamentally easier—and therefore provide lower\nsecurity guarantees. As an exercise, try to find connections between the\nhardness of these problems and that of CDH and DDH. (Twin Diffie–\nHellman is actually as hard as CDH, but that isn’t easy to prove!)\nKey Agreement Protocols\nThe Diffie–Hellman problem is designed to build secure key agreement\nprotocols—protocols designed to secure communication between two or\nmore parties communicating over a network with the aid of a shared\nsecret. This secret is turned into one or more session keys—symmetric keys\nused to encrypt and authenticate the information exchanged for the\nduration of the session. But before studying actual DH protocols, you\nshould know what makes a key agreement protocol secure or insecure,\nand how simpler protocols work. We’ll begin our discussion with a widely\nused key agreement protocol that doesn’t rely on DH.\nAn Example of Non-DH Key Agreement\nTo give you a sense of how a key agreement protocol works and what it\nmeans for it to be secure, let’s look at the protocol used in the 3G and 4G\ntelecommunications standards to establish communication between a\nSIM card and a telecom operator. The protocol is often referred to as\nAKA, for authenticated key agreement. It doesn’t use the Diffie–Hellman\nfunction, but instead uses only symmetric-key operations. The details are\na bit boring, but essentially the protocol works as shown in Figure 11-1.\nFigure 11-1: The authenticated key agreement protocol in 3G and 4G\ntelecommunication\nIn this implementation of the protocol, the SIM card has a secret key,\nK, that the operator knows. The operator begins the session by selecting a\nrandom value, R, and then computes two values, SK and V , based on two\n1\npseudorandom functions, PRF0 and PRF1. Next, the operator sends a\nmessage to the SIM card containing the values R and V , which are visible\n1\nto attackers. Once the SIM card has R, it has what it needs in order to\ncompute SK with PRF0, and it does so. The two parties in this session\nend up with a shared key, SK, that attackers are unable to determine by\nsimply looking at the messages exchanged between the parties, or even by\nmodifying them or injecting new ones. The SIM card verifies that it’s\ntalking to the operator by recomputing V with PRF1, K, and R, and then\n1\nchecking to make sure that the calculated V matches the V sent by the\n1 1\noperator. The SIM card then computes a verification value, V , with a\n2\nnew function, PRF2, with K and R as input, and sends V to the operator.\n2\nThe operator verifies that the SIM card knows K by computing V and\n2\nchecking that the computed value matches the V it received.\n2\nBut this protocol is not immune to all kinds of attacks: in principle\nthere’s a way to fool the SIM card with a replay attack. Essentially, if an\nattacker captures a pair (R, V ), they may send it to the SIM card and\n1\ntrick the SIM into believing that the pair came from a legitimate operator\nthat knows K. To prevent this attack, the protocol includes additional\nchecks to ensure that the same R isn’t reused.\nProblems can also arise if K is compromised. For example, an attacker\nwho compromises K can perform a man-in-the-middle attack and listen\nto all cleartext communication. Such an attacker could send messages\nbetween the two parties while pretending to be both the legitimate SIM\ncard operator and the SIM card. The greater risk is that an attacker can\nrecord communications and any messages exchanged during the key\nagreement, and later decrypt those communications by using the\ncaptured R values. An attacker could then determine the past session keys\nand use them to decrypt the recorded traffic.\nAttack Models for Key Agreement Protocols\nThere is no single definition of security for key agreement protocols, and\nyou can never say that a key protocol is completely secure without\ncontext and without considering the attack model and the security goals.\nYou can, for example, argue that the previous 3G/4G protocol is secure\nbecause a passive attacker won’t find the session keys, but you could also\nargue that it’s insecure because once the key K leaks, then all previous and\nfuture communications are compromised.\nThere are different notions of security in key agreement protocols as\nwell as three main attack models that depend on the information the\nprotocol leaks. From weakest to strongest, these are the eavesdropper, the\ndata leak, and the breach:\nThe eavesdropper This attacker observes the messages exchanged\nbetween the two legitimate parties running a key agreement protocol\nand can record, modify, drop, or inject messages. To protect against an\neavesdropper, a key agreement protocol must not leak any information\non the shared secret established.\nThe data leak In this model, the attacker acquires the session key and\nall temporary secrets (such as SK in the telecom protocol example\ndiscussed previously) from one or more executions of the protocol, but\nnot the long-term secrets (like K in that same protocol).\nThe breach (or corruption) In this model, the attacker learns the\nlong-term key of one or more of the parties. Once a breach occurs,\nsecurity is no longer attainable because the attacker can impersonate\none or both parties in subsequent sessions of the protocol.\nNonetheless, the attacker shouldn’t be able to recover secrets from\nsessions executed before gathering the key.\nNow that we’ve looked at the attack models and seen what an attacker\ncan do, let’s explore the security goals—that is, the security guarantees\nthat the protocol should offer. A key agreement protocol can be designed\nto satisfy several security goals. The four most relevant ones are described\nhere, in order from simplest to most sophisticated.\nAuthentication Each party should be able to authenticate the other\nparty. That is, the protocol should allow for mutual authentication.\nAuthenticated key agreement (AKA) occurs when a protocol\na uthen​\nticates both parties.\nKey control Neither party should be able to choose the final shared\nsecret or coerce it to be in a specific subset. The 3G/4G key agreement\nprotocol discussed earlier lacks this property because the operator\nchooses the value for R that entirely determines the final shared key.\nForward secrecy This is the assurance that even if all long-term\nsecrets are exposed, shared secrets from previous executions of the\nprotocol won’t be able to be computed, even if an attacker records all\nprevious executions or is able to inject or modify messages from\nprevious executions. A forward-secret protocol guarantees that even if\nyou have to deliver your devices and their secrets to some authority or\nother, they won’t be able to decrypt your prior encrypted\ncommunications. (The 3G/4G key agreement protocol doesn’t provide\nforward secrecy.)\nResistance to key-compromise impersonation (KCI) KCI occurs\nwhen an attacker compromises a party’s long-term key and is able to\nuse it to impersonate another party. For example, the 3G/4G key\nagreement protocol allows trivial key-compromise impersonation\nbecause both parties share the same key K. A key agreement protocol\nshould ideally prevent this kind of attack.\nPerformance\nTo be useful, a key agreement protocol should be not only secure but also\nefficient. Several factors should be taken into account when considering a\nkey agreement protocol’s efficiency, including the number of messages\nexchanged, the length and number of messages, the computational effort\nto implement the protocol, and whether precomputations can be made to\nsave time. A protocol is generally more efficient if fewer, shorter\nmessages are exchanged, and it’s best if interactivity is kept minimal so\nthat neither party has to wait to receive a message before sending the next\none. A common measure of a protocol’s efficiency is its duration in terms\nof round trips, or the time it takes to send a message and receive a\nresponse.\nRound-trip time is usually the main cause of latency in protocols, but\nthe amount of computation to be carried out also counts; the fewer the\ncomputations required the better, and the more precomputations that can\nbe done in advance, the better.\nFor example, the 3G/4G key agreement protocol discussed earlier\nexchanges two messages of a few hundred bits each, which must be sent\nin a certain order. Pre-computation can be used with this protocol to save\ntime since the operator can pick many values of R in advance; precompute\nthe matching values of SK, V , and V ; and store them all in a database. In\n1 2\nthis case, precomputation has the advantage of reducing the exposure of\nthe long-term key.\nDiffie–Hellman Protocols\nThe Diffie–Hellman function is the core of most of the deployed public-\nkey agreement protocols. However, there is no single Diffie–Hellman\nprotocol, but rather a variety of ways to use the DH function in order to\nestablish a shared secret. We’ll review three of those protocols in the\nsections that follow. In each discussion, I’ll stick to the usual crypto\nplaceholder names and call the two parties Alice and Bob, and the\nattacker Eve. I’ll write g as the basis of the group used for arithmetic\noperations, a value fixed and known in advance to Alice and Bob.\nAnonymous Diffie–Hellman\nAnonymous Diffie–Hellman is the simplest of the Diffie–Hellman\nprotocols. It’s called anonymous because it’s not authenticated; the\nparticipants have no identity that can be verified by either party, and\nneither party holds a long-term key. Alice can’t prove to Bob that she’s\nAlice, and vice versa.\nIn anonymous Diffie–Hellman, each party picks a random value (a for\nAlice and b for Bob) to use as a private key, and sends the corresponding\npublic key to the other peer. Figure 11-2 shows the process in a bit more\ndetail.\nFigure 11-2: The anonymous Diffie–Hellman protocol\nAs you can see, Alice uses her exponent a and the group basis g to\ncompute A = ga, which she sends to Bob. Bob receives A and computes\nAb, which is equal to (ga)b. Bob now obtains the value gab and computes B\nfrom his random exponent b and the value g. He then sends B to Alice\nand she uses it to compute gab. Alice and Bob end up with the same value,\ngab, after performing similar operations, which involve raising both g and\nthe value received to their private exponent’s power. Pure, simple, but\nonly secure against the laziest of attackers.\nAnonymous DH can be taken down with a man-in-the-middle attack.\nAn eavesdropper simply needs to intercept messages and pretend to be\nBob (to Alice) and pretend to be Alice (to Bob), as shown in Figure 11-3.\nFigure 11-3: A man-in-the-middle attack on the anonymous Diffie–Hellman protocol\nAs in the previous exchange, Alice and Bob pick random exponents, a\nand b. Alice now computes and sends A, but Eve intercepts and drops the\nmessage. Eve then picks a random exponent, c, and computes C = gc to\nsend to Bob. Because this protocol has no authentication, Bob believes he\nis receiving C from Alice and goes on to compute gbc. Bob then computes\nB and sends that value to Alice, but Eve intercepts and drops the message\nagain. Eve now computes gbc, picks a new exponent, d, computes gad,\ncomputes D from gd, and sends D to Alice. Alice then computes gad as\nwell.\nAs a result of this attack, the attacker Eve ends up sharing a secret with\nAlice (gad) and another secret with Bob (gbc), though Alice and Bob believe\nthat they’re sharing a single secret with each other. After completing the\nprotocol execution, Alice will derive symmetric keys from gad in order to\nencrypt data sent to Bob, but Eve will intercept the encrypted messages,\ndecrypt them, and re-encrypt them to Bob using another set of keys\nderived from gbc—after potentially modifying the cleartext. All of this\nhappens with Alice and Bob unaware. That is, they’re doomed.\nTo foil this attack, you need a way to authenticate the parties so that\nAlice can prove that she’s the real Alice and Bob can prove that he’s the\nreal Bob. Fortunately, there is a way to do so.\nAuthenticated Diffie–Hellman\nAuthenticated Diffie–Hellman was developed to address the sort of man-in-\nthe-middle attacks that can affect anonymous DH. Authenticated DH\nequips the two parties with both a private and a public key, thereby\nallowing Alice and Bob to sign their messages in order to stop Eve from\nsending messages on their behalf. Here, the signatures aren’t computed\nwith a DH function, but a public-key signature scheme such as RSA-PSS.\nAs a result, in order to successfully send messages on behalf of Alice, an\nattacker would need to forge a valid signature, which is impossible with a\nsecure signature scheme.\nFigure 11-4 shows how authenticated DH works.\nFigure 11-4: The authenticated Diffie–Hellman protocol\nThe Alice (priv , pub ) label on the first line means that Alice holds her\nA B\nown private key, priv , as well as Bob’s public key, pub . This sort of\nA B\npriv/pub key pair is called a long-term key because it’s fixed in advance and\nremains constant through consecutive runs of the protocol. Of course,\nthese long-term private keys should be kept secret, while the public keys\nare considered to be known to an attacker.\nAlice and Bob begin by picking random exponents, a and b, as in\nanonymous DH. Alice then calculates A and a signature sig based on a\nA\ncombination of her signing function sign, her private key priv , and A.\nA\nNow Alice sends A and sig to Bob, who verifies sig with her public key\nA A\npub . If the signature is invalid, Bob knows that the message didn’t come\nA\nfrom Alice, and he discards A.\nIf the signature is correct, Bob will compute gab from A and his random\nexponent b. He would then compute B and his own signature from a\ncombination of the sign function, his private key priv , and B. Now he\nB\nsends B and sig to Alice, who attempts to verify sig with Bob’s public\nB B\nkey pub . Alice will only compute gab if Bob’s signature is successfully\nB\nverified.\nSecurity Against Eavesdroppers\nAuthenticated DH is secure against eavesdroppers because attackers can’t\nlearn any bit of information on the shared secret gab since they ignore the\nDH exponents. Authenticated DH also provides forward secrecy: even if\nan attacker corrupts any of the parties at some point, as in the breach\nattack model discussed earlier, they would learn the private signing keys\nbut not any of the ephemeral DH exponents; hence, they’d be unable to\nlearn the value of any previously shared secrets.\nAuthenticated DH also prevents any party from controlling the value\nof the shared secret. Alice can’t craft a special value of a in order to\npredict the value of gab because she doesn’t control b, which influences gab\nas much as a does. (One exception would be if Alice were to choose a = 0,\nin which case we’d have gab = 1 for any b. But 0 isn’t an authorized value\nand should be rejected by the protocol.)\nThat said, authenticated DH isn’t secure against all types of attack. For\none thing, Eve can record previous values of A and sig and replay them\nA\nlater to Bob, in order to pretend to be Alice. Bob will then believe that\nhe’s sharing a secret with Alice when he isn’t, even though Eve would not\nbe able to learn that secret. This risk is eliminated in practice by adding a\nprocedure called key confirmation, wherein Alice and Bob prove to each\nother that they own the shared secret. For example, Alice and Bob may\nperform key confirmation by sending respectively Hash(pub || pub , gab)\nA B\nand Hash(pub || pub , gab) for some hash function Hash; when Bob\nB A\nreceives Hash(pub || pub , gab) and Alice receives Hash(pub || pub ,\nA B B A\ngab), both can verify the correctness of these hash values using pub , pub ,\nA B\nand gab. The different order of public keys (pub || pub and pub ||\nA B B\npub ) ensures that Alice and Bob will send different values, and that an\nA\nattacker can’t pretend to be Alice by copying Bob’s hash value.\nSecurity Against Data Leaks\nAuthenticated DH’s vulnerability to data leak attackers is of greater\nconcern. In this type of attack, the attacker learns the value of ephemeral,\nshort-term secrets (namely, the exponents a and b) and uses that\ninformation to impersonate one of the communicating parties. If Eve is\nable to learn the value of an exponent a along with the matching values of\nA and sig sent to Bob, she could initiate a new execution of the protocol\nA\nand impersonate Alice, as shown in Figure 11-5.\nFigure 11-5: An impersonation attack on the authenticated Diffie–Hellman protocol\nIn this attack scenario, Eve learns the value of an a and replays the\ncorresponding A and its signature sig , pretending to be Alice. Bob\nA\nverifies the signature and computes gab from A and sends B and sig ,\nB\nwhich Eve then uses to compute gab, using the stolen a. This results in the\ntwo having a shared secret. Bob now believes he is talking to Alice.\nOne way to make authenticated DH secure against the leak of\nephemeral secrets is to integrate the long-term keys into the shared secret\ncomputation so that the shared secret can’t be determined without\nknowing the long-term secret.\nMenezes–Qu–Vanstone (MQV)\nThe Menezes–Qu–Vanstone (MQV) protocol is a milestone in the history\nof DH-based protocols. Designed in 1998, MQV had been approved to\nprotect most critical assets when the NSA included it in its Suite B, a\nportfolio of algorithms designed to protect classified information. (NSA\neventually dropped MQV, allegedly because it wasn’t used. I’ll discuss the\nreasons why in a bit.)\nMQV is Diffie–Hellman on steroids. It’s more secure than\nauthenticated DH, and it improves on authenticated DH’s performance\nproperties. In particular, MQV allows users to send only two messages,\nindependently of each other, in arbitrary order. Other benefits are that\nusers can send shorter messages than they would be able to with\nauthenticated DH, and they don’t need to send explicit signature or\nverification messages. In other words, you don’t need to use a signature\nscheme in addition to the Diffie–Hellman function.\nAs with authenticated DH, in MQV Alice and Bob each hold a long-\nterm private key as well as the long-term public key of the other party.\nThe difference is that the MQV keys aren’t signing keys: the keys used in\nMQV are composed of a private exponent, x, and a public value, gx.\nFigure 11-6 shows the operation of the MQV protocol.\nFigure 11-6: The MQV protocol\nThe x and y in Figure 11-6 are Alice and Bob’s respective long-term\nprivate keys, and X and Y are their public keys. Bob and Alice start out\nwith their own private keys and each other’s public keys, which are g to\nthe power of a private key. Each chooses a random exponent, and then\nAlice calculates A and sends it to Bob. Bob then calculates B and sends it\nto Alice. Once Alice gets Bob’s ephemeral public key B, she combines it\nwith her long-term private key x, her ephemeral private key a, and Bob’s\nlong-term public key Y by calculating the result of (B × YB)a + xA, as\ndefined in Figure 11-6. Developing this expression, we obtain the\nfollowing:\n(B × YB)a + xA = (g × (gy)B)a + xA = (gb + yB)a + xA = g(b + yB)(a + xA)\nb\nMeanwhile, Bob calculates the result of (A × XA)b + yB, and we can verify\nthat it’s equal to the value calculated by Alice:\n(A × XA)b + yB = (ga × (gx)A)b + yB = (ga + xA)b + yB = g(a + xA)(b + yB) = g(b + yB)(a +\nxA)\nAs you can see, we get the same value for both Alice and Bob, namely\ng(b + yB)(a + xA). This tells us that Alice and Bob share the same secret.\nUnlike authenticated DH, MQV can’t be broken by a mere leak of the\nephemeral secrets. Knowledge of a or b won’t let an attacker determine\nthe final shared secret because they would need the long-term private\nkeys to compute it.\nWhat happens in the strongest attack model, the breach model, where\na long-term key is compromised? If Eve compromises Alice’s long-term\nprivate key x, the previously established shared secrets are safe because\ntheir computation also involved Alice’s ephemeral private keys.\nHowever, MQV doesn’t provide perfect forward secrecy because of the\nfollowing attack. Say, for example, that Eve intercepts Alice’s A message\nand replaces it with her A = ga for some a that Eve has chosen. In the\nmeantime, Bob sends B to Alice (and Eve records B’s value) and computes\nthe shared key. If Eve later compromises Alice’s long-term private key x,\nshe can determine the key that Bob had computed during this session.\nThis breaks forward secrecy, since Eve has now recovered the shared\nsecret of a previous execution of the protocol. In practice, however, the\nrisk can be eliminated by a key-confirmation step that would have Alice\nand Bob realize that they don’t share the same key, and they would\ntherefore abort the protocol before deriving any session keys.\nDespite its elegance and security, MQV is rarely used in practice. One\nreason is because it used to be encumbered by patents, which hampered\nits widespread adoption. Another reason is that it’s harder than it looks to\nget MQV right in practice. In fact, when weighed against its increased\ncomplexity, MQV’s security benefits are often perceived as low in\ncomparison to the simpler authenticated DH.\nHow Things Can Go Wrong\nDiffie–Hellman protocols can fail spectacularly in a variety of ways. I\nhighlight some of the most common ones in the next sections.\nNot Hashing the Shared Secret\nI’ve alluded to the fact that the shared secret that concludes a DH session\nexchange (gab in our examples) is taken as input to derive session keys but\nis not a key itself. And it shouldn’t be. A symmetric key should look\nrandom, and each bit should either be 0 or 1 with the same probability.\nBut gab is not a random string; it’s a random element within some\nmathematical group whose bits may be biased toward 0 or 1. And a\nrandom group element is different from a random string of bits.\nImagine, for example, that we’re working within the multiplicative\ngroup Z * = {1, 2, 3, . . . , 12} using g = 2 as a generator of the group,\n13\nmeaning that gi spans all values of Z * for i in 1, 2, . . . 12: g1 = 2, g2 = 4,\n13\ng3 = 8, g4 = 13, and so on. If g’s exponent is random, you’ll get a random\nelement of Z *, but the encoding of a Z * element as a 4-bit string\n13 13\nwon’t be uniformly random: not all bits will have the same probability of\nbeing a 0 or a 1. In Z *, seven values have 0 as their most significant bit\n13\n(the numbers from 1 to 7 in the group), but only five have 1 as their most\nsignificant bit (from 8 to 12). That is, this bit is 0 with probability 7 / 12 ≈\n0.58, whereas, ideally, a random bit should be 0 with probability 0.5.\nMoreover, the 4-bit sequences 1101, 1110, and 1111 will never appear.\nTo avoid such biases in the session keys derived from a DH shared\nsecret, you should use a cryptographic hash function such as BLAKE2 or\nSHA-3—or, better yet, a key derivation function (KDF). An example of\nKDF construction is HKDF, or HMAC-based KDF (as specified in RFC\n5869), but today BLAKE2 and SHA-3 feature dedicated modes to behave\nas KDFs.\nLegacy Diffie–Hellman in TLS\nThe TLS protocol is the security behind HTTPS secure websites as well\nas the secure mail transfer protocol (SMTP). TLS takes several\nparameters, including the type of Diffie–Hellman protocol it will use,\nthough most TLS implementations still support anonymous DH for\nlegacy reasons, despite its insecurity.\nUnsafe Group Parameters\nIn January 2016, the maintainers of the OpenSSL toolkit fixed a high-\nseverity vulnerability (CVE-2016-0701) that allowed an attacker to\nexploit unsafe Diffie–Hellman parameters. The root cause of the\nvulnerability was that OpenSSL allowed users to work with unsafe DH\ngroup parameters (namely, an unsafe prime p) instead of throwing an\nerror and aborting the protocol altogether before performing any\narithmetic operation.\nEssentially, OpenSSL accepted a prime number p whose multiplicative\ngroup Z * (where all DH operations happen) contained small subgroups.\np\nAs you learned at the beginning of this chapter, the existence of small\nsubgroups within a larger group in a cryptographic protocol is bad\nbecause it confines shared secrets to a much smaller set of possible values\nthan if it were to use the whole group Z *. Worse still, an attacker can\np\ncraft a DH exponent x that, when combined with the victim’s public key\ngy, will reveal information on the private key y and eventually its entirety.\nAlthough the actual vulnerability is from 2016, the principle the attack\nused dates back to the 1997 paper “A Key Recovery Attack on Discrete\nLog-based Schemes Using a Prime Order Subgroup” by Lim and Lee.\nThe fix for the vulnerability is simple: when accepting a prime p as group\nmodulus, the protocol must check that p is a safe prime by verifying that\n(p – 1) / 2 is prime as well in order to ensure that the group Z * won’t\np\nhave small subgroups, and that an attack on this vulnerability will fail.\nFurther Reading\nHere’s a rundown of some things that I didn’t cover in this chapter but\nare useful to learn about.\nYou can dig deeper into the DH key agreement protocols by reading a\nnumber of standards and official publications, including ANSI X9.42,\nRFC 2631 and RFC 5114, IEEE 1363, and NIST SP 800-56A. These\nserve as references to ensure interoperability, and to provide\nrecommendations for group parameters.\nTo learn more about advanced DH protocols (such as MQV and its\ncousins HMQV and OAKE, among others) and their security notions\n(such as unknown-key share attacks and group representation attacks),\nread the 2005 article “HMQV: A High-Performance Secure Diffie–\nHellman Protocol” by Hugo Krawczyk (https://eprint.iacr.org/2005/176/)\nand the 2011 article “A New Family of Implicitly Authenticated Diffie–\nHellman Protocols” by by Andrew C. Yao and Yunlei Zhao\n(https://eprint.iacr.org/2011/035/). You’ll notice in these articles that\nDiffie–Hellman operations are expressed differently than in this chapter.\nFor example, instead of gx, you’ll find the shared secret represented as xP.\nGenerally, you’ll find multiplication replaced with addition and\nexponentiation replaced with multiplication. The reason is that those\nprotocols are usually not defined over groups of integers, but over elliptic\ncurves, as discussed in Chapter 12."
  },
  {
    "input": "What is the elliptic curve discrete logarithm problem (ECDLP) and how does it differ from the classical discrete logarithm problem (DLP)?",
    "summary": "Elliptic curve cryptography (ECC) is more secure and efficient than RSA or classical Diffie-Hellman, as shown by its use in Bitcoin and Apple devices. ECC uses points on an elliptic curve, defined by equations like y² = x³ + ax + b, and operates over finite fields, such as integers modulo a prime. The security of ECC relies on the elliptic curve discrete logarithm problem (ECDLP), which is believed to be computationally hard.",
    "output": "12\nELLIPTIC CURVES\nThe introduction of elliptic curve cryptography (ECC) in 1985\nrevolutionized the way we do public-key cryptography. ECC is more\npowerful and efficient than alternatives like RSA and classical Diffie–\nHellman (ECC with a 256-bit key is stronger than RSA with a 4096-bit\nkey), but it’s also more complex.\nLike RSA, ECC multiplies large numbers, but unlike RSA it does so in\norder to combine points on a mathematical curve, called an elliptic curve\n(which has nothing to do with an ellipse, by the way). To complicate\nmatters, there are many different types of elliptic curves—simple and\nsophisticated ones, efficient and inefficient ones, and secure and insecure\nones.\nAlthough first introduced in 1985, ECC wasn’t adopted by\nstandardization bodies until the early 2000s, and it wasn’t seen in major\ntoolkits until much later: OpenSSL added ECC in 2005, and the\nOpenSSH secure connectivity tool waited until 2011. But modern\nsystems have few reasons not to use ECC, and you’ll find it used in\nBitcoin and many security components in Apple devices. Indeed, elliptic\ncurves allow you to perform common public-key cryptography operations\nsuch as encryption, signature, and key agreement faster than their\nclassical counterparts. Most cryptographic applications that rely on the\ndiscrete logarithm problem (DLP) will also work when based on its\nelliptic curve counterpart, ECDLP, with one notable exception: the\nSecure Remote Password (SRP) protocol.\nThis chapter focuses on applications of ECC and discusses why you\nwould use ECC rather than RSA or classical Diffie–Hellman, as well as\nhow to choose the right elliptic curve for your application.\nWhat Is an Elliptic Curve?\nAn elliptic curve is a curve on a plane—a group of points with x and y\ncoordinates. A curve’s equation defines all the points that belong to that\ncurve. For example, the curve y = 3 is a horizontal line with the vertical\ncoordinate 3, curves of the form y = ax + b with fixed numbers a and b are\nstraight lines, x2 + y2 = 1 is a circle of radius 1 centered on the origin, and\nso on. Whatever the type of curve, the points on a curve are all (x, y) pairs\nthat satisfy the curve’s equation.\nAn elliptic curve as used in cryptography is typically a curve whose\nequation is of the form y2 = x3 + ax + b (known as the Weierstrass form),\nwhere the constants a and b define the shape of the curve. For example,\nFigure 12-1 shows the elliptic curve that satisfies the equation y2 = x3 –\n4x.\n2 3\nFigure 12-1: An elliptic curve with the equation y = x – 4x, shown over the real\nnumbers\nNOTE\nIn this chapter, I focus on the simplest, most common type of elliptic curves—\nnamely, those with an equation that looks like y2 = x3 + ax + b—but there\nare types of elliptic curves with equations in other forms. For example,\nEdwards curves are elliptic curves whose equation is of the form x2 + y2 = 1\n+ dx2y2. Edwards curves are sometimes used in cryptography (for example,\nin the Ed25519 scheme).\nFigure 12-1 shows all the points that make up the curve for x between –\n3 and 4, be they points on the left side of the curve, which looks like a\ncircle, or on the right side, which looks like a parabola. All these points\nhave (x, y) coordinates that satisfy the curve’s equation y2 = x3 – 4x. For\nexample, when x = 0, then y2 = x3 – 4x = 03 – 4 × 0 = 0; hence, y = 0 is a\nsolution, and the point (0, 0) belongs to the curve. Likewise, if x = 2, the\nsolution to the equation is y = 0, meaning that the point (2, 0) belongs to\nthe curve.\nIt is crucial to distinguish points that belong to the curve from other\npoints, because when using elliptic curves for cryptography, we’ll be\nworking with points from the curve, and points off the curve often\npresent a security risk. However, note that the curve’s equation doesn’t\nalways admit solutions, at least not in the natural number plane. For\nexample, to find points with the horizontal coordinate x = 1, we solve y2 =\nx3 – 4x for y2 with x3 – 4x = 13 – 4 × 1, giving a result of –3. But y2 = –3\ndoesn’t have a solution because there is no number for which y2 = –3.\n(There is a solution in the complex numbers, but elliptic curve\ncryptography will only deal with natural numbers—more precisely,\nintegers modulo a prime.) Because there is no solution to the curve’s\nequation for x = 1, the curve has no point at that position on the x-axis, as\nyou can see in Figure 12-1.\nWhat if we try to solve for x = –1? In this case, we get the equation y2 =\n–1 + 4 = 3, which has two solutions (y = √3 and y = –√3), the square root of\nthree and its negative value. Squaring a number always gives a positive\nnumber, so y2 = (–y)2 for any real number y, and as you can see, the curve\nin Figure 12-1 is symmetric with respect to the x-axis for all points that\nsolve its equation (as are all elliptic curves of the form y2 = x3 + ax + b).\nElliptic Curves over Integers\nNow here’s a bit of a twist: the curves used in elliptic curve cryptography\nactually don’t look like the curve shown in Figure 12-1. They look\ninstead like Figure 12-2, which is a cloud of points rather than a curve.\nWhat’s going on here?\nFigures 12-1 and 12-2 are actually based on the same curve equation, y2\n= x3 – 4x, but they show the curve’s points with respect to different sets of\nnumbers: Figure 12-1 shows the curve’s points over the set of real\nnumbers, which includes negative numbers, decimals, and so on. For\nexample, as a continuous curve, it shows the points at x = 2.0, x = 2.1, x =\n2.00002, and so on. Figure 12-2, on the other hand, shows only integers\nthat satisfy this equation, which excludes decimal numbers. Specifically,\nFigure 12-2 shows the curve y2 = x3 – 4x with respect to the integers\nmodulo 191: 0, 1, 2, 3, up to 190. This set of numbers is denoted Z .\n191\n(There’s nothing special with 191 here, except that it’s a prime number. I\npicked a small number to avoid having too many points on the graph.)\nThe points shown on Figure 12-2 therefore all have x and y coordinates\nthat are integers modulo 191 and that satisfy the equation y2 = x3 – 4x.\nFor example, for x = 2, we have y2 = 0, for which y = 0 is a valid solution.\nThis tells us that the point (2, 0) belongs to the curve.\n2 3\nFigure 12-2: The elliptic curve with the equation y = x – 4x over Z , the set of\n191\nintegers modulo 191\nWhat if x = 3? We get the equation y2 = 27 – 12 = 15, which admits two\nsolutions to y2 = 15 (namely, 46 and 145), because 462 mod 191 = 15 and\n1452 mod 191 = 15 both equal 15 in Z . Thus, the points (3, 46) and (3,\n191\n145) belong to the curve and appear as shown in Figure 12-2 (the two\npoints highlighted at the left).\nNOTE\nFigure 12-2 considers points from the set denoted Z = {0, 1, 2, . . . , 190},\n191\nwhich includes zero. This differs from the groups denoted Z * (with a star\np\nsuperscript) that we discussed in the context of RSA and Diffie–Hellman.\nThe reason for this difference is that we’ll both multiply and add numbers,\nand we therefore need to ensure that the set of numbers includes addition’s\nidentity element (namely 0, such that x + 0 = x for every x in Z ). Also,\n191\nevery number x has an inverse with respect to addition, denoted –x, such that\nx + (–x) = 0. For example, the inverse of 100 in Z is 91, because 100 +\n191\n91 mod 191 = 0. Such a set of numbers, where addition and multiplication\nare possible and where each element x admits an inverse with respect to\naddition (denoted –x) as well as an inverse with respect to multiplication\n(denoted 1 / x), is called a field. When a field has a finite number of\nelements, as in Z and as with all fields used for elliptic curve\n191\ncryptography, it is called a finite field.\nAdding and Multiplying Points\nWe’ve seen that the points on an elliptic curve are all coordinates (x, y)\nthat satisfy the curve’s equation, y2 = x3 + ax + b. In this section, we look\nat how to add elliptic curve points, a rule called the addition law.\nAdding Two Points\nSay that we want to add two points on the elliptic curve, P and Q, to give\na new point, R, that is the sum of these two points. The simplest way to\nunderstand point addition is to determine the position of R = P + Q on\nthe curve relative to P and Q based on a geometric rule: draw the line that\nconnects P and Q, find the other point of the curve that intersects with\nthis line, and Q is the reflection of this point with respect to the x-axis.\nFor example, in Figure 12-3, the line connecting P and Q intersects the\ncurve at a third point between P and Q, and the point P + Q is the point at\nthe same x coordinate but the inverse y coordinate.\nFigure 12-3: A general case of the geometric rule for adding points over an elliptic\ncurve\nThis geometric rule is simple, but it won’t directly give you the\ncoordinates of the point R. We compute the coordinates (x , y ) of R\nR R\nusing the coordinates (x , y ) of P and the coordinates (x , y ) of Q using\np p Q Q\nthe formulas x = m2 – x – x and y = m(x – x ) – y , where the value m\nR p Q R p R p\n= (y – y ) / (x – x ) is the slope of the line connecting P and Q.\nQ p Q p\nUnfortunately, these formulas and the line-drawing trick shown in\nFigure 12-3 don’t always work. If, for example, P = Q, you can’t draw a\nline between two points (there’s only one), and if P = –P, the line doesn’t\ncross the curve again, so there is no point on the curve to mirror. We’ll\nexplore these in the next section.\nAdding a Point and Its Negative\nThe negative of a point P = (x , y ) is the point –P = (x , –y ), which is\nP P P P\nthe point mirrored around the x-axis. For any P, we say that P + (–P) = O,\nwhere O is called the point at infinity. And as you can see in Figure 12-4,\nthe line between P and –P runs to infinity and never intersects the curve.\n(The point at infinity is a virtual point that belongs to any elliptic curve; it\nis to elliptic curves what zero is to integers.)\nFigure 12-4: The geometric rule for adding points on an elliptic curve with the\noperation P + (–P) = O when the line between the points never intersects the curve\nDoubling a Point\nWhen P = Q (that is, P and Q are at the same position), adding P and Q is\nequivalent to computing P + P, also denoted 2P. This addition operation\nis therefore called a doubling.\nHowever, to find the coordinates of the result R = 2P, we can’t use the\ngeometric rule from the previous section, because we can’t draw a line\nbetween P and itself. Instead, we draw the line tangent to the curve at P,\nand 2P is the negation of the point where this line intersects the curve, as\nshown on Figure 12-5.\nFigure 12-5: The geometric rule for adding points over an elliptic curve using the\ndoubling operation P + P\nThe formula for determining the coordinates (x , y ) of R = P + P is\nR R\nslightly different from the formula we would use for a distinct P and Q.\nAgain, the basic formula is x = m2 – x – x and y = m(x – x ) – y , but\nR p Q R p R p\nthe value of m is different; it becomes (3x 2 + a) / 2y , where a is the\np p\ncurve’s parameter, as in y2 = x3 + ax + b.\nMultiplication\nIn order to multiply points on elliptic curves by a given number k, where\nk is an integer, we determine the point kP by adding P to itself k – 1\ntimes. In other words, 2P = P + P, 3P = P + P + P, and so on. To obtain\nthe x and y coordinates of kP, repeatedly add P to itself and apply the\npreceding addition law.\nTo compute kP efficiently, however, the naive technique of adding P\nby applying the addition law k – 1 times is far from optimal. For example,\nif k is large (of the order of, say, 2256) as it occurs in elliptic curve–based\ncrypto schemes, then computing k – 1 additions is downright infeasible.\nBut there’s a trick: you can gain an exponential speed-up by adapting\nthe technique discussed in “Fast Exponentiation Algorithm: Square-and-\nMultiply” on page 192 to compute xe mod n. For example, to compute 8P\nin three additions instead of seven using the naive method, you would\nfirst compute P = P + P, then P = P + P , and finally P + P = 8P.\n2 4 2 2 4 4\nElliptic Curve Groups\nBecause points can be added together, the set of points on an elliptic\ncurve forms a group. According to the definition of a group (see “What Is\na Group?” on page 174), if the points P and Q belong to a given curve,\nthen P + Q also belongs to the curve.\nFurthermore, because addition is associative, we have (P + Q) + R = P +\n(Q + R) for any points P, Q, and R. In a group of elliptic curve points, the\nidentity element is called the point at infinity, and denoted O, such that P\n+ O = P for any P. Every point P = (x , y ) has an inverse, –P = (x , –y ),\nP P P P\nsuch that P + (–P) = O.\nIn practice, most elliptic curve–based cryptosystems work with x and y\ncoordinates that are numbers modulo a prime number, p (in other words,\nnumbers in the finite field Z ). Just as the security of RSA depends on the\np\nsize of the numbers used, the security of an elliptic curve–based\ncryptosystem depends on the number of points on the curve. But how do\nwe know the number of points on an elliptic curve, or its cardinality?\nWell, it depends on the curve and the value of p.\nOne rule of thumb is that there are approximately p points on the\ncurve, but you can compute the exact number of points with Schoof’s\nalgorithm, which counts points on elliptic curves over finite fields. You’ll\nfind this algorithm built in to SageMath. For example, Listing 12-1 shows\nhow to use this algorithm to count the number of points on the curve y2 =\nx3 – 4x over Z shown in Figure 12-1.\n191\nsage: Z = Zmod(191)\nsage: E = EllipticCurve(Z, (-4,0))\nsage: E.cardinality()\n192\nListing 12-1: Computing the cardinality, or number of points on a curve\nIn Listing 12-1, we’ve first defined the variable Z as the set over\nintegers modulo 191; then we defined the variable E as the elliptic curve\nover Z with the coefficients –4 and 0. Finally, we computed the number of\npoints on the curve, also known as its cardinality, group order, or just order.\nNote that this count includes the point at infinity O.\nThe ECDLP Problem\nChapter 9 introduced the DLP: that of finding the number y given some\nbase number g, where x = g y mod p for some large prime number p.\nCryptography with elliptic curves has a similar problem: the problem of\nfinding the number k given a base point P where the point Q = kP. This is\ncalled the elliptic curve discrete logarithm problem, or ECDLP. (Instead of\nnumbers, the elliptic curve’s problems operate on points, and\nmultiplication is used instead of exponentiation.)\nAll elliptic curve cryptography is built on the ECDLP problem, which,\nlike DLP, is believed to be hard and has withstood cryptanalysis since its\nintroduction into cryptography in 1985. One important difference\nbetween ECDLP and the classical DLP is that ECDLP allows you to\nwork with smaller numbers and still enjoy a similar level of security.\nGenerally, when p is n bits, you’ll get a security level of about n / 2 bits.\nFor example, an elliptic curve taken over numbers modulo p, with a 256-\nbit p, will give a security level of about 128 bits. For the sake of\ncomparison, to achieve a similar security level with DLP or RSA, you\nwould need to use numbers of several thousands of bits. The smaller\nnumbers used for ECC arithmetic are one reason why it’s often faster"
  },
  {
    "input": "What is the process for solving the Elliptic Curve Discrete Logarithm Problem (ECDLP) and how does it relate to the elliptic curve Diffie–Hellman (ECDH) key agreement protocol?",
    "summary": "Elliptic curve cryptography (ECC) is used for secure key agreement, digital signatures, and encryption. ECC is more efficient than RSA, offering shorter signatures and faster signing, but its security relies on the difficulty of solving the elliptic curve discrete logarithm problem (ECDLP). TLS 1.3 is a secure and efficient protocol that uses ECC for key exchange and authenticated encryption, improving upon earlier versions by removing weak algorithms and simplifying the handshake process. However, TLS is not immune to vulnerabilities, such as those caused by compromised certificate authorities, servers, or clients, or by bugs in its implementation.",
    "output": "than RSA or classical Diffie–Hellman.\nOne way of solving ECDLP is to find a collision between two outputs,\nc P + d Q and c P + d Q. The points P and Q in these equations are such\n1 1 2 2\nthat Q = kP for some unknown k, and c , d , c , and d are the numbers\n1 1 2 2\nyou will need in order to find k.\nAs with the hash function discussed in Chapter 6, a collision occurs\nwhen two different inputs produce the same output. Therefore, in order\nto solve ECDLP, we need to find points where the following is true:\nc P + d Q = c P + d Q\n1 1 2 2\nIn order to find these points, we replace Q with the value kP, and we\nhave the following:\nc P + d kP = (c + d k)P = c P + d kP = (c + d k)P\n1 1 1 1 2 2 2 2\nThis tells us that (c + d k) equals (c + d k) when taken modulo the\n1 1 2 2\nnumber of points on the curve, which is not a secret.\nFrom this, we can deduce the following:\nAnd we’ve found k, the solution to ECDLP.\nOf course, that’s only the big picture—the details are more complex\nand interesting. In practice, elliptic curves extend over numbers of at least\n256 bits, which makes attacking elliptic curve cryptography by finding a\ncollision impractical because doing so takes up to 2128 operations (the\ncost of finding a collision over 256-bit numbers, as you learned in\nChapter 6).\nDiffie–Hellman Key Agreement over Elliptic Curves\nRecall from Chapter 11 that in the classical Diffie–Hellman (DH) key\nagreement protocol, two parties establish a shared secret by exchanging\nnon-secret values. Given some fixed number g, Alice picks a secret\nrandom number a, computes A = ga, sends A to Bob, and Bob picks a\nsecret random b and sends B = gb to Alice. Both then combine their secret\nkey with the other’s public key to produce the same Ab = Ba = gab.\nThe elliptic curve version of DH is identical to that of classical DH but\nwith different notations. In the case of ECC, for some fixed point G,\nAlice picks a secret random number dA, computes PA = dAG (the point G\nmultiplied by d ), and sends P to Bob. Bob picks a secret random d ,\nA A B\ncomputes the point P = d G, and sends it to Alice. Then both compute\nB B\nthe same shared secret, dAPB = dBPA = dAdBG. This method is called elliptic\ncurve Diffie–Hellman, or ECDH.\nECDH is to the ECDLP problem what DH is to DLP: it’s secure as\nlong as ECDLP is hard. DH protocols that rely on DLP can therefore be\nadapted to work with elliptic curves and rely on ECDLP as a hardness\nassumption. For example, authenticated DH and Menezes–Qu–Vanstone\n(MQV) will also be secure when used with elliptic curves. (In fact, MQV\nwas first defined as working over elliptic curves.)\nSigning with Elliptic Curves\nThe standard algorithm used for signing with ECC is ECDSA, which\nstands for elliptic curve digital signature algorithm. This algorithm has\nreplaced RSA signatures and classical DSA signatures in many\napplications. It is, for example, the only signature algorithm used in\nBitcoin and is supported by many TLS and SSH implementations.\nAs with all signature schemes, ECDSA consists of a signature generation\nalgorithm that the signer uses to create a signature using their private key\nand a verification algorithm that a verifier uses to check a signature’s\ncorrectness given the signer’s public key. The signer holds a number, d, as\na private key, and verifiers hold the public key, P = dG. Both know in\nadvance what elliptic curve to use, its order (n, the number of points in\nthe curve), as well as the coordinates of a base point, G.\nECDSA Signature Generation\nIn order to sign a message, the signer first hashes the message with a\ncryptographic hash function such as SHA-256 or BLAKE2 to generate a\nhash value, h, that is interpreted as a number between 0 and n – 1. Next,\nthe signer picks a random number, k, between 1 and n – 1 and computes\nkG, a point with the coordinates (x, y). The signer now sets r = x mod n\nand computes s = (h + rd) / k mod n, and then uses these values as the\nsignature (r, s).\nThe length of the signature will depend on the coordinate lengths\nbeing used. For example, when you’re working with a curve where\ncoordinates are 256-bit numbers, r and s would both be 256 bits long,\nyielding a 512-bit-long signature.\nECDSA Signature Verification\nThe ECDSA verification algorithm uses a signer’s public key to verify the\nvalidity of a signature.\nIn order to verify an ECDSA signature (r, s) and a message’s hash, h,\nthe verifier first computes w = 1 / s, the inverse of s in the signature,\nwhich is equal to k / (h + rd) mod n, since s is defined as s = (h + rd) / k.\nNext, the verifier multiplies w with h to find u according to the following\nformula:\nwh = hk (h + rd) = u\nThe verifier then multiplies w with r to find v:\nwr = rk(h + rd) = v\nGiven u and v, the verifier computes the point Q according to the\nfollowing formula:\nQ = uG + vP\nHere, P is the signer’s public key, which is equal to dG, and the verifier\nonly accepts the signature if the x coordinate of Q is equal to the value r\nfrom the signature.\nThis process works because, as a last step, we compute the point Q by\nsubstituting the public key P with its actual value dG:\nuG + vdG = (u + vd)G\nWhen we replace u and v with their actual values, we obtain the\nfollowing:\nu + vd = hk (h + rd) + drk / (h + rd) = (hk + drk) / (h + rd) = k (h + dr) / (h +\nrd) = k\nThis tells us that (u + vd) is equal to the value k, chosen during\nsignature generation, and that uG + vdG is equal to the point kG. In other\nwords, the verification algorithm succeeds in computing point kG, the\nsame point computed during signature generation. Validation is complete\nonce a verifier confirms that kG’s x coordinate is equal to the r received;\notherwise, the signature is rejected as invalid.\nECDSA vs. RSA Signatures\nElliptic curve cryptography is often viewed as an alternative to RSA for\npublic-key cryptography, but ECC and RSA don’t have much in\ncommon. RSA is only used for encryption and signatures, whereas ECC\nis a family of algorithms that can be used to perform encryption, generate\nsignatures, perform key agreement, and offer advanced cryptographic\nfunctionalities such as identity-based encryption (a kind of encryption\nthat uses encryption keys derived from a personal identifier, such as an\nemail address).\nWhen comparing RSA and ECC’s signature algorithms, recall that in\nRSA signatures, the signer uses their private key d to compute a signature\nas y = xd mod n, where x is the data to be signed and y is the signature.\nVerification uses the public key e to confirm that ye mod n equals x—a\nprocess that’s clearly simpler than that of ECDSA.\nRSA’s verification process is often faster than ECC’s signature\ngeneration because it uses a small public key e. But ECC has two major\nadvantages over RSA: shorter signatures and signing speed. Because ECC\nworks with shorter numbers, it produces shorter signatures than RSA\n(hundreds of bits long, not thousands of bits), which is an obvious benefit\nif you have to store or transmit numerous signatures. Signing with\nECDSA is also much faster than signing with RSA (though signature\nverification is about as fast) because ECDSA works with much smaller\nnumbers than RSA does for a similar security level. For example, Listing\n12-2 shows that ECDSA is about 150 times faster at signing and a little\nfaster at verifying. Note that ECDSA signatures are also shorter than\nRSA signatures because they’re 512 bits (two elements of 256 bits each)\nrather than 4096 bits.\n$ openssl speed ecdsap256 rsa4096\nsign verify sign/s verify/s\nrsa 4096 bits 0.007267s 0.000116s 137.6 8648.0\nsign verify sign/s verify/s\n256 bit ecdsa (nistp256) 0.0000s 0.0001s 21074.6 9675.7\nListing 12-2: Comparing the speed of 4096-bit RSA signatures with 256-bit\nECDSA signatures\nIt’s fair to compare the performance of these differently sized\nsignatures because they provide a similar security level. However, in\npractice, many systems use RSA signatures with 2048 bits, which is orders\nof magnitude less secure than 256-bit ECDSA. Thanks to its smaller\nmodulus size, 2048-bit RSA is faster than 256-bit ECDSA at verifying,\nyet still slower at signing, as shown in Listing 12-3.\n$ openssl speed rsa2048\nsign verify sign/s verify/s\nrsa 2048 bits 0.000696s 0.000032s 1436.1 30967.1\nListing 12-3: The speed of 2048-bit RSA signatures\nThe upshot is that you should prefer ECDSA to RSA except when\nsignature verification is critical and you don’t care about signing speed, as\nin a sign-once, verify-many situation (for example, when a Windows\nexecutable application is signed once and then verified by all the systems\nexecuting it).\nEncrypting with Elliptic Curves\nAlthough elliptic curves are more commonly used for signing, you can\nstill encrypt with them. But you’ll rarely see people do so in practice due\nto restrictions in the size of the plaintext that can be encrypted: you can\nfit only about 100 bits of plaintext, as compared to almost 4000 in RSA\nwith the same security level.\nOne simple way to encrypt with elliptic curves is to use the integrated\nencryption scheme (IES), a hybrid asymmetric–symmetric key encryption\nalgorithm based on the Diffie–Hellman key exchange. Essentially, IES\nencrypts a message by generating a Diffie–Hellman key pair, combining\nthe private key with the recipient’s own public key, deriving a symmetric\nkey from the shared secret obtained, and then using an authenticated\ncipher to encrypt the message.\nWhen used with elliptic curves, IES relies on ECDLP’s hardness and is\ncalled elliptic-curve integrated encryption scheme (ECIES). Given a\nrecipient’s public key, P, ECIES encrypts a message, M, as follows:\n1. Pick a random number, d, and compute the point Q = dG, where the\nbase point G is a fixed parameter. Here, (d, Q) acts as an ephemeral\nkey pair, used only for encrypting M.\n2. Compute an ECDH shared secret by computing S = dP.\n3. Use a key derivation scheme (KDF) to derive a symmetric key, K,\nfrom S.\n4. Encrypt M using K and a symmetric authenticated cipher, obtaining\na ciphertext, C, and an authentication tag, T.\nThe ECIES ciphertext then consists of the ephemeral public key Q\nfollowed by C and T. Decryption is straightforward: the recipient\ncomputes S by multiplying R with their private exponent to obtain S, and\nthen derives the key K and decrypts C and verifies T.\nChoosing a Curve\nCriteria used to assess the safety of an elliptic curve include the order of\nthe group used (that is, its number of points), its addition formulas, and\nits origins.\nThere are several types of elliptic curves, but not all are equally good\nfor cryptographic purposes. When making your selection, be sure to\nchoose coefficients a and b in the curve’s equation y2 = x3 + ax + b\ncarefully; otherwise, you may end up with an insecure curve. In practice,\nyou’ll use some de facto standard curve for encryption, but knowing what\nmakes a safe curve will help you choose among the several available ones\nand better understand any associated risks. Here are some points to keep\nin mind:\nThe order of the group should not be a product of small numbers;\notherwise solving ECDLP becomes much easier.\nIn “Adding and Multiplying Points” on page 221, you learned that\nadding points P + Q required a specific addition formula when Q = P.\nUnfortunately, treating this case differently from the general one\nmay leak critical information if an attacker is able to distinguish\ndoublings from additions between distinct points. Some curves are\nsecure because they use a single formula for all point addition. (When\na curve does not require a specific formula for doublings, we say that\nit admits a unified addition law.)\nIf the creators of a curve don’t explain the origin of a and b, they may\nbe suspected of foul play because you can’t know whether they may\nhave chosen weaker values that enable some yet-unknown attack on\nthe cryptosystem.\nLet’s review some of the most commonly used curves, especially ones\nused for signatures or Diffie–Hellman key agreement.\nNOTE\nYou’ll find more criteria and more details about curves on the dedicated\nwebsite https://safecurves.cr.yp.to/.\nNIST Curves\nIn 2000, the NIST curves were standardized by the US NIST in the\nFIPS 186 document under “Recommended Elliptic Curves for Federal\nGovernment Use.” Five NIST curves work modulo a prime number (as\ndiscussed in “Elliptic Curves over Integers” on page 219), called prime\ncurves. Ten other NIST curves work with binary polynomials, which are\nmathematical objects that make implementation in hardware more\nefficient. (We won’t cover binary polynomials in further detail because\nthey’re seldom used with elliptic curves.)\nThe most common NIST curves are the prime curves. Of these, one of\nthe most common is P-256, a curve that works over numbers modulo the\n256-bit number p = 2256 – 2224 + 2192 + 296 – 1. The equation for P-256 is\ny2 = x3 – 3x + b, where b is a 256-bit number. NIST also provides prime\ncurves of 192 bits, 224 bits, 384 bits, and 521 bits.\nNIST curves are sometimes criticized because only the NSA, creator of\nthe curves, knows the origin of the b coefficient in their equations. The\nonly explanation we’ve been given is that b results from hashing a\nrandom-looking constant with SHA-1. For example, P-256’s b parameter\ncomes from the following constant: c49d3608 86e70493 6a6678e1 139d26b7\n819f7e90.\nNo one knows why the NSA picked this particular constant, but most\nexperts don’t believe the curve’s origin hides any weakness.\nCurve25519\nDaniel J. Bernstein brought Curve25519 (pronounced curve-twenty-five-\nfive-nineteen) to the world in 2006. Motivated by performance, he\ndesigned Curve25519 to be faster and use shorter keys than the standard\ncurves. But Curve25519 also brings security benefits, because unlike the\nNIST curves it has no suspicious constants and can use the same unified\nformula for adding distinct points or for doubling a point.\nThe form of Curve25519’s equation, y2 = x3 + 486662x2 + x, is slightly\ndifferent from that of the other equations you’ve seen in this chapter, but\nit still belongs to the elliptic curve family. The unusual form of this\nequation allows for specific implementation techniques that make\nCurve25519 fast in software.\nCurve25519 works with numbers modulo the prime number 2255 – 19,\na 256-bit prime number that is as close as possible to 2255. The b\ncoefficient 486662 is the smallest integer that satisfies the security criteria\nset by Bernstein. Taken together, these features make Curve25519 more\ntrust​\nworthy than NIST curves and their fishy coefficients.\nCurve25519 is used everywhere: in Google Chrome, Apple systems,\nOpenSSH, and many other systems. However, because Curve25519 isn’t\na NIST standard, some applications stick to NIST curves.\nNOTE\nTo learn all the details and rationale behind Curve25519, view the 2016\npresentation “The first 10 years of Curve25519” by Daniel J. Bernstein,\navailable at http://cr.yp.to/talks.html#2016.03.09/.\nOther Curves\nAs I write this, most cryptographic applications use NIST curves or\nCurve25519, but there are other legacy standards in use, and newer\ncurves are being promoted and pushed within standardization\ncommittees. Some of the old national standards include France’s ANSSI\ncurves and Germany’s Brainpool curves: two families that don’t support\ncomplete addition formulas and that use constants of unknown origins.\nSome newer curves are more efficient than the older ones and are clear\nof any suspicion; they offer different security levels and various efficiency\noptimizations. Examples include Curve41417, a variant of Curve25519,\nwhich works with larger numbers and offers a higher level of security\n(approximately 200 bits); Ed448-Goldilocks, a 448-bit curve first\nproposed in 2014 and considered to be an internet standard; as well as six\ncurves proposed by Aranha et al. in “A note on high-security general-\npurpose elliptic curves” (see http://eprint.iacr.org/2013/647/), though these\ncurves are rarely used. The details specific to all these curves are beyond\nthe scope of this book.\nHow Things Can Go Wrong\nElliptic curves have their downsides due to their complexity and large\nattack surface. Their use of more parameters than classical Diffie–\nHellman brings with it a greater attack surface with more opportunities\nfor mistakes and abuse—and possible software bugs that might affect\ntheir implementation. Elliptic curve software may also be vulnerable to\nside-channel attacks due to the large numbers used in their arithmetic. If\nthe speed of calculations depends on inputs, attackers may be able to\nobtain information about the formulas being used to encrypt.\nIn the following sections, I discuss two examples of vulnerabilities that\ncan occur with elliptic curves, even when the implementation is safe.\nThese are protocol vulnerabilities rather than implementation\nvulnerabilities.\nECDSA with Bad Randomness\nECDSA signing is randomized, as it involves a secret random number k\nwhen setting s = (h + rd) / k mod n. However, if the same k is reused to\nsign a second message, an attacker could combine the resulting two\nvalues, s = (h + rd) / k and s = (h + rd) / k, to get s – s = (h – h ) / k\n1 1 2 2 1 2 1 2\nand then k = (h – h ) / (s – s ). When k is known, the private key d is\n1 2 1 2\neasily recovered by computing the following:\n(ks − h ) / r = ((h + rd) − h ) / r = rd / r = d\n1 1 1 1\nUnlike RSA signatures, which won’t allow the key to be recovered if a\nweak pseudorandom number generator (PRNG) is used, the use of non-\nrandom numbers can lead to ECDSA’s k being recoverable, as happened\nwith the attack on the PlayStation 3 game console in 2010, presented by\nthe fail0verflow team at the 27th Chaos Communication Congress in\nBerlin, Germany.\nBreaking ECDH Using Another Curve\nECDH can be elegantly broken if you fail to validate input points. The\nprimary reason is that the formulas that give the coordinates for the sum\nof points P + Q never involve the b coefficient of the curve; instead, they\nrely only on the coordinates of P and Q and the a coefficient (when\ndoubling a point). The unfortunate consequence of this is that when\nadding two points, you can never be sure that you’re working on the right\ncurve because you may actually be adding points on a different curve with\na different b coefficient. That means you can break ECDH as described\nin the following scenario, called the invalid curve attack.\nSay that Alice and Bob are running ECDH and have agreed on a curve\nand a base point, G. Bob sends his public key d G to Alice. Alice, instead\nB\nof sending a public key d G on the agreed upon curve, sends a point on a\nA\ndifferent curve, either intentionally or accidentally. Unfortunately, this\nnew curve is weak and allows Alice to choose a point P for which solving\nECDLP is easy. She chooses a point of low order, for which there is a\nrelatively small k such that kP = O.\nNow Bob, believing that he has a legitimate public key, computes what\nhe thinks is the shared secret d P, hashes it, and uses the resulting key to\nB\nencrypt data sent to Alice. The problem is that when Bob computes d P,\nB\nhe is unknowingly computing on the weaker curve. As a result, because P\nwas chosen to belong to a small subgroup within the larger group of\npoints, the result d P will also belong to that small subgroup, allowing an\nB\nattacker to determine the shared secret d P efficiently if they know the\nB\norder of P.\nOne way to prevent this is to make sure that points P and Q belong to\nthe right curve by ensuring that their coordinates satisfy the curve’s\nequation. Doing so would prevent this attack by making sure that you’re\nonly able to work on the secure curve.\nSuch an invalid curve attack was found in 2015 on certain\nimplementations of the TLS protocol, which uses ECDH to negotiate\nsession keys. (For details, see the paper “Practical Invalid Curve Attacks\non TLS-ECDH” by Jager, Schwenk, and Somorovsky.)\nFurther Reading\nElliptic curve cryptography is a fascinating and complex topic that\ninvolves lots of mathematics. I’ve not discussed important notions such as\na point’s order, a curve’s cofactor, projective coordinates, torsion points,\nand methods for solving the ECDLP problem. If you are mathematically\ninclined, you’ll find information on these and other related topics in the\nHandbook of Elliptic and Hyperelliptic Curve Cryptography by Cohen and\nFrey (Chapman and Hall/CRC, 2005). The 2013 survey “Elliptic Curve\nCryptography in Practice” by Bos, Halderman, Heninger, Moore,\nNaehrig, and Wustrow also gives a good illustrated introduction with\npractical examples (https://eprint.iacr.org/2013/734/).\n13\nTLS\nThe Transport Layer Security (TLS) protocol, also known as Secure Socket\nLayer (SSL), which is the name of its predecessor, is the workhorse of\ninternet security. TLS protects connections between servers and clients,\nwhether that connection is between a website and its visitors, email\nservers, a mobile application and its servers, or video game servers and\nplayers. Without TLS, there would be no secure online commerce,\nsecure online banking, or for that matter secure online anything.\nTLS is application agnostic; it doesn’t care about the type of content\nencrypted. This means that you can use it for web-based applications that\nrely on the HTTP protocol, as well as for any system where a client\ncomputer or device needs to initiate a connection with a remote server.\nFor example, TLS is widely used for machine-to-machine\ncommunications in so-called internet of things (IoT) applications.\nThis chapter provides you with an abbreviated view of TLS. As you’ll\nsee, TLS has become increasingly complex over the years. Unfortunately,\ncomplexity and bloat brought multiple vulnerabilities, and bugs found in\nits cluttered implementations have made headlines—think Heartbleed,\nBEAST, CRIME, and POODLE, all vulnerabilities that impacted\nmillions of web servers.\nIn 2013, engineers tired of fixing new cryptographic vulnerabilities in\nTLS overhauled it and started working on TLS 1.3. As you’ll learn in this\nchapter, TLS 1.3 ditched unnecessary features and insecure ones, and\nreplaced old algorithms with state-of-the-art ciphers. The result is a\nsimpler, faster, and more secure protocol.\nBut before we explore how TLS 1.3 works, let’s review the problem\nthat TLS aims to solve in the first place, and the reason for its very\nexistence.\nTarget Applications and Requirements\nTLS is best known for being the S in HTTPS websites, and the padlock\nin a browser’s address bar indicating that a page is secure. The primary\ndriver for creating TLS was to enable secure browsing in applications\nsuch as e-commerce or e-banking by encrypting website connections to\nprotect credit card numbers, user credentials, and other sensitive\ninformation.\nTLS also helps to protect internet-based communication in general by\nestablishing a secure channel between a client and a server that ensures the\ndata transferred is confidential, authenticated, and unmodified.\nOne of TLS’s security goals is to prevent man-in-the-middle attacks,\nwherein an attacker intercepts encrypted traffic from the transmitting\nparty, decrypts the traffic to capture the clear content, and re-encrypts it\nto send to the receiving party. TLS defeats man-in-the-middle attacks by\nauthenticating servers (and optionally clients) using certificates and\ntrusted certificate authorities, as we’ll discuss in more detail in the section\n“Certificates and Certificate Authorities” on page 238.\nTo ensure wide adoption, TLS needed to satisfy four more\nrequirements: it needed to be efficient, interoperable, extensible, and\nversatile.\nFor TLS, efficiency means minimizing the performance penalty\ncompared with unencrypted connections. This is good for both the server\n(to reduce the cost of hardware for the service providers) and for clients\n(to avoid perceptible delays or the reduction of mobile devices’ battery\nlife). The protocol needed to be interoperable so that it would work on\nany hardware and any operating system. It was to be extensible so that it\ncould support additional features or algorithms. And it had to be versatile\n—that is, not bound to a specific application (this parallels something like\nTransport Control Protocol, which doesn’t care about the application\nprotocol used on top of it).\nThe TLS Protocol Suite\nTo protect client–server communications, TLS is made up of multiple\nversions of several protocols that together form the TLS protocol suite.\nAnd although TLS stands for Transport Layer Security, it’s actually not a\ntransport protocol. TLS usually sits between the transport protocol TCP\nand an application layer protocol such as HTTP or SMTP, in order to\nsecure data transmitted over a TCP connection.\nTLS can also work over the User Datagram Protocol (UDP) transport\nprotocol, which is used for “connectionless” transmissions such as voice\nor video traffic. However, unlike TCP, UDP doesn’t guarantee delivery\nor correct packet ordering. The UDP version of TLS is therefore slightly\ndifferent and is called DTLS (Datagram Transport Layer Security). For\nmore on TCP and UDP, see Charles Kozierok’s The TCP/IP Guide (No\nStarch Press, 2005.)\nThe TLS and SSL Family of Protocols: A Brief History\nTLS began life in 1995 when Netscape, developer of the Netscape\nbrowser, developed TLS’s ancestor, the Secure Socket Layer (SSL)\nprotocol. SSL was far from perfect, and both SSL 2.0 and SSL 3.0 had\nsecurity flaws. The upshot is that you should never use SSL, you should\nalways use TLS—what adds to the confusion is that TLS is often referred\nto as “SSL,” even by security experts.\nMoreover, not all versions of TLS are secure. TLS 1.0 (1999) is the\nleast secure TLS version, though it’s still more secure than SSL 3.0. TLS\n1.1 (2006) is better but includes a number of algorithms known today to\nbe weak. TLS 1.2 (2008) is better yet, but it’s complex and only gets you\nhigh security if configured correctly (which is no simple matter). Also, its\ncomplexity increases the risk of bugs in implementations and the risk of\nincorrect configurations. For example, TLS 1.2 supports AES in CBC\nmode, which is often vulnerable to padding oracle attacks.\nTLS 1.2 inherited dozens of features and design choices from earlier\nversions of TLS that make it suboptimal, both in terms of security and\nperformance. To clean up this mess, cryptography engineers reinvented\nTLS—keeping only the good parts and adding security features. The\nresult is TLS 1.3, an overhaul that has simplified a bloated design and\nmade it more secure, more efficient, and simpler. Essentially, TLS 1.3 is\nmature TLS.\nTLS in a Nutshell\nTLS has two main protocols: one determines how to transmit data, and\nthe other what data to transmit. The record protocol defines a packet\nformat to encapsulate data from higher-level protocols and sends this data\nto another party. It’s a simple protocol that people often forget is part of\nTLS.\nThe handshake protocol—or just handshake—is TLS’s key agreement\nprotocol. It’s often mistaken for “the” TLS protocol but the record\nprotocol and the handshake can’t be separated.\nThe handshake is started by a client to initiate a secure connection with\na server. The client sends an initial message called ClientHello with\nparameters that include the cipher it wants to use. The server checks this\nmessage and its parameters and then responds with a message called\nServerHello. Once both the client and the server have processed each\nother’s messages, they’re ready to exchange encrypted data using session\nkeys established through the handshake protocol, as you’ll see in the\nsection “The TLS Handshake Protocol” on page 241.\nCertificates and Certificate Authorities\nThe most critical step in the TLS handshake, and the crux of TLS’s\nsecurity, is the certificate validation step, wherein a server uses a certificate to\nauthenticate itself to a client.\nA certificate is essentially a public key accompanied by a signature of\nthat key and associated information (including the domain name). For\nexample, when connecting to https://www.google.com/, your browser will\nreceive a certificate from some network host and will then verify the\ncertificate’s signature, which reads something like “I am google.com and\nmy public key is [key].” If the signature is verified, the certificate (and its\npublic key) are said to be trusted, and the browser can proceed with\nestablishing the connection. (See Chapters 10 and 12 for details about\nsignatures.)\nHow does the browser know the public key needed to verify the\nsignature? That’s where the concept of certificate authority (CA) comes in.\nA CA is essentially a public key hard coded in your browser or operating\nsystem. The public key’s private key (that is, its signing capability)\nbelongs to a trusted organization that ensures the public keys in\ncertificates that it issues belong to the website or entity that claims them.\nThat is, a CA acts as a trusted third party. Without CAs, there would be no\nway to verify that the public key served by google.com belongs to Google\nand not to an eavesdropper performing a man-in-the-middle attack.\nFor example, the command shown in Listing 13-1 shows what happens\nwhen we use the OpenSSL command-line tool to initiate a TLS\nconnection to www.google.com on port 443, the network port used for\nTLS-based HTTP connections (that is, HTTPS.):\n$ openssl s_client -connect www.google.com:443\nCONNECTED(00000003)\n--snip--\n---\nCertificate chain\n❶ 0 s:/C=US/ST=California/L=Mountain View/O=Google Inc/CN=www.google.com\ni:/C=US/O=Google Inc/CN=Google Internet Authority G2\n❷ 1 s:/C=US/O=Google Inc/CN=Google Internet Authority G2\ni:/C=US/O=GeoTrust Inc./CN=GeoTrust Global CA\n❸ 2 s:/C=US/O=GeoTrust Inc./CN=GeoTrust Global CA\ni:/C=US/O=Equifax/OU=Equifax Secure Certificate Authority\n---\nServer certificate\n-----BEGIN CERTIFICATE-----\nMIIEgDCCA2igAwIBAgIISCr6QCbz5rowDQYJKoZIhvcNAQELBQAwSTELMAkGA1UE\nBhMCVVMxEzARBgNVBAoTCkdvb2dsZSBJbmMxJTAjBgNVBAMTHEdvb2dsZSBJbnRl\n--snip--\ncb9reU8in8yCaH8dtzrFyUracpMureWnBeajOYXRPTdCFccejAh/xyH5SKDOOZ4v\n3TP9GBtClAH1mSXoPhX73dp7jipZqgbY4kiEDNx+hformTUFBDHD0eO/s2nqwuWL\npBH6XQ==\n-----END CERTIFICATE-----\nsubject=/C=US/ST=California/L=Mountain View/O=Google\nInc/CN=www.google.com\nissuer=/C=US/O=Google Inc/CN=Google Internet Authority G2\n--snip--\nListing 13-1: Establishing a TLS connection with www.google.com and receiving\ncertificates to authenticate the connection\nI’ve trimmed the output to show only the interesting part, which is the\ncertificate. Notice that before the first certificate (which starts with the\nBEGIN CERTIFICATE tag) is a description of the certificate chain, where the\nline starting with s: describes the subject name and the line starting with\ni: describes the issuer of the signature. Here, certificate 0 is the one\nreceived by google.com ❶, certificate 1 ❷ belongs to the entity that signed\ncertificate 0, and certificate 2 ❸ belongs to the entity that signed\ncertificate 1. The organization that issued certificate 2 (GeoTrust)\ngranted permission to Google Internet Authority to issue a certificate\n(certificate 1) for the domain name www.google.com, thereby transferring\ntrust to Google Internet Authority.\nObviously, these CA organizations must be trustworthy and only issue\ncertificates to trustworthy entities, and they must protect their private\nkeys in order to prevent an attacker from issuing certificates on their\nbehalf (for example, in order to impersonate a legitimate google.com\nserver).\nTo see what’s in a certificate, we enter the command shown in Listing\n13-2 into a Linux terminal and then paste the first certificate shown in\nListing 13-1.\n$ openssl x509 –text –noout\n-----BEGIN CERTIFICATE-----\n--snip--\n-----END CERTIFICATE-----\nCertificate:\nData:\nVersion: 3 (0x2)\nSerial Number: 5200243873191028410 (0x482afa4026f3e6ba)\nSignature Algorithm: sha256WithRSAEncryption\nIssuer: C=US, O=Google Inc, CN=Google Internet Authority G2\nValidity\nNot Before: Dec 15 14:07:56 2016 GMT\nNot After : Mar 9 13:35:00 2017 GMT\nSubject: C=US, ST=California, L=Mountain View, O=Google Inc,\nCN=www.google.com\nSubject Public Key Info:\nPublic Key Algorithm: rsaEncryption\nPublic-Key: (2048 bit)\nModulus:\n00:bc:bc:b2:f3:1a:16:3b:c6:f6:9d:28:e1:ef:8e:\n92:9b:13:b2:ae:7b:50:8f:f0:b4:e0:36:8d:09:00:\n--snip--\n8f:e6:96:fe:41:41:85:9d:a9:10:9a:09:6e:fc:bd:\n43:fa:4d:c6:a3:55:9a:9e:07:8b:f9:b1:1e:ce:d1:\n22:49\nExponent: 65537 (0x10001)\n--snip--\nSignature Algorithm: sha256WithRSAEncryption\n94:cd:66:55:83:f1:16:7d:46:d8:66:21:06:ec:c6:9d:7c:1c:\n2b:c1:f6:4f:b7:3e:cd:01:ad:69:bd:a1:81:6a:7c:96:f5:9c:\n--snip--\n85:fa:2b:99:35:05:04:31:c3:d1:e3:bf:b3:69:ea:c2:e5:8b:\na4:11:fa:5d\nListing 13-2: Decoding a certificate received from www.google.com\nWhat you see in Listing 13-2 is the command openssl x509 decoding a\ncertificate, originally provided as a block of base64-encoded data. Because\nOpenSSL knows how this block of data is structured, it can tell us what’s\ninside the certificate, including a serial number and version information,\nidentifying information, validity dates (the Not Before and Not After lines),\na public key (here as an RSA modulus and its public exponent), and a\nsignature of the preceding information.\nAlthough security experts and cryptographers often claim the whole\ncertificate system is broken by design, it’s one of the best solutions we\nhave, along with the trust-on-first-use (TOFU) policy adopted by SSH,\nfor example.\nThe Record Protocol\nAll data exchanged through TLS 1.3 communications is transmitted as\nsequences of TLS records, the data packets used by TLS. The TLS record\nprotocol (the record layer) is essentially a transport protocol, agnostic of\nthe transported data’s meaning; this is what makes TLS suitable for any\napplication.\nThe TLS record protocol is first used to carry the data exchanged\nduring the handshake. Once the handshake is complete and both parties\nshare a secret key, application data is fragmented into chunks that are\ntransmitted as part of the TLS records.\nStructure of a TLS Record\nA TLS record is a chunk of data of at most 16 kilobytes, structured as\nfollows:\nThe first byte represents the type of data transmitted and is set to the\nvalue 22 for handshake data, 23 for encrypted data, and 21 for alerts.\nIn the TLS 1.3 specifications, this value is called ContentType.\nThe second and third byte are set to 3 and 1, respectively. These\nbytes are fixed for historical reasons and are not unique to TLS\nversion 1.3. In the specifications, this 2-byte value is called\nProtocolVersion.\nThe fourth and fifth bytes encode the length of the data to transmit\nas a 16-bit integer, which can be no larger than 214 bytes (16KB).\nThe rest of the bytes are the data to transmit (also called the payload),\nof a length equal to the value encoded by the record’s fourth and\nfifth bytes.\nNOTE\nA TLS record has a relatively simple structure. As we’ve seen, a TLS\nrecord’s header includes only three fields. For comparison, an IPv4 packet\nincludes 14 fields before its payload and a TCP segment includes 13 fields.\nWhen the first byte of a TLS 1.3 record (ContentType) is set to 23, its\npayload is encrypted and authenticated using an authenticated cipher.\nThe payload consists of a ciphertext followed by an authentication tag,\nwhich the receiving end will decrypt. But then how does the recipient\nknow which cipher and key to decrypt with? That’s the magic of TLS: if\nyou receive an encrypted TLS record, you already know the cipher and\nkey, because they are established when the TLS handshake protocol is\nexecuted.\nNonces\nUnlike many other protocols such as IPsec’s Encapsulating Security\nPayload (ESP), TLS records don’t specify the nonce to be used by the\nauthenticated cipher.\nThe nonces used to encrypt and decrypt TLS records are derived from\n64-bit sequence numbers, maintained locally by each party, and\nincremented for each new record. When the client encrypts data, it\nderives a nonce by XORing the sequence number with a value called\nclient_write_iv, itself derived from the shared secret. The server uses a\nsimilar method but with a different value, called server_write_iv.\nFor example, if you transmit three TLS records, you’ll derive a nonce\nfrom 0 for the first record, from 1 for the second, and from 2 for the\nthird; if you then receive three records, you’ll also use nonces 0, 1, and 2,\nin this order. Reuse of the same sequence numbers values for encrypting\ntrans​\nmitted data and decrypting receiving data isn’t a weakness because they\nare XORed with different constants (client_write_iv and server_write_iv)\nand because you use different secret keys for each direction.\nZero Padding\nTLS 1.3 records support a nice feature known as zero padding that\nmitigates traffic analysis attacks. Traffic analysis is a method that attackers\nuse to extract information from traffic patterns using timing, volume of\ndata transferred, and so on. For example, because ciphertexts are\napproximately the same size as plaintexts, even when strong encryption is\nused, attackers can determine the approximate size of your messages\nsimply by looking at the length of their ciphertext.\nZero padding adds zeros to the plaintext in order to inflate the\nciphertext’s size, and thus to fool observers into thinking that an\nencrypted message is longer than it really is.\nThe TLS Handshake Protocol\nThe handshake is the key TLS agreement protocol—the process by which\na client and server establish shared secret keys in order to initiate secure\ncommunications. During the course of a TLS handshake, the client and\nserver play different roles. The client proposes some configurations (the\nTLS version and a suite of ciphers, in order of preference) and the server\nchooses the configuration to be used. The server should follow the\nclient’s preferences, but it may do otherwise. In order to ensure\ninteroperability between implementations and to guarantee that any\nserver implementing TLS 1.3 will be able to read TLS 1.3 data sent by\nany client implementing TLS 1.3 (even if it’s using a different library or\nprogramming language), the TLS 1.3 specifications also describe the\nformat in which data should be sent.\nFigure 13-1 shows how data is exchanged in the handshake process, as\ndescribed in the TLS 1.3 specifications. As you can see, in the TLS 1.3\nhandshake, the client sends a message to the server saying, “I want to\nestablish a TLS connection with you. Here are the ciphers that I support\nto encrypt TLS records, and here is a Diffie–Hellman public key.” The\npublic key must be generated specifically for this TLS session, and the\nclient keeps the associated private key. The message sent by the client\nalso includes a 32-byte random value and optional information (additional\nparameters and such). This first message is called ClientHello, and it must\nfollow a specific format when transmitted as a series of bytes, as defined\nin the TLS 1.3 specification.\nFigure 13-1: The TLS 1.3 handshake process when connecting to HTTPS websites\nBut note that the specifications also describe in what format data\nshould be sent, in order to ensure interoperability between\nimplementations by guaranteeing that any server implementing TLS 1.3\nwill be able to read TLS 1.3 data sent by any client implementing TLS\n1.3, possibly using a different library or programming language.\nThe server receives the ClientHello message, verifies that it’s correctly\nformatted, and responds with a message called ServerHello. The\nServerHello message is loaded with information: it contains the cipher to\nbe used to encrypt TLS records, a Diffie–Hellman public key, a 32-byte\nrandom value (discussed in “Downgrade Protection” on page 244), a\ncertificate, a signature of all the previous information in ClientHello and\nServerHello messages (computed using the private key associated with\nthe certificate’s public key), a MAC of that same information plus the\nsignature. The MAC is computed using a symmetric key derived from the\nDiffie–Hellman shared secret, which the server computes from its Diffie–\nHellman private key and the client’s public key.\nWhen the client receives the ServerHello message, it verifies the\ncertificate’s validity, verifies the signature, computes the shared Diffie–\nHellman secret and derives symmetric keys from it, and verifies the MAC\nsent by the server. Once everything has been verified, the client is ready\nto send encrypted messages to the server.\nNote, however, that TLS 1.3 supports many options and extensions, so\nit may behave differently than what has been described here (and shown\nin Figure 13-1). You can, for example, configure the TLS 1.3 handshake\nto require a client certificate so that the server verifies the identity of the\nclient. TLS 1.3 also supports a handshake with pre-shared keys.\nNOTE\nTLS 1.3 supports many options and extensions, so it may behave differently\nthan what has been described here (and shown in Figure 13-1). You can, for\nexample, configure the TLS 1.3 handshake to require a client certificate so\nthat the server verifies the identity of the client. TLS 1.3 also supports a\nhandshake with pre-shared keys.\nLet’s look at this in practice. Say you’ve deployed TLS 1.3 to provide\nsecure access to the website https://www.nostarch.com/. When you point\nyour browser (the client) to this site, your browser sends a ClientHello\nmessage to the site’s server that includes the ciphers that it supports. The\nwebsite responds with a ServerHello message and a certificate that\nincludes a public key associated with the domain www.nostarch.com. The\nclient verifies the certificate’s validity using one of the certificate\nauthorities embedded in the browser (the received certificate should be\nsigned by a trusted certificate authority, whose certificate should be\nincluded in the browser’s certificate store in order to be validated). Once\nall checks are passed, the browser requests the site’s initial page from the\nwww.nostarch.com server.\nUpon a successful TLS 1.3 handshake, all communications between the\nclient and the server are encrypted and authenticated. An eavesdropper\ncan learn that a client at a given IP address is talking to a server at\nanother given IP address, and can observe the encrypted content\nexchanged, but won’t be able to learn the underlying plaintext or modify\nthe encrypted messages (if they do, the receiving party will notice that the\ncommunication has been tampered with, because messages are not only\nencrypted but also authenticated). That’s enough security for many\napplications.\nTLS 1.3 Cryptographic Algorithms\nWe know that TLS 1.3 uses authenticated encryption algorithms, a key\nderivation function (a hash function that derives secret keys from a shared\nsecret), as well as a Diffie–Hellman operation. But how exactly do these\nwork, what algorithms are used, and how secure are they?\nWith regard to the choice of authenticated ciphers, TLS 1.3 supports\nonly three algorithms: AES-GCM, AES-CCM (a slightly less efficient\nmode than GCM), and the ChaCha20 stream cipher combined with the\nPoly1305 MAC (as defined in RFC 7539). Because TLS 1.3 prevents you\nfrom using an unsafe key length such as 64 or 80 bits (which are both too\nshort), the secret key can be either 128 bits (AES-GCM or AES-CCM)\nor 256 bits (AES-GCM or ChaCha20-Poly1305).\nThe key derivation operation (KDF) in Figure 13-1 is based on\nHKDF, a construction based on HMAC (discussed in Chapter 7) and\ndefined in RFC 5869 that uses either the SHA-256 or the SHA-384 hash\nfunction.\nYour options for performing the Diffie–Hellman operation (the core of\nthe TLS 1.3 handshake) are limited to elliptic curve cryptography and a\nmultiplicative group of integers modulo a prime number (as in traditional\nDiffie–Hellman). But you can’t use just any elliptic curve or group: the\nsupported curves include three NIST curves as well as Curve25519\n(discussed in Chapter 12) and Curve448, both defined in RFC 7748. TLS\n1.3 also supports DH over groups of integers, as opposed to elliptic\ncurves. The groups supported are the five groups defined in RFC 7919:\ngroups of 2048, 3072, 4096, 6144, and 8192 bits.\nThe 2048-bit group may be TLS 1.3’s weakest link. Whereas the other\noptions provide at least 128-bit security, 2048-bit Diffie–Hellman is\nbelieved to provide less than 100-bit security. Supporting a 2048-bit\ngroup can therefore be seen as inconsistent with other TLS 1.3 design\nchoices.\nTLS 1.3 Improvements over TLS 1.2\nTLS 1.3 is very different from its predecessor. For one thing, it gets rid\nof weak algorithms like MD5, SHA-1, RC4, and AES in CBC mode.\nAlso, whereas TLS 1.2 often protected records using a combination of a\ncipher and a MAC (such as HMAC-SHA-1) within a MAC-then-encrypt\nconstruction, TLS 1.3 only supports the more efficient and more secure\nauthenticated ciphers. TLS 1.3 also ditches elliptic curve point encoding\nnegotiation, and defines a single point format for each curve.\nOne of the main development goals of TLS 1.3 was to remove features\nin 1.2 that weakened the protocol and to reduce the protocol’s overall\ncomplexity and thereby its attack surface. For example, TLS 1.3 ditches\noptional data compression, a feature that enabled the CRIME attack on\nTLS 1.2. This attack exploited the fact that the length of the compressed\nversion of a message leaks information on the content of the message.\nBut TLS 1.3 also brings new features that make connections either\nmore secure or more efficient. I’ll discuss three of these features briefly:\ndowngrade protection, the single round-trip handshake, and session\nresumption.\nDowngrade Protection\nTLS 1.3’s downgrade protection feature is designed as a defense against\ndowngrade attacks, wherein an attacker forces the client and server to use a\nweaker version of TLS than 1.3. To carry out a downgrade attack, an\nattacker forces the server to use a weaker version of TLS by intercepting\nand modifying the ClientHello message to tell the server that the client\ndoesn’t support TLS 1.3. Now the attacker can exploit vulnerabilities in\nearlier versions of TLS.\nIn an effort to defeat downgrade attacks, the TLS 1.3 server uses three\ntypes of patterns in the 32-byte random value sent within the ServerHello\nmessage to identify the type of connection requested. The pattern should\nmatch the client’s request for a specific type of TLS connection. If the\nclient receives the wrong pattern, it knows that something is up.\nSpecifically, if the client asks for a TLS 1.2 connection, the first eight\nof the 32 bytes are set to 44 4F 57 4E 47 52 44 01, and if it asks for a TLS\n1.1 connection, they’re set to 44 4F 57 4E 47 52 44 00. However, if the\nclient requests a TLS 1.3 connection, these first eight bits should be\nrandom. For example, if a client sends a ClientHello asking for a TLS 1.3\nconnection, but an attacker on the network modifies it to ask for a TLS\n1.1 connection, when the client receives the ServerHello with the wrong\npattern, it will know that its ClientHello message was modified. (The\nattacker can’t arbitrarily modify the server’s 32-byte random value\nbecause this value is cryptographically signed.)\nSingle Round-Trip Handshake\nIn a typical TLS 1.2 handshake, the client sends some data to the server,\nwaits for a response, and then sends more data and waits for the server’s\nresponse before sending encrypted messages. The delay is that of two\nround-trip times (RTT). In contrast, TLS 1.3’s handshake takes a single\nround-trip time, as shown in Figure 13-1. The time saved can be in the\nhundreds of milliseconds. That may sound small, but its actually\nsignificant when you consider that servers of popular services handle\nthousands of connections per second.\nSession Resumption\nTLS 1.3 is faster than 1.2, but it can be made even faster (on the order of\nhundreds of milliseconds) by completely eliminating the round trips that\nprecede an encrypted session. The trick is to use session resumption, a\nmethod that leverages the pre-shared key exchanged between the client\nand server in a previous session to bootstrap a new session. Session\nresumption brings two major benefits: the client can start encrypting\nimmediately, and there is no need to use certificates in these subsequent\nsessions.\nFigure 13-2 shows how session resumption works. First, the client\nsends a ClientHello message that includes the identifier of the key already\nshared (denoted PSK for pre-shared key) with the server, along with a fresh\nDH public key. The client can also include encrypted data in this first\nmessage (such data is known as 0-RTT data). When the server responds to\na ClientHello message, it provides a MAC over the data exchange. The\nclient verifies the MAC and knows that it’s talking to the same server as it\ndid previously, thus rendering certificate validation somewhat\nsuperfluous. The client and the server perform a Diffie–Hellman key\nagreement as in the normal handshake, and subsequent messages are\nencrypted using keys that depend on both the PSK and the newly\ncomputed Diffie–Hellman shared secret.\nFigure 13-2: The TLS 1.3 session resumption handshake. The 0-RTT data is the\nsession resumption data sent along with the ClientHello.\nThe Strengths of TLS Security\nWe’ll evaluate the strengths of TLS 1.3 with respect to two main security\nnotions discussed in Chapter 11: authentication and forward secrecy.\nAuthentication\nDuring the TLS 1.3 handshake, the server authenticates to the client\nusing the certificate mechanism. However, the client is not authenticated,\nand clients may authenticate with a server-based application (such as\nGmail) by providing a username and password in a TLS record after\nperforming the handshake. If the client has already established a session\nwith the remote service, it may authenticate by sending a secure cookie, one\nthat can only be sent through a TLS connection.\nIn certain cases, clients can authenticate to a server using a certificate-\nbased mechanism similar to what the server uses in order to authenticate\nto the client: the client sends a client certificate to the server, which in turn\nverifies this certificate before authorizing the client. However, client\ncertificates are rarely used because they complicate things for both clients\nand the server (that is, the certificate issuer): clients need to perform\ncomplex operations in order to integrate the certificate into their system\nand to protect its private key, while the issuer needs to make sure that\nonly authorized clients received a certificate, among other requirements.\nForward Secrecy\nRecall from “Key Agreement Protocols” on page 205 that a key\nagreement is said to provide forward secrecy if previous sessions aren’t\ncompromised when the present session is compromised. In the data leak\nmodel, only temporary secrets are compromised, whereas in the breach\nmodel, long-term secrets are exposed.\nThankfully, TLS 1.3 forward secrecy holds up in the face of both a\ndata leak and a breach. In the case of the data leak model, the attacker\nrecovers temporary secrets such as the session keys or Diffie–Hellman\nprivate keys of a specific session (the values c, s, secret, and keys in Figure\n13-1 on page 242). However, they can only use these values to decrypt\ncommunications from the present session, but not from previous sessions,\nbecause different values of c and s were used (thus yielding different keys).\nIn the breach model, the attacker also recovers long-term secrets\n(namely, the private key that corresponds to the public key in the\ncertificate). However, this is no more useful when decrypting previous\nsessions than temporary secrets, because this private key only serves to\nauthenticate the server, and forward secrecy holds up again.\nBut what happens in practice? Say an attacker compromises a client’s\nmachine and gains access to all of its memory. Now the attacker may\nrecover the client’s TLS session keys and secrets for the current session\nfrom memory. But more importantly, if previous keys are still in memory,\nthe attacker may be able to find them too and use them to decrypt\nprevious sessions, thereby bypassing the theoretical forward secrecy.\nTherefore, in order for a TLS implementation to ensure forward secrecy,\nit must properly erase keys from memory once they are no longer used,\ntypically by zeroing out the memory.\nHow Things Can Go Wrong\nTLS 1.3 fits the bill as a general-purpose secure communications\nprotocol, but it’s not bulletproof. Like any security system, it can fail\nunder certain circumstances (for example, when the assumptions made by\nits designers about real attacks turn out to be wrong). Unfortunately,\neven the latest version of TLS 1.3, configured with the most secure\nciphers, can still be compromised. For example, TLS 1.3 security relies\non the assumption that all three parties (the client, the server, and the\ncertificate authority) will behave honestly, but what if one party is\ncompromised or the TLS implementation itself is poorly implemented?\nCompromised Certificate Authority\nRoot certificate authorities (root CAs) are organizations that are trusted\nby browsers to validate certificates served by remote hosts. For example,\nif your browser accepts the certificate provided by www.google.com, the\nassumption is that a trusted CA has verified the legitimacy of the\ncertificate owner. The browser verifies the certificate by checking its CA-\nissued signature. Since only the CA knows the private key required to\ncreate this signature, we assume that others can’t create valid certificates\non behalf of the CA. Very often a website’s certificate won’t be signed by\na root CA but by a n inter​mediate CA, which is connected t o the root CA\nthrough a certificate chain.\nBut let’s say that a CA’s private key is compromised. Now the attacker\nwill be able to use the CA’s private key to create a certificate for any\nURLs in, say, the google.com domain without Google’s approval. What\nhappens then? The attacker can use those certificates to pretend to host a\nlegitimate server or subdomain like mail.google.com and intercept a user’s\ncredentials and communications. That’s exactly what happened in 2011\nwhen an attacker hacked into the network of the Dutch certificate\nauthority DigiNotar and was able to create certificates that appeared to\nhave been legitimate DigiNotar certificates. The attacker then used these\nfake certificates for several Google services.\nCompromised Server\nIf a server is compromised and fully controlled by an attacker, all is lost:\nthe attacker will be able to see all transmitted data before it’s encrypted,\nand all received data once it has been decrypted. They will also be able to\nget their hands on the server’s private key, which could allow them to\nimpersonate the legitimate server using their own malicious server.\nObviously, TLS won’t save you in this case.\nFortunately, such security disasters are rarely seen in high-profile\napplications such as Gmail and iCloud, which are well protected and\nsometimes have their private keys stored in a separate security module.\nAttacks on web applications via vulnerabilities such as database query\ninjections and cross-site scripting are more common, because they are\nmostly independent of TLS’s security and are carried out by attackers\nover a legitimate TLS connection. Such attacks may compromise\nusernames, passwords, and so on.\nCompromised Client\nTLS security is also compromised when a client, such as a browser, is\ncompromised by a remote attacker. Having compromised the client, the\nattacker will be able to capture session keys, read any decrypted data, and\nso on. They could even install a rogue CA certificate in the client’s\nbrowser to have it silently accept otherwise invalid certificates, thereby\nletting attackers intercept TLS connections.\nThe big difference between the compromised CA or server scenarios\nand the compromised client scenario is that in the case of the\ncompromised client, only the targeted client will be affected, instead of\npotentially all the clients.\nBugs in Implementations\nAs with any cryptographic system, TLS can fail when there are bugs in its\nimplementation. The poster child for TLS bugs is Heartbleed (see Figure\n13-3), a buffer overflow in the OpenSSL implementation of a minor TLS\nfeature known as heartbeat. Heartbleed was discovered in 2014,\nindependently by a Google researcher and by the Codenomicon\ncompany, and affected millions of TLS servers and clients.\nAs you can see in Figure 13-3, a client first sends a buffer along with a\nbuffer length to the server to check whether the server is online. In this\nexample, the buffer is the string BANANAS, and the client explicitly says\nthat this word is seven letters long. The server reads the seven-letter\nword and returns it to the client.\nFigure 13-3: The Heartbleed bug in OpenSSL implementations of TLS\nThe problem is that the server doesn’t confirm that the length is\ncorrect, and will attempt to read as many characters as the client tells it\nto. Consequently, if the client provides a length that is longer than the\nstring’s actual length, the server reads too much data from memory and\nwill return it to the client, together with any extra data that may contain\nsensitive information, such as private keys or session cookies.\nIt won’t surprise you to hear that the Heartbleed bug came as a shock.\nTo avoid similar future bugs, OpenSSL and other major TLS\nimplementations now perform rigorous code reviews and use automated\ntools such as fuzzers in order to identify potential issues.\nFurther Reading\nAs I stated at the outset, this chapter is not a comprehensive guide to\nTLS, and you may want to dig deeper into TLS 1.3. For starters, the\ncomplete TLS 1.3 specifications include everything about the protocol\n(though not necessarily about its underlying rationale). You can find that\non the home page of the TLS Working Group (TLSWG) here:\nhttps://tlswg.github.io/.\nIn addition, let me cite two important TLS initiatives:\nSSL Labs TLS test (https://www.ssllabs.com/ssltest/) is a free service by\nQualys that lets you test a browser’s or a server’s TLS configuration,\nproviding a security rating as well as improvement suggestions. If\nyou set up your own TLS server, use this test to make sure that\neverything is safe and that you get an “A” rating.\nLet’s Encrypt (https://letsencrypt.org/) is a nonprofit that offers a\nservice to “automagically” deploy TLS on your HTTP servers. It\nincludes features to automatically generate a certificate and configure\nthe TLS server, and it supports all the common web servers and\noperating systems."
  },
  {
    "input": "What are post-quantum algorithms and why are they important in the context of quantum computing?",
    "summary": "This chapter discusses the future of cryptography in the presence of quantum computers, which could break current public-key systems like RSA and elliptic curve cryptography. Researchers have developed post-quantum algorithms to counter this threat, with the NSA and NIST leading efforts to standardize them. The chapter also explains how quantum computers work using qubits and quantum gates, highlighting their potential for exponential speed-ups in solving problems like factoring and discrete logarithms, which could compromise modern encryption.",
    "output": "14\nQUANTUM AND POST-QUANTUM\nPrevious chapters focused on cryptography today, but in this chapter I’ll\nexamine the future of cryptography over a time horizon of, say, a century\nor more—one in which quantum computers exist. Quantum computers are\ncomputers that leverage phenomena from quantum physics in order to\nrun different kinds of algorithms than the ones we’re used to. Quantum\ncomputers don’t exist yet and look very hard to build, but if they do exist\none day, then they’ll have the potential to break RSA, Diffie–Hellman,\nand elliptic curve cryptography—that is, all the public-key crypto\ndeployed or standardized as of this writing.\nTo insure against the ri sk posed by quantum comput ers, crypto​graph y\nresearchers have developed alternative public-key crypto algorithms\ncalled post-quantum algorithms that would resist quantum computers. In\n2015, the NSA called for a transition to quantum-resistant algorithms\ndesigned to be safe even in the face of quantum computers, and in 2017\nthe US standardization agency NIST began a process that will eventually\nstandardize post-quantum algorithms.\nThis chapter will thus give you a nontechnical overview of the\nprinciples behind quantum computers as well as a glimpse of post-\nquantum algorithms. There’s some math involved, but nothing more\nthan basic arithmetic and linear algebra, so don’t be scared by the unusual\nnotations.\nHow Quantum Computers Work\nQuantum computing is a model of computing that uses quantum physics\nto compute differently and do things that classical computers can’t, such\nas breaking RSA and elliptic curve cryptography efficiently. But a\nquantum computer is not a super-fast normal computer. In fact, quantum\ncomputers can’t solve any problem that is too hard for a classical\ncomputer, such as brute force search or NP-complete problems.\nQuantum computers are based on quantum mechanics, the branch of\nphysics that studies the behavior of subatomic particles, which behave\ntruly randomly. Unlike classical computers, which operate on bits that are\neither 0 or 1, quantum computers are based on quantum bits (or qubits),\nwhich can be both 0 and 1 simultaneously—a state of ambiguity called\nsuperposition. Physicists discovered that in this microscopic world, particles\nsuch as electrons and photons behave in a highly counterintuitive way:\nbefore you observe an electron, the electron is not at a definite location in\nspace, but in several locations at the same time (that is, in a state of\nsuperposition). But once you observe it—an operation called measurement\nin quantum physics—then it stops at a fixed, random location and is no\nlonger in superposition. This quantum magic is what enables the creation\nof qubits in a quantum computer.\nBut quantum computers only work because of a crazier phenomenon\ncalled entanglement: two particles can be connected (entangled) in a way\nthat observing the value of one gives the value of the other, even if the\ntwo particles are widely separated (kilometers or even light-years away\nfrom each other). This behavior is illustrated by the Einstein–Podolsky–\nRosen (EPR) paradox and is the reason why Albert Einstein initially\ndismissed quantum mechanics. (See https://plato.stanford.edu/entries/qt-epr/\nfor an in-depth explanation of why.)\nTo best explain how a quantum computer works, we should distinguish\nthe actual quantum computer (the hardware, composed of quantum bits)\nfrom quantum algorithms (the software that runs on it, composed of\nquantum gates). The next two sections discuss these two notions.\nQuantum Bits\nQuantum bits (qubits), or groups thereof, are characterized with numbers\ncalled amplitudes, which are akin to probabilities but aren’t exactly\nprobabilities. Whereas a probability is a number between 0 and 1, an\namplitude is a complex number of the form a + b × i, or simply a + bi,\nwhere a and b are real numbers, and i is an imaginary unit. The number i\nis used to form imaginary numbers, which are of the form bi, with b a real\nnumber. When i is multiplied by a real number, we get another imaginary\nnumber, and when it is multiplied by itself it gives –1; that is i2 = –1.\nUnlike real numbers, which can be seen as belonging to a line (see\nFigure 14-1), complex numbers can be seen as belonging to a plane (a space\nwith two dimensions), as shown in Figure 14-2. Here, the x-axis in the\nfigure corresponds to the a in a + bi, the y-axis corresponds to the b, and\nthe dotted lines correspond to the real and imaginary part of each\nnumber. For example, the vertical dotted line going from the point 3 + 2i\ndown to 3 is two units long (the 2 in the imaginary part 2i).\nFigure 14-1: View of real numbers as points on an infinite straight line\nFigure 14-2: A view of complex numbers as points in a two-dimensional space\nAs you can see in Figure 14-2, you can use the Pythagorean theorem to\ncompute the length of the line going from the origin (0) to the point a +\nbi by viewing this line as the diagonal of a triangle. The length of this\ndiagonal is equal to the square root of the sum of the squared coordinates\nof the point, or √(a2 + b2), which we call the modulus of the complex\nnumber a + bi. We denote the modulus as |a + bi| and can use it as the\nlength of a complex number.\nIn a quantum computer, registers consist of 1 or more qubits in a state\nof superposition characterized by a set of such complex numbers. But as\nwe’ll see, these complex numbers—the amplitudes—can’t be any\nnumbers.\nAmplitudes of a Single Qubit\nA single qubit is characterized by two amplitudes that I’ll call α (alpha)\nand β (beta). We can then express a qubit’s state as α |0〉 + β |1〉,\nwhere the “| 〉” notation is used to denote vectors in a quantum state.\nThis notation then means that when you observe this qubit it will appear\nas 0 with a probability |α|2 and 1 with a probability |β|2. Of course, in\norder for these to be actual probabilities, |α|2 and |β|2 must be numbers\nbetween 0 and 1, and |α|2 + |β|2 must be equal to 1.\nFor example, say we have the qubit (psi) with amplitudes of α = 1/√2\nand β = 1/√2. We can express this as follows:\nThis notation means that in the qubit , the value 0 has an amplitude\nof 1/√2, and the value 1 has the same amplitude, 1/√2. To get the actual\nprobability from the amplitudes, we compute the modulus of 1/√2 (which\nis equal to 1/√2, because it has no imaginary part), then square it: (1/√2)2\n= 1/2. That is, if you observe the qubit , you’ll have a 1/2 chance of\nseeing a 0, and the same chance of seeing a 1.\nNow consider the qubit Φ (phi), where\nThe qubit Φ is fundamentally distinct from because unlike , where\namplitudes have equal values, the qubit Φ has distinct amplitudes of α = i/\n√2 (a positive imaginary number) and β = –1/√2 (a negative real number).\nIf, however, you observe Φ, the chance of your seeing a 0 or 1 is 1/2, the\nsame as it is with . Indeed, we can compute the probability of seeing a 0\nas follows, based on the preceding rules:\nNOTE\nBecause α = i/√2, α can be written as a + bi with a = 0 and b = 1/√2, and\ncomputing |α| = √(a2 + b2) yields 1/√2.\nThe upshot is that different qubits can behave similarly to an observer\n(with the same probability of seeing a 0 for both qubits) but have different\namplitudes. This tells us that the actual probabilities of seeing a 0 or a 1\nonly partially characterize a qubit; just as when you observe the shadow of\nan object on a wall, the shape of the shadow will give you an idea of the\nobject’s width and height, but not of its depth. In the case of qubits, this\nhidden dimension is the value of its amplitude: Is it positive or negative?\nIs it a real number or an imaginary number?\nNOTE\nTo simplify notations, a qubit is often simply written as its pair of amplitudes\n(α, β). Our previous example can then be written | 〉 = (1/√2, 1/√2).\nAmplitudes of Groups of Qubits\nWe’ve explored single qubits, but how do we understand multiple qubits?\nFor example, a quantum byte can be formed with 8 qubits, when put into a\nstate where the quantum states of these 8 qubits are somehow connected\nto each other (we say that the qubits are entangled, which is a complex\nphysical phenomenon). Such a quantum byte can be described as follows,\nwhere the αs are the amplitudes associated with each of the 256 possible\nvalues of the group of 8 qubits:\nNote that we must have |α |2 + |α |2 + . . . + |α |2 = 1, so that all\n0 1 255\nprobabilities sum to 1.\nOur group of 8 qubits can be viewed as a set of 28 = 256 amplitudes,\nbecause it has 256 possible configurations, each with its own amplitude.\nIn physical reality, however, you’d only have eight physical objects, not\n256. The 256 amplitudes are an implicit characteristic of the group of 8\nqubits; each of these 256 numbers can take any of infinitely many\ndifferent values. Generalizing, a group of n qubits is characterized by a set\nof 2n complex numbers, a number that grows exponentially with the\nnumbers of qubits.\nThis encoding of exponentially many high-precision complex numbers\nis a core reason why a classical computer can’t simulate a quantum\ncomputer: in order to do so, it would need an unfathomably high amount\nof memory (of size around 2n) to store the same amount of information\ncontained in only n qubits.\nQuantum Gates\nThe concepts of amplitude and quantum gates are unique to quantum\ncomputing. Whereas a classical computer uses registers, memory, and a\nmicroprocessor to perform a sequence of instructions on data, a quantum\ncomputer transforms a group of qubits reversibly by applying a series of\nquantum gates, and then measures the value of one or more qubits.\nQuantum computers promise more computing power because with only n\nqubits, they can process 2n numbers (the qubits’ amplitudes). This\nproperty has profound implications.\nFrom a mathematical standpoint, quantum algorithms are essentially a\ncircuit of quantum gates that transforms a set of complex numbers (the\namplitudes) before a final measurement where the value of 1 or more\nqubits is observed (see Figure 14-3). You’ll also see quantum algorithms\nreferred to as quantum gate arrays or quantum circuits.\nFigure 14-3: Principle of a quantum algorithm\nQuantum Gates as Matrix Multiplications\nUnlike the Boolean gates of a classical computer (AND, XOR, and so\non), a quantum gate acts on a group of amplitudes just as a matrix acts\nwhen mul t i​pl i ed with a vector. For examp l e, i n order to appl y the simplest\nquantum gate, the identity gate, to the qubit Φ, we see I as a 2 × 2 matrix\nand multiply it with the column vector consisting of the two amplitudes\nof Φ, as shown here:\nThe result of this matrix–vector multiplication is another column\nvector with two elements, where the top value is equal to the dot product\nof the I matrix’s first line with the input vector (the result of adding the\nproduct of the first elements 1 and i/√2 to the product of the second\nelements 0 and –1/√2), and likewise for the bottom value.\nNOTE\nIn practice, a quantum computer wouldn’t explicitly compute matrix–vector\nmultiplications because the matrices would be way too large. (That’s why\nquantum computing can’t be simulated by a classical computer.) Instead, a\nquantum computer would transform qubits as physical particles through\nphysical transformations that are equivalent to a matrix multiplication.\nConfused? Here’s what Richard Feynman had to say: “If you are not\ncompletely confused by quantum mechanics, you do not understand it.”\nThe Hadamard Quantum Gate\nThe only quantum gate we’ve seen so far, the identity gate I, is pretty\nuseless because it doesn’t do anything and leaves a qubit unchanged. Now\nwe’re going to see one of the most useful quantum gates, called the\nHadamard gate, usually denoted H. The Hadamard gate is defined as\nfollows (note the negative value in the bottom-right position):\nLet’s see what happens if we apply this gate to the qubit | 〉 = (1/√2,\n1/√2):\nBy applying the Hadamard gate H to | 〉, we obtain the qubit |0〉\nfor which the value |0〉 has amplitude 1, and |1〉 has amplitude 0. This\ntells us that the qubit will behave deterministically: that is, if you observe\nthis qubit, you would always see a 0 and never a 1. In other words, we’ve\nlost the randomness of the initial qubit | 〉.\nWhat happens if we apply the Hadamard gate again to the qubit |0〉?\nThis brings us back to the qubit | 〉 and a randomized state. Indeed,\nthe Hadamard gate is often used in quantum algorithms to go from a\ndeterministic state to a uniformly random one.\nNot All Matrices are Quantum Gates\nAlthough quantum gates can be seen as matrix multiplications, not all\nmatrices correspond to quantum gates. Recall that a qubit consists of the\ncomplex numbers α and β and the amplitudes of the qubit, such that they\nsatisfy the condition |α|2 + |β|2 = 1. If after multiplying a qubit by a\nmatrix we get two amplitudes that don’t match this condition, the result\ncan’t be a qubit. Quantum gates can only correspond to matrices that\npreserve the property |α|2 + |β|2 = 1, and matrices that satisfy this\ncondition are called unitary matrices.\nUnitary matrices (and quantum gates by definition) are invertible,\nmeaning that given the result of an operation, you can compute back the\noriginal qubit by applying the inverse matrix. This is the reason why\nquantum computing is said to be a kind of reversible computing.\nQuantum Speed-Up\nA quantum speed-up occurs when a problem can be solved faster by a\nquantum computer than by a classical one. For example, in order to\nsearch for an item among n items of an unordered list on a classical\ncomputer, you need on average n/2 operations, because you need to look\nat each item in the list before finding the one you’re looking for. (On\naverage, you’ll find that item after searching half of the list.) No classical\nalgorithm can do better than n/2. However, a quantum algorithm exists\nto search for an item in only about √n operations, which is orders of\nmagnitude smaller than n/2. For example, if n is equal to 1000000, then\nn/2 is 500000, whereas √n is 1000.\nWe attempt to quantify the difference between quantum and classical\nalgorithms in terms of time complexity, which is represented by O()\nnotation. In the previous example, the quantum algorithm runs in time\nO(√n) but the classical algorithm can’t be faster than O(n). Because the\ndifference in time complexity here is due to the square exponent, we call\nthis quadratic speed-up. But while such a speed-up will likely make a\ndifference, there are much more powerful ones.\nExponential Speed-Up and Simon’s Problem\nExponential speed-ups are the Holy Grail of quantum computing. They\noccur when a task that takes an exponential amount of time on a classical\ncomputer, such as O(2n), can be performed on a quantum computer with\npolynomial complexity—namely O(nk) for some fixed number k. This\nexponential speed-up can turn a practically impossible task into a possible\none. (Recall from Chapter 9 that cryptographers and complexity theorists\nassociate exponential time with the impossible, and they associate\npolynomial time with the practical.)\nThe poster child of exponential speed-ups is Simon’s problem. In this\ncomputational problem, a function, f(), transforms n-bit strings to n-bit\nstrings, such that the output of f() looks random except that there is a\nvalue, m, such that any two values x, y that satisfies f(x) = f(y), then y = x ⊕\nm. The way to solve this problem is to find m.\nThe route to take when solving Simon’s problem with a classical\nalgorithm boils down to finding a collision, which takes approximately\n2n/2 queries to f(). However, a quantum algorithm (shown in Figure 14-4)\ncan solve Simon’s problem in approximately n queries, with the extremely\nefficient time complexity of O(n).\nFigure 14-4: The circuit of the quantum algorithm that solves Simon’s problem\nefficiently\nAs you can see in Figure 14-4, you initialize 2n qubits to |0〉, apply\nHadamard gates (H) to the first n qubits, then apply the gate Qf to the\ntwo groups of all n qubits. Given two n-qubit groups x and y, the gate Qf\ntransforms the quantum state |x〉|y〉 to the state |x〉|f(x) ⊕ y〉. That\nis, it computes the function f() on the quantum state reversibly, because\nyou can go from the new state to the old one by computing f(x) and\nXORing it to f(x) ⊕ y. (Unfortunately, explaining why all of this works is\nbeyond the scope of this book.)\nThe exponential speed-up for Simon’s problem can be used against\nsymmetric ciphers only in very specific cases, but in the next section\nyou’ll see some real crypto-killer applications of quantum computing.\nThe Threat of Shor’s Algorithm\nIn 1995, AT&T researcher Peter Shor published an eye-opening article\ntitled “Polynomial-Time Algorithms for Prime Factorization and\nDiscrete Logarithms on a Quantum Computer.” Shor’s algorithm is a\nquantum algorithm that causes an exponential speed-up when solving the\nfactoring, discrete logarithm (DLP), and elliptic curve discrete logarithm\n(ECDLP) problems. You can’t solve these problems with a classical\ncomputer, but you could with a quantum computer. That means that you\ncould use a quantum computer to solve any cryptographic algorithm that\nrelies on those problems, including RSA, Diffie–Hellman, elliptic curve\ncrypto​\ngraphy, and all currently deployed public-key cryptography mechanisms.\nIn other words, you could reduce the security of RSA or elliptic curve\ncrypto​\ngraphy to that of Caesar’s cipher. (Shor might as well have titled his\narticle “Breaking All Public-Key Crypto on a Quantum Computer.”)\nShor’s algorithm has been called “one of the major scientific\nachievements of the late 20th century” by renowned complexity theorist\nScott Aaronson.\nShor’s algorithm actually solves a more general class of problems than\nfactoring and discrete logarithms. Specifically, if a function f() is periodic—\nthat is, if there’s a ω (the period) such that f(x + ω) = f(x) for any x, Shor’s\nalgorithm will efficiently find ω. (This looks very similar to Simon’s\nproblem discussed previously, and indeed Simon’s algorithm was a major\ninspiration for Shor’s algorithm.) The ability of Shor’s algorithm to\nefficiently compute the period of a function is important to\ncryptographers because that ability can be used to attack public-key\ncryptography, as I’ll discuss next.\nA discussion of the details of how Shor’s algorithm achieves its speed-\nup is far too technical for this book, but in this section I’ll show how you\ncould use Shor’s algorithm to attack public-key cryptography. Let’s see\nhow Shor’s algorithm could be used to solve the factoring and discrete\nlogarithm problems (as discussed in Chapter 9), which are respectively\nthe hard problems behind RSA and Diffie–Hellman.\nShor’s Algorithm Solves the Factoring Problem\nSay you want to factor a large number, N = pq. It’s easy to factor N if you\ncan compute the period of ax mod N, a task that is hard to do with a\nclassical computer but easy to do on a quantum one. You first pick a\nrandom number a less than N, and ask Shor’s algorithm to find the period\nω of the function f(x) = ax mod N. Once you’ve found the period, you’ll\nhave ax mod N = ax + ω mod N (that is, ax mod N = axaω mod N), which\nmeans that aω mod N = 1, or aω – 1 mod N = 0. In other words, aω – 1 is a\nmultiple of N, or aω – 1 = kN for some unknown number k.\nThe key observation here is that you can easily factor the number aω – 1\nas the product of two terms, where aω – 1 = (aω / 2 – 1)(aω / 2 + 1). You can\nthen compute the greatest common divisor (GCD) between (aω / 2 – 1)\nand N, and check to see if you’ve obtained a nontrivial factor of N (that is,\na value other than 1 or N). If not, you can just rerun the same algorithm\nwith another value of a. After a few trials, you’ll get a factor of N. You’ve\nnow recovered the private RSA key from its public key, which allows you\nto decrypt messages or forge signatures.\nBut just how easy is this computation? Note that the best classical\nalgorithm to use to factor a number N runs in time exponential in n, the\nbit length of N (that is, n = log N). However, Shor’s algorithm runs in\n2\ntime polynomial in n—namely, O(n2(log n)(log log n)). This means that if\nwe had a quantum computer, we could run Shor’s algorithm and see the\nresult within a reasonable amount of time (days? weeks? months, maybe?)\ninstead of thousands of years.\nShor’s Algorithm and the Discrete Logarithm Problem\nThe challenge in the discrete logarithm problem is to find y, given y = gx\nmod p, for some known numbers g and p. Solving this problem takes an\nexponential amount of time on a classical computer, but Shor’s algorithm\nlets you find y easily thanks to its efficient period-finding technique.\nFor example, consider the function f(a, b) = gayb. Say we want to find\nthe period of this function, the numbers ω and ω′, such that f(a + ω, b + ω\n′) = f(a, b) for any a and b. The solution we seek is then x = –ω / ω′\nmodulo q, the order of g, which is a known parameter. The equality f(a +\nω, b + ω′) = f(a, b) implies gωyω′ mod p = 1. By substituting y with gx, we\nhave gω + xω′ mod p = 1, which is equivalent to ω + xω′ mod q = 0, from\nwhich we derive x = – ω / ω′."
  },
  {
    "input": "What is the impact of Grover's algorithm on the security of symmetric and asymmetric cryptographic algorithms?",
    "summary": "Grover's algorithm provides a quadratic speed-up for searching, reducing the time needed to find a secret key from 2^n to 2^(n/2). This means symmetric encryption can be made quantum-safe by doubling key sizes, while asymmetric algorithms like RSA are vulnerable. Building a practical quantum computer remains challenging due to the fragility of qubits and the difficulty of maintaining stability and low error rates.",
    "output": "Again, the overall complexity is O(n2(log n)(log log n)), with n the bit\nlength of p. This algorithm generalizes to find discrete logarithms in any\ncommutative group, not just the group of numbers modulo a prime\nnumber.\nGrover’s Algorithm\nAfter Shor’s algorithm exponential speed-up for factoring, another\nimportant form of quantum speed-up is the ability to search among n\nitems in time proportional to the square root of n, whereas any classical\nalgorithm would take time proportional to n. This quadratic speed-up is\npossible thanks to Grover’s algorithm, a quantum algorithm discovered in\n1996 (after Shor’s algorithm). I won’t cover the internals of Grover’s\nalgorithm because they’re essentially a bunch of Hadamard gates, but I’ll\nexplain what kind of problem Grover solves and its potential impact on\ncryptographic security. I’ll also show why you can salvage a symmetric\ncrypto algorithm from quantum computers by doubling the key or hash\nvalue size, whereas asymmetric algorithms are destroyed for good.\nThink of Grover’s algorithm as a way to find the value x among n\npossible values, such that f(x) = 1, and where f(x) = 0 for most other\nvalues. If m values of x satisfy f(x) = 1, Grover will find a solution in time\nO(√(n / m)); that is, in time proportional to the square root of n divided\nby m. In comparison, a classical algorithm can’t do better than O(n / m).\nNow consider the fact that f() can be any function. It could be, for\nexample, “f(x) = 1 if and only if x is equal to the unknown secret key K\nsuch that E(K, P) = C” for some known plaintext P and ciphertext C, and\nwhere E() is some encryption function. In practice, this means that if\nyou’re looking for a 128-bit AES key with a quantum computer, you’ll\nfind the key in time proportional to 264, rather than 2128 if you had only\nclassical computers. You would need a large enough plaintext to ensure\nthe uniqueness of the key. (If the plaintext and ciphertext are, say, 32 bits,\nmany candidate keys would map that plaintext to that ciphertext.) The\ncomplexity 264 is much smaller than 2128, meaning that a secret key would\nbe much easier to recover. But there’s an easy solution: to restore 128-bit\nsecurity, just use 256-bit keys! Grover’s algorithm will then reduce the\ncomplexity of searching a key to “only” 2256 / 2 = 2128 operations.\nGrover’s algorithm can also find preimages of hash functions (a notion\ndiscussed in Chapter 6). To find a preimage of some value h, the f()\nfunction is defined as “f(x) = 1 if and only if Hash(x) = h, otherwise f(x) =\n0.” Grover thus gets you preimages of n-bit hashes at the cost of the\norder of 2n/2 operations. As with encryption, to ensure 2n post-quantum\nsecurity, just use hash values twice as large, since Grover’s algorithm will\nfind a preimage of a 2n-bit value in at least 2n operations.\nThe bottom line is that you can salvage symmetric crypto algorithms\nfrom quantum computers by doubling the key or hash value size, whereas\nasymmetric algorithms are destroyed for good.\nNOTE\nThere is a quantum algorithm that finds hash function collisions in time\nO(2n/3), instead of O(2n/2), as with the classic birthday attack. This would\nsuggest that quantum computers can outperform classical computers for\nfinding hash function collisions, except that the O(2n/3)-time quantum\nalgorithm also requires O(2n/3) space, or memory, in order to run. Give\nO(2n/3) worth of computer space to a classic algorithm and it can run a\nparallel collision search algorithm with a collision time of only O(2n/6), which\nis much faster than the O(2n/3) quantum algorithm. (For details of this\nattack, see “Cost Analysis of Hash Collisions” by Daniel J. Bernstein at\nhttp://cr.yp.to/papers.html#collisioncost.)\nWhy Is It So Hard to Build a Quantum Computer?\nAlthough quantum computers can in principle be built, we don’t know\nhow hard it will be or when that might happen, if at all. And so far, it\nlooks really hard. As of early 2017, the record holder is a machine that is\nable to keep 14 (fourteen!) qubits stable for only a few milliseconds,\nwhereas we’d need to keep millions of qubits stable for weeks in order to\nbreak any crypto. The point is, we’re not there yet.\nWhy is it so hard to build a quantum computer? Because you need\nextremely small things to play the role of qubits—about the size of\nelectrons or photons. And because qubits must be so small, they’re also\nextremely fragile.\nQubits must also be kept at extremely low temperatures (close to\nabsolute zero) in order to remain stable. But even at such a freezing\ntemperature, the state of the qubits decays, and they eventually become\nuseless. As of this writing, we don’t yet know how to make qubits that will\nlast for more than a couple of seconds.\nAnother challenge is that qubits can be affected by the environment,\nsuch as heat and magnetic fields, which can create noise in the system,\nand hence computation errors. In theory, it’s possible to deal with these\nerrors (as long as the error rate isn’t too high), but it’s hard to do so.\nCorrecting qubits’ errors requires specific techniques called quantum\nerror-correcting codes, which in turn require additional qubits and a low\nenough rate of error. But we don’t know how to build systems with such a\nlow error rate.\nAt the moment, there are two main approaches to forming qubits, and\ntherefore to building quantum computers: superconducting circuits and\nion traps. Using superconducting circuits is the approach championed by\nlabs at Google and IBM. It’s based on forming qubits as tiny electrical\ncircuits that rely on quantum phenomena from superconductor materials,\nwhere charge carriers are pairs of electrons. Qubits made of\nsuperconducting circuits need to be kept at temperatures close to absolute\nzero, and they have a very short lifetime. The record as of this writing is\nnine qubits kept stable for a few microseconds.\nIon traps, or trapped ions, are made up of ions (charged atoms) and are\nmanipulated using lasers in order to prepare the qubits in specific initial\nstates. Using ion traps was one of the first approaches to building qubits,\nand they tend to be more stable than superconducting circuits. The\nrecord as of this writing is 14 qubits stable for a few milliseconds. But ion\ntraps are slower to operate and seem harder to scale than\nsuperconducting circuits.\nBuilding a quantum computer is really a moonshot effort. The\nchallenge comes down to 1) building a system with a handful of qubits\nthat is stable, fault tolerant, and capable of applying basic quantum gates,\nand 2) scaling such a system to thousands or millions of qubits to make it\nuseful. From a purely physical standpoint, and to the best of our\nknowledge, there is nothing to prevent the creation of large fault-tolerant\nquantum computers. But many things are possible in theory and prove\nhard or too costly to realize in practice (like secure computers). Of\ncourse, the future will tell who is right—the quantum optimists (who\nsometimes predict a large quantum computer in ten years) or the\nquantum skeptics (who argue that the human race will never see a\nquantum computer).\nPost-Quantum Cryptographic Algorithms\nThe field of post-quantum cryptography is about designing public-key\nalgorithms that cannot be broken by a quantum computer; that is, they\nwould be quantum safe and able to replace RSA and elliptic curve–based\nalgorithms in a future where off-the-shelf quantum computers could\nbreak 4096-bit RSA moduli in a snap.\nSuch algorithms should not rely on a hard problem known to be\nefficiently solvable by Shor’s algorithm, which kills the hardness in\nfactoring and discrete logarithm problems. Symmetric algorithms such as\nblock ciphers and hash functions would lose only half their theoretical\nsecurity in the face of a quantum computer but would not be badly\nbroken as RSA. They might constitute the basis for a post-quantum\nscheme.\nIn the following sections, I explain the four main types of post-\nquantum algorithms: code-based, lattice-based, multivariate, and hash-\nbased. Of these, hash-based is my favorite because of its simplicity and\nstrong security guarantees.\nCode-Based Cryptography\nCode-based post-quantum cryptographic algorithms are based on error-\ncorrecting codes, which are techniques designed to transmit bits over a\nnoisy channel. The basic theory of error-correcting codes dates back to\nthe 1950s. The first code-based encryption scheme (the McEliece\ncryptosystem) was developed in 1978 and is still unbroken. Code-based\ncrypto schemes can be used for both encryption and signatures. Their\nmain limitation is the size of their public key, which is typically on the\norder of a hundred kilobytes. But is that really a problem when the\naverage size of a web page is around two megabytes?\nLet me first explain what error-correcting codes are. Say you want to\ntransmit a sequence of bits as a sequence of (say) 3-bit words, but the\ntransmission is unreliable and you’re concerned that 1 or more bits may\nbe incorrectly transmitted: you send 010, but the receiver gets 011. One\nsimple way to address this would be to use a very basic error-correction\ncode: instead of transmitting 010 you would transmit 000111000\n(repeating each bit three times), and the receiver would decode the\nreceived word by taking the majority value for each of the three bits. For\nexample, 100110111 would be decoded to 011 because that pattern\nappears twice. But as you can see, this particular error-correcting code\nwould allow a receiver to correct only up to one error per 3-bit chunk,\nbecause if two errors occur in the same 3-bit chunk, the majority value\nwould be the wrong one.\nLinear codes are an example of less trivial error-correcting codes. In the\ncase of linear codes, a word to encode is seen as an n-bit vector v, and\nencoding consists of multiplying v with an m × n matrix G to compute the\ncode word w = vG. (In this example, m is greater than n, meaning that the\ncode word is longer than the original word.) The value G can be\nstructured such that for a given number t, any t-bit error in w allows the\nrecipient to recover the correct v. In other words, t is the maximum\nnumber of errors that can be corrected.\nIn order to encrypt data using linear codes, the McEliece cryptosystem\nconstructs G as a secret combination of three matrices, and encrypts by\ncomputing w = vG plus some random value, e, which is a fixed number of"
  },
  {
    "input": "What is the key concept behind the security of the McEliece encryption scheme?",
    "summary": "The McEliece encryption scheme uses a public key G, which is the product of three private key matrices A, B, and C. Its security is based on the difficulty of decoding a linear code when only insufficient information is available. Lattice-based cryptography involves mathematical structures called lattices and relies on problems like the Short Integer Solution (SIS) and the Closest Vector Problem (CVP) for its security.",
    "output": "1 bit. Here, G is the public key, and the private key is composed of the\nmatrices A, B, and C such that G = ABC. Knowing A, B, and C allows one\nto decode a message reliably and retrieve w. (You’ll find the decoding step\ndescribed online.)\nThe security of the McEliece encryption scheme relies on the hardness\nof decoding a linear code with insufficient information, a problem known\nto be NP-complete and therefore out of reach of quantum computers.\nLattice-Based Cryptography\nLattices are mathematical structures that essentially consist of a set of\npoints in an n-dimensional space, with some periodic structure. For\nexample, in dimension two (n = 2), a lattice can be viewed as the set of\npoints shown in Figure 14-5.\nFigure 14-5: Points of a two-dimensional lattice, where v and w are basis vectors of\nthe lattice, and s is the closest vector to the star-shaped point\nLattice theory has led to deceptively simple cryptography schemes. I’ll\ngive you the gist of it.\nA first hard problem found in lattice-based crypto is known as short\ninteger solution (SIS). SIS consists of finding the secret vector s of n\nnumbers given (A, b) such that b = As mod q, where A is a random m × n\nmatrix and q is a prime number.\nThe second hard problem in lattice-based cryptography is called"
  },
  {
    "input": "What are the key concepts and challenges associated with post-quantum cryptography, particularly in relation to cryptographic schemes like lattice-based, multivariate, and hash-based methods, and how do they compare to traditional cryptographic systems in terms of security and practical implementation?",
    "summary": "Post-quantum cryptography includes schemes like lattice-based (e.g., LWE and SIS), hash-based (e.g., WOTS), and multivariate cryptography, which are designed to be secure against quantum attacks. However, these schemes face challenges such as unclear security levels, implementation vulnerabilities, and the difficulty of choosing secure parameters. Post-quantum encryption is more critical than signatures because encrypting data with quantum-unsafe algorithms compromises confidentiality, while signatures can be replaced with post-quantum alternatives. Despite these challenges, research is ongoing to improve the security and efficiency of post-quantum cryptographic methods.",
    "output": "learning with errors (LWE). LWE consists of finding the secret vector s of\nn numbers given (A, b), where b = As + e mod q, with A being a random m\n× n matrix, e a random vector of noise, and q a prime number. This\nproblem looks a lot like noisy decoding in code-based cryptography.\nSIS and LWE are somewhat equivalent, and can be restated as\ninstances of the closest vector problem (CVP) on a lattice, or the problem of\nfinding the vector in a lattice closest to a given point, by combining a set\nof basis vectors. The dotted vector s in Figure 14-5 shows how we would\nfind the closest vector to the star-shaped point by combining the basis\nvectors v and w.\nCVP and other lattice problems are believed to be hard both for\nclassical and quantum computers. But this doesn’t directly transfer to\nsecure cryptosystems, because some problems are only hard in the worst\ncase (that is, for their hardest instance) rather than the average case\n(which is what we need for crypto). Furthermore, while finding the exact\nsolution to CVP is hard, finding an approximation of the solution can be\nconsiderably easier.\nMultivariate Cryptography\nMultivariate cryptography is about building cryptographic schemes that are\nas hard to break as it is to solve systems of multivariate equations, or\nequations involving multiple unknowns. Consider, for example, the\nfollowing system of equations involving four unknowns x , x , x , x :\n1 2 3 4\nThese equations consist of the sum of terms that are either a single\nunknown, such as x (or terms of degree one), or the product of two\n4\nunknown values, such as x x (terms of degree two or quadratic terms). To\n2 3\nsolve this system, we need to find the values of x , x , x , x that satisfy all\n1 2 3 4\nfour equations. Equations may be over all real numbers, integers only, or\nover finite sets of numbers. In cryptography, however, equations are\ntypically over numbers modulo some prime numbers, or over binary\nvalues (0 and 1).\nThe problem here is to find a solution that is NP-hard given a random\nquadratic system of equations. This hard problem, known as multivariate\nquadratics (MQ) equations, is therefore a potential basis for post-quantum\nsystems because quantum computers won’t solve NP-hard problems\nefficiently.\nUnfortunately, building a cryptosystem on top on MQ isn’t so\nstraightforward. For example, if we were to use MQ for signatures, the\nprivate key might consist of three systems of equations, L , N, and L ,\n1 2\nwhich when combined in this order would give another system of\nequations that we’ll call P, the public key. Applying the transformations\nL , N, and L consecutively (that is, transforming a group of values as per\n1 2\nthe system of equations) is then equivalent to applying P by transforming\nx , x , x , x to y , y , y , y , defined as follows:\n1 2 3 4 1 2 3 4\nIn such a cryptosystem, L , N, and L are chosen such that L and L\n1 2 1 2\nare linear transformations (that is, having equations where terms are only\nadded, not multiplied) that are invertible, and where N is a quadratic\nsystem of equations that is also invertible. This makes the combination of\nthe three a quadratic system that’s also invertible, but whose inverse is\nhard to determine without knowing the inverses of L , N, and L .\n1 2\nComputing a signature then consists of computing the inverses of L ,\n1\nN, and L applied to some message, M, seen as a sequence of variables, x ,\n2 1\nx , . . . .\n2\nS = L −1(N−1(L −(M)))\n2 1\nVerifying a signature then consists of verifying that P(S) = M.\nAttackers could break such a cryptosystem if they manage to compute\nthe inverse of P, or to determine L , N, and L from P. The actual\n1 2\nhardness of solving such problems depends on the parameters of the\nscheme, such as the number of equations used, the size and type of the\nnumbers, and so on. But choosing secure parameters is hard, and more\nthan one multivariate scheme considered safe has been broken.\nMultivariate cryptography isn’t used in major applications due to\nconcerns about the scheme’s security and because it’s often slow or\nrequires tons of memory. A practical benefit of multivariate signature\nschemes, however, is that it produces short signatures.\nHash-Based Cryptography\nUnlike the previous schemes, hash-based cryptography is based on the\nwell-established security of cryptographic hash functions rather than on\nthe hardness of mathematical problems. Because quantum computers\ncannot break hash functions, they cannot break anything that relies on\nthe difficulty of finding collisions, which is the key idea of hash function–\nbased signature schemes.\nHash-based cryptographic schemes are pretty complex, so we’ll just\ntake a look at their simplest building block: the one-time signature, a trick\ndiscovered around 1979, and known as Winternitz one-time signature\n(WOTS), after its inventor. Here “one-time” means that a private key can\nbe used to sign only one message; otherwise, the signature scheme\nbecomes insecure. (WOTS can be combined with other methods to sign\nmultiple messages, as you’ll see in the subsequent section.)\nBut first, let’s see how WOTS works. Say you want to sign a message\nviewed as a number between 0 and w – 1, where w is some parameter of\nthe scheme. The private key is a random string, K. To sign a message, M,\nwith 0 ≤ M < w, you compute Hash(Hash(. . .(Hash(K))), where the hash\nfunction Hash is repeated M times. We denote this value as HashM(K).\nThe public key is Hashw(K), or the result of w nested iterations of Hash,\nstarting from K.\nA WOTS signature, S, is verified by checking that Hashw – M(S) is\nequal to the public key Hashw(K). Note that S is K after M applications of\nHash, so if we do another w – M applications of Hash, we’ll get a value\nequal to K hashed M + (w – M) = w times, which is the public key.\nThis scheme looks rather dumb, and it has significant limitations:\nSignatures can be forged\nFrom HashM(K), the signature of M, you can compute\nHash(HashM(K)) = HashM + 1(K), which is a valid signature of the\nmessage M + 1. This problem can be fixed by signing not only M, but\nalso w – M, using a second key.\nIt only works for short messages\nIf messages are 8 bits long, there are up to 28 – 1 = 255 possible\nmessages, so you’ll have to compute Hash up to 255 times in order to\ncreate a signature. That might work for short messages, but not for\nlonger ones: for example, with 128-bit messages, signing the message\n2128 – 1 would take forever. A workaround is to split longer messages\ninto shorter ones.\nIt works only once\nIf a private key is used to sign more than one message, an attacker can\nrecover enough information to forge a signature. For example, if w = 8\nand you sign the numbers 1 and 7 using the preceding trick to avoid\ntrivial forgeries, the attacker gets Hash1(K) and Hash7(K′) as a\nsignature of 1, and Hash7(K) and Hash1(K′) as a signature of 7. From\nthese values, the attacker can compute Hashx(K) and Hashx(K′) for any\nx in [1;7] and thus forge a signature on behalf of the owner of K and K′.\nThere is no simple way to fix this.\nState-of-the-art hash-based schemes rely on more complex versions of\nWOTS, combined with tree data structures and sophisticated techniques\ndesigned to sign different messages with different keys. Unfortunately,\nthe resulting schemes produce large signatures (on the order of dozens of\nkilobytes, as with SPHINCS, a state-of-the-art scheme at the time of this\nwriting), and they sometimes have a limit on the number of messages\nthey can sign.\nHow Things Can Go Wrong\nPost-quantum cryptography may be fundamentally stronger than RSA or\nelliptic curve cryptography, but it’s not infallible or omnipotent. Our\nunderstanding of the security of post-quantum schemes and their\nimplementations is more limited than for not-post-quantum\ncryptography, which brings with it increased risk, as summarized in the\nfollowing sections.\nUnclear Security Level\nPost-quantum schemes can appear deceptively strong yet prove insecure\nagainst both quantum and classical attacks. Lattice-based algorithms, such\nas the ring-LWE family of computational problems (versions of the\nLWE problem that work with polynomials), are sometimes problematic.\nRing-LWE is attractive for cryptographers because it can be leveraged to\nbui l d c r ypto​systems that are i n principle as hard to break as it i s to solve\nthe hardest instances of Ring-LWE problems, which can be NP-hard.\nBut when security looks too good to be true, it often is.\nOne problem with security proofs is that they are often asymptotic,\nmeaning that they’re true only for a large number of parameters such as\nthe dimension of the underlying lattice. However, in practice, a much\nsmaller number of parameters is used.\nEven when a lattice-based scheme looks to be as hard to break as some\nNP-hard problem, its security remains hard to quantify. In the case of\nlattice-based algorithms, we rarely have a clear picture of the best attacks\nagainst them and the cost of such an attack in terms of computation or\nhardware, because of our lack of understanding of these recent\nconstructions. This uncertainty makes lattice-based schemes harder to\ncompare against better-understood constructions such as RSA, and this\nscares potential users. However, researchers have been making progress\non this front and hopefully in a few years, lattice problems will be as well\nunderstood as RSA. (For more technical details on the Ring-LWE\nproblem, read Peikert’s excellent survey at\nhttps://eprint.iacr.org/2016/351/.)\nFast Forward: What Happens if It’s Too Late?\nImagine this CNN headline: April 2, 2048: “ACME, Inc. reveals its\nsecretly built quantum computer, launches break-crypto-as-a-service\nplatform.” Okay, RSA and elliptic curve crypto are screwed. Now what?\nThe bottom line is that post-quantum encryption is way more critical\nthan post-quantum signatures. Let’s look at the case of signatures first. If\nyou were still using RSA-PSS or ECDSA as a signature scheme, you\ncould just issue new signatures using a post-quantum signature scheme in\norder to restore your signatures’ trust. You would revoke your older,\nquantum-unsafe public keys and compute fresh signatures for every\nmessage you had signed. After a bit of work, you’d be fine.\nYou would only need to panic if you were encrypting data using\nquantum-\nunsafe schemes, such as RSA-OAEP. In this case all transmitted\nciphertext could be compromised. Obviously, it would be pointless to\nencrypt that plaintext again with a post-quantum algorithm since your\ndata’s confidentiality is already gone.\nBut what about key agreement, with Diffie–Hellman (DH) and its\nelliptic curve counterpart (ECDH)?\nWell, at first glance, the situation looks to be as bad as with encryption:\nattackers who’ve collected public keys ga and gb could use their shiny new\nquantum computer to compute the secret exponent a or b and compute\nthe shared secret gab, and then derive from it the keys used to encrypt\nyour traffic. But in practice, Diffie–Hellman isn’t always used in such a\nsimplistic fashion. The actual session keys used to encrypt your data may\nbe derived from both the Diffie–Hellman shared secret and some internal\nstate of your system.\nFor example, that’s how state-of-the-art mobile messaging systems\nwork, thanks to a protocol pioneered with the Signal application. When\nyou send a new message to a peer with Signal, a new Diffie–Hellman\nshared secret is computed and combined with some internal secrets that\ndepend on the previous messages sent within that session (which can span\nlong periods of time). Such advanced use of Diffie–Hellman makes the\nwork of an attacker much harder, even one with a quantum computer.\nImplementation Issues\nIn practice, post-quantum schemes will be code, not algorithms; that is,\nsoftware running on some physical processor. And however strong the\nalgorithms may be on paper, they won’t be immune to implementation\nerrors, software bugs, or side-channel attacks. An algorithm may be\ncompletely post-quantum in theory but may still be broken by a simple\nclassical computer program because a programmer forgot to enter a\nsemicolon.\nFurthermore, schemes such as code-based and lattice-based algorithms\nrely heavily on mathematical operations, the implementation of which\nuses a variety of tricks to make those operations as fast as possible. But by\nthe same token, the complexity of the code in these algorithms makes\nimplementation more vulnerable to side-channel attacks, such as timing\nattacks, which infer information about secret values based on\nmeasurement of execution times. In fact, such attacks have already been\napplied to code-based encryption (see https://eprint.iacr.org/2010/479/)\nand to lattice-based signature schemes (see\nhttps://eprint.iacr.org/2016/300/).\nThe upshot is that, ironically, post-quantum schemes will be less secure\nin practice at first than non-post-quantum ones, due to vulnerabilities in\ntheir implementations.\nFurther Reading\nTo learn the basics of quantum computation, read the classic Quantum\nComputation and Quantum Information by Nielsen and Chuang\n(Cambridge, 2000). Aaronson’s Quantum Computing Since Democritus\n(Cambridge, 2013), a less technical and more entertaining read, covers\nmore than quantum computing.\nSeveral software simulators will allow you to experiment with quantum\ncomputing. The Quantum Computing Playground at\nhttp://www.quantumplayground.net/ is particularly well designed, with a\nsimple programming language and intuitive visualizations.\nFor the latest research in post-quantum cryptography, see\nhttps://pqcrypto.org/ and the associated conference PQCrypto.\nThe coming years promise to be particularly exciting for post-quantum\ncrypto thanks to NIST’s Post-Quantum Crypto Project, a community\neffort to develop the future post-quantum standard. Be sure to check the\nproject’s website http://csrc.nist.gov/groups/ST/post-quantum-crypto/ for the\nrelated algorithms, research papers, and workshops.\nINDEX\nNumbers\n0-RITT data, 245\n2G mobile communications, 89\n3DES (triple DES), 59, 72–74. See also DES (Data Encryption Standard)\n3G mobile communications, 91, 128\n4G mobile communications, 78, 91, 128, 129\nA\nA5/1, 18, 88–91\nAaronson, Scott, 171, 178, 259, 269\nAdvanced Encryption Standard (AES), 53, 59\nAddRoundKey, 60\nblock size, 54\nvs. DES, 59, 80\nand GCM, 152–154, 159, 161\nimplementations, 62–64\ninternals, 59–62\nKeyExpansion, 60\nMixColumns, 60\nwith Poly1305, 138\nand provable security, 48\nsecurity of, 65\nShiftRows, 60\nSubBytes, 60\nand TLS 1.3, 243–244\nAdvanced Vector Extensions (AVX), 55\nAE. See authenticated encryption (AE)\nAEAD (authenticated encryption with associated data), 16, 149, 157–158\nAES. See Advanced Encryption Standard (AES)\nAES-CBC, 69\nAESENC instruction, 64\nAESENCLAST instruction, 64\nAES-GCM\nefficiency, 154\ninternals, 152–153\nsecurity, 154\nand small tags, 161\nand weak hash keys, 159–161\nAES native instructions (AES-NI), 63–64\nAEZ, 161–162\nAKA (authenticated key agreement), 205–207\nalgebraic attacks, 85\nAlvisi, Lorenzo, 125\namplitude, 252–253\nApple, 218, 231\napplication-specific integrated circuit (ASIC), 79\nassociated data, 149\nasymmetric encryption, 1, 15. See also RSA (Rivest–Shamir–Adleman)\nattack costs, 43–44\nattack models, 10\nblack-box, 11–12\nfor key agreement protocols, 207\ngray-box, 12\nauthenticated ciphers, 148\nwith associated data, 149\nfunctional criteria, 151–152\nnonces, 149–150\nonline, 151\nperformance, 150–151\npermutation-based, 157–158\nsecurity, 150\nstreamability, 151\nauthenticated decryption, 148\nauthenticated Diffie–Hellman, 210–213\nauthenticated encryption (AE), 16, 145\nAES-GCM, 152–154, 159–161\nautheticated ciphers, 148–152\nOCB, 155–156\npermutation-based AEAD, 157–158\nSIV, 156–157\nusing MACs, 146–148\nauthenticated encryption with associated data (AEAD), 16, 149, 157–158\nauthenticated key agreement (AKA), 205–207\nauthentication tag, 16. See also authenticated encryption (AE); MACs\n(message authentication codes)\nAVX (Advanced Vector Extensions), 55\nB\nbacktracking resistance, 26\nbackward secrecy, 26\nBcryptGenRandom() function, 33–34\nBellare, Mihir, 143\nBellaso, Giovan Battista, 3\nBellcore attack, 196–197\nBernstein, Daniel J., 52, 95, 100, 136, 139, 230, 231, 261\nbig-number libraries, 192\nbinary exponentiation, 192\nbirthday attacks, 109\nbirthday paradox, 109\nBitcoin, 106\nbit security, 42–43\nBLAKE, 120\nBLAKE2, 215, 226\nBLAKE2b, 123\nBLAKE2s, 123\ncompression function, 124\ndesign rationale, 123\nblinding attacks, 189\nblock ciphers, 53. See also Advanced Encryption Standard (AES)\nblock size, 54–55\nCBC mode, 67–70\ncodebook attacks, 55\nCTR mode, 71–72\ndecryption algorithm, 54\nECB mode, 65–67\nencryption algorithm, 54\nFeistel schemes, 58–59\nkey schedule, 56\nmeet-in-the-middle attacks, 72–74\nmodes of operation, 65\npadding oracle attacks, 74–75\nrounds, 56\nround keys, 56–57\nsecurity goals, 54\nslide attacks, 56–57\nsubstitution–permutation networks, 57–58\nBluetooth, 78\nBoneh, Dan, 199\nBos, Joppe W., 233\nbroadcast attack model, 95\nBrumley, David, 199\nbrute-force attacks, 41, 90\nC\nCA (certificate authority), 238–240, 247–248\ncache-timing attacks, 63\nCaesar cipher, 2–3\nCAESAR competition, 161\nCanetti, Ran, 143\ncarry-less multiplication (CLMUL), 153\nCBC. See cipher block chaining (CBC)\nCBC-MAC, 134\nCCA (chosen-ciphertext attackers), 11\nCCM (counter with CBC-MAC), 162, 243\nCDH (computational Diffie–Hellman), 204\ncertificate authority (CA), 238–240, 247–248\ncertificate chain, 239, 247\nChaCha20, 95, 120, 138, 243–244\nchaining values, 112\nChinese remainder theorem (CRT), 195–196\nchosen-ciphertext attackers (CCA), 11\nchosen-message attacks, 129\nchosen-plaintext attackers (CPA), 11\nChrome browser, 118, 231\nChuang, Isaac, 269\nciphers, 1\ncipher-based MAC (CMAC), 134–135\ncipher block chaining (CBC), 67–69.\nciphertext stealing, 70\npadding, 69–70\npadding oracle attacks, 74\nciphertext, 2\nciphertext-only attackers (COA), 11\nciphertext stealing, 70\nC language, 63\nClay Mathematics Institute, 46, 171\nclient certificate, 246\nclique problem, 169\nCLMUL (carry-less multiplication), 153\nclosest vector problem (CVP), 264–265\nCMAC (cipher-based MAC), 134–135\nCMAC-AES, 157\nciphertext-only attackers (COA), 11\ncode-based cryptography, 263–264\ncodebook attacks, 55, 90–91\nCodenomicon, 248\ncoding problems, 179\nCohen, Henri, 233\nCold War, 53\ncollision resistance, 109, 113\ncomplexity. See computational complexity\ncomplexity class, 168\ncomplex numbers, 253\ncompression functions, 111\nin BLAKE2, 124\nDavies–Meyer construction, 114\nin Merkle–Damgård construction, 112–113\nin SHA-1, 117\ncomputational complexity, 164\nbounds, 167\nclasses, 168\ncomparison, 166\nconstant factors, 165\nconstant time, 166\nexponential, 165, 167\nexponential factorial, 167\nlinear, 165\nlinearithmic, 165\npolynomial, 166–168\nquadratic, 165\nsuperpolynomial, 166–168\ncomputational complexity theory, 163\ncomputational Diffie–Hellman (CDH), 204\ncomputational hardness, 164\ncomputational security, 40–41\nconfidentiality, 1, 106\nconfusion, 57\nconstant-time implementations, 142\nCoppersmith, Don, 199\ncounter mode (CTR), 71–72, 91, 152\ncounter with CBC-MAC (CCM), 162, 243\nCPA (chosen-plaintext attackers), 11\nCRCs (cyclic redundancy checks), 106\nCRT (Chinese remainder theorem), 195–196\nCryptAcquireContext() function, 34\nCryptGenRandom() function, 33–34\nCrypto++, 199\nCryptocat, 37\ncryptographic security, 39. See also security\nCTR (counter mode), 71–72, 91, 152\ncube attacks, 85\nCurve448, 244\nCurve25519, 230–231, 244\nCurve41417, 231\nCVP (closest vector problem), 264–265\ncyclic redundancy checks (CRCs), 106\nD\nDahlin, Mike, 125\nDamgård, Ivan, 111, 126\nData Encryption Standard. See DES (Data Encryption Standard)\nDatagram Transport Layer Security (DTLS), 237\nDavies–Meyer construction, 114, 117, 124\ndecisional Diffie–Hellman (DDH)\nassumption, 205\nproblem, 204–205\ndecryption, 2\ndedicated hardware, 79\nDeMillo, Richard A., 199\nDES (Data Encryption Standard), 53, 80\n3DES, 59, 72–74\nvs. AES, 59, 80\nblock size, 54\ndouble DES, 73\nFeistel schemes in, 58–59\ndeterministic random bit generator (DRBG), 14, 25, 78\n/dev/random, 32–33\n/dev/urandom, 30–32\nDiehard, 29\ndifferential cryptanalysis, 98–99\nDiffie, Whitfield, 201\nDiffie–Hellman problem, 178\nDiffie–Hellman (DH) protocol, 201\nanonymous, 209–210\nauthenticated, 210–213\nCDH problem, 204\nDDH problem, 204–205\nfunction, 202\ngenerating parameters, 202–203\nand key agreement, 205–208, 225–229\nMQV protocol, 213–214\nand shared secrets, 202, 214–215\nin TLS, 215, 242–243\ntwin problem, 205\nunsafe group parameters, 215–216\ndiffusion, 57\ndigest, 106\nDigiNotar, 248\ndigital signatures, 106, 182, 188–189\ndiscrete logarithm problem (DLP), 174–176\nand CDH problem, 204\nECDLP, 224–225\nand Shor’s algorithm, 259, 260\ndistribution. See probability distribution\ndrand48, 28\nDRBG (deterministic random bit generator), 14, 25, 78\nDTLS (Datagram Transport Layer Security), 237\nDurumeric, Zakir, 36\nE\nECB (electronic codebook), 65–67\nECC (elliptic-curve cryptography), 217\nECDH (elliptic-curve Diffie-Hellman), 226, 232–233\nECDSA. See elliptic curve digital signature algorithm (ECDSA)\nECDLP (elliptic curve discrete logarithm problem), 224–225\nECIES (elliptic curve integrated encryption scheme), 229\nEd448-Goldilocks, 231\nEinstein–Podolsky–Rosen (EPR) paradox, 252\nelliptic curves, 217–218, 244\naddition law, 221\nCurve448, 244\nCurve25519, 230–231\nCurve41417, 231\nEdwards curves, 219\ngroups, 224\nwith integers, 219–220\nNIST curves, 230\norder, 224\npoint at infinity, 222, 224\npoint doubling, 222–223\npoint multiplying, 223\nprime curves, 230\nWeierstrass form, 218\nelliptic-curve cryptography (ECC), 217\nelliptic-curve Diffie-Hellman (ECDH), 226, 232–233\nelliptic curve digital signature algorithm (ECDSA), 226\nand bad randomness, 232\nvs. RSA signatures, 227–228\nsignature generation, 226\nsignature verification, 226–227\nelliptic curve discrete logarithm problem (ECDLP), 224–225\nelliptic curve integrated encryption scheme (ECIES), 229\nembarassingly parallel, 43, 90\nEncapsulating Security Payload (ESP), 241\nencrypt-and-MAC, 146–147\nencryption, 1\nasymmetric, 15\nat-rest, 15\nin-transit, 15\nrandomized, 13\nsecurity, 9\nencrypt-then-MAC, 147–148, 152\nentanglement, 252, 255\nentropy, 23–24, 35–36\nentropy pool, 25\nEPR (Einstein–Podolsky–Rosen) paradox, 252\nerror-correcting codes, 263\nESP (Encapsulating Security Payload), 241\neSTREAM competition, 86, 103\neth roots, 185\nEuler’s theorem, 198\nEuler’s totient function, 183\nexponentiation, 192, 194\nextended Euclidean algorithm, 184\nF\nfactorials, 6\nfactoring methods, 172\nfactoring problem, 46, 171\nand NP-completeness, 173–174\nsolving with Shor’s algorithm, 259–260\nfactorization, 172–173, 176–177\nfast correlation attacks, 85\nfault injection, 196–197\nFDH (Full Domain Hash), 190–191\nfeedback shift registers (FSRs), 80–82\ncycle, 82\nfeedback function, 80\nlinear, 83–85\nnonlinear, 86\nperiod, 82\nFeistel schemes, 58–59\nFerguson, Niels, 26, 161\nFHE (fully homomorphic encryption), 17\nfield-programmable gate array (FPGA), 79\nfiltered LFSR, 85\nfirst-preimage resistance, 108\nfixed points, 114\nFlame, 126\nforgery attacks, 128\nformat-preserving encryption (FPE), 16–17\nFortuna, 26–27\nforward secrecy, 26, 208\nin authenticated DH, 211\nin TLS 1.3, 246–247\nFouque, Pierre-Alain, 143\nFOX, 58\nFPGA (field-programmable gate array), 79\nfrequency analysis, 4\nFrey, Gerhard, 233\nFSRs. See feedback shift registers (FSRs)\nfull diffusion, 99\nFull Domain Hash (FDH), 190–191\nfully homomorphic encryption (FHE), 17\nG\nGCD (greatest common divisor), 36, 184, 195, 260\nGCHQ (Government Communications Headquarters), 202\nGCM (Galois Counter Mode), 146, 152, 161. See also AES-GCM\ngcm_ghash_clmul function, 153\ngeneral number field sieve (GNFS), 173, 204\ngetrandom() system call, 33\nGHASH, 152–154, 159–160\nGilbert, E.N., 136\nGit, 105\nGitHub, 51\nGmail, 248\nGMR-1, 103\nGMR-2, 103\nGNFS (general number field sieve), 173, 204\nGNU Multiple Precision (GMP), 192\nGnuPG, 52\nGo, 140, 191, 193\nGoldberg, Ian, 35\nGoldwasser, Shafi, 19\nGoogle, 118, 248\nChrome, 231\nInternet Authority, 239\nGOST, 53, 59\nGovaerts, René, 126\nGovernment Communications Headquarters (GCHQ), 202\nGrain-128a, 86–88\ngraphics processing unit (GPU), 91\ngreatest common divisor (GCD), 36, 184, 195, 260\nGrøstl, 120\ngroups, 174\naxioms, 175\ncommutativity, 175\ncyclic, 175\nfinite, 175\ngenerator, 175\nin RSA, 182–183\nGrover’s algorithm, 260\nGSM mobile communication, 78\nguess-and-determine attacks, 89–90\nH\nHadamard gate, 256–257\nHalderman, Alex, 36, 233\nhardness assumption, 174\nhard problems, 163. See also computational complexity\nclosest vector problem, 264\ndiscrete logarithm problem, 174–176\nfactoring problem, 171–174\nlearning with errors, 264\nmultivariate quadratic equations, 265\nNP-complete problem, 169–170\nand provable security, 46–47\nP vs. NP problem, 170–171\nshort integer solution, 264\nhardware, 63, 102\nhash-based cryptography, 266–267\nhash-based MACs, 132–133\nhash functions, 105. See also Merkle–Damgård (M–D) construction\n3-collisions, 113\ncollisions in, 109–111\ncompression functions, 112\nDavies–Meyers construction, 114\nin digital signatures, 106\niterative, 111\nkeyed, 127\nmulticollisions, 113\nnoncryptographic, 106\npreimage resistance, 107–109\nin proof-of-storage protocols, 125–126\nand P vs. NP problem, 171\nsecurity notions, 106\nsponge functions, 115–116\nuniversal, 136–137\nunpredictability, 107\nhash values, 106\nHeartbleed, 248–249\nHellman, Martin, 201\nHeninger, Nadia, 36, 233\nheuristic security, 48–49\nHMAC-based KDF (HKDF), 215, 244\nHMACs (hash-based MACs), 132–133\nhost-based intrusion detection system (HIDS), 105\nHTTPS, 237\ninsecure, 154, 178\nkeys for, 49, 52\nover TLS, 94, 215, 236\nI\niCloud, 248\nidentity gate, 256\nIES (integrated encryption scheme), 229\nIETF (Internet Engineering Task Force), 152\nIKE (Internet Key Exchange), 134\nimaginary number, 253\nIND-CPA, 13–14\nindifferentiability, 126\nindistinguishability (IND), 12–13, 129\ninformational security, 40\ninitial value (IV), 67–69, 112, 135\nintegrated encryption scheme (IES), 229\nintegrity, of data, 16, 106, 128\nIntel, 30\nInternet Engineering Task Force (IETF), 152\nInternet Key Exchange (IKE), 134\ninternet of things (IoT), 235\nintractable problems. See hard problems\ninvalid curve attack, 232\ninvasive attacks, 12\nion traps, 262\nipad, 132\nIPSec (Internet Protocol Security), 128, 132, 134, 148, 152\niterative hashing, 111\nIV (initial value), 67–69, 112, 135\nJ\nJager, Tibor, 233\nJava, 19\nJH, 120\nJovanovic, Philipp, 158\nK\nKDF. See key derivation function (KDF)\nKeccak 121–123. See also SHA-3\nKelsey, John, 26, 38, 45\nKerckhoffs, Auguste, 4, 10\nKerckhoffs’s principle, 10–11\nkey agreement protocols, 49, 202, 205\nAKA, 205–207\nattack models, 207\nbreaches, 207, 211, 214\ndata leaks, 207, 212\neavesdroppers, 207, 211\nforward secrecy, 208\nperformance, 208\nsecurity goals, 207–208\nkey confirmation, 212, 214\nkey control, 208\nkey derivation function (KDF), 49\nin DH functions, 202, 215\nin ECIES, 229\nin TLS 1.3, 243–244\nkey generation, 49–50\nkey-generation algorithm, 50\nkey scheduling algorithms (KSAs), 11, 92\nkey wrapping, 50\nknapsack problem, 169\nknown-message attack, 128\nknown-plaintext attackers (KPA), 11\nknown-plaintext attacks (KPAs), 89\nKnudsen, Lars, 47\nKohno, Tadayoshi, 26\nKotla, Ramakrishna, 125\nKozierok, Charles, 237\nKrawczyk, Hugo, 143, 216\nKrovetz, Ted, 156\nKSAs (key scheduling algorithms), 11, 92\nKupyna, 116\nL\nlattice-based cryptography, 264–265\nlattice problems, 179\nlearning with errors (LWE), 264, 267\nleast significant bit (LSB), 165, 193\nlength-extension attacks, 125, 131\nLet’s Encrypt, 249\nLeurent, Gaëtan, 143\nlinear code, 263\nlinear combination, 28\nlinear feedback shift registers (LFSRs), 83\nin A5/1, 88–89\nfiltered, 85\nin Grain-128a, 87–88\npolynomials, 83\nsecurity, 84\nlinear transformation, 265\nLinux, 32, 66, 239\nLipton, Richard J., 199\nlogarithm, 23, 42\nlong-term key, 211\nlower bound, 41\nlow-exponent attacks, 195\nLSB (least significant bit), 165, 193\nLucifer, 58\nLWE (learning with errors), 264, 267\nM\nMACs (message authentication codes), 127\nauthentication tag, 128\nCBC-MAC, 134–135\nchosen-message attacks, 129\nCMAC, 134\ndedicated designs, 136\nencrypt-and-MAC, 146–147\nencrypt-then-MAC, 147–148, 152\nforgery attacks, 128\nHMAC, 132–133\nMAC-then-encrypt, 147\nvs. PRFs, 130\nreplay attacks, 129\ntiming attacks, 140–142\nWegman–Carter, 137–138\nMacBook, 194\nMAC-then-encrypt, 147\nMacWilliams, F.J., 136\nmalleability, 186\nman-in-the-middle attacks, 206, 209–210, 236\nmask generating function, 188\nmatrix multiplication, 256\nMcEliece cryptosystem, 263\nMD5, 116, 126\nM–D construction. See Merkle–Damgård (M–D) construction\nmeasurement (quantum physics), 252, 255\nMediaWiki, 36\nmeet-in-the-middle (MitM) attacks, 72–74\nmemory, 44\nmemory footprint, 55\nMenezes–Qu–Vanstone (MQV), 213–214, 226\nMerkle, Ralph, 111, 126, 202\nMerkle–Damgård (M–D) construction, 111\nlength-extension attacks, 125, 131\nmulticollisions, 113\npadding, 112–113\nsecurity, 113\nMerkle’s puzzles, 202\nMersenne Twister (MT) algorithm, 28, 36\nmessage authentication codes. See MACs (message authentication codes)\nMicali, Silvio, 19\nMicrosoft, 65\nMicrosoft Windows CryptoAPI, 194\nmisuse resistance, 150\nMitM (meet-in-the-middle) attacks, 72–74\nmode of operation, 4, 5, 65\nMoore, Jonathan, 233\nmost significant bit (MSB), 28, 135, 138, 215\nMQ (multivariate quadratics), 265\nMQV (Menezes–Qu–Vanstone), 213–214, 226\nMT (Mersenne Twister) algorithm, 28, 36\nmt_rand, 28\nmulticollisions, 113\nmultivariate cryptography, 265–266\nmultivariate problems, 179\nmultivariate quadratics (MQ), 265\nN\nNaehrig, Michael, 233\nNational Institute of Standards and Technology (NIST), 29, 53, 59,\n120–121\nNational Security Agency (NSA), 59, 116, 213, 251\nNetscape, 35, 237\nnetwork-based intrusion detection systems (NIDS), 105\nNeves, Samuel, 123, 158\nNFSR (nonlinear feedback shift register), 86\nNguyen, Phong Q., 143\nNielsen, Michael, 269\nNIST (National Institute of Standards and Technology), 29, 53, 59,\n120–121\nNM (non-malleability), 13\nnonces, 71–72, 78–79\npredictability, 149–150\nreuse, 101\nin TLS records, 241\nWEP insecurity and, 93–94\nnondeterministic polynomial time class. See NP (nondeterministic\npolynomial time) class\nnonlinear equation, 29\nnonlinear feedback shift register (NFSR), 86\nnon-malleability (NM), 13\nnonrepudiation, 188\nnon-uniform distribution, 23\nNP (nondeterministic polynomial time) class, 168–169\nNP-complete problem, 169–170\nNP-hard problem, 170\nNSA (National Security Agency), 59, 116, 213, 251\nNSS library, 199\nnumber field sieve, 204\nO\nOAEP. See Optimal Asymmetric Encryption Padding (OAEP)\nOCB (offset codebook)\nefficiency, 156\ninternals, 155–156\nsecurity, 156\none-time pad, 7\nencrypting with, 7–8\nsecurity, 8–9, 13, 40\none-way function, 107\nopad, 132\nOpenSSH, 136, 217, 231\nOpenSSL toolkit\ngenerating DH parameters, 203\ngenerating keys, 30, 49, 177–178\nGHASH bug, 153\nHeartbleed, 248–249\nunsafe DH group parameters, 215–216\nOptimal Asymmetric Encryption Padding (OAEP), 52, 186\nencoded message, 187\nmask generating function, 188\nP\nP (polynomial time) class, 166–168, 168–169\npadding, 19, 69–70, 112–113\nOAEP, 52, 186–188\nzero padding, 241\npadding oracle attacks, 19, 74–75\nparallelism, 43\nparallelizability, 151, 154, 156\nparent process ID (PPID), 35\npassword, 49, 129\nPaterson, Kenny, 103\nPeikert, Chris, 268\nperfect secrecy, 7\nperiod, 259\npermutation, 4–5, 111\npermutation-based AEAD, 157–158\npseudorandom, 54\nsecurity, 5, 7\nin sponge functions, 115–116\ntrapdoor, 181–182, 183\nPID (process ID), 35\npigeonhole principle, 109\nPKCS (Public-Key Cryptography Standards), 186\nplaintext, 2\nPLD (programmable logic device), 79\nPoly1305, 136–138, 139\nPoly1305-AES, 138\npolynomials, 83\nmultiplication, 153\nprimitive, 83–84\npolynomial time (P) class, 166–168, 168–169\npost-quantum cryptography, 252, 263\ncode-based, 263–264\nhash-based, 266–267\nlattice-based, 264–265\nmultivariate, 265–266\nPost-Quantum Crypto Project, 269\npost-quantum security, 261\npower-analysis attacks, 193\nPPID (parent process ID), 35\nPQCrypto, 269\nprecomputation, 44, 208\nprediction resistance, 26\npreimage resistance, 107–109\nPreneel, Bart, 126\npre-shared key (PSK), 243, 245\nPRFs. See pseudorandom functions (PRFs)\nprime numbers, 172\nprime number theorem, 172\nprivate keys, 15, 181\nPRNGs. See pseudorandom number generators (PRNGs)\nProbabilistic Signature Scheme (PSS), 189–190, 191\nprobability, 9, 22\nprobability distribution, 22–23\nprocess ID (PID), 35\nprogrammable logic device (PLD), 79\nproof-of-storage protocols, 125–126\nproof-of-work, 106\nprovable security, 46–48\npseudorandom functions (PRFs), 127\nvs. MACs, 130\nsecurity, 129\npseudorandom number generators (PRNGs), 24–26\ncryptographic, 27–28\nentropy and, 35–36\nFortuna, 26–27\ngenerating on Unix, 30–32\ngenerating on Windows, 33–34\nhardware-based, 34–35\nnon-cryptographic, 27–28, 36–37\nsecurity, 26\npseudorandom permutation (PRP), 54, 58, 138\nPSPACE, 168\nPSK (pre-shared key), 243, 245\nPSS (Probabilistic Signature Scheme), 189–190, 191\npublic-key cryptography, 15\nPublic-Key Cryptography Standards (PKCS), 186\npublic-key distribution scheme, 201\npublic keys, 181\nP vs. NP, 170–171\nPyCrypto, 62\nPythagorean theorem, 253\nPython language, 62, 66, 71, 92, 198\nQ\nQualys, 249\nquantum bit (qubit), 252\nquantum byte, 255\nquantum circuits, 255\nquantum computers, 174, 251\nquantum gates, 255, 256\nquantum mechanics, 252\nquantum random number generators (QRNGs), 25\nquantum speed-up, 257\nexponential, 258\nquadratic, 258\nquarter-round function, 96\nqubit (quantum bit), 252\nR\nrand, 28\nrandomness, 21\nrandom number generators (RNGs), 24–25\nrandom oracle, 107\nRay, Marsh, 65\nRC4, 79, 92–93\nbroken implementation, 101–102\nin TLS, 94–95\nin WEP, 93–94\nRDRAND instruction, 34–35\nRDSEED instruction, 34\nreduction, 46\nreplay attacks, 129, 206\nRho method, 110–111\nRijndael, 59\nring-LWE, 267\nRivest, Ron, 92, 103\nRivest–Shamir–Adleman. See RSA (Rivest–Shamir–Adleman)\nRogaway, Phillip, 155, 156, 157\nRNGs (random number generators), 24–25\nroot of unity, 198\nrounds, 48\nround trips, 208\nround-trip times (RTT), 245\nRSA (Rivest–Shamir–Adleman), 181–182\nBellcore attack, 196–197\nCRT, 195–196\nvs. ECDSA, 227–228\nencryption, 185\nand factoring problem, 46–47, 177\nFDH, 190–191\ngroups, 182–183\nimplementations, 191–192\nkey generation, 184–185\nmodulus, 182\nOEAP, 186–188\nprivate exponents, 197–199\nprivate keys, 50, 183, 184\nproblem, 204\nPSS, 189–190, 191\npublic exponents, 183\npublic keys, 183\nsecret exponents, 183\nsecurity, 185\nshared moduli, 197\nsignatures, 188–189\nsmall exponents, 194–195\nspeed, 194–196\nsquare-and-multiply, 192–193\ntextbook encryption, 185–186\ntextbook signature, 188\ntrapdoor permutation, 183\nRSAES-OAEP, 186\nRSA Security, 92\nRTT (round-trip times), 245\nS\nSaarinen, Markku-Juhani O., 121, 166\nsafe prime, 203\nSageMath, 176, 184\nSalsa20, 95\nattacking, 99–100\ncolumn-round function, 97\ndouble-round function, 97\ninternal state, 96\nand nonlinear relations, 98–99\nquarter-round function, 96\nrow-round function, 97\nSalsa20/8, 99\nsalt, 190\nsandwich MAC, 133\nsatellite phone (satphone), 102\nS-boxes (substitution boxes), 57\nscheduling problems, 170\nSchneier, Bruce, 26, 38, 121\nSchwenk, Jörg, 233\nsearchable encryption, 17\nsearch algorithm, 164\nsecond-preimage resistance, 108\nsecret-prefix MAC, 130, 133\nsecret-suffix MAC, 131\nsecure channel, 201, 236\nsecure cookie, 246\nSecure Hash Algorithms (SHAs), 116\nSecure Hash Algorithm with Keccak (SHAKE), 121\nSecure Shell (SSH), 51–52, 128, 132, 147, 148, 152, 226, 240\nSecure Socket Layer (SSL), 35, 235, 237\nsecurity\nbit, 42–43\ncomputational, 40–41\ncryptographic, 39\ngoals, 10, 12–13\nheuristic, 46, 48–49\ninformational, 40\nlevels, choosing, 44–45\nmargin, 48–49\nnotions, 10, 13–15\npost-quantum, 261\nproof, 46\nprovable, 46–48\nsemantic, 13, 18\nsession key, 205\nSHA-0, 116–117\nSHA-1, 116, 244\nattacks, 118–119\ncollision, 118\ninternals, 117–118\nSHA-2, 119, 120, 125\nSHA-3, 115, 121–123, 215\ncompetition, 120–121\nsecurity, 123\nZoo, 126\nSHA-224, 119–120\nSHA-256, 119–120, 226\ncompression function, 119\nsecurity, 120\nSHA-384, 120\nSHA-512, 120\nSHAs (Secure Hash Algorithms), 116\nSHAKE (Secure Hash Algorithm with Keccak), 121\nShannon, Claude, 8\nShor, Peter, 259\nShor’s algorithm, 259–260\nshort integer solution (SIS), 264\nShrimpton, Tom, 157\nside-channel attacks, 12, 140, 264, 269\nSignal, 268\nsignatures, 106, 182, 188–189\nSIM card, 206\nSimon’s problem, 258\nSimple Mail Transfer Protocol (SMTP), 237\nSipHash, 139–140, 142\nSipRound function, 139–140\nSIS (short integer solution), 264\nSIV (synthetic IV), 156–157\nSkein, 121\nslide attacks, 56–57\nsliding window method, 193\nSloane, N.J., 136\nSM3, 116\nSMTP (Simple Mail Transfer Protocol), 237\nSNOW3G, 91\nSomorovsky, Juraj, 233\nspace complexity, 168\nSPHINCS, 267\nSPNs (substitution–permutation networks), 57–58, 60\nsponge functions, 111, 115, 142\nabsorbing phase, 115\ncapacity, 116\nsqueezing phase, 116\nsquare-and-multiply, 192–193\nSSH (Secure Shell), 51–52, 128, 132, 147, 148, 152, 226, 240\nSSL (Secure Socket Layer), 35, 235, 237\nSSL Labs, 249\nstatistical test, 29\nStevens, Marc, 118\nstreamability, 151, 154, 156\nstream ciphers, 77\ncounter-based, 79\nencryption and decryption, 78\nhardware-oriented, 79–80\nkeystream, 78\nnonce resuse, 101\nsoftware-oriented, 91\nstateful, 79\nStreebog, 116\nsubstitutions, 4–5\nsubstitution boxes (S-boxes), 57\nsubstitution–permutation networks (SPNs), 57–58, 60\nsuperconducting circuits, 262\nsuperposition, 252\nsymmetric encryption, 1, 15, 16\nsynthetic IV (SIV), 156–157\nT\ntags, 16. See also authenticated encryption (AE); MACs (message\nauthentication codes)\nTE (tweakable encryption), 17\nTEA, 126\nTestU01, 29\ntime complexity, 168\ntime-memory trade-off (TMTO) attacks, 18, 44, 90–91\ntiming attacks, 141, 193, 199, 269\nTLS (Transport Layer Security), 78, 35, 128, 130, 147, 235\nClientHello, 242, 244, 245\nand Diffie–Hellman, 215\ndowngrade protection, 244\nhandshake, 237, 238–240, 241–243\nhistory of, 237\nRC4 in, 92, 94–95\nrecord, 240\nrecord payload, 240\nrecord protocol, 237, 240–241\nsecurity, 236, 246–247, 247–249\nServerHello, 242, 245\nsession resumption, 245\nsingle round-trip handshake, 245\nversion 1.3 algorithms, 243–244\nversion 1.3 improvements, 244–245\nzero padding, 241\nTLS Working Group (TLSWG), 249\nTMTO (time-memory trade-off) attacks, 18, 44, 90–91\nTOFU (trust-on-first-use), 240\ntraffic analysis, 241\nTransport Layer Security. See TLS (Transport Layer Security)\ntrapdoors, 182\ntrapdoor permutations, 181–182, 183\ntraveling salesman problem, 169\ntriple DES (3DES), 59, 72–74\ntrusted third party, 238\ntrust-on-first-use (TOFU), 240\nTuring Award, 202\ntweakable encryption (TE), 17\nU\nUDP (User Datagram Protocol), 237\nunforgeability, 128\nuniform distribution, 23\nunitary matrix, 257\nuniversal hash functions, 136–137\nUnix, 30\nunpredictability, 107\nupper bound, 42\nV\nVandewalle, Joos, 126\nvan Oorschot, Paul C., 126\nVigenère, Blaise de, 3\nVigenère cipher, 3–4\nvirtual private network (VPN), 94\nW\nWagner, David, 35, 38, 56, 101\nWegman–Carter MAC, 137–138, 152\nWeierstrauss form, 218\nWEP (Wireless Encryption Protocol), 92, 93–94\nWiener, Michael, 52, 126, 199\nWi-Fi, 77\nWilcox-O’Hearn, Zooko, 123\nWindows, 30\nWinnerlein, Christian, 123\nWinternitz one-time signature (WOTS), 266–267\nWireless Encryption Protocol (WEP), 92, 93–94\nWPA2, 162\nWustrow, Eric, 36, 233\nX\nXbox, 126\nXOR swap, 101–102\nY\nYao, Andrew C., 216\nYarrow, 26\nZ\nZhao, Yunlei, 216\nZUC, 91\nSerious Cryptography is set in New Baskerville, Futura, TheSansMono\nCondensed, and Dogma."
  },
  {
    "input": "What is the main focus of the book \"Serious Cryptography\"?",
    "summary": "This book provides a practical guide to modern encryption, covering fundamental mathematical concepts and advanced topics like authenticated encryption and post-quantum cryptography. It also includes real-world examples and discussions on common implementation mistakes. Written by Jean-Philippe Aumasson, a principal research engineer at Kudelski Security, the book offers a comprehensive survey of encryption and its applications for both beginners and experienced practitioners.",
    "output": "RESOURCES\nVisit https://www.nostarch.com/seriouscrypto/ for resources, errata, and\nmore information.\nMore no-nonsense books from NO STARCH PRESS\nROOTKITS AND BOOTKITS\nReversing Modern Malware and Next Generation Threats\nby ALEX MATROSOV, EUGENE\nRODIONOV, and SERGEY BRATUS\nSPRING 2018, 504 PP., $49.95\nISBN 978-1-59327-716-1\nATTACKING NETWORK PROTOCOLS\nA Hacker’s Guide to Capture, Analysis, and Exploitation\nby JAMES FORSHAW\nWINTER 2017, 336 PP., $49.95\nISBN 978-1-59327-750-5\nGRAY HAT C#\nA Hacker’s Guide to Creating and Automating Security Tools\nby BRANDON PERRY\nJUNE 2017, 304 PP., $39.95\nISBN 978-1-59327-759-8\nPRACTICAL PACKET ANALYSIS, 3RD EDITION\nUsing Wireshark to Solve Real-World Network Problems\nby CHRIS SANDERS\nAPRIL 2017, 368 PP., $49.95\nISBN 978-1-59327-802-1\nTHE HARDWARE HACKER\nAdventures in Making and Breaking Hardware\nby ANDREW “BUNNIE” HUANG\nMARCH 2017, 416 PP., $29.95\nISBN 978-1-59327-758-1\nBLACK HAT PYTHON\nPython Programming for Hackers and Pentesters\nby JUSTIN SEITZ\nDECEMBER 2014, 192 PP., $34.95\nISBN 978-1-59327-590-7\nPHONE:\n1.800.420.7240 or 1.415.863.9900\nEMAIL:\nSALES@NOSTARCH.COM\nWEB:\nWWW.NOSTARCH.COM\n“A THOROUGH AND UP-TO-DATE DISCUSSION\nOF CRYPTOGRAPHIC ENGINEERING, DESIGNED\nTO HELP PRACTITIONERS WHO PLAN TO\nWORK IN THIS FIELD DO BETTER.” –\nMATTHEW D. GREEN, PROFESSOR, JOHNS\nHOPKINS UNIVERSITY INFORMATION\nSECURITY INSTITUTE\nThis practical guide to modern encryption breaks down the fundamental\nmathematical concepts at the heart of cryptography without shying away\nfrom meaty discussions of how they work. You’ll learn about\nauthenticated encryption, secure randomness, hash functions, block\nciphers, and public-key techniques such as RSA and elliptic curve\ncryptography.\nYou’ll also learn:\n• Key concepts in cryptography, such as computational security, attacker\nmodels, and forward secrecy\n• The strengths and limitations of the TLS protocol behind HTTPS\nsecure websites\n• Quantum computation and post-quantum cryptography\n• About various vulnerabilities by examining numerous code examples\nand use cases\n• How to choose the best algorithm or protocol and ask vendors the right\nquestions\nWhether you’re a Minecraft megafan or a newbie, you’ll see Minecraft in\na whole new light while learning the basics of programming. Sure, you\ncould spend all day mining for precious resources or building your\nmansion by hand, but with the power of Python, those days are over!\nEach chapter includes a discussion of common implementation mistakes\nusing real-world examples and details what could go wrong and how to\navoid these pitfalls.\nWhether you’re a seasoned practitioner or a beginner looking to dive into\nthe field, Serious Cryptography will provide a complete survey of modern\nencryption and its applications.\nAbout the Author\nJean-Philippe Aumasson is Principal Research Engineer at Kudelski\nSecurity, an international cybersecurity company based in Switzerland.\nHe has authored more than 40 research articles in the field of\ncryptography and cryptanalysis and designed the widely used hash\nfunctions BLAKE2 and SipHash. He speaks regularly at information\nsecurity conferences and has presented at Black Hat, DEF CON,\nTroopers, and Infiltrate.\nTHE FINEST IN GEEK ENTERTAINMENT™\nwww.nostarch.com"
  }
]