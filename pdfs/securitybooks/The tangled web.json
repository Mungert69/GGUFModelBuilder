[
  {
    "input": "Preface",
    "output": "P R E F A C E\nJust fifteen years ago, the Web was as simple as it\nwas unimportant: a quirky mechanism that allowed a\nhandful of students, plus a bunch of asocial, basement-\ndwelling geeks, to visit each other’s home pages dedi-\ncated to science, pets, or poetry. Today, it is the platform\nof choice for writing complex, interactive applications\n(from mail clients to image editors to computer games)\nand a medium reaching hundreds of millions of casual\nusers around the globe. It is also an essential tool of\ncommerce, important enough to be credited for caus-\ning a recession when the 1999 to 2001 dot-com bubble\nburst.\nThis progression from obscurity to ubiquity was amazingly fast, even\nbythe standards we are accustomed to in today’s information age—and its\nspeed of ascent brought with it an unexpected problem. The design flaws\nand implementation shortcomings of the World Wide Web are those of a\ntechnology that never aspired to its current status and never had a chance\ntopause and look back at previous mistakes. The resulting issues have quickly\nemerged as some of the most significant and prevalent threats to data secu-\nrity today: As it turns out, the protocol design standards one would apply to\na black-on-gray home page full of dancing hamsters are not necessarily the\nsame for an online shop that processes millions of credit card transactions\nevery year.\nWhen taking a look at the past decade, it is difficult not to be slightly\ndisappointed: Nearly every single noteworthy online application devised so\nfar has had to pay a price for the corners cut in the early days of the Web.\nHeck, xssed.com, a site dedicated to tracking a narrow subset of web-related\nsecurity glitches, amassed some 50,000 entries in about three years of opera-\ntion. Yet, browser vendors are largely unfazed, and the security community\nitself has offered little insight or advice on how to cope with the widespread\nmisery. Instead, many security experts stick to building byzantine vulnerabil-\nity taxonomies and engage in habitual but vague hand wringing about the\nsupposed causes of this mess.\nPart of the problem is that said experts have long been dismissive of the\nwhole web security ruckus, unable to understand what it was all about. They\nhave been quick to label web security flaws as trivial manifestations of the\nconfused deputy problem* or of some other catchy label outlined in a trade jour-\nnal three decades ago. And why should they care about web security, anyway?\nWhat is the impact of an obscene comment injected onto a dull pet-themed\nhome page compared to the gravity of a traditional system-compromise flaw?\nIn retrospect, I’m pretty sure most of us are biting our tongues. Not only\nhas the Web turned out to matter a lot more than originally expected, but\nwe’ve failed to pay attention to some fundamental characteristics that put\nitwell outside our comfort zone. After all, even the best-designed and most\nthoroughly audited web applications have far more issues, far more frequently,\nthan their nonweb counterparts.\nWe all messed up, and it is time to repent. In the interest of repentance,\nThe Tangled Web tries to take a small step toward much-needed normalcy, and\nas such, it may be the first publication to provide a systematic and thorough\nanalysis of the current state of affairs in the world of web application security.\nIn the process of doing so, it aims to shed light on the uniqueness of the secu-\nrity challenges that we—security engineers, web developers, and users—have\nto face every day.\nThe layout of this book is centered on exploring some of the most prom-\ninent, high-level browser building blocks and various security-relevant topics\nderived from this narrative. I have taken this approach because it seems to be\nmore informative and intuitive than simply enumerating the issues using an\n* Confused deputy problem is a generic concept in information security used to refer to a broad\nclassof design or implementation flaws. The term describes any vector that allows the attacker\ntotrick a program into misusing some “authority” (access privileges) to manipulate a resource\nin an unintended manner—presumably one that is beneficial to the attacker, however that\nbenefit is defined. The phrase “confused deputy” is regularly invoked by security researchers\ninacademia, but since virtually all real-world security problems could be placed in this bucket\nwhen considered at some level of abstraction, this term is nearly meaningless.\nxviii Preface"
  },
  {
    "input": "Acknowledgments",
    "output": "arbitrarily chosen taxonomy (a practice seen in many other information\nsecurity books). I hope, too, that this approach will make The Tangled Web\nabetter read.\nFor readers looking for quick answers, I decided to include quick engi-\nneering cheat sheets at the end of many of the chapters. These cheat sheets\noutline sensible approaches to some of the most commonly encountered\nproblems in web application design. In addition, the final part of the book\noffers a quick glossary of the well-known implementation vulnerabilities that\none may come across.\nAcknowledgments\nMany parts of The Tangled Web have their roots in the research done for\nGoogle’s Browser Security Handbook, a technical wiki I put together in 2008\nandreleased publicly under a Creative Commons license. You can browse\nthe original document online at http://code.google.com/p/browsersec/.\nI am fortunate to be with a company that allowed me to pursue this\nproject—and delighted to be working with a number of talented peers who\nprovided excellent input to make the Browser Security Handbook more useful\nand accurate. In particular, thanks to Filipe Almeida, Drew Hintz, Marius\nSchilder, and Parisa Tabriz for their assistance.\nI am also proud to be standing on the shoulders of giants. This book owes\na lot to the research on browser security done by members of the informa-\ntion security community. Special credit goes to Adam Barth, Collin Jackson,\nChris Evans, Jesse Ruderman, Billy Rios, and Eduardo Vela Nava for the\nadvancement of our understanding of this field.\nThank you all—and keep up the good work.\nPreface xix"
  },
  {
    "input": "Information Security in a Nutshell",
    "output": "S E C U R I T Y I N T H E W O R L D\nO F W E B A P P L I C A T I O N S\nTo provide proper context for the technical discus-\nsions later in the book, it seems prudent to first of all\nexplain what the field of security engineering tries to\nachieve and then to outline why, in this otherwise well-\nstudied context, web applications deserve special treat-\nment. So, shall we?\nInformation Security in a Nutshell\nOn the face of it, the field of information security appears to be a mature,\nwell-defined, and accomplished branch of computer science. Resident experts\neagerly assert the importance of their area of expertise by pointing to large\nsets of neatly cataloged security flaws, invariably attributed to security-illiterate\ndevelopers, while their fellow theoreticians note how all these problems would\nhave been prevented by adhering to this year’s hottest security methodology."
  },
  {
    "input": "Flirting with Formal Solutions",
    "output": "A commercial industry thrives in the vicinity, offering various nonbinding\nsecurity assurances to everyone, from casual computer users to giant interna-\ntional corporations.\nYet, for several decades, we have in essence completely failed to come up\nwith even the most rudimentary usable frameworks for understanding and\nassessing the security of modern software. Save for several brilliant treatises\nand limited-scale experiments, we do not even have any real-world success\nstories to share. The focus is almost exclusively on reactive, secondary secu-\nrity measures (such as vulnerability management, malware and attack detec-\ntion, sandboxing, and so forth) and perhaps on selectively pointing out flaws\nin somebody else’s code. The frustrating, jealously guarded secret is that when\nit comes to enabling others to develop secure systems, we deliver far less value\nthan should be expected; the modern Web is no exception.\nLet’s look at some of the most alluring approaches to ensuring informa-\ntion security and try to figure out why they have not made a difference sofar.\nFlirting with Formal Solutions\nPerhaps the most obvious tool for building secure programs is to algorithmi-\ncally prove they behave just the right way. This is a simple premise that intu-\nitively should be within the realm of possibility—so why hasn’t this approach\nnetted us much?\nWell, let’s start with the adjective secure itself: What is it supposed to convey,\nprecisely? Security seems like an intuitive concept, but in the world of comput-\ning, it escapes all attempts to usefully define it. Sure, we can restate the prob-\nlem in catchy yet largely unhelpful ways, but you know there’s a problem\nwhen one of the definitions most frequently cited by practitioners* is this:\nA system is secure if it behaves precisely in the manner intended—\nand does nothing more.\nThis definition is neat and vaguely outlines an abstract goal, but it tells\nvery little about how to achieve it. It’s computer science, but in terms of spec-\nificity, it bears a striking resemblance to a poem by Victor Hugo:\nLove is a portion of the soul itself, and it is of the same nature as\nthe celestial breathing of the atmosphere of paradise.\nOne could argue that practitioners are not the ones to be asked for\nnuanced definitions, but go ahead and pose the same question to a group of\nacademics and they’ll offer you roughly the same answer. For example, the\nfollowing common academic definition traces back to the Bell-La Padula secu-\nrity model, published in the 1960s. (This was one of about a dozen attempts\nto formalize the requirements for secure systems, in this case in terms of a\nfinite state machine;1 it is also one of the most notable ones.)\nA system is secure if and only if it starts in a secure state and cannot\nenter an insecure state.\n* The quote is attributed originally to Ivan Arce, a renowned vulnerability hunter, circa 2000;\nsince then, it has been used by Crispin Cowan, Michael Howard, Anton Chuvakin, and scores\nofother security experts.\n2 Chapter 1\nDefinitions along these lines are fundamentally true, of course, and may\nserve as the basis for dissertations or even a couple of government grants. But\nin practice, models built on these foundations are bound to be nearly useless\nfor generalized, real-world software engineering for at least three reasons:\n There is no way to define desirable behavior for a sufficiently complex\ncomputer system. No single authority can define what the “intended\nmanner” or “secure states” should be for an operating system or a web\nbrowser. The interests of users, system owners, data providers, business\nprocess owners, and software and hardware vendors tend to differ sig-\nnificantly and shift rapidly—when the stakeholders are capable and will-\ning to clearly and honestly disclose their interests to begin with. To add\ninsult to injury, sociology and game theory suggest that computing a sim-\nple sum of these particular interests may not actually result in a benefi-\ncial outcome. This dilemma, known as “the tragedy of the commons,” is\ncentral to many disputes over the future of the Internet.\n Wishful thinking does not automatically map to formal constraints.\nEvenif we can reach a perfect, high-level agreement about how the sys-\ntem should behave in a subset of cases, it is nearly impossible to formal-\nize such expectations as a set of permissible inputs, program states, and\nstate transitions, which is a prerequisite for almost every type of formal\nanalysis. Quite simply, intuitive concepts such as “I do not want my mail\nto be read by others,” do not translate to mathematical models particu-\nlarly well. Several exotic approaches will allow such vague requirements\nto be at least partly formalized, but they put heavy constraints on software-\nengineering processes and often result in rulesets and models that are\nfar more complicated than the validated algorithms themselves. And,\ninturn, they are likely to need their own correctness to be proven . . .\nadinfinitum.\n Software behavior is very hard to conclusively analyze. Static analysis of\ncomputer programs with the intent to prove that they will always behave\naccording to a detailed specification is a task that no one has managed to\nbelievably demonstrate in complex, real-world scenarios (though, as you\nmight expect, limited success in highly constrained settings or with very\nnarrow goals is possible). Many cases are likely to be impossible to solve\nin practice (due to computational complexity) and may even turn out to\nbe completely undecidable due to the halting problem.*\nPerhaps more frustrating than the vagueness and uselessness of the early\ndefinitions is that as the decades have passed, little or no progress has been\nmade toward something better. In fact, an academic paper released in 2001\nby the Naval Research Laboratory backtracks on some of the earlier work and\narrives at a much more casual, enumerative definition of software security—\none that explicitly disclaims its imperfection and incompleteness.2\n* In 1936, Alan Turing showed that (paraphrasing slightly) it is not possible to devise an algorithm\nthat can generally decide the outcome of other algorithms. Naturally, some algorithms are very\nmuch decidable by conducting case-specific proofs, just not all of them.\nSecurity in the World of Web Applications 3"
  },
  {
    "input": "Enter Risk Management",
    "output": "A system is secure if it adequately protects information that it pro-\ncesses against unauthorized disclosure, unauthorized modification,\nand unauthorized withholding (also called denial of service). We\nsay “adequately” because no practical system can achieve these\ngoals without qualification; security is inherently relative.\nThe paper also provides a retrospective assessment of earlier efforts\nandthe unacceptable sacrifices made to preserve the theoretical purity of\nsaid models:\nExperience has shown that, on one hand, the axioms of the Bell-\nLaPadula model are overly restrictive: they disallow operations that\nusers require in practical applications. On the other hand, trusted\nsubjects, which are the mechanism provided to overcome some\nofthese restrictions, are not restricted enough. . . . Consequently,\ndevelopers have had to develop ad hoc specifications for the desired\nbehavior of trusted processes in each individual system.\nIn the end, regardless of the number of elegant, competing models intro-\nduced, all attempts to understand and evaluate the security of real-world soft-\nware using algorithmic foundations seem bound to fail. This leaves developers\nand security experts with no method to make authoritative, future-looking\nstatements about the quality of produced code. So, what other options are on\nthe table?\nEnter Risk Management\nIn the absence of formal assurances and provable metrics, and given the\nfrightening prevalence of security flaws in key software relied upon by mod-\nern societies, businesses flock to another catchy concept: risk management.\nThe idea of risk management, applied successfully to the insurance\nbusiness (with perhaps a bit less success in the financial world), simply states\nthat system owners should learn to live with vulnerabilities that cannot be\naddressed in a cost-effective way and, in general, should scale efforts accord-\ning to the following formula:\nrisk = probability of an event  maximum loss\nFor example, according to this doctrine, if having some unimportant\nworkstation compromised yearly won’t cost the company more than $1,000\nin lost productivity, the organization should just budget for this loss and move\non, rather than spend say $100,000 on additional security measures or con-\ntingency and monitoring plans to prevent the loss. According to the doctrine\nof risk management, the money would be better spent on isolating, securing,\nand monitoring the mission-critical mainframe that churns out billing records\nfor all customers.\n4 Chapter 1\nNaturally, it’s prudent to prioritize security efforts. The problem is that\nwhen risk management is done strictly by the numbers, it does little to help\nus to understand, contain, and manage real-world problems. Instead, it intro-\nduces a dangerous fallacy: that structured inadequacy is almost as good as\nadequacy and that underfunded security efforts plus risk management are\nabout as good as properly funded security work.\nGuess what? No dice.\n In interconnected systems, losses are not capped and are not tied to\nanasset. Strict risk management depends on the ability to estimate typi-\ncal and maximum cost associated with the compromise of a resource.\nUnfortunately, the only way to do this is to overlook the fact that many\nofthe most spectacular security breaches—such as the attacks on TJX*\norMicrosoft†—began at relatively unimportant and neglected entry\npoints. These initial intrusions soon escalated and eventually resulted\ninthe nearly complete compromise of critical infrastructure, bypassing\nany superficial network compartmentalization on their way. In typical\nby-the-numbers risk management, the initial entry point is assigned a\nlower weight because it has a low value when compared to other nodes.\nLikewise, the internal escalation path to more sensitive resources is\ndownplayed as having a low probability of ever being abused. Still,\nneglecting them both proves to be an explosive mix.\n The nonmonetary costs of intrusions are hard to offset with the value\ncontributed by healthy systems. Loss of user confidence and business\ncontinuity, as well as the prospect of lawsuits and the risk of regulatory\nscrutiny, are difficult to meaningfully insure against. These effects can, at\nleast in principle, make or break companies or even entire industries, and\nany superficial valuations of such outcomes are almost purely speculative.\n Existing data is probably not representative of future risks. Unlike the\nparticipants in a fender bender, attackers will not step forward to help-\nfully report break-ins and will not exhaustively document the damage\ncaused. Unless the intrusion is painfully evident (due to the attacker’s\nsloppiness or disruptive intent), it will often go unnoticed. Even though\nindustry-wide, self-reported data may be available, there is simply no reli-\nable way of telling how complete it is or how much extra risk one’s cur-\nrent business practice may be contributing.\n* Sometime in 2006, several intruders, allegedly led by Albert Gonzalez, attacked an unsecured\nwireless network at a retail location and subsequently made their way through the corporate\nnetworks of the retail giant. They copied the credit card data of about 46 million customers and\nthe Social Security numbers, home addresses, and so forth of about 450,000 more. Eleven people\nwere charged in connection with the attack, one of whom committed suicide.\n† Microsoft’s formally unpublished and blandly titled presentation Threats Against and\nProtectionof Microsoft’s Internal Network outlines a 2003 attack that began with the compromise\nofan engineer’s home workstation that enjoyed a long-lived VPN session to the inside of the\ncorporation. Methodical escalation attempts followed, culminating with the attacker gaining\naccess to, and leaking data from, internal source code repositories. At least to the general\npublic, the perpetrator remains unknown.\nSecurity in the World of Web Applications 5"
  },
  {
    "input": "Enlightenment Through Taxonomy",
    "output": " Statistical forecasting is not a robust predictor of individual outcomes.\nSimply because on average people in cities are more likely to be hit by\nlightning than mauled by a bear does not mean you should bolt a light-\nning rod to your hat and then bathe in honey. The likelihood that a\ncompromise will be associated with a particular component is, on an\nindividual scale, largely irrelevant: Security incidents are nearly certain,\nbut out of thousands of exposed nontrivial resources, any service can be\nused as an attack vector—and no one service is likely to see a volume of\nevents that would make statistical forecasting meaningful within the\nscope of a single enterprise.\nEnlightenment Through Taxonomy\nThe two schools of thought discussed above share something in common:\nBoth assume that it is possible to define security as a set of computable goals\nand that the resulting unified theory of a secure system or a model of accept-\nable risk would then elegantly trickle down, resulting in an optimal set of\nlow-level actions needed to achieve perfection in application design.\nSome practitioners preach the opposite approach, which owes less to\nphilosophy and more to the natural sciences. These practitioners argue that,\nmuch like Charles Darwin of the information age, by gathering sufficient\namounts of low-level, experimental data, we will be able to observe, recon-\nstruct, and document increasingly more sophisticated laws in order to arrive\nsome sort of a unified model of secure computing.\nThis latter worldview brings us projects like the Department of Home-\nland Security–funded Common Weakness Enumeration (CWE), the goal of\nwhich, in the organization’s own words, is to develop a unified “Vulnerability\nTheory”; “improve the research, modeling, and classification of software flaws”;\nand “provide a common language of discourse for discussing, finding and\ndealing with the causes of software security vulnerabilities.” A typical, delight-\nfully baroque example of the resulting taxonomy may be this:\nImproper Enforcement of Message or Data Structure\nFailure to Sanitize Data into a Different Plane\nImproper Control of Resource Identifiers\nInsufficient Filtering of File and Other Resource Names\nfor Executable Content\nToday, there are about 800 names in the CWE dictionary, most of which\nare as discourse-enabling as the one quoted here.\nA slightly different school of naturalist thought is manifested in projects\nsuch as the Common Vulnerability Scoring System (CVSS), a business-backed\ncollaboration that aims to strictly quantify known security problems in terms\nof a set of basic, machine-readable parameters. A real-world example of the\nresulting vulnerability descriptor may be this:\nAV:LN / AC:L / Au:M / C:C / I:N / A:P / E:F / RL:T / RC:UR /\nCDP:MH / TD:H / CR:M / IR:L / AR:M\n6 Chapter 1"
  },
  {
    "input": "Toward Practical Approaches",
    "output": "Organizations and researchers are expected to transform this 14-\ndimensional vector in a carefully chosen, use-specific way in order to arrive\natsome sort of objective, verifiable, numerical conclusion about the signifi-\ncance of the underlying bug (say, “42”), precluding the need to judge the\nnature of security flaws in any more subjective fashion.\nYes, I am poking gentle fun at the expense of these projects, but I do\nnotmean to belittle their effort. CWE, CVSS, and related projects serve noble\ngoals, such as bringing a more manageable dimension to certain security pro-\ncesses implemented by large organizations. Still, none has yielded a grand\ntheory of secure software, and I doubt such a framework is within sight.\nToward Practical Approaches\nAll signs point to security being largely a nonalgorithmic problem for now.\nThe industry is understandably reluctant to openly embrace this notion,\nbecause it implies that there are no silver bullet solutions to preach (or better\nyet, commercialize); still, when pressed hard enough, eventually everybody in\nthe security field falls back to a set of rudimentary, empirical recipes. These\nrecipes are deeply incompatible with many business management models,\nbut they are all that have really worked for us so far. They are as follows:\n Learning from (preferably other people’s) mistakes. Systems should be\ndesigned to prevent known classes of bugs. In the absence of automatic\n(or even just elegant) solutions, this goal is best achieved by providing\nongoing design guidance, ensuring that developers know what could go\nwrong, and giving them the tools to carry out otherwise error-prone tasks\nin the simplest manner possible.\n Developing tools to detect and correct problems. Security deficiencies\ntypically have no obvious side effects until they’re discovered by a mali-\ncious party: a pretty costly feedback loop. To counter this problem, we\ncreate security quality assurance (QA) tools to validate implementations\nand perform audits periodically to detect casual mistakes (or systemic\nengineering deficiencies).\n Planning to have everything compromised. History teaches us that major\nincidents will occur despite our best efforts to prevent them. It is impor-\ntant to implement adequate component separation, access control, data\nredundancy, monitoring, and response procedures so that service own-\ners can react to incidents before an initially minor hiccup becomes a\ndisaster of biblical proportions.\nIn all cases, a substantial dose of patience, creativity, and real technical\nexpertise is required from all the information security staff.\nNaturally, even such simple, commonsense rules—essentially basic engi-\nneering rigor—are often dressed up in catchphrases, sprinkled liberally with\naselection of acronyms (such as CIA: confidentiality, integrity, availability), and\nthen called “methodologies.” Frequently, these methodologies are thinly\nveiled attempts to pass off one of the most frustrating failures of the security\nindustry as yet another success story and, in the end, sell another cure-all\nSecurity in the World of Web Applications 7"
  },
  {
    "input": "Tales of the Stone Age: 1945 to 1994",
    "output": "product or certification to gullible customers. But despite claims to the con-\ntrary, such products are no substitute for street smarts and technical prow-\ness—at least not today.\nIn any case, through the remainder of this book, I will shy away from\nattempts to establish or reuse any of the aforementioned grand philosophi-\ncal frameworks and settle for a healthy dose of anti-intellectualism instead. I\nwill review the exposed surface of modern browsers, discuss how to use the\navailable tools safely, which bits of the Web are commonly misunderstood,\nand how to control collateral damage when things go boom.\nAnd that is, pretty much, the best take on security engineering that I can\nthink of.\nA Brief History of the Web\nThe Web has been plagued by a perplexing number, and a remarkable vari-\nety, of security issues. Certainly, some of these problems can be attributed to\none-off glitches in specific client or server implementations, but many are due\nto capricious, often arbitrary design decisions that govern how the essential\nmechanisms operate and mesh together on the browser end.\nOur empire is built on shaky foundations—but why? Perhaps due to sim-\nple shortsightedness: After all, back in the innocent days, who could predict\nthe perils of contemporary networking and the economic incentives behind\ntoday’s large-scale security attacks?\nUnfortunately, while this explanation makes sense for truly ancient mech-\nanisms such as SMTP or DNS, it does not quite hold water here: The Web is\nrelatively young and took its current shape in a setting not that different from\nwhat we see today. Instead, the key to this riddle probably lies in the tumultu-\nous and unusual way in which the associated technologies have evolved.\nSo, pardon me another brief detour as we return to the roots. The pre-\nhistory of the Web is fairly mundane but still worth a closer look.\nTales of the Stone Age: 1945 to 1994\nComputer historians frequently cite a hypothetical desk-sized device called\nthe Memex as one of the earliest fossil records, postulated in 1945 by Vannevar\nBush.3 Memex was meant to make it possible to create, annotate, and follow\ncross-document links in microfilm, using a technique that vaguely resembled\nmodern-day bookmarks and hyperlinks. Bush boldly speculated that this sim-\nple capability would revolutionize the field of knowledge management and\ndata retrieval (amusingly, a claim still occasionally ridiculed as uneducated\nand naïve until the early 1990s). Alas, any useful implementation of the design\nwas out of reach at that time, so, beyond futuristic visions, nothing much\nhappened until transistor-based computers took center stage.\nThe next tangible milestone, in the 1960s, was the arrival of IBM’s\nGeneralized Markup Language (GML), which allowed for the annotation of\ndocuments with machine-readable directives indicating the function of each\nblock of text, effectively saying “this is a header,” “this is a numbered list of\nitems,” and so on. Over the next 20 years or so, GML (originally used by only\n8 Chapter 1\na handful of IBM text editors on bulky mainframe computers) became the\nfoundation for Standard Generalized Markup Language (SGML), a more\nuniversal and flexible language that traded an awkward colon- and period-\nbased syntax for a familiar angle-bracketed one.\nWhile GML was developing into SGML, computers were growing more\npowerful and user friendly. Several researchers began experimenting with\nBush’s cross-link concept, applying it to computer-based document storage\nand retrieval, in an effort to determine whether it would be possible to cross-\nreference large sets of documents based on some sort of key. Adventurous\ncompanies and universities pursued pioneering projects such as ENQUIRE,\nNLS, and Xanadu, but most failed to make a lasting impact. Some common\ncomplaints about the various projects revolved around their limited practical\nusability, excess complexity, and poor scalability.\nBy the end of the decade, two researchers, Tim Berners-Lee and Dan\nConnolly, had begun working on a new approach to the cross-domain refer-\nence challenge—one that focused on simplicity. They kicked off the project\nby drafting HyperText Markup Language (HTML), a bare-bones descendant\nof SGML, designed specifically for annotating documents with hyperlinks\nand basic formatting. They followed their work on HTML with the develop-\nment of HyperText Transfer Protocol (HTTP), an extremely basic, dedi-\ncated scheme for accessing HTML resources using the existing concepts of\nInternet Protocol (IP) addresses, domain names, and file paths. The culmi-\nnation of their work, sometime between 1991 and 1993, was Tim Berners-\nLee’s World Wide Web (Figure 1-1), a rudimentary browser that parsed\nHTML and allowed users to render the resulting data on the screen, and\nthen navigate from one page to another with a mouse click.\nFigure 1-1: Tim Berners-Lee’s World Wide Web\nSecurity in the World of Web Applications 9"
  },
  {
    "input": "The First Browser Wars: 1995 to 1999",
    "output": "To many people, the design of HTTP and HTML must have seemed a\nsignificant regression from the loftier goals of competing projects. After all,\nmany of the earlier efforts boasted database integration, security and digital\nrights management, or cooperative editing and publishing; in fact, even\nBerners-Lee’s own project, ENQUIRE, appeared more ambitious than his\ncurrent work. Yet, because of its low entry requirements, immediate usability,\nand unconstrained scalability (which happened to coincide with the arrival\nof powerful and affordable computers and the expansion of the Internet),\nthe unassuming WWW project turned out to be a sudden hit.\nAll right, all right, it turned out to be a “hit” by the standards of the mid-\n1990s. Soon, there were no fewer than dozens of web servers running on the\nInternet. By 1993, HTTP traffic accounted for 0.1 percent of all bandwidth\ninthe National Science Foundation backbone network. The same year also\nwitnessed the arrival of Mosaic, the first reasonably popular and sophisti-\ncated web browser, developed at the University of Illinois. Mosaic extended\nthe original World Wide Web code by adding features such as the ability to\nembed images in HTML documents and submit user data through forms,\nthus paving the way for the interactive, multimedia applications of today.\nMosaic made browsing prettier, helping drive consumer adoption of the\nWeb. And through the mid-1990s, it served as the foundation for two other\nbrowsers: Mosaic Netscape (later renamed Netscape Navigator) and Spyglass\nMosaic (ultimately acquired by Microsoft and renamed Internet Explorer).\nAhandful of competing non-Mosaic engines emerged as well, including\nOpera and several text-based browsers (such as Lynx and w3m). The first\nsearch engines, online newspapers, and dating sites followed soon after.\nThe First Browser Wars: 1995 to 1999\nBy the mid-1990s, it was clear that the Web was here to stay and that users\nwere willing to ditch many older technologies in favor of the new contender.\nAround that time, Microsoft, the desktop software behemoth that had been\nslow to embrace the Internet before, became uncomfortable and began\ntoallocate substantial engineering resources to its own browser, eventually\nbundling it with the Windows operating system in 1996.* Microsoft’s actions\nsparked a period colloquially known as the “browser wars.”\nThe resulting arms race among browser vendors was characterized by the\nremarkably rapid development and deployment of new features in the compet-\ning products, a trend that often defied all attempts to standardize or even prop-\nerly document all the newly added code. Core HTML tweaks ranged from the\nsilly (the ability to make text blink, a Netscape invention that became the butt\nof jokes and a telltale sign of misguided web design) to notable ones, such as\nthe ability to change typefaces or embed external documents in so-called frames.\nVendors released their products with embedded programming languages such\nas JavaScript and Visual Basic, plug-ins to execute platform-independent Java\n* Interestingly, this decision turned out to be a very controversial one. On one hand, it could\nbeargued that in doing so, Microsoft contributed greatly to the popularization of the Internet.\nOn the other, it undermined the position of competing browsers and could be seen as anti-\ncompetitive. In the end, the strategy led to a series of protracted legal battles over the possible\nabuse of monopoly by the company, such as United States v. Microsoft.\n10 Chapter 1"
  },
  {
    "input": "The Boring Period: 2000 to 2003",
    "output": "or Flash applets on the user’s machine, and useful but tricky HTTP extensions\nsuch as cookies. Only a limited degree of superficial compatibility, sometimes\nhindered by patents and trademarks,* would be maintained.\nAs the Web grew larger and more diverse, a sneaky disease spread across\nbrowser engines under the guise of fault tolerance. At first, the reasoning\nseemed to make perfect sense: If browser A could display a poorly designed,\nbroken page but browser B refused to (for any reason), users would inevita-\nbly see browser B’s failure as a bug in that product and flock in droves to the\nseemingly more capable client, browser A. To make sure that their browsers\ncould display almost any web page correctly, engineers developed increas-\ningly complicated and undocumented heuristics designed to second-guess\nthe intent of sloppy webmasters, often sacrificing security and occasionally\neven compatibility in the process. Unfortunately, each such change further\nreinforced bad web design practices† and forced the remaining vendors to\ncatch up with the mess to stay afloat. Certainly, the absence of sufficiently\ndetailed, up-to-date standards did not help to curb the spread of this disease.\nIn 1994, in order to mitigate the spread of engineering anarchy and gov-\nern the expansion of HTML, Tim Berners-Lee and a handful of corporate\nsponsors created the World Wide Web Consortium (W3C). Unfortunately\nfor this organization, for a long while it could only watch helplessly as the for-\nmat was randomly extended and tweaked. Initial W3C work on HTML 2.0\nand HTML 3.2 merely tried to catch up with the status quo, resulting in half-\nbaked specs that were largely out-of-date by the time they were released to\nthe public. The consortium also tried to work on some novel and fairly well-\nthought-out projects, such as Cascading Style Sheets, but had a hard time get-\nting buy-in from the vendors.\nOther efforts to standardize or improve already implemented mecha-\nnisms, most notably HTTP and JavaScript, were driven by other auspices such\nas the European Computer Manufacturers Association (ECMA), the Interna-\ntional Organization for Standardization (ISO), and the Internet Engineering\nTask Force (IETF). Sadly, the whole of these efforts was seldom in sync, and\nsome discussions and design decisions were dominated by vendors or other\nstakeholders who did not care much about the long-term prospects of the tech-\nnology. The results were a number of dead standards, contradictory advice,\nand several frightening examples of harmful cross-interactions between other-\nwise neatly designed protocols—a problem that will be particularly evident\nwhen we discuss a variety of content isolation mechanisms in Chapter 9.\nThe Boring Period: 2000 to 2003\nAs the efforts to wrangle the Web floundered, Microsoft’s dominance grew\nasa result of its operating system–bundling strategy. By the beginning of the\nnew decade, Netscape Navigator was on the way out, and Internet Explorer\n* For example, Microsoft did not want to deal with Sun to license a trademark for JavaScript\n(alanguage so named for promotional reasons and not because it had anything to do with Java),\nso it opted to name its almost-but-not-exactly-identical version “JScript.” Microsoft’s official\ndocumentation still refers to the software by this name.\n† Prime examples of misguided and ultimately lethal browser features are content and character\nset–sniffing mechanisms, both of which will be discussed in Chapter 13.\nSecurity in the World of Web Applications 11"
  },
  {
    "input": "Web 2.0 and the Second Browser Wars: 2004 and Beyond",
    "output": "held an impressive 80 percent market share—a number roughly comparable\nto what Netscape had held just five years before. On both sides of the fence,\nsecurity and interoperability were the two most notable casualties of the fea-\nture war, but one could hope now that the fighting was over, developers\ncould put differences aside and work together to fix the mess.\nInstead, dominance bred complacency: Having achieved its goals bril-\nliantly, Microsoft had little incentive to invest heavily in its browser. Although\nthrough version 5, major releases of Internet Explorer (IE) arrived yearly,\nit took two years for version 6 to surface, then five full years for Internet\nExplorer 6 to be updated to Internet Explorer 7. Without Microsoft’s inter-\nest, other vendors had very little leverage to make disruptive changes; most\nsites were unwilling to make improvements that would work for only a small\nfraction of their visitors.\nOn the upside, the slowdown in browser development allowed the\nW3Cto catch up and to carefully explore some new concepts for the future\nof theWeb. New initiatives finalized around the year 2000 included HTML 4\n(a cleaned-up language that deprecated or banned many of the redundant or\npolitically incorrect features embraced by earlier versions) and XHTML 1.1 (a\nstrict and well-structured XML-based format that was easier to unambiguously\nparse, with no proprietary heuristics allowed). The consortium also made signif-\nicant improvements to JavaScript’s Document Object Model and to Cascading\nStyle Sheets. Regrettably, by the end of the century, the Web was too mature to\ncasually undo some of the sins of the old, yet too young for the security issues to\nbe pressing and evident enough for all to see. Syntax was improved, tags were\ndeprecated, validators were written, and deck chairs were rearranged, but the\nbrowsers remained pretty much the same: bloated, quirky, and unpredictable.\nBut soon, something interesting happened: Microsoft gave the world a\nseemingly unimportant, proprietary API, confusingly named XMLHttpRequest.\nThis trivial mechanism was meant to be of little significance, merely an\nattempt to scratch an itch in the web-based version of Microsoft Outlook.\nButXMLHttpRequest turned out to be far more, as it allowed for largely\nunconstrained asynchronous HTTP communications between client-side\nJavaScript and the server without the need for time-consuming and disrup-\ntive page transitions. In doing so, the API contributed to the emergence of\nwhat would later be dubbed web 2.0—a range of complex, unusually respon-\nsive, browser-based applications that enabled users to operate on complex\ndata sets, collaborate and publish content, and so on, invading the sacred\ndomain of “real,” installable client software in the process. Understandably,\nthis caused quite a stir.\nWeb 2.0 and the Second Browser Wars: 2004 and Beyond\nXMLHttpRequest, in conjunction with the popularity of the Internet and the\nbroad availability of web browsers, pushed the Web to some new, exciting\nfrontiers—and brought us a flurry of security bugs that impacted both indi-\nvidual users and businesses. By about 2002, worms and browser vulnerabili-\nties had emerged as a frequently revisited theme in the media. Microsoft, by\nvirtue of its market dominance and a relatively dismissive security posture,\n12 Chapter 1\ntook much of the resulting PR heat. The company casually downplayed the\nproblem, but the trend eventually created an atmosphere conducive to a\nsmall rebellion.\nIn 2004, a new contender in the browser wars emerged: Mozilla Firefox\n(a community-supported descendant of Netscape Navigator) took the offen-\nsive, specifically targeting Internet Explorer’s poor security track record and\nstandards compliance. Praised by both IT journalists and security experts,\nFirefox quickly secured a 20 percent market share. While the newcomer soon\nproved to be nearly as plagued by security bugs as its counterpart from Red-\nmond, its open source nature and the freedom from having to cater to stub-\nborn corporate users allowed developers to fix issues much faster.\nNOTE Why would vendors compete so feverishly? Strictly speaking, there is no money to be\nmade by having a particular market share in the browser world. That said, pundits\nhave long speculated that it is a matter of power: By bundling, promoting, or demoting\ncertain online services (even as simple as the default search engine), whoever controls\nthe browser controls much of the Internet.\nFirefox aside, Microsoft had other reasons to feel uneasy. Its flagship prod-\nuct, the Windows operating system, was increasingly being used as an (expend-\nable?) launch pad for the browser, with more and more applications (from\ndocument editors to games) moving to the Web. This could not be good.\nThese facts, combined with the sudden emergence of Apple’s Safari\nbrowser and perhaps Opera’s advances in the world of smartphones, must\nhave had Microsoft executives scratching their heads. They had missed\ntheearly signs of the importance of the Internet in the 1990s; surely they\ncouldn’t afford to repeat the mistake. Microsoft put some steam behind\nInternet Explorer development again, releasing drastically improved and\nsomewhat more secure versions 7, 8, and 9 in rapid succession.\nCompetitors countered with new features and claims of even better (if still\nsuperficial) standards compliance, safer browsing, and performance improve-\nments. Caught off guard by the unexpected success of XMLHttpRequest and\nquick to forget other lessons from the past, vendors also decided to experi-\nment boldly with new ideas, sometimes unilaterally rolling out half-baked or\nsomewhat insecure designs like globalStorage in Firefox or httponly cookies in\nInternet Explorer, just to try their luck.\nTo further complicate the picture, frustrated by creative differences with\nW3C, a group of contributors created a wholly new standards body called the\nWeb Hypertext Application Technology Working Group (WHATWG). The\nWHATWG has been instrumental in the development of HTML5, the first\nholistic and security-conscious revision of existing standards, but it is report-\nedly shunned by Microsoft due to patent policy disputes.\nThroughout much of its history, the Web has enjoyed a unique, highly\ncompetitive, rapid, often overly political, and erratic development model\nwith no unifying vision and no one set of security principles. This state of\naffairs has left a profound mark on how browsers operate today and how\nsecure the user data handled by browsers can be.\nChances are, this situation is not going to change anytime soon.\nSecurity in the World of Web Applications 13"
  },
  {
    "input": "The User as a Security Flaw",
    "output": "The Evolution of a Threat\nClearly, web browsers, and their associated document formats and communi-\ncation protocols, evolved in an unusual manner. This evolution may explain\nthe high number of security problems we see, but by itself it hardly proves\nthat these problems are unique or noteworthy. To wrap up this chapter, let’s\ntake a quick look at the very special characteristics behind the most prevalent\ntypes of online security threats and explore why these threats had no particu-\nlarly good equivalents in the years before the Web.\nThe User as a Security Flaw\nPerhaps the most striking (and entirely nontechnical) property of web\nbrowsers is that most people who use them are overwhelmingly unskilled.\nSure, nonproficient users have been an amusing, fringe problem since the\ndawn of computing. But the popularity of the Web, combined with its remark-\nably low barrier to entry, means we are facing a new foe: Most users simply\ndon’t know enough to stay safe.\nFor a long time, engineers working on general-purpose software have\nmade seemingly arbitrary assumptions about the minimal level of computer\nproficiency required of their users. Most of these assumptions have been with-\nout serious consequences; the incorrect use of a text editor, for instance, would\ntypically have little or no impact on system security. Incompetent users simply\nwould not be able to get their work done, a wonderfully self-correcting issue.\nWeb browsers do not work this way, however. Unlike certain complicated\nsoftware, they can be successfully used by people with virtually no computer\ntraining, people who may not even know how to use a text editor. But at the\nsame time, browsers can be operated safely only by people with a pretty good\nunderstanding of computer technology and its associated jargon, including\ntopics such as Public-Key Infrastructure. Needless to say, this prerequisite is\nnot met by most users of some of today’s most successful web applications.\nBrowsers still look and feel as if they were designed by geeks and for\ngeeks, complete with occasional cryptic and inconsistent error messages,\ncomplex configuration settings, and a puzzling variety of security warnings\nand prompts. A notable study by Berkeley and Harvard researchers in 2006\ndemonstrated that casual users are almost universally oblivious to signals that\nsurely make perfect sense to a developer, such as the presence or absence\noflock icons in the status bar.4 In another study, Stanford and Microsoft\nresearchers reached similar conclusions when they examined the impact of\nthe modern “green URL bar” security indicator. The mechanism, designed\nto offer a more intuitive alternative to lock icons, actually made it easier to\ntrick users by teaching the audience to trust a particular shade of green, no\nmatter where this color appeared.5\nSome experts argue that the ineptitude of the casual user is not the\nfaultof software vendors and hence not an engineering problem at all. Others\nnote that when creating software so easily accessible and so widely distributed,\nit is irresponsible to force users to make security-critical decisions that depend\non technical prowess not required to operate the program in the first place.\n14 Chapter 1"
  },
  {
    "input": "Nonconvergence of Visions",
    "output": "To blame browser vendors alone is just as unfair, however: The computing\nindustry as a whole has no robust answers in this area, and very little research\nis available on how to design comparably complex user interfaces (UIs) in a\nbulletproof way. After all, we barely get it right for ATMs.\nThe Cloud, or the Joys of Communal Living\nAnother peculiar characteristic of the Web is the dramatically understated\nseparation between unrelated applications and the data they process.\nIn the traditional model followed by virtually all personal computers\nover the last 15 years or so, there are very clear boundaries between high-\nlevel data objects (documents), user-level code (applications), and the oper-\nating system kernel that arbitrates all cross-application communications and\nhardware input/output (I/O) and enforces configurable security rules should\nan application go rogue. These boundaries are well studied and useful for\nbuilding practical security schemes. A file opened in your text editor is unlikely\nto be able to steal your email, unless a really unfortunate conjunction of\nimplementation flaws subverts all these layers of separation at once.\nIn the browser world, this separation is virtually nonexistent: Documents\nand code live as parts of the same intermingled blobs of HTML, isolation\nbetween completely unrelated applications is partial at best (with all sites\nnominally sharing a global JavaScript environment), and many types of inter-\naction between sites are implicitly permitted with few, if any, flexible, browser-\nlevel security arbitration frameworks.\nIn a sense, the model is reminiscent of CP/M, DOS, and other principally\nnonmultitasking operating systems with no robust memory protection, CPU\npreemption, or multiuser features. The obvious difference is that few users\ndepended on these early operating systems to simultaneously run multiple\nuntrusted, attacker-supplied applications, so there was no particular reason\nfor alarm.\nIn the end, the seemingly unlikely scenario of a text file stealing your\nemail is, in fact, a frustratingly common pattern on the Web. Virtually all web\napplications must heavily compensate for unsolicited, malicious cross-domain\naccess and take cumbersome steps to maintain at least some separation of\ncode and the displayed data. And sooner or later, virtually all web applications\nfail. Content-related security issues, such as cross-site scripting or cross-site\nrequest forgery, are extremely common and have very few counterparts in\ndedicated, compartmentalized client architectures.\nNonconvergence of Visions\nFortunately, the browser security landscape is not entirely hopeless, and\ndespite limited separation between web applications, several selective secu-\nrity mechanisms offer rudimentary protection against the most obvious attacks.\nBut this brings us to another characteristic that makes the Web such an inter-\nesting subject: There is no shared, holistic security model to grasp and live by.\nWe are not looking for a grand vision for world peace, mind you, but simply\na common set of flexible paradigms that would apply to most, if not all, of the\nSecurity in the World of Web Applications 15"
  },
  {
    "input": "Cross-Browser Interactions: Synergy in Failure",
    "output": "relevant security logic. In the Unix world, for example, the rwx user/group per-\nmission model is one such strong unifying theme. But in the browser realm?\nIn the browser realm, a mechanism called same-origin policy could be\nconsidered a candidate for a core security paradigm, but only until one real-\nizes that it governs a woefully small subset of cross-domain interactions. That\ndetail aside, even within its scope, it has no fewer than seven distinct varieties,\neach of which places security boundaries between applications in a slightly\ndifferent place.* Several dozen additional mechanisms, with no relation to\nthe same-origin model, control other key aspects of browser behavior (essen-\ntially implementing what each author considered to be the best approach to\nsecurity controls that day).\nAs it turns out, hundreds of small, clever hacks do not necessarily add up\nto a competent security opus. The unusual lack of integrity makes it very dif-\nficult even to decide where a single application ends and a different one\nbegins. Given this reality, how does one assess attack surfaces, grant or take\naway permissions, or accomplish just about any other security-minded task?\nToo often, “by keeping your fingers crossed” is the best response we can give.\nCuriously, many well-intentioned attempts to improve security by\ndefining new security controls only make the problem worse. Many of these\nschemes create new security boundaries that, for the sake of elegance, do not\nperfectly align with the hairy juxtaposition of the existing ones. When the\nnew controls are finer grained, they are likely to be rendered ineffective by\nthe legacy mechanisms, offering a false sense of security; when they are more\ncoarse grained, they may eliminate some of the subtle assurances that the\nWeb depends on right now. (Adam Barth and Collin Jackson explore the\ntopic of destructive interference between browser security policies in their\nacademic work.)6\nCross-Browser Interactions: Synergy in Failure\nThe overall susceptibility of an ecosystem composed of several different soft-\nware products could be expected to be equal to a simple sum of the flaws\ncontributed by each of the applications. In some cases, the resulting expo-\nsure may be less (diversity improves resilience), but one would not expect it\nto be more.\nThe Web is once again an exception to the rule. The security community\nhas discovered a substantial number of issues that cannot be attributed to any\nparticular piece of code but that emerge as a real threat when various brows-\ners try to interact with each other. No particular product can be easily singled\nout for blame: They are all doing their thing, and the only problem is that no\none has bothered to define a common etiquette for all of them to obey.\nFor example, one browser may assume that, in line with its own security\nmodel, it is safe to pass certain URLs to external applications or to store or\nread back certain types of data from disk. For each such assumption, there\nlikely exists at least one browser that strongly disagrees, expecting other\n* The primary seven varieties, as discussed throughout Part II of this book, include the security\npolicy for JavaScript DOM access; XMLHttpRequest API; HTTP cookies; local storage APIs; and\nplug-ins such as Flash, Silverlight, or Java.\n16 Chapter 1"
  },
  {
    "input": "The Breakdown of the Client-Server Divide",
    "output": "parties to follow its rules instead. The exploitability of these issues is greatly\naggravated by vendors’ desire to get their foot in the door and try to allow\nweb pages to switch to their browser on the fly without the user’s informed\nconsent. For example, Firefox allows pages to be opened in its browser by\nregistering a firefoxurl: protocol; Microsoft installs its own .NET gateway plug-\nin in Firefox; Chrome does the same to Internet Explorer via a protocol\nnamed cf:.\nNOTE Especially in the case of such interactions, pinning the blame on any particular party\nisa fool’s errand. In a recent case of a bug related to firefoxurl:, Microsoft and half of\nthe information security community blamed Mozilla, while Mozilla and the other half\nof experts blamed Microsoft.7 It did not matter who was right: The result was still a\nvery real mess.\nAnother set of closely related problems (practically unheard of in the\ndays before the Web) are the incompatibilities in superficially similar security\nmechanisms implemented in each browser. When the security models differ,\na sound web application–engineering practice in one product may be inade-\nquate and misguided in another. In fact, several classes of rudimentary tasks,\nsuch as serving a user-supplied plaintext file, cannot be safely implemented\nin certain browsers at all. This fact, however, will not be obvious to develop-\ners unless they are working in one of the affected browsers—and even then,\ntheyneed to hit just the right spot.\nIn the end, all the characteristics outlined in this section contribute to\nawhole new class of security vulnerabilities that a taxonomy buff might call a\nfailure to account for undocumented diversity. This class is very well populated\ntoday.\nThe Breakdown of the Client-Server Divide\nInformation security researchers enjoy the world of static, clearly assigned\nroles, which are a familiar point of reference when mapping security inter-\nactions in the otherwise complicated world. For example, we talk about Alice\nand Bob, two wholesome, hardworking users who want to communicate, and\nMallory, a sneaky attacker who is out to get them. We then have client software\n(essentially dumb, sometimes rogue I/O terminals that frivolously request\nservices) and humble servers, carefully fulfilling the clients’ whim. Develop-\ners learn these roles and play along, building fairly comprehensible and test-\nable network-computing environments in the process.\nThe Web began as a classical example of a proper client-server architec-\nture, but the functional boundaries between client and server responsibilities\nwere quickly eroded. The culprit is JavaScript, a language that offers the HTTP\nservers a way to delegate application logic to the browser (“client”) side and\ngives them two very compelling reasons to do so. First, such a shift often\nresults in more responsive user interfaces, as servers do not need to synchro-\nnously participate in each tiny UI state change imaginable. Second, server-\nside CPU and memory requirements (and hence service-provisioning costs)\ncan decrease drastically when individual workstations across the globe chip\nin to help with the bulk of the work.\nSecurity in the World of Web Applications 17\nThe client-server diffusion process began innocently enough, but it\nwasonly a matter of time before the first security mechanisms followed to the\nclient side too, along with all the other mundane functionality. For example,\nwhat was the point of carefully scrubbing HTML on the server side when the\ndata was only dynamically rendered by JavaScript on the client machine?\nIn some applications, this trend was taken to extremes, eventually leav-\ning the server as little more than a dumb storage device and moving almost\nall the parsing, editing, display, and configuration tasks into the browser\nitself. In such designs, the dependency on a server could even be fully sev-\nered by using offline web extensions such as HTML5 persistent storage.\nA simple shift in where the entire application magic happens is not\nnecessarily a big deal, but not all security responsibilities can be delegated to\nthe client as easily. For example, even in the case of a server acting as dumb\nstorage, clients cannot be given indiscriminate access to all the data stored\non the server for other users, and they cannot be trusted to enforce access\ncontrols. In the end, because it was not desirable to keep all the application\nsecurity logic on the server side, and it was impossible to migrate it fully to the\nclient, most applications ended up occupying some arbitrary middle ground\ninstead, with no easily discernible and logical separation of duties between\nthe client and server components. The resulting unfamiliar designs and\napplication behaviors simply had no useful equivalents in the elegant and\nwholesome world of security role-play.\nThe situation has resulted in more than just a design-level mess; it has\nled to irreducible complexity. In a traditional client-server model with well-\nspecified APIs, one can easily evaluate a server’s behavior without looking\natthe client, and vice versa. Moreover, within each of these components, it\nispossible to easily isolate smaller functional blocks and make assumptions\nabout their intended operation. With the new model, coupled with the\nopaque, one-off application APIs common on the Web, these analytical\ntools,and the resulting ease of reasoning about the security of a system,\nhavebeen brutally taken away.\nThe unexpected failure of standardized security modeling and testing\nprotocols is yet another problem that earns the Web a very special—and\nscary—place in the universe of information security.\n18 Chapter 1"
  },
  {
    "input": "Global browser market share, May 2011",
    "output": "Global browser market share, May 2011\nVendor Browser Name Market Share\nMicrosoft Internet Explorer 6 10%\nInternet Explorer 7 7%\n52%\nInternet Explorer 8 31%\nInternet Explorer 9 4%\nMozilla Firefox 3 12%\n22%\nFirefox 4+ 10%\nGoogle Chrome 13%\nApple Safari 7%\nOpera Software Opera 3%\nSource: Data drawn from public Net Applications reports.1"
  },
  {
    "input": "PART I: Anatomy of the Web\r",
    "output": "PART I\nA N A T O M Y O F T H E W E B\nThe first part of this book focuses on the principal\nconcepts that govern the operation of web browsers,\nnamely, the protocols, document formats, and pro-\ngramming languages that make it all tick. Because all\nthe familiar, user-visible security mechanisms employed\nin modern browsers are profoundly intertwined with\nthese inner workings, the bare internals deserve a fair\nbit of attention before we wander off deeper into the\nwoods."
  },
  {
    "input": "2: It Starts with a URL\r",
    "output": "I T S T A R T S W I T H A U R L\nThe most recognizable hallmark of the Web is a simple\ntext string known as the Uniform Resource Locator (URL).\nEach well-formed, fully qualified URL is meant to con-\nclusively address and uniquely identify a single resource\non a remote server (and in doing so, implement a cou-\nple of related, auxiliary functions). The URL syntax is\nthe cornerstone of the address bar, the most important\nuser interface (UI) security indicator in every browser.\nIn addition to true URLs used for content retrieval, several classes of\npseudo-URLs use a similar syntax to provide convenient access to browser-level\nfeatures, including the integrated scripting engine, several special document-\nrendering modes, and so on. Perhaps unsurprisingly, these pseudo-URL\nactions can have a significant impact on the security of any site that decides\nto link to them.\nThe ability to figure out how a particular URL will be interpreted by the\nbrowser, and the side effects it will have, is one of the most basic and com-\nmon security tasks attempted by humans and web applications alike, but it can"
  },
  {
    "input": "Scheme Name",
    "output": "be a problematic one. The generic URL syntax, the work of Tim Berners-Lee,\nis codified primarily in RFC 3986;1 its practical uses on the Web are outlined\nin RFCs 1738,2 2616,3 and a couple of other, less-significant standards. These\ndocuments are remarkably detailed, resulting in a fairly complex parsing\nmodel, but they are not precise enough to lead to harmonious, compatible\nimplementations in all client software. In addition, individual software ven-\ndors have chosen to deviate from the specifications for their own reasons.\nLet’s have a closer look at how the humble URL works in practice.\nUniform Resource Locator Structure\nFigure 2-1 shows the format of a fully qualified absolute URL, one that specifies\nall information required to access a particular resource and that does not\ndepend in any way on where the navigation began. In contrast, a relative URL,\nsuch as ../file.php?text=hello+world, omits some of this information and must\nbe interpreted in the context of a base URL associated with the current\nbrowsing context.\n(cid:2) (cid:3) (cid:4) (cid:5) (cid:6) (cid:7) (cid:8) (cid:9)\nscheme://login.password@address:port/path/to/resource?query_string#fragment\n(cid:2) Scheme/protocol name\n(cid:3) Indicator of a hierarchical URL (constant)\n(cid:4) Credentials to access the resource (optional)\n(cid:5) Server to retrieve the data from “Authority”\n(cid:6) Port number to connect to (optional)\n(cid:7) Hierarchical Unix path to a resource\n(cid:8) “Query string” parameters (optional)\n(cid:9) “Fragment identifier” (optional)\nFigure 2-1: Structure of an absolute URL\nThe segments of the absolute URL seem intuitive, but each comes with\naset of gotchas, so let’s review them now.\nScheme Name\nThe scheme name is a case-insensitive string that ends with a single colon,\nindicating the protocol to be used to retrieve the resource. The official\nregistry of valid URL schemes is maintained by the Internet Assigned Numbers\nAuthority (IANA), a body more widely known for its management of the IP\naddress space.4 IANA’s current list of valid scheme names includes several\ndozen entries such as http:, https:, and ftp:; in practice, a much broader set of\nschemes is informally recognized by common browsers and third-party appli-\ncations, some which have special security consequences. (Of particular inter-\nest are several types of pseudo-URLs, such as data: or javascript:, as discussed\nlater in this chapter and throughout the remainder of this book.)\n24 Chapter 2"
  },
  {
    "input": "Indicator of a Hierarchical URL",
    "output": "Before they can do any further parsing, browsers and web applications\nneed to distinguish fully qualified absolute URLs from relative ones. The\npresence of a valid scheme in front of the address is meant to be the key\ndifference, as defined in RFC 1738: In a compliant absolute URL, only the\nalphanumerics “+”, “-”, and “.” may appear before the required “:”. In prac-\ntice, however, browsers deviate from this guidance a bit. All ignore leading\nnewlines and white spaces. Internet Explorer ignores the entire nonprintable\ncharacter range of ASCII codes 0x01 to 0x1F. Chrome additionally skips 0x00,\nthe NUL character. Most implementations also ignore newlines and tabs in the\nmiddle of scheme names, and Opera accepts high-bit characters in the string.\nBecause of these incompatibilities, applications that depend on the abil-\nity to differentiate between relative and absolute URLs must conservatively\nreject any anomalous syntax—but as we will soon find out, even this is not\nenough.\nIndicator of a Hierarchical URL\nIn order to comply with the generic syntax rules laid out in RFC 1738, every\nabsolute, hierarchical URL is required to contain the fixed string “//” right\nbefore the authority section. If the string is missing, the format and function\nof the remainder of the URL is undefined for the purpose of that specifica-\ntion and must be treated as an opaque, scheme-specific value.\nNOTE An example of a nonhierarchical URL is the mailto: protocol, used to specify\nemailaddresses and possibly a subject line (mailto:user@example.com?subject=\nHello+world). Such URLs are passed down to the default mail client without making\nany further attempt to parse them.\nThe concept of a generic, hierarchical URL syntax is, in theory, an ele-\ngant one. It ought to enable applications to extract some information about\nthe address without knowing how a particular scheme works. For example,\nwithout a preconceived notion of the wacky-widget: protocol, and by applying\nthe concept of generic URL syntax alone, the browser could decide that\nhttp://example.com/test1/ and wacky-widget://example.com/test2/ reference the\nsame, trusted remote host.\nRegrettably, the specification has an interesting flaw: The aforementioned\nRFC says nothing about what the implementer should do when encountering\nURLs where the scheme is known to be nonhierarchical but where a “//”\nprefix still appears, or vice versa. In fact, a reference parser implementation\nprovided in RFC 1630 contains an unintentional loophole that gives a counter-\nintuitive meaning to the latter class of URLs. In RFC 3986, published some\nyears later, the authors sheepishly acknowledge this flaw and permit imple-\nmentations to try to parse such URLs for compatibility reasons. As a conse-\nquence, many browsers interpret the following examples in unexpected ways:\n http:example.com/ In Firefox, Chrome, and Safari, this address may be\ntreated identically to http://example.com/ when no fully qualified base\nURL context exists and as a relative reference to a directory named\nexample.com when a valid base URL is available.\nIt Starts with a URL 25"
  },
  {
    "input": "Server Address",
    "output": " javascript://example.com/%0Aalert(1) This string is interpreted as a valid\nnonhierarchical pseudo-URL in all modern browsers, and the JavaScript\nalert(1) code will execute, showing a simple dialog window.\n mailto://user@example.com Internet Explorer accepts this URL as a valid\nnonhierarchical reference to an email address; the “//” part is simply\nskipped. Other browsers disagree.\nCredentials to Access the Resource\nThe credentials portion of the URL is optional. This location can specify a\nusername, and perhaps a password, that may be required to retrieve the data\nfrom the server. The method through which these credentials are exchanged\nis not specified as a part of the abstract URL syntax, and it is always protocol\nspecific. For those protocols that do not support authentication, the behav-\nior of a credential-bearing URL is simply undefined.\nWhen no credentials are supplied, the browser will attempt to fetch the\nresource anonymously. In the case of HTTP and several other protocols, this\nmeans not sending any authentication data; for FTP, it involves logging into\na guest account named ftp with a bogus password.\nMost browsers accept almost any characters, other than general URL\nsection delimiters, in this section with two exceptions: Safari, for unclear rea-\nsons, rejects a broader set of characters, including “<”, “>”, “{”, and “}”, while\nFirefox also rejects newlines.*\nServer Address\nFor all fully qualified hierarchical URLs, the server address section must spec-\nify a case-insensitive DNS name (such as example.com), a raw IPv4 address (such\nas 127.0.0.1), or an IPv6 address in square brackets (such as [0:0:0:0:0:0:0:1]),\nindicating the location of a server hosting the requested resource. Firefox\nwill also accept IPv4 addresses and hostnames in square brackets, but other\nimplementations reject them immediately.\nAlthough the RFC permits only canonical notations for IP addresses, stan-\ndard C libraries used by most applications are much more relaxed, accepting\nnoncanonical IPv4 addresses that mix octal, decimal, and hexadecimal nota-\ntion or concatenate some or all of the octets into a single integer. As a result,\nthe following options are recognized as equivalent:\n http://127.0.0.1/ This is a canonical representation of an IPv4 address.\n http://0x7f.1/ This is a representation of the same address that uses a\nhexadecimal number to represent the first octet and concatenates all the\nremaining octets into a single decimal value.\n http://017700000001/ The same address is denoted using a 0-prefixed\noctal value, with all octets concatenated into a single 32-bit integer.\n* This is possibly out of the concern for FTP, which transmits user credentials without any\nencoding; in this protocol, a newline transmitted as is would be misinterpreted by the server\nasthe beginning of a new FTP command. Other browsers may transmit FTP credentials in\nnoncompliant percent-encoded form or simply strip any problematic characters later on.\n26 Chapter 2"
  },
  {
    "input": "Hierarchical File Path",
    "output": "A similar laid-back approach can be seen with DNS names. Theoretically,\nDNS labels need to conform to a very narrow character set (specifically, alpha-\nnumerics, “.”, and “-”, as defined in RFC 10355), but many browsers will happily\nask the underlying operating system resolver to look up almost anything, and\nthe operating system will usually also not make a fuss. The exact set of charac-\nters accepted in the hostname and passed to the resolver varies from client to\nclient. Safari is most rigorous, while Internet Explorer is the most permissive.\nPerhaps of note, several control characters in the 0x0A–0x0D and 0xA0–0xAD\nranges are ignored by most browsers in this portion of theURL.\nNOTE One fascinating behavior of the URL parsers in all of the mainstream browsers is their\nwillingness to treat the character “ ” (ideographic full stop, Unicode point U+3002)\nidentically to a period in hostnames but not anywhere else in the URL. This is report-\nedly because certain Chinese keyboard mappings make it much easier to type this symbol\nthan the expected 7-bit ASCII value.\nServer Port\nThis server port is an optional section that describes a nonstandard network\nport to connect to on the previously specified server. Virtually all application-\nlevel protocols supported by browsers and third-party applications use TCP\nor UDP as the underlying transport method, and both TCP and UDP rely on\n16-bit port numbers to separate traffic between unrelated services running\non a single machine. Each scheme is associated with a default port on which\nservers for that protocol are customarily run (80 for HTTP, 21 for FTP, and\nso on), but the default can be overridden at the URL level.\nNOTE An interesting and unintended side effect of this feature is that browsers can be tricked\ninto sending attacker-supplied data to random network services that do not speak the\nprotocol the browser expects them to. For example, one may point a browser to http://\nmail.example.com:25/, where 25 is a port used by the Simple Mail Transfer Protocol\n(SMTP) service rather than HTTP. This fact has caused a range of security problems\nand prompted a number of imperfect workarounds, as discussed in more detail in\nPartII of this book.\nHierarchical File Path\nThe next portion of the URL, the hierarchical file path, is envisioned as a\nway to identify a specific resource to be retrieved from the server, such as\n/documents/2009/my_diary.txt. The specification quite openly builds on top of\nthe Unix directory semantics, mandating the resolution of “/../” and “/./”\nsegments in the path and providing a directory-based method for sorting out\nrelative references in non–fully qualified URLs.\nUsing the filesystem model must have seemed like a natural choice in\nthe 1990s, when web servers acted as simple gateways to a collection of static\nfiles and the occasional executable script. But since then, many contempo-\nrary web application frameworks have severed any remaining ties with the\nfilesystem, interfacing directly with database objects or registered locations in\nresident program code. Mapping these data structures to well-behaved URL\nIt Starts with a URL 27"
  },
  {
    "input": "Fragment ID",
    "output": "paths is possible but not always practiced or practiced carefully. All of this\nmakes automated content retrieval, indexing, and security testing more\ncomplicated than it should be.\nQuery String\nThe query string is an optional section used to pass arbitrary, nonhierarchi-\ncal parameters to the resource earlier identified by the path. One common\nexample is passing user-supplied terms to a server-side script that implements\nthe search functionality, such as:\nhttp://example.com/search.php?query=Hello+world\nMost web developers are accustomed to a particular layout of the query\nstring; this familiar format is generated by browsers when handling HTML-\nbased forms and follows this syntax:\nname1=value1&name2=value2...\nSurprisingly, such layout is not mandated in the URL RFCs. Instead, the\nquery string is treated as an opaque blob of data that may be interpreted by\nthe final recipient as it sees fit, and unlike the path, it is not encumbered\nwith specific parsing rules.\nHints of the commonly used format can be found in an informational\nRFC 1630,6 in a mail-related RFC 2368,7 and in HTML specifications dealing\nwith forms.8 None of this is binding, and therefore, while it may be impolite,\nit is not a mistake for web applications to employ arbitrary formats for what-\never data they wish to put in that part of the URL.\nFragment ID\nThe fragment ID is an opaque value with a role similar to the query string\nbutthat provides optional instructions for the client application rather than\nthe server. (In fact, the value is not supposed to be sent to the server at all.)\nNeither the format nor function of the fragment ID is clearly specified in\ntheRFCs, but it is hinted that it may be used to address “subresources” in the\nretrieved document or to provide other document-specific rendering cues.\nIn practice, fragment identifiers have only a single sanctioned use in\nthebrowser: that of specifying the name of an anchor HTML element for\nin-document navigation. The logic is simple. If an anchor name is supplied in\nthe URL and a matching HTML tag can be located, the document will be\nscrolled to that location for viewing; otherwise, nothing happens. Because\nthe information is encoded in the URL, this particular view of a lengthy doc-\nument could be easily shared with others or bookmarked. In this use, the\nmeaning of a fragment ID is limited to scrolling an existing document, so\nthere is no need to retrieve any new data from the server when only this por-\ntion of the URL is updated in response to user actions.\n28 Chapter 2"
  },
  {
    "input": "Putting It All Together Again",
    "output": "This interesting property has led to another, more recent and completely\nad hoc use of this value: to store miscellaneous state information needed by\nclient-side scripts. For example, consider a map-browsing application that\nputs the currently viewed map coordinates in the fragment identifier so that\nit will know to resume from that same location if the link is bookmarked or\nshared. Unlike updating the query string, changing the fragment ID on-the-\nfly will not trigger a time-consuming page reload, making this data-storage\ntrick a killer feature.\nPutting It All Together Again\nEach of the aforementioned URL segments is delimited by certain reserved\ncharacters: slashes, colons, question marks, and so on. To make the whole\napproach usable, these delimiting characters should not appear anywhere\ninthe URL for any other purpose. With this assumption in mind, imagine a\nsample algorithm to split absolute URLs into the aforementioned functional\nparts in a manner at least vaguely consistent with how browsers accomplish\nthis task. A reasonably decent example of such an algorithm could be:\nSTEP 1: Extract the scheme name.\nScan for the first “:” character. The part of the URL to its left is the\nscheme name. Bail out if the scheme name does not conform to the\nexpected set of characters; the URL may need to be treated as a relative\none if so.\nSTEP 2: Consume the hierarchical URL identifier.\nThe string “//” should follow the scheme name. Skip it if found; bail out\nif not.\nNOTE In some parsing contexts, implementations will be just as happy with zero, one, or even\nthree or more slashes instead of two, for usability reasons. In the same vein, from its\ninception, Internet Explorer accepted backslashes (\\) in lieu of slashes in any location\nin the URL, presumably to assist inexperienced users.* All browsers other than Firefox\neventually followed this trend and recognize URLs such as http:\\\\example.com\\.\nSTEP 3: Grab the authority section.\nScan for the next “/”, “?”, or “#”, whichever comes first, to extract the\nauthority section from the URL. As mentioned above, most browsers will\nalso accept “\\” as a delimiter in place of a forward slash, which may need\nto be accounted for. The semicolon (;) is another acceptable authority\ndelimiter in browsers other than Internet Explorer and Safari; the rea-\nson for this decision is unknown.\n* Unlike UNIX-derived operating systems, Microsoft Windows uses backslashes instead of slashes\ntodelimit file paths (say, c:\\windows\\system32\\calc.exe). Microsoft probably tried to compensate for\nthe possibility that users would be confused by the need to type a different type of a slash on the\nWeb or hoped to resolve other possible inconsistencies with file: URLs and similar mechanisms\nthat would be interfacing directly with the local filesystem. Other Windows filesystem specifics\n(such as case insensitivity) are not replicated, however.\nIt Starts with a URL 29\nSTEP 3A: Find the credentials, if any.\nOnce the authority section is extracted, locate the at symbol (@) in the\nsubstring. If found, the leading snippet constitutes login credentials,\nwhich should be further tokenized at the first occurrence of a colon (if\npresent) to split the login and password data.\nSTEP 3B: Extract the destination address.\nThe remainder of the authority section is the destination address. Look\nfor the first colon to separate the hostname from the port number. A\nspecial case is needed for bracket-enclosed IPv6 addresses, too.\nSTEP 4: Identify the path (if present).\nIf the authority section is followed immediately by a forward slash—or\nfor some implementations, a backslash or semicolon, as noted earlier—\nscan for the next “?”, “#”, or end-of-string, whichever comes first. The\ntext in between constitutes the path section, which should be normalized\naccording to Unix path semantics.\nSTEP 5: Extract the query string (if present).\nIf the last successfully parsed segment is followed by a question mark,\nscan for the next “#” character or end-of-string, whichever comes first.\nThe text in between is the query string.\nSTEP 6: Extract the fragment identifier (if present).\nIf the last successfully parsed segment is followed by “#”, everything from\nthat character to the end-of-string is the fragment identifier. Either way,\nyou’re done!\nThis algorithm may seem mundane, but it reveals subtle details that even\nseasoned programmers normally don’t think about. It also illustrates that it is\nextremely difficult for casual users to understand how a particular URL may\nbe parsed. Let's start with this fairly simple case:\nhttp://example.com&gibberish=1234@167772161/\nThe target of this URL—a concatenated IP address that decodes to\n10.0.0.1—is not readily apparent to a nonexpert, and many users would\nbelieve they are visiting example.com instead.* But all right, that was an easy\none! So let’s have a peek at this syntax instead:\nhttp://example.com\\@coredump.cx/\nIn Firefox, that URL will take the user to coredump.cx, because example.com\\\nwill be interpreted as a valid value for the login field. In almost all other brows-\ners, “\\” will be interpreted as a path delimiter, and the user will land on example\n.com instead.\n* This particular @-based trick was quickly embraced to facilitate all sorts of online fraud\ntargeted at casual users. Attempts to mitigate its impact ranged from the heavy-handed and\noddly specific (e.g., disabling URL-based authentication in Internet Explorer or crippling it\nwithwarnings in Firefox) to the fairly sensible (e.g., hostname highlighting in the address bar\nofseveral browsers).\n30 Chapter 2"
  },
  {
    "input": "Reserved Characters and Percent Encoding",
    "output": "An even more frustrating example exists for Internet Explorer.\nConsiderthis:\nhttp://example.com;.coredump.cx/\nMicrosoft’s browser permits “;” in the hostname and successfully\nresolvesthis label, thanks to the appropriate configuration of the coredump.cx\ndomain. Most other browsers will autocorrect the URL to http://example.com/\n;.coredump.cx and take the user to example.com instead (except for Safari, where\nthe syntax causes an error). If this looks messy, remember that we are just\ngetting started with how browsers work!\nReserved Characters and Percent Encoding\nThe URL-parsing algorithm outlined in the previous section relies on the\nassumption that certain reserved, syntax-delimiting characters will not appear\nliterally in the URL in any other capacity (that is, they won’t be a part of the user-\nname, request path, and so on). These generic, syntax-disrupting delimiters are:\n: / ? # [ ] @\nThe RFC also names a couple of lower-tier delimiters without giving\nthem any specific purpose, presumably to allow scheme- or application-\nspecific features to be implemented within any of the top-level sections:\n! $ & ' ( ) * + , ; =\nAll of the above characters are in principle off-limits, but there are legiti-\nmate cases where one would want to include them in the URL (for example,\nto accommodate arbitrary search terms entered by the user and passed to the\nserver in the query string). Therefore, rather than ban them, the standard\nprovides a method to encode all spurious occurrences of these values. The\nmethod, simply called percent encoding or URL encoding, substitutes characters\nwith a percent sign (%) followed by two hexadecimal digits representing a\nmatching ASCII value. For example, “/” will be encoded as %2F (uppercase\nis customary but not enforced). It follows that to avoid ambiguity, the naked\npercent sign itself must be encoded as %25. Any intermediaries that handle\nexisting URLs (browsers and web applications included) are further com-\npelled never to attempt to decode or encode reserved characters in relayed\nURLs, because the meaning of such a URL may suddenly change.\nRegrettably, the immutability of reserved characters in existing URLs\nisat odds with the need to respond to any URLs that are technically illegal\nbecause they misuse these characters and that are encountered by the browser\nin the wild. This topic is not covered by the specifications at all, which forces\nbrowser vendors to improvise and causes cross-implementation inconsisten-\ncies. For example, should the URL http://a@b@c/ be translated to http://\na@b%40c/ or perhaps to http://a%40b@c/? Internet Explorer and Safari think\nthe former makes more sense; other browsers side with the latter view.\nIt Starts with a URL 31"
  },
  {
    "input": "Handling of Non-US-ASCII Text",
    "output": "The remaining characters not in the reserved set are not supposed to\nhave any particular significance within the URL syntax itself. However, some\n(such as nonprintable ASCII control characters) are clearly incompatible\nwith the idea that URLs should be human readable and transport-safe. There-\nfore, the RFC outlines a confusingly named subset of unreserved characters\n(consisting of alphanumerics, “-”, “.”, “_”, and “~”) and says that only this\nsubset and the reserved characters in their intended capacity are formally\nallowed to appear in the URL as is.\nNOTE Curiously, these unreserved characters are only allowed to appear in an unescaped\nform; they are not required to do so. User agents may encode or decode them at whim,\nand doing so does not change the meaning of the URL at all. This property brings up\nyet another way to confuse users: the use of noncanonical representations of unreserved\ncharacters. Specifically, all of the following are equivalent:\n http://example.com/\n http://%65xample.%63om/\n\nhttp://%65%78%61%6d%70%6c%65%2e%63%6f%6d/*\nA number of otherwise nonreserved, printable characters are excluded\nfrom the so-called unreserved set. Because of this, strictly speaking, the RFCs\nrequire them to be unconditionally percent encoded. However, since brows-\ners are not explicitly tasked with the enforcement of this rule, it is not taken\nvery seriously. In particular, all browsers allow “^”, “{”, “|”, and “}” to appear\nin URLs without escaping and will send these characters to the server as is.\nInternet Explorer further permits “<”, “>”, and “`” to go through; Internet\nExplorer, Firefox, and Chrome all accept “\\”; Chrome and Internet Explorer\nwill permit a double quote; and Opera and Internet Explorer both pass the\nnonprintable character 0x7F (DEL) as is.\nLastly, contrary to the requirements spelled out in the RFC, most brows-\ners also do not encode fragment identifiers at all. This poses an unexpected\nchallenge to client-side scripts that rely on this string and expect certain\npotentially unsafe characters never to appear literally. We will revisit this\ntopic inChapter 6.\nHandling of Non-US-ASCII Text\nMany languages used around the globe rely on characters outside the basic,\n7-bit ASCII character set or the default 8-bit code page traditionally used by\nall PC-compatible systems (CP437). Heck, some languages depend on alpha-\nbets that are not based on Latin at all.\nIn order to accommodate the needs of an often-ignored but formidable\nnon-English user base, various 8-bit code pages with an alternative set of high-\nbit characters were devised long before the emergence of the Web: ISO8859-1,\n* Similar noncanonical encodings were widely used for various types of social engineering attacks,\nand consequently, various countermeasures have been deployed through the years. As usual,\nsome of these countermeasures are disruptive (for example, Firefox flat out rejects percent-\nencoded text in hostnames), and some are fairly good (such as the forced “canonicalization”\nofthe address bar by decoding all the unnecessarily encoded text for display purposes).\n32 Chapter 2\nCP850, and Windows 1252 for Western European languages; ISO 8859-2,\nCP852, and Windows 1250 for Eastern and Central Europe; and KOI8-R and\nWindows 1251 for Russia. And, because several alphabets could not be accom-\nmodated in the 256-character space, we saw the rise of complex variable-\nwidth encodings, such as Shift JIS for katakana.\nThe incompatibility of these character maps made it difficult to exchange\ndocuments between computers configured for different code pages. By the\nearly 1990s, this growing problem led to the creation of Unicode—a sort of\nuniversal character set, too large to fit within 8 bits but meant to encompass\npractically all regional scripts and specialty pictographs known to man. Uni-\ncode was followed by UTF-8, a relatively simple, variable-width representation\nof these characters, which was theoretically safe for all applications capable of\nhandling traditional 8-bit formats. Unfortunately, UTF-8 required more bytes\nto encode high-bit characters than did most of its competitors, and to many\nusers, this seemed wasteful and unnecessary. Because of this criticism, it took\nwell over a decade for UTF-8 to gain traction on the Web, and it only did so\nlong after all the relevant protocols had solidified.\nThis unfortunate delay had some bearing on the handling of URLs that\ncontain user input. Browsers needed to accommodate such use very early\non,but when the developers turned to the relevant standards, they found no\nmeaningful advice. Even years later, in 2005, the RFC 3986 had just this to say:\nIn local or regional contexts and with improving technology, users\nmight benefit from being able to use a wider range of characters;\nsuch use is not defined by this specification.\nPercent-encoded octets . . . may be used within a URI to represent\ncharacters outside the range of the US-ASCII coded character set if\nthis representation is allowed by the scheme or by the protocol\nelement in which the URI is referenced. Such a definition should\nspecify the character encoding used to map those characters to\noctets prior to being percent-encoded for the URI.\nAlas, despite this wishful thinking, none of the remaining standards\naddressed this topic. It was always possible to put raw high-bit characters in a\nURL, but without knowing the code page they should be interpreted in, the\nserver would not be able to tell if that %B1 was supposed to mean “±”, “a”, or\nsome other squiggly character specific to the user’s native script.\nSadly, browser vendors have not taken the initiative and come up with a\nconsistent solution to this problem. Most browsers internally transcode URL\npath segments to UTF-8 (or ISO 8859-1, if sufficient), but then they generate\nthe query string in the code page of the referring page instead. In certain\ncases, when URLs are entered manually or passed to certain specialized APIs,\nhigh-bit characters may be also downgraded to their 7-bit US-ASCII look-\nalikes, replaced with question marks, or even completely mangled due to\nimplementation flaws.\nIt Starts with a URL 33\nPoorly implemented or not, the ability to pass non-English characters\ninquery strings and paths scratched an evident itch. The traditional percent-\nencoding approach left just one URL segment completely out in the cold:\nHigh-bit input could not be allowed as is when specifying the name of the\ndestination server, because at least in principle, the well-established DNS\nstandard permitted only period-delimited alphanumerics and dashes to\nappear in domain names—and while nobody adhered to the rules, the set\nofexceptions varied from one name server to another.\nAn astute reader might wonder why this limitation would matter; that is,\nwhy was it important to have localized domain names in non-Latin alphabets,\ntoo? That question may be difficult to answer now. Quite simply, several folks\nthought a lack of these encodings would prevent businesses and individuals\naround the world from fully embracing and enjoying the Web—and, rightly\nor not, they were determined to make it happen.\nThis pursuit led to the formation of the Internationalized Domain Names\nin Applications (IDNA). First, RFC 3490,9 which outlined a rather contrived\nscheme to encode arbitrary Unicode strings using alphanumerics and dashes,\nand then RFC 3492,10 which described a way to apply this encoding to DNS\nlabels using a format known as Punycode. Punycode looked roughly like this:\nxn--[US-ASCII part]-[encoded Unicode data]\nA compliant browser presented with a technically illegal URL that con-\ntained a literal non-US-ASCII character anywhere in the hostname was sup-\nposed to transform the name to Punycode before performing a DNS lookup.\nConsequently, when presented with Punycode in an existing URL, it should\nput a decoded, human-readable form of the string in the address bar.\nNOTE Combining all these incompatible encoding strategies can make for an amusing mix.\nConsider this example URL of a made-up Polish-language towel shop:\nIntent: http://www.ręczniki.pl/ręcznik?model=Jaś#Złóż_zamówienie\nActual URL: http://www.xn--rczniki-98a.pl/r%C4%99cznik?model=Ja%B6#Złóż_zamówienie\nLabel converted Path converted Query string Literal UTF-8\nto Punycode to UTF-8 converted to\nISO 8859-2\nOf all the URL-based encoding approaches, IDNA soon proved to be the\nmost problematic. In essence, the domain name in the URL shown in the\nbrowser’s address bar is one of the most important security indicators on the\nWeb, as it allows users to quickly differentiate sites they trust and have done\nbusiness with from the rest of the Internet. When the hostname shown by the\nbrowser consists of 38 familiar and distinctive characters, only fairly careless\nvictims will be tricked into thinking that their favorite example.com domain\nand an impostor examp1e.com site are the same thing. But IDNA casually and\nindiscriminately extended these 38 characters to some 100,000 glyphs sup-\nported by Unicode, many of which look exactly alike and are separated from\neach other based on functional differences alone.\n34 Chapter 2\nHow bad is it? Let’s consider Cyrillic, for example. This alphabet has a\nnumber of homoglyphs that look practically identical to their Latin counter-\nparts but that have completely different Unicode values and resolve to com-\npletely different Punycode DNS names:\nLatin a c e i j o p s x y\nU+0061 U+0063 U+0065 U+0069 U+006A U+006F U+0070 U+0073 U+0078 U+0079\nCyrillic a c e i j o p s x y\nU+0430 U+0441 U+0435 U+0456 U+0458 U+043E U+0440 U+0455 U+0445 U+0443\nWhen IDNA was proposed and first implemented in browsers, nobody\nseriously considered the consequences of this issue. Browser vendors appar-\nently assumed that DNS registrars would prevent people from registering\nlook-alike names, and registrars figured it was the browser vendors’ problem\nto have unambiguous visuals in the address bar.\nIn 2002 the significance of the problem was finally recognized by all\nparties involved. That year, Evgeniy Gabrilovich and Alex Gontmakher pub-\nlished “The Homograph Attack,”11 a paper exploring the vulnerability in\ngreat detail. They noted that any registrar-level work-arounds, even if imple-\nmented, would have a fatal flaw. An attacker could always purchase a whole-\nsome top-level domain and then, on his own name server, set up a subdomain\nrecord that, with the IDNA transformation applied, would decode to a string\nvisually identical to example.com/ (the last character being merely a nonfunc-\ntional look-alike of the actual ASCII slash). The result would be:\nhttp://example.com/.wholesome-domain.com/\nThis only looks like a real slash.\nThere is nothing that a registrar can do to prevent this attack, and the\nball is in the browser vendors’ court. But what options do they have, exactly?\nAs it turns out, there aren’t many. We now realize that the poorly envi-\nsioned IDNA standard cannot be fixed in a simple and painless way. Browser\ndevelopers have responded to this risk by reverting to incomprehensible\nPunycode when a user’s locale does not match the script seen in a particular\nDNS label (which causes problems when browsing foreign sites or when using\nimported or simply misconfigured computers); permitting IDNA only in cer-\ntain country-specific, top-level domains (ruling out the use of international-\nized domain names in .com and other high-profile TLDs); and blacklisting\ncertain “bad” characters that resemble slashes, periods, white spaces, and\nsoforth (a fool’s errand, given the number of typefaces used around the\nworld).\nThese measures are drastic enough to severely hinder the adoption of\ninternationalized domain names, probably to a point where the standard’s\nlingering presence causes more security problems than it brings real usability\nbenefits to non-English users.\nIt Starts with a URL 35"
  },
  {
    "input": "Protocols Claimed by Third-Party Applications and Plug-ins",
    "output": "Common URL Schemes and Their Function\nLet’s leave the bizarre world of URL parsing behind us and go back to the\nbasics. Earlier in this chapter, we implied that certain schemes may have\nunexpected security consequences and that because of this, any web applica-\ntion handling user-supplied URLs must be cautious. To explain this point a\nbit better, it is useful to review all the URL schemes commonly supported in\na typical browser environment. These can be combined into four basic groups.\nBrowser-Supported, Document-Fetching Protocols\nThese schemes, handled internally by the browser, offer a way to retrieve\narbitrary content using a particular transport protocol and then display it\nusing common, browser-level rendering logic. This is the most rudimentary\nand the most expected function of a URL.\nThe list of commonly supported schemes in this category is surprisingly\nshort: http: (RFC 2616), the primary transport mode used on the Web and\nthe focus of the next chapter of this book; https:, an encrypted version of HTTP\n(RFC 281812); and ftp:, an older file transfer protocol (RFC 95913). All brows-\ners also support file: (previously also known as local:), a system-specific method\nfor accessing the local filesystem or NFS and SMB shares. (This last scheme is\nusually not directly accessible through Internet-originating pages, though.)\nTwo additional, obscure cases also deserve a brief mention: built-in\nsupport for the gopher: scheme, one of the failed predecessors of the Web\n(RFC 143614), which is still present in Firefox, and shttp:, an alternative,\nfailed take on HTTPS (RFC 266015), still recognized in Internet Explorer\n(but today, simply aliased to HTTP).\nProtocols Claimed by Third-Party Applications and Plug-ins\nFor these schemes, matching URLs are simply dispatched to external, spe-\ncialized applications that implement functionality such as media playback,\ndocument viewing, or IP telephony. At this point, the involvement of the\nbrowser (mostly) ends.\nScores of external protocol handlers exist today, and it would take another\nthick book to cover them all. Some of the most common examples include\nthe acrobat: scheme, predictably routed to Adobe Acrobat Reader; callto: and\nsip: schemes claimed by all sorts of instant messengers and telephony soft-\nware; daap:, itpc:, and itms: schemes used by Apple iTunes; mailto:, news:, and\nnntp: protocols claimed by mail and Usenet clients; mmst:, mmsu:, msbd:, and\nrtsp: protocols for streaming media players; and so on. Browsers are some-\ntimes also included on the list. The previously mentioned firefoxurl: scheme\nlaunches Firefox from within another browser, while cf: gives access to Chrome\nfrom Internet Explorer.\nFor the most part, when these schemes appear in URLs, they usually\nhave no impact on the security of the web applications that allow them to\ngothrough (although this is not guaranteed, especially in the case of plug-\nin–supported content). It is worth noting that third-party protocol handlers\ntend to be notoriously buggy and are sometimes abused to compromise the\n36 Chapter 2"
  },
  {
    "input": "Encapsulating Pseudo-Protocols",
    "output": "operating system. Therefore, restricting the ability to navigate to mystery pro-\ntocols is a common courtesy to the user of any reasonably trustworthy website.\nNonencapsulating Pseudo-Protocols\nAn array of protocols is reserved to provide convenient access to the\nbrowser’s scripting engine and other internal functions, without actually\nretrieving any remote content and perhaps without establishing an isolated\ndocument context to display the result. Many of these pseudo-protocols are\nhighly browser-specific and are either not directly accessible from the Inter-\nnet or are incapable of doing harm. However, there are several important\nexceptions to this rule.\nPerhaps the best-known exception is the javascript: scheme (in earlier\nyears, also available under aliases such as livescript: or mocha: in Netscape brows-\ners). This scheme gives access to the JavaScript-programming engine in the\ncontext of the currently viewed website. In Internet Explorer, vbscript: offers\nsimilar capabilities through the proprietary Visual Basic interface.\nAnother important case is the data: protocol (RFC 239716), which\npermits short, inline documents to be created without any extra network\nrequests and sometimes inherits much of their operating context from the\nreferring page. An example of a data: URL is:\ndata:text/plain,Why,%20hello%20there!\nThese externally accessible pseudo-URLs are of acute significance to site\nsecurity. When navigated to, their payload may execute in the context of the\noriginating domain, possibly stealing sensitive data or altering the appear-\nance of the page for the affected user. We’ll discuss the specific capabilities\nof browser scripting languages in Chapter 6, but as you might expect, they\nare substantial. (URL context inheritance rules, on the other hand, are the\nfocus of Chapter 10.)\nEncapsulating Pseudo-Protocols\nThis special class of pseudo-protocols may be used to prefix any other URL\nin order to force a special decoding or rendering mode for the retrieved\nresource. Perhaps the best-known example is the view-source: scheme sup-\nported by Firefox and Chrome, used to display the pretty-printed source of\nan HTML page. This scheme is used in the following way:\nview-source:http://www.example.com/\nOther protocols that function similarly include jar:, which allows content\nto be extracted from ZIP files on the fly in Firefox; wyciwyg: and view-cache:,\nwhich give access to cached pages in Firefox and Chrome respectively; an\noddball feed: scheme, which is meant to access news feeds in Safari;17 and a\nhost of poorly documented protocols associated with the Windows help sub-\nsystem and other components of Microsoft Windows (hcp:, its:, mhtml:, mk:,\nms-help:, ms-its:, and ms-itss:).\nIt Starts with a URL 37"
  },
  {
    "input": "Resolution of Relative URLs",
    "output": "The common property of many encapsulating protocols is that they allow\nthe attacker to hide the actual URL that will be ultimately interpreted by the\nbrowser from naïve filters: view-source:javascript: (or even view-source:view-\nsource:javascript:) followed by malicious code is a simple way to accomplish\nthis. Some security restrictions may be present to limit such trickery, but they\nshould not be relied upon. Another significant problem, recurring especially\nwith Microsoft’s mhtml:, is that using the protocol may ignore some of the\ncontent directives provided by the server on HTTP level, possibly leading\ntowidespread misery.18\nClosing Note on Scheme Detection\nThe sheer number of pseudo-protocols is the primary reason why web appli-\ncations need to carefully screen user-supplied URLs. The wonky and browser-\nspecific URL-parsing patterns, coupled with the open-ended nature of the\nlist of supported schemes, means that it is unsafe to simply blacklist known\nbad schemes; for example, a check for javascript: may be circumvented if this\nkeyword is spliced with a tab or a newline, replaced with vbscript:, or prefixed\nwith another encapsulating scheme.\nResolution of Relative URLs\nRelative URLs have been mentioned on several occasions earlier in the chap-\nter, and they deserve some additional attention at this point, too. The reason\nfor their existence is that on almost every web page on the Internet, a consid-\nerable number of URLs will reference resources hosted on that same server,\nperhaps in the same directory. It would be inconvenient and wasteful to require\na fully qualified URL to appear in the document every time such a reference\nis needed, so short, relative URLs (such as ../other_file.txt) are used instead.\nThe missing details are inferred from the URL of the referring document.\nBecause relative URLs are allowed to appear in exactly the same scenar-\nios in which any absolute URL may appear, a method to distinguish between\nthe two is necessary within the browser. Web applications also benefit from the\nability to make the distinction, because most types of URL filters may want to\nscrutinize absolute URLs only and allow local references through as is.\nThe specification may make this task seem very simple: If the URL string\ndoes not begin with a valid scheme name followed by a semicolon and, pref-\nerably, a valid “//” sequence, it should be interpreted as a relative reference.\nAnd if no context for parsing such a relative URL exists, it should be rejected.\nEverything else is a safe relative link, right?\nPredictably, it’s not as easy as it seems. First, as outlined in previous sec-\ntions, the accepted set of characters in a valid scheme name, and the patterns\naccepted in lieu of “//”, vary from one implementation to another. Perhaps\nmore interestingly, it is a common misconception that relative links can\npoint only to resources on the same server; quite a few other, less-obvious\nvariants of relative URLs exist.\n38 Chapter 2\nLet’s have a quick peek at the known classes of relative URLs to better\nillustrate this possibility.\nScheme, but no authority present (http:foo.txt)\nThis infamous loophole is hinted at in RFC 3986 and attributed to an\noversight in one of the earlier specs. While said specs descriptively clas-\nsified such URLs as (invalid) absolute references, they also provided a\npromiscuous reference-parsing algorithm keen on interpreting them\nincorrectly.\nIn the latter interpretation, these URLs would set a new protocol\nand path, query, or fragment ID but have the authority section copied\nover from the referring location. This syntax is accepted by several\nbrowsers, but inconsistently. For example, in some cases, http:foo.txt\nmaybe treated as a relative reference, while https:example.com may be\nparsed as an absolute one!\nNo scheme, but authority present (//example.com)\nThis is another notoriously confusing but at least well-documented quirk.\nWhile /example.com is areference to a local resource on the current server,\nthe standard compels browsers to treat //example.com as a very different\ncase: a reference toa different authority over the current protocol. In\nthis scenario, the scheme will be copied over from the referring location,\nand all other URL details will be derived from the relative URL.\nNo scheme, no authority, but path present (../notes.txt)\nThis is the most common variant of a relative link. Protocol and author-\nity information is copied over from the referring URL. If the relative\nURL does not start with a slash, the path will also be copied over up to\nthe rightmost “/”. For example, if the base URL is http://www.example\n.com/files/, the path isthe same, but in http://www.example.com/files/index\n.html, the filename is truncated. The new path is then appended, and\nstandard path normalization follows on the concatenated value. The\nquery string and fragment ID are derived only from the relative URL.\nNo scheme, no authority, no path, but query string present (?search=bunnies)\nIn this scenario, protocol, authority, and path information are copied\nverbatim from the referring URL. The query string and fragment ID\narederived from the relative URL.\nOnly fragment ID present (#bunnies)\nAll information except for the fragment ID is copied verbatim from the\nreferring URL; only the fragment ID is substituted. Following this type of\nrelative URL does not cause the page to be reloaded under normal cir-\ncumstances, as noted earlier.\nBecause of the risk of potential misunderstandings between application-\nlevel URL filters and the browser when handling these types of relative refer-\nences, it is a good design practice never to output user-supplied relative URLs\nverbatim. Where feasible, they should be explicitly rewritten to absolute ref-\nerences, and all security checks should be carried out against the resulting\nfully qualified address instead.\nIt Starts with a URL 39"
  },
  {
    "input": "When Decoding Parameters Received Through URLs",
    "output": "Security Engineering Cheat Sheet\nWhen Constructing Brand-New URLs Based on User Input\n If you allow user-supplied data in path, query, or fragment ID: If one of the section\ndelimiters manages to get through without proper escaping, the URL may have a differ-\nent effect from what you intended (for example, linking one of the user-visible HTML\nbuttons to the wrong server-side action). It is okay to err on the side of caution: When\ninserting an attacker-controlled field value, you can simply percent-escape everything\nbutalphanumerics.\n If you allow user-supplied scheme name or authority section: This is a major code injec-\ntion and phishing risk! Apply the relevant input-validation rules outlined below.\nWhen Designing URL Input Filters\n Relative URLs: Disallow or explicitly rewrite them to absolute references to avoid trouble.\nAnything else is very likely unsafe.\n Scheme name: Permit only known prefixes, such as http://, https://, or ftp://. Do not use\nblacklisting instead; it is extremely unsafe.\n Authority section: Hostname should contain only alphanumerics, “-”, and “.” and can only\nbe followed by “/”, “?”, “#”, or end-of-string. Allowing anything else will backfire. If you\nneed to examine the hostname, make sure to make a proper right-hand substring match.\nIn rare cases, you might need to account for IDNA, IPv6 bracket notation, port num-\nbers, or HTTP credentials in the URL. If so, you must fully parse the URL, validate all sec-\ntions and reject anomalous values, and reserialize them into a nonambiguous, canonical,\nwell-escaped representation.\nWhen Decoding Parameters Received Through URLs\n Do not assume that any particular character will be escaped just because the standard says\nso or because your browser does it. Before echoing back any URL-derived values or put-\nting them inside database queries, new URLs, and so on, scrub them carefully for danger-\nous characters.\n40 Chapter 2"
  },
  {
    "input": "3: Hypertext Transfer Protocol\r",
    "output": "H Y P E R T E X T T R A N S F E R\nP R O T O C O L\nThe next essential concept we need to discuss is the\nHypertext Transfer Protocol (HTTP): the core trans-\nfer mechanism of the Web and the preferred method\nfor exchanging URL-referenced documents between\nservers and clients. Despite having hypertext in its\nname, HTTP and the actual hypertext content (the\nHTML language) often exist independent of each\nother. That said, they are intertwined in sometimes\nsurprising ways.\nThe history of HTTP offers interesting insight into its authors’ ambitions\nand the growing relevance of the Internet. Tim Berners-Lee’s earliest 1991\ndraft of the protocol (HTTP/0.91) was barely one and a half pages long, and\nit failed to account for even the most intuitive future needs, such as extensi-\nbility needed to transmit non-HTML data."
  },
  {
    "input": "Basic Syntax of HTTP Traffic",
    "output": "Five years and several iterations of the specification later, the first\nofficialHTTP/1.0 standard (RFC 19452) tried to rectify many of these short-\ncomings in about 50 densely packed pages of text. Fast-forward to 1999, and\nin HTTP/1.1 (RFC 26163), the seven credited authors attempted to antici-\npate almost every possible use of the protocol, creating an opus over 150\npages long. That’s not all: As of this writing, the current work on HTTPbis,4\nessentially a replacement for the HTTP/1.1 specification, comes to 360 pages\nor so. While much of the gradually accumulated content is irrelevant to the\nmodern Web, this progression makes it clear that the desire to tack on new\nfeatures far outweighs the desire to prune failed ones.\nToday, all clients and servers support a not-entirely-accurate superset of\nHTTP/1.0, and most can speak a reasonably complete dialect of HTTP/1.1,\nwith a couple of extensions bolted on. Despite the fact that there is no practi-\ncal need to do so, several web servers, and all common browsers, also main-\ntain backward compatibility with HTTP/0.9.\nBasic Syntax of HTTP Traffic\nAt a glance, HTTP is a fairly simple, text-based protocol built on top of\nTCP/IP.* Every HTTP session is initiated by establishing a TCP connection\nto the server, typically to port 80, and then issuing a request that outlines the\nrequested URL. In response, the server returns the requested file and, in the\nmost rudimentary use case, tears down the TCP connection immediately\nthereafter.\nThe original HTTP/0.9 protocol provided no room for any additional\nmetadata to be exchanged between the participating parties. The client\nrequest always consisted of a single line, starting with GET, followed by the\nURL path and query string, and ending with a single CRLF newline (ASCII\ncharacters 0x0D 0x0A; servers were also advised to accept a lone LF). A\nsample HTTP/0.9 request might have looked like this:\nGET /fuzzy_bunnies.txt\nIn response to this message, the server would have immediately returned\nthe appropriate HTML payload. (The specification required servers to wrap\nlines of the returned document at 80 characters, but this advice wasn’t really\nfollowed.)\nThe HTTP/0.9 approach has a number of substantial deficiencies. For\nexample, it offers no way for browsers to communicate users’ language pref-\nerences, supply a list of supported document types, and so on. It also gives\nservers no way to tell a client that the requested file could not be found, that\nit has moved to a different location, or that the returned file is not an HTML\n* Transmission Control Protocol (TCP) is one of the core communications protocols of the Internet,\nproviding the transport layer to any application protocols built on top of it. TCP offers reason-\nably reliable, peer-acknowledged, ordered, session-based connectivity between networked hosts.\nIn most cases, the protocol is also fairly resilient against blind packet spoofing attacks attempted\nby other, nonlocal hosts on the Internet.\n42 Chapter 3\ndocument to begin with. Finally, the scheme is not kind to server admin-\nistrators: When the transmitted URL information is limited to only the path\nand query strings, it is impossible for a server to host multiple websites,\ndistinguished by their hostnames, under one IP address—and unlike DNS\nrecords, IP addresses don’t come cheap.\nIn order to fix these shortcomings (and to make room for future\ntweaks), HTTP/1.0 and HTTP/1.1 standards embrace a slightly different\nconversation format: The first line of a request is modified to include proto-\ncol version information, and it is followed by zero or more name: value pairs\n(also known as headers), each occupying a separate line. Common request\nheaders included in such requests are User-Agent (browser version informa-\ntion), Host (URL hostname), Accept (supported MIME document types*),\nAccept-Language (supported language codes), and Referer (a misspelled field\nindicating the originating page for the request, if known).\nThese headers are terminated with a single empty line, which may be\nfollowed by any payload the client wishes to pass to the server (the length of\nwhich must be explicitly specified with an additional Content-Length header).\nThe contents of the payload are opaque from the perspective of the protocol\nitself; in HTML, this location is commonly used for submitting form data in\none of several possible formats, though this is in no way a requirement.\nOverall, a simple HTTP/1.1 request may look like this:\nPOST /fuzzy_bunnies/bunny_dispenser.php HTTP/1.1\nHost: www.fuzzybunnies.com\nUser-Agent: Bunny-Browser/1.7\nContent-Type: text/plain\nContent-Length: 17\nReferer: http://www.fuzzybunnies.com/main.html\nI REQUEST A BUNNY\nThe server is expected to respond to this query by opening with a line\nthat specifies the supported protocol version, a numerical status code (used\nto indicate error conditions and other special circumstances), and an optional,\nhuman-readable status message. A set of self-explanatory headers comes next,\nending with an empty line. The response continues with the contents of the\nrequested resource:\nHTTP/1.1 200 OK\nServer: Bunny-Server/0.9.2\nContent-Type: text/plain\nConnection: close\nBUNNY WISH HAS BEEN GRANTED\n* MIME type (aka Internet media type) is a simple, two-component value identifying the class and\nformat of any given computer file. The concept originated in RFC 2045 and RFC 2046, where it\nserved as a way to describe email attachments. The registry of official values (such as text/plain or\naudio/mpeg) is currently maintained by IANA, but ad hoc types are fairly common.\nHypertext Transfer Protocol 43"
  },
  {
    "input": "The Consequences of Supporting HTTP/0.9",
    "output": "RFC 2616 also permits the response to be compressed in transit using\none of three supported methods (gzip, compress, deflate), unless the client\nexplicitly opts out by providing a suitable Accept-Encoding header.\nThe Consequences of Supporting HTTP/0.9\nDespite the improvements made in HTTP/1.0 and HTTP/1.1, the unwelcome\nlegacy of the “dumb” HTTP/0.9 protocol lives on, even if it is normally hid-\nden from view. The specification for HTTP/1.0 is partly to blame for this,\nbecause it requested that all future HTTP clients and servers support the\noriginal, half-baked draft. Specifically, section 3.1 says:\nHTTP/1.0 clients must . . . understand any valid response in the\nformat of HTTP/0.9 or HTTP/1.0.\nIn later years, RFC 2616 attempted to backtrack on this requirement\n(section 19.6: “It is beyond the scope of a protocol specification to mandate\ncompliance with previous versions.”), but acting on the earlier advice, all\nmodern browsers continue to support the legacy protocol as well.\nTo understand why this pattern is dangerous, recall that HTTP/0.9 serv-\ners reply with nothing but the requested file. There is no indication that the\nresponding party actually understands HTTP and wishes to serve an HTML\ndocument. With this in mind, let’s analyze what happens if the browser sends\nan HTTP/1.1 request to an unsuspecting SMTP service running on port 25\nof example.com:\nGET /<html><body><h1>Hi! HTTP/1.1\nHost: example.com:25\n...\nBecause the SMTP server doesn’t understand what is going on, it’s likely\nto respond this way:\n220 example.com ESMTP\n500 5.5.1 Invalid command: \"GET /<html><body><h1>Hi! HTTP/1.1\"\n500 5.1.1 Invalid command: \"Host: example.com:25\"\n...\n421 4.4.1 Timeout\nAll browsers willing to follow the RFC are compelled to accept these\nmessages as the body of a valid HTTP/0.9 response and assume that the\nreturned document is, indeed, HTML. These browsers will interpret the\nquoted attacker-controlled snippet appearing in one of the error messages\nasif it comes from the owners of a legitimate website at example.com. This\nprofoundly interferes with the browser security model discussed in Part II\nofthis book and, therefore, is pretty bad.\n44 Chapter 3"
  },
  {
    "input": "Newline Handling Quirks",
    "output": "Newline Handling Quirks\nSetting aside the radical changes between HTTP/0.9 and HTTP/1.0, several\nother core syntax tweaks were made later in the game. Perhaps most notably,\ncontrary to the letter of earlier iterations, HTTP/1.1 asks clients not only to\nhonor newlines in the CRLF and LF format but also to recognize a lone CR\ncharacter. Although this recommendation is disregarded by the two most\npopular web servers (IIS and Apache), it is followed on the client side by all\nbrowsers except Firefox.\nThe resulting inconsistency makes it easier for application developers\ntoforget that not only LF but also CR characters must be stripped from any\nattacker-controlled values that appear anywhere in HTTP headers. To illus-\ntrate the problem, consider the following server response, where a user-\nsupplied and insufficiently sanitized value appears in one of the headers,\nashighlighted in bold:\nHTTP/1.1 200 OK[CR][LF]\nSet-Cookie: last_search_term=[CR][CR]<html><body><h1>Hi![CR][LF]\n[CR][LF]\nAction completed.\nTo Internet Explorer, this response may appear as:\nHTTP/1.1 200 OK\nSet-Cookie: last_search_term=\n<html><body><h1>Hi!\nAction completed.\nIn fact, the class of vulnerabilities related to HTTP header newline\nsmuggling—be it due to this inconsistency or just due to a failure to filter any\ntype of a newline—is common enough to have its own name: header injection\nor response splitting.\nAnother little-known and potentially security-relevant tweak is support\nfor multiline headers, a change introduced in HTTP/1.1. According to the\nstandard, any header line that begins with a whitespace is treated as a contin-\nuation of the previous one. For example:\nX-Random-Comment: This is a very long string,\nso why not wrap it neatly?\nMultiline headers are recognized in client-issued requests by IIS and\nApache, but they are not supported by Internet Explorer, Safari, or Opera.\nTherefore, any implementation that relies on or simply permits this syntax\ninany attacker-influenced setting may be in trouble. Thankfully, this is rare.\nHypertext Transfer Protocol 45"
  },
  {
    "input": "Proxy Requests",
    "output": "Proxy Requests\nProxies are used by many organizations and Internet service providers to\nintercept, inspect, and forward HTTP requests on behalf of their users. This\nmay be done to improve performance (by allowing certain server responses\nto be cached on a nearby system), to enforce network usage policies (for\nexample, to prevent access to porn), or to offer monitored and authenti-\ncated access to otherwise separated network environments.\nConventional HTTP proxies depend on explicit browser support: The\napplication needs to be configured to make a modified request to the proxy\nsystem, instead of attempting to talk to the intended destination. To request\nan HTTP resource through such a proxy, the browser will normally send a\nrequest like this:\nGET http://www.fuzzybunnies.com/ HTTP/1.1\nUser-Agent: Bunny-Browser/1.7\nHost: www.fuzzybunnies.com\n...\nThe key difference between the above example and the usual syntax is\nthe presence of a fully qualified URL in the first line of the request (http://\nwww.fuzzybunnies.com/), instructing the proxy where to connect to on behalf\nof the user. This information is somewhat redundant, given that the Host\nheader already specifies the hostname; the only reason for this overlap is that\nthe mechanisms evolved independent of each other. To avoid being fooled\nby co-conspiring clients and servers, proxies should either correct any mis-\nmatching Host headers to match the request URL or associate cached con-\ntent with a particular URL-Host pair and not just one of these values.\nMany HTTP proxies also allow browsers to request non-HTTP resources,\nsuch as FTP files or directories. In these cases, the proxy will wrap the response\nin HTTP, and perhaps convert it to HTML if appropriate, before returning it\nto the user.* That said, if the proxy does not understand the requested proto-\ncol, or if it is simply inappropriate for it to peek into the exchanged data (for\nexample, inside encrypted sessions), a different approach must be used. A\nspecial type of a request, CONNECT, is reserved for this purpose but is not\nfurther explained in the HTTP/1.1 RFC. The relevant request syntax is instead\noutlined in a separate, draft-only specification from 1998.5 It looks like this:\nCONNECT www.fuzzybunnies.com:1234 HTTP/1.1\nUser-Agent: Bunny-Browser/1.7\n...\n* In this case, some HTTP headers supplied by the client may be used internally by the proxy,\nbut they will not be transmitted to the non-HTTP endpoint, which creates some interesting, if\nnon-security-relevant, protocol ambiguities.\n46 Chapter 3"
  },
  {
    "input": "Resolution of Duplicate or Conflicting Headers",
    "output": "If the proxy is willing and able to connect to the requested destination,\nitacknowledges this request with a specific HTTP response code, and the role\nof this protocol ends. At that point, the browser will begin sending and receiv-\ning raw binary data within the established TCP stream; the proxy, in turn, is\nexpected to forward the traffic between the two endpoints indiscriminately.\nNOTE Hilariously, due to a subtle omission in the draft spec, many browsers have incorrectly\nprocessed the nonencrypted, proxy-originating error responses returned during an\nattempt to establish an encrypted connection. The affected implementations interpreted\nsuch plaintext responses as though they originated from the destination server over a\nsecure channel. This glitch effectively eliminated all assurances associated with the use\nof encrypted communications on the Web. It took over a decade to spot and correct\ntheflaw.6\nSeveral other classes of lower-level proxies do not use HTTP to com-\nmunicate directly with the browser but nevertheless inspect the exchanged\nHTTP messages to cache content or enforce certain rules. The canonical\nexample of this is a transparent proxy that silently intercepts traffic at the\nTCP/IP level. The approach taken by transparent proxies is unusually dan-\ngerous: Any such proxy can look at the destination IP and the Host header\nsent in the intercepted connection, but it has no way of immediately telling\nifthat destination IP is genuinely associated with the specified server name.\nUnless an additional lookup and correlation is performed, co-conspiring cli-\nents and servers can have a field day with this behavior. Without these addi-\ntional checks, the attacker simply needs to connect to his or her home server\nand send a misleading Host: www.google.com header to have the response\ncached for all other users as though genuinely coming from www.google.com.\nResolution of Duplicate or Conflicting Headers\nDespite being relatively verbose, RFC 2616 does a poor job of explaining how\na compliant parser should resolve potential ambiguities and conflicts in the\nrequest or response data. Section 19.2 of this RFC (“Tolerant Applications”)\nrecommends relaxed and error-tolerant parsing of certain fields in “unam-\nbiguous” cases, but the meaning of the term itself is, shall we say, not particu-\nlarly unambiguous.\nFor example, because of a lack of specification-level advice, roughly half\nof all browsers will favor the first occurrence of a particular HTTP header,\nand the rest will favor the last one, ensuring that almost every header injec-\ntion vulnerability, no matter how constrained, is exploitable for at least some\npercentage of targeted users. On the server side, the situation is similarly ran-\ndom: Apache will honor the first Host header seen, while IIS will completely\nreject a request with multiple instances of this field.\nHypertext Transfer Protocol 47"
  },
  {
    "input": "Semicolon-Delimited Header Values",
    "output": "On a related note, the relevant RFCs contain no explicit prohibition\nonmixing potentially conflicting HTTP/1.0 and HTTP/1.1 headers and no\nrequirement for HTTP/1.0 servers or clients to ignore all HTTP/1.1 syntax.\nBecause of this design, it is difficult to predict the outcome of indirect con-\nflicts between HTTP/1.0 and HTTP/1.1 directives that are responsible for\nthe same thing, such as Expires and Cache-Control.\nFinally, in some rare cases, header conflict resolution is outlined in the\nspec very clearly, but the purpose of permitting such conflicts to arise in the\nfirst place is much harder to understand. For example, HTTP/1.1 clients are\nrequired to send the Host header on all requests, but servers (not just prox-\nies!) are also required to recognize absolute URLs in the first line of the\nrequest, as opposed to the traditional path- and query-only method. This\nrulepermits a curiosity such as this:\nGET http://www.fuzzybunnies.com/ HTTP/1.1\nHost: www.bunnyoutlet.com\nIn this case, section 5.2 of RFC 2616 instructs clients to disregard the\nnonfunctional (but still mandatory!) Host header, and many implementa-\ntions follow this advice. The problem is that underlying applications are likely\nto be unaware of this quirk and may instead make somewhat important deci-\nsions based on the inspected header value.\nNOTE When complaining about the omissions in the HTTP RFCs, it is important to recognize\nthat the alternatives can be just as problematic. In several scenarios outlined in that\nRFC, the desire to explicitly mandate the handling of certain corner cases led to patently\nabsurd outcomes. One such example is the advice on parsing dates in certain HTTP\nheaders, at the request of section 3.3 in RFC 1945. The resulting implementation (the\nprtime.c file in the Firefox codebase7) consists of close to 2,000 lines of extremely con-\nfusing and unreadable C code just to decipher the specified date, time, and time zone in\nasufficiently fault-tolerant way (for uses such as deciding cache content expiration).\nSemicolon-Delimited Header Values\nSeveral HTTP headers, such as Cache-Control or Content-Disposition, use a\nsemicolon-delimited syntax to cram several separate name=value pairs into a\nsingle line. The reason for allowing this nested notation is unclear, but it is\nprobably driven by the belief that it will be a more efficient or a more intuitive\napproach that using several separate headers that would always have to go\nhand in hand.\nSome use cases outlined in RFC 2616 permit quoted-string as the right-\nhand parameter in such pairs. Quoted-string is a syntax in which a sequence of\narbitrary printable characters is surrounded by double quotes, which act as\ndelimiters. Naturally, the quote mark itself cannot appear inside the string,\nbut—importantly—a semicolon or a whitespace may, permitting many other-\nwise problematic values to be sent as is.\n48 Chapter 3"
  },
  {
    "input": "Header Character Set and Encoding Schemes",
    "output": "Unfortunately for developers, Internet Explorer does not cope with\nthequoted-string syntax particularly well, effectively rendering this encoding\nscheme useless. The browser will parse the following line (which is meant to\nindicate that the response is a downloadable file rather than an inline docu-\nment) in an unexpected way:\nContent-Disposition: attachment; filename=\"evil_file.exe;.txt\"\nIn Microsoft’s implementation, the filename will be truncated at the\nsemicolon character and will appear to be evil_file.exe. This behavior creates a\npotential hazard to any application that relies on examining or appending a\n“safe” filename extension to an attacker-controlled filename and otherwise\ncorrectly checks for the quote character and newlines in this string.\nNOTE An additional quoted-pair mechanism is provided to allow quotes (and any other char-\nacters) to be used safely in the string when prefixed by a backslash. This mechanism\nappears to be specified incorrectly, however, and not supported by any major browser\nexcept for Opera. For quoted-pair to work properly, stray “\\” characters would need to\nbe banned from the quoted-string, which isn’t the case in RFC 2616. Quoted-pair\nalso permits any CHAR-type token to be quoted, including newlines, which is incom-\npatible with other HTTP-parsing rules.\nIt is also worth noting that when duplicate semicolon-delimited fields are\nfound in a single HTTP header, their order of precedence is not defined by\nthe RFC. In the case of filename= in Content-Disposition, all mainstream browsers\nuse the first occurrence. But there is little consistency elsewhere. For example,\nwhen extracting the URL= value from the Refresh header (used to force reload-\ning the page after a specified amount of time), Internet Explorer6 will fall\nback to the last instance, yet all other browsers will prefer the first one. And\nwhen handling Content-Type, Internet Explorer, Safari, and Opera will use the\nfirst charset= value, while Firefox and Chrome will rely on the last.\nNOTE Food for thought: A fascinating but largely non-security-related survey of dozens\nofinconsistencies associated with the handling of just a single HTTP header—\nContent-Disposition—can be found on a page maintained by Julian Reschke:\nhttp://greenbytes.de/tech/tc2231/.\nHeader Character Set and Encoding Schemes\nLike the documents that laid the groundwork for URL handling, all subse-\nquent HTTP specs have largely avoided the topic of dealing with non-US-\nASCII characters inside header values. There are several plausible scenarios\nwhere non-English text may legitimately appear in this context (for example,\nthe filename in Content-Disposition), but when it comes to this, the expected\nbrowser behavior is essentially undefined.\nHypertext Transfer Protocol 49\nOriginally, RFC 1945 permitted the TEXT token (a primitive broadly\nused to define the syntax of other fields) to contain 8-bit characters, provid-\ning the following definition:\nOCTET = <any 8-bit sequence of data>\nCTL = <any US-ASCII control character\n(octets 0 - 31) and DEL (127)>\nTEXT = <any OCTET except CTLs,\nbut including LWS>\nThe RFC followed up with cryptic advice: When non-US-ASCII charac-\nters are encountered in a TEXT field, clients and servers may interpret them\nas ISO-8859-1, the standard Western European code page, but they don’t\nhave to. Later, RFC 2616 copied and pasted the same specification of TEXT\ntokens but added a note that non-ISO-8859-1 strings must be encoded using\na format outlined in RFC 2047,8 originally created for email communications.\nFair enough; in this simple scheme, the encoded string opens with a “=?” pre-\nfix, followed by a character-set name, a “?q?” or “?b?” encoding-type indicator\n(quoted-printable* or base64,† respectively), and lastly the encoded string itself.\nThe sequence ends with a “?=” terminator. An example of this may be:\nContent-Disposition: attachment; filename=\"=?utf-8?q?Hi=21.txt?=\"\nNOTE The RFC should also have stated that any spurious “=?...?=” patterns must never be\nallowed as is in the relevant headers, in order to avoid unintended decoding of values\nthat were not really encoded to begin with.\nSadly, the support for this RFC 2047 encoding is spotty. It is recognized\nin some headers by Firefox and Chrome, but other browsers are less cooper-\native. Internet Explorer chooses to recognize URL-style percent encoding in\nthe Content-Disposition field instead (a habit also picked up by Chrome) and\ndefaults to UTF-8 in this case. Firefox and Opera, on the other hand, prefer\nsupporting a peculiar percent-encoded syntax proposed in RFC 2231,9 a\nstriking deviation from how HTTP syntax is supposed to look:\nContent-Disposition: attachment; filename*=utf-8'en-us'Hi%21.txt\nAstute readers may notice that there is no single encoding scheme sup-\nported by all browsers at once. This situation prompts some web application\ndevelopers to resort to using raw high-bit values in the HTTP headers, typi-\ncally interpreted as UTF-8, but doing so is somewhat unsafe. In Firefox, for\nexample, a long-standing glitch causes UTF-8 text to be mangled when put\n* Quoted-printable is a simple encoding scheme that replaces any nonprintable or otherwise illegal\ncharacters with the equal sign (=) followed by a 2-digit hexadecimal representation of the 8-bit\ncharacter value to be encoded. Any stray equal signs in the input text must be replaced with\n“=3D” as well.\n† Base64 is a non-human-readable encoding that encodes arbitrary 8-bit input using a 6-bit alpha-\nbet of case-sensitive alphanumerics, “+”, and “/”. Every 3 bytes of input map to 4 bytes of output.\nIf the input does not end at a 3-byte boundary, this is indicated by appending one or two equal\nsigns at the end of the output string.\n50 Chapter 3"
  },
  {
    "input": "Referer Header Behavior",
    "output": "inthe Cookie header, permitting attacker-injected cookie delimiters to mate-\nrialize in unexpected places.10 In other words, there are no easy and robust\nsolutions to this mess.\nWhen discussing character encodings, the problem of handling of the\nNUL character (0x00) probably deserves a mention. This character, used as a\nstring terminator in many programming languages, is technically prohibited\nfrom appearing in HTTP headers (except for the aforementioned, dysfunc-\ntional quoted-pair syntax), but as you may recall, parsers are encouraged to be\ntolerant. When this character is allowed to go through, it is likely to have\nunexpected side effects. For example, Content-Disposition headers are trun-\ncated at NUL by Internet Explorer, Firefox, and Chrome but not by Opera\nor Safari.\nReferer Header Behavior\nAs mentioned earlier in this chapter, HTTP requests may include a Referer\nheader. This header contains the URL of a document that triggered the cur-\nrent navigation in some way. It is meant to help with certain troubleshooting\ntasks and to promote the growth of the Web by emphasizing cross-references\nbetween related web pages.\nUnfortunately, the header may also reveal some information about user\nbrowsing habits to certain unfriendly parties, and it may leak sensitive infor-\nmation that is encoded in the URL query parameters on the referring page.\nDue to these concerns, and the subsequent poor advice on how to mitigate\nthem, the header is often misused for security or policy enforcement pur-\nposes, but it is not up to the task. The main problem is that there is no way\ntodifferentiate between a client that is not providing the header because of\nuser privacy preferences, one that is not providing it because of the type of\nnavigation taking place, and one that is deliberately tricked into hiding this\ninformation by a malicious referring site.\nNormally, this header is included in most HTTP requests (and preserved\nacross HTTP-level redirects), except in the following scenarios:\n After organically entering a new URL into the address bar or opening a\nbookmarked page.\n When the navigation originates from a pseudo-URL document, such as\ndata: or javascript:.\n When the request is a result of redirection controlled by the Refresh\nheader (but not a Location-based one).\n Whenever the referring site is encrypted but the requested page isn’t.\nAccording to RFC 2616 section 15.1.2, this is done for privacy reasons, but\nit does not make a lot of sense. The Referer string is still disclosed to third\nparties when one navigates from one encrypted domain to an unrelated\nencrypted one, and rest assured, the use of encryption is not synonymous\nwith trustworthiness.\n If the user decides to block or spoof the header by tweaking browser set-\ntings or installing a privacy-oriented plug-in.\nHypertext Transfer Protocol 51"
  },
  {
    "input": "POST",
    "output": "As should be apparent, four out of five of these conditions can be pur-\nposefully induced by any rogue site.\nHTTP Request Types\nThe original HTTP/0.9 draft provided a single method (or “verb”) for\nrequesting a document: GET. The subsequent proposals experimented\nwithan increasingly bizarre set of methods to permit interactions other\nthanretrieving a document or running a script, including such curiosities\nasSHOWMETHOD, CHECKOUT, or—why not—SPACEJUMP.11\nMost of these thought experiments have been abandoned in HTTP/1.1,\nwhich settles on a more manageable set of eight methods. Only the first two\nrequest types—GET and POST—are of any significance to most of the mod-\nern Web.\nGET\nThe GET method is meant to signify information retrieval. In practice, it\nisused for almost all client-server interactions in the course of a normal\nbrowsing session. Regular GET requests carry no browser-supplied payloads,\nalthough they are not strictly prohibited from doing so.\nThe expectation is that GET requests should not have, to quote the RFC,\n“significance of taking an action other than retrieval” (that is, they should\nmake no persistent changes to the state of the application). This requirement\nis increasingly meaningless in modern web applications, where the applica-\ntion state is often not even managed entirely on the server side; consequently,\nthe advice is widely ignored by application developers.*\nNOTE In HTTP/1.1, clients may ask the server for any set of possibly noncontiguous or over-\nlapping fragments of the target document by specifying the Range header on GET\n(and, less commonly, on some other types of requests). The server is not obliged to comply,\nbut where the mechanism is available, browsers may use it to resume aborted downloads.\nPOST\nThe POST method is meant for submitting information (chiefly HTML\nforms) to the server for processing. Because POST actions may have persis-\ntent side effects, many browsers ask the user to confirm before reloading any\ncontent retrieved with POST, but for the most part, GET and POST are used\nin a quasi-interchangeable manner.\nPOST requests are commonly accompanied by a payload, the length of\nwhich is indicated by the Content-Length header. In the case of plain HTML,\nthe payload may consist of URL-encoded or MIME-encoded form data (a for-\nmat detailed in Chapter 4), although again, the syntax is not constrained at\nthe HTTP level in any special way.\n* There is an anecdotal (and perhaps even true) tale of an unfortunate webmaster by the name\nof John Breckman. According to the story, John’s website has been accidentally deleted by a\nsearch engine–indexing robot. The robot simply unwittingly discovered an unauthenticated,\nGET-based administrative interface that John had built for his site . . . and happily followed every\n“delete” link it could find.\n52 Chapter 3"
  },
  {
    "input": "TRACE",
    "output": "HEAD\nHEAD is a rarely used request type that is essentially identical to GET but\nthat returns only the HTTP headers, and not the actual payload, for the\nrequested content. Browsers generally do not issue HEAD requests on their\nown, but the method is sometimes employed by search engine bots and other\nautomated tools, for example, to probe for the existence of a file or to check\nits modification time.\nOPTIONS\nOPTIONS is a metarequest that returns the set of supported methods for a\nparticular URL (or “*”, meaning the server in general) in a response header.\nThe OPTIONS method is almost never used in practice, except for server\nfingerprinting; because of its limited value, the returned information may\nnot be very accurate.\nNOTE For the sake of completeness, we need to note that OPTIONS requests are also a corner-\nstone of a proposed cross-domain request authorization scheme, and as such, they may\ngain some prominence soon. We will revisit this scheme, and explore many other upcom-\ning browser security features, in Chapter 16.\nPUT\nA PUT request is meant to allow files to be uploaded to the server at the\nspecified target URL. Because browsers do not support PUT, intentional file-\nupload capabilities are almost always implemented through POST to a server-\nside script, rather than with this theoretically more elegant approach.\nThat said, some nonweb HTTP clients and servers may use PUT for their\nown purposes. Just as interestingly, some web servers may be misconfigured\nto process PUT requests indiscriminately, creating an obvious security risk.\nDELETE\nDELETE is a self-explanatory method that complements PUT (and that is\nequally uncommon in practice).\nTRACE\nTRACE is a form of “ping” request that returns information about all the\nproxy hops involved in processing a request and echoes the original request\nas well. TRACE requests are not issued by web browsers and are seldom used\nfor legitimate purposes. TRACE’s primary use is for security testing, where it\nmay reveal interesting details about the internal architecture of HTTP serv-\ners in a remote network. Precisely for this reason, the method is often dis-\nabled by server administrators.\nHypertext Transfer Protocol 53"
  },
  {
    "input": "200-299: Success",
    "output": "CONNECT\nThe CONNECT method is reserved for establishing non-HTTP connections\nthrough HTTP proxies. It is not meant to be issued directly to servers. If the\nsupport for CONNECT request is enabled accidentally on a particular server,\nit may pose a security risk by offering an attacker a way to tunnel TCP traffic\ninto an otherwise protected network.\nOther HTTP Methods\nA number of other request methods may be employed by other nonbrowser\napplications or browser extensions; the most popular set of HTTP extensions\nmay be WebDAV, an authoring and version-control protocol described in\nRFC 4918.12\nFurther, the XMLHttpRequest API nominally allows client-side JavaScript\nto make requests with almost arbitrary methods to the originating server—\nalthough this last functionality is heavily restricted in certain browsers (we\nwill look into this in Chapter 9).\nServer Response Codes\nSection 10 of RFC 2616 lists nearly 50 status codes that a server may choose\nfrom when constructing a response. About 15 of these are used in real life,\nand the rest are used to indicate increasingly bizarre or unlikely states, such\nas “402 Payment Required” or “415 Unsupported Media Type.” Most of the\nRFC-listed states do not map cleanly to the behavior of modern web applica-\ntions; the only reason for their existence is that somebody hoped they even-\ntually would.\nA few codes are worth memorizing because they are common or carry\nspecial meaning, as discussed below.\n200–299: Success\nThis range of status codes is used to indicate a successful completion of a\nrequest:\n200 OK This is a normal response to a successful GET or POST. The\nbrowser will display the subsequently returned payload to the user or\nwillprocess it in some other context-specific way.\n204 No Content This code is sometimes used to indicate a successful\nrequest to which no verbose response is expected. A 204 response aborts\nnavigation to the URL that triggered it and keeps the user on the origi-\nnating page.\n206 Partial Content This code is like 200, except that it is returned by\nservers in response to range requests. The browser must already have a\nportion of the document (or it would not have issued a range request)\nand will normally inspect the Content-Range response header to reassem-\nble the document before further processing it.\n54 Chapter 3"
  },
  {
    "input": "400-499: Client-Side Error",
    "output": "300–399: Redirection and Other Status Messages\nThese codes are used to communicate a variety of states that do not indicate\nan error but that require special handling on the browser end:\n301 Moved Permanently, 302 Found, 303 See Other This response\ninstructs the browser to retry the request at a new location, specified in\nthe Location response header. Despite the distinctions made in the RFC,\nwhen encountering any of these response codes, all modern browsers\nreplace POST with GET, remove the payload, and then resubmit the\nrequest automatically.\nNOTE Redirect messages may contain a payload, but if they do, this message will\nnot be shown to the user unless the redirection is not possible (for example,\nbecause of a missing or unsupported Location value). In fact, in some\nbrowsers, display of the message may besuppressed even in that scenario.\n304 Not Modified This nonredirect response instructs the client that\nthe requested document hasn’t been modified in relation to the copy the\nclient already has. This response is seen after conditional requests with\nheaders such as If-Modified-Since, which are issued to revalidate the browser\ndocument cache. The response body is not shown to the user. (If the\nserver responds this way to an unconditional request, the result will be\nbrowser-specific and may be hilarious; for example, Opera will pop up\nanonfunctional download prompt.)\n307 Temporary Redirect Similar to 302, but unlike with other modes\nofredirection, browsers will not downgrade POST to GET when follow-\ning a 307 redirect. This code is not commonly used in web applications,\nand some browsers do not behave very consistently when handling it.\n400–499: Client-Side Error\nThis range of codes is used to indicate error conditions caused by the behav-\nior of the client:\n400 Bad Request (and related messages) The server is unable or unwill-\ning to process the request for some unspecified reason. The response pay-\nload will usually explain the problem to some extent and will be typically\nhandled by the browser just like a 200 response.\nMore specific variants, such as “411 Length Required,” “405 Method\nNot Allowed,” or “414 Request-URI Too Long,” also exist. It’s anyone’s\nguess as to why not specifying Content-Length when required has a dedi-\ncated 411 response code but not specifying Host deserves only a generic\n400 one.\n401 Unauthorized This code means that the user needs to provide\nprotocol-level HTTP authentication credentials in order to access the\nresource. The browser will usually prompt the user for login information\nnext, and it will present a response body only if the authentication pro-\ncess is unsuccessful. This mechanism will be explained in more detail\nshortly, in “HTTP Authentication” on page62.\nHypertext Transfer Protocol 55"
  },
  {
    "input": "Keepalive Sessions",
    "output": "403 Forbidden The requested URL exists but can’t be accessed for\nreasons other than incorrect HTTP authentication. Reasons may involve\ninsufficient filesystem permissions, a configuration rule that prevents\nthis request from being processed, or insufficient credentials of some\nsort (e.g., invalid cookies or an unrecognized source IP address). The\nresponse will usually be shown to the user.\n404 Not Found The requested URL does not exist. The response body\nis typically shown to the user.\n500–599: Server-Side Error\nThis is a class of error messages returned in response to server-side problems:\n500 Internal Server Error, 503 Service Unavailable, and so on The server\nis experiencing a problem that prevents it from fulfilling the request. This\nmay be a transient condition, a result of misconfiguration, or simply the\neffect of requesting an unexpected location. The response is normally\nshown to the user.\nConsistency of HTTP Code Signaling\nBecause there is no immediately observable difference between returning\nmost 2xx, 4xx, and 5xx codes, these values are not selected with any special\nzeal. In particular, web applications are notorious for returning “200 OK”\neven when an application error has occurred and is communicated on the\nresulting page. (This is one of the many factors that make automated testing\nof web applications much harder than it needs to be.)\nOn rare occasions, new and not necessarily appropriate HTTP codes are\ninvented for specific uses. Some of these are standardized, such as a couple\nof messages introduced in the WebDAV RFC.13 Others, such as Microsoft’s\nMicrosoft Exchange “449 Retry With” status, are not.\nKeepalive Sessions\nOriginally, HTTP sessions were meant to happen in one shot: Make one\nrequest for each TCP connection, rinse, and repeat. The overhead of repeat-\nedly completing a three-step TCP handshake (and forking off a new process\nin the traditional Unix server design model) soon proved to be a bottleneck,\nso HTTP/1.1 standardized the idea of keepalive sessions instead.\nThe existing protocol already gave the server an understanding of where\nthe client request ended (an empty line, optionally followed by Content-Length\nbytes of data), but to continue using the existing connection, the client also\nneeded to know the same about the returned document; the termination of\na connection could no longer serve as an indicator. Therefore, keepalive ses-\nsions require the response to include a Content-Length header too, always speci-\nfying the amount of data to follow. Once this many payload bytes are received,\nthe client knows it is okay to send a second request and begin waiting for\nanother response.\n56 Chapter 3"
  },
  {
    "input": "Chunked Data Transfers",
    "output": "Although very beneficial from a performance standpoint, the way this\nmechanism is designed exacerbates the impact of HTTP request and response-\nsplitting bugs. It is deceptively easy for the client and the server to get out of\nsync on which response belongs to which request. To illustrate, let’s consider\na server that thinks it is sending a single HTTP response, structured as follows:\nHTTP/1.1 200 OK[CR][LF]\nSet-Cookie: term=[CR]Content-Length: 0[CR][CR]HTTP/1.1 200 OK[CR]Gotcha: Yup[CR][LF]\nContent-Length: 17[CR][LF]\n[CR][LF]\nAction completed.\nThe client, on the other hand, may see two responses and associate the\nfirst one with its most current request and the second one with the yet-to-be-\nissued query* (which may even be addressed to a different hostname on the\nsame IP):\nHTTP/1.1 200 OK\nSet-Cookie: term=\nContent-Length: 0\nHTTP/1.1 200 OK\nGotcha: Yup\nContent-Length: 17\nAction completed.\nIf this response is seen by a caching HTTP proxy, the incorrect result\nmay also be cached globally and returned to other users, which is really bad\nnews. A much safer design for keepalive sessions would involve specifying the\nlength of both the headers and the payload up front or using a randomly gen-\nerated and unpredictable boundary to delimit every response. Regrettably,\nthe design does neither.\nKeepalive connections are the default in HTTP/1.1 unless they are\nexplicitly turned off (Connection: close) and are supported by many HTTP/1.0\nservers when enabled with a Connection: keep-alive header. Both servers and\nbrowsers can limit the number of concurrent requests serviced per connec-\ntion and can specify the maximum amount of time an idle connection is kept\naround.\nChunked Data Transfers\nThe significant limitation of Content-Length-based keepalive sessions is\ntheneed for the server to know in advance the exact size of the returned\nresponse. This is a pretty simple task when dealing with static files, as the\n* In principle, clients could be designed to sink any unsolicited server response data before\nissuing any subsequent requests in a keepalive session, limiting the impact of the attack. This\nproposal is undermined by the practice of HTTP pipelining, however; for performance reasons,\nsome clients are designed to dump multiple requests at once, without waiting for a complete\nresponse in between.\nHypertext Transfer Protocol 57"
  },
  {
    "input": "Caching Behavior",
    "output": "information is already available in the filesystem. When serving dynamically\ngenerated data, the problem is more complicated, as the output must be\ncached in its entirety before it is sent to the client. The challenge becomes\ninsurmountable if the payload is very large or is produced gradually (think\nlive video streaming). In these cases, precaching to compute payload size is\nsimply out of the question.\nIn response to this challenge, RFC 2616 section 3.6.1 gives servers the\nability to use Transfer-Encoding: chunked, a scheme in which the payload is sent\nin portions as it becomes available. The length of every portion of the docu-\nment is declared up front using a hexadecimal integer occupying a separate\nline, but the total length of the document is indeterminate until a final zero-\nlength chunk is seen.\nA sample chunked response may look like this:\nHTTP/1.1 200 OK\nTransfer-Encoding: chunked\n...\n5\nHello\n6\nworld!\n0\nThere are no significant downsides to supporting chunked data trans-\nfers, other than the possibility of pathologically large chunks causing integer\noverflows in the browser code or needing to resolve mismatches between\nContent-Length and chunk length. (The specification gives precedence to\nchunk length, although any attempts to handle this situation gracefully appear\nto be ill-advised.) All the popular browsers deal with these conditions prop-\nerly, but new implementations need to watch their backs.\nCaching Behavior\nFor reasons of performance and bandwidth conservation, HTTP clients\nandsome intermediaries are eager to cache HTTP responses for later reuse.\nThis must have seemed like a simple task in the early days of the Web, but it\nis increasingly fraught with peril as the Web encompasses ever more sensi-\ntive, user-specific information and as this information is updated more and\nmore frequently.\nRFC 2616 section 13.4 states that GET requests responded to with a range\nof HTTP codes (most notably, “200 OK” and “301 Moved Permanently”) may\nbe implicitly cached in the absence of any other server-provided directives.\nSuch a response may be stored in the cache indefinitely, and may be reused\nfor any future requests involving the same request method and destination\nURL, even if other parameters (such as Cookie headers) differ. There is a pro-\nhibition against caching requests that use HTTP authentication (see “HTTP\nAuthentication” on page62), but other authentication methods, such as\ncookies, are not recognized in the spec.\n58 Chapter 3\nWhen a response is cached, the implementation may opt to revalidate it\nbefore reuse, but doing so is not required most of the time. Revalidation is\nachieved by request with a special conditional header, such as If-Modified-Since\n(followed by a date recorded on the previously cached response) or If-None-\nMatch (followed by an opaque ETag header value that the server returned\nwith an earlier copy). The server may respond with a “304 Not Modified”\ncode or return a newer copy of the resource.\nNOTE The Date/If-Modified-Since and ETag/If-None-Match header pairs, when cou-\npled with Cache-Control: private, offer a convenient and entirely unintended way\nfor websites to store long-lived, unique tokens in the browser.14 The same can also be\nachieved by depositing a unique token inside a cacheable JavaScript file and returning\n“304 Not Modified” to all future conditional requests to the token-generating location.\nUnlike purpose-built mechanisms such as HTTP cookies (discussed in the next section),\nusers have very little control over what information is stored in the browser cache,\nunder what circumstances, and for how long.\nImplicit caching is highly problematic, and therefore, servers almost\nalways should resort to using explicit HTTP-caching directives. To assist with\nthis, HTTP/1.0 provides an Expires header that specifies the date by which\nthe cached copy should be discarded; if this value is equal to the Date header\nprovided by the server, the response is noncacheable. Beyond that simple\nrule, the connection between Expires and Date is unspecified: It is not clear\nwhether Expires should be compared to the system clock on the caching sys-\ntem (which is problematic if the client and server clocks are not in sync) or\nevaluated based on the Expires – Date delta (which is more robust, but which\nmay stop working if Date is accidentally omitted). Firefox and Opera use the\nlatter interpretation, while other browsers prefer the former one. In most\nbrowsers, an invalid Expires value also inhibits caching, but depending on it\nisa risky bet.\nHTTP/1.0 clients can also include a Pragma: no-cache request header,\nwhich may be interpreted by the proxy as an instruction to obtain a new\ncopyof the requested resource, instead of returning an existing one. Some\nHTTP/1.0 proxies also recognize a nonstandard Pragma: no-cache response\nheader as an instruction not to make a copy of the document.\nIn contrast, HTTP/1.1 embraces a far more substantial approach to\ncaching directives, introducing a new Cache-Control header. The header takes\nvalues such as public (the document is cacheable publicly), private (proxies\nare not permitted to cache), no-cache (which is a bit confusing—the response\nmay be cached but should not be reused for future requests),* and no-store\n(absolutely no caching at all). Public and private caching directives may be\naccompanied with a qualifier such as max-age, specifying the maximum time\nan old copy should be kept, or must-revalidate, requesting a conditional\nrequest to be made before content reuse.\n* The RFC is a bit hazy in this regard, but it appears that the intent is to permit the cached\ndocument to be used for purposes such as operating the “back” and “forward” navigation\nbuttons in a browser but not when a proper page load is requested. Firefox follows this\napproach, while all other browsers consider no-cache and no-store to be roughly equivalent.\nHypertext Transfer Protocol 59"
  },
  {
    "input": "HTTP Cookie Semantics",
    "output": "Unfortunately, it is typically necessary for servers to return both HTTP/1.0\nand HTTP/1.1 caching directives, because certain types of legacy commer-\ncial proxies do not understand Cache-Control correctly. In order to reliably\nprevent caching over HTTP, it may be necessary to use the following set of\nresponse headers:\nExpires: [current date]\nDate: [current date]\nPragma: no-cache\nCache-Control: no-cache, no-store\nWhen these caching directives disagree, the behavior is difficult to pre-\ndict: Some browsers will favor HTTP/1.1 directives and give precedence to\nno-cache, even if it is mistakenly followed by public; others don’t.\nAnother risk of HTTP caching is associated with unsafe networks, such\naspublic Wi-Fi networks, which allow an attacker to intercept requests to cer-\ntain URLs and return modified, long-cacheable contents on requests to the\nvictim. If such a poisoned browser cache is then reused on a trusted network,\nthe injected content will unexpectedly resurface. Perversely, the victim does\nnot even have to visit the targeted application: A reference to a carefully cho-\nsen sensitive domain can be injected by the attacker into some other context.\nThere are no good solutions to this problem yet; purging your browser cache\nafter visiting Starbucks may be a very good idea.\nHTTP Cookie Semantics\nHTTP cookies are not a part of RFC 2616, but they are one of the more\nimportant protocol extensions used on the Web. The cookie mechanism\nallows servers to store short, opaque name=value pairs in the browser by send-\ning a Set-Cookie response header and to receive them back on future requests\nvia the client-supplied Cookie parameter. Cookies are by far the most popular\nway to maintain sessions and authenticate user requests; they are one of the\nfour canonical forms of ambient authority* on the Web (the other forms being\nbuilt-in HTTP authentication, IP checking, and client certificates).\nOriginally implemented in Netscape by Lou Montulli around 1994,\nanddescribed in a brief four-page draft document,15 the mechanism has not\nbeen outlined in a proper standard in the last 17 years. In 1997, RFC 210916\nattempted to document the status quo, but somewhat inexplicably, it also pro-\nposed a number of sweeping changes that, to this day, make this specification\nsubstantially incompatible with the actual behavior of any modern browser.\nAnother ambitious effort—Cookie2—made an appearance in RFC 2965,17 but\na decade later, it still has virtually no browser-level support, a situation that is\n* Ambient authority is a form of access control based on a global and persistent property of the\nrequesting entity, rather than any explicit form of authorization that would be valid only for a\nspecific action. A user-identifying cookie included indiscriminately on every outgoing request to\na remote site, without any consideration for why this request is being made, falls into that\ncategory.\n60 Chapter 3\nunlikely to change. A new effort to write a reasonably accurate cookie specifi-\ncation—RFC 626518—was wrapped up shortly before the publication of this\nbook, finally ending this specification-related misery.\nBecause of the prolonged absence of any real standards, the actual\nimplementations evolved in very interesting and sometimes incompatible\nways. In practice, new cookies can be set using Set-Cookie headers followed\nbya single name=value pair and a number of optional semicolon-delimited\nparameters defining the scope and lifetime of the cookie.\nExpires Specifies the expiration date for a cookie in a format similar to\nthat used for Date or Expires HTTP headers. If a cookie is served without\nan explicit expiration date, it is typically kept in memory for the duration\nof a browser session (which, especially on portable computers with sus-\npend functionality, can easily span several weeks). Definite-expiry cook-\nies may be routinely saved to disk and persist across sessions, unless a\nuser’s privacy settings explicitly prevent this possibility.\nMax-age This alternative, RFC-suggested expiration mechanism is not\nsupported in Internet Explorer and therefore is not used in practice.\nDomain This parameter allows the cookie to be scoped to a domain\nbroader than the hostname that returned the Set-Cookie header. The\nexact rules and security consequences of this scoping mechanism are\nexplored in Chapter 9.\nNOTE Contrary to what is implied in RFC 2109, it is not possible to scope\ncookies to a specific hostname when using this parameter. For example,\ndomain=example.com will always match www.example.com as well.\nOmitting domain is the only way to create host-scoped cookies, but even\nthis approach is not working as expected in Internet Explorer.\nPath Allows the cookie to be scoped to a particular request path prefix.\nThis is not a viable security mechanism for the reasons explained in\nChapter 9, but it may be used for convenience, to prevent identically\nnamed cookies used in various parts of the application from colliding\nwith each other.\nSecure attribute Prevents the resulting cookie from being sent over\nnonencrypted connections.\nHttpOnly attribute Removes the ability to read the cookie through the\ndocument.cookie API in JavaScript. This is a Microsoft extension, although\nit is now supported by all mainstream browsers.\nWhen making future requests to a domain for which valid cookies are\nfound in the cookie jar, browsers will combine all applicable name=value pairs\ninto a single, semicolon-delimited Cookie header, without any additional meta-\ndata, and return them to the server. If too many cookies need to be sent on a\nparticular request, server-enforced header size limits will be exceeded, and\nthe request may fail; there is no method for recovering from this condition,\nother than manually purging the cookie jar.\nHypertext Transfer Protocol 61"
  },
  {
    "input": "HTTP Authentication",
    "output": "Curiously, there is no explicit method for HTTP servers to delete unneeded\ncookies. However, every cookie is uniquely identified by a name-domain-path\ntuple (the secure and httponly attributes are ignored), which permits an old\ncookie of a known scope to be simply overwritten. Furthermore, if the over-\nwriting cookie has an expires date in the past, it will be immediately dropped,\neffectively giving a contrived way to purge the data.\nAlthough RFC 2109 requires multiple comma-separated cookies to be\naccepted within a single Set-Cookie header, this approach is dangerous and is\nno longer supported by any browser. Firefox allows multiple cookies to be\nsetin a single step via the document.cookie JavaScript API, but inexplicably, it\nrequires newlines as delimiters instead. No browser uses commas as Cookie\ndelimiters, and recognizing them on the server side should be considered\nunsafe.\nAnother important difference between the spec and reality is that cookie\nvalues are supposed to use the quoted-string format outlined in HTTP specs\n(see “Semicolon-Delimited Header Values” on page48), but only Firefox\nand Opera recognize this syntax in practice. Reliance on quoted-string values\nis therefore unsafe, and so is allowing stray quote characters in attacker-\ncontrolled cookies.\nCookies are not guaranteed to be particularly reliable. User agents enforce\nmodest settings on the number and size of cookies permitted per domain\nand, as a misguided privacy feature, may also restrict their lifetime. Because\nequally reliable user tracking may be achieved by other means, such as the\nETag/If-None-Match behavior outlined in the previous section, the efforts to\nrestrict cookie-based tracking probably do more harm than good.\nHTTP Authentication\nHTTP authentication, as specified in RFC 2617,19 is the original credential-\nhandling mechanism envisioned for web applications, one that is now almost\ncompletely extinct. The reasons for this outcome might have been the inflex-\nibility of the associated browser-level UIs, the difficulty of accommodating\nmore sophisticated non-password-based authentication schemes, or perhaps\nthe inability to exercise control over how long credentials are cached and\nwhat other domains they are shared with.\nIn any case, the basic scheme is fairly simple. It begins with the browser\nmaking an unauthenticated request, to which the server responds with a “401\nUnauthorized” code.* The server must also include a WWW-Authenticate\nHTTP header, specifying the requested authentication method, the realm\nstring (an arbitrary identifier to which the entered credentials should be\nbound), and other method-specific parameters, if applicable.\n* The terms authentication and authorization appear to be used interchangeably in this RFC, but\nthey have a distinctive meaning elsewhere in information security. Authentication is commonly\nused to refer to the process of proving your identity, whereas authorization is the process of\ndetermining whether your previously established credentials permit you to carry out a specific\nprivileged action.\n62 Chapter 3\nThe client is expected to obtain the credentials in one way or the other,\nencode them in the Authorization header, and retry the original request with\nthis header included. According to the specification, for performance rea-\nsons, the same Authorization header may also be included on subsequent\nrequests to the same server path prefix without the need for a second WWW-\nAuthenticate challenge. It is also permissible to reuse the same credentials in\nresponse to any WWW-Authenticate challenges elsewhere on the server, if the\nrealm string and the authentication method match.\nIn practice, this advice is not followed very closely: Other than Safari and\nChrome, most browsers ignore the realm string or take a relaxed approach to\npath matching. On the flip side, all browsers scope cached credentials not\nonly to the destination server but also to a specific protocol and port, a prac-\ntice that offers some security benefits.\nThe two credential-passing methods specified in the original RFC are\nknown as basic and digest. The first one essentially sends the passwords in\nplaintext, encoded as base64. The other computes a one-time cryptographic\nhash that protects the password from being viewed in plaintext and prevents\nthe Authorization header from being replayed later. Unfortunately, modern\nbrowsers support both methods and do not distinguish between them in any\nclear way. As a result, attackers can simply replace the word digest with basic in\nthe initial request to obtain a clean, plaintext password as soon as the user\ncompletes the authentication dialog. Surprisingly, section 4.8 of the RFC pre-\ndicted this risk and offered some helpful yet ultimately ignored advice:\nUser agents should consider measures such as presenting a visual\nindication at the time of the credentials request of what authentica-\ntion scheme is to be used, or remembering the strongest authenti-\ncation scheme ever requested by a server and produce a warning\nmessage before using a weaker one. It might also be a good idea\nfor the user agent to be configured to demand Digest authentica-\ntion in general, or from specific sites.\nIn addition to these two RFC-specified authentication schemes, some\nbrowsers also support less-common methods, such as Microsoft’s NTLM and\nNegotiate, used for seamless authentication with Windows domain credentials.20\nAlthough HTTP authentication is seldom encountered on the Internet,\nit still casts a long shadow over certain types of web applications. For example,\nwhen an external, attacker-supplied image is included in a thread on a mes-\nsage board, and the server hosting that image suddenly decides to return\n“401 Unauthorized” on some requests, users viewing the thread will be pre-\nsented out of the blue with a somewhat cryptic password prompt. After double-\nchecking the address bar, many will probably confuse the prompt for a request\nto enter their forum credentials, and these will be immediately relayed to the\nattacker’s image-hosting server. Oops.\nHypertext Transfer Protocol 63"
  },
  {
    "input": "Protocol-Level Encryption and Client Certificates",
    "output": "Protocol-Level Encryption and Client Certificates\nAs should now be evident, all information in HTTP sessions is exchanged in\nplaintext over the network. In the 1990s, this would not have been a big deal:\nSure, plaintext exposed your browsing choices to nosy ISPs, and perhaps to\nanother naughty user on your office network or an overzealous government\nagency, but that seemed no worse than the behavior of SMTP, DNS, or any\nother commonly used application protocol. Alas, the growing popularity of\nthe Web as a commerce platform has aggravated the risk, and substantial net-\nwork security regression caused by the emergence of inherently unsafe pub-\nlic wireless networks put another nail in that coffin.\nAfter several less successful hacks, a straightforward solution to this\nproblem was proposed in RFC 2818:21 Why not encapsulate normal HTTP\nrequests within an existing, multipurpose Transport Layer Security (TLS, aka\nSSL) mechanism developed several years earlier? This transport method lever-\nages public key cryptography* to establish a confidential, authenticated com-\nmunication channel between the two endpoints, without requiring any\nHTTP-level tweaks.\nIn order to allow web servers to prove their identity, every HTTPS-enabled\nweb browser ships with a hefty set of public keys belonging to a variety of\ncertificate authorities. Certificate authorities are organizations that are trusted\nby browser vendors to cryptographically attest that a particular public key\nbelongs to a particular site, hopefully after validating the identity of the per-\nson who requests such attestation and after verifying his claim to the domain\nin question.\nThe set of trusted organizations is diverse, arbitrary, and not particularly\nwell documented, which often prompts valid criticisms. But in the end, the\nsystem usually does the job reasonably well. Only a handful of bloopers have\nbeen documented so far (including a recent high-profile compromise of a\ncompany named Comodo22), and no cases of widespread abuse of CA privi-\nleges are on the record.\nAs to the actual implementation, when establishing a new HTTPS con-\nnection, the browser receives a signed public key from the server, verifies the\nsignature (which can’t be forged without having access to the CA’s private\nkey), checks that the signed cn (common name) or subjectAltName fields in\nthe certificate indicate that this certificate is issued for the server the browser\nwants to talk to, and confirms that the key is not listed on a public revocation\nlist (for example, due to being compromised or obtained fraudulently). If\neverything checks out, the browser can proceed by encrypting messages to\nthe server with that public key and be certain that only that specific party will\nbe able to decrypt them.\nNormally, the client remains anonymous: It generates a temporary encryp-\ntion key, but that process does not prove the client’s identity. Such a proof\ncan be arranged, though. Client certificates are embraced internally by cer-\ntain organizations and are adopted on a national level in several countries\n* Public key cryptography relies on asymmetrical encryption algorithms to create a pair of keys: a\nprivate one, kept secret by the owner and required to decrypt messages, and a public one,\nbroadcast to the world and useful only to encrypt traffic to that recipient, not to decrypt it.\n64 Chapter 3"
  },
  {
    "input": "Error-Handling Rules",
    "output": "around the world (e.g., for e-government services). Since the usual purpose\nof a client certificate is to provide some information about the real-world\nidentity of the user, browsers usually prompt before sending them to newly\nencountered sites, for privacy reasons; beyond that, the certificate may act as\nyet another form of ambient authority.\nIt is worth noting that although HTTPS as such is a sound scheme that\nresists both passive and active attackers, it does very little to hide the evidence\nof access to a priori public information. It does not mask the rough HTTP\nrequest and response sizes, traffic directions, and timing patterns in a typical\nbrowsing session, thus making it possible for unsophisticated, passive attack-\ners to figure out, for example, which embarrassing page on Wikipedia is being\nviewed by the victim over an encrypted channel. In fact, in one extreme case,\nMicrosoft researchers illustrated the use of such packet profiling to recon-\nstruct user keystrokes in an online application.23\nExtended Validation Certificates\nIn the early days of HTTPS, many public certificate authorities relied on\nfairly pedantic and cumbersome user identity and domain ownership checks\nbefore they would sign a certificate. Unfortunately, in pursuit of convenience\nand in the interest of lowering prices, some now require little more than a\nvalid credit card and the ability to put a file on the destination server in order\nto complete the verification process. This approach renders most of the cer-\ntificate fields other than cn and subjectAltName untrustworthy.\nTo address this problem, a new type of certificate, tagged using a special\nflag, is being marketed today at a significantly higher price: Extended Validation\nSSL (EV SSL). These certificates are expected not only to prove domain own-\nership but also more reliably attest to the identity of the requesting party,\nfollowing a manual verification process. EV SSL is recognized by all modern\nbrowsers by making portion of the address bar blue or green. Although hav-\ning this tier of certificates is valuable, the idea of coupling a higher-priced\ncertificate with an indicator that vaguely implies a “higher level of security”\nisoften criticized as a cleverly disguised money-making scheme.\nError-Handling Rules\nIn an ideal world, HTTPS connections that involve a suspicious certificate\nerror, such as a grossly mismatched hostname or an unrecognized certifica-\ntion authority, should simply result in a failure to establish the connection.\nLess-suspicious errors, such as a recently expired certificate or a hostname\nmismatch, perhaps could be accompanied by just a gentle warning.\nUnfortunately, most browsers have indiscriminately delegated the\nresponsibility for understanding the problem to the user, trying hard (and\nultimately failing) to explain cryptography in layman’s terms and requiring\nthe user to make a binary decision: Do you actually want to see this page or\nnot? (Figure 3-1 shows one such prompt.)\nHypertext Transfer Protocol 65\nFigure 3-1: An example certificate warning dialog\nin the still-popular Internet Explorer 6\nThe language and appearance of SSL warnings has evolved through the\nyears toward increasingly dumbed-down (but still problematic) explanations\nof the problem and more complicated actions required to bypass the warn-\ning. This trend may be misguided: Studies show that over 50 percent of even\nthe most frightening and disruptive warnings are clicked through.24 It is easy\nto blame the users, but ultimately, we may be asking them the wrong questions\nand offering exactly the wrong choices. Simply, if it is believed that clicking\nthrough the warning is advantageous in some cases, offering to open the\npage in a clearly labeled “sandbox” mode, where the harm is limited, would\nbe a more sensible solution. And if there is no such belief, any override capa-\nbilities should be eliminated entirely (a goal sought by Strict Transport Security,\nan experimental mechanism that will be discussed in Chapter 16).\n66 Chapter 3"
  },
  {
    "input": "When Constructing Other Types of User-Controlled Requests or Responses",
    "output": "Security Engineering Cheat Sheet\nWhen Handling User-Controlled Filenames in Content-Disposition Headers\n If you do not need non-Latin characters: Strip or substitute any characters except for alpha-\nnumerics, “.”, “-”, and “_”. To protect your users against potentially harmful or deceptive\nfilenames, you may also want to confirm that at least the first character is alphanumeric\nand substitute all but the rightmost period with something else (e.g., an underscore).\nKeep in mind that allowing quotes, semicolons, backslashes, and control characters\n(0x00–0x1F) will introduce vulnerabilities.\n If you need non-Latin names: You must use RFC 2047, RFC 2231, or URL-style percent\nencoding in a browser-dependent manner. Make sure to filter out control characters\n(0x00–0x1F) and escape any semicolons, backslashes, and quotes.\nWhen Putting User Data in HTTP Cookies\n Percent-encode everything except for alphanumerics. Better yet, use base64. Stray quote\ncharacters, control characters (0x00–0x1F), high-bit characters (0x80–0xFF), commas,\nsemicolons, and backslashes may allow new cookie values to be injected or the meaning\nand scope of existing cookies to be altered.\nWhen Sending User-Controlled Location Headers\n Consult the cheat sheet in Chapter 2. Parse and normalize the URL, and confirm that the\nscheme is on a whitelist of permissible values and that you are comfortable redirecting\ntothe specified host.\nMake sure that any control and high-bit characters are escaped properly. Use Puny-\ncode for hostnames and percent-encoding for the remainder of the URL.\nWhen Sending User-Controlled Redirect Headers\n Follow the advice provided for Location. Note that semicolons are unsafe in this header\nand cannot be escaped reliably, but they also happen to have a special meaning in some\nURLs. Your choice is to reject such URLs altogether or to percent-encode the “;” charac-\nter, thereby violating the RFC-mandated syntax rules.\nWhen Constructing Other Types of User-Controlled Requests or Responses\n Examine the syntax and potential side effects of the header in question. In general, be\nmindful of control and high-bit characters, commas, quotes, backslashes, and semicolons;\nother characters or strings may be of concern on a case-by-case basis. Escape or substitute\nthese values as appropriate.\n When building a new HTTP client, server, or proxy: Do not create a new implementation\nunless you absolutely have to. If you can’t help it, read this chapter thoroughly and aim to\nmimic an existing mainstream implementation closely. If possible, ignore the RFC-provided\nadvice about fault tolerance and bail out if you encounter any syntax ambiguities.\nHypertext Transfer Protocol 67"
  },
  {
    "input": "4: Hypertext Markup Language\r",
    "output": "H Y P E R T E X T M A R K U P\nL A N G U A G E\nThe Hypertext Markup Language (HTML) is the pri-\nmary method of authoring online documents. One of\nthe earliest written accounts of this language is a brief\nsummary posted on the Internet by Tim Berners-Lee\nin 1991.1 His proposal outlines an SGML-derived syn-\ntax that allows text documents to be annotated with\ninline hyperlinks and several types of layout aids. In the following years,\nthisspecification evolved gradually under the direction of Sir Berners-Lee\nand Dan Connolly, but it wasn’t until 1995, at the onset of the First Browser\nWars, that a reasonably serious and exhaustive specification of the language\n(HTML 2.0) made it to RFC 1866.2\nFrom that point on, all hell broke loose: For the next few years, compet-\ning browser vendors kept introducing all sorts of flashy, presentation-oriented\nfeatures and tweaked the language to their liking. Several attempts to amend\nthe original RFC have been undertaken, but ultimately the IETF-managed"
  },
  {
    "input": "Basic Concepts Behind HTML Documents",
    "output": "standardization approach proved to be too inflexible. The newly formed\nWorld Wide Web Consortium took over the maintenance of the language\nand eventually published the HTML 3.2 specification in 1997.3\nThe new specification tried to reconcile the differences in browser\nimplementations while embracing many of the bells and whistles that\nappealed to the public, such as customizable text colors and variable type-\nfaces. Ultimately, though, HTML 3.2 proved to be a step back for the clarity\nof the language and had only limited success in catching up with the facts.\nIn the following years, the work on HTML 4 and 4.014 focused on prun-\ning HTML of all accumulated excess and on better explaining how document\nelements should be interpreted and rendered. It also defined an alternative,\nstrict XHTML syntax derived from XML, which was much easier to consis-\ntently parse but more punishing to write. Despite all this work, however, only\na small fraction of all websites on the Internet could genuinely claim compli-\nance with any of these standards, and little or no consistency in parsing modes\nand error recovery could be seen on the client end. Consequently, some of\nthe work on improving the core language fizzled out, and the W3C turned\nitsattention to stylesheets, the Document Object Model, and other more\nabstract or forward-looking challenges.\nIn the late 2000s, some of the low-level work has been revived under the\nbanner of HTML5,5 an ambitious project to normalize almost every aspect\nofthe language syntax and parsing, define all the related APIs, and more\nclosely police browser behavior in general. Time will tell if it will be success-\nful; until then, the language itself, and each of the four leading parsing\nengines,* come with their own set of frustrating quirks.\nBasic Concepts Behind HTML Documents\nFrom a purely theoretical standpoint, HTML relies on a fairly simple syntax:\na hierarchical structure of tags, name=value tag parameters, and text nodes\n(forming the actual document body) in between. For example, a simple doc-\nument with a title, a heading, and a hyperlink may look like this:\n<html>\n<head>\n<title>Hello world</title>\n</head>\n<body>\n<h1>Welcome to our example page</h1>\n<a href=\"http://www.example.com/\">Click me!</a>\n</body>\n</html>\n* To process HTML documents, Internet Explorer uses the Trident engine (aka MSHTML);\nFirefox and some derived products use Gecko; Safari, Chrome, and several other browsers use\nWebKit; and Opera relies on Presto. With the exception of WebKit, a collaborative open source\neffort maintained by several vendors, these engines are developed largely in-house by their\nrespective browser teams.\n70 Chapter 4"
  },
  {
    "input": "Document Parsing Modes",
    "output": "This syntax puts some constraints on what may appear inside a parame-\nter value or inside the document body. Five characters—angle brackets, sin-\ngle and double quotes, and an ampersand—are reserved as the building\nblocks of the HTML markup, and these need to be avoided or escaped in\nsome way when used outside of their intended function. The most important\nrules are:\n Stray ampersands (&) should never appear in most sections of an HTML\ndocument.\n Both types of angle brackets are obviously problematic inside a tag,\nunless properly quoted.\n The left angle bracket (<) is a hazard inside a text node.\n Quote characters appearing inside a tag can have undesirable effects,\ndepending on their exact location, but are harmless in text nodes.\nTo allow these characters to appear in problematic locations without\ncausing side effects, an ampersand-based encoding scheme, discussed in\n“Entity Encoding” on page76, is provided.\nNOTE Of course, the availability of such an encoding scheme is not a guarantee of its use.\nThe failure to properly filter out or escape reserved characters when displaying user-\ncontrolled data is the cause of a range of extremely common and deadly web application\nsecurity flaws. A particularly well-known example of this is cross-site scripting (XSS),\nan attack in which malicious, attacker-provided JavaScript code is unintentionally\nechoed back somewhere in the HTML markup, effectively giving the attacker full con-\ntrol over the appearance and operation of the targeted site.\nDocument Parsing Modes\nFor any HTML document, a top-level <!DOCTYPE> directive may be used to\ninstruct the browser to parse the file in a manner that at least superficially\nconforms to one of the officially defined standards; to a more limited extent,\nthe same signal can be conveyed by the Content-Type header, too. Of all the\navailable parsing modes, the most striking difference exists between XHTML\nand traditional HTML. In the traditional mode, parsers will attempt to recover\nfrom most types of syntax errors, including unmatched opening and closing\ntags. In addition, tag and parameter names will be considered case insensi-\ntive, parameter values will not always need to be quoted, and certain types of\ntags, such as <img>, will be closed implicitly. In other words, the following\ninput will be grudgingly tolerated:\n<hTmL>\n<BODY>\n<IMG src=\"/hello_world.jpg\">\n<a HREF=http://www.example.com/>\nClick me!\n</oops>\n</html>\nHypertext Markup Language 71"
  },
  {
    "input": "The Battle over Semantics",
    "output": "The XML mode, on the other hand, is strict: All tags need to be balanced\ncarefully, named using the proper case, and closed explicitly. (The XML-\nspecific self-closing tag syntax, such as <img />, is permitted.) In addition,\nmost syntax mistakes, even trivial ones, will result in an error and prevent the\ndocument from being displayed at all.\nUnlike the regular flavor of HTML, XML-based documents may also ele-\ngantly incorporate sections using other XML-compliant markup formats,\nsuch as MathML, a mathematical formula markup language. This is done by\nspecifying a different xmlns namespace setting for a particular tag, with no\nneed for one-off, language-level hacks.\nThe last important difference worth mentioning here is that traditional\nHTML parsing strategies feature a selection of special modes, entered into\nafter certain tags are encountered and exited only when a specific terminator\nstring is seen; everything in between is interpreted as non-HTML text. Some\nexamples of such special tags include <style>, <script>, <textarea>, or <xmp>. In\npractical implementations, these modes are exited only when a literal, case-\ninsensitive match on </style, </script, or a similar matching value, is made; any\nother markup inside such a block will not be interpreted as HTML. (Interest-\ningly, there is one officially obsolete tag, <plaintext>, that cannot be exited at\nall; it stays in effect for the remainder of the document.)\nIn comparison, the XML mode is more predictable. It generally forbids\nstray “<” and “&” characters inside the document, but it provides a special\nsyntax, starting with “<![CDATA[” and ending with “]]>”, as a way to encap-\nsulate any raw text inside an arbitrary tag. For example:\n<script>\n<![CDATA[\nalert('>>> Hello world! <<<');\n]]>\n</script>\nThe other notable special parsing mode available in both XHTML and\nnormal HTML is a comment block. In XML, it quite simply begins with “<!--”\nand ends with “-->”. In the traditional HTML parser in Firefox versions prior\nto 4, any occurrence of “--”, later followed by “>”, is also considered good\nenough.\nThe Battle over Semantics\nThe low-level syntax of the language aside, HTML is also the subject of a fas-\ncinating conceptual struggle: a clash between the ideology and the reality of\nthe online world. Tim Berners-Lee always championed the vision of a semantic\nweb, an interconnected system of documents in which every functional block,\nsuch as a citation, a snippet of code, a mailing address, or a heading, has its\nmeaning explained by an appropriate machine-readable tag (say, <cite>, <code>,\n<address>, or <h1> to <h6>).\n72 Chapter 4"
  },
  {
    "input": "Understanding HTML Parser Behavior",
    "output": "This approach, he and other proponents argued, would make it easier\nfor machines to crawl, analyze, and index the content in a meaningful way,\nand in the near future, it would enable computers to reason using the sum\nofhuman knowledge. According to this philosophy, the markup language\nshould provide a way to stylize the appearance of a document, but only as\nanafterthought.\nSir Berners-Lee has never given up on this dream, but in this one regard,\nthe actual usage of HTML proved to be very different from what he wished for.\nWeb developers were quick to pragmatically distill the essence of HTML3.2\ninto a handful of presentation-altering but semantically neutral tags, such as\n<font>, <b>, and <pre>, and saw no reason to explain further the structure of\ntheir documents to the browser. W3C attempted to combat this trend but with\nlimited success. Although tags such as <font> have been successfully obso-\nleted and largely abandoned in favor of CSS, this is only because stylesheets\noffered more powerful and consistent visual controls. With the help of CSS,\nthe developers simply started relying on a soup of semantically agnostic <span>\nand <div> tags to build everything from headings to user-clickable buttons, all\nin a manner completely opaque to any automated content extraction tools.\nDespite having had a lasting impact on the design of the language, in\nsome ways, the idea of a semantic web may be becoming obsolete: Online\ncontent less frequently maps to the concept of a single, viewable document,\nand HTML is often reduced to providing a convenient drawing surface and\ngraphic primitives for JavaScript applications to build their interfaces with.\nUnderstanding HTML Parser Behavior\nThe fundamentals of HTML syntax outlined in the previous sections are usu-\nally enough to understand the meaning of well-formed HTML and XHTML\ndocuments. When the XHTML dialect is used, there is little more to the\nstory: The minimal fault-tolerance of the parser means that anomalous syn-\ntax almost always leads simply to a parsing error. Alas, the picture is very dif-\nferent with traditional, laid-back HTML parsers, which aggressively second-\nguess the intent of the page developer even in very ambiguous or potentially\nharmful situations.\nSince an accurate understanding of user-supplied markup is essential to\ndesigning many types of security filters, let’s have a quick look at some of these\nbehaviors and quirks. To begin, consider the following reference snippet:\n<img src=image.jpg title=\"Hello world\" class=examples>\n(cid:2) (cid:3) (cid:4) (cid:5) (cid:6) (cid:7)\nWeb developers are usually surprised to learn that this syntax can be drasti-\ncally altered without changing its significance to the browser. For example,\nInternet Explorer will allow an NUL character (0x00) to be inserted in the\nlocation marked at , a change that is likely to throw all naïve HTML filters\noff the trail. It is also not widely known that the whitespaces at  and  can\nHypertext Markup Language 73"
  },
  {
    "input": "Interactions Between Multiple Tags",
    "output": "be substituted with uncommon vertical tab (0x0B) or form feed (0x0C) char-\nacters in all browsers and with a nonbreaking UTF-8 space (0xA0) in Opera.*\nOh, and here's a really surprising bit: In Firefox, the whitespace at  can also\nbe replaced with a single, regular slash—yet the one at  can’t.\nMoving on, the location marked  is also of note. In this spot, NUL\ncharacters are ignored by most parsers, as are many types of whitespaces. Not\nlong ago, WebKit browsers accepted a slash in this location, but recent parser\nimprovements have eliminated this quirk.\nQuote characters are a yet another topic of interest. Website developers\nknow that single and double quotes can be used to put a string containing\nwhitespaces or angle brackets in an HTML parameter, but it usually comes as\na surprise that Internet Explorer also honors backticks (`) instead of real\nquotes in the location marked . Similarly, few people realize that in any\nbrowser, an implicit whitespace is inserted after a quoted parameter, and\nthat the explicit whitespace at  can therefore be skipped without changing\nthe meaning of the tag.\nThe security impact of these patterns is not always easy to appreciate, but\nconsider an HTML filter tasked with scrubbing an <img> tag with an attacker-\ncontrolled title parameter. Let’s say that in the input markup, this parameter\nis not quoted if it contains no whitespaces and angle brackets—a design that\ncan be seen on a popular blogging site. This practice may appear safe at first,\nbut in the following two cases, a malicious, injected onerror parameter will\nmaterialize inside a tag:\n<img ... title=\"\"onerror=\"alert(1)\">\nand\n<img ... title=``onerror=`alert(1)`>\nYet another wonderful quote-related quirk in Internet Explorer makes\nthis job even more complicated. While most browsers recognize quoting only\nwhen it is used at the beginning of a parameter value, Internet Explorer sim-\nply checks for any occurrence of an equal sign (=) followed by a quote and\nwill parse this syntax in a rather unexpected way:\n<img src=test.jpg?value=\">Yes, we are still inside a tag!\">\nInteractions Between Multiple Tags\nParsing a single tag can be a daunting task, but as you might imagine, anom-\nalous arrangements of multiple HTML tags will be even less predictable.\nConsider the following trivial example:\n<i <b>\n* The behavior exhibited by Opera is particularly sneaky: The Unicode whitespace is not\nrecognized by many standard library functions used in server-side HTML sanitizers, such as\nisspace(...) in libc. This increases the risk of implementation glitches.\n74 Chapter 4"
  },
  {
    "input": "Explicit and Implicit Conditionals",
    "output": "When presented with such syntax, most browsers only interpret <i> and\ntreat the “<b” string as an invalid tag parameter. Firefox versions before 4,\nhowever, would automatically close the <i> tag first when encountering an\nangle bracket and, in the end, will interpret both <i> and <b>. In the spirit of\nfault tolerance, until recently WebKit followed that model, too.\nA similar behavior can be observed in previous versions of Firefox when\ndealing with tag names that contain invalid characters (in this case, the equal\nsign). Instead of doing its best to ignore the entire block, the parser would\nsimply reset and interpret the quoted tag:\n<i=\"<b>\">\nThe handling of tags that are not closed before the end of the file is\nequally fascinating. For example, the following snippet will prompt most\nbrowsers to interpret the <i> tag or ignore the entire string, but Internet\nExplorer and Opera use a different backtracking approach and will see <b>\ninstead:\n<i foo=\"<b>\" [EOF]\nIn fact, Firefox versions prior to version 4 engaged in far-fetched repars-\ning whenever particular special tags, such as <title>, were not closed before\nthe end of the document:\n<title>This text will be interpreted as a title\n<i>This text will be shown as document body!\n[EOF]\nThe last two parsing quirks have interesting security consequences in any\nscenario where the attacker may be able to interrupt page load prematurely.\nEven if the markup is otherwise fairly well sanitized, the meaning of the doc-\nument may change in a very unexpected way.\nExplicit and Implicit Conditionals\nTo further complicate the job of HTML parsing, some browsers exhibit behav-\niors that can be used to conditionally skip some of the markup in a document.\nFor example, in an attempt to help novice users of Microsoft’s Active Server\nPages development platform, Internet Explorer treats <% … %> blocks as a\ncompletely nonstandard comment, hiding any markup between these two\ncharacter sequences. Another Internet Explorer–specific feature is explicit\nconditional expressions interpreted by the parser and smuggled inside stan-\ndard HTML comment blocks:\n<!--[if IE 6]>\nMarkup that will be parsed only for Internet Explorer 6\n<![endif]-->\nHypertext Markup Language 75"
  },
  {
    "input": "Entity Encoding",
    "output": "Many other quirks of this type are related to the idiosyncrasies of SGML\nand XML. For example, due to the comment-handling behavior mentioned\nearlier in an aside, browsers disagree on how to parse !- and ?-directives (such\nas <!DOCTYPE> or <?xml>), whether to allow XML-style CDATA blocks in\nnon-XHTML modes, and on what precedence to give to overlapping special\nparsing mode tags (such as “<style><!-- </style> -->”).\nHTML Parsing Survival Tips\nThe set of parsing behaviors discussed in the previous sections is by no means\nexhaustive. In fact, an entire book has been written on this topic: Inquisitive\nreaders are advised to grab Web Application Obfuscation (Syngress, 2011) by\nMario Heiderich, Eduardo Alberto Vela Nava, Gareth Heyes, and David\nLindsay—and then weep about the fate of humanity. The bottom line is\nthatbuilding HTML filters that try to block known dangerous patterns,\nandallow the remaining markup as is, is simply not feasible.\nThe only reasonable approach to tag sanitization is to employ a realistic\nparser to translate the input document into a hierarchical in-memory docu-\nment tree, and then scrub this representation for all unrecognized tags and\nparameters, as well as any undesirable tag/parameter/value configurations.\nAt that point, the tree can be carefully reserialized into a well-formed, well-\nescaped HTML that will not flex any of the error correction muscles in the\nbrowser itself. Many developers think that a simpler design should be possi-\nble, but eventually they discover the reality the hard way.\nEntity Encoding\nLet’s talk about character encoding again. As noted on the first pages of this\nchapter, certain reserved characters are generally unsafe inside text nodes\nand tag parameter values, and they will often lead to outright syntax errors\ninXHTML. In order to allow such characters to be used safely (and to allow\na convenient way to embed high-bit text), a simple ampersand-prefixed,\nsemicolon-terminated encoding scheme, known as entity encoding, is avail-\nable to developers.\nThe most familiar use of this encoding method is the inclusion of certain\npredefined, named entities. Only a handful of these are specified for XML,\nbut several hundred more are scattered in HTML specifications and sup-\nported by all modern browsers. In this approach, &lt; is used to insert a left\nangle bracket; &gt; substitutes a right angle bracket; &amp; replaces the\nampersand itself; while, say, &rarr; is a nice Unicode arrow.\nNOTE In XHTML documents, additional named entities can be defined using the <!ENTITY>\ndirective and made to resolve to internally defined strings or to the contents of an exter-\nnal file URL. (This last option is obviously unsafe if allowed when processing untrusted\ncontent; the resulting attack is sometimes called External XML Entity, or XXE for\nshort.)\n76 Chapter 4\nIn addition to the named entities, it is also possible to insert an arbitrary\nASCII or Unicode character using a decimal &#number; notation. In this\ncase, &#60; maps to a left angle bracket; &#62; substitutes a right one; and\n&#128569; is, I kid you not, a Unicode 6.0 character named “smiling cat face\nwith tears of joy.” Hexadecimal notation can also be used if the number is\nprefixed with “x”. In this variant, the left angle bracket becomes &#x3c;, etc.\nThe HTML parser recognizes entity encoding inside text nodes and\nparameter values and decodes it transparently when building an in-memory\nrepresentation of the document tree. Therefore, the following two cases are\nfunctionally identical:\n<img src=\"http://www.example.com\">\nand\n<img src=\"ht&#x74;p&#x3a;//www.example.com\">\nThe following two examples, on the other hand, will not work as\nexpected, as the encoding interferes with the structure of the tag itself:\n<img src&#x3d;\"http://www.example.com\">\nand\n<img s&#x72;c=\"http://www.example.com\">\nThe largely transparent behavior of entity encoding makes it important\nto correctly resolve it prior to making any security decisions about the con-\ntents of a document and, if applicable, to properly restore it in the sanitized\noutput later on. To illustrate, the following syntax must be recognized as an\nabsolute reference to a javascript: pseudo-URL and not to a cryptic fragment\nID inside a relative resource named “./javascript&”:\n<a href=\"javascript&#x3a;alert(1)\">\nUnfortunately, even the simple task of recognizing and parsing HTML\nentities can be tricky. In traditional parsing, for example, entities may often\nbe accepted even if the trailing semicolon is omitted, as long as the next\ncharacter is not an alphanumeric. (In Firefox, dashes and periods are also\naccepted in entity names.) Numeric entities are even more problematic, as\nthey may have an overlong notation with an arbitrary number of trailing\nzeros. Moreover, if the numerical value is higher than 232, the standard size\nof an integer on many computer architectures, the corresponding character\nmay be computed incorrectly.\nHypertext Markup Language 77"
  },
  {
    "input": "HTTP/HTML Integration Semantics",
    "output": "Developers working with XHTML should be aware of a potential pitfall\nin that dialect, too. Although HTML entities are not recognized in most of\nthe special parsing modes, XHTML differs from traditional HTML in that\ntags such as <script> and <style> do not automatically toggle a special parsing\nmode on their own. Instead, an explicit <![CDATA[…]]> block around any\nscripts or stylesheets is required to achieve a comparable effect. Therefore,\nthe following snippet with an attacker-controlled string (otherwise scrubbed\nfor angle brackets, quotes, backslashes, and newlines) is perfectly safe in\nHTML, but not in XHTML:\n<script>\nvar tmp = 'I am harmless! &#x27;+alert(1);// Or am I?';\n...\n</script>\nHTTP/HTML Integration Semantics\nFrom Chapter 3, we recall that HTTP headers may give new meaning to the\nentire response (Location, Transfer-Encoding, and so on), change the way the\npayload is presented (Content-Type, Content-Disposition), or affect the client-\nside environment in other, auxiliary ways (Refresh, Set-Cookie, Cache-Control,\nExpires, etc.).\nBut what if an HTML document is delivered through a non-HTTP proto-\ncol or loaded from a local file? Clearly, in this case, there is no simple way to\nexpress or preserve this information. We can part with some of it easily, but\nparameters such as the MIME type or the character set are essential, and los-\ning them forces browsers to improvise later on. (Consider, for example, that\ncharsets such as UTF-7, UTF-16, and UTF-32 are not ASCII-compatible and,\ntherefore, HTML documents can’t even be parsed without determining\nwhich of these transformations needs to be used.)\nThe security consequences of the browser-level heuristics used to detect\ncharacter sets and document types will be explored in detail in Chapter 13.\nMeanwhile, the problem of preserving protocol-level information within a\ndocument is somewhat awkwardly addressed by a special HTML directive,\n<meta http-equiv=...>. By the time the browser examines the markup, many\ncontent-handling decisions must have already been made, but some tweaks\nare still on the table; for example, it may be possible to adjust the charset to\nagenerally compatible value or to specify Refresh, Set-Cookie, and caching\ndirectives.\nAs an illustration of permissible syntax, consider the following directive\nthat, when appearing in an 8-bit ASCII document, will clarify for the browser\nthat the charset of the document is UTF-8 and not, say, ISO-8859-1:\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n78 Chapter 4"
  },
  {
    "input": "Plain Links",
    "output": "On the flip side, all of the following directives will fail, because at this point\nit is too late to switch to an incompatible UTF-32 encoding, change the docu-\nment type to a video format, or execute a redirect instead of parsing the file:\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-32\">\n<meta http-equiv=\"Content-Type\" content=\"video/mpeg\">\n<meta http-equiv=\"Location\" content=\"http://www.example.com\">\nBe mindful that when http-equiv values conflict with each other, or con-\ntradict the HTTP headers received from the server earlier on, their behavior\nis not consistent and should not be relied upon. For example, the first sup-\nported charset= value usually prevails (and HTTP headers have precedence\nover <meta> in this case), but with several conflicting Refresh values, the behav-\nior is highly browser-specific.\nNOTE Some browsers will attempt to speculatively extract <meta http-equiv> information\nbefore actually parsing the document, which may lead to embarrassing mistakes. For\nexample, a security bug recently fixed in Firefox 4 caused the browser to interpret the\nfollowing statement as a character set declaration: <meta http-equiv=\"Refresh\"\ncontent=\"10;http://www.example.com/charset=utf-7\">.6\nHyperlinking and Content Inclusion\nOne of the most important and security-relevant features of HTML is,\npredictably, the ability to link to and embed external content. HTTP-level\nfeatures such as Location and Refresh aside, this can be accomplished in a\ncouple of straightforward ways.\nPlain Links\nThe following markup demonstrates the most familiar and most basic\nmethod for referencing external content from within a document:\n<a href=\"http://www.example.com/\">Click me!</a>\nThis hyperlink may point to any of the browser-recognized schemes,\nincluding pseudo-URLs (data:, javascript:, and so on) and protocols handled\nby external applications (such as mailto:). Clicking on the text (or any HTML\nelements) nested inside such a <a href=...> block will typically prompt the\nbrowser to navigate away from the linking document and go to the specified\nlocation, if meaningfully possible for the protocol used.\nAn optional target parameter may be used to target other windows or\ndocument views for navigation. The parameter must specify the name of the\ntarget view. If the name cannot be found, or if access is denied, the default\nbehavior is typically to open a new window instead. The conditions in which\naccess may be denied are the topic of Chapter 11.\nHypertext Markup Language 79"
  },
  {
    "input": "Forms and Form-Triggered Requests",
    "output": "Four special target names can be used, too (as shown on the left of Fig-\nure 4-1): _blank always opens a brand-new window, _parent navigates a higher-\nlevel view that embeds the link-bearing document (if any), and _top always nav-\nigates the top-level browser window, no matter how many document embed-\nding levels are in between. Oh, right, the fourth special target, _self, is identical\nto not specifying a value at all and exists for no reason whatsoever.\nBunny Browser 2000 Bunny Browser 2000\nhttp://fuzzybunnies.com\n_top _blank\n_parent\n_self (default)\n<a href=...target=...>\nFigure 4-1: Predefined targets for hyperlinks\nForms and Form-Triggered Requests\nAn HTML form can be thought of as an information-gathering hyperlink:\nWhen the “submit” button is clicked, a dynamic request is constructed on the\nfly from the data collected via any number of input fields. Forms allow user\ninput and files to be uploaded to the server, but in almost every other way,\nthe result of submitting a form is similar to following a normal link.\nA simple form markup may look like this:\n<form method=GET action=\"/process_form.cgi\">\nGiven name: <input type=text name=given>\nFamily name: <input type=text name=family>\n...\n<input type=submit value=\"Click here when done!\">\n</form>\nThe action parameter works like the href value used for normal links, with\none minor difference: If the value is absent, the form will be submitted to the\nlocation of the current document, whereas any destination-free <a> links will\nsimply not work at all. An optional target parameter may also be specified and\nwill behave as outlined in the previous section.\nNOTE Unusually, unlike <a> tags, forms cannot be nested inside each other, and only the top-\nlevel <form> tag will remain operational in such a case.\nWhen the method value is set to GET or is simply not present at all, all the\nnested field names and their current values will be escaped using the familiar\npercent-encoding scheme outlined in Chapter 2, but with two rather arbitrary\ndifferences. First, the space character (0x20) will be substituted with the plus\n80 Chapter 4\nsign, rather than encoded as “%20”. Second, following from this, any existing\nplus signs need to be encoded as “%2B”, or else they will be misinterpreted\nas spaces.\nEncoded name=value pairs are then delimited with ampersands and com-\nbined into a single string, such as this:\ngiven=Erwin+Rudolf+Josef+Alexander&family=Schr%C3%B6dinger\nThe resulting value is inserted into the query part of the destination URL\n(replacing any existing contents of that section) and submitted to the server.\nThe received response is then shown to the user in the targeted viewport.\nThe situation is a bit more complicated if the method parameter is set to\nPOST. For that type of HTTP request, three data submission formats are avail-\nable. In the default mode (referred to as application/x-www-form-urlencoded),\nthe message is constructed the same way as for GET but is transmitted in the\nrequest payload instead, leaving the query string and all other parts of the\ndestination URL intact.*\nThe existence of the second POST submission mode, triggered by speci-\nfying enctype=\"text/plain\" on the <form> tag, is difficult to justify. In this mode,\nfield names and values will not be percent encoded at all (but, depending on\nthe browser, plus signs may be used to substitute for spaces), and a newline\ndelimiter will be used in place of an ampersand. The resulting format is essen-\ntially useless, as it can’t be parsed unambiguously: Form-originating newlines\nand equal signs are indistinguishable from browser inserted ones.\nThe last mode is triggered with enctype=\"multipart/form-data\" and must be\nused whenever submitting user-selected files through a form (which is possi-\nble with a special <input type=\"file\"> tag). The resulting request body consists\nof a series of short MIME messages corresponding to every submitted field.†\nThese messages are delimited with a client-selected random, unique bound-\nary token that should otherwise not appear in the encapsulated data:\nPOST /process_form.cgi HTTP/1.1\n…\nContent-Type: multipart/form-data; boundary=random1234\n--random1234\nContent-Disposition: form-data; name=\"given\"\nErwin Rudolf Josef Alexander\n--random1234\nContent-Disposition: form-data; name=\"family\"\n* This has the potential for confusion, as the same parameter may appear both in the query string\nand in the POST payload. There is no consistency in how various server-side web applications\nframeworks resolve this conflict.\n† MIME (Multipurpose Internet Mail Extensions) is a data format intended for encapsulating\nand safely transmitting various types of documents in email messages. The format makes several\nunexpected appearances in the browser world. For example, Content-Type file format identifiers\nalso have unambiguous MIME roots.\nHypertext Markup Language 81"
  },
  {
    "input": "Type-Specific Content Inclusion",
    "output": "Schrödinger\n--random1234\nContent-Disposition: form-data; name=\"file\"; filename=\"cat_names.txt\"\nContent-Type: text/plain\n(File contents follow)\n--random1234--\nDespite the seemingly open-ended syntax of the tag, other request\nmethods and submission formats are not supported by any browser, and\nthisis unlikely to change. For a short while, the HTML5 standard tried to\nintroduce PUT and DELETE methods in forms, but this proposal was quickly\nshot down.\nFrames\nFrames are a form of markup that allows the contents of one HTML docu-\nment to be displayed in a rectangular region of another, embedding page.\nSeveral framing tags are supported by modern browsers, but the most com-\nmon way of achieving this goal is with a hassle-free and flexible inline frame:\n<iframe src=\"http://www.example.com/\"></iframe>\nIn traditional HTML documents, this tag puts the parser in one of the\nspecial parsing modes, and all text between the opening and the closing tag\nwill simply be ignored in frame-aware browsers. In legacy browsers that do\nnot understand <iframe>, the markup between the opening and closing tags\nis processed normally, however, offering a decidedly low-budget, conditional\nrendering directive. This conditional behavior is commonly used to provide\ninsightful advice such as “This page must be viewed in a browser that sup-\nports frames.”\nThe frame is a completely separate document view that in many aspects\nis identical to a new browser window. (It even enjoys its own JavaScript execu-\ntion context.) Like browser windows, frames can be equipped with a name\nparameter and then targeted from <a> and <form> tags.\nThe constraints on the src URL for framed content are roughly similar to\nthe rules enforced on regular links. This includes the ability to point frames\nto javascript: or to load externally handled protocols that leave the frame\nempty and open the target application in a new process.\nFrames are of special interest to web security, as they allow almost uncon-\nstrained types of content originating from unrelated websites to be com-\nbined onto a single page. We will have a second look at the problems\nassociated with this behavior in Chapter 11.\nType-Specific Content Inclusion\nIn addition to content-agnostic link navigation and document framing, HTML\nalso provides multiple ways for a more lightweight inclusion of several pre-\ndefined types of external content.\n82 Chapter 4\nImages\nImage files can be retrieved and displayed on a page using <img> tags, via\nstylesheets, and through a legacy background= parameter on markup such\nas <body> or <table>.\nThe most popular image type on the Internet is a lossy but very effi-\ncient JPEG file, followed by lossless and more featured (but slower) PNG.\nAn increasingly obsolete lossless GIF format is also supported by every\nbrowser, and so is the rarely encountered and usually uncompressed Win-\ndows bitmap file (BMP). An increasing number of rendering engines\nsupport SVG, an XML-based vector graphics and animation format, too,\nbut the inclusion of such images through the <img> tag is subject to addi-\ntional restrictions.\nThe list of recognized image types can be wrapped up with odds and\nends such as Windows metafiles (WMF and EMF), Windows Media Photo\n(WDP and HDP), Windows icons (ICO), animated PNG (APNG), TIFF\nimages, and—more recently—WebP. Browser support for these is far\nfrom universal, however.\nCascading stylesheets\nThese text-based files can be loaded with a <link rel=stylesheet href=...>\ntag—even though <style src=...> would be a more intuitive choice—and\nmay redefine the visual aspects of almost any other HTML tag within their\nparent document (and in some cases, even include embedded JavaScript).\nThe syntax and function of CSS are the subject of Chapter 5.\nIn the absence of the appropriate charset value in the Content-Type\nheader for the downloaded stylesheet, the encoding according to which\nthis subresource will be interpreted can be specified by the including\nparty through the charset parameter of the <link> tag.\nScripts\nScripts are text-based programs included with <script> tags andare exe-\ncuted in a manner that gives them full control over the host document.\nThe primary scripting language for the Web is JavaScript, although an\nembedded version of Visual Basic is also supported in Internet Explorer\nand can be used at will. Chapter 6 takes an in-depth look at client-side\nscripts and their capabilities.\nAs with CSS, in the absence of valid Content-Type data, the charset\naccording to which the script is interpreted may be controlled by the\nincluding party.\nPlug-in content\nThis category spans miscellaneous binary files included with <embed> or\n<object> tags or via an obsolete, Java-specific <applet> tag. Browser plug-in\ncontent follows its own security rules, which are explored to some extent in\nChapters 8 and 9. In many cases, it is safe to consider plug-in-supported\ncontent as equivalent to or more powerful than JavaScript.\nHypertext Markup Language 83"
  },
  {
    "input": "A Note on Cross-Site Request Forgery",
    "output": "NOTE The standard permits certain types of browser-supported documents, such as text/html\nor text/plain, to be loaded through <object> tags, in which case they form a close\nequivalent of <iframe>. This functionality is not used in practice, and the rationale\nbehind it is difficult to grasp.\nOther supplementary content\nThis category includes various rendering cues that may or may not be\nhonored by the browser; they are most commonly provided through\n<link> directives. Examples include website icons (known as “favicons”),\nalternative versions of a page, and chapter navigation links.\nSeveral other once-supported content inclusion methods, such as the\n<bgsound> tag for background music, were commonplace in the past but have\nfallen out of grace. On the other hand, as a part of HTML5, new tags such as\n<video> and <audio> are expected to gain popularity soon.\nThere is relatively little consistency in what URL schemes are accepted\nfor type-specific content retrieval. It should be expected that protocols routed\nto external applications will be rejected, as they do not have a sensible mean-\ning in this context, but beyond this, not many assumptions should be made.\nAs a security precaution, most browsers will also reject scripting-related schemes\nwhen loading images and stylesheets, although Internet Explorer 6 and Opera\ndo not follow this practice. As of this writing, javascript: URLs are also permit-\nted on <embed> and <applet> tags in Firefox but not, for example, on <img>.\nFor almost all of the type-specific content inclusion methods, Content-Type\nand Content-Disposition headers provided by the server will typically be ignored\n(perhaps except for the charset= value), as may be the HTTP response code\nitself. It is best to assume that whenever the body of any server-provided\nresource is even vaguely recognizable as one of the data formats enumerated\nin this section, it may be interpreted as such.\nA Note on Cross-Site Request Forgery\nOn all types of cross-domain navigation, the browser will transparently include\nany ambient credentials; consequently, to the server, a request legitimately\noriginating from its own client-side code will appear roughly the same as a\nrequest originating from a rogue third-party site, and it may be granted the\nsame privileges.\nApplications that fail to account for this possibility when processing any\nsensitive, state-changing requests are said to be vulnerable to cross-site request\nforgery (XSRF or CSRF). This vulnerability can be mitigated in a number of\nways, the most common of which is to include a secret user- and session-\nspecific value on such requests (as an additional query parameter or a hid-\nden form field). The attacker will not be able to obtain this value, as read\naccess to cross-domain documents is restricted by the same-origin policy\n(seeChapter 9).\n84 Chapter 4"
  },
  {
    "input": "When Converting HTML to Plaintext",
    "output": "Security Engineering Cheat Sheet\nGood Engineering Hygiene for All HTML Documents\n Always output consistent, valid, and browser-supported Content-Type and charset informa-\ntion to prevent the document from being interpreted contrary to your original intent.\nWhen Generating HTML Documents with Attacker-Controlled Bits\nThis task is difficult to perform consistently across the entire web application, and it is one of\nthe most significant sources of web application security flaws. Consider using context-sensitive\nauto-escaping frameworks, such as JSilver or CTemplate, to automate it. If that is not possible,\nread on.\n User-supplied content in text body: Always entity-encode “<”, “>”, and “&”. Note that cer-\ntain other patterns may be dangerous in certain non-ASCII-compatible output encodings.\nIf applicable, consult Chapter 13.\nKeep in mind that some Unicode metacharacters (e.g., U+202E) alter the direction\norflow of the subsequent text. It may be desirable to remove them in particularly sensi-\ntive uses.\n Tag-specific style and on* parameters: Multiple levels of escaping are required. This prac-\ntice is extremely error prone, meaning not really something to attempt. If it is absolutely\nunavoidable, review the cheat sheets in Chapters 5 and 6.\n All other HTML parameter values: Always use quotes around attacker-controlled input.\nEntity-encode “<”, “>”, “&”, and any stray quotes. Remember that some parameters\nrequire additional validation. For URLs, see the cheat sheet in Chapter 2.\nNever attempt to blacklist known bad values in URLs or any other parameters; doing\nso will backfire and may lead to script execution flaws.\n Special parsing modes (e.g., <script> and <style> blocks): For values appearing inside\nquoted strings, replace quote characters, backslash, “<”, “>”, and all nonprintable charac-\nters with language-appropriate escape codes. For values appearing outside strings, exer-\ncise extreme caution and allow only carefully validated, known, alphanumeric values.\nIn XHTML mode, remember to wrap the entire script section in a CDATA block.\nAvoid cases that require multiple levels of encoding, such as building parameters to the\nJavaScript eval(...) function using attacker-supplied strings. Never place user-controlled\ndata inside HTML comments, !-type or ?-type tags, and other nonessential or unusually\nparsed blocks.\nWhen Converting HTML to Plaintext\n A common mistake is to strip only well-formed tags. Remember that all left-angle brackets\nmust be removed, even if no matching right-angle bracket is found. To minimize the risk\nof errors, always entity-escape angle brackets and ampersands in the generated output, too.\nHypertext Markup Language 85"
  },
  {
    "input": "When Writing a Markup Filter for User Content",
    "output": "When Writing a Markup Filter for User Content\n Read this chapter carefully. Use a reasonably robust HTML parser to build an in-memory\ndocument tree. Walk the tree, removing any unrecognized or unnecessary tags and\nparameters and scrubbing any undesirable tags/parameters/value combinations.\nWhen done, reserialize the document, making sure to apply proper escaping rules to\nparameter values and text content. (See the first tip on this cheat sheet.) Be aware of the\nimpact of special parsing modes.\n Because of the somewhat counterintuitive namespace interactions with JavaScript, do\nnotallow name and id parameters on user-supplied markup—at least not without reading\nChapter 6 first.\n Do not attempt to sanitize an existing, serialized document in place. Doing so inevitably\nleads to security problems.\n86 Chapter 4"
  },
  {
    "input": "5: Cascading Style Sheets\r",
    "output": "C A S C A D I N G S T Y L E S H E E T S\nAs the Web matured through the 1990s, website devel-\nopers increasingly needed a consistent and flexible way\nto control the appearance of HTML documents; the\ncollection of random, vendor-specific tag parameters\navailable at the time simply would not do. After review-\ning several competing proposals, W3C eventually set-\ntled on Cascading Style Sheets (CSS), a fairly simple text-\nbased page appearance description language proposed\nby Håkon Wium Lie.\nThe initial CSS level 1 specification saw the light of day by the end of\n1996,1 but further revisions of this document continued until 2008. The ini-\ntial draft of CSS level 2 followed in December 1998 and has yet to be finalized\nas of 2011. The work on the most recent iteration, level 3, started in 2005 and\nalso continues to this day. Although most of the individual features envisioned\nfor CSS2 and CSS3 have been adopted by all modern browsers after years of\ntrial and error, many subtle details vary significantly from one implementation\nto another, and the absence of a finalized standard likely contributes to this."
  },
  {
    "input": "Basic CSS Syntax",
    "output": "Despite the differences from one browser to another, CSS is a very pow-\nerful tool. With only a couple of constraints, stylesheets permit almost every\nHTML tag to be scaled, positioned, and decorated nearly arbitrarily, thereby\novercoming the constraints originally placed on it by the underlying markup\nlanguage; in some implementations, JavaScript programs can be embedded\nin the CSS presentation directives as well. The job of placing user-controlled\nvalues inside stylesheets, or recoding any externally provided CSS, is there-\nfore of great interest to web application security.\nBasic CSS Syntax\nStylesheets can be placed in an HTML document in three ways: inlined glo-\nbally for the entire document with a <style> block, retrieved from an external\nURL via the <link rel=stylesheet> directive, or attached to a specific tag using\nthe style parameter. In addition, XML-based documents (including XHTML)\nmay also leverage a little-known <?xml-stylesheet href=... ?> directive to achieve\nthe same goal.\nThe first two methods of inclusion require a fully qualified stylesheet\nconsisting of any number of selectors (directives describing which HTML\ntags the following ruleset will apply to) followed by semicolon-delimited\nname: value rules between curly brackets. Here is a simple example of such\nsyntax, defining the appearance of <img>, <span>, and <div> tags:\nimg {\nborder-size: 1px;\nborder-style: solid;\n}\nspan, div {\ncolor: red;\n}\nSelectors can reference a particular type of a tag (such as img), a\nperiod-prefixed name of a class of tags (for example, .photos, which will apply\nto all tags with an inline class=photos parameter), or a combination of both\n(img.company_logo). Selector suffixes such as :hover or :visited may also be used\nto make the selector match only under certain circumstances, such as when\nthe mouse hovers over the content or when a particular displayed hyperlink\nhas already been visited before.\nSo-called complex selectors2 are an interesting feature introduced in CSS2\nand extended in CSS3. They allow any given ruleset to apply only to tags with\nparticular strings appearing in parameter values or that are positioned in a par-\nticular relation to other markup. One example of such a selector is this:\na[href^=\"ftp:\"] {\n/* Styling applicable only to FTP links. */\n}\n88 Chapter 5"
  },
  {
    "input": "@ Directives and XBL Bindings",
    "output": "NOTE Oh, while we are at it: As evident in this example, C-style /*...*/ comment blocks are\npermitted in CSS syntax anywhere outside a quoted string. On the flip side, //-style\ncomments are not recognized at all.\nProperty Definitions\nInside the { … } block that follows a selector, as well as inside the style param-\neter attached to a specific tag, any number of name: value rules can be used to\nredefine almost every aspect of how the affected markup is displayed. Visibil-\nity, shape, color, screen position, rendering order, local or remote typeface,\nand even any additional text (content property supported on certain pseudo-\nclasses) and mouse cursor shape are all up for grabs.* Simple types of auto-\nmation, such as counters for numbered lists, are available through CSS rules\nas well.\nProperty values can be formatted as the following:\n Raw text This method is used chiefly to specify numerical values (with\noptional units), RGB vectors and named colors, and other predefined\nkeywords (“absolute,” “left,” “center,” etc.).\n Quoted strings Single or double quotes should be placed around\nanynonkeyword values, but there is little consistency in how this rule is\nenforced. For example, quoting is not required around typeface names\nor certain uses of URLs, but it is necessary for the aforementioned content\nproperty.\n Functional notation Two parameter-related pseudo-functions are\nmentioned in the original CSS specification: rgb(...), for converting indi-\nvidual RGB color values into a single color code, and url(...), required for\nURLs in most but not all contexts. On top of this, several more pseudo-\nfunctions have been rolled out in recent years, including scale(...),\nrotate(...), or skew(...).\nA proprietary expression(...) function is also available in Internet\nExplorer; it permits JavaScript statements to be inserted within CSS. This\nfunction is one of the most important reasons why attacker-controlled\nstylesheets can be a grave security risk.\n@ Directives and XBL Bindings\nIn addition to selectors and properties, several @-prefixed directives are rec-\nognized in stand-alone stylesheets. All of them modify the meaning of the\nstylesheet; for example, by specifying the namespace or the display media that\nthe stylesheet should be applied to. But two special directives also affect the\nbehavior of the parsing process. The first of these is @charset, which sets the\ncharset of the current CSS block; the other is @import, which inserts an exter-\nnal file into the stylesheet.\n* The ability to redefine mouse cursors using an arbitrary bitmap has predictably resulted in\nsome security bugs. An oversized cursor combined with script-based mouse position tracking\ncould be used to obscure or replace important elements of the browser UI and trick the user\ninto doing something dangerous.\nCascading Style Sheets 89"
  },
  {
    "input": "Parser Resynchronization Risks",
    "output": "The @import directive itself serves as a good example of the idiosyncrasies\nof CSS parsing; the parser views all of the following examples as equivalent:\n@import \"foo.css\";\n@import url('foo.css');\n@import'foo.css';\nIn Firefox, external content directives, including JavaScript code, may be\nalso loaded from an external source using the -moz-binding property, a vendor-\nspecific way to weave XML Binding Language3 files (an obscure method of\nproviding automation to XML content) into the document. There is some talk\nof supporting XBL in other browsers, too, at which point the name of the prop-\nerty would change and the XSS risk may or may not be addressed in some way.\nNOTE As can be expected, the handling of pseudo-URLs in @import, url(...) and other CSS-\nbased content inclusion schemes is a potential security risk. While most current browsers\ndo not accept scripting-related schemes in these contexts, Internet Explorer 6 allows them\nwithout reservations, thereby creating a code injection vector if the URL is not vali-\ndated carefully enough.\nInteractions with HTML\nIt follows from the discussion in the previous chapter that for any stylesheets\ninlined in HTML documents, HTML parsing is performed first and is com-\npletely independent of CSS syntax rules. Therefore, it is unsafe to place certain\nHTML syntax characters inside CSS properties, as in the following example,\neven when quoted properly. A common mistake is permitting this:\n<style>\nsome_descriptor {\nbackground: url('http://www.example.com/</style><h1>Gotcha!');\n}\n</style>\nWe’ll discuss a way to encode problematic characters in stylesheets shortly,\nbut first, let’s have a quick look at another very distinctive property of CSS.\nParser Resynchronization Risks\nAn undoubtedly HTML-inspired behavior that sets CSS apart from most\nother languages is that compliant parsers are expected to continue after\nencountering a syntax error and restart at the next matching curly bracket\n(some superficial nesting-level tracking is mandated by the spec). In particu-\nlar, the following stylesheet snippet, despite being obviously malformed, will\nstill apply the specified border style to all <img> tags:\na {\n$$$ This syntax makes absolutely no sense $$$\n!(@*#)!!@ 123\n}\n90 Chapter 5"
  },
  {
    "input": "Character Encoding",
    "output": "img {\nborder: 1px solid red;\n}\nThis unusual behavior creates an opportunity to exploit parser incom-\npatibilities in an interesting way: If there is any way to derail a particular CSS\nimplementation with inputs that seem valid to other parsers, the resynchro-\nnization logic may cause the attacked browser to resume parsing at an incor-\nrect location, such as in the middle of an attacker-supplied string.\nA naïve illustration of this issue may be Internet Explorer’s support for\nmultiline string literals. In this browser, it is seemingly safe not to scrub CR\nand LF characters in user-supplied CSS strings, so some webmasters may\nallow it. Unfortunately, the same pattern will cause any other browser to\nresume at an unexpected offset and interpret the evil_rule ruleset:\nsome_benign_selector {\ncontent: 'Attacker-controlled text...\n} evil_rule { margin-left: -1000px; }';\n}\nThe support for multiline strings is a Microsoft-specific extension, and\nthe aforementioned problem is easily fixed by avoiding such noncompliant\nsyntax to begin with. Unfortunately, other desynchronization risks are intro-\nduced by the standard itself. For example, recall complex selectors: This\nCSS3 syntax makes no sense to pre-CSS3 parsers. In the following example,\nan older implementation may bail out after encountering an unexpected\nangle bracket and resume parsing from the attacker-supplied evil_rule\ninstead:\na[href^='} evil_rule { margin-left: -1000px; }'] {\n/* Harmless, validated rules here. */\n}\nThe still-popular browser Internet Explorer 6 would be vulnerable to this\ntrick.\nCharacter Encoding\nTo make it possible to quote reserved or otherwise problematic characters\ninside strings, CSS offers an unorthodox escaping scheme: a backslash (\\)\nfollowed by one to six hexadecimal digits. For example, according to this\nscheme, the letter e may be encoded as “\\65”, “\\065”, or “\\000065”. Alas, only\nthe last syntax, “\\000065”, will be unambiguous if the next character happens\nto be a valid hexadecimal digit; encoding “teak” as “t\\65ak” would not work\nas expected, because the escape sequence would be interpreted as “\\65A”, an\nArabic sign in the Unicode character map.\nCascading Style Sheets 91\nTo avoid this problem, the specification embraces an awkward compro-\nmise: A whitespace can follow an escape sequence and will be interpreted as\na terminator, and then removed from the string (e.g., “t\\65 ak”). Regrettably,\nmore familiar and predictable fixed-length C-style escape sequences such as\n\\x65 cannot be used instead.\nIn addition to the numerical escaping scheme, it is also possible to place\na backslash in front of a character that is not a valid hexadecimal digit. In this\ncase, the subsequent character will be treated as a literal. This mechanism is\nuseful for encoding quote characters and the backslash itself, but it should\nnot be used to escape HTML control characters such as angle brackets. The\naforementioned precedence of HTML parsing over CSS parsing renders this\napproach inadequate.\nIn a bizarre twist, due to somewhat ambiguous guidance in the W3C drafts,\nmany CSS parsers recognize arbitrary escape sequences in locations other than\nquote-enclosed strings. To add insult to injury, in Internet Explorer, the sub-\nstitution of these sequences apparently takes place before the pseudo-function\nsyntax is parsed, effectively making the following two examples equivalent:\ncolor: expression(alert(1))\ncolor: expression\\028 alert \\028 1 \\029 \\029\nEven more confusingly, in a misguided bid to maintain fault tolerance,\nMicrosoft’s implementation does not recognize backslash escape codes inside\nurl(...) values; this is, once more, to avoid hurting the feelings of users who\ntype the wrong type of a slash when specifying a URL.\nThese and similar quirks make the detection of known dangerous CSS\nsyntax extremely error prone.\n92 Chapter 5"
  },
  {
    "input": "When Allowing User-Specified Class Values on HTML Markup",
    "output": "Security Engineering Cheat Sheet\nWhen Loading Remote Stylesheets\n You are linking the security of your site to the originating domain of the stylesheet. Even\nin browsers that do not support JavaScript expressions inside stylesheets, features such as\nconditional selectors and url(...) references can be used to exfiltrate portions of your site.4\n When in doubt, make a local copy of the data instead.\n On HTTPS sites, require stylesheets to be served over HTTPS as well.\nWhen Putting Attacker-Controlled Values into CSS\n Strings and URLs inside stand-alone blocks. Always use quotes. Backslash-escape all con-\ntrol characters (0x00–0x1F), “\\”, “<”, “>”, “{“, “}”, and quotes using numerical codes. It is\nalso preferable to escape high-bit characters. For URLs, consult the cheat sheet in Chap-\nter 2 to avoid code injection vulnerabilities.\n Strings in style parameters. Multiple levels of escaping are involved. The process is error\nprone, so do not attempt it unless absolutely necessary. If it is unavoidable, apply the above\nCSS escaping rules first and then apply HTML parameter encoding to the resulting string.\n Nonstring attributes. Allow only whitelisted alphanumeric keywords and carefully vali-\ndated numerical values. Do not attempt to reject known bad patterns instead.\nWhen Filtering User-Supplied CSS\n Remove all content outside of functional rulesets. Do not preserve or generate user-\ncontrolled comment blocks, @-directives, and so on.\n Carefully validate selector syntax, permitting only alphanumerics; underscores; white-\nspaces; and correctly positioned colons, periods, and commas before “{”. Do not permit\ncomplex text-matching selectors; they are unsafe.\n Parse and validate every rule in the { … } block. Permit only whitelisted properties with\nwell-understood consequences and confirm that they take expected, known safe values.\nNote that strings passed to certain properties may sometimes be interpreted as URLs even\nin the absence of a url(...) wrapper.\n Encode every parameter value using the rules outlined earlier in this section. Bail out on\nany syntax abnormalities.\n Keep in mind that unless specifically prevented from doing so, CSS may position user\ncontent outside the intended drawing area or redefine the appearance of any part of the\nUI of your application. The safest way to avoid this problem is to display the untrusted\ncontent inside a separate frame.\nWhen Allowing User-Specified Class Values on HTML Markup\n Ensure that user-supplied content can’t reuse class names that are used for any part of the\napplication UI. If a separate frame is not being used, it’s advisable to maintain separate\nnamespace prefixes.\nCascading Style Sheets 93"
  },
  {
    "input": "6: Browser-Side Scripts\r",
    "output": "B R O W S E R - S I D E S C R I P T S\nThe first browser scripting engine debuted in Netscape\nNavigator around 1995, thanks to the work of Brendan\nEich. The integrated Mocha language, as it was origi-\nnally called, gave web developers the ability to manip-\nulate HTML documents, display simple, system-level\ndialogs, open and reposition browser windows, and use\nother basic types of client-side automation in a hassle-\nfree way.\nWhile iterating through beta releases, Netscape eventually renamed\nMocha LiveScript, and after an awkward branding deal was struck with Sun\nMicrosystems, JavaScript was chosen as the final name. The similarities\nbetween Brendan’s Mocha and Sun’s Java were few, but the Netscape Cor-\nporation bet that this odd marketing-driven marriage would secure JavaScript’s\ndominance in the more lucrative server world. It made this sentiment clear"
  },
  {
    "input": "Basic Characteristics of JavaScript",
    "output": "in a famously confusing 1995 press release that introduced the language to\nthe world and immediately tried to tie it to an impressive range of random\ncommercial products:1\nNetscape and Sun Announce JavaScript, the Open, Cross-\nPlatform Object Scripting Language for Enterprise Networks\nand the Internet\n[ . . . ]\nNetscape Navigator Gold 2.0 enables developers to create and edit\nJavaScript scripts, while Netscape LiveWire enables JavaScript pro-\ngrams to be installed, run and managed on Netscape servers, both\nwithin the enterprise and across the Internet. Netscape LiveWire\nPro adds support for JavaScript connectivity to high-performance\nrelational databases from Illustra, Informix, Microsoft, Oracle and\nSybase. Java and JavaScript support are being built into all Netscape\nproducts to provide a unified, front-to-back, client/server/tool\nenvironment for building and deploying live online applications.\nDespite Netscape’s misplaced affection for Java, the value of JavaScript\nfor client-side programming seemed clear, including to the competition. In\n1996 Microsoft responded by shipping a near-verbatim copy of JavaScript in\nInternet Explorer 3.0 along with a counterproposal of its own: a Visual Basic–\nderived language dubbed VBScript. Perhaps because it was late to the party,\nand perhaps because of VBScript’s clunkier syntax, Microsoft’s alternative\nfailed to gain prominence or even any cross-browser support. In the end,\nJavaScript secured its position in the market, and in part due to Microsoft’s\nfailure, no new scripting languages have been attempted in mainstream\nbrowsers since.\nEncouraged by the popularity of the JavaScript language, Netscape\nhanded over some of the responsibility for maintaining it to an independent\nbody, the European Computer Manufacturers Association (ECMA). The new\noverseers successfully released ECMAScript, 3rd edition in 19992 but had\nsubstantially more difficulty moving forward from there. The 4th edition, an\nambitious overhaul of the language, was eventually abandoned after several\nyears of bickering between the vendors, and a scaled-down 5th edition,3 pub-\nlished in 2009, still enjoys only limited (albeit steadily improving) browser\nsupport. The work on a new iteration, called “Harmony,” begun in 2008, still\nhas not been finalized. Absent an evolving and widely embraced standard,\nvendor-specific extensions of the language are common, but they usually\ncause only pain.\nBasic Characteristics of JavaScript\nJavaScript is a fairly simple language meant to be interpreted at runtime. It has\nvaguely C-influenced syntax (save for pointer arithmetic); a straightforward\nclassless object model, said to be inspired by a little-known programming lan-\nguage named Self; automatic garbage collection; and weak, dynamic typing.\nJavaScript as such has no built-in I/O mechanisms. In the browser, lim-\nited abilities to interact with the host environment are offered through a set\n96 Chapter 6"
  },
  {
    "input": "Script Processing Model",
    "output": "of predefined methods and properties that map to native code inside the\nbrowser, but unlike what can be seen in many other programming languages,\nthese interfaces are fairly limited and purpose built.\nMost of the core features of JavaScript are fairly unremarkable and\nshould be familiar to developers already experience with C, C++, or, to a\nlesser extent, Java. A simple JavaScript program might look like this:\nvar text = \"Hi mom!\";\nfunction display_string(str) {\nalert(str);\nreturn 0;\n}\n// This will display \"Hi mom!\".\ndisplay_str(text);\nBecause it is beyond the scope of this book to provide a more detailed\noverview of the semantics of JavaScript, we’ll summarize only some of its more\nunique and security-relevant properties later in this chapter. For readers look-\ning for a more systematic introduction to the language, Marijn Haverbeke’s\nEloquent JavaScript (No Starch Press, 2011) is a good choice.\nScript Processing Model\nEvery HTML document displayed in a browser—be it in a separate window\nor in a frame—is given a separate instance of the JavaScript execution envi-\nronment, complete with an individual namespace for all global variables and\nfunctions created by the loaded scripts. All scripts executing in the context\nofa particular document share this common sandbox and can also interact\nwith other contexts through browser-supplied APIs. Such cross-document\ninteractions must be done in a very explicit way; accidental interference is\nunlikely. Superficially, script-isolation rules are reminiscent of the process-\ncompartmentalization model in modern multitasking operating systems but\na lot less inclusive.\nWithin a particular execution context, all encountered JavaScript blocks\nare processed individually and almost always in a well-defined order. Each\ncode block must consist of any number of self-contained, well-formed syntax\nunits and will be processed in three distinct, consequent steps: parsing, func-\ntion resolution, and code execution.\nParsing\nThe parsing stage validates the syntax of the script block and, usually, con-\nverts it to an intermediate binary representation, which can be subsequently\nexecuted at a more reasonable speed. The code has no global effects until\nthis step completes successfully. In case of syntax errors, the entire problem-\natic block is abandoned, and the parser proceeds to the next available chunk\nof code.\nBrowser-Side Scripts 97\nTo illustrate the behavior of a compliant JavaScript parser, consider the\nfollowing HTML snippet:\nblock #1: <script>\nvar my_variable1 = 1;\nvar my_variable2 =\n</script>\nblock #2: <script>\n2;\n</script>\nContrary to what developers schooled in C may be accustomed to, the\nabove sequence is not equivalent to the following snippet:\n<script>\nvar my_variable1 = 1;\nvar my_variable2 = 2;\n</script>\nThis is because <script> blocks are not concatenated before parsing.\nInstead, the first script segment will simply cause a syntax error (an assign-\nment with a missing right-hand value), resulting in the entire block being\nignored and not reaching execution stage. The fact that the whole segment\nis abandoned before it can have any global side effects also means that the\noriginal example is not equivalent to this:\n<script>\nvar my_variable1 = 1;\n</script>\n<script>\n2;\n</script>\nThis sets JavaScript apart from many other scripting languages such as\nBash, where the parsing stage is not separated from execution in such a\nstrong way.\nWhat will happen in the original example provided earlier in this section\nis that the first block will be ignored but the second one (<script>2;</script>)\nwill be parsed properly. That second block will amount to a no-op when exe-\ncuted, however, because it uses a pure, numerical expression as a code\nstatement.\nFunction Resolution\nOnce the parsing stage is completed successfully, the next step involves regis-\ntering every named, global function that the parser found within the cur-\nrently processed block. Past this point, each function found will be reachable\n98 Chapter 6\nfrom the subsequently executed code. Because of this extra pre-execution\nstep, the following syntax will work flawlessly (contrary to what programmers\nmay be accustomed to in C or C++, hello_world() will be registered before the\nfirst code statement—a call to said function—is executed):\n<script>\nhello_world();\nfunction hello_world() {\nalert('Hi mom!');\n}\n</script>\nOn the other hand, the modified example below will not have the\ndesired effect:\n<script>\nhello_world();\n</script>\n<script>\nfunction hello_world() {\nalert('Hi mom!');\n}\n</script>\nThis modified case will fail with a runtime error because individual\nblocks of code are not processed simultaneously but, rather, are looked at\nbased on the order in which they are made available to the JavaScript engine.\nThe block that defines hello_world() will not yet be parsed when the first block\nis already executing.\nTo further complicate the picture, the mildly awkward global name reso-\nlution model outlined here applies only to functions, not to variable declara-\ntions. Variables are registered sequentially at execution time, in a way similar\nto other interpreted scripting languages. Consequently, the following code\nsample, which merely replaces our global hello_world() with an unnamed\nfunction assigned to a global variable, will not work as planned:\n<script>\nhello_world();\nvar hello_world = function() {\nalert('Hi mom!');\n}\n</script>\nIn this case, the assignment to the hello_world variable will not be done by\nthe time the hello_world() call is attempted.\nBrowser-Side Scripts 99"
  },
  {
    "input": "Execution Ordering Control",
    "output": "Code Execution\nOnce function resolution is completed, the JavaScript engine normally\nproceeds with the ordered execution of all statements outside of function\nblocks. The execution of a script may fail at this point due to an unhandled\nexception or for a couple of other, more esoteric reasons. If such an error is\nencountered, however, any resolved functions within the offending code\nblock will remain callable, and any effects of the already executed code will\npersist in the current scripting context.\nException recovery and several other JavaScript execution characteristics\nare illustrated by the following lengthy but interesting code snippet:\n<script>\nfunction not_called() { This function will not execute, because\nreturn 42; it’s not called from anywhere.\n}\nfunction hello_world() { This function will execute only\nalert(\"With this program, anything is possible!\"); when called. It will show a dialog,\ndo_stuff(); but then will throw an exception\n} due to an unresolved reference to\na function named do_stuff().\nalert(\"Welcome to our demo application.\"); The execution of the program\nwill start from this statement.\nhello_world(); The “With this...” message will be displayed next.\nalert(\"Thank you, come again.\"); This code will not be reached due to an unhandled\n</script> exception triggered inside hello_world().\nThe previous exception will not\nprevent this independent block\nfrom executing next.\n<script>\nalert(\"Now that you are done, how about a nice game of chess?\");\n</script>\nTry to follow this example on your own and see if you agree with the\nannotations provided on the right.\nAs should be evident from this exercise, any unexpected and unhandled\nexceptions have an unusual consequence: They may leave the application in\nan inconsistent but still potentially executable state. Because exceptions are\nmeant to prevent error propagation caused by unanticipated errors, this\ndesign is odd—especially given that on many other fronts (such as the ban\non goto statements), JavaScript exhibits a more fundamentalist stance.\nExecution Ordering Control\nIn order to properly analyze the security properties of certain common web\napplication design patterns, it is important to understand the JavaScript\nengine’s execution ordering and timing model. Thankfully, this model is\nremarkably sane.\n100 Chapter 6"
  },
  {
    "input": "Code and Object Inspection Capabilities",
    "output": "Virtually all JavaScript living within a particular execution context is exe-\ncuted synchronously. The code can’t be reentered due to an external event\nwhile it is still executing, and there is no support for threads that would be able\nto simultaneously modify any shared memory. While the execution engine is\nbusy, the processing of events, timers, page navigation requests, and so on, is\npostponed; in most cases, the entire browser, or at least the HTML renderer,\nwill also remain largely unresponsive. Only once the execution stops and the\nscripting engine enters an idle state will the processing of queued events\nresume. At this point, the JavaScript code may be entered again.\nFurther, JavaScript offers no sleep(...) or pause(...) function to temporarily\nrelease the CPU and later resume execution from the same location. Instead,\nif a programmer desires to postpone the execution of a script, it is necessary to\nregister a timer to initiate a new execution flow later on. This flow will need\nto start at the beginning of a specified handler function (or at the beginning\nof an ad hoc, self-contained snippet of code provided when setting up a timer).\nAlthough these design decisions can be annoying, they substantially reduce\nthe risk of race conditions in the resulting code.\nNOTE There are several probably unintentional loopholes in this synchronous execution model.\nOne of them is the possibility of code execution while the execution of another piece of\nJavaScript is temporarily suspended after calling alert(...) or showModalDialog(...).\nSuch corner cases do not come into play very often, though.\nThe disruptive, browser-blocking behavior of busy JavaScript loops requires\nthe implementation of some mitigation on the browser level. We will explore\nthese mitigations in detail in Chapter 14. For now, suffice it to say that they\nhave another highly unusual consequence: Any endless loop may, in fact, ter-\nminate, in a fashion similar to throwing an unhandled exception. The engine\nwill then return to the idle state but will remain operational, the offending\ncode will remain callable, and all timers and event handlers will stay in place.\nWhen triggered on purpose by the attacker, the ability to unexpectedly\nterminate the execution of CPU-intensive code may put the application in an\ninconsistent state by aborting an operation that the author expects to always\ncomplete successfully. And that’s not all: Another, closely related conse-\nquence of these semantics should become evident in “JavaScript Object\nNotation and Other Data Serializations” on page104.\nCode and Object Inspection Capabilities\nThe JavaScript language has a rudimentary provision for inspecting the\ndecompiled source code of any nonnative functions, simply by invoking the\ntoString() or toSource() method on any function that the developer wishes to\nexamine. Beyond that capability, opportunities to inspect the flow of programs\nare limited. Applications may leverage access to the in-memory representa-\ntion of their host document and look up all inlined <script> blocks, but there\nis no direct visibility into any remotely loaded or dynamically generated code.\nSome insight into the call stack may also be gained through a nonstandard\ncaller property, but there is also no way to tell which line of code is being cur-\nrently executed or which one is coming up next.\nBrowser-Side Scripts 101"
  },
  {
    "input": "Modifying the Runtime Environment",
    "output": "The ability to dynamically create new JavaScript code is a more promi-\nnent part of the language. It is possible to instruct the engine to synchro-\nnously interpret strings passed to the built-in eval(...) function. For example,\nthis will display an alert dialog:\neval(\"alert(\\\"Hi mom!\\\")\")\nSyntax errors in any input text provided to eval(...) will cause this func-\ntion to throw an exception. Similarly, if parsing succeeds, any unhandled\nexceptions thrown by the interpreted code will be passed down to the caller.\nFinally, in the absence of syntax errors or runtime problems, the value of the\nlast statement evaluated by the engine while executing the supplied code will\nbe used as the return value of eval(...) itself.\nIn addition to this function, other browser-level mechanisms can be\nleveraged to schedule deferred parsing and execution of new JavaScript\nblocks once the execution engine returns to the idle state. Examples of such\nmechanisms include timers (setTimeout, setInterval), event handlers (onclick,\nonload, and so on), and interfaces to the HTML parser itself (innerHTML,\ndocument.write(...), and such).\nWhereas the ability to inspect the code is somewhat underhanded, run-\ntime object introspection capabilities are well developed in JavaScript. Appli-\ncations are permitted to enumerate almost any object method or property\nusing simple for ... in or for each ... in iterators and can leverage operators\nsuch as typeof, instanceof, or “strictly equals” (===) and properties such as\nlength to gain additional insight into the identity of every discovered item.\nAll of the foregoing features make it largely impossible for scripts run-\nning in the same context to keep secrets from each other. The functionality\nalso makes it more difficult to keep secrets across document contexts, a prob-\nlem that browser vendors had to combat for a very long time—and that, as\nyou’ll learn in Chapter 11, is still not completely a thing of the past.\nModifying the Runtime Environment\nDespite the relative simplicity of the JavaScript language, executed scripts\nhave many unusual ways of profoundly manipulating the behavior of their\nown JavaScript sandbox. In some rare cases, these behaviors can impact\nother documents, as well.\nOverriding Built-Ins\nOne of the more unusual tools at the disposal of a rogue script is the ability\nto delete, overwrite, or shadow most of the built-in JavaScript functions and\nvirtually all browser-supplied I/O methods. For example, consider the behav-\nior of the following code:\n// This assignment will not trigger an error.\neval = alert;\n// This call will unexpectedly open a dialog prompt.\neval(\"Hi mom!\");\n102 Chapter 6\nAnd this is just where the fun begins. In Chrome, Safari, and Opera, it is\npossible to subsequently remove the eval(...) function altogether, using the\ndelete operator. Confusingly, attempting the same in Firefox will restore the\noriginal built-in function, undoing the effect of the original override. Finally,\nin Internet Explorer, the deletion attempt will generate a belated exception\nthat seems to serve no meaningful purpose at that point.\nFurther along these lines, almost every object, including built-ins such as\nString or Array, has a freely modifiable prototype. This prototype is a master\nobject from which all existing and future object instances derive their meth-\nods and properties (forming a crude equivalent of class inheritance present\nin more fully featured programming languages). The ability to tamper with\nobject prototypes can cause rather counterintuitive behavior of newly cre-\nated objects, as illustrated here:\nNumber.prototype.toString = function() {\nreturn \"Gotcha!\";\n};\n// This will display \"Gotcha!\" instead of \"42\":\nalert(new Number(42));\nSetters and Getters\nMore interesting features of the object model available in contemporary dia-\nlects of JavaScript are setters and getters: ways to supply custom code that han-\ndles reading or setting properties of the host object. Although not as powerful\nas operator overloading in C++, these can be used to make existing objects or\nobject prototypes behave in even more confusing ways. In the following snip-\npet, the acts of setting the object property and reading it back later on are\nboth subverted easily:\nvar evil_object = {\nset foo() { alert(\"Gotcha!\"); },\nget foo() { return 2; }\n};\n// This will display \"Gotcha!\" and have no other effect.\nevil_object.foo = 1;\n// This comparison will fail.\nif (evil_object.foo != 1) alert(\"What's going on?!\");\nNOTE Setters and getters were initially developed as a vendor extension but are now standard-\nized under ECMAScript edition 5. The feature is available in all modern browsers but\nnot in Internet Explorer 6 or 7.\nImpact on Potential Uses of the Language\nAs a result of the techniques discussed in the previous two sections, a script\nexecuting inside a context once tainted by any other untrusted content has\nno reliable way to examine its operating environment or take corrective\nBrowser-Side Scripts 103"
  },
  {
    "input": "JavaScript Object Notation and Other Data Serializations",
    "output": "action; even the behavior of simple conditional expressions or loops can’t\nnecessarily be relied upon. The proposed enhancements to the language are\nlikely to make the picture even more complicated. For example, the failed\nproposal for ECMAScript edition 4 featured full-fledged operator overload-\ning, and this idea may return.\nEven more interestingly, these design decisions also make it difficult to\ninspect any execution context from outside the per-page sandbox. For example,\nblind reliance on the reliability of the location object of a potentially hostile doc-\nument has led to a fair number of security vulnerabilities in browser plug-ins,\nJavaScript-based extensions, and several classes of client-side web application\nsecurity features. These vulnerabilities eventually resulted in the development\nof browser-level workarounds designed to partially protect this specific object\nagainst sabotage, but most of the remaining object hierarchy is up for grabs.\nNOTE The ability to tamper with one’s own execution context is limited in the “strict” mode of\nECMAScript edition 5. This mode is not fully supported in any browser as of this writ-\ning, however, and is meant to be an opt-in, discretionary mechanism.\nJavaScript Object Notation and Other Data Serializations\nA very important syntax structure in JavaScript is its very compact and conve-\nnient in-place object serialization, known as JavaScript Object Notation, or\nJSON (RFC 46274). This data format relies on overloading the meaning of\nthe curly bracket symbol ({). When such a brace is used to open a fully quali-\nfied statement, it is treated in a familiar way, as the start of a nested code block.\nIn an expression, however, it is assumed to be the beginning of a serialized\nobject. The following example illustrates a correct use of this syntax and will\ndisplay a simple prompt:\nvar impromptu_object = {\n\"given_name\" : \"John\",\n\"family_name\" : \"Smith\",\n\"lucky_numbers\" : [ 11630, 12067, 12407, 12887 ]\n};\n// This will display \"John\".\nalert(impromptu_object.given_name);\nIn contrast to the unambiguous serializations of numbers, strings, or\narrays, the overloading of the curly bracket means that JSON blocks will not\nbe recognized properly when used as a standalone statement. This may seem\ninsignificant, but it is an advantage: It prevents any server-supplied responses\nthat comply with this syntax from being meaningfully included across domains\nvia <script src=...>.* The listing that follows will cause a syntax error, ostensibly\n* Unlike most other content inclusion schemes available to scripts (such as XMLHttpRequest),\n<script src=...> is not subject to the cross-domain security restrictions outlined in Chapter 9.\nTherefore, the mechanism is a security risk whenever ambient authority credentials, such as\ncookies, are used by the server to dynamically generate user-specific JavaScript code. This class\nof vulnerabilities is unimaginatively referred to as cross-site script inclusion, or XSSI.\n104 Chapter 6\ndue to an illegal quote () in what the interpreter attempts to treat as a code\nlabel,* and will have no measurable side effects:\n<script>\n{\n \"given_name\" : \"John\",\n\"family_name\" : \"Smith\",\n\"lucky_numbers\" : [ 11630, 12067, 12407, 12887 ]\n};\n</script>\nNOTE The inability to include JSON via <script src=...> is an interesting property, but it is\nalso a fragile one. In particular, wrapping the response in parentheses or square brack-\nets, or removing quotes around the labels, will render the syntax readily executable in a\nstandalone block, which may have observable side effects. Given the rapidly evolving\nsyntax of JavaScript, it is not wise to bank on this particular code layout always caus-\ning a parsing error in the years to come. That said, in many noncritical uses, this level\nof assurance will be good enough to rely on as a simple security mechanism.\nOnce retrieved through a channel such as XMLHttpRequest, the JSON\nserialization can be quickly and effortlessly converted to an in-memory object\nusing the JSON.parse(...) function in all common browsers, other than Internet\nExplorer. Unfortunately, for purposes of compatibility with Internet Explorer,\nand sometimes just out of custom, many developers resort to an equally fast\nyet far more dangerous hack:\nvar parsed_object = eval(\"(\" + json_text + \")\");\nThe problem with this syntax is that the eval(...) function used to com-\npute the “value” of a JSON expression permits not only pure JSON inputs but\nany other well-formed JavaScript syntax to appear in the string. This can have\nundesirable, global side effects. For example, the function call embedded in\nthis faux JSON response will execute:\n{ \"given_name\": alert(\"Hi mom!\") }\nThis behavior creates an additional burden on web developers to accept\nJSON payloads only from trusted sources and always to correctly escape feeds\nproduced by their own server-side code. Predictably, failure to do so has con-\ntributed a fair number of application-level security bugs.\nNOTE The difficulty of getting eval(...) right is embodied by the JSON specification (RFC\n4627) itself: The allegedly secure parser implementation included in that document\nunintentionally permits rogue JSON responses to freely increment or decrement any pro-\ngram variables that happen to consist solely of the letters “a”, “e”, “f”, “l”, “n”, “r”,\n* Somewhat unexpectedly, JavaScript supports C-style labeled statements, such as my_label:\nalert(“Hi mom!”). This is interesting because for philosophical reasons, the language has no\nsupport for goto and, therefore, such a label can’t be meaningfully referenced in most cases.\nBrowser-Side Scripts 105"
  },
  {
    "input": "E4X and Other Syntax Extensions",
    "output": "“s”, “t”, “u”, plus digits; that’s enough to spell “unsafe” and about 1,000 other com-\nmon English words. The faulty regular expression legitimized in this RFC appears all\nover the Internet and will continue to do so.\nThanks to their ease of use, JSON serializations are ubiquitous in server-\nto-client communications across all modern web applications. The format is\nrivaled only by other, less secure string or array serializations and by JSONP.*\nAll of these schemes are incompatible with JSON.parse(...), however, and must\nrely on unsafe eval(...) to be converted to in-memory data. The other prop-\nerty of these formats is that, unlike proper JSON, they will parse properly\nwhen loaded with <script src=...> on a third-party page. This property is advan-\ntageous in some rare cases, but mostly it just constitutes an unobvious risk. For\nexample, consider that even though loading an array serialization via a <script>\ntag normally has no measurable side effects, an attacker could, at least until\nrecent improvements, modify the setters on an Array prototype to retrieve the\nsupplied data. A common but often insufficient practice of prefixing a response\nwith a while(1); loop to prevent this attack can backfire in interesting ways if\nyou recall the possibility of endless loops terminating in JavaScript.\nE4X and Other Syntax Extensions\nLike HTML, JavaScript is quickly evolving. Some of the changes made to it\nover the years have been fairly radical and may end up turning text formats\nthat were previously rejected by the parser into a valid JavaScript code. This,\nin turn, may lead to unexpected data disclosure, especially in conjunction\nwith the extensive code and object inspection and modification capabilities\ndiscussed earlier in this chapter—and the ability to use <script src=...> to load\ncross-domain code.\nOne of the more notable examples of this trend is ECMAScript for XML\n(E4X),5 a completely unnecessary but elegant plan to incorporate XML syn-\ntax directly into JavaScript as an alternative to JSON-style serializations. In\nany E4X-compatible engine, such as Firefox, the following two snippets of\ncode would be roughly equivalent:\n// Normal object serialization\nvar my_object = { \"user\": {\n\"given_name\": \"John\",\n\"family_name\": \"Smith\",\n\"id\": make_up_value()\n} };\n// E4X serialization\nvar my_object = <user>\n<given_name>John</given_name>\n<family_name>Smith</family_name>\n<id>{ make_up_value() }</id>\n</user>;\n* JSONP literally means “JSON with padding” and stands for JSON serialization wrapped in some\nsupplementary code that turns it into a valid, standalone JavaScript statement for convenience.\nCommon examples may include a function call (e.g., callback_function({ ...JSON data... })) or a\nvariable assignment (var return_value = { ...JSON data... }).\n106 Chapter 6"
  },
  {
    "input": "Standard Object Hierarchy",
    "output": "The unexpected consequence of E4X is that, under this regime, any well-\nformed XML document suddenly becomes a valid <script src=...> target that\nwill parse as an expression-as-statement block. Moreover, if an attacker can\nstrategically place “{” and “}” characters on an included page, or alter the set-\nters for the right object prototype, the attacker may be able to extract user-\nspecific text displayed in an unrelated document. The following example\nillustrates the risk:\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n...\n{ steal_stuff( attacker-supplied string\n...\n<span>User-specific secrets here</span>\n...\n) } attacker-supplied string\n...\n</html>\nTo their credit, after several years of living with the flaw, Firefox develop-\ners decided to disallow any E4X statements that span the entirety of any\nparsed script, partly closing this loophole. Nevertheless, the fluidity of the\nlanguage is evident, and it casts some doubt on the robustness of using of\nJSON responses as a defense against cross-domain script inclusion. The\nmoment a third meaning is given to the “{” symbol or quotes-as-labels start\nhaving a purpose, the security of this server-to-client data exchange format\nwill be substantially degraded. Be sure to plan ahead.\nStandard Object Hierarchy\nThe JavaScript execution environment is structured around an implicit root\nobject, which is used as the default namespace for all global variables and func-\ntions created by the program. In addition to a handful of language-mandated\nbuilt-ins, this namespace is prepopulated with a hierarchy of functions that\nimplement input and output capabilities in the browser environment. These\ncapabilities include manipulating browser windows (open(...), close(), moveTo(...),\nresizeTo(...), focus(), blur(), and such); configuring JavaScript timers (setTimeout(...),\nsetInterval(...), and so on); displaying various UI prompts (alert(...), prompt(...),\nprint(...)); and performing a variety of other vendor-specific and frequently\nrisky functions, such as accessing the system clipboard, creating bookmarks,\nor changing the home page.\nThe top-level object also provides JavaScript references to root objects\nbelonging to related contexts, including the parent frame (parent), the top-\nlevel document in the current browser window (top), the window that created\nthe current one (opener), and all subframes of the current document (frames[]).\nSeveral circular references to the current root object itself are also included—\nsay, window and self. In browsers other than Firefox, elements with specified\nid or name parameters will be automatically registered in this namespace, too,\npermitting syntax such as this:\n<img id=\"hello\" src=\"http://www.example.com/\">\n...\nBrowser-Side Scripts 107\n<script>\nalert(hello.src);\n</script>\nThankfully, in case of any name conflicts with JavaScript variables or built-\nins, id data will not be given precedence, largely avoiding any possible inter-\nference between otherwise sanitized, user-supplied markup and in-document\nscripts.\nThe remainder of the top-level hierarchy consists primarily of a couple\nof distinguished children objects that group browser API features by theme:\nlocation object\nThis is a collection of properties and methods that allow the program to\nread the URL of the current document or initiate navigation to a new\none. This last action, in most cases, is lethal to the caller: The current\nscripting context will be destroyed and replaced with a new one shortly\nthereafter. Updating just the fragment identifier (location.hash) is an\nexception to this rule, as explained in Chapter 2.\nNote that when using location.* data to construct new strings (HTML\nand JavaScript code in particular), it is unsafe to assume that it is escaped\nin any specific way. Internet Explorer will keep angle brackets as is in\nthelocation.search property (which corresponds to the URL query string).\nChrome, on the other hand, will escape them, but it will glance over dou-\nble quotes (\") or backslashes. Most browsers also do not apply any escap-\ning to the fragment ID.\nhistory object\nThis hierarchy provides several infrequently used methods for moving\nthrough the per-window browsing history, in a manner similar to clicking\nthe “back” and “forward” buttons in the browser UI. It is not possible to\ndirectly examine any of the previously visited URLs; the only option is to\nnavigate to the history blindly by providing numerical offsets, such as\nhistory.go(-2). (Some recent additions to this hierarchy will be discussed in\nChapter 17.)\nscreen object\nA basic API for examining the dimensions of the screen and the browser\nwindow, monitor DPI, color depth, and so on. This is offered to help web-\nsites optimize the presentation of a page for a particular display device.\nnavigator object\nAn interface for querying the browser version, the underlying operating\nsystem, and the list of installed plug-ins.\ndocument object\nBy far the most complex of the hierarchies, this is a doorway to the Docu-\nment Object Model6 of the current page; we will have a look at this model\nin the following section. A couple of functions not related to document\nstructure also appear under the document hierarchy, usually due to arbi-\ntrary design decisions. Examples include document.cookie for manipulating\ncookies, document.write(...) for appending HTML to the current page, and\ndocument.execCommand(...) for performing certain WYSIWYG editing tasks.\n108 Chapter 6"
  },
  {
    "input": "The Document Object Model",
    "output": "NOTE Interestingly, the information available through the navigator and screen objects is\nsufficient to uniquely fingerprint many users with a high degree of confidence. This\nlong-known property is emphatically demonstrated by Panopticlick, a project of the\nElectronic Frontier Foundation: https://panopticlick.eff.org/.\nSeveral other language-mandated objects offer simple string-processing\nor arithmetic capabilities. For example, Math.random() implements an\nunsafe, predictable pseudo-random number generator (a safe PRNG alter-\nnative is unfortunately not available at this time in most browsers*), while\nString.fromCharCode() can be used to convert numerical values into Unicode\nstrings. In privileged execution contexts, which are not reachable by normal\nweb applications, a fair number of other task-specific objects will also appear.\nNOTE When accessing any of the browser-supplied objects, it is important to remember that\nwhile JavaScript does not use NUL-terminated ASCIZ strings, the underlying browser\n(written in C or C++) sometimes will. Therefore, the outcomes of assigning NUL-\ncontaining strings to various DOM properties, or supplying them to native functions,\nmay be unpredictable and inconsistent. Almost all browsers truncate assignments to\nlocation.* at NUL, but only some engines will do the same when dealing with DOM\n*.innerHTML.\nThe Document Object Model\nThe Document Object Model, accessible through the document hierarchy,\nprovides a structured, in-memory representation of the current document as\nmapped out by the HTML parser. The resulting object tree exposes all HTML\nelements on the page, their tag-specific methods and properties, and the asso-\nciated CSS data. This representation, not the original HTML source, is used\nby the browser to render and update the currently displayed document.\nJavaScript can access the DOM in a very straightforward way, similarly to\nany normal objects. For example, the following snippet will go to the fifth tag\nwithin the document’s <body> block, look up the first nested subtag, and set\nthat element’s CSS color to red:\ndocument.body.children[4].children[0].style.color = \"red\";\nTo avoid having to waddle through the DOM tree in order to get to a\nparticular deeply nested element, the browser provides several document-\nwide lookup functions, such as getElementById(...) and getElementsByTagName(...),\nas well as partly redundant grouping mechanisms such as frames[], images[],\nor forms[]. These features permit syntax such as the following two lines of\ncode, both of which directly reference an element no matter where in the\ndocument hierarchy it happens to appear:\ndocument.getElementsByTagName(\"input\")[2].value = \"Hi mom!\";\ndocument.images[7].src = \"/example.jpg\";\n* There are a recently added window.crypto.getRandomValues(...) API in Chrome and a currently\nnonoperational window.crypto.random(...) API in Firefox.\nBrowser-Side Scripts 109\nFor legacy reasons, the names of certain HTML elements (<img>, <form>,\n<embed>, <object>, and <applet>) are also directly mapped to the document\nnamespace, as illustrated in the following snippet:\n<img name=\"hello\" src=\"http://www.example.com/\">\n<script>\nalert(document.hello.src);\n</script>\nUnlike in the more reasonable case of name and id mapping in the global\nnamespace (see previous section), such document entries may clobber built-in\nfunctions and objects such as getElementById or body. Therefore, permitting\nuser-specified tag names, for example for the purpose of constructing forms,\ncan be unsafe.\nIn addition to providing access to an abstract representation of the\ndocument, many DOM nodes may expose properties such as innerHTML and\nouterHTML, which permit a portion of the document tree to be read back as a\nwell-formed, serialized HTML string. Interestingly, the same property can be\nwritten to in order to replace any portion of the DOM tree with the result of\nparsing a script-supplied snippet of HTML. One example of that last use is this:\ndocument.getElementById(\"output\").innerHTML = \"<b>Hi mom!</b>\";\nEvery assignment to innerHTML must involve a well-formed and self-\ncontained block of HTML that does not alter the document hierarchy outside\nthe substituted fragment. If this condition is not met, the input will be coerced\nto a well-formed syntax before the substitution takes place. Therefore, the\nfollowing example will not work as expected; that is, it will not display “Hi\nmom!” in bold and will not put the remainder of the document in italics:\nsome_element.innerHTML = \"<b>Hi\";\nsome_element.innerHTML += \" mom!</b><i>\";\nInstead, each of these two assignments will be processed and corrected\nindividually, resulting in a behavior equivalent to this:\nsome_element.innerHTML = \"<b>Hi</b> mom!<i></i>\";\nIt is important to note that the innerHTML mechanism should be used\nwith extreme caution. In addition to being inherently prone to markup injec-\ntion if proper HTML escaping is not observed, browser implementations of\nthe DOM-to-HTML serialization algorithms are often imperfect. A recent\n(now fixed) example of such a problem in WebKit7 is illustrated here:\n<textarea>\n&lt;/textarea&gt;&lt;script&gt;alert(1)&lt;/script&gt;\n</textarea>\n110 Chapter 6"
  },
  {
    "input": "Access to Other Documents",
    "output": "Because of the confusion over the semantics of <textarea>, this seemingly\nunambiguous input markup, when parsed to a DOM tree and then accessed\nthrough innerHTML, would be incorrectly read back as:\n<textarea>\n</textarea><script>alert(1)</script>\n</textarea>\nIn such a situation, even performing a no-op assignment of this serializa-\ntion (such as some_element.innerHTML += \"\") would lead to unexpected script\ninjection. Similar problems tend to plague other browsers, too. For example,\nInternet Explorer developers working on the innerHTML code were unaware\nthat MSHTML recognizes backticks (`) as quote characters and so ended up\nhandling them incorrectly. In their implementation, the following markup:\n<img src=\"test.jpg\" alt=\"``onload=alert(1)\">\nwould be reserialized as this:\n<img src=test.jpg alt=``onload=alert(1)>\nIndividual bugs aside, the situation with innerHTML is pretty dire: Sec-\ntion 10.3 of the current draft of HTML5 simply acknowledges that certain\nscript-created DOM structures are completely impossible to serialize to\nHTML and does not require browsers to behave sensibly in such a case.\nCaveat emptor!\nAccess to Other Documents\nScripts may come into possession of object handles that point to the root\nhierarchy of another scripting context. For example, by default, every con-\ntext can readily reference parent, top, opener, and frames[], all supplied to it in\nthe top-level object. Calling the window.open(...) function to create a new win-\ndow will also return a reference, and so will an attempt to look up an existing\nnamed window using this syntax:\nvar window_handle = window.open(\"\", \"window_name\");\nOnce the program holds a handle pointing to another scripting context,\nit may attempt to interact with that context, subject to security checks dis-\ncussed in Chapter 9. An example of a simple interaction might be as follows:\ntop.location.path = \"/new_path.html\";\nor\nframes[2].document.getElementById(\"output\").innerHTML = \"Hi mom!\";\nBrowser-Side Scripts 111"
  },
  {
    "input": "Script Character Encoding",
    "output": "In the absence of a valid handle, JavaScript-level interaction with an\nunrelated document should not be possible. In particular, there is no way\ntolook up unnamed windows opened in completely separate navigation\nflows, at least until their name is explicitly set by one of the visited pages\n(thewindow.name property permits this).\nScript Character Encoding\nJavaScript engines support several familiar, backslash-based string-encoding\nmethods that can be employed to escape quote characters, HTML markup,\nand other problematic bits in the embedded text. These methods are as follows:\n C-style shorthand notation for certain control characters: \\b for back-\nspace, \\t for horizontal tab, \\v for vertical tab, \\f for form feed, \\r for CR,\nand \\n for LF. This exact set of escape codes is recognized by both\nECMAScript and the JSON RFC.\n Three-digit, zero-padded, 8-bit octal character codes with no prefix\n(such as “\\145” instead of “e”). This C-inspired syntax is not a part of\nECMAScript but is in practice supported by all scripting engines, both\ninnormal code and in JSON.parse(...).\n Two-digit, zero-padded, 8-bit hexadecimal character codes, prefixed\nwith“x” (“e” becomes “\\x65”). Again, this scheme is not endorsed by\nECMAScript or RFC 4627, but having its roots in the C language, it is\nwidely supported in practice.\n Four-digit, zero-padded, 16-bit hexadecimal Unicode values, prefixed\nwith “u” (“e” turns into “\\u0065”). This format is sanctioned by ECMA-\nScript and RFC 4627 and is supported by all modern browsers.\n A backslash followed by any character other than an octal digit; “b”, “t”,\n“v”, “f”, “r,” or “n” characters used for other predefined escape sequences;\nand “x” or “u”. In this scheme, the subsequent character will be treated\nas a literal. ECMAScript permits this scheme to be used to escape only\nquotes and the backslash character itself, but in practice, any other value\nis accepted as well.\nThis approach is somewhat error prone, and as in the case of CSS,\nitshould not be used to escape angle brackets and other HTML syntax\ndelimiters. This is because JavaScript parsing takes place after HTML\nparsing, and the backslash prefix will be not treated in any special way\nbythe HTML parser itself.\nNOTE Somewhat inexplicably, Internet Explorer does not recognize the vertical tab (“\\v”)\nshorthand, thereby creating one of the more convenient (but very naughty!) ways to\ntestfor that particular browser:\nif (\"\\v\" == \"v\") alert(\"Looks like Internet Explorer!\");\n112 Chapter 6"
  },
  {
    "input": "Code Inclusion Modes and Nesting Risks",
    "output": "Surprisingly, the Unicode-based escaping method (but not the other\nones) is also recognized outside strings. Although the idea seems arbitrary, the\nbehavior is a bit more sensible than with CSS: Escape codes can be used only\nin identifiers, and they will not work as a substitute for any syntax-sensitive\nsymbols. Therefore, the following is possible:\n\\u0061lert(\"This displays a message!\");\nOn the other hand, any attempt to substitute the parentheses or quotes\nin a similar fashion would fail.\nUnlike in some C or C++ implementations, stray multiline string literals\nare not tolerated by any JavaScript engine. That said, despite a strongly worded\nprohibition in ECMAScript specs, there is one exception: A lone backslash at\nthe end of a line may be used to join multiline literals seamlessly. This behav-\nior is illustrated below:\nvar text = 'This syntax\nis invalid.';\nvar text = 'This syntax, on the other hand, \\\nis OK in all browsers.';\nCode Inclusion Modes and Nesting Risks\nAs should be evident from the earlier discussions in this chapter, there are\nseveral ways to execute scripts in the context of the current page. It is proba-\nbly useful to enumerate some of the most common ones:\n Inline <script> blocks\n Remote scripts loaded with <script src=...>*\n javascript: URLs in various HTML parameters and in CSS\n CSS expression(...) syntax and XBL bindings in certain browsers\n Event handlers (onload, onerror, onclick, etc.)\n Timers (setTimeout, setInterval)\n eval(...) calls\nCombining these methods often seems natural, but doing so can create\nvery unexpected and dangerous parsing chains. For example, consider the\ntransformation that would need to be applied to the value inserted by the\nserver in place of user_string in this code:\n<div onclick=\"setTimeout('do_stuff(\\'user_string\\')', 1000)\">\n* On both types of <script> blocks, Microsoft supports a pseudo-dialect called JScript.Encode. This\nmode can be selected by specifying a language parameter on the <script> tag and simply permits\nthe actual script to be encoded using a trivial alphabet substitution cipher to make it unreadable\nto casual users. The mechanism is completely worthless from the security standpoint, as the\n“encryption” can be reverted easily.\nBrowser-Side Scripts 113"
  },
  {
    "input": "The Living Dead: Visual Basic",
    "output": "It is often difficult to notice that the value will go through no fewer\nthanthree rounds of parsing! First, the HTML parser will extract the onclick\nparameter and put it into DOM; next, when the button is clicked, the first\nround of JavaScript parsing will extract the setTimeout(...) syntax; and finally,\none second after the initial click, the actual do_stuff(...) sequence will be\nparsed and executed.\nTherefore, in the example above, in order to survive the process, user_string\nneeds to be double-encoded using JavaScript backslash sequences, and then\nencoded again using HTML entities, in that exact order. Any different approach\nwill likely lead to code injection.\nAnother tricky escaping situation is illustrated here:\n<script>\nvar some_value = \"user_string\";\n...\nsetTimeout(\"do_stuff('\" + some_value + \"')\", 1000);\n</script>\nEven though the initial assignment of some_value requires user_string to\nbe escaped just once, the subsequent ad hoc construction of a second-order\nscript in the setTimeout(...) parameter introduces a vulnerability if no addi-\ntional escaping is applied beforehand.\nSuch coding patterns happen frequently in JavaScript programs, and\nthey are very easy to miss. It is much better to consistently discourage them\nthan to audit the resulting code.\nThe Living Dead: Visual Basic\nHaving covered most of the needed ground related to JavaScript, it’s time\nforan honorable mention of the long-forgotten contender for the scripting\nthrone. Despite 15 years of lingering in almost complete obscurity, browser-\nside VBScript is still supported in Internet Explorer. In most aspects, Micro-\nsoft’s language is supposed to be functionally equivalent to JavaScript, and it\nhas access to exactly the same Document Object Model APIs and other built-\nin functions as JavaScript. But, as one might expect, some tweaks and exten-\nsions are present—for example, a couple of VB-specific functions in place of\nthe JavaScript built-ins.\nThere is virtually no research into the security properties of VBScript,\nthe robustness of the parser, or its potential incompatibilities with the mod-\nern DOM. Anecdotal evidence suggests that the language receives no consis-\ntent scrutiny on Microsoft’s end, either. For example, the built-in MsgBox8\ncan be used to display modal, always-on-top prompts with a degree of flexibil-\nity completely unheard of in the JavaScript world, leaving alert(...) in the dust.\nIt is difficult to predict how long VBScript will continue to be supported\nin this browser and what unexpected consequences for user and web applica-\ntion security it is yet to have. Only time will tell.\n114 Chapter 6"
  },
  {
    "input": "When Interacting with Browser Objects on the Client Side",
    "output": "Security Engineering Cheat Sheet\nWhen Loading Remote Scripts\nAs with CSS, you are linking the security of your site to the originating domain of the script.\nWhen in doubt, make a local copy of the data instead. On HTTPS sites, require all scripts to\nbe served over HTTPS.\nWhen Parsing JSON Received from the Server\nRely on JSON.parse(...) where supported. Do not use eval(...) or the eval-based implementation\nprovided in RFC 4627. Both are unsafe, especially when processing data from third parties. A\nlater implementation from the author of RFC 4627, json2.js,9 is probably okay.\nWhen Putting User-Supplied Data Inside JavaScript Blocks\n Stand-alone strings in <script> blocks: Backslash-escape all control characters (0x00–0x1F),\n“\\”, “<”, “>”, and quotes using numerical codes. It is also preferable to escape high-bit\ncharacters.\nDo not rely on user-supplied strings to construct dynamic HTML. Always use safe\nDOM features such as innerText or createTextNode(...) instead. Do not use user-supplied\nstrings to construct second-order scripts; avoid eval(...), setTimeout(...), and so on.\n Stand-alone strings in separately served scripts: Follow the same rules as for <script>\nblocks. If your scripts contain any sensitive, user-specific information, be sure to account\nfor cross-site script inclusion risks; use reliable parser-busting prefixes, such as “)}]'\\n”,\nnear the beginning of a file or, at the very minimum, use a proper JSON serialization with\nno padding or other tweaks. Additionally, consult Chapter 13 for tips on how to prevent\ncross-site scripting in non-HTML content.\n Strings in inlined event handlers, javascript: URLs, and so on: Multiple levels of escaping\nare involved. Do not attempt this because it is error prone. If unavoidable, apply the above\nJS escaping rules first and then apply HTML or URL parameter encoding, as applicable,\nto the resulting string. Never use in conjunction with eval(...), setTimeout(...), innerHTML,\nand such.\n Nonstring content: Allow only whitelisted alphanumeric keywords and carefully validated\nnumerical values. Do not attempt to reject known bad patterns instead.\nWhen Interacting with Browser Objects on the Client Side\n Generating HTML content on the client side: Do not resort to innerHTML, document.write(...),\nand similar tools because they are prone to introducing cross-site scripting flaws, often in\nunexpected ways. Use safe methods such as createElement(...) and appendChild(...) and\nproperties such as innerText or textContent to construct the document instead.\n Relying on user-controlled data: Make no assumptions about the escaping rules applied\nto any values read back from the browser and, in particular, to location properties and\nother external sources of URLs, which are inconsistent and vary from one implementa-\ntion to another. Always do your own escaping.\nBrowser-Side Scripts 115"
  },
  {
    "input": "If You Want to Allow User-Controlled Scripts on Your Page",
    "output": "If You Want to Allow User-Controlled Scripts on Your Page\nIt is virtually impossible to do this safely. Experimental JavaScript rewriting frameworks,\nsuchas Caja (http://code.google.com/p/google-caja/), are the only portable option. Also see\nChapter 16 for information on sandboxed frames, an upcoming alternative for embedding\nuntrusted gadgets on web pages.\n116 Chapter 6"
  },
  {
    "input": "Plaintext Files",
    "output": "N O N - H T M L\nD O C U M E N T T Y P E S\nIn addition to HTML documents, about a dozen other\nfile formats are recognized and displayed by the ren-\ndering engines of modern web browsers; a list that is\nlikely to grow over time.\nBecause of the powerful scripting capabilities available in some of these\nformats, and because of the antics of browser-content handling, the set of\nnatively supported non-HTML inputs deserves a closer examination at this\npoint, even if a detailed discussion of some of their less-obvious security\nconsequences—such as content sniffing—will have to wait until Part II of\nthisbook.\nPlaintext Files\nPerhaps the most prosaic type of non-HTML document recognized by every\nsingle browser is a plaintext file. In this rendering mode, the input is simply\ndisplayed as is, typically using a nonproportional typeface, and save for\noptional character set transcoding, the data is not altered in any way."
  },
  {
    "input": "Bitmap Images",
    "output": "All browsers recognize plaintext files served with Content-Type: text/plain\nin the HTTP headers. In all implementations but Internet Explorer, plain-\ntext is also the fallback display method for headerless HTTP/0.9 responses\nand HTTP/1.x data with Content-Type missing; in both these cases, plaintext\nisused when all other content detection heuristics fail. (Internet Explorer\nunconditionally falls back to HTML rendering, true to the letter of Tim\nBerners-Lee’s original protocol drafts.)\nFor the convenience of developers, most browsers also automatically\nmap several other MIME types, including application/javascript and friends*\nor text/css, to plaintext. Interestingly, application/json, the value mandated for\nJSON responses in RFC 4627, is not on the list (perhaps because it is seldom\nused in practice).\nPlaintext rendering has no specific security consequences. That said,\ndueto a range of poor design decisions in other browser components and in\nthird-party code, even seemingly harmless non-HTML formats are at a risk\nofbeing misidentified as, for example, HTML. Attacker-controlled plaintext\ndocuments are of special concern because their layout is often fairly uncon-\nstrained and therefore particularly conducive to being misidentified. Chap-\nter 13 dissects these threats and provides advice on how to mitigate the risk.\nBitmap Images\nBrowser-rendering engines recognize direct navigation to the same set of bit-\nmap image formats that are normally supported in HTML documents when\nloaded via the <img> tag, including JPEG, PNG, GIF, BMP, and a couple more.\nWhen the user navigates directly to such a resource, the decoded bitmap is\nshown in the document window, allowing the user little more than the ability\nto scroll, zoom in and out, and save the file to disk.\nIn the absence of Content-Type information, images are detected based on\nfileheader checks. When a Content-Type value is present, it is compared with\nabout a dozen predefined image types, and the user is routed accordingly.\nBut if an attempt to decode the image fails, file headers are used to make a\nsecond guess. It is therefore possible (but, for the reasons explored in Chap-\nter 13, often unwise) to serve a GIF file as image/jpeg.\nAs with text files, bitmap images are a passive resource and carry no\nunusual security risks.† However, whenever serving user-supplied images,\nremember that attackers will have a degree of control over the data, even if\nthe format is carefully validated and scaled or recompressed. Therefore, the\nconcerns about such a document format being misinterpreted by a browser\nor a plug-in still remain.\n* The official MIME type for JavaScript is application/javascript, as per RFC 4329, but about a\ndozen other values have been used in the past (e.g., text/javascript, application/x-javascript,\napplication/ecmascript).\n† Naturally, exploitable coding errors occasionally happen in all programs that deal with\ncomplex data formats, and image parsers are no exception.\n118 Chapter 7"
  },
  {
    "input": "XML-Based Documents",
    "output": "Audio and Video\nFor a very long time, browsers had no built-in support for playing audio and\nvideo content, save for an obscure and oft-ridiculed <bgsound> tag in Internet\nExplorer, which to this day can be used to play simple MID or WAV files. In\nthe absence of real, cross-browser multimedia playback functionality, audio\nand video were almost exclusively the domain of browser plug-ins, whether\npurpose-built (such as Windows Media Player or Apple QuickTime) or generic\n(Adobe Flash, Microsoft Silverlight, and so on).\nThe ongoing work on HTML5 seeks to change this through support for\n<audio> and <video> tags: convenient, scriptable methods to interface with\nbuilt-in media decoders. Unfortunately, there is substantial vendor-level dis-\nagreement as to which video formats to support and what patent consequences\nthis decision may have. For example, while many browsers already support\nOgg Theora (a free, open source, but somewhat niche codec), spirited argu-\nments surrounding the merits of supporting the very popular but patent- and\nroyalty-encumbered H.264 format and the prospects of a new, Google-backed\nWebM alternative will probably continue for the foreseeable future.\nAs with other passive media formats (and unlike some types of plug-in-\nrendered content!), neither <bgsound> nor HTML5 multimedia are expected\nto have any unusual implications for web application security, as long as the\npossibility of content misidentification is mitigated appropriately.*\nXML-Based Documents\nReaders who found the handling of the formats discussed so far to be too\nsane for their tastes are in for a well-deserved treat. The largest and definitely\nmost interesting family of browser-supported non-HTML document types\nrelies on the common XML syntax and provides more than a fair share of\ninteresting surprises.\nSeveral of the formats belonging to this category are forwarded to\nspecialized, single-purpose XML analyzers, usually based on the received\nContent-Type value or other simple heuristics. But more commonly, the pay-\nload is routed to the same parser that is relied upon to render XHTML docu-\nments and then displayed using this common pipeline.\nIn the latter case, the actual meaning of the document is determined by\nthe URL-like xmlns namespace directives present in the markup itself, and\nthe namespace parameter may have nothing to do with the value originally\nsupplied in Content-Type. Quite simply, there is no mechanism that would pre-\nvent a document served as application/mathml+xml from containing nothing\nbut XHTML markup and beginning with <html xmlns=\"http://www.w3.org/\n1999/xhtml\">.\n* But some far-fetched interactions between various technologies are a distinct possibility. For\nexample, what if the <audio> tag supports raw, uncompressed audio and is pointed to a sensitive\nnonaudio document, and then the proposed HTML5 microphone API is used by another\nwebsite to capture the resulting waveform and reconstruct the contents of the file?\nNon-HTML Document Types 119"
  },
  {
    "input": "Generic XML View",
    "output": "In the most common scenario, the namespace for the entire XML file is\ndefined only once and is attached to the top-level tag. In principle, however,\nany number of different xmlns directives may appear in a single file, giving\ndifferent meanings to each section of the document. For example:\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n<u>Hello world!</u>\n<svg xmlns=\"http://www.w3.org/2000/svg\">\n<line x1=\"0\" y1=\"0\" x2=\"100\" y2=\"100\" style=\"stroke: red\" />\n</svg>\n</html>\nFaced with such input, the general-purpose renderer will usually do\nitsbest to make sense of all the recognized namespaces and assemble the\nmarkup into a single, consistent document with a normal Document Object\nModel representation. And, if any one of the recognized namespaces hap-\npens to support scripting, any embedded scripts will execute, too.\nBecause of the somewhat counterintuitive xmlns handling behavior,\nContent-Type is not a suitable way to control how a particular XML document\nwill be parsed; the presence of a particular top-level xmlns directive is also not\na guarantee that no other data formats will be honored later on. Any attacker-\ncontrolled XML-based formats must therefore be handled with care and san-\nitized very thoroughly.\nGeneric XML View\nIn most browsers, a valid XML document with no renderer-recognized\nnamespaces present anywhere in the markup will be shown as an interactive,\npretty-printed representation of the document tree, as shown in Figure 7-1.\nThis mode is not particularly useful to end users, but it can aid debugging.\nThat said, when any of the namespaces in the document is known to the\nbrowser (even when the top-level one is not recognized at all!), the document\nwill be rendered differently: All recognized markup will work as intended, all\nunsupported tags will simply have no effect, and any text between them will\nbe shown as is.\nTo illustrate this rendering strategy, consider the following input:\n<foo xmlns=\"http://www.example.com/nonexistent\">\n<u>Hello</u>\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n<u>world!</u>\n</html>\n</foo>\nThe above example will be rendered as “Hello world!” The first <u> tag,\nwith no semantics-defining namespace associated with it, will have no visible\neffect. The second one will be understood as an XHTML tag that triggers\nunderlining.\n120 Chapter 7"
  },
  {
    "input": "Scalable Vector Graphics",
    "output": "Figure 7-1: Firefox displaying an XML document with no recognized namespaces\nThe consequences of this fault-tolerant approach to the rendering of\nunknown XML documents and unrecognized namespaces are subtle but\nfairly important. For example, it will not be safe to proxy an unsanitized RSS\nfeed, even though this format is typically routed to a specialized renderer\nand thus not subject to XSS risks. Any browser with no built-in RSS reader\nmay fall back to generic rendering and then find HTML buried deep inside\nthe feed.\nScalable Vector Graphics\nScalable Vector Graphics (SVG)1 is a quickly evolving, XML-based vector\ngraphics format. First published in 2001 by W3C, it is noteworthy for its inte-\ngrated animation capabilities and direct JavaScript scripting features. The\nfollowing example of a vector image draws a circle and displays a message\nwhen this circle is clicked:\n<svg xmlns=\"http://www.w3.org/2000/svg\">\n<script><![CDATA[\nfunction clicked() { alert(\"Hi mom!\"); }\n]]></script>\n<circle onclick=\"clicked()\" cx=\"50\" cy=\"50\"\nr=\"50\" fill=\"pink\" />\n</svg>\nNon-HTML Document Types 121"
  },
  {
    "input": "XML User Interface Language",
    "output": "The SVG file format is recognized all modern browsers except for\nInternet Explorer prior to 9, and it is handled by the general-purpose XML\nrenderer. SVG images can be embedded into XHTML with an appropriate\nxmlns directive or inlined in non-XML HTML5 documents using a pre-\ndefined <svg> tag.\nInterestingly, in several browsers the format can also be placed in a stand-\nalone XML document and then viewed directly, or it can be loaded on third-\nparty pages via the <img> markup. While it is safe to load SVG images via <img>\n(scripting should be disabled in this scenario), it is fairly dangerous to host\nuser-supplied SVG data because in cases of direct navigation, all embedded\nscripts will execute in the context of the hosting domain. This unexpected\nproblem means that serving any externally originating SVG images will require\nvery careful syntax sanitization to eliminate non-SVG xmlns content from the\nXML container and to permit only certain types of markup in the remainder\nof the document.\nNOTE The Content-Disposition header on the relevant HTTP responses is a potential\nworkaround that permits SVG to be included via <img> but not accessed directly. This\napproach is not perfect, but it limits the risk. Using a throwaway domain to host such\nimages is another possibility.\nMathematical Markup Language\nMathematical Markup Language (MathML)2 is a fairly straightforward means\nto facilitate the semantic, if a bit verbose, representation of mathematical\nequations. The standard was originally proposed by the W3C in 1998, and it\nhas been substantially refined through the years. Because of its somewhat\nniche application, MathML needed over a decade to gain partial support in\nOpera and Firefox browsers, but it is slowly gaining acceptance today. In the\nbrowsers that support the language, it may be placed in a standalone file or\ninline in XHTML and HTML5 documents.\nUnlike SVG, MathML has no additional security considerations beyond\nthose associated with generically handled XML.\nXML User Interface Language\nThe XML User Interface Language (XUL)3 is a presentation markup lan-\nguage created by Mozilla specifically for building browser-based applications,\nrather than documents. XUL exists because although modern HTML is often\npowerful enough to build basic graphical user interfaces, it is not particularly\nconvenient for certain specialized tasks that desktop applications excel in,\nsuch as implementing common dialog windows or system menus.\nXUL is not currently supported by any browser other than Firefox and\nappears to be disabled in the recent release, Firefox 6. In Firefox, it is handled\nby the general-purpose renderer, based on the appropriate xmlns namespace.\nFirefox uses XUL for much of its internal UI, but otherwise the language is\nseldom encountered on the Internet.\nFrom the standpoint of web application security, Internet-originating\nXUL documents can be considered roughly equivalent to HTML documents.\n122 Chapter 7"
  },
  {
    "input": "RSS and Atom Feeds",
    "output": "Essentially, the language has JavaScript scripting capabilities and allows broad\ncontrol over the appearance of the rendered page. Other than that property,\nit has no unusual quirks.\nWireless Markup Language\nWireless Markup Language (WML)4 is a largely obsolete “optimized” HTML\nsyntax developed in the 1990s by a consortium of mobile handset manufac-\nturers and cellular network operators. This XML-based language, a part of\nthe Wireless Application Protocol suite (WAP), offered a simplified weblike\nbrowsing experience for pre-smartphone devices with limited bandwidth and\nCPU resources.* A simple WML page might have looked like this:\n<wml>\n<card title=\"Hello world!\">\n<a href=\"elsewhere.wml\">Click here!</a>\n</card>\n</wml>\nBecause WAP services needed to be engineered independently of nor-\nmal HTML content and had to deal with closed and underspecified client\narchitectures and other carrier-imposed restrictions, WML never became as\npopular as its proponents hoped. In almost all developed markets, WML has\nbeen displaced by fast, Internet-enabled smartphones with fully featured\nHTML browsers. Nevertheless, the legacy of the language lives on, and it is\nstill routed to specialized renderers in Opera and in Internet Explorer Mobile.\nIn the browsers that support the format, it is often possible to use WML-\nbased scripts. There are two methods to achieve this. The canonical way is to\nuse WMLScript (WMLS), a JavaScript-derived execution environment that\ndepends on stand-alone script files, coupled with an extremely inconsiderate\nabuse of fragment IDs for an equivalent of possibly attacker-controlled\neval(...) statements:\n<a href=\"scriptfile.wmls#some_function()\">Click here!</a>\nThe other method of executing scripts, available in more featured brows-\ners, is to simply embed normal javascript: URLs or insert <script> blocks into\nthe WML file.\nRSS and Atom Feeds\nFeeds are a standardized way for clients to periodically poll sites of interest\ntousers (such as their favorite blogs) for machine-readable updates to said\nsites’ content. Really Simple Syndication (RSS)5 and Atom6 are two superfi-\ncially similar but fiercely competing XML-based feed formats. The first (RSS)\nis popular; the second (Atom) is said to be good.\n* Astute readers will note that XML is not a particularly good way to conserve bandwidth or CPU\nresources. To that effect, the WAP suite provides an alternative, binary-only serialization of\nXML, known as WBXML.\nNon-HTML Document Types 123"
  },
  {
    "input": "A Note on Nonrenderable File Types",
    "output": "Built-in, specialized RSS and Atom renderers are available in Firefox,\nSafari, and Opera. The determination to route an XML document to these\nmodules is based on simple, browser-specific heuristics, such as the top-level\ntag being named <rss> or <feed> (and not having any conflicting xmlns direc-\ntives). In Firefox, RSS parsing may kick in even if Content-Type is image/svg+xml\nor text/html. Safari will happily recognize feeds in even more unrelated MIME\ntypes.\nOne interesting feature of both feed formats is that they permit a subset\nof HTML, including CSS, to be embedded in a document in a rather pecu-\nliar, indirect way: as an entity-escaped text. Here is an example of this syntax:\n<rss>\n...\n<description type=\"html\">\n&lt;u&gt; Underlined text! &lt;/u&gt;\n</description>\n...\n</rss>\nThe subset of HTML permitted in RSS and Atom feeds is not well defined,\nand some feed renderers have previously permitted direct scripting or navi-\ngation to potentially dangerous pseudo-URLs. Perhaps more importantly,\nhowever, any browser that does not have built-in feed previews may render\nthe file using the generic XML parsing approach; if such feeds are not sani-\ntized carefully, script execution will ensue.\nA Note on Nonrenderable File Types\nFor the sake of completeness, it should be noted that all modern browsers\nsupport a number of specialized file formats that remain completely opaque\nto the renderer or to the web application layer but that are nevertheless rec-\nognized by a variety of in-browser subsystems.\nA detailed investigation of these formats is beyond the scope of this\nbook, but some notable examples include plug-in and extension installation\nmanifests, automatic HTTP proxy autoconfiguration files (PAC), installable\nvisual skins, Certificate Revocation Lists (CRLs), antimalware site blacklists,\nand downloadable TrueType and OpenType fonts.\nThe security properties of these mechanisms should be studied individ-\nually before deciding to allow any of these formats to be served to the user.\nSave for the generic content-hosting considerations outlined in Chapter 13,\nthey are unlikely to harm the hosting web application directly, but they may\ncause problems for users.\n124 Chapter 7"
  },
  {
    "input": "On All Non-HTML Document Types",
    "output": "Security Engineering Cheat Sheet\nWhen Hosting XML-Based Document Formats\nAssume that the payload may be interpreted as XHTML or some other script-enabled docu-\nment type, regardless of the Content-Type and the top-level xmlns directive. Do not allow uncon-\nstrained attacker-controlled markup anywhere inside the file. Use the Content-Disposition:\nattachment if data is not meant to be viewed directly; <img> and feeds will still work.\nOn All Non-HTML Document Types\nUse correct, browser-recognized Content-Type and charset values. Specify the Content-Disposition:\nattachment where possible. Verify and constrain output syntax. Consult the cheat sheet in\nChapter 13 to avoid security problems related to content-sniffing flaws.\nNon-HTML Document Types 125"
  },
  {
    "input": "8: Content Rendering with Browser Plug-ins\r",
    "output": "C O N T E N T R E N D E R I N G W I T H\nB R O W S E R P L U G - I N S\nBrowser plug-ins come in many forms and shapes, but\nthe most common variety give the ability to display new\nfile formats in the browser, as if they were HTML. The\nbrowser simply hands over the retrieved file, provides\nthe helper application with a rectangular drawing sur-\nface in the document window, and essentially backs away\nfrom the scene. Such content-rendering plug-ins are clearly distinguished from\nbrowser extensions, a farmore numerous bunch that commonly relies on\nJavaScript code to tweak how the already-supported, in-browser content is\npresented to the user.\nBrowser plug-ins have a long and colorful history of security flaws. In\nfact, according to some analysts, 12 out of the 15 most frequently exploited\nclient-side vulnerabilities in 2010 could be attributed to the quality of plug-in\nsoftware.1 Many of these problems are because the underlying parsers were\noriginally not meant to handle malicious inputs gracefully and have not ben-\nefited from the intense scrutiny that the remainder of the Web has been sub-\nject to. Other problems stem from the unusual security models devised by"
  },
  {
    "input": "Invoking a Plug-in",
    "output": "plug-in developers and the interference between these permissions, the tra-\nditional design of web browsers, and the commonsense expectations of appli-\ncation developers.\nWe will review some of the security mechanisms used by popular plug-ins\nin the next chapter of this book. Before taking this dive, it makes sense to\nlook at the ways plug-ins integrate with other online content and the com-\nmon functionality they offer.\nInvoking a Plug-in\nContent-rendering plug-ins can be activated in a couple of ways. The most\npopular explicit method is to use <embed src=...> or <object data=...> markup\nina “host” HTML document, with the src or data parameter pointing to the\nURL from which the actual plug-in-recognized document is to be retrieved.\nThe dimensions and position of the drawable area allocated for the plug-in\ncan be controlled with CSS (or with legacy HTML parameters).\nIn this scenario, every <embed> or <object> tag should be accompanied by\nan additional type parameter. The MIME type specified there will be com-\npared to the list of MIME types registered by all the active plug-ins, and the\nretrieved file will be routed to the appropriate handler. If no match is found,\na warning asking the user to download a plug-in should be theoretically dis-\nplayed instead, although most browsers look at other signals before resorting\nto this unthinkable possibility; examining Content-Type or the apparent file\nextension spotted in the URL are two common choices.\nNOTE An obsolete <applet> tag, used to load Java programs (roughly equivalent to\n<objecttype=\"application/x-java-applet\">), works in a comparable way but\nunconditionally disregards these auxiliary signals.\nAdditional input to the plug-in is commonly passed using <param> tags\nnested inside the <object> block or through nonstandard additional parame-\nters attached to the <embed> markup itself. The former, more modern\napproach may look like this:\n<object data=\"app.swf\" type=\"application/x-shockwave-flash\">\n<param name=\"some_param1\" value=\"some_value1\">\n<param name=\"some_param2\" value=\"some_value2\">\n...\n</object>\nIn this content-inclusion mode, the Content-Type header returned by the\nserver when retrieving the subresource is typically ignored, unless the type\nparameter is unknown to the browser. This is an unfortunate design, for rea-\nsons that will be explained shortly.\nThe other method for displaying plug-in content involves navigating\ndirectly to a suitable file. In this case, and in the case of <embed> or <object>\nwith a missing type parameter, the Content-Type value obtained from the server\nis honored, and it will be compared with the list of plug-in-recognized MIME\n128 Chapter 8"
  },
  {
    "input": "The Perils of Plug-in Content-Type Handling",
    "output": "types. If a match is found, the content is routed to the appropriate component.\nIf the Content-Type lookup fails or the header is missing, some browsers will\nexamine the response body for known content signatures; others just give up.\nNOTE The aforementioned content-focused methods aside, several types of plug-ins can be\nloaded directly from within JavaScript or VBScript programs without the need to explic-\nitly create any HTML markup or retrieve any external data. Such is the case for ActiveX,\nan infamous script-to-system integration bridge available in Internet Explorer. (We will\ndevote some time to ActiveX later in this chapter, but first things first.)\nThe Perils of Plug-in Content-Type Handling\nAs noted in the previous section, in certain scenarios the Content-Type param-\neter on a retrieved plug-in-handled file is ignored, and the type parameter in\nthe corresponding markup on the embedding page is used instead. While\nthis decision is somewhat similar to the behavior of other type-specific con-\ntent-inclusion tags (say, <img>), as discussed in “Type-Specific Content Inclu-\nsion” on page82, it has some unique and ultimately disastrous consequences\nin the plug-in world.\nThe big problem is that several types of plug-ins are essentially full-\nfledged code execution environments and give the executed applications\n(applets) a range of special privileges to interact with the originating domain.\nFor example, a Flash file retrieved from fuzzybunnies.com would be granted\naccess to its originating domain (complete with a user’s cookies) when\nembedded on the decidedly rogue bunnyoutlet.com.\nIn such a scenario, it would seem to be important for fuzzybunnies.com\ntobe able to clearly communicate that a particular type of a document is\nindeed meant to be interpreted by a plug-in—and, consequently, that some\ndocuments aren’t meant to be used this way. Unfortunately, there is no way\nfor this to happen: The handling of a retrieved file is fully controlled by\ntheembedding site (in our example, by the mean-spirited bullies who own\nbunnyoutlet.com). Therefore, if the originating domain hosts any type of user-\ncontrolled content, even in a nominally harmless format (such as text/plain\nor image/jpeg), the owners of bunnyoutlet.com may instruct the browser to dis-\nregard the existing metadata and route that document to a plug-in of their\nchoice. A simple markup to achieve this sinister goal may be\n<object data=\"http://fuzzybunnies.com/avatars/user11630.jpg\"\ntype=\"application/x-shockwave-flash\">\nIf this turn of events seems wrong, that’s because it is. Security researchers\nhave repeatedly demonstrated that it is quite easy to construct documents that\nare, for example, simultaneously a valid image and a valid plug-in-recognized\nexecutable. The well-known “GIFAR” vulnerability, discovered in 2008 by\nBilly Rios,2 exploited that very trick: It smuggled a Java applet inside a per-\nfectly kosher GIF image. In response, Sun Microsystems reportedly tightened\ndown the Java JAR file parser to mitigate the risk, but the general threat of\nsuch mistakes is still very real and will likely rear its ugly head once more.\nContent Rendering with Browser Plug-ins 129"
  },
  {
    "input": "Document Rendering Helpers",
    "output": "Interestingly, the decision by some developers to rely on Content-Type and\nother signals if the type parameter is unrecognized is almost as bad. This deci-\nsion makes it impossible for the well-intentioned fuzzybunnies.com to safely\nembed a harmless video from the rogues at bunnyoutlet.com by simply specifying\ntype=\"video/x-ms-wmv\", because if any of the visitors do not have a plug-in for\nthat specific media type, bunnyoutlet.com will suddenly have a say in what type\nof plug-in should be loaded on the embedding site instead. Some browsers,\nsuch as Internet Explorer, Chrome, or Opera, may also resort to looking for\napparent file extensions present inthe URL, which can lead to an interesting\nsituation where neither the embedding nor the hosting party has real control\nover how a document is displayed—and quite often only the attacker is in\ncharge.\nA much safer design would require the embedder-controlled type param-\neter and the host-controlled Content-Type header to match (at least superfi-\ncially). Unfortunately, there is currently no way to make this happen. Several\nindividual plug-ins try to play nice (for example, following a 2008 overhaul,\nAdobe Flash rejects applets served with Content-Disposition: attachment, as does\nthe built-in PDF reader in Chrome), but these improvements are few and far\nbetween.\nDocument Rendering Helpers\nA significant portion of the plug-in landscape belongs to programs that allow\ncertain very traditional, “nonweb” document formats to be shown directly in\nthe browser. Some of these programs are genuinely useful: Windows Media\nPlayer, RealNetworks RealPlayer, and Apple QuickTime have been the back-\nbone of online multimedia playback for about a decade, at least until their\ndisplacement by Adobe Flash. The merits of others are more questionable,\nhowever. For example, Adobe Reader and Microsoft Office both install in-\nbrowser document viewers, increasing the user’s attack surface appreciably,\nthough it is unclear whether these viewers offer a real benefit over opening\nthe same document in a separate application with one extra click.\nOf course, in a perfect world, hosting or embedding a PDF or a Word\ndocument should have no direct consequences for the security of the partici-\npating websites. Yet, predictably, the reality begs to differ. In 2009, a researcher\nnoted that PDF-based forms that submit to javascript: URLs can apparently lead\nto client-side code execution on the embedding site.3 Perhaps even more trou-\nbling than this report alone, according to that researcher’s account, Adobe ini-\ntially dismissed the report with the following note: “Our position is that, like\nan HTML page, a PDF file is active content.”\nIt is regrettable that the hosting party does not have full control of when\nthis active content is detected and executed and that otherwise reasonable\nwebmasters may think of PDFs or Word documents as just a fancy way to pre-\nsent text. In reality, despite their harmless appearance, in a bid to look cool,\nmany such document formats come equipped with their own hyperlinking\ncapabilities or even scripting languages. For example, JavaScript code can\nbeembedded in PDF documents, and Visual Basic macros are possible in\n130 Chapter 8"
  },
  {
    "input": "Plug-in-Based Application Frameworks",
    "output": "Microsoft Office files. When a script-bearing document is displayed on an\nHTML page, some form of a programmatic plug-in-to-browser bridge usually\npermits a degree of interaction with the embedding site, and the design of\nsuch bridges can vary from vaguely questionable to outright preposterous.\nIn one 2007 case, Petko D. Petkov noticed that a site that hosts any\nPDFdocuments can be attacked simply by providing completely arbitrary\nJavaScript code in the fragment identifier. This string will be executed on\nthehosting page through the plug-in bridge:4\nhttp://example.com/random_document.pdf#foo=javascript:alert(1)\nThe two vulnerabilities outlined here are now fixed, but the lesson is\nthatspecial care should be exercised when hosting or embedding any user-\nsupplied documents in sensitive domains. The consequences of doing so are\nnot well documented and can be difficult to predict.\nPlug-in-Based Application Frameworks\nThe boring job of rendering documents is a well-established role for browser\nplug-ins, but several ambitious vendors go well beyond this paradigm. The\naim of some plug-ins is simply to displace HTML and JavaScript by providing\nalternative, more featured platforms for building interactive web applications.\nThat reasoning is not completely without merit: Browsers have long lacked\ninperformance, in graphics capabilities, and in multimedia codecs, stifling\nsome potential uses of the Web. Reliance on plug-ins is a reasonable short-\nterm way to make a difference. On the flip side, when proprietary, patent-\nand copyright-encumbered plug-ins are promoted as the ultimate way to build\nan online ecosystem, without any intent to improve the browsers themselves,\nthe openness of the Web inevitably suffers. Some critics, notably Steve Jobs,\nthink that creating a tightly controlled ecosystem is exactly what several plug-\nin vendors, most notably Adobe, aspire to.5\nIn response to this perceived threat of a hostile takeover of the Web,\nmany of the shortcomings that led to the proliferation of alternative applica-\ntion frameworks are now being hastily addressed under the vaguely defined\numbrella of HTML5; <video> tags and WebGL* are the prime examples of this\nwork. That said, some of the features available in plug-ins will probably not be\ncaptured as a part of any browser standard in the immediate future. For exam-\nple, there is currently no serious plan to add inherently dangerous elevated\nprivilege programs supported by Java or security-by-obscurity content protec-\ntion schemes (euphemistically called Digital Rights Management, or DRM).\nTherefore, while the landscape will change dramatically in the coming\nyears, we can expect that in one form or another, proprietary web applica-\ntion frameworks are here to stay.\n* WebGL is a fairly recent attempt to bring OpenGL-based 3D graphics to JavaScript applica-\ntions. The first specification of the standard appeared in March 2011, and wide browser-level\nsupport is expected to follow.\nContent Rendering with Browser Plug-ins 131"
  },
  {
    "input": "Adobe Flash",
    "output": "Adobe Flash\nAdobe Flash is a web application framework introduced in 1996, in the heat\nof the First Browser Wars. Before its acquisition by Adobe in 2005, the Flash\nplatform was known as Macromedia Flash or Shockwave Flash (hence the .swf\nfile extension used for Flash files), and it is still sometimes referred to as such.\nFlash is a fairly down-to-earth platform built on top of a JavaScript-based\nlanguage dubbed ActionScript.7 It includes a 2-D vector and bitmap graphics-\nrendering engine and built-in support for several image, video, and audio\nformats, such as the popular and efficient H.264 codec (which is used for\nmuch of today’s online multimedia).\nBy most estimates, Flash is installed on around 95 to 99 percent of all\ndesktop systems.8, 9 This user base is substantially higher than that of any\nother media player plug-in. (Support for the Windows Media Player and\nQuickTime plug-ins is available on only about 60 percent of PCs, despite\naggressive bundling strategies, while the increasingly unpopular RealPlayer\nisstill clinging to 25 percent.) The market position contributes to the prod-\nuct’s most significant and unexpected use: the replacement of all multimedia\nplayback plug-ins previously relied upon for streaming video on the Web.\nAlthough the plug-in is also used for a variety of other jobs (including imple-\nmenting online games, interactive advertisements, and so on), simple multi-\nmedia constitutes a disproportionately large slice of the pie.\nNOTE Confusingly, a separate plug-in called Adobe Shockwave Player (without the word\n“Flash”) is also available, which can be used to play back content created with Adobe\nDirector. This plug-in is sometimes mistakenly installed in place of or alongside Adobe\nFlash, contributing to an approximately 20 percent install base,6 but it is almost always\nunnecessary. The security properties of this plug-in are not particularly well studied.\nProperties of ActionScript\nThe capabilities of ActionScript in SWF files are generally analogous to those\nof JavaScript code embedded on HTML pages with some minor, yet interest-\ning, differences. For example, Flash programs are free to enumerate all fonts\ninstalled on a system and collect other useful system fingerprinting signals\nnot available to normal scripts. Flash programs can also use full screen ren-\ndering, facilitating UI spoofing attacks, and they can request access to input\ndevices such as a camera or a microphone (this requires the user’s consent).\nFlash also tends to ignore browser security and privacy settings and uses its\nown configuration for mechanisms such as in-plug-in persistent data storage\n(although some improvements in this area were announced in May 2011).\nThe remaining features are less surprising. We’ll discuss the network\nandDOM access permissions of Flash applications in more detail in the next\nchapter, but in short, by default, every Flash applet can use the browser HTTP\nstack (and any ambient credentials managed therein) to talk back to its orig-\ninating server, request a limited range of subresources from other sites, and\nnavigate the current browser window or open a new one. ActionScript pro-\ngrams may also negotiate browser-level access to other currently running\n132 Chapter 8\nFlash applications and, in some cases, access the DOM of the embedding\npage. This last functionality is implemented by injecting eval(...)-like state-\nments into the target JavaScript context.\nActionScript offers fertile ground for web application vulnerabilities.\nForexample, the getURL(...) and navigateToURL(...) functions, used to navi-\ngate the browser or open new windows, are sometimes invoked with attacker-\ncontrolled inputs. Such a use is dangerous. Even though javascript: URLs do\nnot have a special meaning to Flash, the function will pass such strings to the\nbrowser, in some cases resulting in script injection on the embedding site.\nUntil recently, a related problem was present with other URL-handling\nAPIs, such as loadMovie(...). Even though the function did not rely on the\nbrowser to load the document, it would recognize an internal asfunction:\nscheme, which works similarly to eval(...) and could be trivially leveraged to\nperform a call to getURL(...):\nasfunction:getURL,javascript:alert('Hi mom!')\nThe issue with loading scripts from untrusted sources, discussed in\nChapter 6, also has an equivalent in the plug-in word. In Flash, it is very unsafe\nto invoke certain functions that affect the state of the ActionScript execution\nenvironment (such as the LoadVars.load(...)) with attacker-controlled URLs,\neven if the scheme from which the resource is loaded is http: or https:.\nAnother commonly overlooked attack surface is the internal, simpli-\nfied HTML parser offered by the Flash plug-in: Basic HTML markup can be\nassigned to properties such as TextField.htmlText and TextArea.htmlText. It is easy\nto forget that user-supplied content must be escaped correctly in this setting.\nFailure to do so may permit attackers to modify the appearance of the appli-\ncation UI or to inject potentially problematic scripting-oriented links.\nYet another class of Flash-related security bugs may arise due to design\norimplementation problems in the plug-in itself. For example, take the\nExternalInterface.call(...) API. It is meant to allow ActionScript to call existing\nJavaScript functions on the embedding page and takes two parameters: the\nname of the JavaScript function to call and an optional string to be passed to\nthis routine. While it is understood that the first parameter should not be\nattacker controlled, it appears to be safe to put user data in the second one.\nIn fact, the documentation provides the following code snippet outlining this\nspecific use case:10\nExternalInterface.call(\"sendToJavaScript\", input.text);\nThis call will result in the following eval(...) statement being injected on\nthe embedding page:\ntry {\n__flash__toXML(sendToJavaScript, \"value of input.text\"));\n} catch (e) {\n\"<undefined/>\";\n}\nContent Rendering with Browser Plug-ins 133"
  },
  {
    "input": "Sun Java",
    "output": "When writing the code behind this call, the authors of the plug-in\nremembered to use backslash escaping when outputting the second parame-\nter: hello\"world becomes hello\\\"world. Unfortunately, they overlooked the need\nto escape any stray backslash characters, too. Because of this, if the value of\ninput.text is set to the following string, the embedded script will unexpectedly\nexecute:\nHello world!\\\"+alert(1)); } catch(e) {} //\nI contacted Adobe about this particular problem in March 2010. Over a\nyear later, its response was this: “We have not made any change to this behav-\nior for backwards compatibility reasons.”\nThat seems unfortunate.\nMicrosoft Silverlight\nMicrosoft Silverlight is a versatile development platform built on the Windows\nPresentation Foundation, a GUI framework that is a part of Microsoft’s .NET\nstack. It debuted in 2007 and combines an Extensible Application Markup\nLanguage (XAML)11 (Microsoft’s alternative to Mozilla’s XUL) with code writ-\nten in one of several managed .NET languages,* such as C# or Visual Basic.\nDespite substantial design differences and a more ambitious (and con-\nfusing) architecture, this plug-in is primarily meant to compete with Adobe\nFlash. Many of the features available to Silverlight applications mirror those\nimplemented in its competitor, including a nearly identical security model\nand a similar eval(...)-based bridge to the embedding page. To Microsoft’s\ncredit, Silverlight does not come with an equivalent of the asfunction: scheme\nor with a built-in HTML renderer, however.\nSilverlight is marketed by Microsoft fairly aggressively, and it is bundled\nwith some editions of Internet Explorer. As a result, depending on the source,\nit is believed to have about a 60 to 75 percent desktop penetration.12 Despite\nits prevalence, Silverlight is used fairly infrequently to develop actual web\napplications, perhaps because it usually offers no compelling advantages over\nits more established counterpart or because its architecture is seen as more\ncontrived and platform-specific. (Netflix, a popular video streaming and\nrental service, is one of the very few high-profile websites that actually relies\non Silverlight for playback on some devices.)\nSun Java\nJava is a programming language coupled with a platform-independent,\nmanaged-code execution platform. Developed in the early to mid-1990s by\nJames Gosling for Sun Microsystems, Java has a well-established role as a server-\nside programming language and a very robust presence in many other niches,\n* Managed code is not executed directly by the CPU (which would be inherently unsafe, because\nCPUs are not designed to enforce web security rules). Rather, it is compiled to an intermediate\nbinary form and then interpreted at runtime by a specialized virtual machine. Thisapproach is\nfaster than interpreting scripts at runtime and permits custom security policy enforcement as\nthe program is being executed.\n134 Chapter 8"
  },
  {
    "input": "XML Browser Applications (XBAP)",
    "output": "including mobile devices. Yet, from the beginning, Sun hoped that Java\nwould also occupy a prominent place on the browser end.\nJava in the browser predated Flash and most similar plug-ins, and the\nnow-obsolete <applet> tag is a testament to how important and unique and\nnovel this addition must have seemed back in its day. Yet, despite this head\nstart, the Java language is nearly extinct as an in-browser development plat-\nform, and even in its heyday it never enjoyed real prominence. It retains a\nremarkable 80 percent installed base, but this high percentage is attributed\nlargely to the fact that the Java plug-in is bundled with Java Runtime Environ-\nment (JRE), a more practically useful and commonly preinstalled compo-\nnent that is required to run normal, desktop Java applications on the system\nwithout any involvement on the browser end.\nThe reasons for the failure of Java as a browser technology are difficult\ntopinpoint. Perhaps it’s due to the plug-in’s poor startup performance, the\nclunky UI libraries that made it difficult to develop snappy and user-friendly\nweb applications, or the history of vicious litigation between Sun and Microsoft\nthat cast a long shadow over the future of the language on Microsoft’s oper-\nating systems.* Whatever the reasons may be, the high install base of Java\ncoupled with its marginal use means that the risks it creates far outweigh any\npotential benefits to the users. (The plug-in had close to 80 security vulnera-\nbilities in 2010,13 and the vendor is commonly criticized for patching such\nbugs very slowly.)\nJava’s security policies are somewhat similar to those of other plug-ins,\nbut in some aspects, such as its understanding of the same-origin policy or\nitsability to restrict access to the embedding page, it compares unfavorably.\n(The next chapter provides an overview of this.) It is also worth noting that\nunlike with Flash or Silverlight, certain types of cryptographically signed\napplets may request access to potentially dangerous OS features, such as\nunconstrained networking or file access, and only a user’s easily coaxed\nconsent stands in the way.\nXML Browser Applications (XBAP)\nXML Browser Applications (XBAP)14 is Microsoft’s heavy-handed foray into\nthe world of web application frameworks, attempted in the years during\nwhich the battle over Java started going sour and before the company\nreleased Silverlight.\nXBAP is reminiscent of Silverlight in that it leverages the same Windows\nPresentation Foundation and .NET architecture. However, instead of being a\nself-contained and snappy browser plug-in, it depends on the large and unwieldy\n.NET runtime, in a manner similar to the Java plug-in’s dependence on JRE.\nIt executes the managed code in a separate process called PresentationHost.exe,\noften loading extensive dependencies at initialization time. By Microsoft’s own\nadmission, the load time of a medium-size previously uncached application\n* The legal battles started in 1997, when Microsoft decided to roll out its own (and in some\nways,superior) version of the Java virtual machine. Sun Microsystems sued, hoping to win an\ninjunction that would force Microsoft to bundle Sun’s version instead. The two companies ini-\ntially settled in 2001, but shortly thereafter they headed back to court. In the final settlement in\n2004, Sun walked away with $1.6 billion in cash, but Windows users were not getting any Java\nruntime at all.\nContent Rendering with Browser Plug-ins 135"
  },
  {
    "input": "ActiveX Controls",
    "output": "could easily reach 10 seconds or more. When the technology premiered in\n2002, most users were already expecting Internet applications to be far more\nresponsive than that.\nThe security model of XBAP applications is poorly documented and has\nnot been researched to date, perhaps due to XBAP’s negligible real-world\nuse and obtuse, multilayer architecture. One would reasonably expect that\nXBAP’s security properties would parallel the model eventually embraced for\nSilverlight, but with broader access to certain .NET libraries and UI widgets.\nAnd, apparently as a result of copying from Sun, XBAP programs can also be\ngiven elevated privileges when loaded from the local filesystem or signed\nwith a cryptographic certificate.\nMicrosoft bundled XBAP plug-ins with its .NET framework to the point of\nsilently installing nonremovable Windows Presentation Foundation plug-ins—\nnot only in Internet Explorer but also in the competing Firefox and Chrome.\nThis move stirred some well-deserved controversy, especially once the first\nvulnerability reports started pouring in. (Mozilla even temporarily disabled\nthe plug-in through an automated update to protect its users.) Still, despite\nsuch bold and questionable moves to popularize it, nobody actually wanted\nto write XBAP applets, and inch by inch, the technology followed Java into\nthe dustbin of history.\nEventually, Microsoft appeared to acknowledge this failure and chose to\nfocus on Silverlight instead. Beginning with Internet Explorer 9, XBAP is dis-\nabled by default for Internet-originating content, and the dubious Firefox\nand Chrome plug-ins are no longer automatically pushed to users. Neverthe-\nless, it seems reasonable to assume that at least 10 percent of all Internet\nusers may be still browsing with a complex, partly abandoned, and largely\nunnecessary plug-in installed on their machines and will continue to do so\nfor the next couple of years.\nActiveX Controls\nAt its core, ActiveX is the successor to Object Linking and Embedding\n(OLE), a 1990 technology that made it possible for programs to reuse com-\nponents of other applications in a standardized, language-independent way.\nA simple use case for ActiveX would be a spreadsheet application wishing to\nembed an editable vector image from a graphics-editing program or a simple\ngame that wants to embed a video player.\nThe idea is not controversial, but by the mid-1990s Microsoft had decided\nthat ActiveX made sense in the browser, too. After all, wouldn’t websites want\nto benefit from the same Windows components that desktop applications could\nrely on? The approach violates the idea of nurturing an open, OS-independent\nweb, but it’s otherwise impressive, as illustrated by the following JavaScript\nexample that casually creates, edits, and saves an Excel spreadsheet:\nvar sheet = new ActiveXObject(\"Excel.Sheet\");\nsheet.ActiveSheet.Cells(42,42).Value = \"Hi mom!\";\nsheet.SaveAs(\"c:\\\\spreadsheet.xls\");\nsheet.Application.Quit();\n136 Chapter 8"
  },
  {
    "input": "Living with Other Plug-ins",
    "output": "Standards compliance aside, Microsoft’s move to ActiveX proved disas-\ntrous from a security standpoint. Many of the exposed ActiveX components\nwere completely unprepared to behave properly when interacting with\nuntrusted environments, and over the next 15 years, researchers discovered\nseveral hundred significant security vulnerabilities in web-accessible ActiveX\ncontrols. Heck, the simple observation that Firefox does not support this\ntechnology helped bolster its security image at the onset of the Second\nBrowser Wars.\nDespite this fiasco, Microsoft stood by ActiveX defiantly, investing in grad-\nually limiting the number of controls that could be accessed from the Inter-\nnet and fixing the bugs in those it considered essential. Not until Internet\nExplorer 9 did Microsoft finally decide to let go: Internet Explorer 9 disables\nall ActiveX access by default, requiring several extra clicks to use it when needed.\nNOTE The wisdom of delegating the choice to the user is unclear, especially since the permission\ngranted to a site extends not only to legitimate content on that website but also to any\npayloads injected due to application bugs such as XSS. Still, Internet Explorer 9 is\nsome improvement.\nLiving with Other Plug-ins\nSo far, we have covered almost all general-purpose browser plug-ins in use\ntoday. Although there is a long tail of specialized or experimental plug-ins,\ntheir use is fairly insignificant and not something that we need to take into\naccount when surveying the overall health of the online ecosystem.\nWell, with one exception. An unspecified but probably significant\npercentage of online users can be expected to have an assortment of web-\nexposed browser plug-ins or ActiveX controls that they never knowingly\ninstalled, or that they were forced to install even though it’s doubtful that\nthey would ever benefit from the introduced functionality.\nThis inexcusable practice is sometimes embraced by otherwise reputable\nand trusted companies. For example, Adobe forces users who wish to down-\nload Adobe Flash to also install GetRight, a completely unnecessary third-\nparty download utility. Microsoft does the same with Akamai Download Man-\nager on its developer-oriented website, complete with a hilarious justification\n(emphasis mine):15\nWhat is the Akamai Download Manager and why do I have to use it?\nTo help you download large files with reduced chance of inter-\nruption, some downloads require the use of the Akamai Download\nManager.\nThe primary concern with software installed this way and exposed\ndirectly to malicious input from anywhere on the Internet is that unless it\nisdesigned with extreme care, it is likely to have vulnerabilities (and sure\nenough, both GetRight and Akamai Download Manager had some). There-\nfore, the risks of browsing with a completely unnecessary plug-in that only\nserved a particular purpose once or twice far outweigh the purported (and\nusually unwanted) benefits.\nContent Rendering with Browser Plug-ins 137"
  },
  {
    "input": "If You Want to Write a New Browser Plug-in or ActiveX Component",
    "output": "Security Engineering Cheat Sheet\nWhen Serving Plug-in-Handled Files\n Data from trusted sources: Data from trusted sources is generally safe to host, but remem-\nber that security vulnerabilities in Flash, Java, or Silverlight applets, or in the Adobe Reader\nJavaScript engine, may impact the security of your domain. Avoid processing user-supplied\nURLs and generating or modifying user-controlled HTML from within plug-in-executed\napplets. Exercise caution when using the JavaScript bridge.\n User-controlled simple multimedia: User-controlled multimedia is relatively safe to host,\nbut be sure to validate and constrain the format, use the correct Content-Type, and consult\nthe cheat sheet in Chapter 13 to avoid security problems caused by content-sniffing flaws.\n User-controlled document formats: These are not inherently unsafe, but they have an\nincreased risk of contributing security problems due to plug-in design flaws. Consider host-\ning from a dedicated domain when possible. If you need to authenticate the request to an\nisolated domain, do so with a single-use request token instead of by relying on cookies.\n User-controlled active applications: These are unsafe to host in sensitive domains.\nWhen Embedding Plug-in-Handled Files\nAlways make sure that plug-in content on HTTPS sites is also loaded over HTTPS,* and always\nexplicitly specify the type parameter on <object> or <embed>. Note that because of the non-\nauthoritative handling of type parameters, restraint must be exercised when embedding plug-\nin content from untrusted sources, especially on highly sensitive sites.\n Simple multimedia: It is generally safe to load simple multimedia from third-party sources,\nwith the caveats outlined above.\n Document formats: These are usually safe, but they carry a greater potential for plug-in\nand browser content-handling issues than simple multimedia. Exercise caution.\n Flash and Silverlight: In principle, Flash and Silverlight apps can be embedded safely\nfrom external sources if the appropriate security flags are present in the markup. If the\nflags are not specified correctly, you may end up tying the security of your site to that of\nthe provider of the content. Consult the cheat sheet in Chapter 9 for advice.\n Java: Java always ties the security of your service to that of the provider of the content,\nbecause DOM access to the embedding page can’t be reliably restricted. See Chapter 9.\nDo not load Java apps from untrusted sites.\nIf You Want to Write a New Browser Plug-in or ActiveX Component\nUnless you are addressing an important, common-use case that will benefit a significant\nfraction of the Internet, please reconsider. If you are scratching an important itch, consider\ndoing it in a peer-reviewed, standardized manner as a part of HTML5.\n* If loading an HTTP-delivered applet on an HTTPS page is absolutely unavoidable, it is safer to place it inside an\nintermediate HTTP frame rather than directly inside the HTTPS document, as this prevents the applet-to-JavaScript\nbridge from being leveraged for attacks.\n138 Chapter 8"
  },
  {
    "input": "PART II: Browser Security Features\r",
    "output": "PART II\nB R O W S E R S E C U R I T Y\nF E A T U R E S\nHaving reviewed the basic building blocks of the Web,\nwe can now comfortably examine all the security fea-\ntures that keep rogue web applications at bay. Part II\nof this book takes a look at everything from the well-\nknown but often misunderstood same-origin policy to\nthe obscure and proprietary zone settings of Internet\nExplorer. It explains what these mechanisms can do\nfor you—and when they tend to fall apart."
  },
  {
    "input": "9: Content Isolation Logic\r",
    "output": "C O N T E N T I S O L A T I O N L O G I C\nMost of the security assurances provided by web brows-\ners are meant to isolate documents based on their ori-\ngin. The premise is simple: Two pages from different\nsources should not be allowed to interfere with each\nother. Actual practice can be more complicated, how-\never, as no universal agreement exists about where a\nsingle document begins and ends or what constitutes asingle origin. The\nresult is a sometimes unpredictable patchwork of contradictory policies that\ndon’t quite work well together but that can’t be tweaked without profoundly\naffecting all current legitimate uses of the Web.\nThese problems aside, there is also little clarity about what actions should\nbe subject to security checks in the first place. It seems clear that some inter-\nactions, such as following a link, should be permitted without special restric-\ntions as they are essential to the health of the entire ecosystem, and that others,\nsuch as modifying the contents of a page loaded in a separate window,\nshould require a security check. But a large gray area exists between these\nextremes, and that middle ground often feels as if it’s governed more by a\nroll of the dice than by any unified plan. In these murky waters, vulnerabili-\nties such as cross-site request forgery (see Chapter 4) abound."
  },
  {
    "input": "Same-Origin Policy for the Document Object Model",
    "output": "It’s time to start exploring. Let’s roll a die of our own and kick off the\njourney with JavaScript.\nSame-Origin Policy for the Document Object Model\nThe same-origin policy (SOP) is a concept introduced by Netscape in 1995\nalongside JavaScript and the Document Object Model (DOM), just one year\nafter the creation of HTTP cookies. The basic rule behind this policy is\nstraightforward: Given any two separate JavaScript execution contexts, one\nshould be able to access the DOM of the other only if the protocols, DNS\nnames,* and port numbers associated with their host documents match\nexactly. All other cross-document JavaScript DOM access should fail.\nThe protocol-host-port tuple introduced by this algorithm is commonly\nreferred to as origin. As a basis for a security policy, this is pretty robust: SOP\nis implemented across all modern browsers with a good degree of consis-\ntency and with only occasional bugs.† In fact, only Internet Explorer stands\nout, as it ignores the port number for the purpose of origin checks. This\npractice is somewhat less secure, particularly given the risk of having non-\nHTTP services running on a remote host for HTTP/0.9 web servers (see\nChapter 3). But usually it makes no appreciable difference.\nTable 9-1 illustrates the outcome of SOP checks in a variety of situations.\nTable 9-1: Outcomes of SOP Checks\nOriginating document Accessed document Non–IE browser Internet Explorer\nhttp://example.com/a/ http://example.com/b/ Access okay Access okay\nhttp://example.com/ http://www.example.com/ Host mismatch Host mismatch\nhttp://example.com/ https://example.com/ Protocol mismatch Protocol mismatch\nhttp://example.com:81/ http://example.com/ Port mismatch Access okay\nNOTE This same-origin policy was originally meant to govern access only to the DOM ; that is,\nthe methods and properties related to the contents of the actual displayed document. The\npolicy has been gradually extended to protect other obviously sensitive areas of the root\nJavaScript object, but it is not all-inclusive. For example, non-same-origin scripts can usu-\nally still call location.assign() or location.replace(...) on an arbitrary window or a\nframe. The extent and the consequences of these exemptions are the subject of Chapter 11.\n* This and most other browser security mechanisms are based on DNS labels, not on examin-\ning the underlying IP addresses. This has a curious consequence: If the IP of a particular host\nchanges, the attacker may be able to talk to the new destination through the user’s browser, pos-\nsibly engaging in abusive behaviors while hiding the true origin of the attack (unfortunate, not\nvery interesting) or interacting with the victim's internal network, which normally would not be\naccessible due to the presence of a firewall (a much more problematic case). Intentional change\nof an IP for this purpose is known as DNS rebinding. Browsers try to mitigate DNS rebinding to\nsome extent by, for example, caching DNS lookup results for a certain time (DNS pinning), but\nthese defenses are imperfect.\n† One significant source of same-origin policy bugs is having several separate URL-parsing\nroutines in the browser code. If the parsing approach used in the HTTP stack differs from that\nused for determining JavaScript origins, problems may arise. Safari, in particular, combated a\nsignificant number of SOP bypass flaws caused by pathological URLs, including many of the\ninputs discussed in Chapter 2.\n142 Chapter 9"
  },
  {
    "input": "document.domain",
    "output": "The simplicity of SOP is both a blessing and a curse. The mechanism\nisfairly easy to understand and not too hard to implement correctly, but its\ninflexibility can be a burden to web developers. In some contexts, the policy\nis too broad, making it impossible to, say, isolate home pages belonging to\nseparate users (short of giving each a separate domain). In other cases, the\nopposite is true: The policy makes it difficult for legitimately cooperating sites\n(say, login.example.com and payments.example.com) to seamlessly exchange data.\nAttempts to fix the first problem—to narrow down the concept of an\norigin—are usually bound to fail because of interactions with other explicit\nand hidden security controls in the browser. Attempts to broaden origins or\nfacilitate cross-domain interactions are more common. The two broadly sup-\nported ways of achieving these goals are document.domain and postMessage(...),\nas discussed below.\ndocument.domain\nThis JavaScript property permits any two cooperating websites that share a\ncommon top-level domain (such as example.com, or even just .com) to agree\nthat for the purpose of future same-origin checks, they want to be considered\nequivalent. For example, both login.example.com and payments.example.com may\nperform the following assignment:\ndocument.domain = \"example.com\"\nSetting this property overrides the usual hostname matching logic during\nsame-origin policy checks. The protocols and port numbers still have to match,\nthough; if they don’t, tweaking document.domain will not have the desired effect.\nBoth parties must explicitly opt in for this feature. Simply because\nlogin.example.com has set its document.domain to example.com does not mean\nthat it will be allowed to access content originating from the website hosted\nat http://example.com/. That website needs to perform such an assignment,\ntoo, even if common sense would indicate that it is a no-op. This effect is sym-\nmetrical. Just as a page that sets document.domain will not be able to access\npages that did not, the action of setting the property also renders the caller\nmostly (but not fully!)* out of reach of normal documents that previously\nwould have been considered same-origin with it. Table 9-2 shows the effects\nof various values of document.domain.\nDespite displaying a degree of complexity that hints at some special sort\nof cleverness, document.domain is not particularly safe. Its most significant\nweakness is that it invites unwelcome guests. After two parties mutually set\nthis property to example.com, it is not simply the case that login.example.com\nand payments.example.com will be able to communicate; funny-cat-videos.example\n.com will be able to jump on the bandwagon as well. And because of the degree\n* For example, in Internet Explorer, it will still be possible for one page to navigate any other doc-\numents that were nominally same-origin but that became “isolated” after setting document.domain,\nto javascript: URLs. Doing so permits any JavaScript to execute in the context of such as a pseudo-\nisolated domain. On top of this, obviously nothing stops the originating page from simply setting\nits own document.domain to a value identical with that of the target in order to eliminate the bound-\nary. In other words, the ability to make a document non-same-origin with other pages through\ndocument.domain should not be relied upon for anything even remotely serious or security relevant.\nContent Isolation Logic 143"
  },
  {
    "input": "postMessage(...)",
    "output": "of access permitted between the pages, the integrity of any of the participat-\ning JavaScript contexts simply cannot be guaranteed to any realistic extent.\nIn other words, touching document.domain inevitably entails tying the security\nof your page to the security of the weakest link in the entire domain. An\nextreme case of setting the value to *.com is essentially equivalent to assisted\nsuicide.\nTable 9-2: Outcomes of document.domain Checks\nOriginating document Accessed document Outcome\ndocument document\nURL .domain URL .domain\nhttp://www.example.com/ example.com http://payments.example.com/ example.com Access okay\nhttp://www.example.com/ example.com https://payments.example.com/ example.com Protocol\nmismatch\nhttp://payments.example.com/ example.com http://example.com/ (not set) Access denied\nhttp://www.example.com/ (not set) http://www.example.com/ example.com Access denied\npostMessage(...)\nThe postMessage(...) API is an HTML5 extension that permits slightly less\nconvenient but remarkably more secure communications between non-same-\norigin sites without automatically giving up the integrity of any of the parties\ninvolved. Today it is supported in all up-to-date browsers, although because it\nis fairly new, it is not found in Internet Explorer 6 or 7.\nThe mechanism permits a text message of any length to be sent to any\nwindow for which the sender holds a valid JavaScript handle (see Chapter 6).\nAlthough the same-origin policy has a number of gaps that permit similar\nfunctionality to be implemented by other means,* this one is actually safe to\nuse. It allows the sender to specify what origins are permitted to receive the\nmessage in the first place (in case the URL of the target window has changed),\nand it provides the recipient with the identity of the sender so that the integ-\nrity of the channel can be ascertained easily. In contrast, legacy methods that\nrely on SOP loopholes usually don’t come with such assurances; if a particu-\nlar action is permitted without robust security checks, it can usually also be\ntriggered by a rogue third party and not just by the intended participants.\nTo illustrate the proper use of postMessage(...), consider a case in which a\ntop-level document located at payments.example.com needs to obtain user login\ninformation for display purposes. To accomplish this, it loads a frame point-\ning to login.example.com. This frame can simply issue the following command:\nparent.postMessage(\"user=bob\", \"https://payments.example.com\");\n* More about this in Chapter 11, but the most notable example is that of encoding data in URL\nfragment identifiers. This is possible because navigating frames to a new URL is not subject to\nsecurity restrictions in most cases, and navigation to a URL where only the fragment identifier\nchanges does not actually trigger a page reload. Framed JavaScipt can simply poll location.hash\nand detect incoming messages this way.\n144 Chapter 9"
  },
  {
    "input": "Interactions with Browser Credentials",
    "output": "The browser will deliver the message only if the embedding site indeed\nmatches the specified, trusted origin. In order to securely process this response,\nthe top-level document needs to use the following code:\n// Register the intent to process incoming messages:\naddEventListener(\"message\", user_info, false);\n// Handle actual data when it arrives:\nfunction user_info(msg) {\nif (msg.origin == \"https://login.example.com\") {\n// Use msg.data as planned\n}\n}\nPostMessage(...) is a very robust mechanism that offers significant benefits\nover document.domain and over virtually all other guerrilla approaches that\npredate it; therefore, it should be used as often as possible. That said, it can\nstill be misused. Consider the following check that looks for a substring in\nthe domain name:\nif (msg.origin.indexOf(\".example.com\") != -1) { ... }\nAs should be evident, this comparison will not only match sites within\nexample.com but will also happily accept messages from www.example.com\n.bunnyoutlet.com. In all likelihood, you will stumble upon code like this more\nthan once in your journeys. Such is life!\nNOTE Recent tweaks to HTML5 extended the postMessage(...) API to incorporate somewhat\noverengineered “ports” and “channels,” which are meant to facilitate stream-oriented\ncommunications between websites. Browser support for these features is currently very\nlimited and their practical utility is unclear, but from the security standpoint, they do\nnot appear to be of any special concern.\nInteractions with Browser Credentials\nAs we are wrapping up the overview of the DOM-based same-origin policy, it\nis important to note that it is in no way synchronized with ambient creden-\ntials, SSL state, network context, or many other potentially security-relevant\nparameters tracked by the browser. Any two windows or frames opened in a\nbrowser will remain same-origin with each other even if the user logs out\nfrom one account and logs into another, if the page switches from using a\ngood HTTPS certificate to a bad one, and so on.\nThis lack of synchronization can contribute to the exploitability of other\nsecurity bugs. For example, several sites do not protect their login forms against\ncross-site request forgery, permitting any third-party site to simply submit a\nusername and a password and log the user into an attacker-controlled account.\nThis may seem harmless at first, but when the content loaded in the browser\nbefore and after this operation is considered same-origin, the impact of nor-\nmally ignored “self-inflicted” cross-site scripting vulnerabilities (i.e., ones\nwhere the owner of a particular account can target only himself) is suddenly\nContent Isolation Logic 145"
  },
  {
    "input": "Same-Origin Policy for XMLHttpRequest",
    "output": "much greater than it would previously appear. In the most basic scenario, the\nattacker may first open and keep a frame pointing to a sensitive page on the\ntargeted site (e.g., http://www.fuzzybunnies.com/address_book.php) and then log\nthe victim into the attacker-controlled account to execute self-XSS in an\nunrelated component of fuzzybunnies.com. Despite the change of HTTP cre-\ndentials, the code injected in that latter step will have unconstrained access\nto the previously loaded frame, permitting data theft.\nSame-Origin Policy for XMLHttpRequest\nThe XMLHttpRequest API, mentioned in this book on several prior occasions,\ngives JavaScript programs the ability to issue almost unconstrained HTTP\nrequests to the server from which the host document originated, and read\nback response headers and the document body. The ability to do so would\nnot be particularly significant were it not for the fact that the mechanism\nleverages the existing browser HTTP stack and its amenities, including ambi-\nent credentials, caching mechanisms, keep-alive sessions, and so on.\nA simple and fairly self-explanatory use of a synchronous XMLHttpRequest\ncould be as follows:\nvar x = new XMLHttpRequest();\nx.open(\"POST\", \"/some_script.cgi\", false);\nx.setRequestHeader(\"X-Random-Header\", \"Hi mom!\");\nx.send(\"...POST payload here...\");\nalert(x.responseText);\nAsynchronous requests are very similar but are executed without block-\ning the JavaScript engine or the browser. The request is issued in the back-\nground, and an event handler is called upon completion instead.\nAs originally envisioned, the ability to issue HTTP requests via this API\nand to read back the data is governed by a near-verbatim copy of the same-\norigin policy with two minor and seemingly random tweaks. First, the document\n.domain setting has no effect on this mechanism, and the destination URL\nspecified for XMLHttpRequest.open(...) must always match the true origin of the\ndocument. Second, in this context, port number is taken into account in Inter-\nnet Explorer versions prior to 9, even though this browser ignores it elsewhere.\nThe fact that XMLHttpRequest gives the user an unprecedented level of\ncontrol over the HTTP headers in a request can actually be advantageous to\nsecurity. For example, inserting a custom HTTP header, such as X-Coming-\nFrom: same-origin, is a very simple way to verify that a particular request is not\ncoming from a third-party domain, because no other site should be able to\ninsert a custom header into a browser-issued request. This assurance is not\nvery strong, because no specification says that the implicit restriction on cross-\ndomain headers can’t change;* nevertheless, when it comes to web security,\nsuch assumptions are often just something you have to learn to live with.\nControl over the structure of an HTTP request can also be a burden,\nthough, because inserting certain types of headers may change the meaning\nof a request to the destination server, or to the proxies, without the browser\n146 Chapter 9\nrealizing it. For example, specifying an incorrect Content-Length value may\nallow an attacker to smuggle a second request into a keep-alive HTTP session\nmaintained by the browser, as shown here.\nvar x = new XMLHttpRequest();\nx.open(\"POST\", \"http://www.example.com/\", false);\n// This overrides the browser-computed Content-Length header:\nx.setRequestHeader(\"Content-Length\", \"7\");\n// The server will assume that this payload ends after the first\n// seven characters, and that the remaining part is a separate\n// HTTP request.\nx.send(\n\"Gotcha!\\n\" +\n\"GET /evil_response.html HTTP/1.1\\n\" +\n\"Host: www.bunnyoutlet.com\\n\\n\"\n);\nIf this happens, the response to that second, injected request may be mis-\ninterpreted by the browser later, possibly poisoning the cache or injecting con-\ntent into another website. This problem is especially pronounced if an HTTP\nproxy is in use and all HTTP requests are sent through a shared channel.\nBecause of this risk, and following a lot of trial and error, modern brows-\ners blacklist a selection of HTTP headers and request methods. This is done\nwith relatively little consistency: While Referer, Content-Length, and Host are\nuniversally banned, the handling of headers such as User-Agent, Cookie, Origin,\nor If-Modified-Since varies from one browser to another. Similarly, the TRACE\nmethod is blocked everywhere, because of the unanticipated risk it posed to\nhttponly cookies—but the CONNECT method is permitted in Firefox, despite\ncarrying a vague risk of messing with HTTP proxies.\nNaturally, implementing these blacklists has proven to be an entertain-\ning exercise on its own. Strictly for your amusement, consider the following\ncases that worked in some browsers as little as three years ago:1\nXMLHttpRequest.setRequestHeader(\"X-Harmless\", \"1\\nOwned: Gotcha\");\nor\nXMLHttpRequest.setRequestHeader(\"Content-Length: 123 \", \"\");\nor simply\nXMLHttpRequest.open(\"GET\\thttp://evil.com\\tHTTP/1.0\\n\\n\", \"/\", false);\n* In fact, many plug-ins had problems in this area in the past. Most notably, Adobe Flash permitted\narbitrary cross-domain HTTP headers until 2008, at which point its security model underwent a\nsubstantial overhaul. Until 2011, the same plug-in suffered from a long-lived implementation\nbug that caused it to resend any custom headers to an unrelated server following an attacker-\nsupplied HTTP 307 redirect code. Both of these problems are fixed now, but discovery-to-patch\ntime proved troubling.\nContent Isolation Logic 147"
  },
  {
    "input": "Same-Origin Policy for Web Storage",
    "output": "NOTE Cross-Origin Resource Sharing2 (CORS) is a proposed extension to\nXMLHttpRequest that permits HTTP requests to be issued across domains and\nthenread back if a particular response header appears in the returned data. The mech-\nanism changes the semantics of the API discussed in this session by allowing certain\n“vanilla” cross-domain requests, meant to be no different from regular navigation, to be\nissued via XMLHttpRequest.open(...) with no additional checks; more elaborate\nrequests require an OPTIONS-based preflight request first. CORS is already available\nin some browsers, but it is opposed by Microsoft engineers, who pursued a competing\nXDomainRequest approach in Internet Explorer 8 and 9. Because the outcome of\nthis conflict is unclear, a detailed discussion of CORS is reserved for Chapter 16, which\nprovides a more systematic overview of upcoming and experimental mechanisms.\nSame-Origin Policy for Web Storage\nWeb storage is a simple database solution first implemented by Mozilla engi-\nneers in Firefox 1.5 and eventually embraced by the HTML5 specification.3 It\nis available in all current browsers but not in Internet Explorer 6 or 7.\nFollowing several dubious iterations, the current design relies on two\nsimple JavaScript objects: localStorage and sessionStorage. Both objects offer an\nidentical, simple API for creating, retrieving, and deleting name-value pairs\nin a browser-managed database. For example:\nlocalStorage.setItem(\"message\", \"Hi mom!\");\nalert(localStorage.getItem(\"message\"));\nlocalstorage.removeItem(\"message\");\nThe localStorage object implements a persistent, origin-specific storage that\nsurvives browser shutdowns, while sessionStorage is expected to be bound to the\ncurrent browser window and provide a temporary caching mechanism that is\ndestroyed at the end of a browsing session. While the specification says that\nboth localStorage and sessionStorage should be associated with an SOP-like ori-\ngin (the protocol-host-port tuple), implementations in some browsers do not\nfollow this advice, introducing potential security bugs. Most notably, in Inter-\nnet Explorer 8, the protocol is not taken into account when computing the\norigin, putting HTTP and HTTPS pages within a shared context. This design\nmakes it very unsafe for HTTPS sites to store or read back sensitive data\nthrough this API. (This problem is corrected in Internet Explorer 9, but\nthere appears to be no plan to backport the fix.)\nIn Firefox, on the other hand, the localStorage behaves correctly, but the\nsessionStorage interface does not. HTTP and HTTPS use a shared storage con-\ntext, and although a check is implemented to prevent HTTP content from\nreading keys created by HTTPS scripts, there is a serious loophole: Any key\nfirst created over HTTP, and then updated over HTTPS, will remain visible\nto nonencrypted pages. This bug, originally reported in 2009,4 will eventually\nbe resolved, but when is not clear.\n148 Chapter 9"
  },
  {
    "input": "Security Policy for Cookies",
    "output": "Security Policy for Cookies\nWe discussed the semantics of HTTP cookies in Chapter 3, but that discus-\nsion left out one important detail: the security rules that must be imple-\nmented to protect cookies belonging to one site from being tampered with\nby unrelated pages. This topic is particularly interesting because the approach\ntaken here predates the same-origin policy and interacts with it in a number\nof unexpected ways.\nCookies are meant to be scoped to domains, and they can’t be limited\neasily to just a single hostname value. The domain parameter provided with\nacookie may simply match the current hostname (such as foo.example.com),\nbut this will not prevent the cookie from being sent to any eventual sub-\ndomains, such as bar.foo.example.com. A qualified right-hand fragment of the\nhostname, such as example.com, can be specified to request a broader scope,\nhowever.\nAmusingly, the original RFCs imply that Netscape engineers wanted to\nallow exact host-scoped cookies, but they did not follow their own advice.\nThe syntax devised for this purpose was not recognized by the descendants\nofNetscape Navigator (or by any other implementation for that matter). To\na limited extent, setting host-scoped cookies is possible in some browsers by\ncompletely omitting the domain parameter, but this method will have no\neffect in Internet Explorer.\nTable 9-3 illustrates cookie-setting behavior in some distinctive cases.\nTable 9-3: A Sample of Cookie-Setting Behaviors\nCookie set at foo.example.com, Scope of the resulting cookie\ndomain parameter is:\nNon–IE browsers Internet Explorer\n(value omitted) foo.example.com (exact) *.foo.example.com\nbar.foo.example.com Cookie not set: domain more specific than origin\nfoo.example.com *.foo.example.com\nbaz.example.com Cookie not set: domain mismatch\nexample.com *.example.com\nample.com Cookie not set: domain mismatch\n.com Cookie not set: domain too broad, security risk\nThe only other true cookie-scoping parameter is the path prefix: Any\ncookie can be set with a specified path value. This instructs the browser to send\nthe cookie back only on requests to matching directories; a cookie scoped to\ndomain of example.com and path of /some/path/ will be included on a request to\nhttp://foo.example.com/some/path/subdirectory/hello_world.txt\nThis mechanism can be deceptive. URL paths are not taken into account\nduring same-origin policy checks and, therefore, do not form a useful secu-\nrity boundary. Regardless of how cookies work, JavaScript code can simply hop\nbetween any URLs on a single host at will and inject malicious payloads into\nContent Isolation Logic 149"
  },
  {
    "input": "Impact of Cookies on the Same-Origin Policy",
    "output": "such targets, abusing any functionality protected with path-bound cookies.\n(Several security books and white papers recommend path scoping as a secu-\nrity measure to this day. In most cases, this advice is dead wrong.)\nOther than the true scoping features (which, along with cookie name,\nconstitute a tuple that uniquely identifies every cookie), web servers can also\noutput cookies with two special, independently operated flags: httponly and\nsecure. The first, httponly, prevents access to the cookie via the document.cookie\nAPI in the hope of making it more difficult to simply copy a user’s credentials\nafter successfully injecting a malicious script on a page. The second, secure,\nstops the cookie from being submitted on requests over unencrypted proto-\ncols, which makes it possible to build HTTPS services that are resistant to\nactive attacks.*\nThe pitfall of these mechanisms is that they protect data only against\nreading and not against overwriting. For example, it is still possible for Java-\nScript code delivered over HTTP to simply overflow the per-domain cookie\njar and then set a new cookie without the secure flag.† Because the Cookie\nheader sent by the browser provides no metadata about the origin of a partic-\nular cookie or its scope, such a trick is very difficult to detect. A prominent\nconsequence of this behavior is that the common “stateless” way of prevent-\ning cross-site request forgery vulnerabilities by simultaneously storing a secret\ntoken in a client-side cookie and in a hidden form field, and then comparing\nthe two, is not particularly safe for HTTPS websites. See if you can figure\noutwhy!\nNOTE Speaking of destructive interference, until 2010, httponly cookies also clashed with\nXMLHttpRequest. The authors of that API simply have not given any special\nthought to whether the XMLHttpRequest.getResponseHeader(...) function\nshould be able to inspect server-supplied Set-Cookie values flagged as httponly—\nwith predictable results.\nImpact of Cookies on the Same-Origin Policy\nThe same-origin policy has some undesirable impact on the security of cookies\n(specifically, on the path-scoping mechanism), but the opposite interaction\nis more common and more problematic. The difficulty is that HTTP cookies\noften function as credentials, and in such cases, the ability to obtain them is\nroughly equivalent to finding a way to bypass SOP. Quite simply, with the right\nset of cookies, an attacker could use her own browser to interact with the tar-\nget site on behalf of the victim; same-origin policy is taken out of the picture,\nand all bets are off.\n* It does not matter that https://webmail.example.com/ is offered only over HTTPS. If it uses a cookie\nthat is not locked to encrypted protocols, the attacker may simply wait until the victim navigates\nto http://www.fuzzybunnies.com/, silently inject a frame pointing to http://webmail.example.com/ on\nthat page, and then intercept the resulting TCP handshake. The browser will then send all the\nwebmail.example.com cookies over an unencrypted channel, and at this point the game is essen-\ntially over.\n† Even if this possibility is prevented by separating the jars for httponly and normal cookies,\nmultiple identically named but differently scoped cookies must be allowed to coexist, and they\nwill be sent together on any matching requests. They will be not accompanied by any useful\nmetadata, and their ordering will be undefined and browser specific.\n150 Chapter 9"
  },
  {
    "input": "Problems with Domain Restrictions",
    "output": "Because of this property, any discrepancies between the two security mech-\nanisms can lead to trouble for the more restrictive one. For example, the rela-\ntively promiscuous domain-scoping rules used by HTTP cookies mean that it is\nnot possible to isolate fully the sensitive content hosted on webmail.example.com\nfrom the less trusted HTML present on blog.example.com. Even if the owners of\nthe webmail application scope their cookies tightly (usually at the expense of\ncomplicating the sign-on process), any attacker who finds a script injection\nvulnerability on the blogging site can simply overflow the per-domain cookie\njar, drop the current credentials, and set his own *.example.com cookies. These\ninjected cookies will be sent to webmail.example.com on all subsequent requests\nand will be largely indistinguishable from the real ones.\nThis trick may seem harmless until you realize that such an action may\neffectively log the victim into a bogus account and that, as a result, certain\nactions (such as sending email) may be unintentionally recorded within that\naccount and leaked to the attacker before any foul play is noticed. If webmail\nsounds too exotic, consider doing the same on Amazon or Netflix: Your casual\nproduct searches may be revealed to the attacker before you notice anything\nunusual about the site. (On top of this, many websites are simply not prepared\nto handle malicious payloads in injected cookies, and unexpected inputs may\nlead to XSS or similar bugs.)\nThe antics of HTTP cookies also make it very difficult to secure encrypted\ntraffic against network-level attackers. A secure cookie set by https://webmail\n.example.com/ can still be clobbered and replaced by a made-up value set by a\nspoofed page at http://webmail.example.com/, even if there is no actual web ser-\nvice listening on port 80 on the target host.\nProblems with Domain Restrictions\nThe misguided notion of allowing domain-level cookies also poses problems\nfor browser vendors and is a continuing source of misery. The key question is\nhow to reliably prevent example.com from setting a cookie for *.com and avoid\nhaving this cookie unexpectedly sent to every other destination on theInternet.\nSeveral simple solutions come to mind, but they fall apart when you have\nto account for country-level TLDs: example.com.pl must be prevented from set-\nting a *.com.pl cookie, too. Realizing this, the original Netscape cookie speci-\nfication provided the following advice:\nOnly hosts within the specified domain can set a cookie for a domain\nand domains must have at least two (2) or three (3) periods in them\nto prevent domains of the form: “.com”, “.edu”, and “va.us”.\nAny domain that fails within one of the seven special top level\ndomains listed below only requires two periods. Any other domain\nrequires at least three. The seven special top level domains are:\n“COM”, “EDU”, “NET”, “ORG”, “GOV”, “MIL”, and “INT”.\nAlas, the three-period rule makes sense only for country-level registrars\nthat mirror the top-level hierarchy (example.co.uk) but not for the just as pop-\nulous group of countries that accept direct registrations (example.fr). In fact,\nthere are places where both approaches are allowed; for example, both\nexample.jp and example.co.jp are perfectly fine.\nContent Isolation Logic 151"
  },
  {
    "input": "The Unusual Danger of “localhost”",
    "output": "Because of the out-of-touch nature of this advice, most browsers dis-\nregarded it and instead implemented a patchwork of conditional expressions\nthat only led to more trouble. (In one case, for over a decade, you could actu-\nally set cookies for *.com.pl.) Comprehensive fixes to country-code top-level\ndomain handling have shipped in all modern browsers in the past four years,\nbut as of this writing they have not been backported to Internet Explorer 6\nand 7, and they probably never will be.\nNOTE To add insult to injury, the Internet Assigned Numbers Authority added a fair number\nof top-level domains in recent years (for example, .int and .biz), and it is contemplat-\ning a proposal to allow arbitrary generic top-level domain registrations. If it comes to\nthis, cookies will probably have to be redesigned from scratch.\nThe Unusual Danger of “localhost”\nOne immediately evident consequence of the existence of domain-level scop-\ning of cookies is that it is fairly unsafe to delegate any hostnames within a sen-\nsitive domain to any untrusted (or simply vulnerable) party; doing so may\naffect the confidentiality, and invariably the integrity, of any cookie-stored\ncredentials—and, consequently, of any other information handled by the tar-\ngeted application.\nSo much is obvious, but in 2008, Tavis Ormandy spotted something far less\nintuitive and far more hilarious:5 that because of the port-agnostic behavior of\nHTTP cookies, an additional danger lies in the fairly popular and convenient\nadministrative practice of adding a “localhost” entry to a domain and having\nit point to 127.0.0.1.* When Ormandy first published his advisory, he asserted\nthat this practice is widespread—not a controversial claim to make—and\nincluded the following resolver tool output to illustrate his point:\nlocalhost.microsoft.com has address 127.0.0.1\nlocalhost.ebay.com has address 127.0.0.1\nlocalhost.yahoo.com has address 127.0.0.1\nlocalhost.fbi.gov has address 127.0.0.1\nlocalhost.citibank.com has address 127.0.0.1\nlocalhost.cisco.com has address 127.0.0.1\nWhy would this be a security risk? Quite simply, it puts the HTTP services\non the user’s own machine within the same domain as the remainder of the\nsite, and more importantly, it puts all the services that only look like HTTP in\nthe very same bucket. These services are typically not exposed to the Internet,\nso there is no perceived need to design them carefully or keep them up-to-\ndate. Tavis’s case in point is a printer-management service provided by CUPS\n(Common UNIX Printing System), which would execute attacker-supplied\nJavaScript in the context of example.com if invoked in the following way:\nhttp://localhost.example.com:631/jobs/?[...]\n&job_printer_uri=javascript:alert(\"Hi mom!\")\n* This IP address is reserved for loopback interfaces; any attempt to connect to it will route you\nback to the services running on your own machine.\n152 Chapter 9"
  },
  {
    "input": "Plug-in Security Rules",
    "output": "The vulnerability in CUPS can be fixed, but there are likely many other\ndodgy local services on all operating systems—everything from disk manage-\nment tools to antivirus status dashboards. Introducing entries pointing back\nto 127.0.0.1, or any other destinations you have no control over, ties the secu-\nrity of cookies within your domain to the security of random third-party soft-\nware. That is a good thing to avoid.\nCookies and “Legitimate” DNS Hijacking\nThe perils of the domain-scoping policy for cookies don’t end with localhost.\nAnother unintended interaction is related to the common, widely criticized\npractice of some ISPs and other DNS service providers of hijacking domain\nlookups for nonexistent (typically mistyped) hosts. In this scheme, instead of\nreturning the standard-mandated NXDOMAIN response from an upstream\nname server (which would subsequently trigger an error message in the\nbrowser or other networked application), the provider will falsify a record to\nimply that this name resolves to its site. Its site, in turn, will examine the Host\nheader supplied by the browser and provide the user with unsolicited, paid\ncontextual advertising that appears to be vaguely related to her browsing\ninterests. The usual justification offered for this practice is that of offering a\nmore user-friendly browsing experience; the real incentive, of course, is to\nmake more money.\nInternet service providers that have relied on this practice include\nCablevision, Charter, Earthlink, Time Warner, Verizon, and many more.\nUnfortunately, their approach is not only morally questionable, but it also\ncreates a substantial security risk. If the advertising site contains any script-\ninjection vulnerabilities, the attacker can exploit them in the context of any\nother domain simply by accessing the vulnerable functionality through an\naddress such as nonexistent.example.com. When coupled with the design of\nHTTP cookies, this practice undermines the security of any arbitrarily tar-\ngeted services on the Internet.\nPredictably, script-injection vulnerabilities can be found in such hastily\ndesigned advertising traps without much effort. For example, in 2008, Dan\nKaminsky spotted and publicized a cross-site scripting vulnerability on the\npages operated by Earthlink.6\nAll right, all right: It’s time to stop obsessing over cookies and move on.\nPlug-in Security Rules\nBrowsers do not provide plug-in developers with a uniform and extensible\nAPI for enforcing security policies; instead, each plug-in decides what rules\nshould be applied to executed content and how to put them into action. Con-\nsequently, even though plug-in security models are to some extent inspired\nby the same-origin policy, they diverge from it in a number of ways.\nThis disconnect can be dangerous. In Chapter 6, we discussed the ten-\ndency for plug-ins to rely on inspecting the JavaScript location object to deter-\nmine the origin of their hosting page. This misguided practice forced browser\ndevelopers to restrict the ability of JavaScript programs to tamper with some\nContent Isolation Logic 153"
  },
  {
    "input": "Adobe Flash",
    "output": "portions of their runtime environment to save the day. Another related, com-\nmon source of incompatibilities is the interpretation of URLs. For example,\nin the middle of 2010, one researcher discovered that Adobe Flash had trou-\nble with the following URL:7\nhttp://example.com:80@bunnyoutlet.com/\nThe plug-in decided that the origin of any code retrieved through this\nURL should be set to example.com, but the browser, when presented with such\na URL, would naturally retrieve the data from bunnyoutlet.com instead and then\nhand it over to the confused plug-in for execution.\nWhile this particular bug is now fixed, other vulnerabilities of this type\ncan probably be expected in the future. Replicating some of the URL-parsing\nquirks discussed in Chapters 2 and 3 can be a fool’s errand and, ideally,\nshould not be attempted at all.\nIt would not be polite to end this chapter on such a gloomy note!\nSystemic problems aside, let’s see how some of the most popular plug-ins\napproach the job of security policy enforcement.\nAdobe Flash\nThe Flash security model underwent a major overhaul in 2008,8 and since\nthen, it has been reasonably robust. Every loaded Flash applet is now assigned\nan SOP-like origin derived from its originating URL* and is granted nominal\norigin-related permissions roughly comparable to those of JavaScript. In\nparticular, each applet can load cookie-authenticated content from its origi-\nnating site, load some constrained datatypes from other origins, and make\nsame-origin XMLHttpRequest-like HTTP calls through the URLRequest API.\nThe set of permissible methods and request headers for this last API is man-\naged fairly reasonably and, as of this writing, is more restrictive than most of\nthe browser-level blacklists for XMLHttpRequest itself.9\nOn top of this sensible baseline, three flexible but easily misused mecha-\nnisms permit this behavior to be modified to some extent, as discussed next.\nMarkup-Level Security Controls\nThe embedding page can specify three special parameters provided through\n<embed> or <object> tags to control how an applet will interact with its host\npage and the browser itself:\n AllowScriptAccess parameter This setting controls an applet’s ability to\nuse the JavaScript ExternalInterface.call(...) bridge (see Chapter 8) to exe-\ncute JavaScript statements in the context of the embedding site. Possible\nvalues are always, never, and sameorigin; the last setting gives access to the\npage only if the page is same-origin with the applet itself. (Prior to the\n2008 security overhaul, the plug-in defaulted to always; the current\ndefault is the much safer sameorigin.)\n* In some contexts, Flash may implicitly permit access from HTTPS origins to HTTP ones but\nnot the other way round. This is usually harmless, and as such, it is not given special attention\nthroughout the remainder of this section.\n154 Chapter 9\n AllowNetworking parameter This poorly named setting restricts an\napplet’s permission to open or navigate browser windows and to make\nHTTP requests to its originating server. When set to all (the default), the\napplet can interfere with the browser; when set to internal, it can perform\nonly nondisruptive, internal communications through the Flash plug-in.\nSetting this parameter to none disables most network-related APIs alto-\ngether.* (Prior to recent security improvements, allowNetworking=all\nopened up several ways to bypass allowScriptAccess=none, for example, by\ncalling getURL(...) on a javascript: URL. As of this writing, however, all\nscripting URLs should be blacklisted in this scenario.)\n AllowFullScreen parameter This parameter controls whether an applet\nshould be permitted to go into full-screen rendering mode. The possible\nvalues are true and false, with false being the default. As noted in Chapter8,\nthe decision to give this capability to Flash applets is problematic due to\nUI spoofing risks; it should be not enabled unless genuinely necessary.\nSecurity.allowDomain(...)\nThe Security.allowDomain(...) method10 allows Flash applets to grant access to\ntheir variables and functions to any JavaScript code or to other applets coming\nfrom a different origin. Buyer beware: Once such access is granted, there is\nno reliable way to maintain the integrity of the original Flash execution con-\ntext. The decision to grant such permissions should not be taken lightly, and\nthe practice of calling allowDomain(\"*\") should usually be punished severely.\nNote that a weirdly named allowInsecureDomain(...) method is also avail-\nable. The existence of this method does not indicate that allowDomain(...)\nisparticularly secure; rather, the “insecure” variant is provided for compati-\nbility with ancient, pre-2003 semantics that completely ignored the HTTP/\nHTTPS divide.\nCross-Domain Policy Files\nThrough the use of loadPolicyFile(...), any Flash applet can instruct its runtime\nenvironment to retrieve a security policy file from an almost arbitrary URL.\nThis XML-based document, usually named crossdomain.xml, will be inter-\npreted as an expression of consent to cross-domain, server-level access to the\norigin determined by examining the policy URL.11 The syntax of a policy file\nis fairly self-explanatory and may look like this:\n<cross-domain-policy>\n<allow-access-from domain=\"foo.example.com\"/>\n<allow-http-request-headers-from domain=\"*.example.com\"\nheaders=\"X-Some-Header\" />\n</cross-domain-policy>\n* It should not be assumed that this setting prevents any sensitive data available to a rogue applet\nfrom being relayed to third parties. There are many side channels that any Flash applet could\nleverage to leak information to a cooperating party without directly issuing network requests. In\nthe simplest and most universal case, CPU loads can be manipulated to send out individual bits of\ninformation to any simultaneously loaded applet that continuously samples the responsiveness of\nits runtime environment.\nContent Isolation Logic 155\nThe policy may permit actions such as loading cross-origin resources\norissuing arbitrary URLRequest calls with whitelisted headers, through the\nbrowser HTTP stack. Flash developers do attempt to enforce a degree of\npath separation: A policy loaded from a particular subdirectory can in princi-\nple permit access only to files within that path. In practice, however, the\ninteractions with SOP and with various path-mapping semantics of modern\nbrowsers and web application frameworks make it unwise to depend on this\nboundary.\nNOTE Making raw TCP connections via XMLSocket is also possible and controlled by an\nXML policy, but following Flash’s 2008 overhaul, XMLSocket requires that a sepa-\nrate policy file be delivered on TCP port 843 of the destination server. This is fairly safe,\nbecause no other common services run on this port and, on many operating systems,\nonly privileged users can launch services on any port below 1024. Because of the inter-\nactions with certain firewall-level mechanisms, such as FTP protocol helpers, this design\nmay still cause some network-level interference,12 but this topic is firmly beyond the\nscope of this book\nAs expected, poorly configured crossdomain.xml policies are an apprecia-\nble security risk. In particular, it is a very bad idea to specify allow-access-from\nrules that point to any domain you do not have full confidence in. Further,\nspecifying “*” as a value for this parameter is roughly equivalent to executing\ndocument.domain = “com”. That is, it’s a death wish.\nPolicy File Spoofing Risks\nOther than the possibility of configuration mistakes, another security risk\nwith Adobe’s policy-based security model is that random user-controlled\ndocuments may be interpreted as cross-domain policies, contrary to the site\nowner’s intent.\nPrior to 2008, Flash used a notoriously lax policy parser, which when\nprocessing loadPolicyFile(...) files would skip arbitrary leading garbage in\nsearch of the opening <cross-domain-policy> tag. It would simply ignore the\nMIME type returned by the server when downloading the resource, too. As\naresult, merely hosting a valid, user-supplied JPEG image could become a\ngrave security risk. The plug-in also skipped over any HTTP redirects, mak-\ning it dangerous to do something as simple as issuing an HTTP redirect to a\nlocation you did not control (an otherwise harmless act).\nFollowing the much-needed revamp of the loadPolicyFile behavior, many\nof the gross mistakes have been corrected, but the defaults are still not per-\nfect. On the one hand, redirects now work intuitively, and the file must be a\nwell-formed XML document. On the other, permissible MIME types include\ntext/*, application/xml, and application/xhtml+xml, which feels a bit too broad.\ntext/plain or text/csv may be misinterpreted as a policy file, and that should\nnot be the case.\nThankfully, to mitigate the problem, Adobe engineers decided to roll\nout meta-policies, policies that are hosted at a predefined, top-level location\n(/crossdomain.xml) that the attacker can’t override. A meta-policy can specify\nsitewide restrictions for all the remaining policies loaded from attacker-supplied\n156 Chapter 9"
  },
  {
    "input": "Java",
    "output": "URLs. The most important of these restrictions is <site-control permitted-cross-\ndomain-policies=\"...\">. This parameter, when set to master-only, simply instructs\nthe plug-in to disregard subpolicies altogether. Another, less radical value,\nby-content-type, permits additional policies to be loaded but requires them to\nhave a nonambiguous Content-Type header set to text/x-cross-domain-policy.\nNeedless to say, it’s highly advisable to use a meta-policy that specifies\none of these two directives.\nMicrosoft Silverlight\nIf the transition from Flash to Silverlight seems abrupt, it’s because the\ntwoare easy to confuse. The Silverlight plug-in borrows from Flash with\nremarkable zeal; in fact, it is safe to say that most of the differences between\ntheir security models are due solely to nomenclature. Microsoft’s platform\nuses the same-origin-determination approach, substitutes allowScriptAccess\nwith enableHtmlAccess, replaces crossdomain.xml with the slightly different\nclientaccesspolicy.xml syntax, provides a System.Net.Sockets API instead of\nXMLSocket, uses HttpWebRequest in place of URLRequest, rearranges the\nflowers, and changes the curtains in the living room.\nThe similarities are striking, down to the list of blocked request headers\nfor the HttpWebRequest API, which even includes X-Flash-Version from the Adobe\nspec.13 Such consistency is not a problem, though: In fact, it is preferable to\nhaving a brand-new security model to take into account. Plus, to its credit,\nMicrosoft did make a couple of welcome improvements, including ditching\nthe insecure allowDomain logic in favor of RegisterScriptableObject, an approach\nthat allows only explicitly specified callbacks to be exposed to third-party\ndomains.\nJava\nSun’s Java (now officially belonging to Oracle) is a very curious case. Java\nisaplug-in that has fallen into disuse, and its security architecture has not\nreceived much scrutiny in the past decade or so. Yet, because of its large\ninstalled base, it is difficult to simply ignore it and move on.\nUnfortunately, the closer you look, the more evident it is that the ideas\nembraced by Java tend to be incompatible with the modern Web. For exam-\nple, a class called java.net.HttpURLConnection14 permits credential-bearing\nHTTP requests to be made to an applet’s originating website, but the “origi-\nnating website” is understood as any website hosted at a particular IP address,\nas sanctioned by the java.net.URL.equals(...) check. This model essentially\nundoes any isolation between HTTP/1.1 virtual hosts—an isolation strongly\nenforced by the same-origin policy, HTTP cookies, and virtually all other\nbrowser security mechanisms in use today.\nFurther along these lines, the java.net.URLConnection class15 allows arbi-\ntrary request headers, including Host, to be set by the applet, and another\nclass, Socket,16 permits unconstrained TCP connections to arbitrary ports\nonthe originating server. All of these behaviors are frowned upon in the\nbrowser and in any other contemporary plug-in.\nContent Isolation Logic 157"
  },
  {
    "input": "IP Addresses",
    "output": "Origin-agnostic access from the applet to the embedding page is pro-\nvided through the JSObject mechanism and is expected to be controlled by\nthe embedding party through the mayscript attribute specified in the <applet>,\n<embed>, or <object> tags.17 The documentation suggests that this is a security\nfeature:\nDue to security reasons, JSObject support is not enabled in Java\nPlug-in by default. To enable JSObject support in Java Plug-in,\nanew attribute called MAYSCRIPT needs to be present in the\nEMBED/OBJECT tag.\nUnfortunately, the documentation neglects to mention that another\nclosely related mechanism, DOMService,18 ignores this setting and gives applets\nlargely unconstrained access to the embedding page. While DOMService is\nnot supported in Firefox and Opera, it is available in other browsers, which\nmakes any attempt to load third-party Java content equivalent to granting full\naccess to the embedding site.\nWhoops.\nNOTE Interesting fact: Recent versions of Java attempt to copy the crossdomain.xml support\navailable in Flash.\nCoping with Ambiguous or Unexpected Origins\nThis concludes our overview of the basic security policies and consent isola-\ntion mechanisms. If there is one observation to be made, it’s that most of\nthese mechanisms depend on the availability of a well-formed, canonical\nhostname from which to derive the context for all the subsequent opera-\ntions. But what if this information is not available or is not presented in the\nexpected form?\nWell, that’s when things get funny. Let’s have a look at some of the com-\nmon corner cases, even if just for fleeting amusement.\nIP Addresses\nDue to the failure to account for IP addresses when designing HTTP cookies\nand the same-origin policy, almost all browsers have historically permitted\ndocuments loaded from, say, http://1.2.3.4/ to set cookies for a “domain”\nnamed *.3.4. Adjusting document.domain in a similar manner would work as\nwell. In fact, some of these behaviors are still present in older versions of\nInternet Explorer.\nThis behavior is unlikely to have an impact on mainstream web applica-\ntions, because such applications are not meant to be accessed through an IP-\nbased URL and will often simply fail to function properly. But a handful of\nsystems, used primarily by technical staff, are meant to be accessed by their IP\naddresses; these systems may simply not have DNS records configured at all.\nIn these cases, the ability for http://1.2.3.4/ to inject cookies for http://123\n.234.3.4/ may be an issue. The IP-reachable administrative interfaces of home\nrouters are of some interest, too.\n158 Chapter 9"
  },
  {
    "input": "Local Files",
    "output": "Hostnames with Extra Periods\nAt their core, cookie-setting algorithms still depend on counting the number\nof periods in a URL to determine whether a particular domain parameter is\nacceptable. In order to make the call, the count is typically correlated with a\nlist of several hundred entries on the vendor-maintained Public Suffix List\n(http://publicsuffix.org/).\nUnfortunately for this algorithm, it is often possible to put extra periods\nin a hostname and still have it resolve correctly. Noncanonical hostname rep-\nresentations with excess periods are usually honored by OS-level resolvers\nand, if honored, will confuse the browser. Although said browser would not\nautomatically consider a domain such as www.example.com.pl. (with an extra\ntrailing period) to be the same as the real www.example.com.pl, the subtle and\nseemingly harmless difference in the URL could escape even the most atten-\ntive users.\nIn such a case, interacting with the URL with trailing period can be\nunsafe, as other documents sharing the *.com.pl. domain may be able to\ninject cross-domain cookies with relative ease.\nThis period-counting problem was first noticed around 1998.19 About a\ndecade later, many browser vendors decided to roll out basic mitigations by\nadding a yet another special case to the relevant code; as of this writing,\nOpera is still susceptible to this trick.\nNon–Fully Qualified Hostnames\nMany users browse the Web with their DNS resolvers configured to append\nlocal suffixes to all found hostnames, often without knowing. Such settings\nare usually sanctioned by ISPs or employers through automatic network con-\nfiguration data (Dynamic Host Configuration Protocol, DHCP).\nFor any user browsing with such a setting, the resolution of DNS labels\nisambiguous. For example, if the DNS search path includes coredump.cx,\nthenwww.example.com may resolve to the real www.example.com website or to\nwww.example.com.coredump.cx if such a record exists. The outcomes are partly\ncontrolled by configuration settings and, to some extent, can be influenced\nby an attacker.\nTo the browser, both locations appear to be the same, which may have\nsome interesting side effects. Consider one particularly perverse case: Should\nhttp://com, which actually resolves to http://com.coredump.cx/, be able to set\n*.com cookies by simply omitting the domain parameter?\nLocal Files\nBecause local resources loaded through the file: protocol do not have an\nexplicit hostname associated with them, it’s impossible for the browser to\ncompute a normal origin. For a very long time, the vendors simply decided\nthat the best course of action in such a case would be to simply ditch the same-\norigin policy. Thus, any HTML document saved to disk would automatically\nContent Isolation Logic 159\nbe granted access to any other local files via XMLHttpRequest or DOM and, even\nmore inexplicably, would be able to access any Internet-originating content\nin the same way.\nThis proved to be a horrible design decision. No one expected that the\nmere act of downloading an HTML document would put all of the user’s local\nfiles, and his online credentials, in jeopardy. After all, accessing that same\ndocument over the Web would be perfectly safe.\nMany browsers have tried to close this loophole in recent years, with vary-\ning degrees of success:\nChrome (and, by extension, other WebKit browsers)\nThe Chromebrowser completely disallows any cross-document DOM or\nXMLHttpRequest access from file: origins, and it ignores document.cookie\ncalls or <meta http-equiv=\"Set-Cookie\" ...> directives in this setting. Access to\na localStorage container shared by all file: documents is permitted, but this\nmay change soon.\nFirefox\nMozilla’s browser permits access only to files within the directory of the\noriginal document, as well as nearby subdirectories. This policy is pretty\ngood, but it still poses some risk to documents stored or previously down-\nloaded to that location. Access to cookies via document.cookie or <meta http-\nequiv=\"Set-Cookie\" ...> is possible, and all file: cookies are visible to any\nother local JavaScript code.* The same holds true for access to storage\nmechanisms.\nInternet Explorer 7 and above\nUnconstrained access to local and Internet content from file: origins is\npermitted, but it requires the user to click through a nonspecific warn-\ning to execute JavaScript first. The consequences of this action are not\nexplained clearly (the help subsystem cryptically states that “Internet\nExplorer restricts this content because occasionally these programs can malfunction\nor give you content you don’t want”), and many users may well be tricked\ninto clicking through the prompt.\nInternet Explorer’s cookie semantics are similar to those of Firefox.\nWeb storage is not supported in this origin, however.\nOpera and Internet Explorer 6\nBoth of these browsers permit unconstrained DOM or XMLHttpRequest\naccess without further checks. Noncompartmentalized file: cookies are\npermitted, too.\nNOTE Plug-ins live by their own rules in file: land: Flash uses a local-with-filesystem sand-\nbox model,20 which gives largely unconstrained access to the local filesystem, regardless\nof the policy enforced by the browser itself, while executing Java or Windows Presenta-\ntion Framework applets from the local filesystem may in some cases be roughly equiva-\nlent to running an untrusted binary.\n* Because there is no compartmentalization between file: cookies, it is unsafe to rely on them for\nlegitimate purposes. Some locally installed HTML applications ignore this advice, and conse-\nquently, their cookies can be easily tampered with by any downloaded, possibly malicious, HTML\ndocument viewed by the user.\n160 Chapter 9"
  },
  {
    "input": "Other Uses of Origins",
    "output": "Pseudo-URLs\nThe behavior of pseudo-URLs such as about:, data:, or javascript: originally\nconstituted a significant loophole in the implementations of the same-origin\npolicy. All such URLs would be considered same-origin and would permit\nunconstrained cross-domain access from any other resource loaded over the\nsame scheme. The current behavior, which is very different, will be the topic\nof the next chapter of this book; in a nutshell, the status quo reflects several\nrounds of hastily implemented improvements and is a complex mix of\nbrowser-specific special cases and origin-inheritance rules.\nBrowser Extensions and UI\nSeveral browsers permit JavaScript-based UI elements or certain user-installed\nbrowser extensions to run with elevated privileges. These privileges may entail\ncircumventing specific SOP checks or calling normally unavailable APIs in\norder to write files, modify configuration settings, and so on.\nPrivileged JavaScript is a prominent feature of Firefox, where it is used\nwith XUL to build large portions of the browser user interface. Chrome also\nrelies on privileged JavaScript to a smaller but still notable degree.\nThe same-origin policy does not support privileged contexts in any\nspecific way. The actual mechanism by which extra privileges are granted\nmay involve loading the document over a special and normally unreachable\nURL scheme, such as chrome: or res:, and then adding special cases for that\nscheme in other portions of the browser code. Another option is simply to\ntoggle a binary flag for a JavaScript context, regardless of its actual origin,\nand examine that flag later. In all cases, the behavior of standard APIs such\nas localStorage, document.domain, or document.cookie may be difficult to predict\nand should not be relied upon: Some browsers attempt to maintain isolation\nbetween the contexts belonging to different extensions, but most don’t.\nNOTE Whenever writing browser extensions, any interaction with nonprivileged contexts must\nbe performed with extreme caution. Examining untrusted contexts can be difficult,\nandthe use of mechanisms such as eval(...) or innerHMTL may open up privilege-\nescalation paths.\nOther Uses of Origins\nWell, that’s all to be said about browser-level content isolation logic for now.\nIt is perhaps worth noting that the concept of origins and host- or domain-\nbased security mechanisms is not limited to that particular task and makes\nmany other appearances in the browser world. Other quasi-origin-based pri-\nvacy or security features include preferences and cached information related\nto per-site cookie handling, pop-up blocking, geolocation sharing, password\nmanagement, camera and microphone access (in Flash), and much, much\nmore. These features tend to interact with the security features described in\nthis chapter at least to some extent; we explore this topic in more detail soon.\nContent Isolation Logic 161"
  },
  {
    "input": "When Embedding Plug-in-Handled Active Content from Third Parties",
    "output": "Security Engineering Cheat Sheet\nGood Security Policy Hygiene for All Websites\nTo protect your users, include a top-level crossdomain.xml file with the permitted-cross-domain-\npolicies parameter set to master-only or by-content-type, even if you do not use Flash anywhere\nonyour site. Doing so will prevent unrelated attacker-controlled content from being mis-\ninterpreted as a secondary crossdomain.xml file, effectively undermining the assurances of\nthesame-origin policy in Flash-enabled browsers.\nWhen Relying on HTTP Cookies for Authentication\n Use the httponly flag; design the application so that there is no need for JavaScript to\naccess authentication cookies directly. Sensitive cookies should be scoped as tightly as\npossible, preferably by not specifying domain at all.\n If the application is meant to be HTTPS only, cookies must be marked as secure, and you\nmust be prepared to handle cookie injection gracefully. (HTTP contexts may overwrite\nsecure cookies, even though they can’t read them.) Cryptographic cookie signing may\nhelp protect against unconstrained modification, but it does not defend against replacing\na victim’s cookies with another set of legitimately obtained credentials.\nWhen Arranging Cross-Domain Communications in JavaScript\n Do not use document.domain. Rely on postMessage(...) where possible and be sure to\nspecify the destination origin correctly; then verify the sender’s origin when receiving\nthedata on the other end. Beware of naïve substring matches for domain names:\nmsg.origin.indexOf(\".example.com\") is very insecure.\n Note that various pre-postMessage SOP bypass tricks, such as relying on window.name, are\nnot tamper-proof and should not be used for exchanging sensitive data.\nWhen Embedding Plug-in-Handled Active Content from Third Parties\nConsult the cheat sheet in Chapter 8 first for general advice.\n Flash: Do not specify allowScriptAccess=always unless you fully trust the owner of the origi-\nnating domain and the security of its site. Do not use this setting when embedding HTTP\napplets on HTTPS pages. Also, consider restricting allowFullScreen and allowNetworking as\nappropriate.\n Silverlight: Do not specify enableHtmlAccess=true unless you trust the originating domain,\nas above.\n Java: Java applets can’t be safely embedded from untrusted sources. Omitting mayscript\ndoes not fully prevent access to the embedding page, so do not attempt to do so.\n162 Chapter 9"
  },
  {
    "input": "When Writing Browser Extensions",
    "output": "When Hosting Your Own Plug-in-Executed Content\n Note that many cross-domain communication mechanisms provided by browser plug-ins\nmay have unintended consequences. In particular, avoid crossdomain.xml, clientaccesspolicy\n.xml, or allowDomain(...) rules that point to domains you do not fully trust.\nWhen Writing Browser Extensions\n Avoid relying on innerHTML, document.write(...), eval(...), and other error-prone coding\npatterns, which can cause code injection on third-party pages or in a privileged JavaScript\ncontext.\n Do not make security-critical decisions by inspecting untrusted JavaScript security con-\ntexts, as their behavior can be deceptive.\nContent Isolation Logic 163"
  },
  {
    "input": "10: Origin Inheritance\r",
    "output": "O R I G I N I N H E R I T A N C E\nSome web applications rely on pseudo-URLs such as\nabout:, javascript:, or data: to create HTML documents\nthat do not contain any server-supplied content and that\nare instead populated with the data constructed entirely\non the client side. This approach eliminates the delay\nassociated with the usual HTTP requests to the server\nand results in far more responsive user interfaces.\nUnfortunately, the original vision of the same-origin policy did not\naccount for such a use case. Specifically, a literal application of the protocol-,\nhost-, and port-matching rules discussed in Chapter 9 would cause every\nabout:blank document created on the client side to have a different origin\nfrom its parent page, preventing it from being meaningfully manipulated.\nFurther, all about:blank windows created by completely unrelated websites\nwould belong to the same origin and, under the right circumstances, would\nbe able to interfere with each other with no supervision at all."
  },
  {
    "input": "Origin Inheritance for about:blank",
    "output": "To address this incompatibility of client-side documents with the same-\norigin policy, browsers gradually developed incompatible and sometimes\ncounterintuitive approaches to computing a synthetic origin and access per-\nmissions for pseudo-URLs. An understanding of these rules is important on\nits own merit, and it will lay the groundwork for the discussion of certain\nother SOP exceptions in Chapter 11.\nOrigin Inheritance for about:blank\nThe about: scheme is used in modern browsers for a variety of purposes, most\nof which are not directly visible to normal web pages. The about:blank docu-\nment is an interesting special case, however: This URL can be used to create\na minimal DOM hierarchy (essentially a valid but empty document) to which\nthe parent document may write arbitrary data later on.\nHere is an example of a typical use of this scheme:\n<iframe src=\"about:blank\" name=\"test\"></iframe>\n<script>\n...\nframes[\"test\"].document.body.innerHTML = \"<h1>Hi mom!</h1>\";\n...\n</script>\nNOTE In the HTML markup provided in this example, and when creating new windows or\nframes in general, about:blank can be omitted. The value is defaulted to when no\nother URL is specified by the creator of the parent document.\nIn every browser, most types of navigation to about:blank result in the cre-\nation of a new document that inherits its SOP origin from the page that initi-\nated the navigation. The inherited origin is reflected in the document.domain\nproperty of the new JavaScript execution context, and DOM access to or\nfrom any other origins is not permitted.\nThis simple formula holds true for navigation actions such as clicking a\nlink, submitting a form, creating a new frame or a window from a script, or\nprogrammatically navigating an existing document. That said, there are excep-\ntions, the most notable of which are several special, user-controlled navigation\nmethods. These include manually entering about:blank in the address bar, fol-\nlowing a bookmark, or performing a gesture reserved for opening a link in a\nnew window or a tab.* These actions will result in a document that occupies a\nunique synthetic origin and that can’t be accessed by any other page.\nAnother special case is the loading of a normal server-supplied docu-\nment that subsequently redirects to about:blank using Location or Refresh. In\nFirefox and WebKit-based browsers, such redirection results in a unique, non-\naccessible origin, similar to the scenario outlined in the previous paragraph.\nIn Internet Explorer, on the other hand, the resulting document will be\n* This is usually accomplished by holding CTRL or SHIFT while clicking on a link, or by right-\nclicking the mouse to access a contextual menu, and then selecting the appropriate option.\n166 Chapter 10"
  },
  {
    "input": "Inheritance for data: URLs",
    "output": "accessible by the parent page if the redirection occurs inside an <iframe> but\nnot if it took place in a separate window. Opera’s behavior is the most diffi-\ncult to understand: Refresh results in a document that can be accessed by the\nparent page, but the Location redirect will give the resulting page the origin\nof the site that performed the redirect.\nFurther, it is possible for a parent document to navigate an existing\ndocument frame to an about:blank URL, even if the existing document shown\nin that container has a different origin than the caller.* The newly created\nblank document will inherit the origin from the caller in all browsers other\nthan Internet Explorer. In the case of Internet Explorer, such navigation will\nsucceed but will result in an inaccessible document. (This behavior is most\nlikely not intentional.)\nIf this description makes your head spin, the handling of about:blank doc-\numents is summarized in Table 10-1.\nTable 10-1: Origin Inheritance for about:blank URLs\nType of navigation\nNew page Existing non- Location redirect Refresh redirect URL entry or\nsame-origin gesture\npage\nInternet Inherited Unique origin (Denied) Frame: Inherited Unique\nExplorer from caller from parent origin\nWindow:\nUnique origin\nFirefox Inherited from caller Unique origin\nAll WebKit Inherited from caller (Denied) Unique origin\nOpera Inherited from caller Inherited from Inherited from\nredirecting party parent\nInheritance for data: URLs\nThe data: scheme,1 first outlined in Chapter 2, was designed to permit small\ndocuments, such as icons, to be conveniently encoded and then directly\ninlined in an HTML document, saving time on HTTP round-trips. For\nexample:\n<img src=\"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEBLAEsAAD...\">\nWhen the data: scheme is used in conjunction with type-specific sub-\nresources, the only unusual security consideration is that it poses a challenge\nfor plug-ins that wish to derive permissions for an applet from its originating\n* The exact circumstances that make this possible will be the focus of Chapter 11. For now,\nsuffice it to say that this can be accomplished in many settings in a browser-specific way. For\nexample, in Firefox, you call window.open(..., 'target'), while in Internet Explorer, calling\ntarget.location.assign(...) is the way to go.\nOrigin Inheritance 167\nURL. The origin can’t be computed by looking at the URL alone, and the\nbehavior is somewhat unpredictable and highly plug-in specific (for exam-\nple, Adobe Flash currently rejects any attempts to use data: documents).\nMore important than the case of type-specific content is the use of data:\nas a destination for windows and frames. In all browsers but Internet Explorer,\nthe scheme can be used as an improved variant of about:blank, as in this\nexample:\n<iframe src=\"data:text/html;charset=utf-8,<h1>Hi mom!</h1>\">\n</iframe>\nIn this scenario, there is no compelling reason for a data: URL to behave\ndifferently than about:blank. In reality, however, it will behave differently in\nsome browsers and therefore must be used with care.\n WebKit browsers In Chrome and Safari, all data: documents are given a\nunique, nonaccessible origin and do not inherit from the parent at all.\n Firefox In Firefox, the origin for data: documents is inherited from the\nnavigating context, similar to about:blank. However, unlike with about:blank,\nmanually entering data: URLs or opening bookmarked ones results in\nthe new document inheriting origin from the page on which the naviga-\ntion occurred.\n Opera As of this writing, a shared “empty” origin is used for all data:\nURLs, which is accessible by the parent document. This approach is\nunsafe, as it may allow cross-domain access to frames created by unre-\nlated pages, as shown in Figure 10-1. (I reported this behavior to Opera,\nand it likely will be amended soon.)\n Internet Explorer data: URLs are not supported in Internet Explorer\nversions prior to 8. The scheme is supported only for select types of sub-\nresources in Internet Explorer 8 and 9 and can’t be used for navigation.\nTable 10-2 summarizes the current behavior of data: URLs.\nTable 10-2: Origin Inheritance for data: URLs\nType of navigation\nNew page Existing non-same- Location Refresh URL entry or\norigin page redirect redirect gesture\nInternet (Not supported)\nExplorer 6/7\nInternet (Not supported for navigation)\nExplorer 8/9\nFirefox Inherited from caller Unique origin Inherited from\nprevious page\nAll WebKit Unique origin (Denied) Unique Unique origin\norigin\nOpera Shared origin (This is a bug!) (Denied) Inherited\nfrom\nparent\n168 Chapter 10"
  },
  {
    "input": "Inheritance for javascript: and vbscript: URLs",
    "output": "Opera\nTop-level document: fuzzybunnies.com\nframe: data:text/html,...\nCross-domain DOM\naccess possible\nframe: bunnyoutlet.com\nframe: data:text/html,...\n<script>\ntop.frames[0].document.body.innerHTML = ...\n</script>\nFigure 10-1: Access between data: URLs in Opera\nInheritance for javascript: and vbscript: URLs\nScripting-related pseudo-URLs, such as javscript:, are a very curious mecha-\nnism. Using them to load some types of subresources will lead to code execu-\ntion in the context of the document that attempts to load such an operation\n(subject to some inconsistent restrictions, as discussed in Chapter 4). An\nexample of this may be\n<iframe src=\"javascript:alert('Hi mom!')\"></iframe>\nMore interestingly (and far less obviously) than the creation of new\nsubresources, navigating existing windows or frames to javascript: URLs will\ncause the inlined JavaScript code to execute in the context of the navigated\npage (and not the navigating document!)—even if the URL is entered man-\nually or loaded from a bookmark.\nGiven this behavior, it is obviously very unsafe to allow one document\ntonavigate any other non-same-origin context to a javascript: URL, as it\nwould enable the circumvention of all other content-isolation mecha-\nnisms: Just load fuzzybunnies.com in a frame, and then navigate that frame\ntojavascript:do_evil_stuff() and call it a day. Consequently, such navigation\nisprohibited in all browsers except for Firefox. Firefox appears to permit it\nfor some reason, but it changes the semantics in a sneaky way. When the\norigin of the caller and the navigation target do not match, it executes the\njavascript: payload in a special null origin, which lacks its own DOM or any of\nthe browser-supplied I/O functions registered (thus permitting only purely\nalgorithmic operations to occur).\nOrigin Inheritance 169"
  },
  {
    "input": "A Note on Restricted Pseudo-URLs",
    "output": "The cross-origin case is dangerous, but its same-origin equivalent is not:\nWithin a single origin, any content is free to navigate itself or its peers to\njavascript: URLs on its own volition. In this case, the javascript: scheme is hon-\nored when following links, submitting forms, calling location.assign(...), and\nso on. In WebKit and Opera, Refresh redirection to javascript: will work as well;\nother browsers reject such navigation due to vague and probably misplaced\nscript-injection concerns.\nThe handling of scripting URLs is outlined in Table 10-3.\nTable 10-3: Origin Inheritance for Scripting URLs\nType of navigation\nNew page Existing Existing Location Refresh URL entry\nsame-origin non-same- redirect redirect or gesture\npage origin page\nInternet Inherited Inherited (Denied) (Denied) (Denied) Inherited\nExplorer from caller from from\nnavigated navigated\nFirefox Null context (Denied)\npage page\nAll WebKit (Denied) Inherited from\nnavigated\npage\nOpera (Denied) Inherited from\nnavigated\npage\nOn top of these fascinating semantics, there is a yet another twist unique\nto the javascript: scheme: In some cases, the handling of such script-containing\nURLs involves a second step. Specifically, if the supplied code evaluates prop-\nerly, and the value of the last statement is nonvoid and can be converted to a\nstring, this string will be interpreted as an HTML document and will replace\nthe navigated page (inheriting origin from the caller). The logic governing\nthis curious behavior is very similar to that influencing the behavior of data:\nURLs. An example of such a document-replacing expression is this:\njavascript:\"<b>2 + 2 = \" + (2+2) + \"</b>\"\nA Note on Restricted Pseudo-URLs\nThe somewhat quirky behavior of the three aforementioned classes of\nURLs—about:blank, javascript:, and data:—are all that most websites need to\nbe concerned with. Nevertheless, browsers use a range of other documents\nwith no inherent, clearly defined origin (e.g., about:config in Firefox, a privi-\nleged JavaScript page that can be used to tweak the browser’s various under-\nthe-hood settings, or chrome://downloads in Chrome, which lists the recently\ndownloaded documents with links to open any of them). These documents\nare a continued source of security problems, even if they are not reachable\ndirectly from the Internet.\n170 Chapter 10\nBecause of the incompatibility of these URLs with the boundaries con-\ntrolled by the same-origin policy, special care must be taken to make sure\nthat these URLs are sufficiently isolated from other content whenever they\nare loaded in the browser as a result of user action or some other indirect\nbrowser-level process. An interesting case illustrating the risk is a 2010 bug\ninthe way Firefox handled about:neterror.2 Whenever Firefox can’t correctly\nretrieve a document from a remote server (a condition that is usually easy\ntotrigger with a carefully crafted link), it puts the destination URL in the\naddress bar but loads about:neterror in place of the document body. Unfortu-\nnately, due to a minor oversight, this special error page would be same-origin\nwith any about:blank document opened by any Internet-originating content,\nthereby permitting the attacker to inject arbitrary content into the\nabout:neterror window while preserving the displayed destination URL.\nThe moral of this story? Avoid the urge to gamble with the same-origin\npolicy; instead, play along with it. Note that making about:neterror a hierarchi-\ncal URL, instead of trying to keep track of synthetic origins, would have pre-\nvented the bug.\nOrigin Inheritance 171"
  },
  {
    "input": "Security Engineering Cheat Sheet",
    "output": "Security Engineering Cheat Sheet\nBecause of their incompatibility with the same-origin policy, data:, javascript:, and implicit\norexplicit about:blank URLs should be used with care. When performance is not critical, it is\npreferable to seed new frames and windows by pointing them to a server-supplied blank docu-\nment with a definite origin first.\nKeep in mind that data: and javascript: URLs are not a drop-in replacement for about:blank,\nand they should be used only when absolutely necessary. In particular, it is currently unsafe to\nassume that data: windows can’t be accessed across domains.\n172 Chapter 10"
  },
  {
    "input": "11: Life Outside Same-Origin Rules\r",
    "output": "L I F E O U T S I D E\nS A M E - O R I G I N R U L E S\nThe same-origin policy is the most important mecha-\nnism we have to keep hostile web applications at bay,\nbut it’s also an imperfect one. Although it is meant to\noffer a robust degree of separation between any two\ndifferent and clearly identifiable content sources, it\noften fails at this task.\nTo understand this disconnect, recall that contrary to what common\nsense may imply, the same-origin policy was never meant to be all-inclusive.\nIts initial focus, the DOM hierarchy (that is, just the document object exposed\nto JavaScript code) left many of the peripheral JavaScript features completely\nexposed to cross-domain manipulation, necessitating ad hoc fixes. For exam-\nple, a few years after the inception of SOP, vendors realized that allowing third-\nparty documents to tweak the location.host property of an unrelated window is\na bad idea and that such an operation could send potentially sensitive data\npresent in other URL segments to an attacker-specified site. The policy has"
  },
  {
    "input": "Changing the Location of Existing Documents",
    "output": "subsequently been extended to at least partly protect this and a couple of\nother sensitive objects, but in some less clear-cut cases, awkward loopholes\nremain.\nThe other problem is that many cross-domain interactions happen\ncompletely outside of JavaScript and its object hierarchy. Actions such as\nloading third-party images or stylesheets are deeply rooted in the design of\nHTML and do not depend on scripting in any meaningful way. (In principle,\nit would be possible to retrofit them with origin-based security controls, but\ndoing so would interfere with existing websites. Plus, some think that such a\ndecision would go against the design principles that made the Web what it is;\nthey believe that the ability to freely cross-reference content should not be\ninfringed upon.)\nIn light of this, it seems prudent to explore the boundaries of the same-\norigin policy and learn about the rich life that web applications can lead out-\nside its confines. We begin with document navigation—a mechanism that at\nfirst seems strikingly simple but that is really anything but.\nWindow and Frame Interactions\nOn the Web, the ability to steer the browser from one website to another\nistaken for granted. Some of the common methods of achieving such nav-\nigation are discussed throughout Part I of this book; the most notable of\nthese are HTML links, forms, and frames; HTTP redirects; and JavaScript\nwindow.open(...) and location.* calls.\nActions such as pointing a newly opened window to an off-domain URL\nor specifying the src parameter of a frame are intuitive and require no fur-\nther review. But when we look at the ability of one page to navigate another,\nexisting document—well, the reign of intuition comes to a sudden end.\nChanging the Location of Existing Documents\nIn the simple days before the advent of HTML frames, only one document\ncould occupy a given browser window, and only that single window would be\nunder the document’s control. Frames changed this paradigm, however, per-\nmitting several different and completely separate documents to be spliced\ninto a single logical view, coexisting within a common region of the screen.\nThe introduction of the mechanism also necessitated another step: To sanely\nimplement certain frame-based websites, any of the component documents\ndisplayed in a window needed the ability to navigate its neighboring frames\nor perhaps the top-level document itself. (For example, imagine a two-frame\npage with a table of contents on the left and the actual chapter on the right.\nClicking a chapter name in the left pane should navigate the chapter in the\nright pane, and nothing else.)\nThe mechanism devised for this last purpose is fairly simple: One can\nspecify the target parameter on <a href=...> links or forms, or provide the\nname of a window to the JavaScript method known as window.open(...), in\n174 Chapter 11\norder to navigate any other, previously named document view. In the mid-\n1990s, when this functionality first debuted, there seemed to be no need to\nincorporate any particular security checks into this logic; any page could nav-\nigate any other named window or a frame displayed by the browser to a new\nlocation at will.\nTo understand the consequences of this design, it is important to pause\nfor a moment and examine the circumstances under which a particular doc-\nument may obtain a name to begin with. For frames, the story is simple: In\norder to reference a frame easily on the embedding page, virtually all frames\nhave a name attribute (and some browsers, such as Chrome, also look at id).\nBrowser windows, on the other hand, are typically anonymous (that is, their\nwindow.name property is an empty string), unless created programmatically;\nin the latter case, the name is specified by whoever creates the view. Anony-\nmous windows do not necessarily stay anonymous, however. If a rogue appli-\ncation is displayed in such a window even briefly, it may set the window.name\nproperty to any value, and this effect will persist.\nThe aforementioned ability to target windows and frames by name is not\nthe only way to navigate them; JavaScript programs that hold window handles\npointing to other documents may directly invoke certain DOM methods with-\nout knowing the name of their target at all. Attacker-supplied code will not\nnormally hold handles to completely unrelated windows, but it can traverse\nproperties such as opener, top, parent, or frames[] in order to locate even distant\nrelatives within the same navigation flow. An example of such a far-reaching\nlookup (and subsequently, navigation) is\nopener.opener.frames[2].location.assign(\"http://www.bunnyoutlet.com/\");\nThese two lookup techniques are not mutually exclusive: JavaScript\nprograms can first obtain the handle of an unrelated but named window\nthrough window.open(...) and then traverse the opener or frames[] properties\nofthat context in order to reach its interesting relatives nearby.\nOnce a suitable handle is looked up in any fashion, the originating con-\ntext can leverage one of several DOM methods and properties in order to\nchange the address of the document displayed in that view. In every contem-\nporary browser, calling the <handle>.location.replace(...) method, or assigning a\nvalue to <handle>.location or <handle>.location.href properties, should do the\ntrick. Amusingly, due to random implementation quirks, other theoretically\nequivalent approaches (such as invoking <handle>.location.assign(...) or\n<handle>.window.open(..., \"_self\")) may be hit-and-miss.\nOkay, so it may be possible to navigate unrelated documents to new\nlocations—but let’s see what could possibly go wrong.\nFrame Hijacking Risks\nThe ability for one domain to navigate windows created by other sites, or\nones that are simply no longer same-origin with their creator, is usually not\nagrave concern. This laid-back design may be an annoyance and may pose\nLife Outside Same-Origin Rules 175\nsome minor, speculative phishing risk,* but in the grand scheme of things, it\nis neither a very pronounced issue nor a particularly distinctive one. This is,\nperhaps, the reason why the original authors of the relevant APIs have not\ngiven the entire mechanism too much thought.\nAlas, the concept of HTML frames alters the picture profoundly: Any\napplication that relies on frames to build a trusted user interface is at an obvi-\nous risk if an unrelated site is permitted to hijack such UI elements without\nleaving any trace of the attack in the address bar! Figure 11-1 shows one such\nplausible attack scenario.\nBunny Browser 2000 Bunny Browser 2000\nhttps://fuzzybunnies.com http://bunnyoutlet.com\nWelcome to Fuzzy Bunnies <script>\nOnline Banking and BBQ! bank_win.frames[0].location.href =\n\"http://bunnyoutlet.com/fakelogin\";\n</script>\nframe: login.fuzzybunnies.com\nLogin:\nPassword: Login frame can be navigated\nto an attacker-supplied URL.\nFigure 11-1: A historically permitted, dangerous frame navigation scenario: The window\non the right is opened at the same time as a banking website and is actively subverting it.\nGeorgi Guninski, one of the pioneering browser security researchers,\nrealized as early as 1999 that by permitting unconstrained frame navigation,\nwe were headed for some serious trouble. Following his reports, vendors\nattempted to roll out frame navigation restrictions mid-2000.1 Their imple-\nmentation constrained all cross-frame navigation to the scope of a single\nwindow, preventing malicious web pages from interfering with any other\nsimultaneously opened browser sessions.\nSurprisingly, even this simple policy proved difficult to implement\ncorrectly. It was only in 2008 that Firefox eliminated this class of problems,2\nwhile Microsoft essentially ignored the problem until 2006. Still, these set-\nbacks aside, we should be fine—right?\nFrame Descendant Policy and Cross-Domain Communications\nThe simple security restriction discussed in the previous session was not,\ninfact, enough. The reason was a new class of web applications, sometimes\nknown as mashups, that combined data from various sources to enable users\nto personalize their working environment and process data in innovative ways.\nUnfortunately for browser vendors, such web applications frequently relied\non third-party gadgets loaded through <iframe> tags, and their developers\n* One potential attack is this: Open a legitimate website (say, http://trusted-bank.com/) in a new\nwindow, wait for the user to inspect the address bar, and then quickly change the location to an\nattacker-controlled but similarly named site (e.g., http://trustea-bank.com/). The likelihood of\nsuccessfully phishing the victim may be higher than when the user is navigating to the bad URL\nright away.\n176 Chapter 11\ncould not reasonably expect that loading a single frame from a rogue source\nwould put all other frames on the page at risk. Yet, the simple and elegant\nwindow-level navigation policy amounted to permitting exactly that.\nAround 2006, Microsoft agreed that the current approach was not sustain-\nable and developed a more secure descendant policy for frame navigation in\nInternet Explorer 7. Under this policy, navigation of non-same-origin frames\nis permitted only if the party requesting the navigation shares the origin with\none of the ancestors of the targeted view. Figure 11-2 shows the navigation\nscenario permitted by this new policy.\nBunny Browser 2000\nhttp://bunnyoutlet.com\nframe: bunnyoutlet.com\n<script>\nwindow.open(\"http://bunnyoutlet.com/fakeframe\", \"private\");\n</script>\nNested frame\nframe: fuzzybunnies.com navigation\npossible\nframe “private”: fuzzybunnies.com\nFigure 11-2: A complex but permissible navigation between non-same-origin frames.\nThis attempt succeeds only because the originating frame has the same origin as one\nof the ancestors of the targeted document—here, it’s the top-level page itself.\nAs with many other security improvements, Microsoft never backported\nthis policy to the still popular Internet Explorer 6, and it never convincingly\npressured users to abandon the older and increasingly insecure (but still\nsuperficially supported) version of its browser. On a more positive note, by\n2009, three security researchers (Adam Barth, Collin Jackson, and John C.\nMitchell) convinced Mozilla, Opera, and WebKit to roll out a similar policy\nin their browsers,3 finally closing the mashup loophole for a good majority\nofthe users of the Internet.\nWell, almost closing it. Even the new, robust policy has a subtle flaw.\nNotice in Figure 11-2 that a rogue site, http://bunnyoutlet.com/, can interfere\nwith a private frame that http://fuzzybunnies.com/ has created for its own use.\nAt first glance, there is no harm here: The attacker’s domain is shown in the\naddress bar, so the victim, in theory, should not be fooled into interacting\nwith the subverted UI of http://fuzzybunnies.com/ in any meaningful way. Sadly,\nthere is a catch: Some web applications have learned to use frames not to\nLife Outside Same-Origin Rules 177"
  },
  {
    "input": "Unsolicited Framing",
    "output": "create user interfaces but to relay programmatic messages between origins.\nFor applications that need to support Internet Explorer 6 and 7, where\npostMessage(...) is not available, the tricks similar to the approach shown\ninFigure 11-3 are commonplace.\nBunny Browser 2000\nhttp://www.fuzzybunnies.com\n// Step 1: send message to login.fuzzybunnies.com\n// This is permitted because the send_to_child frame is a descendant of this document.\nframes[\"send_to_child\"].src = \"http://login.fuzzybunnies.com/login_handler#\" + message_to_send;\nframe “send_to_child”: login.fuzzybunnies.com/login_handler#\n// Step 2: read message sent in step 1.\n// It is always possible to examine your own fragment ID.\nresponse_text = process_message_from_parent(location.hash);\n// Step 3: send response to www.fuzzybunnies.com.\n// This is permitted because send_to_parent is a descendant of this document.\nframes[\"send_to_parent\"].location = \"http://www.fuzzywunnies.com/blank#\" + response_text\nframe “send_to_parent”: www.fuzzybunnies.com/blank#\n// Step 4: read back data from login.fuzzybunnies.com.\n// This is permitted because the send_to_parent frame is same-origin with this document.\nprocess_message_from_child(frames[\"send_to_parent\"].location.hash);\nFigure 11-3: A potential cross-domain communication scheme, where the top-level\npage encodes messages addressed to the embedded gadget in the fragment identi-\nfier of the gadget frame and the gadget responds by navigating a subframe that is\nsame-origin with the top-level document. If this application is framed on a rogue site,\nthe top-level document controlled by the attacker will be able to inject messages\nbetween the two parties by freely navigating send_to_parent and send_to_child.\nIf an application that relies on a similar hack is embedded by a rogue\nsite, the integrity of the communication frames may be compromised, and\nthe attacker will be able to inject messages into the stream. Even the uses of\npostMessage(...) may be at risk: If the party sending the message does not spec-\nify a destination origin or if the recipient does not examine the originating\nlocation, hijacking a frame will benefit the attacker in exactly the sameway.\nUnsolicited Framing\nThe previous discussion of cross-frame navigation highlights one of the more\ninteresting weaknesses in the browser security model, as well as the discon-\nnect between the design goals of HTML and the aim of the same-origin pol-\nicy. But that’s not all: The concept of cross-domain framing is, by itself, fairly\nrisky. Why? Well, any malicious page may embed a third-party application with-\nout a user’s knowledge, let alone consent. Further, it may obfuscate this fact by\noverlaying other visual elements on top of the frame, leaving visible just a small\nchunk of the original site, such as a button that performs a state-changing\n178 Chapter 11\naction. In such a setting, any user logged into the targeted application with\nambient credentials may be easily tricked into interacting with the disguised\nUI control and performing an undesirable and unintended action, such as\nchanging sharing settings for a social network profile or deleting data.\nThis attack can be improved by the rogue site leveraging a CSS2 property\ncalled opacity to make the targeted frame completely invisible without affecting\nits actual behavior. Any click in the area occupied by such a see-through frame\nwill be delivered to the UI controls contained therein (see Figure 11-4). Too,\nby combining CSS opacity with JavaScript code to make the frame follow the\nmouse pointer, it is possible to carry out the attack fairly reliably in almost\nany setting: Convincing the user to click anywhere in the document window\nis not particularly hard.\nFigure 11-4: A simplified example of a UI-splicing attack that\nuses CSS opacity to hide the document the user will actually\ninteract with\nResearchers have recognized the possibility of such trickery to some\nextent since the early 2000s, but a sufficiently convincing attack wasn’t dem-\nonstrated until 2008, when Robert Hansen and Jeremiah Grossman publi-\ncized the issue broadly.4 Thus, the term clickjacking was born.\nThe high profile of Hansen and Grossman’s report, and their interesting\nproof-of-concept example, piqued vendors’ interest. This interest proved to\nbe short-lived, however, and there appears to be no easy way to solve this\nproblem without taking some serious risks. The only even remotely plausible\nway to mitigate the impact would be to add renderer-level heuristics to dis-\nallow event delivery to cross-domain frames that are partly obstructed or that\nhave not been displayed long enough. But this solution is complicated and\nhairy enough to be unpopular.5 Instead, the problem has been slapped with\na Band-Aid. A new HTTP header, X-Frame-Options, permits concerned sites to\nopt out of being framed altogether (X-Frame-Options: deny) or consent only to\nframing within a single origin (X-Frame-Options: same-origin).6 This header\nLife Outside Same-Origin Rules 179\nissupported in all modern browsers (in Internet Explorer, beginning with\nversion 8),* but it actually does little to address the vulnerability.\nFirstly, the opt-in nature of the defense means that most websites will\nnotadopt it or will not adopt it soon enough; in fact, a 2011 survey of the top\n10,000 destinations on the Internet found that barely 0.5 percent used this\nfeature.7\nTo add insult to injury, the proposed mechanism is useless for applica-\ntions that want to be embedded on third-party sites but that wish to preserve\nthe integrity of their UIs. Various mashups and gadgets, those syndicated\n“like” buttons provided by social networking sites, and managed online dis-\ncussion interfaces are all at risk.\nBeyond the Threat of a Single Click\nAs the name implies, the clickjacking attack outlined by Grossman and\nHansen targets simple, single-click UI actions. In reality, however, the prob-\nlem with deceptive framing is more complicated than the early reporting\nwould imply. One example of a more complex interaction is the act of select-\ning, dragging, and dropping a snippet of text. In 2010, Paul Stone proposed\na number of ways in which such an action could be disguised as a plausible\ninteraction with an attacker’s site,8 the most notable of which is the similarity\nbetween drag-and-drop and the use of a humble document-level scrollbar.\nThe same click-drag-release action may be used to interact with a legitimate\nUI control or to unwittingly drag a portion of preselected text out of a sensi-\ntive document and drop it into an attacker-controlled frame. (Cross-domain\ndrag-and-drop is no longer permitted in WebKit, but as of this writing other\nbrowser vendors are still debating the right way to address this risk.)\nAn even more challenging problem is keystroke redirection. Sometime\nin 2010, I noticed that it was possible to selectively redirect keystrokes across\ndomains by examining the code of a pressed key using the onkeydown event in\nJavaScript. If the pressed key matched what a rogue site wanted to enter into\na targeted application, HTML element focus could be changed momentarily\nto a hidden <iframe>, thereby ensuring the delivery of the actual keystrokes to\nthe targeted web application rather than the harmless text field the user seems\nto be interacting with.9 Using this method, an attacker can synthesize arbi-\ntrarily complex text in another domain on the user’s behalf—for example,\ninviting the attacker as an administrator of the victim’s blog.\nBrowser vendors addressed the selective keystroke redirection issue by\ndisallowing element focus changes in the middle of a keypress, but doing so\ndid not close the loophole completely. After all, in some cases, an attacker\ncan predict what key will be pressed next and roughly at what time, thereby\npermitting a preemptive, blindly executed focus switch. The two most obvi-\nous cases are a web-based action game or a typing-speed test, since both typi-\ncally involve rapid pressing of attacker-influenced keys.\n* In older versions of Internet Explorer, web application developers sometimes resort to Java-\nScript in an attempt to determine whether the window object is the same as parent, a condition\nthat should be satisfied if no higher-level frame is present. Unfortunately, due to the flexibility of\nJavaScript DOM, such checks, as well as many types of possible corrective actions, are notoriously\nunreliable.\n180 Chapter 11"
  },
  {
    "input": "Cross-Domain Content Inclusion",
    "output": "In fact, it gets better: Even if a malicious application only relies on free-\nform text entry—for example, by offering the user a comment-submission\nform—it’s often possible to guess which character will be pressed next based\non the previous few keystrokes alone. English text (and text in most other\nhuman languages) is highly redundant, and in many cases, a considerable\namount of input can be predicted ahead of time: You can bet that a-a-r-d-v\nwill be followed by a-r-k, and almost always you will be right.\nCross-Domain Content Inclusion\nFraming and navigation are a distinct source of trouble, but these mecha-\nnisms aside, HTML supports a number of other ways to interact with non-\nsame-origin data. The usual design pattern for these features is simple and\nseemingly safe: A constrained data format that will affect the appearance of\nthe document is retrieved and parsed without being directly shown to the ori-\ngin that referenced it. Examples of mechanisms that follow this rule include\nmarkup such as <script src=...>, <link rel=stylesheet href=...>, <img src=...>, and\nseveral related cases discussed throughout Part I of this book.\nRegrettably, the devil is in the details. When these mechanisms were first\nproposed, nobody asked several extremely pressing questions:\n Should these subresources be requested with ambient credentials associ-\nated with their origin? If so, there is a danger that the response may con-\ntain sensitive data not intended for the requesting party. It would probably\nbe better to require some explicit form of authentication or to notify the\nserver about the origin of the requesting page.\n Should the relevant parsers be designed to minimize the risk of mis-\ntaking one document type for another? And should the servers have\ncontrol over how their responses are interpreted (for example through\nthe Content-Type header)? If not, what are the consequences of, say, inter-\npreting a user’s private JPEG image as a script?\n Should the requesting page have no way to infer anything about the\ncontents of the retrieved payloads? If yes, then this goal needs to be\ntaken into account with utmost care when designing all the associated\nAPIs. (If such separation is not a goal, the importance of the previous\nquestions is even more pronounced.)\nThe developers acted with conflicting assumptions about these topics, or\nperhaps had not given them any thought at all, leading to a number of pro-\nfound security risks. For example, in most browsers, it used to be possible to\nread arbitrary, cookie-authenticated text by registering an onerror handler on\ncross-domain <script> loads: The verbose “syntax error” message generated by\nthe browser would include a snippet of the retrieved file. Still, no problem in\nthis category is more interesting than a glitch discovered by Chris Evans in\n2009.10 He noticed that the hallmark fault tolerance of CSS parsers (which,\nas you may recall, recover from syntax errors by attempting to resynchronize\nat the nearest curly bracket) is also a fatal security flaw.\nIn order to understand the issue, consider the following simple HTML\ndocument. This document contains two occurrences of an attacker-controlled\nLife Outside Same-Origin Rules 181\nstring, and—sandwiched in between—a sensitive, user-specific value (in this\ncase, a user’s name):\n<head>\n<title>Page not found: ');} gotcha { background-image: url('/</title>\n</head>\n<body>\n...\n<span class=\"header\">You are logged in as: John Doe</span>\n...\n<div class=\"error_message\">\nPage not found: ');} gotcha { background-image: url('/\n</div>\n...\n</body>\nLet’s assume that the attacker lured the victim to his own page and, on\nthis page, used <link rel=stylesheet> to load the aforementioned cross-domain\nHTML document in place of a stylesheet. The victim’s browser will happily\ncomply: It will request the document using the victim’s cookies, will ignore\nContent-Type on the subsequent response, and will hand the retrieved content\nover to the CSS parser. The parser will cheerfully ignore all syntax errors\nleading up to what appears to be a CSS rule named gotcha. It will then process\nthe url('... pseudo-function, consuming all subsequent HTML (including the\nsecret user name!), until it reaches a matching quote and a closing parenthe-\nsis. When this faux stylesheet is later applied to a class=gotcha element on the\nattacker’s website, the browser will attempt to load the resulting URL and will\nleak the secret value to the attacker’s server in the process.\nAstute readers may note that the CSS standard does not support multi-\nline string literals, and as such, this trick would not work as specified. That’s\npartly true: In most browsers, the attempt will succeed only if the critical seg-\nment of the page contains no stray newlines. Some web applications are opti-\nmized to avoid unnecessary whitespaces and therefore will be vulnerable, but\nmost web developers use newlines liberally, thwarting the attack. Alas, as noted\nin Chapter 5, one browser behaves differently: Internet Explorer accepts\nmultiline strings in stylesheets and many other egregious syntax violations,\naccidentally amplifying the impact of this flaw.\nNOTE Since identifying this problem, Chris Evans has pushed for fixes in all mainstream brows-\ners, and as of this writing, most implementations reject cross-domain stylesheets that don’t\nbegin right away with a valid CSS rule or that are served with an incompatible Content-\nType header (same-origin stylesheets are treated less restrictively). The only vendor to\nresist was Microsoft, which changed its mind only after a demonstration of a successful\nproof-of-concept attack against Twitter.11 Following this revelation, Microsoft agreed not\nonly to address the problem in Internet Explorer 8 but also—uncharacteristically—to\nbackport this particular fix to Internet Explorer 6 and 7 as well.\nThanks to Chris’s efforts, stylesheets are a solved problem, but similar\nproblems are bound to recur for other types of cross-domain subresources.\nIn such cases, not all transgressions can be blamed on the sins of the old. For\n182 Chapter 11"
  },
  {
    "input": "A Note on Cross-Origin Subresources",
    "output": "example, when browser vendors rolled out <canvas>, a simple HTML5 mech-\nanism that enables JavaScript to create vector and bitmap graphics,12 many\nimplementations put no restrictions on loading cross-domain images onto\nthe canvas and then reading them back pixel by pixel. As of this writing, this\nissue, too, has been resolved: A canvas once touched by a cross-domain image\nbecomes “tainted” and can only be written to, not read. But when we need\ntofix each such case individually, something is very wrong.\nA Note on Cross-Origin Subresources\nSo far, we have focused on the risks of malicious websites navigating or\nincluding content that belongs to trusted parties. That said, the ability to\nload certain types of subresources from other origins has significant conse-\nquences, even if not actively subverted by a third-party site.\nIn Part I of the book, we hinted that loading a script or a stylesheet\nfromanother origin effectively equates the security of the document that\nperforms the load to the security of the origin of the loaded subresource; in\nparticular, loading an HTTP script on an HTTPS page undoes most of the\nbenefits of encryption. Similarly, loading a script from a provider whose\ninfrastructure is vulnerable to attack can be nearly as problematic as not\nproperly maintaining your own servers.\nIn addition to scripts and stylesheets, other content types that may lead\nto serious trouble include remote fonts (a recent addition to CSS) and plug-\nins with access to the embedding page (such as allowScriptAccess=always for\nFlash). It is also somewhat dangerous to load images, icons, cursors, or HTML\nframes from untrusted sources, although the impact of doing so is contained\nto some extent and will be use specific.\nContemporary browsers attempt to detect cases where HTTPS documents\nload HTTP resources—a condition known as mixed content. They do so fairly\ninconsistently, however: Internet Explorer is the only browser that blocks most\ntypes of mixed content by default (and Chrome is expected to follow suit), but\nneither Internet Explorer nor Firefox nor Opera consistently detects mixed\ncontent on <embed>, <object>, or <applet> tags. In browsers other than Internet\nExplorer, the default action is a subtle warning (for example, an exclamation\nmark next to the lock icon) or a cryptic dialog, which does very little to pro-\ntect the user but which may alert a sufficiently attentive web developer.\nAs to the other flavor of mixed content—loading subresources across\ndomains that offer different levels of trust—browsers have no way to detect\nthis. The decision to include content from dubious sources is often made too\nlightly and such mistakes can be difficult to spot until too late.\nNOTE Another interesting problem with cross-domain subresources is that they may request\ncertain additional permissions or credentials from the browser. The associated browser\nsecurity prompts are usually not designed with such scenarios with mind, and they do\nnot always make sufficiently clear which origin is requesting the permission and based\non what sort of relationship with the top-level site. We discussed one such problem in\nChapter 3: the authentication prompt shown in response to HTTP code 401. Several\nother, related cases will appear in Chapter 15.\nLife Outside Same-Origin Rules 183"
  },
  {
    "input": "Privacy-Related Side Channels",
    "output": "Privacy-Related Side Channels\nAnother unfortunate and noteworthy consequence of the gaps in the same-\norigin policy is the ability to collect information about a user’s interaction\nwith unrelated sites. Some of the most rudimentary examples, most of them\nknown for well over a decade,13 include the following:\n Using onload handlers to measure the time it takes to load certain docu-\nments, an indication of whether they have been previously visited and\ncached by the browser or not.14\n Using onload and onerror on <img> tags to see if an authentication-requir-\ning image on a third-party site can be loaded, thus disclosing whether\nthe user is logged into that site or not. (Bonus: Sometimes, the error\nmessage disclosed to the onerror handler will include snippets of the tar-\ngeted page, too.)\n Loading an unrelated web application in a hidden frame and examining\nproperties such as the number and names of subframes created on that\npage (available through the <handle>.frames[] array) or the set of global\nvariables (sometimes leaked through the semantics of the delete opera-\ntor) in order to detect the same. Naturally, the set of sites the user visits\nor is logged into can be fairly sensitive.\nIn addition to these tricks, a particularly frightening class of privacy prob-\nlems is associated with two APIs created several years ago to help websites under-\nstand the style applied to any document element (the sum of browser-specific\ndefaults, CSS rules, and any runtime tweaks made automatically by the browser\nor performed via JavaScript). The two APIs in question are getComputedStyle,\nmandated by CSS Level 2,15 and currentStyle, proprietary to Internet Explorer.16\nTheir functionality, together with the ability to assign distinctive styling to\nvisited links (using the :visited pseudo-class), means that any rogue JavaScript\ncan rapidly display and examine thousands of URLs to see which ones are\nshaded differently (due to being present in a user’s browsing history), thereby\nbuilding a reliable, extensive, and possibly incriminating overview of a user’s\nonline habits with unprecedented efficiency and reliability.\nThis problem has been known since at least since 2002, when Andrew\nClover posted a brief note about it to the popular BUGTRAQ mailing list.17\nThe issue received little scrutiny in the following years, until a series of\nlayperson-targeted demonstrations and a subsequent public outcry around\n2006. A few years later, Firefox and WebKit browsers rolled out security\nimprovements to limit the extent of styling possible in :visited selectors\nandtolimit the ability to inspect the resulting composite CSS data.\nThat said, such fixes will never be perfect. Even though they make\nautomated data collection impossible, smaller quantities of data can be\nobtained with a user’s help. Case in point: Collin Jackson and several other\nresearchers proposed a simple scheme that involved presenting a faux\n184 Chapter 11"
  },
  {
    "input": "Other SOP Loopholes and Their Uses",
    "output": "CAPTCHA* consisting of seven-segment, LCD-like digits.18 Rather than being\nan actual, working challenge, the number the user would see depended on\nthe :visited-based styling applied to superimposed links (see Figure 11-5); by\ntyping that number back onto the page, the user would unwittingly tell the\nauthor of the site what exact styling had been applied and, therefore, what\nsites appeared in the victim’s browsing history.\nVertical pipe character (|) linked\nto www.fuzzybunnies.com\n(white if visited)\nSegment linked to\nwww.bunnyoutlet.com\n(white if visited)\nFigure 11-5: A fake seven-segment display can be used to read\nback link styling when the displayed number is entered into the\nbrowser in an attempt to solve a CAPTCHA. The user will see\n5, 6, 9, or 8, depending on prior browsing history.\nOther SOP Loopholes and Their Uses\nAlthough this chapter has focused on areas where the limitations of the\nsame-origin policy have a clear, negative impact on the security or privacy of\nonline browsing, there are several accidental gaps in the scheme that in most\ncases seem to be of no special consequence. For example, in many versions\nof Internet Explorer, it was possible to manipulate the value of window.opener\nor window.name of an unrelated window. Meanwhile in Firefox, there are cur-\nrently no constraints on setting location.hash across domains, even though all\nother partial location properties are restricted.\nThe primary significance of these mechanisms is that they are often\nrepurposed to build cross-domain communication channels in browsers that\ndo not support the postMessage(...) API. Such mechanisms are often built on\nshaky ground: The lack of SOP enforcement is typically uniform and means\nthat any website, not just the “authorized” parties, will be able to interfere with\nthe data. The ability for rogue parties to navigate nested frames, as discussed\nin “Frame Hijacking Risks” on page175, further complicates the picture.\n* CAPTCHA (sometimes expanded as Completely Automated Public Turing test to tell Com-\nputers and Humans Apart) is a term for a security challenge that is believed to be difficult to\nsolve using computer algorithms but that should be easy for a human being. It is usually imple-\nmented by showing an image of several randomly selected, heavily distorted characters and ask-\ning the user to type them back. CAPTCHA may be used to discourage the automation of certain\ntasks, such as opening new accounts or sending significant volumes of email. (Needless to say,\ndue to advances in computer image processing, robust CAPTCHAs are increasingly difficult for\nhumans to solve, too.)\nLife Outside Same-Origin Rules 185"
  },
  {
    "input": "When Arranging Cross-Domain Communications in JavaScript",
    "output": "Security Engineering Cheat Sheet\nGood Security Hygiene for All Websites\n Serve all content for your site with X-Frame-Options: sameorigin. Make case-by-case excep-\ntions only for specific, well-understood locations that require cross-domain embedding.\nTry not to depend on JavaScript “framebusting” code to prevent framing because it’s very\ntricky to get that code right.\n Return user-specific, sensitive data that is not meant to be loaded across domains using\nwell-constrained formats that are unlikely to be misinterpreted as standalone scripts,\nstylesheets, and so on. Always use the right Content-Type.\nWhen Including Cross-Domain Resources\n In many scenarios (especially when dealing with scripts, stylesheets, fonts, and certain\ntypes of plug-in-handled content), you are linking the security of your site to the originat-\ning domain of the subresource. When in doubt, make a local copy of the data instead. On\nHTTPS sites, require all subresources to be served over HTTPS.\nWhen Arranging Cross-Domain Communications in JavaScript\n Consult the cheat sheet in Chapter 9. Do not use cross-frame communication schemes\nbased on location.hash, window.name, frameElements, and similar ephemeral hacks, unless\nyou are prepared to deal with injected content.\n Do not expect subframes on your page to sit still, especially if you are not using X-Frame-\nOptions to limit the ability of other sites to frame your application. In certain cases, an\nattacker may be able to navigate such frames to a different location without your knowl-\nedge or consent.\n186 Chapter 11"
  },
  {
    "input": "12: Other Security Boundaries\r",
    "output": "O T H E R S E C U R I T Y\nB O U N D A R I E S\nAll previously described origin-level content-isolation\npolicies, and the accompanying context inheritance\nand document navigation logic, work hand in hand to\nform the bulk of the browser security model. Impene-\ntrable and fragile, that model is also incomplete: A\nhandful of interesting corner cases completely escape\nany origin-based frameworks.\nThe security risks associated with these corner cases can’t be addressed\nsimply by fine-tuning the mechanisms discussed earlier in this book. Instead,\nadditional, sometimes hopelessly imperfect security boundaries need to be\ncreated from scratch. These new boundaries may, for example, further\nrestrict the ability of rogue web pages to navigate to certain URLs.\nThis chapter offers a quick look at some of the most significant examples\nof the loopholes in the origin-based model and the ways that vendors have\ndealt with them."
  },
  {
    "input": "Navigation to Sensitive Schemes",
    "output": "Navigation to Sensitive Schemes\nIn the past, browser vendors reasoned that there was no harm in allowing\nanypage on the Internet to navigate to a document stored on a user’s hard\ndrive using the file: protocol or to open a new window pointing to a privi-\nleged resource, such as the about:config page in Firefox. After all, they thought,\nthe originating document and the destination would not be same-origin,\nand, therefore, any direct access to the sensitive data would be prevented.\nFor many years, based on this rationale, browsers permitted such naviga-\ntion to take place. Alas, this decision proved to be not only extremely confus-\ning* but also dangerous. The danger comes from the fact that many programs,\nbrowsers included, tend to store various types of Internet-originating content\nin the filesystem; temporary files and cached documents are a common exam-\nple. In many cases, an attacker could have some control over the creation\nand contents of such files, and, if the resources are created at a predictable\nlocation, subsequent navigation to the right file: URL could allow the attacker\nto execute his own payload in this coveted origin, with access to any other\nfileon the disk and, perhaps, any other website on the Internet.\nComparably disastrous consequences have been observed with a variety\nof privileged, internally handled URLs. The ability to navigate directly to\nlocations such as about:config (Firefox) not only made it possible to exploit\npotential vulnerabilities in the privileged scripts (a transgression to which\nbrowser vendors are not immune) but also led to system compromise if,\nthrough a literal application of the same-origin policy, the browser naïvely\ndeemed about:config and about:blank to come from the same origin.\nHaving learned from a history of painful mishaps, modern browsers typi-\ncally police navigation based on three tiers of URL schemes:\n Unrestricted This category includes virtually all true network protocols,\nsuch as HTTP, HTTPS, FTP; most encapsulating pseudo-protocols such\nas mhtml: or jar:; and all schemes registered to plug-ins and external appli-\ncations. Navigation to these URLs is not constrained in any specific way.\n Partly restricted This category includes several security-sensitive schemes\nsuch as file: and special pseudo-URLs such as javascript: or vbscript:. Navi-\ngation to them is not completely denied, but it is subject to additional,\nscheme-specific security checks. For example, access to file: is usually\npermitted only from other file: documents, requiring the first one to be\nopened manually. (The rules for navigation to javascript: URLs were dis-\ncussed in Chapter 10.)\n Fully restricted This category includes privileged pages in about:, res:,\nchrome:, and similar browser-specific namespaces. Normal, unprivileged\nHTML documents are not permitted to navigate to them under any\ncircumstance.\n* For example, on Windows systems, a common prank was to use a seamlessly embedded <iframe>\npointing to file:///c:/ in order to display the contents of a victim’s hard drive, leading some users\nto believe that the page doing so has somehow gained access to their files.\n188 Chapter 12"
  },
  {
    "input": "Access to Internal Networks",
    "output": "Access to Internal Networks\nThe trouble with accessing sensitive protocols is merely a prelude to a far\nmore serious issue that somehow escaped the creators of the same-origin\npolicy. The problem is that DNS-derived origins may have nothing to do with\nactual network-level boundaries—or with how these boundaries change over\ntime. A malicious script may be granted same-origin access to intranet sites\non the victim’s local network, even if a firewall prevents the attacker from\ninteracting with these destinations directly.\nThere are at least three distinctive venues for such attacks.\nOrigin Infiltration\nWhen a user visits a rogue network—such as an open wireless network at\nan airport or in a café—an attacker on that network may trick the victim’s\nbrowser into opening a URL such as http://us-payroll/. When this happens,\nthe attacker may provide his own, spoofed content for that site. Frighten-\ningly, if the user then brings the same browser to a corporate network,\nthe previously injected content will have same-origin access to the real\nversion of http://us-payroll/, complete with the user’s ambient credentials.\nThe persistence of injected content may be achieved in a couple of\nways. The most basic method is for an attacker simply to inject a hidden\nhttp://us-payroll/ frame onto every visited page in the hope that the user\nwill suspend a portable computer with the browser still running and then\ntake it to another network. Another technique is cache poisoning: creating\nlong-lived, cached objects that the browser will use instead of retrieving\nafresh copy from the destination site. Several other, more obscure\napproaches also exist.\nDNS Rebinding\nThis arguably less serious but more easily exploitable problem was men-\ntioned in footnote 1 in Chapter 9. In short, since the same-origin policy\nlooks just at the DNS name of a host, not at the IP address, an attacker\nwho owns bunnyoutlet.com is free to respond initially to a DNS lookup\nfrom a user with a public IP such as 213.134.128.25 and then switch to\nanaddress reserved for private networks, such as 10.0.0.1. Documents\nloaded from both sources will be considered same-origin, giving the\nattacker the ability to interact with the victim’s internal network.\nThe mitigating factor is that this interaction will not involve proper\nambient credentials that the victim normally has for the targeted site: As\nfar as the browser is concerned, it is still talking to bunnyoutlet.com and not\nto, say, the aforementioned us-payroll site. Still, the prospect of the attacker\nexamining the internal network and perhaps trying to brute-force the\nappropriate credentials or identify vulnerabilities is disconcerting.\nOther Security Boundaries 189"
  },
  {
    "input": "Prohibited Ports",
    "output": "Simple Exploitation of XSS or XSRF Flaws\nEven outside the realm of the same-origin policy, the mere possibility\nofnavigating to intranet URLs means that the attacker may attempt to\n(blindly) target known or suspected vulnerabilities in locally running\nsoftware. Because internal applications are thought to be protected from\nmalicious users, they are often not engineered or maintained to the\nsame standards as externally facing code.\nOne striking example of this problem is the dozens of vulnerabilities\ndiscovered over the years in internal-only web management interfaces\nofhome network routers manufactured by companies such as Linksys\n(Cisco), Netgear, D-Link, Motorola, and Siemens. Cross-site request forg-\nery vulnerabilities in these applications can, in extreme cases, permit\nattackers to access the device and intercept or modify all network traffic\ngoing to or through it.\nSo far, the disconnect between browser security mechanisms and net-\nwork segmentation remains an unsolved problem in browser engineering.\nSeveral browsers try to limit the impact of DNS rebinding by caching DNS\nresponses for a predefined time—a practice known as DNS pinning—but the\ndefense is imperfect, and the remaining attack vectors still remain.\nNOTE Unusually, Internet Explorer takes the lead on this front, offering an optional way to\nmitigate the risk. Microsoft’s users are protected to some extent if they flip a cryptic zone\nsetting named “websites in less privileged web content zone can navigate into this zone”\nto “disable” in the configuration options for local intranet. Unfortunately, the zone\nmodel in Internet Explorer comes with some unexpected pitfalls, as we’ll discuss in\nChapter 15.\nProhibited Ports\nSecurity researchers have cautioned that the ability of browsers to sub-\nmitlargely unconstrained cross-origin request bodies, for example with\n<form method=\"POST\" enctype=\"text/plain\">, may interfere with certain other\nfault-tolerant but non-HTTP network services. For example, consider SMTP,\nthe dominant mail transfer protocol: When interacting with an unsuspect-\ning browser, most servers that speak SMTP will patiently ignore the first few\nincomprehensible lines associated with HTTP headers and then honor any\nSMTP commands that appear in the request body. In effect, the browser\ncould be used as a proxy for relaying spam.\nA related but less well-explored concern, discussed in Chapter 3, is the\nrisk of an attacker talking to non-HTTP services running in the same domain\nas the targeted web application and tricking the browser into misinterpreting\nthe returned, possibly partly attacker-controlled data as HTML delivered over\nHTTP/0.9. This behavior could expose cookies or other credentials associ-\nated with the targeted site.\nThe design of HTTP makes it impossible to solve these problems in\naparticularly robust way. Instead, browser vendors have responded in a\nrather unconvincing manner: by shipping a list of prohibited TCP ports\n190 Chapter 12\ntowhich requests cannot be sent. For Internet Explorer versions 6 and 7,\nthelist consists of the following port numbers:\n19 chargen\n21 ftp\n25 smtp\n110 pop3\n119 nntp\n143 imap2\nVersions 8 and 9 of Internet Explorer further prohibit ports 220 (imap3)\nand 993 (ssl imap3).\nAll other browsers discussed in this book use a different, common list:\n1 tcpmux 115 sftp\n7 echo 117 uccp-path\n9 discard 119 nntp\n11 systat 123 ntp\n13 daytime 135 loc-srv\n15 netstat 139 netbios\n17 qotd 143 imap2\n19 chargen 179 bgp\n20 ftp-data 389 ldap\n21 ftp 465 ssl smtp\n22 ssh 512 exec\n23 telnet 513 login\n25 smtp 514 shell\n37 time 515 printer\n42 name 526 tempo\n43 nicname 530 courier\n53 domain 531 chat\n77 priv-rjs 532 netnews\n79 finger 540 uucp\n87 ttylink 556 remotefs\n95 supdup 563 ssl nntp\n101 hostriame 587 smtp submission\n102 iso-tsap 601 syslog\n103 gppitnp 636 ssl ldap\n104 acr-nema 993 ssl imap\n109 pop2 995 ssl pop3\n110 pop3 2049 nfs\n111 sunrpc 4045 lockd\n113 auth 6000 X11\nOther Security Boundaries 191"
  },
  {
    "input": "Limitations on Third-Party Cookies",
    "output": "There are, of course, various protocol-specific exceptions to these rules.\nFor example, ftp: URLs are obviously permitted to access port 21, normally\nassociated with that protocol.\nThe current solution is flawed in several ways, the most important of\nwhich may be that both lists have numerous glaring omissions and, given the\nnumber of network protocols devised to date, simply have no chance of ever\nbeing exhaustive. For example, no rule would prevent the browser from talk-\ning to Internet Relay Chat (IRC) servers, which use a fault-tolerant, text-based\nprotocol not entirely unlike SMTP.\nThe lists are also not regularly updated to reflect the demise of nearly\nextinct network protocols or the introduction of new ones. Lastly, they can\nunfairly and unexpectedly penalize system administrators for picking non-\nstandard ports for certain services they want to hide from public view: Doing\nso means opting out of this browser-level protection mechanism.\nLimitations on Third-Party Cookies\nSince their inception, HTTP cookies have been misunderstood as the tool\nthat enabled online advertisers to violate users’ privacy to an unprecedented\nand previously unattainable extent. This sentiment has been echoed by the\nmainstream press in the years since. For example, in 2001, the New York Times\npublished a lengthy exposé on the allegedly unique risks of HTTP cookies and\neven quoted Lawrence Lessig, a noted legal expert and a political activist:1\nBefore cookies, the Web was essentially private. After cookies, the\nWeb becomes a space capable of extraordinary monitoring.\nThe high-profile assault on a single HTTP header continued over the\ncourse of a decade, gradually shifting its focus toward third-party cookies in\nparticular. Third-party cookies are the cookies set by domains other than the\ndomain of the top-level document, and they are usually associated with the\nprocess of loading images, frames, or applets from third-party sites. The rea-\nson they have attracted attention is that operators of advertising networks\nhave embraced such cookies as a convenient way to tag a user who sees their\nad embedded on fuzzybunnies.com and then recognize that user through a\nsimilar embedded ad served on playboy.com.\nBecause the clearly undesirable possibility of performing this type of\ncross-domain tracking has been erroneously conflated with the existence of\nthird-party cookies, the pressure on browser vendors has continued to mount.\nIn one instance, the Wall Street Journal flat out accused Microsoft of being in\nbed with advertisers for not eliminating third-party cookies in the company’s\nproduct.2\nNaturally, the readers of this book will recognize that the fixation on\nHTTP cookies is deeply misguided. There is no doubt that some parties use\nthe mechanism for vaguely sinister purposes, but nothing makes it uniquely\nsuited for this task; there are many other equivalent ways to store unique iden-\ntifiers on visitors’ computers (such as cache-based tags, previously discussed\nin Chapter 3). Besides, it is simply impossible to prevent cooperating sites\n192 Chapter 12\nfrom using existing unique fingerprints of every browser (exposed through\nthe JavaScript object model or plug-ins such as Flash) to correlate and mine\ncross-domain browsing patterns at will. The sites that embed advertisements\nfor profit are quite willing to cooperate with the parties who pay their bills.\nIn fact, the common reliance on HTTP cookies offers a distinctive\nadvantage to users: Unlike many of the easily embraced alternatives, this\nmechanism is purpose built and coupled with reasonably well-designed and\nfine-grained privacy controls. Breaking cookies will not hinder tracking but\nwill remove any pretense of transparency from the end user. Another noted\nprivacy and security activist, Ed Felten, once said: “If you’re going to track\nme, please use cookies.”3\nUnscrupulous online tracking is a significant social issue, and new tech-\nnical mechanisms may be needed so that users can communicate their privacy\npreferences to well-behaved sites (such as the recently added DNT request\nheader4 rolled out in Firefox 4). In order to deal with the ill-behaved ones,\naregulatory framework may be required, too. In the absence of such a frame-\nwork, in Internet Explorer 9, Microsoft is experimenting with a managed\nblacklist of known bad sources of tracking cookies—but the odds that this\nwould discourage sleazy business practices are slim.\nIn any case, despite having little or no merit, the continued public outcry\nagainst third-party cookies eventually resulted in several browser vendors\nshipping half-baked and easily circumvented solutions that let them claim\nthey had done something.\n In Internet Explorer, setting and reading third-party cookies is blocked\nby default, except for session cookies accompanied by a satisfactory P3P\nheader. P3P (Platform for Privacy Preferences)5 is a method to construct\nmachine-readable, legally binding summaries of a site’s privacy policy, be\nit as an XML file or as a compact policy in an HTTP header. For example,\nthe keyword TEL in an HTTP header means that the site uses the col-\nlected information for telemarketing purposes. (No technical measure\nwill prevent a site from lying in a P3P header, but the potential legal\nconsequences are meant to discourage that.)\nNOTE The incredibly ambitious, 111-page P3P specification caused the solution\nto crumble under its own weight. Large businesses are usually very hesi-\ntant to embrace P3P as a solution to technical problems because of the\nlegal footprint of the spec, while small businesses and individual site\nowners copy over P3P header recipes with little or no understanding of\nwhat they are supposed to convey.\n In Safari, the task of setting third-party cookies is blocked by default,\nbutpreviously issued cookies can be read freely. However, this behavior\ncan be overridden if the user interacts with the cookie-setting document\nfirst. Such an interaction could be intentional but may very well not be:\nThe clickjacking-related tricks outlined in Chapter 11 apply to this sce-\nnario as well.\nOther Security Boundaries 193\n In other browsers, third-party cookies are permitted by default, but a\nconfiguration option is provided to change the behavior. Enabling this\noption limits the ability to set third-party cookies, but reading existing\nones is not limited in any way.\nFor the purpose of these checks, a cookie is considered to be coming from\na third party if it’s loaded from a completely unrelated domain. For example, a\nframe pointing to bunnyoutlet.com loaded on fuzzybunnies.com meets this crite-\nrion, but www1.fuzzybunnies.com and www2.fuzzybunnies.com are considered to\nbe in a first-party relationship. The logic used to make this determination is\nfragile, and it suffers from the same problems that cookie domain scoping\nwould. In Internet Explorer 6 and 7, for example, the comparisons in certain\ncountry-level domains are performed incorrectly.\nNOTE The crusade against third-party cookies could be seen as a harmless exercise, but it has\nhad negative consequences, too. Browsers that reject third-party cookies make it very dif-\nficult to build cookie-based authentication for embeddable gadgets and other types of\nmashups, and they make it difficult to use “sandbox” domains to isolate untrusted but\nprivate content from the main application to limit the impact of script-injection flaws.\n194 Chapter 12"
  },
  {
    "input": "When Using Third-Party Cookies for Gadgets or Sandboxed Content",
    "output": "Security Engineering Cheat Sheet\nWhen Building Web Applications on Internal Networks\n Assume that determined attackers will be able to interact with those applications through\na victim’s browser, regardless of any network-level security controls. Ensure that proper\nengineering standards are met and require HTTPS with secure cookies for all sensitive\napplications in order to minimize the risk of origin infiltration attacks.\nWhen Launching Non-HTTP Services, Particularly on Nonstandard Ports\n Evaluate the impact of browsers unintentionally issuing HTTP requests to the service\nandthe impact of having the response interpreted as HTTP/0.9. For vulnerable proto-\ncols, consider dropping the connection immediately if the received data begins with\n“GET” or “POST” as one possible precaution.\nWhen Using Third-Party Cookies for Gadgets or Sandboxed Content\n If you need to support Internet Explorer, be prepared to use P3P policies (and evaluate\ntheir legal significance). If you need to support Safari, you may have to resort to an alter-\nnative credential storage mechanism (such as HTML5 localStorage).\nOther Security Boundaries 195"
  },
  {
    "input": "13: Content Recognition Mechanisms\r",
    "output": "C O N T E N T R E C O G N I T I O N\nM E C H A N I S M S\nSo far, we have looked at a fair number of well-\nintentioned browser features that, as the technology\nmatured, proved to be short-sighted and outright dan-\ngerous. But now, brace for something special: In the\nhistory of the Web, nothing has proven to be as mis-\nguided as content sniffing.\nThe original premise behind content sniffing was simple: Browser vendors\nassumed that in some cases, it would be appropriate—even desirable—to\nignore the normally authoritative metadata received from the server, such as\nthe Content-Type header. Instead of honoring the developer’s declared intent,\nimplementations that support content sniffing may attempt to second-guess\nthe appropriate course of action by applying proprietary heuristics to the\nreturned payload in order to compensate for possible mistakes. (Recall from\nChapter 1 that during the First Browser Wars, vendors turned fault-tolerance\ncompatibility into an ill-conceived competitive advantage.)"
  },
  {
    "input": "Document Type Detection Logic",
    "output": "It didn’t take long for content-sniffing features to emerge as a substantial\nand detrimental aspect of the overall browser security landscape. To their\nhorror and disbelief, web developers soon noticed that they couldn’t safely\nhost certain nominally harmless document types like text/plain or text/csv on\nbehalf of their users; any attempt to do so would inevitably create a risk that\nsuch content could be misinterpreted as HTML.\nPerhaps partly in response to these concerns, in 1999 the practice of\nunsolicited content sniffing was explicitly forbidden in HTTP/1.1:\nIf and only if the media type is not given by a Content-Type field, the\nrecipient may attempt to guess the media type via inspection of its\ncontent and/or the name extension(s) of the URI used to identify\nthe resource.\nAlas, this uncharacteristically clear requirement arrived a bit too late. Most\nbrowsers were already violating this rule to some extent, and absent a con-\nvenient way to gauge the potential consequences, their authors hesitated to\nsimply ditch the offending code. Although several of the most egregious mis-\ntakes were cautiously reverted in the past decade, two companies—Microsoft\nand Apple—largely resisted the effort. They decided that interoperability with\nbroken web applications should trump the obvious security problems. To\npacify any detractors, they implemented a couple of imperfect, secondary\nsecurity mechanisms intended to mitigate the risk.\nToday, the patchwork of content-handling policies and the subsequently\ndeployed restrictions cast a long shadow on the online world, making it nearly\nimpossible to build certain types of web services without resorting to contrived\nand sometimes expensive tricks. To understand these limitations, let’s begin\nby outlining several scenarios where a nominally passive document may be\nmisidentified as HTML or something like it.\nDocument Type Detection Logic\nThe simplest and the least controversial type of document detection heuris-\ntics, and the one implemented by all modern browsers, is the logic imple-\nmented to handle the absence of the Content-Type header. This situation,\nwhich is encountered very rarely, may be caused by the developer acciden-\ntally omitting or mistyping the header name or the document being loaded\nover a non-HTTP transport mechanism such as ftp: or file:.\nFor HTTP specifically, the original RFCs explicitly permit the browser\ntoexamine the payload for clues when the Content-Type value is not available.\nFor other protocols, the same approach is usually followed, often as a natural\nconsequence of the design of the underlying code.\nThe heuristics employed to determine the type of a document typically\namount to checking for static signatures associated with several dozen known\nfile formats (such as images and common plug-in-handled files). The response\nwill also be scanned for known substrings in order to detect signatureless for-\nmats such as HTML (in which case, the browser will look for familiar tags—\n<body>, <font>, etc). In many browsers, noncontent signals, such as trailing .html\nor .swf strings in the path segment of the URL, are taken into account aswell.\n198 Chapter 13"
  },
  {
    "input": "Malformed MIME Types",
    "output": "The specifics of content-sniffing logic vary wildly from one browser to\nanother and are not well documented or standardized. To illustrate, consider\nthe handling of Adobe Flash (SWF) files served without Content-Type: In Opera,\nthey are recognized unconditionally based on a content signature check; in\nFirefox and Safari, an explicit .swf suffix in the URL is required; and Internet\nExplorer and Chrome will not autorecognize SWF at all.\nRest assured, the SWF file format is not an exceptional case. For example,\nwhen dealing with HTML files, Chrome and Firefox will autodetect the docu-\nment only if one of several predefined HTML tags appears at the very begin-\nning of the file; while Firefox will be eager to “detect” HTML based solely on\nthe presence of an .html extension in the URL, even if no recognizable markup\nis seen. Internet Explorer, on the other hand, will simply always default to\nHTML in the absence of Content-Type, and Opera will scan for known HTML\ntags within the first 1000 bytes of the returned payload.\nThe assumption behind all this madness is that the absence of Content-\nType is an expression of an intentional wish by the publisher of the page—\nbut that assumption is not always accurate and has caused a fair number of\nsecurity bugs. That said, most web servers actively enforce the presence of a\nContent-Type header and will insert a default value if one is not explicitly gen-\nerated by the server-side scripts that handle user requests. So perhaps there is\nno need to worry? Well, unfortunately, this is not where the story of content\nsniffing ends.\nMalformed MIME Types\nThe HTTP RFC permits content sniffing only in the absence of Content-Type\ndata; the browser is openly prohibited from second-guessing the intent of the\nwebmaster if the header is present in any shape or form. In practice, however,\nthis advice is not taken seriously. The next small step taken off the cliff was\nthe decision to engage heuristics if the server-returned MIME type was\ndeemed invalid in any way.\nAccording to the RFC, the Content-Type header should consist of two\nslash-delimited alphanumeric tokens (type/subtype), potentially followed by\nother semicolon-delimited parameters. These tokens may contain any non-\nwhitespace, seven-bit ASCII characters other than a couple of special “sepa-\nrators” (a generic set that includes characters such as “@”, “?”, and the slash\nitself). Most browsers attempt to enforce this syntax but do so inconsistently;\nthe absence of a slash is seen almost universally as an invitation to content\nsniffing, and so is the inclusion of whitespaces and certain (but not all) con-\ntrol characters in the first portion of the identifier (the type token). On the\nother hand, the technically illegal use of high-bit characters or separators\naffects the validity of this field only in Opera.\nThe reasons for this design are difficult to understand, but to be fair, the\nsecurity impact is still fairly limited. As far as web application developers are con-\ncerned, care must be exercised not to make typos in Content-Type values and not\nto allow users to specify arbitrary, user-controlled MIME types (merely validated\nagainst a blacklist of known bad options). These requirements may be unex-\npected, but usually they do not matter a lot. So, what are we ultimately getting at?\nContent Recognition Mechanisms 199"
  },
  {
    "input": "Special Content-Type Values",
    "output": "Special Content-Type Values\nThe first clear signal that content sniffing was becoming truly dangerous was\nthe handling of a seemingly unremarkable MIME type known as application/\noctet-stream. This specific value is not mentioned at all in the HTTP specifica-\ntion but is given a special (if vague) role deep in the bowels of RFC 2046:1\nThe recommended action for an implementation that receives an\napplication/octet-stream entity is to simply offer to put the data in a\nfile, with any Content-Transfer-Encoding undone, or perhaps to use it\nas input to a user-specified process.\nThe original intent of this MIME type may not be crystal clear from the\nquoted passage alone, but it is commonly interpreted as a way for web servers\nto indicate that the returned file has no special meaning to the server and\nthat it should not have one to the client. Consequently, most web servers\ndefault to application/octet-stream on all types of opaque, nonweb files, such as\ndownloadable executables or archives, if no better Content-Type match can be\nfound. However, in rare cases of administrator errors (for example, due to\ndeletion of the essential AddType directives in Apache configuration files),\nweb servers may also fall back to this MIME type on documents meant for\nin-browser consumption. This configuration error is, of course, very easy to\ndetect and fix, but Microsoft, Opera, and Apple nevertheless chose to com-\npensate for it. The browsers from these vendors eagerly engage in content\nsniffing whenever application/octet-stream is seen.*\nThis particular design decision has suddenly made it more difficult for\nweb applications to host binary files on behalf of the user. For example, any\ncode-hosting platform must exercise caution when returning executables or\nsource archives as application/octet-stream, because there is a risk they may be\nmisinterpreted as HTML and displayed inline. That’s a major issue for any\nsoftware hosting or webmail system and for many other types of web apps.\n(It’s slightly safer for them to use any other generic-sounding MIME type,\nsuch as application/binary, because there is no special case for it in the\nbrowser code.)\nIn addition to the special treatment given to application/octet-stream, a\nsecond, far more damaging exception exists for text/plain. This decision,\nunique to Internet Explorer and Safari, traces back to RFC 2046. In that doc-\nument, text/plain is given a dual function: first, to transmit plaintext docu-\nments (ones that “do not provide for or allow formatting commands, font attribute\nspecifications, processing instructions, interpretation directives, or content markup”)\nand, second, to provide a fallback value for any text-based documents not\notherwise recognized by the sender.\n* In Internet Explorer, this implemented logic differs subtly from a scenario where no Content-\nType is present. Instead of always assuming HTML, the browser will scan the first 256 bytes for\npopular HTML tags and other predefined content signatures. From the security standpoint,\nhowever, it’s not a very significant difference.\n200 Chapter 13\nThe distinction between application/octet-stream and text/plain fallback\nmade perfect sense for email messages, a topic that this RFC originally dealt\nwith, but proved to be much less relevant to the Web. Nevertheless, some\nweb servers adopted text/plain as the fallback value for certain types of\nresponses (most notably, the output of CGI scripts).\nThe text/plain logic subsequently implemented in Internet Explorer and\nSafari in order to detect HTML in such a case is really bad news: It robs web\ndevelopers of the ability to safely use this MIME type to generate user-specific\nplaintext documents and offers no alternatives. This has resulted in a sub-\nstantial number of web application vulnerabilities, but to this day, Internet\nExplorer developers seem to have no regrets and have not changed the\ndefault behavior of their code.\nSafari developers, on the other hand, recognized and tried to mitigate the\nrisk while keeping the functionality in place—but they failed to appreciate\nthe complexity of the Web. The solution implemented in their browser is to\nrely on a secondary signal in addition to the presence of a plausible-looking\nHTML markup in the document body. The presence of an extension such as\n.html or .xml at the end of the URL path is interpreted by their implementa-\ntion as a sign that content sniffing can be performed safely. After all, the\nowner of the site wouldn’t name the file this way otherwise, right?\nAlas, the signal they embraced is next to worthless. As it turns out, almost\nall web frameworks support at least one of several methods for encoding param-\neters in the path segment of the URL instead of in the more traditionally\nused query part. For example, in Apache, one such mechanism is known as\nPATH_INFO, and it happens to be enabled by default. By leveraging such a\nparameter-passing scheme, the attacker can usually append nonfunctional\ngarbage to the path, thereby confusing the browser without affecting how the\nserver will respond to the submitted request itself.\nTo illustrate, the following two URLs will likely have the same effect for\nwebsites running on Apache or IIS:\nhttp://www.fuzzybunnies.com/get_file.php?id=1234\nand\nhttp://www.fuzzybunnies.com/get_file.php/evil.html?id=1234\nIn some less-common web frameworks, the following approach may\nalsowork:\nhttp://www.fuzzybunnies.com/get_file.php;evil.html?id=1234\nContent Recognition Mechanisms 201"
  },
  {
    "input": "Unrecognized Content Type",
    "output": "Unrecognized Content Type\nDespite the evident trouble with text/plain, the engineers working on Inter-\nnet Explorer decided to take their browser’s heuristics even further. Internet\nExplorer applies both content sniffing and extension matching* not only\ntoahandful of generic MIME types but also to any document type not\nimmediately recognized by the browser. This broad category may include\neverything from JSON (application/json) to multimedia formats such as Ogg\nVorbis (audio/ogg).\nSuch a design is, naturally, problematic and causes serious problems when\nhosting any user-controlled document formats other than a small list of uni-\nversally supported MIME types registered internally in the browser or when\nrouted to a handful of commonly installed external applications.\nNor do the content-sniffing habits of Internet Explorer finally end there:\nThe browser will also resort to payload inspection when dealing with internally\nrecognized document formats that, for any reason, can’t be parsed cleanly.\nIn Internet Explorer versions prior to 8, serving a user-supplied but non-\nvalidated file claiming to be an JPEG image can lead to the response being\ntreated as HTML. And it gets even more hilarious: Even a subtle mistake,\nsuch as serving a valid GIF file with Content-Type: image/jpeg, triggers the same\ncode path. Heck, several years ago, Internet Explorer even detected HTML\non any valid, properly served PNG file. Thankfully, this logic has since been\ndisabled—but the remaining quirks are still a minefield.\nNOTE In order to fully appreciate the risk of content sniffing on valid images, note that it is\nnot particularly difficult to construct images that validate correctly but that carry\nattacker-selected ASCII strings—such as HTML markup—in the raw image data. In\nfact, it is relatively easy to construct images that, when scrubbed, rescaled, and recom-\npressed using a known, deterministic algorithm, will have a nearly arbitrary string\nappear out of the blue in the resulting binary stream.\nTo its credit, in Internet Explorer 8 and beyond, Microsoft decided to\ndisallow most types of gratuitous content sniffing on known MIME types\ninthe image/* category. It also disallowed HTML detection (but not XML\ndetection) on image formats not recognized by the browser, such as image/\njp2 (JPEG2000).\nThis single tweak aside, Microsoft has proven rather unwilling to make\nmeaningful changes to its content-sniffing logic, and its engineers have pub-\nlicly defended the need to maintain compatibility with broken websites.2\nMicrosoft probably wants to avoid the wrath of large institutional customers,\nmany of whom rely on ancient and poorly designed intranet apps and depend\non the quirks of the Internet Explorer–based monoculture on the client end.\nIn any case, due to the backlash that Internet Explorer faced over its text/\nplain handling logic, newer versions offer a partial workaround: an optional\n* Naturally, path-based extension matching is essentially worthless for the reasons discussed\ninthe previous section; but in the case of Internet Explorer 6, it gets even worse. In this browser,\nthe extension can appear in the query portion of the URL. Nothing stops the attacker from simply\nappending ?foo=bar.html to the requested URL, effectively ensuring that this check is always\nsatisfied.\n202 Chapter 13"
  },
  {
    "input": "Defensive Uses of Content-Disposition",
    "output": "HTTP header, X-Content-Type-Options: nosniff, which allows website owners\ntoopt out of most of the controversial content heuristics. The use of this\nheader is highly recommended; unfortunately, the support for it has not\nbeen backported to versions 6 and 7 of the browser and has only a limited\nsupport in other browsers. In other words, it cannot be depended on as a\nsole defense against content sniffing.\nNOTE Food for thought: According to the data collected in a 2011 survey by SHODAN and\nChris John Riley,3 only about 0.6 percent of the 10,000 most popular websites on the\nInternet used this header on a site-wide level.\nDefensive Uses of Content-Disposition\nThe Content-Disposition header, mentioned several times in Part I of this\nbook,may be considered a defense against content sniffing in some use cases.\nThe function of this header is not explained satisfactorily in the HTTP/1.1\nspecification. Instead, it is documented only in RFC 2183,4 where its role is\nexplained only as it relates to mail applications:\nBodyparts can be designated “attachment” to indicate that they are\nseparate from the main body of the mail message, and that their\ndisplay should not be automatic, but contingent upon some fur-\nther action of the user. The MUA* might instead present the user\nof a bitmap terminal with an iconic representation of the attach-\nments, or, on character terminals, with a list of attachments from\nwhich the user could select for viewing or storage.\nThe HTTP RFC acknowledges the use of Content-Disposition: attachment in\nthe web domain but does not elaborate on its intended function. In practice,\nupon seeing this header during a normal document load, most browsers will\ndisplay a file download dialog, usually with three buttons: “open,” “save,” and\n“cancel.” The browser will not attempt to interpret the document any further\nunless the “open” option is selected or the document is saved to disk and\nthen opened manually. For the “save” option, an optional filename parameter\nincluded in the header is used to suggest the name of the download, too. If\nthis field is absent, the filename will be derived from the notoriously unreli-\nable URL path data.\nBecause the header prevents most browsers from immediately inter-\npreting and displaying the returned payload, it is particularly well suited for\nsafely hosting opaque, downloadable files such as the aforementioned case of\narchives or executables. Furthermore, because it is ignored on type-specific\nsubresource loads (such as <img> or <script>), it may also be employed to pro-\ntect user-controlled JSON responses, images, and so on against content sniff-\ning risks. (The reason why all implementations ignore Content-Disposition for\nthese types of navigation is not particularly clear, but given the benefits, it’s\nbest not to question the logic now.)\n* MUA stands for “mail user agent,” that is, a client application used to retrieve, display, and\ncompose mail messages.\nContent Recognition Mechanisms 203"
  },
  {
    "input": "Content Directives on Subresources",
    "output": "One example of a reasonably robust use of Content-Disposition and other\nHTTP headers to discourage content sniffing on a JSON response may be\nContent-Type: application/json; charset=utf-8\nX-Content-Type-Options: nosniff\nContent-Disposition: attachment; filename=\"json_response.txt\"\n{ \"search_term\": \"<html><script>alert('Hi mom!')</script>\", ... }\nThe defensive use of Content-Disposition is highly recommended where\npossible, but it is important to recognize that the mechanism is neither man-\ndated for all user agents nor well documented. In less popular browsers, such\nas Safari Mobile, the header may have no effect; in mainstream browsers,\nsuch as Internet Explorer 6, Opera, and Safari, a series of Content-Disposition\nbugs have at one point or another rendered the header ineffective in\nattacker-controlled cases.\nAnother problem with the reliance on Content-Disposition is that the user\nmay still be inclined to click “open.” Casual users can’t be expected to be wary\nof viewing Flash applets or HTML documents just because a download prompt\ngets in the way. In most browsers, selecting “open” puts the document in a\nfile: origin, which may be problematic on its own (the recent improvements\nin Chrome certainly help), and in Opera, the document will be displayed in\nthe context of the originating domain. Arguably, Internet Explorer makes the\nbest choice: HTML documents are placed in a special sandbox using a mark-\nof-the-web mechanism (outlined in more detail in Chapter 15), but even in\nthat browser, Java or Flash applets will not benefit from this feature.\nContent Directives on Subresources\nMost content-related HTTP headers, such as Content-Type, Content-Disposition,\nand X-Content-Type-Options, have largely no effect on type-specific subresource\nloads, such as <img>, <script>, or <embed>. In these cases, the embedding party\nhas nearly complete control over how the response will be interpreted by the\nbrowser.\nContent-Type and Content-Disposition may also not be given much attention\nwhen handling requests initiated from within plug-in-executed code. For\nexample, recall from Chapter 9 that any text/plain or text/csv documents may\nbe interpreted by Adobe Flash as security-sensitive crossdomain.xml policies\nunless an appropriate site-wide metapolicy is present in the root directory on\nthe destination server. Whether you wish to call it “content sniffing” or just\n“content-type blindness,” the problem is still very real.\nConsequently, even when all previously discussed HTTP headers are\nused religiously, it is important to always consider the possibility that a third-\nparty page may trick the browser into interpreting that page as one of several\nproblematic document types; applets and applet-related content, PDFs, style-\nsheets, and scripts are usually of particular concern. To minimize the risk of\nmishaps, you should carefully constrain the structure and character set of any\nserved payloads or use “sandbox” domains to isolate any document types that\ncan’t be constrained particularly well.\n204 Chapter 13"
  },
  {
    "input": "Downloaded Files and Other Non-HTTP Content",
    "output": "Downloaded Files and Other Non-HTTP Content\nThe behavior of HTTP headers such as Content-Type, Content-Disposition, and\nX-Content-Type-Options may be convoluted and exception ridden, but at the\nvery least, they add up to a reasonably consistent whole. Still, it is easy to for-\nget that in many real-world cases, the metadata contained in these headers is\nsimply not available—and in that case, all bets are off. For example, the han-\ndling of documents retrieved over ftp:, or saved to disk and opened over the\nfile: protocol, is highly browser- and protocol-specific and often surprises\neven the most seasoned security experts.\nWhen opening local files, browsers usually give precedence to file extension\ndata, and if the extension is one of the hardcoded values known to the browser,\nsuch as .txt or .html, most browsers will take this information at face value. Chrome\nis the exception; it will attempt to autodetect certain “passive” document types,\nsuch as JPEG, even inside .txt documents. (HTML, however, is strictly off-limits.)\nWhen it comes to other extensions registered to external programs, the\nbehavior is a bit less predictable. Internet Explorer will usually invoke the\nexternal application, but most other browsers will resort to content sniffing,\nbehaving as though they loaded the document over HTTP with no Content-\nType set. All browsers will also fall back to content sniffing if the extension is\nnot known (say, .foo).\nThe heavy reliance on file extension data and content sniffing for file:\ndocuments creates an interesting contrast with the normal handling of\nInternet-originating resources. On the Web, Content-Type is by and large the\nauthoritative descriptor of document type. File extension information is\nignored most of the time, and it is perfectly legal to host a functional JPEG\nfile at a location such as http://fuzzybunnies.com/gotcha.txt. But what happens\nwhen this document is downloaded to disk? Well, in such case, the effective\nmeaning of the resource will unexpectedly change: When accessing it over\nthe file: protocol, the browser may insist on rendering it as a text file, based\nstrictly on the extension data.\nThe example above is\nfairly harmless, but other con-\ntent promotion vectors, such\nas an image becoming an exe-\ncutable, may be more trou-\nbling. To that effect, Opera\nand Internet Explorer will\nattempt to modify the exten-\nFigure 13-1: Prompt displayed by Firefox when\nsion to match the MIME type\nsaving a Content-Type: image/jpeg document\nfor a handful of known Content-\nserved with Content-Disposition: attachment. The\nType values. Other browsers\n“hello.exe” filename is derived by the browser from\ndo not offer this degree of\na nonfunctional PATH_INFO suffix appended by the\nprotection, however, and may attacker at the end of the URL. The prompt incorrectly\neven be thoroughly confused claims that the .exe file is a “JPEG Image.” In fact,\nby the situation they find when saved to disk, it will be an executable.\nthemselves in. Figure 13-1\ncaptures Firefox in one such\nembarrassing moment.\nContent Recognition Mechanisms 205"
  },
  {
    "input": "Character Set Handling",
    "output": "This problem underscores the importance of returning an explicit,\nharmless filename value whenever using a Content-Disposition attachment, to\nprevent the victim from being tricked into downloading a document format\nthat the site owner never intended to host.\nGiven the complex logic used for file: URLs, the simplicity of ftp: handling\nmay come as a shock. When accessing documents over FTP, most browsers\npay no special attention to file extensions and will simply indulge in rampant\ncontent sniffing. One exception is Opera, where extension data still takes\nprecedence. From the engineering point of view, the prevalent approach to\nFTP may seem logical: The protocol can be considered roughly equivalent to\nHTTP/0.9. Nevertheless, the design also violates the principle of least aston-\nishment. Server owners would not expect that by allowing users to upload .txt\ndocuments to an FTP site, they are automatically consenting to host active\nHTML content within their domain.\nCharacter Set Handling\nDocument type detection is one of the more important pieces of the content-\nprocessing puzzle, but it is certainly not the only one. For all types of text-based\nfiles rendered in the browser, one more determination needs to be made: The\nappropriate character set transformation must be identified and applied to the\ninput stream. The output encoding sought by the browser is typically UTF-8\nor UTF-16; the input, on the other hand, is up to the author of the page.\nIn the simplest scenario, the appropriate encoding method will be pro-\nvided by the server in a charset parameter of the Content-Type header. In the case\nof HTML documents, the same information may also be conveyed to some\nextent through the <meta> directive. (The browser will attempt to speculatively\nextract and interpret this directive before actually parsing the document.)\nUnfortunately, the dangerous qualities of certain character encodings,\naswell as the actions taken by the browser when the charset parameter is not\npresent or is not recognized, once again make life a lot more interesting\nthan the aforementioned simple rule would imply. To understand what can\ngo wrong, we first need to recognize three special classes of character sets\nthat may alter the semantics of HTML or XML documents:\n Character sets that permit noncanonical representations of standard\n7-bit ASCII codes. Such noncanonical sequences could be used to clev-\nerly encode HTML syntax elements, such as angle brackets or quotes,\nina manner that survives a simple server-side check. For example, the\nfamously problematic UTF-7 encoding permits the “<” character to be\nencoded as a five-character sequence of “+ADw-”, a string that most server-\nside filters will happily permit as is. In a similar vein, UTF-8 specification\nformally prohibits, but technically permits, “<” to be represented by\nunnecessarily verbose 2- to 5-byte sequences, from 0xC0 0xBC to 0xFC\n0x80 0x80 0x80 0x80 0xBC.*\n* Today, this problem is mitigated by most browsers: Their parsers now have additional checks\ntoreject overlong UTF-8 encodings as a matter of principle. The same cannot be said of all\npossible server-side UTF-8 libraries, however.\n206 Chapter 13\n Variable length encodings that give special meaning to one or more bytes\nthat follow a special prefix. Such logic may result in legitimate HTML syn-\ntax elements being “consumed” as part of an unintentional multibyte lit-\neral. For example, the Shift JIS prefix code 0xE0 can cause the subsequent\nangle bracket or a quote to be consumed in Internet Explorer, Firefox,\nand Opera (but not in Chrome), possibly severely altering the meaning\nof the inline markup.\nThe opposite problem may also occur: The server may be convinced\nthat it is outputting a multibyte literal, but this literal may be rejected by the\nbrowser and interpreted as several individual characters. In EUC-KR, the\n0x8E prefix is honored only if the subsequent character has an ASCII code\nof 0x41 or higher. Any less and it will not have the expected effect, but\nnot all server-side implementations may notice.\n Encodings that are completely incompatible with 8-bit ASCII. These\ncases will simply lead to a very different view of document structure\nbetween the client and the server. Common examples include UTF-16\norUTF-32.\nThe bottom line is that unless the server has a perfect command of the\ncharacter set it is generating and unless it is certain that the client will not\napply an unexpected transformation to the payload, serious complications may\narise. For example, consider a web application that removes angle brackets\nfrom the highlighted user-controlled string in the following piece of HTML:\nYou are currently viewing:\n<span class=\"blog_title\">\n+ADw-script+AD4-alert(\"Hi mom!\")+ADw-/script+AD4-\n</span>\nIf that document is interpreted as UTF-7 by the receiving party, the\nactual parsed markup will look as follows:\nYou are currently viewing:\n<span class=\"blog_title\">\n<script>alert(\"Hi mom!\")</script>\n</span>\nA similar problem, this time related to byte consumption in Shift JIS encod-\ning, is illustrated below. A multibyte prefix is permitted to consume a closing\nquote, and as a result, the associated HTML tag is not terminated as expected,\nenabling the attacker to inject an extra onerror handler into the markup:\n<img src=\"http://fuzzybunnies.com/[0xE0]\">\n...this is still a part of the markup...\n...but the server doesn't know...\n\" onerror=\"alert('This will execute!')\"\n<div>\n...page content continues...\n</div>\nContent Recognition Mechanisms 207"
  },
  {
    "input": "Byte Order Marks",
    "output": "It is simply imperative to prevent character set autodetection for all text-\nbased documents that contain any type of user-controlled data. Most browsers\nwill engage in character set detection if the charset parameter is not found in\nthe Content-Type header or in the <meta> tag. Some marked differences exist\nbetween the implementations (for example, only Internet Explorer is keen to\ndetect UTF-7), but you should never assume that the outcome of character\nset sniffing will be safe.\nCharacter set autodetection will also be attempted if the character set is\nnot recognized or is mistyped; this problem is compounded by the fact that\ncharset naming can be ambiguous and that web browsers are inconsistent in\nhow much tolerance they have for common name variations. As a single data\npoint, consider the fact that Internet Explorer recognizes both ISO-8859-2\nand ISO8859-2 (with no dash after the ISO part) as valid character set identi-\nfiers in the Content-Type header but fails to recognize UTF8 as an alias for\nUTF-8. The wrong choice can cause some serious pain.\nNOTE Fun fact: The X-Content-Type-Options header has no effect on character-sniffing\nlogic.\nByte Order Marks\nWe are not done with character set detection just yet! Internet Explorer needs\nto be singled out for yet another dramatically misguided content-handling\npractice: the tendency to give precedence to the so-called byte order mark\n(BOM), a sequence of bytes that can be placed at the beginning of a file to\nidentify its encoding, over the explicitly provided charset data. When such a\nmarker is detected in the input file, the declared character set is ignored.\nTable 13-1 shows several common markers. Of these, the printable\nUTF-7 BOM is particularly sneaky.\nTable 13-1: Common Byte Order Markers (BOMs)\nEncoding name Byte order mark sequence\nUTF-7 “+/v” followed by “8”, “9”, “+”, or “/”\nUTF-8 0xEF 0xBB 0xBF\nUTF-16 little endian 0xFF 0xFE\nUTF-16 big endian 0xFE 0xFF\nUTF-32 little endian 0xFF 0xFE 0x00 0x00\nUTF-32 big endian 0x00 0x00 0xFE 0xFF\nGB-18030 0x84 0x31 0x95 0x33\nNOTE Microsoft engineers acknowledge the problem with this design and, as of this writing,\nsay that the logic may be revised, depending on the outcome of compatibility tests. If\ntheproblem is resolved by the time this book hits the shelves, kudos to them. Until then,\nallowing the attacker to control the first few bytes of an HTTP response that is not other-\nwise protected by Content-Disposition may be a bad idea—and other than padding\nthe response, there is no way to work around this glitch.\n208 Chapter 13"
  },
  {
    "input": "Markup-Controlled Charset on Subresources",
    "output": "Character Set Inheritance and Override\nTwo additional, little-known mechanisms should be taken into account when\nevaluating the potential impact on character set handling strategies in con-\ntemporary web browsers. Both of these features may permit an attacker to\nforce undesirable character encoding upon another page, without relying\noncharacter sniffing.\nThe first apparatus in question, supported by all but Internet Explorer, is\nknown as character set inheritance. Under this policy, any encoding defined for\nthe top-level frame may be automatically applied to any framed documents\nthat do not have their own, valid charset value set. Initially, such inheritance is\nextended to all framing scenarios, even across completely unrelated websites.\nHowever, when Stefan Esser, Abhishek Arya, and several other researchers\ndemonstrated a number of plausible attacks that leveraged this feature to\nforce UTF-7 parsing on unsuspecting targets, Firefox and WebKit developers\ndecided to limit the behavior to same-origin frames. (Opera still permits cross-\ndomain inheritance. Although it does not support UTF-7, other problematic\nencodings, such as Shift JIS, are fair game.)\nThe other mechanism that deserves mention is the ability to manually\noverride the currently used character set. This feature is available through\nthe View > Encoding menu or similar in most browsers. Using this menu to\nchange the character set causes the page and all its subframes (including\ncross-domain ones!) to be reparsed using the selected encoding, regardless\nof any charset directives encountered earlier for that content.\nBecause users may be easily duped into selecting an alternative encoding\nfor an attacker-controlled page (simply in order to view it correctly), this\ndesign should make you somewhat uncomfortable. Casual users can’t be\nexpected to realize that their election will also apply to hidden <iframe> tags\nand that such a seemingly innocuous action may enable cross-site scripting\nattacks against unrelated web properties. In fact, let’s be real: Most of them\nwill not know—and should not have to know—what an <iframe> is.\nMarkup-Controlled Charset on Subresources\nWe are nearing the end of the epic journey through the web of content-\nhandling quirks, but we are not quite done yet. Astute readers may recall that\nin “Type-Specific Content Inclusion” on page82, I mentioned that on cer-\ntain types of subresources (namely, stylesheets and scripts), the embedding\npage can specify its own charset value in order to apply a specific transforma-\ntion to the retrieved document, for example,\n<script src=\"http://fuzzybunnies.com/get_js_data.php\" charset=\"EUC-JP\">\nThis parameter is honored by all browsers except for Opera. Where it is\nsupported, it typically does not take precedence over charset in Content-Type,\nunless that second parameter is missing or unrecognized. But to every rule,\nthere is an exception, and all too often, the name of this exception is Inter-\nnet Explorer 6. In that still-popular browser, the encoding specified by the\nmarkup overrides HTTP data.\nContent Recognition Mechanisms 209"
  },
  {
    "input": "Detection for Non-HTTP Files",
    "output": "Does this behavior matter in practice? To fully grasp the consequences,\nlet’s also quickly return to Chapter 6, where we debated the topic of securing\nserver-generated, user-specific, JSON-like code against cross-domain inclu-\nsion. One example of an application that needs such a defense is a search-\nable address book in a webmail application: The search term is provided in\nthe URL, and a JavaScript serialization of the matching contacts is returned\nto the browser but must be shielded from inclusion on unrelated sites.\nNow, let’s assume that the developer came up with a simple trick to\nprevent third-party web pages from loading this data through <script src=...>:\nA single “//” prefix is used to turn the entire response into a comment.\nSame-origin callers that use the XMLHttpRequest API can simply examine the\nresponse, strip the prefix, and pass the data to eval(...)—but remote callers,\ntrying to abuse the <script src=...> syntax, will be out of luck.\nIn this design, a request to /contact_search.php?q=smith may yield the fol-\nlowing response:\n// var result = { \"q\": \"smith\", \"r\": [ \"j.smith@example.com\" ] };\nAs long as the search term is properly escaped or filtered, this scheme\nappears safe. But when we realize that the attacker may force the response\ntobe interpreted as UTF-7, the picture changes dramatically. A seemingly\nbenign search term that, as far as the server is concerned, contains no illegal\ncharacters could still unexpectedly decode to\n// var result = { \"q\": \"smith[CR][LF]\nvar gotcha = { \"\", \"r\": [ \"j.smith@example.com\" ] };\nThis response, when loaded via <script src=... charset=utf-7> inside\nthevictim’s browser, gives the attacker access to a portion of the user’s\naddressbook.\nThis is not just a thought exercise: The “//” approach is fairly common\non the Web, and Masato Kinugawa, a noted researcher, found several popu-\nlar web applications affected by this bug. And a more contrived variant of the\nsame attack is also possible against other execution-preventing prefixes, such\nas while (1);. In the end, the problems with cross-domain charset override on\n<script> tags is one of the reasons why in Chapter 6, we strongly recommend\nusing a robust parser-stopping prefix to prevent the interpreter from ever\nlooking at any attacker-controlled bits. Oh—and if you factor in the support\nfor E4X, the picture becomes even more interesting,5 but let’s leave it at that.\nDetection for Non-HTTP Files\nTo wrap up this chapter, let’s look at the last missing detail: character set\nencoding detection for documents delivered over non-HTTP protocols. As\ncan be expected, documents saved to disk and subsequently opened over\nthefile: protocol, or loaded by other means where the usual Content-Type\nmetadata is absent, will usually be subjected to character set detection logic.\n210 Chapter 13\nHowever, unlike with document determination heuristics, there is no sub-\nstantial difference among all the possible delivery methods: In all cases, the\nsniffing behavior is roughly the same.\nThere is no clean and portable way to address this problem for all text-\nbased documents, but for HTML specifically, the impact of character set\nsniffing can be mitigated by embedding a <meta> directive inside the docu-\nment body:\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=...\">\nYou should not ditch Content-Type in favor of this indicator. Unlike <meta>,\nthe header works for non-HTML content, and it is easier to enforce and audit\non a site-wide level. That said, documents that are likely to be saved to disk\nand that contain attacker-controlled tidbits will benefit from a redundant\n<meta> tag. (Just make sure that this value actually matches Content-Type.)\nContent Recognition Mechanisms 211"
  },
  {
    "input": "When Hosting User-Generated Files",
    "output": "Security Engineering Cheat Sheet\nGood Security Practices for All Websites\n Instruct the web server to append the X-Content-Options: nosniff header to all HTTP\nresponses.\n Consult the cheat sheet in Chapter 9 to set up an appropriate /crossdomain.xml meta-policy.\n Configure the server to append default charset and Content-Type values on all responses\nthat would otherwise not have one.\n If you are not using path-based parameter passing (such as PATH_INFO), consider dis-\nabling this feature.\nWhen Generating Documents with Partly Attacker-Controlled Contents\n Always return an explicit, valid, well-known Content-Type value. Do not use text/plain or\napplication/octet-stream.\n For any text-based documents, return a explicit, valid, well-known charset value in the\nContent-Type header; UTF-8 is preferable to any other variable-width encodings. Do not\nassume that application/xml+svg, text/csv, and other non-HTML documents do not need a\nspecified character set. For HTML, consider a redundant <meta> directive if it’s conceiv-\nable that the file may be downloaded by the user. Beware of typos—UTF8 is not a valid\nalias for UTF-8.\n Use Content-Disposition: attachment and an appropriate, explicit filename value for responses\nthat do not need to be viewed directly—including JSON data.\n Do not allow the user to control the first few bytes of the file. Constrain the response as\nmuch as possible. Do not pass through NULs, control characters, or high-bit values unless\nabsolutely necessary.\n When performing server-side encoding conversions, be sure that your converters reject\nall unexpected or invalid inputs (e.g., overlong UTF-8).\nWhen Hosting User-Generated Files\nConsider using a sandbox domain if possible. If you intend to host unconstrained or unknown\nfile formats, a sandbox domain is a necessity. Otherwise, at the very minimum, do the following:\n Use Content-Disposition: attachment and an appropriate, explicit filename value that matches\nthe Content-Type parameter.\n Carefully validate the input data and always use the appropriate, commonly recognized\nMIME type. Serving JPEG as image/gif may lead to trouble. Refrain from hosting MIME\ntypes that are unlikely to be supported by popular browsers.\n Refrain from using Content-Type: application/octet-stream and use application/binary instead,\nespecially for unknown document types. Refrain from returning Content-Type: text/plain.\nDo not permit user-specified Content-Type headers.\n212 Chapter 13"
  },
  {
    "input": "14: \rDealing with Rogue Scripts",
    "output": "D E A L I N G W I T H\nR O G U E S C R I P T S\nIn the previous five chapters, we examined a fairly broad\nrange of browser security mechanisms—and looking\nback at them, it is fair to say that almost all share a com-\nmon goal: to stop rogue content from improperly inter-\nfering with any other, legitimate web pages displayed\nin a browser. This is an important pursuit but also a\nfairly narrow one; subverting the boundaries between unrelated websites\nisalarge part of every attacker’s repertoire but certainly not the only trick\ninthe book.\nThe other significant design-level security challenge that all browsers have\nto face is that attackers may abuse well-intentioned scripting capabilities in\norder to disrupt or impersonate third-party sites without actually interacting\nwith the targeted content. For example, if JavaScript code controlled by an\nattacker is permitted to create arbitrary undecorated windows on a screen, the\nattacker may find that, rather than look for a way to inject a malicious payload\ninto the content served at fuzzybunnies.com, it may be easier to just open a\nwindow with a believable replica of the address bar, thus convincing the\nuserthat the content displayed is from a trusted site."
  },
  {
    "input": "Denial-of-Service Attacks",
    "output": "Unfortunately for victims, in the early days of the Web, no real attention\nwas given to the susceptibility of JavaScript APIs to attacks meant to disrupt or\nconfuse users, and, unlike cross-domain content isolation issues, this class of\nproblems is still not taken very seriously. The situation is unlikely to change\nanytime soon: Vendor resources are stretched thin between addressing com-\nparatively more serious implementation-level flaws in the notoriously buggy\nbrowser codebases and rolling out new, shiny security features that appease\nweb application developers, users, and the mainstream press alike.\nDenial-of-Service Attacks\nThe possibility of an attacker crashing a browser or otherwise rendering it\ninoperable is one of the most common, obvious, and least appreciated issues\naffecting the modern Web. In the era of gadgets and mashups, it can have\nunexpectedly unpleasant consequences, too.\nThe most prominent reason why most browsers are susceptible to\ndenial-of-service (DoS) attacks is due simply to a lack of planning: Neither the\nunderlying document formats nor the capabilities exposed through scripting\nlanguages were designed to have a sensible, constrained worst-case CPU or\nmemory footprint. In other words, any sufficiently complex HTML file or an\nendless JavaScript loop could bring the underlying operating system to its\nknees. Worse, the attempts to mandate resource limits or to give users a way\nto resume control of a runaway browser following a visit to a rogue page meet\nwith resistance. For example, the authors of many of the recently proposed\nHTML5 APIs provide no advice on preventing resource exhaustion attacks,\nnor do they even acknowledge this need, because they think that any limits\nimposed today will likely hinder the growth of the Web 5 or 10 years from\nnow. Browser developers, in turn, refuse to take any action absent any\nstandards-level guidance.\nA common utilitarian argument against any proposed DoS defenses\nisthat they are pointless—that the browser is hopelessly easy to crash in a\nmultitude of ways, so why take special measures to address a specific vector\ntoday? It’s hard to argue with this view, but it’s also important to note that it\nacts as a self-fulfilling prophecy: The steady increase in the number of DoS\nvectors is making it more and more unlikely that the situation will be com-\nprehensively addressed any time soon.\nNOTE To be fair, the computational complexity of certain operations is not the only reason why\nbrowsers are easy to crash. Vendors are also constrained by the need to maintain a sig-\nnificant degree of synchronicity during page-rendering and script-execution steps (see\nChapter 6). This design eliminates the need for website developers to write reentrant\nand thread-safe code and has substantial code complexity and security benefits. Unfor-\ntunately, it also makes it much easier for one document to lock up the entire browser, or\nat least a good portion thereof.\nRegardless of all these considerations, and even if browser vendors refuse\nto acknowledge DoS risks as a specific flaw, the impact of such attacks is dif-\nficult to ignore. For one, whenever a browser is brought down, there is a\n214 Chapter 14"
  },
  {
    "input": "Execution Time and Memory Use Restrictions",
    "output": "substantial risk of data loss (in the browser itself or in any applications indi-\nrectly affected by the attack). Also, on some social-networking sites, an attacker\nmay be able to lock out the victim from the site simply by sharing a rogue gad-\nget, or perhaps even a well-selected image, with the victim, preventing that\nperson from ever using that service again.\nSome of the common tricks used to take a browser out of service include\nloading complex XHTML or SVG documents, opening a very large number of\nwindows, running an endless JavaScript loop that allocates memory, queuing\na significant number of postMessage(...) calls, and so on. While these examples\nare implementation-specific, every browser offers a fair number of ways to\nachieve this goal. Even in Chrome, which uses separate renderer processes\ntoisolate unrelated pages, it’s not difficult to bring down the entire browser:\nThe top-level process mediates a variety of script-accessible and sometimes\nmemory- or CPU-intensive tasks.\nGiven the above, it’s no surprise that despite generally dismissive attitudes,\nthe major browsers nevertheless implement several DoS countermeasures.\nThey do not add up to a coherent strategy, and have they have been rolled\nout only in response to the widespread abuse of specific APIs or to mitigate\nnonmalicious but common programming errors. Nevertheless, let’s look at\nthem briefly.\nExecution Time and Memory Use Restrictions\nBecause of the aforementioned need to enforce a degree of synchronicity\nformany types of JavaScript operations, most browser vendors err on the side\nof caution and execute scripts synchronously with most of the remaining\nbrowser code. This design has an obvious downside: A good portion of the\nbrowser may become completely unresponsive as the JavaScript engine is,\nsay, trying to evaluate a bogus while (1) loop. In Opera and Chrome, the top-\nlevel user interface will still be largely responsive, if sluggish, but in most\nother browsers, it won’t even be possible to close the browser window using\nthe normal UI.\nBecause endless loops are fairly easy to create by accident, in order to aid\ndevelopers, Internet Explorer, Firefox, Chrome, and Safari enforce a modest\ntime limit on any continuously or nearly continuously executing scripts. If\nthe script is making the browser unresponsive for longer than a couple of\nseconds, the user will be shown a dialog and given the option to abort execu-\ntion. Picking this option will have a result similar to encountering an unhan-\ndled exception, that is, of abandoning the current execution flow.\nRegrettably, such a limit is not a particularly robust defense against mali-\ncious scripts. For example, regardless of the user’s choice, it is still possible to\nresume execution through timers or event handlers, and it’s easy to avoid\ntriggering the prompt in the first place by periodically returning the CPU\nbriefly to an idle state in order to reset the counter. Too, as noted previously,\nthere are ways to hog CPU resources without resorting to busy loops: Render-\ning complex XHTML, SVG, or XSLT documents can be just as disruptive\nand is not subject to any checks.\nDealing with Rogue Scripts 215"
  },
  {
    "input": "Connection Limits",
    "output": "Execution time aside, there have been attempts to control the memory\nfootprint of executed scripts. The size of the call stack is limited to a browser-\nspecific value between 500 and 65535, and attempting a deeper recursion\nwill result in an unconditional stop. Script heap size, on the other hand, is\ntypically not restricted in a meaningful way; pages can allocate and use up\ngigabytes of memory. In fact, most of the previously implemented restric-\ntions (such as the 16MB cap in Internet Explorer 6) have been removed in\nmore recent releases.\nConnection Limits\nIn many web applications, each web page consists not only of the proper\nHTML document retrieved from the URL visible in the address bar but\nalsoas many as several dozen other, separately loaded subresources, such\nasimages, stylesheets, and scripts. Because requesting all of these elements\nthrough individually established HTTP connections can be slow, the reader\nmay recall from Chapter 3 that the protocol has been extended to offer keep-\nalive sessions and request pipelining. But even with these improvements, one\nstubborn problem remains. The inherent limitation of the protocol is that\nthe server must always send responses in the same order that it received the\nrequests, so if any of the subresources (no matter how inconsequential) takes\na bit longer to generate, the loading of all subsequent ones will be delayed.\nTo work around this problem, and to optimize performance when keep-\nalive requests or pipelining can’t be used, all browsers permit the opening of\nseveral simultaneous HTTP connections to the destination server. This way,\nthe browser can issue multiple requests in parallel.\nUnfortunately, the parallel connection design can be expensive for the\ndestination website, especially if the server relies on the traditional fork()-\nbased connection-handling architecture.* Therefore, in order to limit the\nrisk of accidentally or intentionally launching a distributed DoS attack, the\nnumber of parallel connections needs to be limited to a modest per-host\nvalue, typically between 4 and 16. Furthermore, to prevent attackers from\noverloading the browser itself (or affecting the performance of the nearby\nnetworking equipment), the total number of simultaneous connections to\nalldestinations is also constrained to a low multiple of the per-host cap.\nNOTE In many implementations, the per-host connection limit is enforced by looking at DNS\nlabels, not at IP addresses. Therefore, an attacker may still be able to point several\nbogus DNS entries in his own domains to any unrelated target IP and circumvent\nthefirst restriction. The global connection limit will be still in effect, though.\nAlthough the number of concurrent HTTP sessions is limited, there are\nno practical restrictions on how long an active session may be kept alive (that\nis, as long as no kernel-level TCP/IP timeouts are encountered). This design\n* The traditional design of most Unix services is to have a master “listener” process, and then\ncreate a new process for handling every accepted connection. For the developer, this model is\nremarkable in its simplicity; but it comes with many significant hidden costs for the operating\nsystem, which sometimes finds handling more than several hundred simultaneous connections\nat once challenging.\n216 Chapter 14"
  },
  {
    "input": "Pop-Up Filtering",
    "output": "may make it possible for attackers to simply exhaust the global connection\nlimit by talking to a couple of intentionally slow destinations, preventing the\nuser from doing anything useful in the meantime.\nPop-Up Filtering\nThe window.open(...) and window.showModalDialog(...)* APIs permit web pages\nto create new browser windows, pointing them to any otherwise permitted\nURLs. In both cases, the browser may be instructed not to show certain win-\ndow decorations for the newly loaded document or to position the window\non the screen in a specific way. A simple use of window.open(...) might look\nlike this:\nwindow.open(\"/hello.html\", \"_blank\", \"menubar=no,left=50,top=50\");\nIn addition to these two JavaScript methods, new windows may also be\nopened indirectly by programatically interacting with certain HTML ele-\nments. For example, it is possible to call the click() method on an HTML link\nor to invoke the submit() method on a form. If the relevant markup includes\natarget parameter, the resulting navigation will take place in a new window\nofa specified name.\nAs could be expected, the ability for random web pages to open new\nbrowser windows soon proved to be problematic. In the late 1990s, many\nplayers in the then-young online advertising industry decided they needed\ntoattract attention to their ads at any cost, even at the expense of profoundly\nannoying and alienating their audiences. Automatically spawning windows\nsolely to show a flashy advertisement seemed like a great way to do business\nand make new friends.\nPop-up and pop-under† advertisements have quickly emerged as one of\nthe best-known and most reviled aspects of the Web. For good reason, too:\nEspecially with pop-unders, it would not be unusual to amass a dozen of\nthem after two to three hours of casual browsing.\nDue to widespread complaints, browser vendors stepped in and imple-\nmented a simple restriction: Spurious attempts by non-whitelisted pages to\ncreate new windows would be silently ignored.‡ Exceptions were made for\nattempts made immediately after a mouse click or a similar user action. For\n* The little-known showModalDialog(...) method is a bit of a misnomer. It is essentially equivalent\nto window.open(...), but it is supposed to vaguely emulate the behavior of a modal dialog by block-\ning the scripts in the calling context until such a “dialog” window is dismissed. The exact behav-\nior of this API varies randomly from one browser to another. For example, it is sometimes possible\nfor other pages to navigate the underlying window or execute new scripts while the original JS\ncode that called showModalDialog(...) is in progress.\n† A “pop-under” is a pop-up window that, immediately after its creation, is moved to the back of\nthe window stack with the help of opener.window.focus() or window.blur(). Pop-unders are arguably\nslightly less distracting than pop-ups, because the user does not have to take immediate action to\ngo back to the original document. They are no less despised, however.\n‡ For example, a call to window.open(...) would not generate an exception. The return value in\nsuch a case is not standardized, however, making it difficult to detect a blocked pop-up reliably.\nIn Internet Explorer and Firefox, the function will return null; in Safari, it will return another\nspecial value, undefined; in Opera, a dummy window handle will be supplied; and in Chrome, the\nreturned window handle will even have a quasi-functional DOM.\nDealing with Rogue Scripts 217"
  },
  {
    "input": "Dialog Use Restrictions",
    "output": "example, in the case of JavaScript, the ability to call window.open(...) would be\ngranted to code executed in response to an onclick event and revoked shortly\nthereafter. (In Internet Explorer and WebKit, this permission expires the\nmoment the event handler is exited. Other browsers may recognize a short\ngrace period of one second or so.)\nThe pop-up blocking feature initially curtailed pop-up advertising but, ulti-\nmately, proved to be fairly ineffective: Many websites would simply wait for the\nuser to click anywhere on the page (in order to follow a link or even scroll the\ndocument) and spawn new windows in response. Others simply moved on to\neven more disruptive practices such as interstitials—full-page advertisements\nyou need to click through to get to the content you actually want to read.\nThe advertising arms race aside, the war on window.open(...) is also inter-\nesting from the DoS perspective. Creating hundreds of thousands of windows,\nthereby exhausting OS-enforced limits on the number of UI handles, is a\nsure way to crash the browser and to disrupt other applications as well. Any\nmechanism that limits this capability would be, at least in theory, a valuable\ndefense. No such luck: Unbelievably, only Internet Explorer and Chrome\nsensibly limit the actual number of times window.open(...) can be called in\nresponse to a single click. In other browsers, once the temporary permission\nto open windows is granted, the attacker can go completely nuts and open as\nmany windows as she desires.\nDialog Use Restrictions\nWindow-related woes aside, all web-originating scripts can open certain\nbrowser- or OS-handled dialogs. The usefulness of these dialogs to modern\nweb applications is minimal, but they still constitute another interesting part\nof the browser security landscape. Dialog-initiating APIs include window\n.alert(...), used to display simple text messages; window.prompt(...) and window\n.confirm(...), used to request basic user input; and window.print(...), which brings\nup the OS-level printing dialog. A couple of obscure vendor extensions, such\nas Mozilla’s window.sidebar.addPanel(...) and window.sidebar.addSearchEngine(...)\n(to create bookmarks and register new search providers, respectively), are\nalso on this list.\nThe aforementioned JavaScript methods aside, several types of dialogs\ncan be spawned indirectly. For example, it is possible to invoke the click()\nmethod on a file upload button or to navigate to a downloadable file, which\nusually brings up the OS-supplied file selection dialog. Navigating to a URL\nthat requires HTTP authentication will also typically bring up a browser-level\nprompt.\nSo, what makes dialogs so interesting? The challenge with these prompts\nis quite different from that of programmatically created windows. Unlike\nthelargely asynchronous window.open(...) API, dialogs pause the execution of\nJavaScript and defer many other actions (such as navigation or event deliv-\nery), effectively preventing dialogs from being created in large numbers to\nexhaust resources and crash the application. But their modal behavior is\nalso their curse: They prevent any interaction with some portion of the\nbrowser until the user dismisses the dialog itself.\n218 Chapter 14"
  },
  {
    "input": "Window-Positioning and Appearance Problems",
    "output": "This creates an interesting loophole. If a new dialog is opened immedi-\nately after the old one is closed, the victim may be locked out of a vital portion\nof the browser UI, often even losing the ability to close the window or navi-\ngate away from the offending page. Malware authors sometimes abuse that\nquirk to force casual, panicked users to perform a dangerous action (such as\ndownloading and executing an untrusted executable) just to be permitted to\ncontinue their work: Making any other choice in the script-initiated security\nprompt will only make the same dialog reappear over and over again.\nProbably because of this malware-related tangent, browser vendors have\nbegun experimenting with less disruptive prompting methods. In Chrome,\nfor example, some of the most common modal dialogs have a checkbox that\nallows the user to suppress future attempts by the page to use the offending\nAPI (until the next reload, that is). In Opera, it is possible to stop the execu-\ntion of scripts on the page. And in both Opera and recent versions of Firefox,\nmany common dialogs are modal\nonly in relation to the document-\ncontrolled area of the window, still\nallowing the tab to be closed or a\ndifferent URL to be entered in the\naddress bar. Nevertheless, the cov-\nerage of such improvements is\nlimited.\nFigure 14-1: Firefox generated a profoundly\nNOTE *Many browser-level dialogs do a poor confusing and vague prompt following the exe-\ncution of an onbeforeunload handler on a web\njob of explaining where the prompt\npage. The handler gives page authors a chance\noriginated and its intended purpose.\nto explain the consequences of navigating away\nIn some cases, such as the Firefox dia-\nfrom their page (such as losing any unsaved\nlog shown in Figure 14-1, the result data) and requests a final decision from the\ncan be comical—and there is a more user.* In this screenshot, the first and the last\nsinister side to such goofiness, too. line come from the browser itself; the middle\nSpawning authoritative-sounding dia- two lines are an “explanation” supplied by an\n(unnamed!) rogue website instead. The security\nlogs that claim to be coming from the\nimpact of this particular dialog is minimal, but\noperating system itself is a common\nit is a remarkable example of poor UI design.\ntrick used by malware authors to con-\nSadly, a nearly identical dialog is also used by\nfuse less experienced users. It’s not Internet Explorer, and most other browser dia-\nhard to imagine why that works. logs are not much better.\nWindow-Positioning and Appearance Problems\nAll right, all right—let’s move beyond the arguably uninspiring and unpopu-\nlar topic of DoS flaws. There is a lot more to the various UI-related APIs—\nand window.open(...) is a particularly curious case. Recall from the discussion\nearlier in this chapter that this humble function permits web applications not\nonly to create new windows but also to position them in a specific spot on the\n* For usability reasons, random pages on the Internet are no longer permitted to abort pending\nnavigation by means other than this specific onbeforeunload dialog. (Surprisingly, the by-design\nability to trap the user on a rogue page forever and cancel any navigation attempts wasn’t\nreceived well.)\nDealing with Rogue Scripts 219\nscreen. Several other methods, such as window.moveTo(...), window.resizeTo(...),\nwindow.focus(), or window.blur(), further permit such a window to be moved\naround the screen, scaled, or stacked in a particular way. Finally, window.close()\nallows it to be discreetly disposed of when the script no longer needs it.\nAs with most other UI-manipulation features, these APIs soon proved to\nbe a source of pain. Following a series of amusing hacks that involved creat-\ning “hidden” windows by placing them partly or completely off-screen or by\nmaking them really tiny, these functions now require newly created windows\nto have certain minimal dimensions and to stay entirely within the visible desk-\ntop area. (It is still possible to create a window that constantly hops around\nthe screen and evades all mouse-driven attempts to close it, but given what\nyou’ve read so far, this deserves nothing but a heavy sigh.)\nThe restrictions on window\nsize do not mean that the entire\ncontents of the address bar have\nto be visible to the user, how-\never. An undersized window\ncould be leveraged to mislead\nthe user as to the origin of a\ndocument simply by carefully\ntruncating the hostname, as\nshown in Figure 14-2. Browser\nvendors have been aware of this\nproblem since at least my report\nin 2010,1 but as of this writing,\nonly Internet Explorer uses a\nsomewhat convincing if subtle\nmitigation: It appends “...” at\nthe end of any elided host-\nFigure 14-2: A window carefully sized by a script\nnames in the address bar.\nso that the real origin of the displayed content is\nAnother interesting issue\nelided ina confusing way. The actual URL of this\nwith script-controlled window cat-themed page is http://www.example.com\npositioning is the prospect of .coredump.cx/, nothttp://www.example.com/.\ncreating several cleverly aligned,\noverlapping windows to form what appears to be a single document window\nwith an address bar that doesn’t correspond to portions of the document dis-\nplayed. This attack, which I like to call window splicing, is perhaps best illus-\ntrated in Figure 14-3.\nWindow positioning offers some interesting if far-fetched attack scenar-\nios, but manipulating the contents of a programmatically created window is\nalso of some relevance to browser security. We have already mentioned that\none of the features of the window.open(...) API is its ability to hide certain ele-\nments of the browser chrome (scrollbars, menus, and so on) in the newly\nopened window. An example of such a UI-restricting call is\nwindow.open(\"http://example.com/\", \"_blank\", \"location=no,menubar=no\");\n220 Chapter 14\nFigure 14-3: A window-splicing attack in Chrome. What may appear as a single document\nis actually a composite of two overlapping, aligned windows. The user is led to believe that\nthe file upload button comes from the domain shown in the address bar of the top window,\nbut it does not. Certain visual cues indicate foul play (for example, part of the window bor-\nder has a slightly different hue), but they are too subtle to be easily noticed by the user.\nOne of these settings, location=no, was meant to hide the address bar.\nThis is, of course, a horrible idea: It enables the attacker not only to hide the\nactual address bar but also to load a page that simply provides a pixel-perfect\nimage of the address bar showing a completely unrelated URL. Heck, with\nsome minimal effort, that fake address bar may even be fully interactive.\nRealizing the dangers of this design, most browsers eventually began\ndisplaying a minimalistic, read-only address bar in any windows opened with\nlocation=no; Apple, however, sees no harm in allowing this setting to work as\noriginally envisioned in the 1990s. Too bad: Figure 14-4 shows a simple attack\non its UI. (I contacted Apple about this attack sometime in 2010 but have yet\nto hear back.)\nFigure 14-4: Allowing websites to hide the address bar in Safari is a bad idea.\nThe displayed document is not retrieved from http://www.example.com/.\nInstead, the page simply displays a screenshot of a real address bar in a win-\ndow created by window.open(\"http://coredump.cx/...\", \"location=no\").\nDealing with Rogue Scripts 221"
  },
  {
    "input": "Timing Attacks on User Interfaces",
    "output": "Microsoft has not fared much better: Although they patched up\nwindow.open(...), they forgot about window.createPopup(...), an ancient\nandobscure API still not subject to the necessary checks.\nTiming Attacks on User Interfaces\nThe problems we’ve discussed so far in this chapter may be hard to fix, but at\nleast in principle, the solutions are not out of reach. Still, here’s a preposter-\nous question: Could the current model of web scripting be fundamentally\nincompatible with the way human beings work? By that, I do not mean merely\nthe dangers of web-delivered social engineering that targets the inattentive\nand the easily confused; rather, I’m asking if it’s possible for scripts to consis-\ntently outsmart alert and knowledgeable victims simply due to the inherent\nlimitations of human cognition?\nThe question is outlandish enough not to be asked often, yet the answer\nmay be yes. Consider that in a typical, attentive human subject, the usual\nlatency between a visual stimulus and a voluntary motor response is between\n100 and 300 milliseconds.2 Humans do not pause for that long to assess the\nsituation after every minute muscle movement; instead, we subconsciously\nschedule a series of learned motor actions well in advance and process any\nsensory feedback as it arrives later on. For a split second, we cannot abort a\npremeditated action, even if something goes horribly wrong.\nAlas, on today’s personal computers, a lot can happen in as little as one-\ntenth of that interval. In particular, scripts can open new windows, move them\naround, or close any existing ones; they can also initiate or abort system-level\nprompts. In such a setting, designing security-sensitive UIs is not nearly as\nsimple as it seems, and some types of attacks may be simply impossible to\ndefend against without a major paradigm shift in how we design software.\nTo illustrate the issue, consider a page that attempts to start an unsolicited\ndownload of a dangerous file type. The download will typically initiate a browser-\nlevel dialog with three options: “open,” “save,” and “cancel.” Sane users will\nmake that last choice—but not if the attacker robs them of a chance to do so.\nLet’s assume that just milliseconds after the dialog is opened, and per-\nhaps before the user even registers its presence, a new window is created\nontop that hides it from view. In that window, the attacker plants a carefully\npositioned button or link that the user is likely to click, for example, a button\nto dismiss an annoying interstitial advertisement. As the user attempts to per-\nform this perfectly reasonable action, the rogue page may use onmousemove\nevents to monitor the position and velocity of the mouse pointer and fairly\naccurately predict the timing of an upcoming click. Closing the overlay win-\ndow several milliseconds before that click, only to reveal the “open” button\nin the same position, will lead the user inevitably to make that choice in the\nsecurity prompt. There is simply nothing the user can do. (I demonstrated a\npractical attack on Firefox along these lines in 2007.)3\nIn response to the attacks on security dialogs, a variety of security\ndelayshave been implemented in the past few years, requiring anywhere\nfrom 500milliseconds to 5 seconds between the dialog coming into focus\nand any dangerous buttons being enabled for user input. But such delays do\n222 Chapter 14\nnot sit well with browser UI designers: They hate them, feeling that the prod-\nuct should be as responsive as possible and that annoying the user with non-\nclickable buttons or countdowns is a significant usability issue. Some have even\npushed to remove existing timeouts from legacy UIs.* HTML5 geolocation-\nsharing prompts are impacted by this view. Many browsers are not protected\nagainst the attack on this UI in any significant way.4\nTo further complicate the picture, browser-level user interfaces are not\nthe only concern for UI-timing attacks. The security- or privacy-sensitive func-\ntionality of many trusted websites can also be attacked, and fixing that prob-\nlem is a lot harder than adding delay timers on a handful of known\ndangerous system-level UIs.\nNOTE Millisecond-level click or keypress hijacking aside, it has been repeatedly demonstrated\nthat with minimal and seemingly innocuous conditioning, healthy and focused test\nsubjects can be reliably tricked into ignoring even very prominent and unusual visual\nstimuli. The infamous Invisible Gorilla experiment,5 shown in Figure 14-5, is a partic-\nularly well-known example of this. Almost all viewers watching a clip prepared by the\nresearchers fail to notice a plainly visible gorilla in a crowd. The corollary is that even\nsavvy users can be conditioned to ignore cues such as changes to the address bar or to\nSSL indicators in the browser—a very disconcerting thought. The only reason why we\nare not trying to solve this problem today is that few exploit writers are behavioral scien-\ntists. But if you are a high-profile target, this seems like a risky bet.\nFigure 14-5: A single frame from the Invisible Gorilla experiment, courtesy\nofDaniel Simons6 (http://dansimons.com/). When asked to view this video\nand count the number of times the players pass the basketball, most view-\ners fail to notice a person in a gorilla suit casually strolling across the room\nhalfway through the clip. Really! Go to http://theinvisiblegorilla.com/\nvideos.html and try it on a friend.\n* See, for example, Mozilla bug 561177, where one of the Firefox UI engineers proposed the\nremoval of a security delay from the plug-in installation prompt.\nDealing with Rogue Scripts 223"
  },
  {
    "input": "When Building Security-Sensitive UIs",
    "output": "Security Engineering Cheat Sheet\nWhen Permitting User-Created <iframe> Gadgets on Your Site\n Don’t do so unless you are prepared to live with the consequences. You can’t reliably\nprevent a malicious gadget from launching DoS attacks on your users. Any such gadget\nwill also be able to bring up various obscure dialogs that, as a rule, will not distinguish\nbetween your top-level page and the domain the gadget is hosted in.\nWhen Building Security-Sensitive UIs\n Because of the risk of UI race conditions, avoid situations where a vital setting can be\nchanged with a single keypress or a single click. Require at least two operations (such\nasselecting a checkbox and then clicking Save). If single-click actions are unavoidable,\nconsider examining other signals. For example, was the mouse pointer in the current\nwindow 500 milliseconds ago?\n224 Chapter 14"
  },
  {
    "input": "15: Extrinsic Site Privileges\r",
    "output": "E X T R I N S I C S I T E P R I V I L E G E S\nTo wrap up the discussion of all the noteworthy browser\nsecurity features, we’ll look at a handful of mechanisms\nthat grant special privileges to sites hand-picked by the\nuser or hardcoded by the authors of the browser itself.\nThe approach taken in these cases is in stark contrast to\nthe schemes we have discussed previously, all of which\nrely on a fairly sensible examination of intrinsic properties of the displayed\ncontent. Normally, the implementation would have us look at the source of\nthe document, the context it is displayed in, or the nature of the operation\nthat the document is attempting to perform, but barring the outcome of these\nchecks, the browser would never give preferential treatment to a single other-\nwise unremarkable origin.\nPer-site privileges violate this principle of impartiality in a fairly brutal\nway, for reasons ranging from questionable to—more commonly—just utili-\ntarian. There are compelling usability reasons to bring certain inherently\ndangerous features to the browser world, but there is no good way to"
  },
  {
    "input": "Browser- and Plug-in-Managed Site Permissions",
    "output": "programmatically decide which web applications are trustworthy enough to\nbe given access to them. Delegating this task to a human being may be the\nbest thing we can do.*\nNaturally, the creation of a caste of privileged applications can be very\nproblematic because the boundaries between any two web applications are\nnot particularly well defined to begin with, making it difficult to contain the\npermissions precisely. And because the already imperfect boundaries apply\nonly to certain cross-site interactions, vulnerabilities such as XSS or XSRF may\nfurther contribute to the misery. In the end, a significant disconnect may\ndevelop between the intent of a per-site permission and the actual conse-\nquences of such a grant.\nBrowser- and Plug-in-Managed Site Permissions\nWhen balancing security, privacy, and usability, browser vendors sometimes\nfind themselves between a rock and a hard place. Some proposed features\nseem essential to the continued growth of the Web but are simply too dan-\ngerous to be made available to every website on the Internet. Examples of\nsuch problematic mechanisms include giving access tovideo camera or micro-\nphone feeds,† allowing websites to query for user geolocation data,‡ installing\nbrowser extensions or themes, or opening desktop notifications.\nAs a work-around for this problem, vendors require the user to approve\nthe application’s request in order for it to be allowed to access a privileged API.\nOn the first attempt to use restricted functionality, the user is typically pro-\nvided with a visual cue (ranging from an icon to a modal prompt) and given\nthree choices: ignore the request, permit it once, or permanently authorize\nthe requesting site to access the API. Of these choices, the last one is the most\ninteresting: If selected, all future access from a matching host will be auto-\nmatically approved, sometimes without any further visual indication.\nNOTE Most whitelists look only at the hostname, and not at the protocol or port. Any entry on\nthese lists will therefore match more than one SOP origin. In particular, authorizing\nhttps://fuzzybunnies.com/ to access your camera may also authorize the non-\nencrypted site at http://fuzzybunnies.com/ to do the same.\nGranting websites access to privacy- or security-sensitive features should\nbe done with care, because, as noted earlier, the implications of doing so\nextend beyond merely trusting the authors of the whitelisted application.\n* It is fair to complain that browsers do not do much to equip users with affirmative signals about\nthe trustworthiness of a visited site, even though many robust indicators may plausibly be arrived\nat in an automated way. Blacklist-driven attempts to block known malicious sites exist, but given\nthe negligible cost of registering a new domain (or compromising a random existing one), these\napproaches are arguably of less value.\n† This functionality is currently supported only by plug-ins, such as Adobe Flash, but on track to\nbecome a part of HTML5.\n‡ This API derives user location from parameters such as the current IP address, the list of\nnearby wireless networks or cell towers, or the data supplied by a hardware GPS receiver. With\nthe exception of GPS data, it may be necessary to consult an external service provider to map\nthese inputs to physical coordinates.\n226 Chapter 15"
  },
  {
    "input": "Form-Based Password Managers",
    "output": "Permission is granted to any content executed in the matching origin, regard-\nless of how the payload got there, greatly amplifying the impact of simple (and,\nin the long run, inevitable) implementation bugs. A script injection vulnera-\nbility in a privileged origin no longer merely exposes the data stored within\nthe application but may also leak client-originating sensitive data feeds.\nHardcoded Domains\nIn addition to the list of user-authorized privileged domains, some browsers\nor browser plug-ins come with a list of vendor-selected sites or SOP origins\nthat are given substantial privileges to reconfigure or update portions of the\nbrowser or the operating system. Some of the most prominent examples of\nthis trend include update.microsoft.com, which is recognized by ActiveX con-\ntrols that ship with Microsoft Windows and is allowed to install software\nupdates; addons.mozilla.org and chrome.google.com, recognized by their corre-\nsponding browsers and given special privileges to install extensions or themes;\nor www.macromedia.com, which is allowed to reconfigure Adobe Flash.\nThe designs of these mechanisms vary and, as a rule, are not documented\nin a satisfactory way. Some features require second-level verification, such as\na cryptographic signature or user consent, but others do not. Broadly speak-\ning, the proliferation of such privileged domains is troubling, because it is\nclear that they will not be immune to the usual security problems that plague\nthe rest of the modern Web. Case in point: http://xssed.com/ lists six publicly\nreported XSS vulnerabilities in addons.mozilla.org.1\nForm-Based Password Managers\nSurprised? Don’t be. Mentioning password managers may seem out of place,\nbut it is very useful to consider this technology as an indirect form of a site-\nbound privilege. Before we explain, let’s briefly review why password manage-\nment is implemented in modern browsers to begin with and how it actually\noperates.\nThe answer to the first question is fairly simple: Today, almost every\nmajor website requires, or at least strongly encourages, all visitors to open an\naccount. Logging in is typically necessary in order to customize the appear-\nance of the site and is a prerequisite for interacting with other registered\nusers. Unfortunately, these site-specific authentication systems are not syn-\nchronized (save for several limited-scale “federated login” experiments, such\nas OpenID),2 and they effectively force the general population to create and\nmemorize several dozen robust passwords, one for every destination fre-\nquented. This approach is difficult to sustain and leads to rampant and dan-\ngerous password reuse; that’s where browser vendors decided to step in.\nForm-based password managers are an inelegant but pragmatic solution\nto the problem of coping with the proliferation of per-site credentials. They\napply simple heuristics to detect the submission of normal-looking login\nforms (the browser looks for an <input type=password> field and then perhaps\nexamines the names of form fields for strings such as user and pass). When a\nsuitable form is detected, the browser will offer to save the associated login\nExtrinsic Site Privileges 227\ninformation in a persistent store on the hard drive,* and if the user consents,\nit will then automatically retrieve and paste this data into matching forms\nencountered later on. In Firefox, Chrome, and Safari, the process of retriev-\ning a stored password is automatic; in Internet Explorer and Opera, an addi-\ntional user gesture may be required to confirm the intent.\nThe design of password managers is fragile but has one clear benefit:\nItworks right away even without official support (or, for that matter, informed\nconsent) from any websites. Web applications that are unhappy about this\nfeature may opt out by appending a poorly named autocomplete=off parameter\nto the offending password field,† but beyond that, the process is almost com-\npletely seamless.\nThe primary way that every in-browser password manager protects stored\ndata is by tying the credentials to the SOP origin where they were originally\nentered—paying close attention to the hostname, protocol, and port. Some\nbrowsers also consider secondary indicators, such as the ordering or naming\nof form fields, the URL path to the form, or the address to which the creden-\ntials are sent. (As we know from Chapter 9, such scoping measures are not\nparticularly useful from the security standpoint due to the operation of the\nsame-origin policy.)\nIn browsers that autocomplete login forms without the need for human\ninteraction, it is sensible to look at the mechanism as a form of a privileged\nAPI: Any content executing in the appropriate origin will be able to request\nbrowser-stored credentials by constructing a believable-looking form and\nthen waiting for it to be automatically populated with login data. In order to\nread back this information, the script merely needs to examine the value\nproperty of the DOM element associated with the password field.\nNOTE Removing the ability to inspect values of password fields may seem like a simple way to\nimprove the scheme, but it is not a very good one. The data could still be stolen by, say,\nwaiting for password autocompletion, changing the data submission method from\nPOST to GET, and then calling submit() on the login form. These steps would result\nin navigation to a page that has the password plainly visible in the location.search\nstring. (Plus, many web applications have legitimate uses for reading back these fields\non the client side, for example, to advise on password strength.)\nAs should be clear, the most serious risk associated with password managers\nis the amplification of XSS bugs. In web applications that use httponly cookies,\nasuccessful exploitation of an XSS flaw may give the attacker only transient\naccess to a user’s account, but if the same vulnerability can be leveraged to\nsteal a user’s password, the consequences are more dire and longer-lived.‡\n* This data may be stored on disk as a plaintext representation, a naïvely obfuscated string, or a\nproperly encrypted value protected with a “master” password that needs to be entered before-\nhand. All three methods are comparably vulnerable to determined attackers with access to the\nlocal system, but the plaintext approach is sometimes frowned upon, as it is more exposed to\nnosy but nontechnical users.\n† Despite the name, this stops the browser from recording the password and not just from\nautocompleting it.\n‡ Such consequences may extend beyond the affected application: Even with password managers\nin place, password reuse is a common, unfortunate trend.\n228 Chapter 15"
  },
  {
    "input": "Internet Explorer’s Zone Model",
    "output": "More obscure side effects are possible, too. For example, any application that\nallows users to construct custom form-based surveys must carefully restrict the\nlayout of the generated forms or risk doubling as apassword-harvesting tool.\nInternet Explorer’s Zone Model\nInternet Explorer’s zone model3 is a proprietary attempt to reconcile the dif-\nferent security requirements that users (or system administrators) may have\nfor different types of web applications, for example, a banking page and an\nonline game. Microsoft’s approach is to establish several predefined classes\nof websites—known as zones—each with its own set of configurable security\npermissions. The five supported zones are these:\n My computer (aka local machine) This hidden zone is used for all local\nfile: resources (with one exception—more about it soon). The user can-\nnot add or remove any elements from this set and cannot change its\nsecurity settings through the normal user interface. Administrators and\ndevelopers can modify the registry or use urlmon.dll hooks to override\nsettings, however.\n Local intranet This zone is meant to include trusted applications on a\nuser’s local network. By default, local intranet enjoys many problematic\nprivileges, such as unrestricted access to the system clipboard, the ability\nto open windows without an address bar, or the ability to bypass the usual\nframe navigation security checks (the descendant policy, outlined in\nChapter 11). Members of this set are detected automatically using several\nconfigurable heuristics, and they may include destinations with non–fully\nqualified hostnames, addresses on the HTTP proxy exemption list,* or\nremote file: URLs accessed over SMB. Manual inclusion of sites in this\nzone is also possible (in addition to or instead of the built-in heuristics).\nNOTE The local intranet zone makes an implicit connection between a local net-\nwork and a trusted environment. This connection is often dubious in the\nmodern-day environment, especially given the prevalence of public Inter-\nnet access over unencrypted Wi-Fi: Other uses of the network are not any\nmore trustworthy than a random website hosted across the globe.\n Trusted sites These are nominally empty zones roughly equivalent to\nlocal intranet in terms of their security settings but managed solely by the\nuser. Autodetection heuristics are unavailable, and all entries have to be\ncreated by hand.\n Restricted sites In these nominally empty zones, the user may add\n“untrusted” destinations. The default settings for these zones remove\nmany rudimentary and generally harmless capabilities from the loaded\ncontent (for example, Refresh headers will not work) while offering lim-\nited security benefits.\n* In configurations where a proxy is required to access protected internal systems but not\nrequired to access the Internet, these may have the unintended and scary effect of classifying\ntheentire Web as a local network.\nExtrinsic Site Privileges 229\nThe practicality of this zone seems unclear. Because of the need to\nwhitelist every untrusted site, the zone obviously can’t be relied upon as\nan alternative to browsing the Internet with sensible default settings for\npreviously unseen destinations.\n Internet This is a default zone for sites not included in any of the\nremaining categories. Its default settings match the general browser\nsecurity model baseline discussed previously in this book.\nThe concept of zones, coupled with some of their security controls, seems to\nbe a step in the right direction. For example, it allows system administrators to\nfine-tune the permissions for file: documents without affecting the security\nor convenience of normal browsing—or to prohibit Internet sites from navi-\ngating to local, corporate systems (using the setting named “Websites in less\nprivileged web content zone can navigate into this zone”). Unfortunately, the\nactual implementation of the zone model is muddied by a lack of focus, and\nin practice, it is misused more often than it is genuinely benefited from.\nThe first problem evident to anyone trying to master the zone mecha-\nnism is its obtuse terminology and the almost-comical complexity of many\nofthe settings. Every zone comes with over 100 checkboxes; some of these\nwill alter the browser security model profoundly, while others have no secu-\nrity consequences whatsoever. (The aforementioned Refresh setting is one\nexample of a security no-op; the ability to disable form submission is another.)\nThese two classes of settings are not distinguished in any clear way, and many\nare nearly impossible to comprehend at a glance. For example, the option\n“Binary and script behaviors” can be set to “enable” or “disable,” but the help\nsubsystem offers no information about what either setting will actually do.\nThe only explanation is provided in the official developer documentation\nposted on Microsoft’s site—but even this document can confuse.4 See for\nyourself:\nInternet Explorer contains dynamic binary behaviors: components\nthat encapsulate specific functionality for HTML elements to which\nthey were attached. These binary behaviors are not controlled by\nany Internet Explorer security setting, allowing them to work on\nWeb pages in the Restricted Sites zone. In Windows Server 2003\nService Pack 1, there is a new Internet Explorer security setting for\nbinary behaviors. This new setting disables binary behaviors in the\nRestricted Sites zone by default. In combination with the Local\nMachine Lockdown security feature, it also requires administrative\napproval for binary behaviors to run in the Local Machine zone by\ndefault. This new binary behaviors security setting provides a general\nmitigation to vulnerabilities in Internet Explorer binary behaviors.\nThere are many similar cases of settings that require a substantial effort\nto understand. For example, it is unlikely that even the most seasoned admin-\nistrators will understand the implications of tweaking settings named “Access\ndata sources across domains” or “Navigate windows and frames across differ-\nent domains”. All this confusion has an interesting consequence: Trusted\nparties unintentionally dispense dubious advice. For example, Charles Schwab,\na prominent investment bank, tells customers to disable the frame navigation\n230 Chapter 15"
  },
  {
    "input": "Mark of the Web and Zone.Identifier",
    "output": "descendant model,5 essentially making HTML frames unsafe to use not only\nfor Charles Schwab but also for any other website. One of the sites main-\ntained by the Internal Revenue Service provides the same, extremely incon-\nsiderate tip.6\nThe complexity and poor documentation of Internet Explorer’s zone\nsettings aside, the other problem with the zone model is the clustering of\nunrelated permissions. The settings for local intranet and trusted sites containers\nenable a random collection of features that may be required by some trusted\nsites—but none of the trusted sites could possibly require all of the permissions\nthe zone entails. Because of this design, adding sites to privileged zones can\nonce more have unexpectedly far-ranging consequences in the case of, say,\natrivial XSS flaw.\nMark of the Web and Zone.Identifier\nTo maintain the integrity of the zone model on downloaded files, Internet\nExplorer further utilizes two overlapping mechanisms to track the original\nzone information for any externally retrieved document:\n Mark of the Web (MotW) This simple pseudo-HTML tag is inserted at\nthe beginning of HTML documents downloaded via Internet Explorer\nto indicate their initial source.7 One example of a MotW tag may be\n<!-- saved from url=(0024)http://fuzzybunnies.com/ -->. The URL recorded in\nthis tag is mapped to an appropriate zone; the document is then opened\nin a unique origin in that zone. The most important consesequence is\nthat the downloaded content is isolated from other file:URLs.\nNOTE The inline nature of MotW is one of its flaws. Faux tags can be pre-\ninserted by rogue parties into HTML documents downloaded through\nnon–Internet Explorer browsers, saved from email clients, or downloaded\nby Internet Explorer with a non-HTML extension (and then subjected to\ncontent sniffing). Though, to be fair, the privileges of file: documents\nsaved without any MotW tags are significant enough to keep attackers\nrelatively uninterested in hopping from the My Computer zone to, say,\nLocal Intranet.\n Alternate Data Stream (ADS) Zone Identifier This is a piece of NTFS\nmetadata attached by Internet Explorer (and Chrome) to every down-\nloaded file, indicating the numerical code of the zone the file was\nretrieved from.8 The Zone.Identifier mechanism is less portable than\nMotW, and the information is lost when files are saved to non-NTFS\nfilesystems. However, it is also more versatile, as it can be applied to\nnon-HTML documents.\nZone.Identifier metadata is recognized by Internet Explorer itself, by\nthe Windows GUI shell, and by some other Microsoft products, but third-\nparty software almost universally ignores it. Where it is supported, it may\nresult in a more restrictive security policy being applied to the docu-\nment; more commonly, it just pops up a security warning about the\nunspecified risks of opening Internet-originating data.\nExtrinsic Site Privileges 231"
  },
  {
    "input": "When Writing Plug-ins or Extensions That Recognize Privileged Origins",
    "output": "Security Engineering Cheat Sheet\nWhen Requesting Elevated Permissions from Within a Web Application\nKeep in mind that requesting access to geolocation data, video or microphone feeds, and other\nprivileged APIs comes with responsibility. If your site is prone to XSS vulnerabilities, you are\ngambling not only with the data stored in the application but with the privacy of your users.\nPlan accordingly and compartmentalize the privileged functionality well. Never ask your users\nto lower their Internet Explorer security settings to accommodate your application, and do\nnot blindly follow this advice when given by others—no matter who they are.\nWhen Writing Plug-ins or Extensions That Recognize Privileged Origins\nYou are putting your users at elevated risk due to inevitable web application security bugs.\nDesign APIs robustly and try to use secondary security measures, such as cryptography, to fur-\nther secure communications with your server. Do not whitelist nonencrypted origins, as they\nare prone to spoofing on open wireless networks.\n232 Chapter 15"
  },
  {
    "input": "PART III: A Glimpse of Things to Come\r",
    "output": "PART III\nA G L I M P S E O F T H I N G S\nT O C O M E\nFollowing nearly a decade of stagnation, the world of\nbrowsers is once more a raging battlefield. In a man-\nner all too reminiscent of the First Browser Wars in the\nlate 1990s, vendors compete by bringing new features\nto market monthly. The main difference is that secu-\nrity is now seen as a clear selling point.\nOf course, objectively measuring the robustness of any sufficiently\ncomplex piece of software is an unsolved problem in computing, doubly so\nifyour codebase happens to carry almost two decades worth of bloat. There-\nfore, much of the competitive effort goes into inventing and then rapidly\ndeploying new security-themed additions, often with little consideration for\nhow well they actually solve the problem they were supposed to address.\nIn the meantime, standards bodies, mindful of their earlier misadventures,\nhave ditched much of their academic rigor in favor of just letting a dedicated\ngroup of contributors tweak the specifications as they see fit. There is talk of\nmaking HTML5 the last numbered version of the standard and transitioning\nto a living document that changes every day—often radically. The relaxation\nof the requirement has helped keep ongoing much of the work around W3C\nand WHATWG, but it has also undermined some of the benefits of having a\ncentral organization to begin with. Many recent proposals gravitate toward\nquick, narrowly scoped hacks that do not even try to form a consistent and\nwell-integrated framework. When this happens, no robust feedback mecha-\nnism is in place to allow external experts to review reasonably stable specifi-\ncations and voice concerns before any implementation work takes place. The\nonly way to stay on top of the changes is to immerse oneself in the day-to-day\ndynamics of the working group.\nIt is difficult to say if this new approach to standardization is a bad thing.\nIn fact, its benefits may easily outweigh any of the speculative risks; for one,\nwe now have a chance at a standard that is reasonably close to what browsers\nactually do. Nevertheless, the results of this frantic and largely unsupervised\nprocess can be unpredictable, and they require the security community to be\nvery alert.\nIn this spirit, the last part of the book will explore some of the more plau-\nsible and advanced proposals that may shape the future of the Web . . . or that\nmay just as likely end up in the dustbin of history a few years from now.\n234 Part III"
  },
  {
    "input": "16: New and Upcoming Security Features\r",
    "output": "N E W A N D U P C O M I N G\nS E C U R I T Y F E A T U R E S\nYou will soon find out that there is little rhyme and rea-\nson to how all the new browser features mesh, but we\nstill need to organize the discussion in some way. Per-\nhaps the best approach is to look at their intended\npurposes and begin with all the mechanisms created\nspecifically to tweak the Web’s security model for a\nwell-defined gain.\nThe dream of inventing a brand-new browser security model is strong\nwithin the community, but it is always followed by the realization that it would\nrequire rebuilding the entire Web. Therefore, much of the practical work\nfocuses on more humble extensions to the existing approach, necessarily\nincreasing the complexity of the security-critical sections of the browser\ncodebase. This complexity is unwelcome, but its proponents invariably see it\nasjustified, whether because they aim to mitigate a class of vulnerabilities,"
  },
  {
    "input": "Cross-Domain Requests",
    "output": "build a stopgap for some other hard problem that nobody wants to tackle\nright now,* or simply enable new types of applications to be built in the\nfuture. All these benefits usually trump the vague risk.\nSecurity Model Extension Frameworks\nSome of the most successful security enhancements proposed in the past few\nyears boil down to adding flexibility to the original constraints imposed by the\nsame-origin policy and its friends. For example, one formerly experimental\nproposal that has now crossed into the mainstream is the postMessage(...) API\nfor communicating across origins, discussed in Chapter 9. Surprisingly, the\nact of relaxing SOP checks in certain carefully chosen scenarios is more intu-\nitive and less likely to cause problems than locking the policy down. So, to\nbegin on a lighter note, we’ll focus on this class of frameworks first.\nCross-Domain Requests\nUnder the original constraints of the same-origin policy, scripts associated\nwith one origin have no clean and secure way to communicate with client-\nside scripts executing in any other origin and no safe way to retrieve poten-\ntially useful data from a willing third-party server.\nWeb developers have long complained about these constraints, and\ninrecent years, browser vendors have begun to listen to their demands. As\nyou recall, the more pressing task of arranging client-side communications\nbetween scripts was solved with postMessage(...). The client-to-server scenario\nwas found to be less urgent and still awaits a canonical solution, but there\nhasbeen some progress to report.\nThe most successful attempt to create a method for retrieving docu-\nments from non-same-origin servers began in 2005. Under the auspices of\nW3C, several developers working on VoiceXML, an obscure document for-\nmat for building Interactive Voice Response (IVR) systems, drafted a pro-\nposal for Cross-Origin Resource Sharing (CORS).1 Between 2007 and 2009, their\nawkward, XML-based design gradually morphed into a much simpler and\nmore widely useful scheme, which relied on HTTP header–level signaling\ntocommunicate consent to cross-origin content retrieval using a natural\nextension of theXMLHttpRequest API.\nCORS Request Types\nAs specified today, CORS relies on differentiating between two types of calls\nto the XMLHttpRequest API. When the site attempts to load a cross-origin doc-\nument through the API, the browser first needs to distinguish between simple\nrequests, where the resulting HTTP traffic is deemed close enough to what\n* Malicious URL blacklists, a feature supported by (and usually enabled in) all modern browsers,\nare a prime example of this trend. The blacklist is a lightweight, crude substitute for an antivirus,\nwhich is, in turn, a poor substitute for up-to-date and well-designed software. Antimalware fea-\ntures do not make individual attacks any more difficult; they are simply meant to stop the large-\nscale distribution of unsophisticated malware, based on the assumption that most users are not\ninteresting enough to be specifically targeted or attacked with something clever.\n236 Chapter 16\ncan be generated through other, existing methods of navigation, and non-\nsimple requests, which encompass everything else. The operation of these two\nclasses of requests vary significantly, as we’ll see.\nThe current specification says that simple requests must have a method\nof GET, POST, or HEAD. Additionally, if any custom headers are specified\nby the caller, they must belong to the following set:\n Cache-Control\n Content-Language\n Content-Type\n Expires\n Last-Modified\n Pragma\nToday, browsers that support CORS simply do not allow methods other\nthan GET, POST, and HEAD. At the same time, they ignore the recom-\nmended whitelist of headers, unconditionally demoting any requests with\ncustom header values to non-simple status. The implementation in WebKit\nalso considers any payload-bearing requests to be non-simple. (It is not clear\nwhether this is an intentional design decision or a bug.)\nSecurity Checks for Simple Requests\nThe CORS specification allows simple requests to be submitted to the desti-\nnation server immediately, without attempting to confirm whether the des-\ntination is willing to engage in cross-domain communications to begin with.\nThis decision is based on the fact that the attacker may initiate fairly similar\ncookie-authenticated traffic by other means (for example, by automatically\nsubmitting a form) and, therefore, that there is no point in introducing an\nadditional handshake specifically for CORS.*\nThe crucial security check is carried out only after the response is\nretrieved from the server: The data is revealed to the caller through the\nXMLHttpRequest API only if the response includes a suitable, well-formed\nAccess-Control-Allow-Origin header. To assist the server, the original request\nwill include a mandatory Origin header, specifying the origin associated\nwiththe calling script.\nTo illustrate this behavior, consider the following cross-domain\nXMLHttpRequest call performed from http://www.bunnyoutlet.com/:\nvar x = XMLHttpRequest();\nx.open('GET', 'http://fuzzybunnies.com/get_message.php?id=42', false);\nx.send(null);\n* That assumption is not completely correct. For example, prior to the introduction of this\nscheme, attackers would not have been able to initiate a cross-domain request completely\nindistinguishable from the submission of a file upload form, but under CORS, such forgery\nispossible.\nNew and Upcoming Security Features 237\nThe result will be an HTTP request that looks roughly like this:\nGET /get_message.php?id=42 HTTP/1.0\nHost: fuzzybunnies.com\nCookie: FUZZYBUNNIES_SESSION_ID=EA7E8167CE8B6AD93D43AC5AA869A920\nOrigin: http://www.bunnyoutlet.com\nTo indicate that the response should be readable across domains, the\nserver needs to respond with\nHTTP/1.0 200 OK\nAccess-Control-Allow-Origin: http://www.bunnyoutlet.com\nThe secret message is: \"It's a cold day for pontooning.\"\nNOTE It is possible to use a wildcard (“*”) in Access-Control-Allow-Origin, but do so with\ncare. It is certainly unwise to indiscriminately set Access-Control-Allow-Origin: *\non all HTTP responses, because this step largely eliminates any assurances of the same-\norigin policy in CORS-compliant browsers.\nNon-simple Requests and Preflight\nIn the early drafts of the CORS protocol, almost all requests were meant to\nbe submitted without first checking to see if the server was actually willing to\naccept them. Unfortunately, this design undermined an interesting property\nleveraged by some web applications to prevent cross-site request forgery:\nPrior to CORS, attackers could not inject arbitrary HTTP headers into cross-\ndomain requests, so the presence of a custom header often served as a proof\nthat the request came from the same origin as the destination and was issued\nthrough XMLHttpRequest.\nLater CORS revisions corrected this problem by requiring a more com-\nplicated two-step handshake for requests that did not meet the strict “simple\nrequest” criteria outlined in “CORS Request Types” on page236. The hand-\nshake for non-simple requests aims to confirm that the destination server is\nCORS compliant and that it wants to receive nonstandard traffic from that par-\nticular caller. The handshake is implemented by sending a vanilla OPTIONS\nrequest (“preflight”) to the target URL containing an outline of the parame-\nters of the underlying XMLHttpRequest call. The most important information\nis conveyed to the server in three self-explanatory headers: Origin, Access-\nControl-Request-Method, and Access-Control-Request-Headers.\nThis handshake is considered successful only if these parameters are\nproperly acknowledged in the response through the use of Access-Control-\nAllow-Origin, Access-Control-Allow-Method, and Access-Control-Allow-Headers. Fol-\nlowing a correct handshake, the actual request is made. For performance\nreasons, the result of the preflight check for a particular URL may be cached\nby the client for a set period of time.\n238 Chapter 16"
  },
  {
    "input": "XDomainRequest",
    "output": "Current Status of CORS\nAs of this writing, CORS is available only in Firefox and WebKit-based brows-\ners and is notably absent in Opera or Internet Explorer. The most important\nfactor hindering its adoption may be simply that the API is not as critical as\npostMessage(...), its client-side counterpart, because it can be often replaced\nby a content-fetching proxy on the server side. But the scheme is also facing\nthree principal, if weak, criticisms, some of which come directly from one of\nthe vendors. Obviously, these criticisms don’t help matters.\nThe first complaint, voiced chiefly by Microsoft developers and echoed\nby some academics, is that the scheme needlessly abuses ambient authority.\nThey argue that there are very few cases where data shared across domains\nwould need to be tailored based on the credentials available for the destina-\ntion site. The critics believe that the risks of accidentally leaking sensitive\ninformation far outweigh any benefits and that a scheme permitting only\nnonauthenticated requests to be made would be preferable. In their view,\nany sites that need a form of authentication should instead rely on explicitly\nexchanged authentication tokens.*\nThe other, more pragmatic criticism of CORS is that the scheme is need-\nlessly complicated: It extends an already problematic and error-prone API\nwithout clearly explaining the benefits of some of the tweaks. In particular, it\nis not clear if the added complexity of preflight requests is worth the periph-\neral benefit of being able to issue cross-domain requests with unorthodox\nmethods or random headers.\nThe last of the weak complaints hinges on the fact that CORS is suscep-\ntible to header injection. Unlike some other recently proposed browser fea-\ntures, such as WebSockets (Chapter 17), CORS does not require the server to\necho back an unpredictable challenge string to complete the handshake. Par-\nticularly in conjunction with preflight caching, this may worsen the impact of\ncertain header-splitting vulnerabilities in the server-side code.\nXDomainRequest\nMicrosoft’s objection to CORS appears to stem from the aforementioned\nconcerns over the use of ambient authority, but it also bears subtle overtones\nof their dissatisfaction with interactions with W3C. In 2008, Sunava Dutta, a\nprogram manager at Microsoft, offered this somewhat cryptic insight:2\nDuring the [Internet Explorer 8] Beta 1 timeframe there were\nmany security based concerns raised for cross domain access of\nthird party data using cross site XMLHttpRequest and the Access\nControl framework. Since Beta 1, we had the chance to work with\nother browsers and attendees at a W3C face-to-face meeting to\nimprove the server-side experience and security of the W3C’s\nAccess Control framework.\n* The same claim can be made about the use of HTTP cookies in any other setting and seems\nequally futile. It is true that ambient credentials cause problems more frequently than some\nother forms of explicit authentication would, but they are also a lot more convenient to use\nandare simply not going away.\nNew and Upcoming Security Features 239"
  },
  {
    "input": "Other Uses of the Origin Header",
    "output": "Instead of embracing the CORS extensions to XMLHttpRequest, Micro-\nsoft decided to implement a counterproposal, dubbed XDomainRequest.3 This\nremarkably simple, new API differs from the variant available in other brows-\ners in that the resulting requests are always anonymous (that is, devoid of any\nbrowser-managed credentials) and that it does not allow for any custom HTTP\nheaders or methods to be used.\nThe use of Microsoft’s API is otherwise very similar to XMLHttpRequest:\nvar x = new XDomainRequest();\nx.open(\"GET\", \"http://www.fuzzybunnies.com/get_data.php?id=1234\");\nx.send();\nBorrowing from W3C’s proposal, the resulting request will bear an Origin\nheader, and the response data will be revealed to the caller only if a match-\ning Access-Control-Allow-Origin header is present in the response.* Preflight\nrequests and permission caching are not a part of the design.\nFor all intents and purposes, Microsoft’s solution is far more reasonable\nthan CORS: It is simpler, safer, and probably just as functional in all the plau-\nsible uses. That said, it is also unpopular. It is supported only in Internet\nExplorer 8 and up, and owing to W3C backing CORS, others have no reason\nto embrace XDomainRequest anytime soon.\nIn the meantime, a separate group of researchers have proposed a third\nsolution, again acting under the auspices of W3C. Their design, known as Uni-\nform Messaging Policy (complete with a corresponding UniformRequest API),4\nembraces an approach nearly identical to Microsoft’s. It is not supported in\nany existing browser, but there is some talk of unifying it with CORS.\nOther Uses of the Origin Header\nThe Origin header is an essential part of CORS, XDomainRequest, and UMP,\nbut it actually evolved somewhat independently with other uses in mind. In\ntheir 2008 paper, Adam Barth, Collin Jackson, and John C. Mitchell5 advo-\ncated the introduction of a new HTTP header that would offer a more reli-\nable and privacy-conscious alternative to Referer. It would also serve as a way\ntoprevent cross-site request vulnerabilities by providing the server with the\ninformation needed to identify the SOP-level origin of a request, without\ndisclosing the potentially more sensitive path or query data.\nOf course, it was unclear whether the subtle improvement between\nReferer and its proposed successor would actually make a difference for the\nsmall but nonnegligible population of users who block that first header on\nprivacy grounds. The proposal consequently ended up in a virtual limbo,\nnot being deployed in any existing browsers but also discouraging others\nfrom pursuing other solutions such as XSRF or XSSI.6 (To be fair, the con-\ncept was very recently revived under the new name of From-Origin and may\nnot be completely dead yet.)7\n* The reason for this check, even if the response is not authenticated, is to prevent the use of the\nbrowser as a proxy (for example, to crawl internal networks or send out spam).\n240 Chapter 16"
  },
  {
    "input": "Security Model Restriction Frameworks",
    "output": "The fate of the original idea aside, the utility of the Origin header in spe-\ncialized cases such as CORS was pretty clear. Around 2009, this led to Barth\nsubmitting an IETF draft specifying the syntax of the header,8 while shying\naway from making any statements about when the header should be sent, or\nwhat specific security problems it might solve:\nThe user agent MAY include an Origin header in any HTTP\nrequest.\n[…]\nWhenever a user agent issues an HTTP request from a “privacy-\nsensitive” context, the user agent MUST send the value “null” in\nthe Origin header.\nNOTE: This document does not define the notion of a privacy-\nsensitive context. Applications that generate HTTP requests can\ndesignate contexts as privacy-sensitive to impose restrictions on\nhow user agents generate Origin headers.\nThe bottom line of this specification is that whatever the decision pro-\ncess is, once the client chooses to provide the header, the value is required to\naccurately represent the SOP origin from which the request is being made.\nFor example, when a particular operation takes place from http://www\n.bunnyoutlet.com:1234/bunny_reports.php, the transmitted value should be\nOrigin: http://www.bunnyoutlet.com:1234\nFor origins that do not meaningfully map to a protocol-host-port tuple,\nthe browser must send the value of null instead.\nDespite all of these plans, as of this writing only one browser includes the\nOrigin header on non-CORS navigation: WebKit-based implementations send\nit when submitting HTML forms. Firefox seems to be considering a different\napproach, but nothing specific seems to have been implemented yet.\nSecurity Model Restriction Frameworks\nDesigns that extend the bounds of the same-origin policy are fairly simple to\nunderstand and typically fail securely. If the proposed change is not accounted\nfor in one of the possible code paths, or is simply not supported in a particu-\nlar browser, the previously implemented, more restrictive logic will kick in.\nCompared with this, it is far more dangerous to try to erect new boundaries\non top of the existing browser security model. That’s because every security-\nsensitive code path must be tweaked to recognize the new scheme and every\nbrowser must comply right away, or unexpected problems will arise.\nIn this section, we will take a quick look at some of the more accomplished\nattempts to take this dangerous but potentially rewarding path—and explore\nwhere they come apart.\nNew and Upcoming Security Features 241"
  },
  {
    "input": "Content Security Policy",
    "output": "Content Security Policy\nContent Security Policy (CSP) is an unusually comprehensive security frame-\nwork first proposed by Brandon Sterne of Mozilla in 2008.9 The framework\nwas originally envisioned as an all-encompassing way to mitigate the impact\nof common web vulnerabilities, from XSRF to XSS, and as a tool for website\nowners to perform a variety of non-security content-policing tasks.\nIn the years that followed, CSP evolved rapidly, and on several occasions,\nits scope changed in major ways. (For example, the author quickly abandoned\nthe plan to address XSRF vulnerabilities, delegating the job to the yet unreal-\nized extensions of the Origin header.) In fact, as of this writing, the canonical\nMozilla specification is being rewritten as a W3C draft,10 resulting in substantial\ndifferences in the implementation shipped in Firefox and the partial support\nimplemented in WebKit by Adam Barth. (Internet Explorer and Opera do not\nsupport CSP and have not announced any specific plans to embrace it.)\nPrimary CSP Directives\nAt its core, Sterne’s design permits site owners to specify per-document poli-\ncies that constrain the ability of the subject document to perform actions that\nwould normally be permitted under the same-origin policy. For example, CSP\nmay prevent a page from loading any external subresources except for images\nand restrict image sources to only a set of trusted origins, like so:\nX-Content-Security-Policy: default-src 'none'; img-src http://*.example.com\nAs should be evident from this example, the policies may be encoded in\nan HTTP header. Under the W3C draft, it is also possible to embed them in\nthe document itself (using <meta> tags) or host the policy at an external URL\nand point to it with policy-uri.\nFor every content source directive, the author of the policy may specify\nany number of fully qualified origins or wildcard expressions that match mul-\ntiple hosts, protocols, or ports. Three special keywords (none, self, and data:)\ncorrespond to an empty set, the origin associated with the policy-bearing\npage, or all inline data: URLs, in corresponding order.\nAs of today, the following behaviors can be controlled with CSP directives:\n Script execution A script-src directive can be used to specify the proto-\ncol, host, and port for permissible <script src=...> URLs. Normally, the CSP\ndisables the ability to embed scripts inline in the document (whether\nthrough standalone <script> blocks or via event handlers) and of existing\nscripts to carelessly pass strings to functions such as eval(...), setTimeout(...),\nsetInterval(...), and so on. Because of this, the script-src directive is useful\nfor limiting the impact of XSS vulnerabilities: Any markup injected by\nthe attacker will be limited to loading scripts legitimately hosted in one\nof the approved origins.*\n* CSP offers several ways to shoot yourself in the foot here. For one, it is possible to re-enable script\nexecution with settings such as inline-script (Mozilla’s naming, changed to disable-xss-protection in\nW3C draft) or eval-script. Perhaps less obviously, it is also possible to make the mistake of permit-\nting data: or * as a permissible origin or allowing an HTTP origin on an HTTPS site.\n242 Chapter 16\n Plug-in content This is controlled through object-src. Because plug-ins\nsuch as Java or Flash may have unconstrained access to the embedding\npage, the directive should be considered largely analogous to script-src,\nand the two directives must be restricted in a comparable way to achieve\nany security benefits.\n Stylesheets and fonts This is controlled by style-src and font-src. Unlike its\nhandling of scripts, CSP originally did not prevent inline <style> blocks\nor style= parameters from appearing on the page. Therefore, any attacker\nexploiting an XSS flaw could dramatically alter the appearance and func-\ntion of the vulnerable page (or worse),* and these two directives only served\nnonsecurity goals, with the possible exception of limiting mixed-content\nbugs. Only moments before the publication of the book, the specifica-\ntions have been amended to include a more robust approach to CSS.\n Passive multimedia Directives such as img-src or media-src control the\nability to embed multimedia content from specific origins. As with the\noriginal design of CSS controls, this could not have been considered a\nsecurity feature. For example, in the case of an XSS bug, CSP would not\nhave prevented the attacker from leveraging stylesheets to draw arbitrary\nshapes on the vulnerable page or even animating them to some extent.\n Subframes The frame-src directive specifies the acceptable destinations\nfor any <iframe> tags encountered on the page; the policy of the parent\npage is not inherited by the framed document. To preserve the value of\nother XSS mitigations, steps must be taken not to allow data: URLs here\n(see Chapter 10).\n Default policy Known as default-src in the W3C draft, and under a more\ncryptic name (allow) in Mozilla documentation, the directive specifies fall-\nback behavior for any content not covered by a more specific directive.\nThe directive is required, even in cases where it is technically unnecessary.\nNOTE It may be unfortunate that CSP directives are selected to map very closely to individual\nHTML tags, instead of grouping functionally similar behaviors. Because of this, it is dif-\nficult to appreciate the tricky interactions among settings such as script-src, frame-src,\nand object-src. Also, the approach is simply not very future-safe: There already are\nsome peripheral classes of subresources (such as “favicons”) that are excluded from\nCSPaltogether, and that list will probably unintentionally grow.\nIn an unusual departure from the subresource-driven model outlined thus\nfar, CSP also features an oddball directive called frame-ancestors. This parameter\nis meant to mitigate the impact of clickjacking by specifying the allowed ances-\ntors for the current document in a manner similar to the better-established\nX-Frame-Options header (outlined in Chapter 11). The frame-ancestors logic is\ncompletely independent of default-src or any other parts of CSP; its default\nvalue is “*”.\n* Remember advanced selectors in CSS3? By cleverly leveraging them in injected stylesheets,\nsome information about the strings appearing on the page may be conveniently relayed to a\nthird-party server without the use of JavaScript.\nNew and Upcoming Security Features 243\nMany other possible extensions of the policy are being discussed as of\nthis writing. These include a script-nonce directive that could be used to more\nsecurely embed inline scripts (every script block must begin with a policy-\nspecified, unpredictable token, often making XSS exploitation harder) and\nasandbox directive, which offers an alternative interface to another security\nmechanism, discussed in “Sandboxed Frames” on page245.\nPolicy Violations\nThe policy specified according to these rules constrains the behavior of the\nunderlying document. Violations normally result in a failed subresource load,\nthe failure to execute an inline script, or the inhibition of page rendering\n(inthe special case of frame-ancestors).\nBecause CSP controls a wide range of content behaviors, and because the\ndefault failure mode is fairly brutal, the authors perceived a need to ease the\nworries of webmasters. To make CSP more user-friendly, and perhaps also in\na naïve attempt to offer exploit detection, an optional feature of CSP allows\nthe browser to report all policy violations immediately back to the owner of the\nsite. This feature can be enabled through the report-uri keyword in the policy.\nTo further simplify deployment, it is also possible to roll out any policy—or\npart thereof—in a “soft” mode, where violations result only in an HTTP noti-\nfication but do not actually break the page. This is achieved by specifying the\npolicy inside a header named X-Content-Security-Policy-Report-Only.*\nCriticisms of CSP\nCSP is a remarkably sensible and consistent design compared to most of the\none-off security features proposed or deployed in the browser world. Never-\ntheless, from its inception, the proposal has been haunted by recurring\ndesign and implementation concerns.\nPerhaps the most prosaic complaint about CSP is a nonsecurity one: In\norder to benefit from the XSS defenses offered by the framework, webmasters\nhave to move all inline scripts on the page (often hundreds of individual snip-\npets of code) to a separately requested document; in the new drafts of CSP, the\nsame will be required for all stylesheets. The complexity of retrofitting exist-\ning pages to work with CSP and the performance penalty of an additional\nHTTP request are often prohibitive. (It may be possible to resolve this prob-\nlem with the script-nonce extension proposed in the most recent drafts.)\nA more fundamental concern with the design of CSP is that the currently\nenvisioned origin-level granularity of the rulesets may not offer a sufficiently\nrobust defense against XSS. Consider the fact that any complex, real-life\ndomain may well host a dozen largely separate web applications, each consist-\ning of hundreds of possibly unrelated static scripts and JavaScript APIs. Attack-\ners exploiting an XSS vulnerability in a CSP-protected site are prevented from\ndirectly executing a malicious script, but they may be able to put the applica-\ntion into an inconsistent and possibly dangerous state by loading the existing\n* As a side note, this feature is useful not only for short-term experiments but also for detecting\nnoncritical issues on an ongoing basis. For example, the owner of a site may leverage it to detect\nmixed-content issues by creating a report-only policy for HTTPS pages that will be violated by\nany HTTP scripts.\n244 Chapter 16"
  },
  {
    "input": "Sandboxed Frames",
    "output": "scripts in the wrong context or in an incorrect sequence. The history of vul-\nnerabilities in nonweb software suggests that such state corruption condi-\ntions are exploitable more often than we may think.\nAn even more troubling prospect is that an attacker can load a sub-\nresource that is not truly a script but that might be mistaken for one. An\nextreme example of this may be a browser supporting E4X (see Chapter 6):\nAny valid XHTML document in which the attacker can place a nominally\nharmless string—say, {alert(\"Hi mom!\")}—may result in code execution when\nloaded via <script src=...>. Recognizing this problem, the developers decided\nto require whitelisted Content-Type values for any scripts loaded under CSP,\nbut even this approach is often insufficient.\nTo understand what may go wrong, consider the exceedingly common\npractice of hosting public JSONP APIs in which the client can specify the\nname of the callback function:\nGET /store_locator_api.cgi?zip=90210&callback=myResultParser HTTP/1.0\n...\nHTTP/1.0 200 OK\nContent-Type: application/x-javascript\n...\nmyResultParser({ \"store_name\": \"Spacely Space Sprockets\",\n\"street\": … });\nSuch an API anywhere within a CSP-permitted origin may be leveraged\nby an attacker to call arbitrary existing functions in the client-side code, per-\nhaps together with attacker-controlled parameters. And if the callback string\nis not constrained to alphanumerics (and why should it be?), specifying\ncallback=alert(1);// will lead to straightforward code injection.\nIssues with granularity aside, CSP deserves some gentle criticism for its\nsometimes puzzling and detrimental lack of focus. On one hand, through\nthe inclusion of directives such as frame-descendants or sandbox, it seems to be\nflirting with the idea of building a single, unifying browser security frame-\nwork—only to unexpectedly exclude XSRF flaws from its scope without offer-\ning a viable alternative beyond a vague mention of Origin. On the other hand,\nthe proposal often aspires to be just a “Content Policy,” with no special atten-\ntion paid to offering sufficiently robust and intuitive security properties. The\nease of creating dangerous script policies, coupled with the originally ineffec-\ntive policing of stylesheets and images, is a testament to this trend.\nSandboxed Frames\nSandboxed frames11 are an extension of the normal <iframe> behavior.\nTheyallow the owner of the top-level page to place certain additional restric-\ntions on the embedded document along with any of that document’s sub-\nframes. The goal is to make it safer for web applications to embed potentially\nNew and Upcoming Security Features 245\nuntrusted advertisements, gadgets, or preformatted HTML documents on an\notherwise sensitive site. The refinement of the design and the initial imple-\nmentation of this feature in WebKit (which is currently the only engine sup-\nporting it) was driven by Adam Barth.\nNOTE Curiously, sandboxed frames are not exactly a novel idea: Microsoft came up with a\nsimilar proposal almost a decade earlier. Since version 6, Internet Explorer has sup-\nported a proprietary security=restricted parameter, which forces the target frame to be\nrendered in the Restricted Zone, effectively removing its ability to execute scripts, navi-\ngate to other locations, and so on. However, no one seemed interested in using this fea-\nture for anything other than bypassing certain client-side JavaScript security mechanisms\n(most notably, anticlickjacking checks). We will soon know whether the HTML5 succes-\nsor fares any better.\nThe design of sandboxed frames is fairly simple: Any frame embedded in\na document may be constrained by specifying the sandbox parameter on the\nappropriate <iframe> tag. By default, the document subject to this restriction\nis prevented from executing scripts and performing certain types of naviga-\ntions. The permissions may be fine-tuned with one or more whitespace-\ndelimited keywords, specified as a value for the sandbox parameter itself:\n Allow-scripts In the absence of this keyword, the document displayed\ninside the frame will be unable to execute JavaScript code. The primary\nfunction of this feature is to prevent the embedded document from per-\nforming DoS attacks, opening browser dialogs, or employing any other\ncomplex automation of the page.\n Allow-forms When this keyword is absent, any HTML forms encountered\nin the embedded document will not work. This mechanism is designed\nto prevent the framed content from exploiting its placement on a trusted\nwebsite to phish for sensitive information. (Note that with allow-scripts\nenabled, there is little or no point in allow-forms. Scripts may easily con-\nstruct form-like controls and automatically relay the collected informa-\ntion to another site without the need for a functioning <form> tag.)\n Allow-top-navigation This keyword re-enables the ability of the embed-\nded page to navigate the top-level window. This type of navigation is nor-\nmally permitted as one of the exceptions to the same-origin policy (see\nChapter 11), and it may be abused simply to prevent the user from inter-\nacting with the embedding site or to carry out phishing attacks.\n Allow-same-origin Without this flag, the content inside a sandboxed\nframe is assigned a unique, randomly selected, synthetic origin. This\nprevents the page from accessing any origin-bound content that would\nnormally be available to scripts executing in the domain it is nominally\nhosted in. The inclusion of allow-same-origin removes the synthetic origin\nand permits same-origin data access.\n246 Chapter 16\nScripting, Forms, and Navigation\nThe first three restrictions available to sandboxed frames—scripting, forms,\nand navigation—are fairly intuitive and safe to use. Their value is diminished\nonly by the need to also disable all plug-ins whenever the sandbox attribute is\nused, because frameworks such as Flash or Java do not honor the extension\nand would allow any embedded applets to bypass the newly added browser\nchecks. Unfortunately, the three most obvious use cases for sandboxed\nframes—embedded advertisements, videos, and games—rely heavily on\nFlash, thus rendering this security mechanism much less useful than it\nmightotherwise be.\nSynthetic Origins\nThe last mechanism on the list, synthetic origins, is far more problematic and\nis likely misguided. It is envisioned primarily as a way to make it possible for\nuntrusted documents (such as incoming HTML-based emails in a webmail\ninterface) to be served as is, along with the rest of the application, while pre-\nventing these untrusted documents from accessing sensitive data.\nUnfortunately, the concept of synthetic origins creates more problems\nthan it solves. For one, unless the URL of the embedded document is unpre-\ndictable, the attacker may simply navigate to it directly in a new browser win-\ndow, in which case the browser will not see the sandbox attribute at all.\nAs an attempt to work around this problem, the authors of the specification\neventually proposed the use of a specialized MIME type (text/html-sandboxed)\nfor content meant to be shown only in a sandboxed frame. Their reasoning\nisthat browsers will normally not recognize this MIME type and will not dis-\nplay it inline and that a special case may be created in the <iframe> handling\ncode. Of course, as should be clear from Chapter 13, such a defense is inade-\nquate, because some browsers and plug-ins will render text/html-sandboxed\nresponses inline or interpret the returned data in other troubling ways (say,\nas crossdomain.xml).\nThe concept of synthetic origins is also highly problematic given the\nfragmentation of origin- or domain-level security mechanisms in a typical\nbrowser. For example, dangerous interactions are possible with password\nmanagers, which must be explicitly prevented from autocompleting login\nforms in the sandboxed documents. Also, special logic must be added to\nsecurity prompts, such as the one associated with the geolocation API.\nAfter some trial and error, the implementation currently available in\nWebKit resolved many of these issues on a case-by-case basis. That said, future\nimplementations are likely to fall for this trap repeatedly, especially since the\nHTML5 specification considers the behavior of these features to be out of\nscope and does not specify the required behavior in any way.\nNOTE Removing synthetic origins leads to trouble, too: If the user clicks on a same-site link in\na sandboxed advertisement and that link opens in a new window, the browser probably\nshould prevent the unrestricted scripts in the new window from traversing the opener\nobject to perform actions that its parent is prohibited from performing on its own.\nNew and Upcoming Security Features 247"
  },
  {
    "input": "Strict Transport Security",
    "output": "Strict Transport Security\nOne of the most significant weaknesses in the design of HTTPS is that users\noften begin navigation by typing in a protocol-less URL in the address bar\n(such as bankofamerica.com rather than https://www.bankofamerica.com), in\nwhich case the browser will presume HTTP and send the initial request in\nplaintext. Even if the site immediately redirects this traffic to HTTPS, any\nactive attacker on the victim’s network may intercept and modify that initial\nresponse, preventing the user from ever upgrading to a secure protocol. In\nsuch case, the absence of a tiny lock icon in the browser UI will be very easy\nto miss.\nThis problem, as well as several peripheral issues related to mixed con-\ntent and cookie scoping, prompted Jeff Hodges and several other research-\ners to draft a proposal for HTTP Strict Transport Security (HSTS, or STS for\nshort).12 Their approach (currently supported in WebKit and Firefox) allows\nany site on the Internet to instruct the browser that all future requests made\nto a particular hostname or domain should always use HTTPS and that any\nHTTP traffic should be automatically upgraded and submitted only over\nHTTPS.\nThe reasoning behind the design of HSTS is that the user’s first inter-\naction with a particular domain is unlikely to occur over a connection that is\nbeing actively tampered with—but that, over time, as the user roams on open\nwireless networks, the chances of encountering an attacker increase rapidly.\nHSTS is, therefore, an imperfect defense, but in practice it is usually good\nenough.\nThe HSTS opt-in header may appear in HTTPS responses, looking some-\nthing like this:\nStrict-Transport-Security: max-age=3000000; includeSubDomains\nNOTE For HSTS to offer reasonable protection, max-age (the number of seconds that the STS\nrecord may be stored in the browser) must be set to a value substantially higher than the\nusual worst-case time between visits to the site. Because there is no easy way to disable or\noverride HSTS when something goes wrong with the HTTPS site, website owners will be\ntempted to choose a value small enough to minimize disruption when they mess some-\nthing up and have to revert. It is not clear whether this conflict of interests will lead web\nprogrammers to make optimal choices.\nThe negative security consequences of this design are fairly unremarkable:\nThere is a slightly elevated risk of DoS attacks, because an attacker could inject\nthis response header into a domain that is not fully HTTPS enabled. There is\nalso the possibility of using a unique combination of HSTS settings for sev-\neral decoy hostnames to tag a particular instance of a browser, offering yet\nanother alternative to cookie-based user tracking. Neither of these concerns\nis particularly pronounced, however.\n248 Chapter 16"
  },
  {
    "input": "Private Browsing Modes",
    "output": "Unfortunately, as with other restriction-adding frameworks discussed in\nthis section of the book, the mechanism sounds great in principle, but it’s\ndifficult to fully account for how it may interact with other legacy code. In\nparticular, unless the includeSubDomains flag is used, HSTS offers unexpect-\nedly little protection for HTTP cookies: Cookies not marked as secure may still\nbe intercepted simply by inventing a nonexistent subdomain and intercept-\ning the HTTP request made to that destination.* (Even secure cookies could\nbe clobbered in a similar fashion, just not read back.)\nIn a similar vein, the enforcement of HSTS on requests originating from\nplug-in-based content is unlikely to work well.\nPrivate Browsing Modes\nPrivate browsing, colloquially known as the “porn mode,” is a nonstandard-\nized feature available in most up-to-date browsers. It is meant to create a non-\npersistent browsing sandbox, isolated from the main browser session, which\nis completely discarded as soon as the last private browsing window is closed.\nIn a sense, this mechanism can be considered a form of content isolation\nadded on top of the existing browser security paradigms, so it seems fitting to\nbriefly mention it now.\nWith the exception of Chrome, most browser vendors do not accurately\nexplain the security assurances associated with private browsing. Unfortu-\nnately, the intuitive understanding of the term is quite different from what\nbrowsers can actually deliver.\nArguably, the most straightforward interpretation of the feature is that a\nprivate browsing session should be perfectly anonymous and that no data about\nthe user’s activity will persist on the system. These two assumptions are already\npartly undermined by the constraints imposed by the networking stacks and\nthe memory management practices of modern operating systems. But even\nwithin the browser itself, the goal of reasonable anonymity is nearly impossi-\nble to achieve. Almost every stateful browser mechanism, from geolocation or\npop-up permissions to Strict Transport Security to form autocompletion to\nplug-in-based persistent data storage, must be modified in order to properly\naccount for the distinction between the two browsing modes, and for each\nvendor, achieving that goal is an uphill battle. Perhaps more frustratingly,\nanonymity is also undermined by the ability of scripts to uniquely fingerprint\nany given system simply by examining its characteristics—such as the set of\ninstalled plug-ins, fonts, screen resolutions, window sizes, clock drift, or even\nthe behavior of noncryptographically secure PRNGs.13\nIn the end, despite appearances to the contrary, private browsing mode\nis suitable only for preventing casual data disclosure to other nontechnical\nusers of the same machine, and even that goal is sometimes difficult to\nachieve.\n* Recall from Chapter 9 that host-scoped cookies are fairly tricky to create in some browsers and\noutright impossible to have in Internet Explorer.\nNew and Upcoming Security Features 249"
  },
  {
    "input": "In-Browser HTML Sanitizers",
    "output": "Other Developments\nThe security features discussed previously in this chapter aim to shift the\nboundaries between web applications and change the way sites interact with\neach other. Another group of proposed mechanisms escapes this simple clas-\nsification yet is important or mature enough to briefly mention here. We’ll\nreview some of them now.\nIn-Browser HTML Sanitizers\nXSS vulnerabilities are by far the most common security issue encountered\nin modern web applications. It must be surprising, then, that so few of the\nproposed security frameworks aim to address the problem in a comprehen-\nsive way. True, CSP is a strong contender, but it requires a radical change in\nhow web applications are written, and it can’t be deployed particularly gradu-\nally or selectively. Sandboxed frames, on the other hand, are probably too\nresource-intensive and too awkward to use for the most common task of dis-\nplaying hundreds of individual, short snippets of user-supplied data.\nPerhaps the best solution to many XSS woes would be a method for web\nframeworks to provide the browser with a parsed, unambiguous, binary DOM\ntree. Such a solution would eliminate many of the issues associated with tem-\nplate escaping and HTML sanitization. A more down-to-earth alternative\nmight be to equip web developers with a robust tool to mark the boundaries\nof an attacker-supplied string and restrict the behavior or appearance of the\nembedded payload without having to escape or sanitize it. One might think\nof syntax such as this:\n<sandbox token=\"random_value12345\" settings=\"allow_static_html\">\n...any unsanitized text or HTML...\n</sandbox token=\"random_value12345\">\nWere such a tool to be used, the attacker would be unable to escape such\na sandbox and remove the restriction on scripting without guessing the cor-\nrect value of the randomly generated token boundary.\nSadly, such a proposal is unlikely to become a part of HTML5 or to ship\nin any browser, because this serialization is fundamentally incompatible with\nXML, and revising XML itself to allow an obscure use case in HTML is a dif-\nficult act to pull off. Depressingly, XML already offers a similar method of\nencapsulating arbitrary data inside a <![CDATA[...]]> block, but absent a token-\nbased guard, this sandbox can be escaped easily when exploiting XSS.\nOn the flip side, it is considerably easier to restrict the privileges of\nanyHTML generated by scripts on the client side. Beginning with Internet\nExplorer 8, Microsoft offers a simple and somewhat inflexible toStaticHTML(...)\nAPI,14 which promises to remove JavaScript from any fully qualified bit of\nHTML passed to it as a parameter. The output of this method is designed to\nbe safe to assign to the innerHTML property somewhere in the existing DOM.*\n* Amusingly, the HTML parser in Internet Explorer is apparently so obtuse that even the authors\nof toStaticHTML(...) had some trouble following it. Since its introduction, the API has suffered\nfrom a fair number of bypass vulnerabilities, most frequently related to the handling of CSS data.\n250 Chapter 16"
  },
  {
    "input": "XSS Filtering",
    "output": "Microsoft’s proposal is fine, but it dances around the most common and\nproblematic task of safely displaying server-supplied documents. And its API has\na minor but entirely unnecessary weakness: It makes it unexpectedly danger-\nous to trim or concatenate the sanitized toStaticHTML(...) output after the call\nbut before the innerHTML assignment, a practice that many web developers\nwill probably attempt. A more sensible approach would be to allow content\nsanitization only upon assignment to innerHTML. In fact, WebKit engineers\nbriefly discussed a proposal for such an API (alternately named innerStaticHTML\nor safeInnerHTML), but the effort seems to have fizzled out long ago.\nXSS Filtering\nReducing the incidence of cross-site vulnerabilities is difficult, and so is\nlimiting their impact. Because of this, some researchers have concluded that\ndetecting and stopping the exploitation of such flaws may be a better choice.\nAnd so, around 2008, David Ross of Microsoft announced the inclusion of\nXSS-detection logic in the upcoming release of Internet Explorer 8;15 several\nmonths later, Adam Barth implemented a similar feature in WebKit. The\nimplementations compare portions of the current URL with any strings\nappearing on the retrieved page or passed to APIs such as document.write(...)\nand innerHTML. If that comparison reveals that a portion of JavaScript present\non the page may have originated with an improperly escaped URL parameter,\nthe relevant portion of the page may be substituted with a harmless string.\nSadly, this seemingly elegant idea is known to cause serious problems. Acci-\ndental false positives aside (users of Internet Explorer 8 will have unexpected\ntrouble visiting http://www.google.com/search?q=<script>), the filter may also be\ntripped for ill purposes by appending a legitimate portion of the page as a non-\nfunctional parameter in the URL. In one extreme and now resolved case, this\nbehavior was leveraged to create XSS vectors where none had existed before,\nsimply by tricking the browser into haphazardly rearranging the markup.16\nBut more fundamentally, it’s risky for any complex web application to selec-\ntively disable attacker-selected script blocks, even if the structure of the page\nis otherwise correctly preserved, and such a tweak may easily put the client-\nside code inan inconsistent or dangerous state. For example, consider an\nonline document editor that implements each of the following in a separate\n<script>block:\n1. Initializes the internal state of the editor and creates the UI with an\nempty starting document.\n2. Loads the current version of the document requested by the user in a URL\nparameter with error checking to catch any potential network problems.\n3. If no errors are detected, enters an interactive editing mode and auto-\nmatically saves the current state of the document every 30 seconds under\nthe URL-derived ID.\nIn this not entirely unreasonable design, the ability to remove step two\ncan be disastrous because the next step could overwrite the existing, server-\nstored document with a blank copy. D’oh.\nNew and Upcoming Security Features 251\nThis problem could have been avoided by using much simpler design\nwhereby any suspected XSS attacks would result in the browser simply refus-\ning to render the document. Alas, the relatively high incidence of accidental\nfalse positives prevented the authors from taking this route. Only after some\ndebate did Microsoft decide to offer a “strict” blocking mode on an opt-in\nbasis, toggled by a response header such as this:\nXSS-Protection: 1; mode=block\nNOTE In addition to the risk of false positives, XSS filters are also prone to false negatives,\nasituation that probably can’t be improved by much. By design, these filters will never\nbe able to detect the arguably more dangerous stored XSS vulnerabilities, where incor-\nrectly escaped data comes from a source other than the followed link. But even beyond\nthat, the multitude of (often implicit) input escaping schemes and the growing use of\nlocation.hash or pushState (Chapter 17) as a method to store application state make\nit difficult to formulate an accurate connection between what the browser sees in the\naddress bar and what the application makes of the received URL.\n252 Chapter 16"
  },
  {
    "input": "Security Engineering Cheat Sheet",
    "output": "Security Engineering Cheat Sheet\nApproach experimental browser security features with care, particularly when dealing with\nmechanisms that create finer-grained security boundaries. Ensure that any application lever-\naging these mechanisms will degrade safely in a noncompliant browser.\n Cross-domain XMLHttpRequest (CORS): Fairly safe, but easy to misuse. Avoid non-simple\nrequests and do not permit arbitrary headers or methods. If you have control over the\nserver-side application framework, consider automatically stripping Cookie headers on\nincoming CORS requests with nonwhitelisted Origin values to minimize the risk of acci-\ndentally sharing user-specific data. To minimize the incidence of mixed-content bugs,\nconsider rejecting HTTPS Origin values on any requests received over plain HTTP.\nBe wary of Access-Control-Allow-Origin: *, and if you need to use it, make sure it is only\nreturned for the location you intend to share.\n XDomainRequest: This is safe to use. As with XMLHttpRequest, restricting access to HTTP\nAPIs from HTTPS origins may be a good way to stamp out mixed-content bugs.\n Content Security Policy: This is safe to use as defense in depth. Review the caveats related\nto the interactions among script-src, object-src, and so on, and the dangers of permitting\ndata: origins. Do not accidentally allow mixed content: Always specify protocols in the\nrulesets and make sure they match the protocol the requesting page is served over.\n Sandboxed frames: This is safe to use as a way to embed gadgets from other origins, but\nthe mechanism will fail dramatically in noncompliant browsers. You should not sandbox\nsame-origin documents.\n Strict Transport Security: This is safe to use as defense in depth. Be sure to mark all rele-\nvant cookies as secure and be prepared for the possibility of cookie injection via spoofed,\nnon-STS locations in your domain. Use includeSubDomains where feasible to mitigate\nthisrisk.\n toStaticHTML(...): This is safe to use where available, but it is difficult to substitute on\ntheclient side in noncompliant browsers. Bypass vulnerabilities have an above-average\nchance of recurring in the API due to the design of the filter.\n Private browsing: Do not rely on this mechanism for security purposes.\n XSS filtering: Do not rely on this mechanism for security purposes. Always explicitly spec-\nify XSS-Protection: 1; mode=block or XSS-Protection: 0 in HTTP responses. The default is fairly\nunsafe.\nNew and Upcoming Security Features 253"
  },
  {
    "input": "17: Other Browser Mechanisms of Note\r",
    "output": "O T H E R B R O W S E R\nM E C H A N I S M S O F N O T E\nTo conclude the third part of the book, we briefly enu-\nmerate some of the recently implemented or simply\nplanned APIs that, although not designed for security\npurposes, may substantially change the security land-\nscape in the coming years. For example, some change\nthe types of data that web applications have access to\nor alter the way the browser communicates with the\noutside world.\nThe following list is necessarily incomplete: New, reasonably plausible\ndesigns are drafted every week, and old approaches are scrapped at a moment’s\nnotice, often long before shipping in an actual browser. Still, this chapter\nshould serve as an interesting snapshot of what the future may bring."
  },
  {
    "input": "URL- and Protocol-Level Proposals",
    "output": "URL- and Protocol-Level Proposals\nThese features seek to change the processes surrounding the behavior of\nlinks, the address bar, and the exchange of data over the wire.\nProtocol registration\nWeb applications commonly assume the handling of URL schemes pre-\nviously reserved for “real” desktop software. One prime example of this\nmay be the mailto: protocol, which was originally meant to instantiate a\nstand-alone mail application but which is often more sensibly routed to\nwebmail interfaces today. To this end, Mozilla proposed and WebKit\nembraced a simple navigator.registerProtocolHandler(...) API.1 When this\nAPI is invoked, the user is presented with a simple security prompt, and\nif the action is approved, a URL-based handler is associated with a par-\nticular scheme. As of today, the associated prompts are vulnerable to\ntherace conditions outlined in Chapter 14, and they seemto be lacking\nin other ways, as shown in Figure 17-1.\nl\nFigure 17-1: A seriously confusing prompt in Firefox. The prompt shown in the upper\narea of the browser window was generated by the browser in response to a call to\nthe registerProtocolHandler(...) API, with the protocol name set to “doing really awe-\nsome stuff” and application name set to “Firefox (mozilla.org)”. This particular example\nis harmless, but more sinister abuse is within reach.\nAddress bar manipulation\nThe newly introduced HTML5 history.pushState(...) API,2 supported by\nFirefox, WebKit, and Opera, permits the currently displayed document\nto change the contents of the address bar to any other same-origin URL,\nwithout actually triggering a page transition normally associated with this\nstep. The API offers a superior alternative to the widespread abuse of\nlocation.hash to store application state. Interestingly, despite its simplicity,\nit has already led to a fair number of interesting security bugs. For example,\nsome implementations briefly allowed not only the top-level document\n256 Chapter 17\nbut also any dodgy third-party frames to change the top-level URL shown\nin the address bar, and they permitted origins such as about:blank to put\nlargely unconstrained gibberish in the URL field.\nBinary HTTP\nSPDY3 (“Speedy”) is a simple, encrypted drop-in replacement for HTTP\nthat preserves the protocol’s key design principles (including the layout\nand function of most headers). At the same time, it mini- mizes the over-\nhead associated with delivering concurrent requests or with the parsing\nof text-based requests and response data. The protocol is currently sup-\nported only in Chrome, and other than select Google services, it is not\ncommonly encountered on the Web. It may be coming to Firefox soon,\ntoo, however.\nHTTP-less networking\nWebSocket4 is a still-evolving API designed for negotiating largely\nunconstrained, bidirectional TCP streams for when the transactional\nnature of TCP gets in the way (e.g., in the case of a low-latency chat appli-\ncation). The protocol is bootstrapped using a keyed challenge-response\nhandshake, which looks sort of like HTTP and which is (quite remarkably)\nimpossible to spoof by merely exploiting a header-splitting flaw in the des-\ntination site. Following a successful handshake, raw data may be exchanged\nbidirectionally within the resulting long-lived TCP connection, with each\nmessage enveloped inside a simple protocol frame. The mechanism is\nsupported in WebKit and is probably coming soon to Firefox.\nP2P networking\nWebRTC5 is a proposed set of APIs and network protocols designed to facil-\nitate the discovery of and communication with other browsers without the\nneed for a centralized server infrastructure. The primary use case for such\na protocol is the implementation of IP telephony and video-conferencing\nfeatures within web apps. No stable browser support is available yet.\nOffline applications\nCache manifests6 are a relatively simple way for aweb server to instruct\nthe browser that copies of certain documents should be stored indefi-\nnitely and reused whenever the client appears to have no network con-\nnectivity. In conjunction with client-side storage mechanisms such as\nlocalStorage (Chapter 9), this allows certain self-sufficient JavaScript appli-\ncations to be used in offline mode. Offline operation is supported in Fire-\nfox, the WebKit browser, and Opera. As with localStorage, the persistent\nnature of this mechanism could exacerbate the long-term consequences\nof visiting an untrusted network.\nBetter cookies\nCake7 is a now-expired proposal drafted by Adam Barth that aims to cre-\nate a more lightweight and secure alternative to HTTP cookies: one ori-\ngin-bound, browser-generated nonce for every destination site. A more\ncurrent but incomplete proposal appears to flirt with normal but origin-\nbased cookies as an alternative. Neither approach is available in any\nbrowser today.\nOther Browser Mechanisms of Note 257"
  },
  {
    "input": "Content-Level Features",
    "output": "Content-Level Features\nThe proposals outlined in this section aim to enable new classes of web appli-\ncations to be built on top of HTML and JavaScript.\nClient-side databases\nSeveral APIs for creating and manipulating locally stored databases have\nbeen proposed over the years, including the notorious WebSQL API,8\nwhich would have brought the famously dangerous SQL syntax to client-\nside JavaScript. The WebSQL proposal was ditched in favor of a more sen-\nsible IndexedDB design,9 which offers a clean API without serialized queries\nand has a security model comparable to that of localStorage—but not until\nWebSQL support had shipped ina couple of browsers. Meanwhile, the\nnew API has shipped in Chrome and is expected to appear in Firefox.\nBackground processes\nThe Worker API,10 available in Firefox, WebKit, and Opera, permits the\ncreation of background JavaScript processes to perform computationally\nexpensive tasks without having to worry about blocking the browser UI.\nEach worker runs in an isolated environment that lacks the usual window\nor document DOM and may communicate with its creator asynchronously\nthrough the postMessage(...) API. Dedicated workers are directly reachable\nonly by their creator, while shared workers may be “attached” to several dif-\nferent sites at any given time. (Persistent workers, which would run indepen-\ndently of any sustained demand for their services, were proposed early on\nbut then dropped.) The concept of worker threads raises some periph-\neral DoS concerns but otherwise poses no apparent security risks.\nGeolocation discovery\nThe navigator.geolocation.getCurrentPosition(...) API11 permits any website\nto request information about the physical location of the client device,\nsubject to a user’s (largely hijackable) consent. The computed geoloca-\ntion data may be derived from GPS information on a system with a suit-\nable hardware module, or it may be looked up based on the names of\nnearby wireless access points, cell towers, and so forth. The API is sup-\nported in all major browsers except for Internet Explorer.\nDevice orientation\nA nonrestricted event-driven DeviceOrientation API12 allows websites to\nread back the orientation of the device, based on accelerometer data.\nThis API, which is probably geared toward mobile gaming, is available in\nFirefox, WebKit, and Opera on systems equipped with the appropriate\nhardware. Two researchers at the University of California, Davis have\nrecently demonstrated a fatal flaw: On smartphones, minute movements\nof the device may be used to reliably reconstruct on-screen keyboard\ninput, including passwords entered on unrelated websites.13\nPage prerendering\nThis experimental feature in Chrome allows pages to be prefetched in\nanticipation of the user following a particular link, and it permits the entire\nHTML document to be prerendered in a hidden tab14 and momentarily\n258 Chapter 17"
  },
  {
    "input": "I/O Interfaces",
    "output": "revealed once the predicted navigation action takes place. The mech-\nanism has some interesting browser security consequences if the pre-\nrendered page turns out to be malicious. The implementation in Chrome\nis careful to defer any disruptive actions until the tab is revealed, but mis-\ntakes will be very easy to make across all browser codebases.\nNavigation timing\nSeveral complementary APIs, currently available only in Chrome, permit\ncertain types of navigation, including cross-domain page loads, to be very\naccurately benchmarked from client-side JavaScript.15 This interface is\ndesigned to allow site owners to identify obvious performance bottle-\nnecks, as experienced by a typical visitor. The API allows some privacy-\nrelated information to be collected by profiling the time needed to load\ncertain third-party content, but because the same attack is possible in\nmany other ways (for example with onload handlers on subresources),\nthat probably does not matter much.\nI/O Interfaces\nThe features listed below offer new input and output capabilities to web-\nbased scripts.\nUI notifications\nNotification and window.notifications16 APIs allow the creation of text-only or\nHTML-based, always-on-top pop-ups in the corner of the screen, allowing\nselect web applications to gently notify users of important developments\n(such as a new mail message). User consent to receiving notifications is\nrequired on a per-site basis, limiting the risk of abuse. Nevertheless, care\nmust be taken to properly communicate the origin of the tiny notification\nwindow and any dialogs or prompts it subsequently creates, an aspect that\ntook some time to refine. The API is available only in WebKit today.\nFull-screen mode\nSeveral proposals have been circulated to allow JavaScript to maximize\nthe current browser window and hide all the browser chrome. This func-\ntionality is essential to tasks such as viewing presentations or watching\nmovies, but it is obviously very dangerous from the security standpoint:\nOnce in control of the entire screen, any malicious page may draw a fake\nbrowser window with a fake address bar. So far, no specific implementa-\ntion seems to be available for review. An early-stage proposal for mouse\ncursor locking is being discussed, too.\nMedia capture\nA proposed suite of navigator.device.capture APIs17 has been postulated for\ngiving websites access to webcam and microphone data. Obvious security\nand privacy concerns arise around this mechanism, especially around\nthe resilience of any associated security prompts with respect to race con-\ndition attacks. The API has no stable browser support today.\nOther Browser Mechanisms of Note 259"
  },
  {
    "input": "18: Common Web Vulnerabilities\r",
    "output": "C O M M O N W E B\nV U L N E R A B I L I T I E S\nUp until this point, we have paid little attention to\nthe taxonomy of common web vulnerabilities. Gaining\ninsight into the underlying mechanics of web applica-\ntions is far more important than memorizing several\nthousand random and often unnecessary terms; nomen-\nclature such as improper restriction of operations within the\nbounds of a memory buffer (Common Weakness Enumer-\nation) or insecure direct object references (Open Web Appli-\ncation Security Project) finds no place in a reasonable\nconversation—and rightly so.\nNevertheless, the industry has come up with a handful of reasonably\nprecise phrases that security researchers use every day. Having thoroughly\ndiscussed the inner workings of the browser, it seems useful to recap and\nhighlight the terminology the average reader is likely to see."
  },
  {
    "input": "Vulnerabilities Specific to Web Applications",
    "output": "Vulnerabilities Specific to Web Applications\nThe terms outlined in this section are unique to the technologies used on\nthe Web and often have no immediate counterparts in the world of “tradi-\ntional” application security.\nCross-site request forgery (XSRF, CSRF)\nA vulnerability caused by the failure to verify that a particular state-\nchanging HTTP request received by the server-side portion of the web\napplication was initiated from the expected client-side origin. This flaw\npermits any third-party website loaded in the browser to perform actions\non behalf of the victim.\n See Chapter 4 for a more detailed discussion of XSRF.\nCross-site script inclusion (XSSI)\nA flaw caused by the failure to secure sensitive JSON-like responses\nagainst being loaded on third-party sites via <script src=...>. User-specific\ninformation in the response may be leaked to attackers.\n See Chapter 6 for an overview of the problem (and potential fixes).\nCross-site scripting (XSS)\nInsufficient input validation or output escaping can allow an attacker to\nplant his own HTML markup or scripts on a vulnerable site. The injected\nscripts will have access to the entirety of the targeted web application\nand, in many cases, to HTTP cookies stored by the client.\nThe qualifier reflected refers to cases where the injected string is\nsimply a result of incorrectly echoing back a portion of the request,\nwhereas stored or persistent refers to a situation where the payload takes a\nmore complex route. DOM-based may be used to denote that the vulner-\nability is triggered by the behavior of the client-side portion of the web\napp (i.e., JavaScript).\n See Chapter 4 for common XSS vectors in HTML documents.\n See Chapter 6 for an overview of DOM-based XSS risks.\n See Chapter 13 for XSS vectors associated with content sniffing.\n See Chapter 9 for a discussion of the normal security model for JS code.\nHeader injection (response splitting)\nInsufficient escaping of newlines (or equivalent characters) in HTTP\nresponses generated by the server-side portion of a web application.\nThisbehavior will typically lead to XSS, browser, or proxy cache poison-\ning and more.\n See Chapter 3 for a detailed discussion of the flaw.\nMixed content\nA catch-all name for loading non-HTTPS subresources on HTTPS pages.\nIn the case of scripts and applets, this behavior makes the application\ntrivially vulnerable to active attackers, particularly on open wireless\n262 Chapter 18"
  },
  {
    "input": "Problems to Keep in Mind in Web Application Design",
    "output": "networks (at cafés, airports, and so on), and undoes almost all benefits of\nHTTPS. The consequences of mixed content bugs with stylesheets, fonts,\nimages, or frames are usually also fairly serious but more constrained.\n See Chapters 4 and 8 for content-specific precautions on HTTPS sites.\n See Chapter 11 for an overview of mixed-content handling rules.\nOpen redirection\nA term used to refer to applications that perform HTTP- or script-based\nrequests to user-supplied URLs without constraining the possible desti-\nnations in any meaningful way. Open redirection is not advisable and\nmay be exploitable in some scenarios, but it is typically not particularly\ndangerous by itself.\n See Chapter 10 for cases where unconstrained redirection may lead to XSS.\nReferer leakage\nAccidental disclosure of a sensitive URL by embedding an off-site sub-\nresource or providing an off-site link. Any security- or privacy-relevant\ndata encoded in the URL of the parent document will be leaked in the\nReferer header, with the exception of the fragment identifier.\n See Chapter 3 for an overview of the Referer logic.\nProblems to Keep in Mind in Web Application Design\nThe problems outlined in this section are an unavoidable circumstance of\ndoing business on the Internet and must be properly accounted for when\ndesigning or implementing new web apps.\nCache poisoning\nThe possibility of long-term pollution of the browser cache (or any\ninterim proxies) with a fabricated, malicious version of the targeted\nwebapplication. Encrypted web applications may be targeted due to\nresponse-splitting vulnerabilities. For nonencrypted traffic, active net-\nwork attackers may be able to modify the responses received by the\nrequestor, too.\n See Chapter 3 for an overview of HTTP-caching behaviors.\nClickjacking\nThe possibility of framing or otherwise decorating or obscuring a por-\ntion of another web application so that the victim, when interacting with\nthe attacker’s site, is not aware that individual clicks or keystrokes are\ndelivered to the other site, resulting in undesirable actions being taken\non behalf of the user.\n See Chapter 11 for a discussion of clickjacking and related UI issues.\nCommon Web Vulnerabilities 263\nContent and character set sniffing\nDescribes the possibility that the browser will ignore any authoritative\ncontent type or character set information provided by the server and\ninterpret the returned document incorrectly.\n See Chapter 13 for a discussion of content-sniffing logic.\n See Chapters 4 and 8 for scenarios where Content-Type data is ignored.\nCookie forcing (or cookie injection)\nThe possibility of blindly injecting HTTP cookies into the context of an\notherwise impenetrable web application due to issues in how the mecha-\nnism is designed and implemented in modern browsers. Cookie injec-\ntion is of particular concern to HTTPS applications. (Cookie stuffing is a\nless common term referring specifically to maliciously deleting cookies\nbelonging to another application by overflowing the cookie jar.)\n See Chapter 9 for more information on cookie scoping.\n See Chapter 3 for a general discussion of the operation of HTTP cookies.\nDenial-of-service (DoS) attacks\nA broad term denoting any opportunities for the attacker to bring down\na browser or server or otherwise make the use of a particular targeted\napplication significantly more difficult.\n See Chapter 14 for an overview of DoS considerations with JavaScript.\nFramebusting\nThe possibility of a framed page navigating the top-level document to a\nnew URL without having to satisfy same-origin checks. The behavior may\nbe exploited for phishing attacks or simply for petty mischief.\n See Chapter 11 for this and other frame navigation quirks.\nHTTP downgrade\nThe ability for active attackers to prevent the user from reaching an\nHTTPS version of a particular site or to downgrade an existing HTTPS\nsession to HTTP.\n See Chapter 3 for an overview of HTTPS.\n See Chapter 16 for Strict Transport Security, a proposed solution to the\nproblem.\nNetwork fenceposts\nThe prospect of websites on the Internet leveraging the browser to inter-\nact with destinations not directly accessible to the attacker, for example,\nwith the systems on a victim’s internal network. Such attacks can be per-\nformed blindly, or (with the help of attacks such as DNS rebinding) the\nattacker may be able to see responses to all requests.\n See Chapter 12 for an overview of non-SOP boundaries in a browser.\n See Chapter 15 for Internet Explorer zone model, a potential approach to\nthisrisk.\n264 Chapter 18"
  },
  {
    "input": "Common Problems Unique to Server-Side Code",
    "output": "NOTE Beware non-buzzword bugs! Not all vulnerabilities have catchy names. Web developers\nshould be wary of many other implementation and design issues that are outside the\nscope of this book but that can nevertheless bite hard. Examples include weak pseudo-\nrandom number generators (especially for session management purposes); insufficient\nauthentication and authorization checks (in particular, overly trusting the browser-\noriginating data); incorrect uses of cryptography (inventing one’s own algorithms is\nusually a no-no); and so on. For a remarkably detailed discussion of these and many\nother failure patterns, see The Art of Software Security Assessment by Dowd,\nMcDonald, and Schuh (Addison-Wesley, 2006).\nCommon Problems Unique to Server-Side Code\nThe following issues are commonly encountered in the server-hosted portion\nof any web application and, by virtue of being tied to specific programming\nlanguages or software components, are unlikely to occur on the client side.\nBuffer overflow\nA condition where a program allows more information to be stored in\naparticular memory region than there is space to accommodate the\nincoming data, leading to the unexpected overwrite of other vital data\nstructures. Buffer overflows happen chiefly in low-level programming\nlanguages, such as C or C++, and in these languages, they can be fre-\nquently leveraged to execute attacker-supplied code.\nCommand injection (SQL, shell, PHP, and so on)\nA problem where, due to insufficient input filtering or output escaping,\nattacker-controlled strings may be unintentionally processed as state-\nments in an interpreted language used by the application. (In a distant\nsense, this is similar to XSS.) The consequences depend on the capabili-\nties of the language, but in most cases, code execution is the eventual\noutcome.\nDirectory traversal\nA problem where, due to insufficient input filtering (most commonly,\nthe failure to properly recognize and handle “../” segments in filenames),\nan application can be tricked into reading or writing files at arbitrary loca-\ntions on the disk. Any consequences depend on additional constraints,\nbut unconstrained file-writing bugs are usually easily exploitable to run\nattacker-supplied code.\nFile inclusion\nIf used without a qualifier or prefixed with local (LFI), the term is largely\nsynonymous with read-related directory traversal. Remote file inclusion\n(RFI), on the other hand, is an alternative way to exploit file-inclusion\nvulnerabilities by specifying a URL rather than a valid file path. In some\nscripting languages, a single, common API opens local files and fetches\nremote URLs. In these cases, the ability to retrieve the file from an\nattacker-controlled server may offer substantial benefits, depending\nonhow the data is subsequently processed.\nCommon Web Vulnerabilities 265\nFormat-string vulnerability\nA handful of commonly used library functions accept templates (“format\nstrings”), followed by a set of parameters that the function is expected\ntoinsert into the template at predefined locations. Such an approach is\nparticularly common in C (printf(...), syslog(...), and so on), but it is not\nlimited to that language. Format-string vulnerabilities are caused by\nunintentionally permitting attackers to supply the template to one of\nthese functions. Depending on the capabilities of the template system\nand the specifics of the language, this error may lead to anything from\nminor data leaks to code execution.\nInteger overflow\nA vulnerability specific to languages with limited or no range checking. The\nflaw is caused by the developer failing to detect that an integer exceeded\nthe maximum possible value and rolled back to zero, to a very large neg-\native integer, or to some other hardware-specific and unexpected result.\nDepending on how the value is used, this may put the program in an\ninconsistent state or, worse, lead to the reading or writing of data at an\nincorrect memory location (which, in turn, may lend itself to code exe-\ncution). Integer underflow is the opposite effect: crossing the minimum\npermissible value and rolling over to a very large positive integer.\nPointer management vulnerabilities\nIn languages that encourage or require the use of raw memory pointers\n(chiefly C and C++), it is possible to use pointers that are either uninitial-\nized or no longer valid (“dangling”), leading to vulnerabilities such as use\nafter free, double free, and many more. These vulnerabilities will corrupt the\ninternal state of the program and usually allow an attacker to execute\nattacker-supplied code.\n266 Chapter 18"
  },
  {
    "input": "Epilogue",
    "output": "E P I L O G U E\nWell, who would have thought. This concludes The\nTangled Web! I hope you’ve enjoyed reading this book\nas much as I’ve enjoyed exploring the world of browser\nsecurity over the last decade or so. I also hope that what\nyou’ve discovered on these pages will guide you in your\nfuture journeys, wherever they may be.\nAs for what to make of it all: To me, the stark contrast between the amaz-\ning robustness of the modern Web and the inexplicable unsoundness of its\nfoundations was difficult to reconcile at first. In retrospect, I think it offers\nanimportant insight into our own, unreasonable attitude about securing the\nonline world.\nI am haunted by the uncomfortable observation that in real life,\nmodernsocieties are built on remarkably shaky ground. Every day, each of\nusdepends on the sanity, moral standards, and restraint of thousands of ran-\ndom strangers—from cab drivers, to food vendors, to elevator repair techs.\nThe rules of the game are weakly enforced through a series of deterrence\nmechanisms, but if crime statistics are to be believed, their efficacy is remark-\nably low. The problem isn’t just that most petty criminals think they can get\naway with their misdeeds but that they are usually right.\nIn this sense, our world is little more than an incredibly elaborate honor\nsystem that most of us voluntarily agree to participate in. And that’s probably\nokay: Compliance with self-imposed norms has proven to be a smart evolu-\ntionary move, and it is a part of who we are today. A degree of trust is simply\nessential to advancing our civilization at a reasonable pace. Too, paradoxi-\ncally, despite short-term weaknesses, accelerated progress makes usall a lot\nstronger and more adaptable in the long run.\nIt is difficult to understand, then, why we treat our online existence in\nsuch a dramatically different way. For example, why is it that we get upset at\ndevelopers who use cryptography incorrectly, but we don’t mind that the\nlocks on our doors can be opened with a safety pin? Why do we scorn web\ndevelopers who can’t get input validation right, but we don’t test our break-\nfast for laxatives or LSD?\nThe only explanation I can see is that humankind has had thousands of\nyears to work out the rules of social engagement in the physical realm. Dur-\ning that time, entire societies have collapsed, new ones have emerged, and\nan increasingly complex system of behavioral norms, optimized for the pres-\nervation of communities, has emerged in the process. Unfortunately for us,\nwe have difficulty transposing these rules into the online ecosystem, and this\nworld is so young, it hasn’t had the chance to develop its own, separate code\nof conduct yet.\nThe phenomenon is easy to see: While your neighbor will not try to sneak\ninto your house, he may have no qualms about using your wireless network\nbecause doing so feels much less like a crime. He may oppose theft, but he\nmay be ambivalent about unlawfully duplicating digital content. Or he may\nfrown upon crude graffiti in the neighborhood but chuckle at the sight of a\ndefaced website. The parallels are there but just aren’t good enough.\nWhat if our pursuit of perfection in the world of information security\nstems from nothing but a fundamental misunderstanding of how human com-\nmunities can emerge and flourish? The experts of my kind preach a model of\nnetworked existence based on complete distrust, but perhaps wrongly so: As\nthe complexity of our online interactions approaches that of real life, the odds\nof designing perfectly secure software are rapidly diminishing. Meanwhile, the\nextreme paranoia begins to take a heavy toll on how quickly we can progress.\nPerhaps we are peddling a recipe for a failure. What if our insistence on\nabsolute security only takes us closer to the fate of so many other early civili-\nzations, which collapsed under the weight of their flaws and ultimately van-\nished? I find this perverse thought difficult to dismiss. Fortunately, we know\nthat from the rubble, new, more enlightened societies will certainly emerge\none day. Their ultimate nature is anyone’s guess.\n268 Epilogue"
  },
  {
    "input": "Notes\r",
    "output": "N O T E S\nChapter 1\n1. D.E. Bell and L.J. La Padula, Secure Computer System: Unified Exposition\nandMultics Interpretation (ESD-TR-75-306), Bedford, MA: MITRE Corpo-\nration for US Air Force (1976), http://csrc.nist.gov/publications/history/\nbell76.pdf.\n2. C.E. Landwehr, C.L. Heitmeyer, and J.D. McLean, “A Security Model for\nMilitary Message Systems: Retrospective,” paper presented at the 17th\nAnnual Computer Security Applications Conference, New Orleans, LA\n(2001), http://www.acsa-admin.org/2001/papers/141.pdf.\n3. V. Bush, “As We May Think,” Atlantic Monthly (July 1945), http://\nwww.theatlantic.com/doc/194507/bush/.\n4. R. Dhamija, J.D. Tygar, and M. Hearst, “Why Phishing Works,” paper\npresented at the Conference on Human Factors in Computing Systems,\nMontreal, Canada (2006), http://people.seas.harvard.edu/~rachna/papers/\nwhy_phishing_works.pdf.\n5. C. Jackson, D.R. Simon, D.S. Tan, and A. Barth, “An Evaluation of\nExtended Validation and Picture-in-Picture Phishing Attacks,” paper\npresented at Usable Security, Lowlands, Trinidad and Tobago (2007),\nhttp://usablesecurity.org/papers/jackson.pdf.\n6. C. Jackson and A. Barth, “Beware of Finer-Grained Origins,” paper pre-\nsented at Web 2.0 Security and Privacy, Oakland, CA (2008), http://seclab\n.stanford.edu/websec/origins/fgo.pdf; C. Jackson, and A. Barth, “Beware of\nCoarser-Grained Origins,” paper presented at Web 2.0 Security and Pri-\nvacy, Oakland, CA (2008), http://seclab.stanford.edu/websec/origins/scheme/.\n7. “Security Exploit Uses Internet Explorer to Attack Mozilla Firefox,”\nMozillaZine (July 11, 2007), http://www.mozillazine.org/talkback\n.html?article=22198.\nPage 19\n1. Net Applications website, http://marketshare.hitslink.com/browser-market-share\n.aspx?qprid=0, http://marketshare.hitslink.com/browser-market-share.aspx?qprid=2\n(accessed June 13, 2011).\nChapter 2\n1. T. Berners-Lee, R. Fielding, and L. Masinter, “Uniform Resource Identi-\nfier (URI): Generic Syntax,” IETF Request for Comments 3986 (2005),\nhttp://www.ietf.org/rfc/rfc3986.txt.\n2. T. Berners-Lee, L. Masinter, and M. McCahill, “Uniform Resource Loca-\ntors (URL),” IETF Request for Comments 1738 (1994), http://www.ietf\n.org/rfc/rfc1738.txt.\n3. R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, and T.\nBerners-Lee, “Hypertext Transfer Protocol—HTTP/1.1,” IETF Request\nfor Comments 2616 (1999), http://www.ietf.org/rfc/rfc2616.txt.\n4. “Uniform Resource Identifer (URI) Schemes per RFC4395,” Internet\nAssigned Numbers Authority (June 6, 2011), http://www.iana.org/\nassignments/uri-schemes.html.\n5. P. Mockapetris, “Domain Names—Implementation and Specification,”\nIETF Request for Comments 1035 (1987), http://www.ietf.org/rfc/\nrfc1035.txt.\n6. T. Berners-Lee, “Universal Resource Identifiers in WWW,” IETF Request\nfor Comments 1630 (1994), http://www.w3.org/Addressing/rfc1630.txt.\n7. P. Hoffman, L. Masinter, and J. Zawinski, “The mailto URL Scheme,”\nIETF Request for Comments 2368 (1998), http://www.ietf.org/rfc/\nrfc2368.txt.\n8. “HTML 4.01 Specification: Forms,” World Wide Web Consortium (1999),\nhttp://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1.\n9. P. Faltstrom, P. Hoffman, and A. Costello, “Internationalizing Domain\nNames in Applications (IDNA),” IETF Request for Comments 3490\n(2003), http://www.ietf.org/rfc/rfc3490.txt.\n10. A. Costello, “Punycode: A Bootstring Encoding of Unicode for Interna-\ntionalized Domain Names in Applications (IDNA),” IETF Request for\nComments 3492 (2003), http://www.ietf.org/rfc/rfc3492.txt.\n11. E. Gabrilovich and A. Gontmakher, “The Homograph Attack,” Commu-\nnications of the ACM (2002), http://www.cs.technion.ac.il/~gabr/papers/\nhomograph_full.pdf.\n270 Notes for Pages 17–35\n12. E. Rescorla, “HTTP Over TLS,” IETF Request for Comments 2818 (2000),\nhttp://www.ietf.org/rfc/rfc2818.txt.\n13. J. Postel and J. Reynolds, “File Transfer Protocol (FTP),” IETF Request\nfor Comments 959 (1985), http://www.ietf.org/rfc/rfc959.txt.\n14. F. Anklesaria, M. McCahill, P. Lindner, D. Johnson, D. Torrey, and B.\nAlberti, “The Internet Gopher Protocol,” IETF Request for Comments\n1436 (1993), http://www.ietf.org/rfc/rfc1436.txt.\n15. E. Rescorla and A. Schiffman, “The Secure HyperText Transfer Proto-\ncol,” IETF Request for Comments 2660 (1999), http://www.ietf.org/rfc/\nrfc2660.txt.\n16. L. Masinter, “The ‘data’ URL Scheme,” IETF Request for Comments\n2397 (1998), http://www.ietf.org/rfc/rfc2397.txt.\n17. “What Are rss: and feed: Links?” http://www.brindys.com/winrss/\nfeedformat.html.\n18. M. Zalewski, “A Note on an MHTML Vulnerability,” Lcamtuf’s blog\n(March11, 2011), http://lcamtuf.blogspot.com/2011/03/note-on-mhtml-\nvulnerability.html.\nChapter 3\n1. T. Berners-Lee, “The Original HTTP as defined in 1991.” World Wide\nWeb Consortium archives (1991), http://www.w3.org/Protocols/HTTP/\nAsImplemented.html.\n2. T. Berners-Lee, R. Fielding, and H. Frystyk, “Hypertext Transfer\nProtocol—HTTP/1.0,” IETF Request for Comments 1945 (1996),\nhttp://www.ietf.org/rfc/rfc1945.txt.\n3. R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, and\nT.Berners-Lee, “Hypertext Transfer Protocol—HTTP/1.1,” IETF Request\nfor Comments 2616 (1999), http://www.ietf.org/rfc/rfc2616.txt.\n4. HTTPbis Working Group, “Httpbis Status Pages,” http://tools.ietf.org/wg/\nhttpbis/.\n5. A. Luotonen, “Tunneling TCP-Based Protocols Through Web Proxy\nServers,” IETF draft (1998), http://tools.ietf.org/id/draft-luotonen-web-proxy-\ntunneling-01.txt.\n6. S. Chen, Z. Mao, Y.M. Wang, and M. Zhang, “Pretty-Bad-Proxy: An\nOverlooked Adversary in Browsers’ HTTPS Deployments,” Microsoft\nResearch (2009), http://research.microsoft.com/pubs/79323/pbp-final-with-\nupdate.pdf.\n7. “Mozilla Cross-Reference mozilla1.8.0,” Mozilla code repository, http://\nmxr.mozilla.org/mozilla1.8.0/source/nsprpub/pr/src/misc/prtime.c#1045.\n8. K. Moore, “MIME (Multipurpose Internet Mail Extensions) Part Three:\nMessage Header Extensions for Non-ASCII Text,” IETF Request For\nComments 2047 (1996), http://www.ietf.org/rfc/rfc2047.txt.\nNotes for Pages 36–50 271\n9. N. Freed and K. Moore, “MIME Parameter Value and Encoded Word\nExtensions: Character Sets, Languages, and Continuations,” IETF\nRequest for Comments 2231 (1997), http://www.ietf.org/rfc/rfc2231.txt.\n10. Mozilla Bug Tracking System, Mozilla bug #418394, https://bugzilla\n.mozilla.org/show_bug.cgi?id=418394.\n11. T. Berners-Lee, “Basic HTTP as defined in 1992: Methods,” World Wide\nWeb Consortium archives (1992), http://www.w3.org/Protocols/HTTP/\nMethods.html.\n12. L. Dusseault, “HTTP Extensions for Web Distributed Authoring and\nVersioning (WebDAV),” IETF Request for Comments 4918 (2007),\nhttp://www.ietf.org/rfc/rfc4918.txt.\n13. See note 12 above.\n14. M. Pool, “Meantime: Non-Consensual HTTP User Tracking Using\nCaches” (2000), http://sourcefrog.net/projects/meantime/.\n15. L. Montulli, “Persistent Client State HTTP Cookies” (1994), http://curl\n.haxx.se/rfc/cookie_spec.html.\n16. D. Kristol and L. Montulli, “HTTP State Management Mechanism,” IETF\nRequest for Comments 2109 (1997), http://www.ietf.org/rfc/rfc2109.txt.\n17. D. Kristol and L. Montulli, “HTTP State Management Mechanism,” IETF\nRequest for Comments 2965 (2000), http://tools.ietf.org/rfc/rfc2965.txt.\n18. A. Barth, “HTTP State Management Mechanism,” IETF Request for\nComments 6265 (2011), http://www.ietf.org/rfc/rfc6265.txt.\n19. J. Franks, P. Hallam-Baker, J. Hostetler, S. Lawrence, P. Leach, A.\nLuotonen, and L. Stewart, “HTTP Authentication: Basic and Digest\nAccess Authentication,” IETF Request for Comments 2617 (1999),\nhttp://www.ietf.org/rfc/rfc2617.txt.\n20. R. Tschalär, “NTLM Authentication Scheme for HTTP” (2003), http://\nwww.innovation.ch/personal/ronald/ntlm.html.\n21. E. Rescorla, “HTTP Over TLS,” IETF Request for Comments 2818 (2000),\nhttp://www.ietf.org/rfc/rfc2818.txt.\n22. P. Hallam-Baker, “The Recent RA Compromise,” Comodo IT Security\n(blog) (March 23, 2011), http://blogs.comodo.com/it-security/data-security/\nthe-recent-ra-compromise/.\n23. S. Chen, R. Wang, X. F. Wang, and K. Zhang, “Side-Channel Leaks\ninWeb Applications: A Reality Today, a Challenge Tomorrow,”\nMicrosoft Research (2010), http://research.microsoft.com/pubs/119060/\nWebAppSideChannel-final.pdf.\n24. C. Evans, “Open Redirectors: Some Sanity,” Security: Hacking Everything\n(blog) (June 25, 2010), http://scarybeastsecurity.blogspot.com/2010_06_01\n_archive.html.\n272 Notes for Pages 50–66\nChapter 4\n1. T. Berners-Lee, “HTML Tags,” World Wide Web Consortium archives\n(1991), http://www.w3.org/History/19921103-hypertext/hypertext/WWW/\nMarkUp/Tags.html.\n2. T. Berners-Lee and D. Connolly, “Hypertext Markup Language—2.0,”\nIETF Request for Comments 1866 (1995), http://www.ietf.org/rfc/\nrfc1866.txt.\n3. D. Raggett, “HTML 3.2 Reference Specification,” World Wide Web\nConsortium (1997), http://www.w3.org/TR/REC-html32.\n4. D. Raggett, A. Le Hors, and I. Jacobs, “HTML 4.01 Specification,” World\nWide Web Consortium (1999), http://www.w3.org/TR/html401/.\n5. I. Hickson, “HTML5,” World Wide Web Consortium draft, revision\n1.5019 (2011), http://dev.w3.org/html5/spec/Overview.html.\n6. G. Coldwind, “Too general charset = detection in meta,” Mozilla\nbug640529 (2011), https://bugzilla.mozilla.org/show_bug.cgi?id=640529.\nChapter 5\n1. H. Wium Lie and B. Bos, “Cascading Style Sheets, Level 1,” World\nWideWeb Consortium, (1996), http://www.w3.org/TR/CSS1/.\n2. T. Çelik, E.J. Etemad, D. Glazman, I. Hickson, P. Linss, and J. Williams,\n“Selectors Level 3: Selectors,” World Wide Web Consortium (2009), http://\nwww.w3.org/TR/css3-selectors/#selectors.\n3. I. Hickson, “XML Binding Language (XBL) 2.0,” World Wide Web\nConsortium (2007), http://www.w3.org/TR/xbl/.\n4. G. Heyes, D. Lindsay, and E.V. Nava, “The Sexy Assassin: Tactical\nExploitation Using CSS” (2009), http://www.scribd.com/doc/54664700/\nTactical-Xploit-Css.\nChapter 6\n1. Netscape Communications Corporation, “Netscape and Sun Announce\nJavaScript, the Open, Cross-Platform Object Scripting Language for Enter-\nprise Networks and the Internet” (press release) (December 4, 1995),\nhttp://web.archive.org/web/20070916144913/http://wp.netscape.com/newsref/\npr/newsrelease67.html.\n2. ECMA International, “ECMA-262: ECMAScript Language Specifica-\ntion,” 3rd ed. (1999), http://www.ecma-international.org/publications/files/\nECMA-ST-ARCH/ECMA-262,%203rd%20edition,%20December%201999.pdf.\n3. ECMA International, “ECMA-262: ECMAScript Language Specification,”\n5th ed. (2009), http://www.ecma-international.org/publications/files/ECMA-ST/\nECMA-262.pdf.\nNotes for Pages 69–96 273\n4. D. Crockford, “The Application/JSON Media Type for JavaScript Object\nNotation (JSON),” IETF Request for Comments 4627 (2006), http://\nwww.ietf.org/rfc/rfc4627.txt.\n5. J. Schneider, R. Yu, and J. Dyer, eds., “Standard ECMA-357: ECMAScript\nfor XML (E4X) Specification,” 2nd ed., ECMA International (2005), http://\nwww.ecma-international.org/publications/standards/Ecma-357.htm.\n6. P. Le Hégaret, R. Whitmer, and L. Wood, “Document Object Model\n(DOM),” World Wide Web Consortium (2005), http://www.w3.org/DOM/.\n7. E. Vela Nava, “Bug 38922—innerHTML decompilation issues in text-\narea” (WebKit bug-tracking system post) (2010), https://bugs.webkit.org/\nshow_bug.cgi?id=38922.\n8. “Windows Scripting 5.8: MsgBox Function,” Microsoft Developer\nNetworkPlatforms (2009), http://msdn.microsoft.com/en-us/library/\nsfw6660x%28v=vs.85%29.aspx.\n9. D. Crockford, “JSON in JavaScript,” GitHub Social Coding (blog) (March 5,\n2011), https://github.com/douglascrockford/JSON-js/blob/master/json2.js.\nChapter 7\n1. J. Ferraiolo, F. Jun, and D. Jackson, “Scalable Vector Graphics (SVG) 1.1\nSpecification,” World Wide Web Consortium (2003), http://www.w3.org/\nTR/2003/REC-SVG11-20030114/.\n2. D. Carlisle, P. Ion, and R. Miner, “Mathematical Markup Language\n(MathML) Version 3.0,” World Wide Web Consortium WC3 Recom-\nmendation 21 (2010), http://www.w3.org/TR/MathML3/.\n3. A. Mechelynck, “XUL,” Mozilla Developer Network (2011), https://\ndeveloper.mozilla.org/en/xul.\n4. Wireless Application Protocol Forum, “Wireless Application Protocol:\nWireless Markup Language Specification version 30” (1998), http://www\n.wapforum.org/what/technical/wml-30-apr-98.pdf.\n5. RSS Advisory Board, “RSS 2.0 Specification version 2.0.11” (2009), http://\nwww.rssboard.org/rss-specification.\n6. M. Nottingham and R. Sayre, eds., “The Atom Syndication Format,” IETF\nRequest for Comments 4287 (2005), http://www.ietf.org/rfc/rfc4287.txt.\nChapter 8\n1. E. Mills, “Security Labs Report: January–June 2010 Recap,” M86 Security\n(2010), http://www.m86security.com/documents/pdfs/security_labs/m86_security\n_labs_report_1H2010.pdf.\n2. B. Rios, “Sun Fixes GIFARs” (December 17, 2008), http://xs-sniper.com/\nblog/2008/12/17/sun-fixes-gifars/.\n274 Notes for Pages 104–129\n3. A.K. Sood, “PDF Silent HTTP Form Repurposing Attacks,” SecNiche\nSecurity Labs (2009), http://secniche.org/papers/SNS_09_03_PDF_Silent\n_Form_Re_Purp_Attack.pdf.\n4. P.D. Petkov, “Universal PDF XSS Afterparty” (January 4, 2007), http://\nwww.gnucitizen.org/blog/universal-pdf-xss-after-party/.\n5. S. Jobs, “Thoughts on Flash” (2010), http://www.apple.com/hotnews/\nthoughts-on-flash/.\n6. “Adobe Shockwave Player,” Adobe Systems Incorporated, http://www\n.adobe.com/products/shockwaveplayer/.\n7. “ActionScript 3.0 Reference for the Adobe Flash Platform,” Adobe Sys-\ntems Incorporated, http://help.adobe.com/en_US/FlashPlatform/reference/\nactionscript/3/index.html.\n8. “Content Played Back in Flash Player Reaches 99% of Internet Viewers,”\nAdobe Systems Incorporated (March 2011), http://www.adobe.com/products/\nplayer_census/flashplayer/.\n9. “Web Browser Plugin Market Share,” StatOwl (May 2011), http://www\n.statowl.com/plugin_overview.php.\n10. “ActionScript 3.0 Reference for the Adobe Flash Platform: External-\nInterface,” Adobe Systems Incorporated, http://livedocs.adobe.com/flex/\n3/langref/flash/external/ExternalInterface.html#includeExamplesSummary.\n11. “XAML Overview (WPF),” Microsoft Corporation, http://msdn.microsoft\n.com/en-us/library/ms752059.aspx.\n12. “Rich Internet Application Statistics” (July 2011), http://www.riastats.com/\n. See also StatOwl (Chapter 8, note 9).\n13. “Secunia Half Year Report 2010,” Secunia (2010), http://secunia.com/gfx/\npdf/Secunia_Half_Year_Report_2010.pdf.\n14. “WPF XAML Browser Applications Overview,” Microsoft Corporation,\nhttp://msdn.microsoft.com/en-us/library/aa970060.aspx.\n15. “Akamai Download Manager Help,” Microsoft Corporation, https://\nmsdn.microsoft.com/en-us/subscriptions/manage/bb153537.aspx.\nChapter 9\n1. A. Klein, “IE + Some Popular Forward Proxy Servers = XSS, Defacement\n(Browser Cache Poisoning)” (May 22, 2006), http://seclists.org/webappsec/\n2006/q2/352; M. Zalewski, “Web 2.0 Backdoors Made Easy with MSIE &\nXMLHttpRequest” (February 3, 2007), http://seclists.org/fulldisclosure/\n2007/Feb/81.\n2. A. van Kesteren, ed., “Cross-Origin Resource Sharing,” working draft,\nWorld Wide Web Consortium (July 27, 2010), http://www.w3.org/TR/cors/.\n3. I. Hickson, “Web Storage,” editor’s draft, World Wide Web Consortium\n(July 28, 2011), http://dev.w3.org/html5/webstorage/.\nNotes for Pages 130–148 275\n4. J. Stenback, “Make sessionStorage Use Principals Instead of String\nDomains,” Mozilla bug #495337 (May 28, 2009), https://bugzilla.mozilla\n.org/show_bug.cgi?id=495337.\n5. T. Ormandy, “Common DNS Misconfiguration Can Lead to ‘Same Site’\nScripting” (January 18, 2008), http://seclists.org/bugtraq/2008/Jan/270.\n6. R. Singel, “ISPs’ Error Page Ads Let Hackers Hijack Entire Web,\nResearcher Discloses,” Wired (April 19, 2008), http://www.wired.com/\nthreatlevel/2008/04/isps-error-page/.\n7. “APSB10-14 Security Update Available for Adobe Flash Player,” Adobe\nSystems Incorporated (June 10, 2010), http://www.adobe.com/support/\nsecurity/bulletins/apsb10-14.html.\n8. “Understanding Flash Player 9 April 2008: Security Update Compatibil-\nity,” Adobe Systems Incorporated (April 8, 2008), http://www.adobe.com/\ndevnet/flashplayer/articles/flash_player9_security_update.html.\n9. “ActionScript® 3.0 Reference for the Adobe® Flash® Platform: URL-\nRequestHeader,” Adobe Systems Incorporated, http://help.adobe.com/\nen_US/FlashPlatform/reference/actionscript/3/flash/net/URLRequestHeader.html.\n10. “ActionScript® 3.0 Reference for the Adobe® Flash® Platform: Security,”\nAdobe Systems Incorporated, http://livedocs.adobe.com/flash/9.0/\nActionScriptLangRefV3/flash/system/Security.html.\n11. “Adobe Cross Domain Policy File Specification,” version 2.0, Adobe Sys-\ntems Incorporated (August 2, 2010), http://learn.adobe.com/wiki/download/\nattachments/64389123/CrossDomain_PolicyFile_Specification.pdf?version=1.\n12. M. Zalewski, “[RAZOR] Linux Kernel IP Masquerading Vulnerability”\n(July 30, 2001), http://seclists.org/bugtraq/2001/Jul/733.\n13. “Silverlight: WebHeaderCollection Class,” Microsoft, http://msdn.microsoft\n.com/en-us/library/system.net.webheadercollection%28v=VS.95%29.aspx.\n14. “Class HttpURLConnection,” Sun Microsystems/Oracle, http://download\n.oracle.com/javase/1.4.2/docs/api/java/net/HttpURLConnection.html.\n15. “Class URLConnection,” Sun Microsystems/Oracle, http://download\n.oracle.com/javase/1.4.2/docs/api/java/net/URLConnection.html.\n16. “Class Socket,” Sun Microsystems/Oracle, http://download.oracle.com/\njavase/1.4.2/docs/api/java/net/Socket.html.\n17. “Java-to-Javascript Communication,” Sun Microsystems/Oracle, http://\ndownload.oracle.com/javase/1.4.2/docs/guide/plugin/developer_guide/\njava_js.html.\n18. “Java-to-Javascript Communication: Common DOM API,” Sun Microsys-\ntems/Oracle, http://download.oracle.com/javase/1.4.2/docs/guide/plugin/\ndeveloper_guide/java_js.html#common_dom.\n19. B. “Snowhare” Franz, “Triple Dot Cookies” (1998), http://snowhare\n.com/utilities/triple_dot/.\n20. “Adobe ActionScript 3.0: Security Sandboxes,” Adobe Systems Incorpo-\nrated, http://help.adobe.com/en_US/ActionScript/3.0_ProgrammingAS3/\nWS5b3ccc516d4fbf351e63e3d118a9b90204-7e3f.html.\n276 Notes for Pages 148–160\nChapter 10\n1. L. Masinter, “The ‘data’ URL scheme,” IETF Request for Comments\n2397 (1998), http://www.ietf.org/rfc/rfc2397.txt.\n2. M. Zalewski, “about:neterror, certerror permit URL spoofing by being\nsame-origin with about:blank,” Mozilla bug #602780 (CVE-2010-3774)\n(2010), https://bugzilla.mozilla.org/show_bug.cgi?id=602780.\nChapter 11\n1. G. Guninski, “Frame spoofing using loading two frames,” Mozilla bug\n#13871 (1999), https://bugzilla.mozilla.org/show_bug.cgi?id=13871.\n2. R. Zilberman, “Frame spoofing is possible within a short time frame\nwhile the window is loading,” Mozilla bug #381300 (CVE-2007-3089)\n(2008), https://bugzilla.mozilla.org/show_bug.cgi?id=381300.\n3. A. Barth, C. Jackson, and J.C. Mitchell, “Securing Frame Communication\nin Browsers,” Communications of the ACM 52, no. 6 (2009): 83-91, http://\nwww.adambarth.com/papers/2009/barth-jackson-mitchell-cacm.pdf.\n4. R. Hansen and J. Grossman, “Clickjacking” (2008), http://www.sectheory\n.com/clickjacking.htm.\n5. M. Zalewski, “Dealing with UI redress vulnerabilities inherent to the cur-\nrent web” (post to whatwg.org list) (September 25, 2008), http://lists.whatwg\n.org/htdig.cgi/whatwg-whatwg.org/2008-September/thread.html#16292.\n6. E. Lawrence, “IE8 Security Part VII: ClickJacking Defenses,” IEBlog\n(January 27, 2009), http://blogs.msdn.com/b/ie/archive/2009/01/27/\nie8-security-part-vii-clickjacking-defenses.aspx.\n7. SHODAN, “HTTP Header Survey” (March 14, 2011), http://www.shodanhq\n.com/research/infodisc/report.\n8. P. Stone, “Next Generation Clickjacking,” Blackhat Europe (2010), http://\nblog.c22.cc/2010/04/14/blackhat-europe-next-generation-clickjacking-3/.\n9. M. Zalewski, “The curse of inverse strokejacking,” Icamtuf’s blog (June 8,\n2010), http://lcamtuf.blogspot.com/2010/06/curse-of-inverse-strokejacking.html.\n10. C. Evans, “Generic cross-browser cross-domain theft,” Security (blog)\n(December 28, 2009) http://scarybeastsecurity.blogspot.com/2009/12/\ngeneric-cross-browser-cross-domain.html.\n11. C. Evans, “IE8 CSS-based forced tweeting,” Security (blog) (September 29,\n2010), http://scarybeastsecurity.blogspot.com/2010/09/ie8-css-based-forced-\ntweeting.html.\n12. I. Hickson, “HTML: 4.8.11 The canvas element,” WHATWG (2011),\nhttp://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-\nelement.html.\n13. E.W. Felten and M.A. Schneider, “Timing Attacks on Web Privacy,”\nProceedings of the 7th ACM Conference on Computer and Communications\nSecurity (2000), http://sip.cs.princeton.edu/pub/webtiming.pdf.\nNotes for Pages 167–184 277\n14. C. Evans, “Cross-domain search timing,” Security (blog) (December 11,\n2009), http://scarybeastsecurity.blogspot.com/2009/12/cross-domain-search-\ntiming.html.\n15. C. Wilson, P. Le Hégaret, and V. Apparao, “Document Object Model\nCSS: 2.2.1 Override and computed style sheet,” World Wide Web Con-\nsortium (2000), http://www.w3.org/TR/DOM-Level-2-Style/css.html#CSS-\nOverrideAndComputed.\n16. “currentStyle Object,” Microsoft Corporation MSDN Library, http://\nmsdn.microsoft.com/en-us/library/ms535231%28v=vs.85%29.aspx.\n17. A. Clover, “CSS visited pages disclosure” (February 20, 2002), http://\nseclists.org/bugtraq/2002/Feb/271.\n18. Z. Weinberg, E.Y. Chen, P.R. Jayaraman, and C. Jackson, “I Still Know\nWhat You Visited Last Summer” (2011), http://websec.sv.cmu.edu/visited/\nvisited.pdf.\nChapter 12\n1. J. Schwartz, “Giving Web a Memory Cost Its Users Privacy,” New York\nTimes (September 4, 2001), http://www.nytimes.com/2001/09/04/technol-\nogy/04COOK.html.\n2. N. Wingfield, “Microsoft Quashed Effort to Boost Online Privacy,”\nWallStreet Journal (August 2, 2010), http://online.wsj.com/article/\nSB10001424052748703467304575383530439838568.html.\n3. E. Felten, “If You’re Going to Track Me, Please Use Cookies,” Freedom\ntoTinker (blog) (July 7, 2009), http://www.freedom-to-tinker.com/blog/felten/\nif-youre-going-track-me-please-use-cookies.\n4. J. Mayer, A. Narayanan, and S. Stamm, “Do Not Track: A Universal Third-\nParty Web Tracking Opt Out,” IETF Request for Comments (2011), http://\ndatatracker.ietf.org/doc/draft-mayer-do-not-track/?include_text=1.\n5. L. Cranor, M. Langheinrich, M. Marchiori, M. Presler-Marshall, and\nJ.Reagle, “The Platform for Privacy Preferences 1.0 (P3P1.0) Specifica-\ntion,” World Wide Web Consortium (2002), http://www.w3.org/TR/P3P/.\nChapter 13\n1. N. Freed and N. Borenstein, “Multipurpose Internet Mail Extensions\n(MIME) Part Two: Media Types,” IETF Request for Comments 2046\n(1996), http://www.ietf.org/rfc/rfc2046.txt.\n2. V. Gupta, “IE Content-Type Logic,” IEBlog (February 1, 2005), http://\nblogs.msdn.com/b/ie/archive/2005/02/01/364581.aspx.\n3. SHODAN, “HTTP Header Survey” (2011), http://www.shodanhq.com/\nresearch/infodisc/download_latest.\n278 Notes for Pages 184–203\n4. R. Troost, S. Dorner, and K. Moore, “Communicating Presentation\nInformation in Internet Messages: The Content-Disposition Header\nField,” IETF Request for Comments 2183 (1997), http://www.ietf.org/\nrfc/rfc2183.txt.\n5. G. Heyes, “Inline UTF-7 E4X Javascript Hijacking,” The Spanner (blog)\n(February 24, 2009), http://www.thespanner.co.uk/2009/02/24/inline-utf-\n7-e4x-javascript-hijacking/.\nChapter 14\n1. M. Zalewski, “URL Spoofing Is Likely Possible Through Address Bar Elid-\ning” (2010), https://bugzilla.mozilla.org/show_bug.cgi?id=581313.\n2. R. J. Kosinski, “A Literature Review on Reaction Time,” Clemson Uni-\nversity (2010), http://biae.clemson.edu/bpc/bp/Lab/110/reaction.htm\n#Type%20of%20Stimulus.\n3. M. Zalewski, “Bug 376473: File Action Dialog Controls Vulnerable to\nRefocus Race” (2007), https://bugzilla.mozilla.org/show_bug.cgi?id=376473.\n4. M. Zalewski, “Geolocation Spoofing and Other UI Woes,” Bugtraq (mail-\ning list) (August 17, 2010), http://seclists.org/bugtraq/2010/Aug/201.\n5. D. Simons and C. Chabris, “Selective Attention Test” (1999), http://www\n.youtube.com/watch?v=vJG698U2Mvo&feature=player_embedded.\n6. D.J. Simmons and C.F. Chabris, “Gorillas in our midst: Sustained inatten-\ntional blindness for dynamic events,” Perception, 28, 1059–1074 (1999),\nhttp://www.cnbc.cmu.edu/~behrmann/dlpapers/Simons_Chabris.pdf.\nChapter 15\n1. http://www.xssed.com/search?key=addons.mozilla.org\n2. http://openid.net/\n3. “Internet Explorer: Security Zones,” Microsoft, http://technet.microsoft\n.com/en-us/library/dd361896.aspx.\n4. “Internet Explorer Binary Behaviors Security Setting,” Microsoft, http://\ntechnet.microsoft.com/en-us/library/cc776248(WS.10).aspx.\n5. Charles Schwab, “Technical Support,” http://www.visualwebcaster.com/\ncharles_schwab/support/ (accessed September 9, 2011).\n6. Internal Revenue Service, “Streaming Media System Requirements &\nTroubleshooting Assistance,” http://www.irsvideos.gov/sbv_1099webinar/\nplayer/IRS_Webinar_Technical_Support.pdf (accessed September 9, 2011).\n7. “.NET Framework 3.0: Mark of the Web,” Microsoft, http://msdn.microsoft\n.com/en-us/library/ms537628%28VS.85%29.aspx.\n8. “Persistent Zone Identifier Object,” Microsoft, http://msdn.microsoft.com/\nen-us/library/ms537029%28VS.85%29.aspx.\nNotes for Pages 203–231 279\nChapter 16\n1. A. van Kesteren, “Cross-Origin Resource Sharing,” (working draft) World\nWide Web Consortium (July 27, 2010), http://www.w3.org/TR/cors/.\n2. S. Dutta, “Updates for AJAX in IE8 Beta 2,” IEBlog (2008), http://blogs\n.msdn.com/b/ie/archive/2008/10/06/updates-for-ajax-in-ie8-beta-2.aspx.\n3. “.NET Framework 3.0: XDomainRequest Object,” Microsoft Developer\nNetwork, http://msdn.microsoft.com/en-us/library/cc288060%28v=vs\n.85%29.aspx.\n4. T. Close and M. Miller, “Uniform Messaging Policy, Level One,” (work-\ning draft) World Wide Web Consortium (January 26, 2010), http://www\n.w3.org/TR/UMP/.\n5. A. Barth, C. Jackson, and J.C. Mitchell, “Robust Defenses for Cross-Site\nRequest Forgery,” ACM Conference on Computer and Communications\nSecurity (2008), http://seclab.stanford.edu/websec/csrf/csrf.pdf.\n6. B. Sterne, “Origin Header Proposal,” http://people.mozilla.com/~bsterne/\ncontent-security-policy/origin-header-proposal.html.\n7. A. van Kesteren, “The From-Origin Header,” (working draft) World\nWide Web Consortium (July 21, 2011), http://www.w3.org/TR/2011/\nWD-from-origin-20110721/.\n8. A. Barth, “The Web Origin Concept (v. 9),” IETF Draft (November 26,\n2010), http://tools.ietf.org/html/draft-abarth-origin-09.\n9. B. Sterne, “Content Security Policy” (2008), http://people.mozilla.com/\n~bsterne/content-security-policy/.\n10. B. Sterne, “Content Security Policy,” (draft) World Wide Web Consor-\ntium (March 15, 2011), https://dvcs.w3.org/hg/content-security-policy/raw-file/\ntip/csp-unofficial-draft-20110315.html.\n11. I. Hickson, “HTML Living Standard,” WHATWG (2011), http://www\n.whatwg.org/specs/web-apps/current-work/multipage/the-iframe-element.html\n#attr-iframe-sandbox.\n12. J. Hodges, C. Jackson, and A. Barth, “HTTP Strict Transport Security\n(HSTS),” (draft) IETF Request for Comments (August 5, 2011), http://\ntools.ietf.org/html/draft-ietf-websec-strict-transport-sec-02.\n13. A. Klein, “Google Chrome 6.0 and Above: Math.random Vulnerability”\n(2010), http://www.trusteer.com/sites/default/files/Google_Chrome_6.0_and\n_7.0_Math.random_vulnerability.pdf.\n14. “.NET Framework 3.0: toStaticHTML Method,” Microsoft, http://msdn\n.microsoft.com/en-us/library/cc848922%28v=vs.85%29.aspx.\n15. D. Ross, “IE8 Security Part IV: The XSS Filter,” IEBlog (2008), http://blogs\n.msdn.com/b/ie/archive/2008/07/02/ie8-security-part-iv-the-xss-filter.aspx.\n16. E. Vela Nava and D. Lindsay, “Abusing Internet Explorer 8’s XSS Filters”\n(2009), http://p42.us/ie8xss/Abusing_IE8s_XSS_Filters.pdf.\n280 Notes for Pages 236–251\nChapter 17\n1. “navigator.registerProtocolHandler,” Mozilla Developer Network, https://\ndeveloper.mozilla.org/en/DOM/window.navigator.registerProtocolHandler.\n2. “Manipulating the Browser History,” Mozilla Developer Network, https://\ndeveloper.mozilla.org/en/DOM/Manipulating_the_browser_history/.\n3. A. Langley and M. Belsche, “SPDY: An Experimental Protocol for a\nFaster Web,” The Chromium Projects, http://www.chromium.org/spdy/\nspdy-whitepaper/.\n4. I. Fette and A. Melnikov, “The WebSocket Protocol,” IETF Request\nforComments draft (2011), http://tools.ietf.org/html/draft-ietf-hybi-\nthewebsocketprotocol-10/.\n5. J. Rosenberg, M. Kaufman, M. Hiie, and F. Audet, “An Architectural\nFramework for Browser Based Real-Time Communications,” IETF\nRequest for Comments draft (2011), http://tools.ietf.org/html/draft-\nrosenberg-rtcweb-framework-00/.\n6. I. Hickson, “HTML5: 5.6—Offline Web Applications,” World Wide Web\nConsortium (2011), http://www.w3.org/TR/html5/offline.html.\n7. A. Barth, “Simple HTTP State Management Mechanism,” IETF Request\nfor Comments draft (2010), http://tools.ietf.org/html/draft-abarth-cake-00/.\n8. I. Hickson, “Web SQL Database: W3C Working Group Note 18,” World\nWide Web Consortium (2010), http://www.w3.org/TR/webdatabase/.\n9. N. Mehta, J. Sicking, E. Graff, A. Popescu, and J. Orlow, “Indexed Data-\nbase API: W3C Working Draft 19,” World Wide Web Consortium (2011),\nhttp://www.w3.org/TR/IndexedDB/.\n10. I. Hickson, “Web Applications 1.0: Web Workers,” WHATWG (2011),\nhttp://www.whatwg.org/specs/web-apps/current-work/complete/workers.html.\n11. A. Popescu, “Geolocation API Specification: Editor’s Draft,” World\nWideWeb Consortium (February 10, 2010), http://dev.w3.org/geo/api/\nspec-source.html.\n12. “Detecting Device Orientation,” Mozilla Developer Network, https://\ndeveloper.mozilla.org/en/detecting_device_orientation/.\n13. L. Cai and H. Chen, “TouchLogger: Inferring Keystrokes on Touch\nScreen from Smartphone Motion,” Usenix HOTSEC (2011), http://\nwww.usenix.org/event/hotsec11/tech/final_files/Cai.pdf.\n14. “Web Developer’s Guide to Prerendering in Chrome,” Google code labs,\nhttp://code.google.com/chrome/whitepapers/prerender.html.\n15. Z. Wang, “Navigation Timing: Editor’s Draft,” World Wide Web Consor-\ntium (July 27, 2011), https://dvcs.w3.org/hg/webperf/raw-file/tip/specs/\nNavigationTiming/Overview.html.\nNotes for Pages 256–259 281\n16. J. Gregg, “Web Notifications Overview: W3C Editor’s Draft,” World Wide\nWeb Consortium (October 12, 2010), http://dev.w3.org/2006/webapi/\nWebNotifications/publish/.\n17. D.D. Tran, I. Oksanen, and I. Kliche, “The Media Capture API: W3C\nWorking Draft,” World Wide Web Consortium (September 28, 2010),\nhttp://www.w3.org/TR/media-capture-api/.\n282 Notes for Page 259"
  },
  {
    "input": "Index\r",
    "output": "I N D E X\nSymbols & Numbers Accept request header, 43\nAccess-Control-Allow-Origin header,\n& (ampersand), in HTML, 71\n237–238,240\n< > (angle brackets)\nacrobat: scheme, 36\nbrowser interpretation, 74–75\naction parameter, for <form> tag, 80\nin HTML, 71\nActionScript, 132–134\n<![CDATA[...]]> blocks, 72, 78, 250\nActive Server Pages, 75\n<!DOCTYPE> directive, 71\nActiveX, 129, 136–137\n<!ENTITY> directive, 76\naddress bars, 220\n<!-- and -->, for HTML comments, 72\nand EV SSL, 65\n<% ... %> blocks, Internet Explorer\nhiding, 221\nand,75\nmanipulation, 256–257\n@ directives, in CSS, 89–90\nAdobe Flash, 119, 130, 132–134\n\\ (backslashes) in URLs, browser accep-\nand cross-domain HTTP headers, 147n\ntance of, 29\nfile handling without Content-Type, 199\n` (backticks), as quote characters, 74, 111\nHTML parser offered by plug-in, 133\n!- directives, 76\npolicy file spoofing risks, 156–157\n// fixed string, in URLs, 25\nsecurity rules, 154–157\n% (percent sign), for character\nAdobe Reader, 130\nencoding,31\nAdobe Shockwave Player, 132\n. (period), hostnames with, and cookie-\nADS (Alternate Data Stream) Zone\nsetting algorithms, 159\nIdentifier, 231\n?-directives, 76\nadvertisements, new window for, 217\n<?xml-stylesheet href=... ?> directive, 88\nAkamai Download Manager, 137\n; (semicolon), as delimiter\nAllow-forms keyword, for sandbox\nin HTTP headers, 48–49\nparameter, 246\nin URLs, 29\nAllowFullScreen parameter, for Flash, 155\n200–299 status codes, 54\nAllowNetworking parameter, for Flash, 155\n300–399 status codes, 55\nAllow-same-origin keyword, for sandbox\n400–499 status codes, 55–56\nparameter, 246\n500–599 status codes, 56\nAllowScriptAccess parameter, for Flash, 154\nAllow-scripts keyword, for sandbox\nA parameter, 246\nAllow-top-navigation keyword, for sandbox\n<a href=...> tag (HTML), 79\nparameter, 246\ntarget parameter, 174–175\nAlternate Data Stream (ADS) Zone\nabout:blank document, origin inheritance,\nIdentifier, 231\n165, 166–167\nambient authority, 60, 60n\nabout:config (Firefox), navigation risks, 188\nampersand (&), in HTML, 71\nabsolute URLs, vs. relative, 25\nanchor element (HTML), specifying\nAccept-Language request header, 43\nname of, 28\nangle brackets (< >) BMP file format, 83\nbrowser interpretation, 74–75 <body> tag (HTML), 83\nin HTML, 71 BOM (byte order marks), 208\nanonymity, scripts and, 249 Breckman, John, 52n\nanonymous requests, in CORS, 239 browser cache\nanonymous windows, 175 information in, 59\nantimalware, 236n poisoning, 60\nApache browser extensions and UI, 161\nand Host headers, 47 browser-managed site permissions, 226–227\nPATH_INFO, 201 browser market share, May 2011, 19\nAPNG file format, 83 browser-side scripts, 95–116\nApple QuickTime, 119, 130, 132 browser wars, 10–11, 233\nApple Safari. See Safari (Apple) buffer overflow, 265\n<applet> tag (HTML), 83, 128, 135, 183 bugs, preventing classes of, 7\napplication/binary, 212 Bush, Vannevar, 8\napplication/javascript document type, 118 byte order marks (BOM), 208\napplication/json document type, 118, 202\napplication/mathml+xml document type, 119 C\napplication/octet-stream document type,\n200–201, 212 cache. See browser cache\napplication/x-www-for-urlencoded, 81 Cache-Control directive, 48, 59\nArce, Ivan, 2n cache manifests, 257\nArya, Abhishek, 209 cache poisoning, 189, 263\nasynchronous XMLHttpRequest, 146 caching behavior, in HTTP, 58–60\nAtom, 123 caching HTTP proxy, keepalive\n<audio> tag (HTML), 84, 119 sessionsand, 57\nauthentication, in HTTP, 62–63 Caja, 116\nauthorization, vs. authentication, 62n Cake (proposal), 257\nAuthorization header (HTTP), 63 call stack, limiting size, 216\ncallto: scheme, 36\n<canvas> tag (HTML5), 183\nB\nCAPTCHA, 184–185, 185n\nbackground parameter for HTML tags, 83 Cascading Style Sheets (CSS), 11, 12, 73,\nbackground processes, in JavaScript, 258 83, 87–93\nbackslashes (\\) in URLs, browser accep- basic syntax, 88–90\ntance of, 29 character encoding, 91–92\nbackticks (`), as quote characters, 74, 111 interaction with HTML, 90\nBad Request status error (400), 55 opacity property, 179\nbandwidth, and XML, 123n parser resynchronization risks, 90–91\nBarth, Adam, 16, 177, 240, 241, 246, 257 property definitions, 89\nBase64 encoding, 50n case of tags, HTML vs. XML, 72\nbasic credential-passing method, 63 <![CDATA[...]]> blocks, 72, 78, 250\nBell-La Padula security model, 2, 4 certificate authorities, 64\nBerners-Lee, Tim, 9, 41, 69 certificates\nand semantic web, 72–73 extended validation, 65\nWorld Wide Web browser, 9 warning dialog example, 66\nWorld Wide Web Consortium, 11 cf: scheme, 36\n<bgsound> tag (HTML), 84, 119 characters\nbinary HTTP, 257 delimiting, in URLs, 29\nbitmap images, browser recognition of, 118 encoding in CSS, 91–92\nblacklists encoding in filenames, 49–51\nof HTTP headers in XMLHttpRequest, 147 encoding in HTML, 76–78\nmalicious URLs, 236n encoding in JavaScript, 112–113\nencoding in URLs, 31–35\n_blank, as link target, 80\nprintable, browser treatment of, 32\n284 INDEX\nreserved, 31–35 Common UNIX Printing System (CUPS),\nunreserved, 32 152–153\ncharacter sets Common Vulnerability Scoring System\nbyte order marks and detection, 208 (CVSS), 6–7\ndetection for non-HTTP files, 210–211 Common Weakness Enumeration (CWE), 6\nhandling, 206–211 complex selectors, in CSS, 88\nfor headers, 49–51 computer proficiency of user, 14\ninheritance and override, 209 conditionals, explicit and implicit, in\nmarkup-controlled, on subresources, HTML, 75–76\n209–210 conflicting headers, resolution of, 47–48\nsniffing, 264 CONNECT requests, 46, 54\nin URLs, 33 Connolly, Dan, 9\n@charset (CSS), 89 content directives, on subresources, 204\nchildren objects in JavaScript, 108 Content-Disposition directive, 48, 84, 122\nChrome defensive uses, 203–204\nautodetection of passive document NUL character and, 51\ntypes, 205 plug-in-executed code and, 204\ncached pages in, 37 user-controlled filenames in, 67\ncharacters in URL scheme name content inclusion in HTML\nignored by, 25 hyperlinking and, 79–84\ndeleting JavaScript function, 103 type-specific, 82–84\nand file extensions in URLs, 130 Content-Length header, 43, 52, 147\nlocal file access, 160 in keepalive sessions, 56–58\nmodal dialogs for prompts, 219 content recognition, 197–211\nnavigation timing, 259 content rendering, plug-ins for, 127–138\nprerendering page, 258–259 Content Security Policy (CSP), 242–245,\nprintable characters in, 32 250, 253\nprivileged JavaScript in, 161 criticisms of, 244–245\nand realm string, 63 violations, 244\nand RFC 2047 encoding, 50 content sniffing, 197–198, 205, 264\nstored password retrieval, 228 Content-Type directive, 49, 71, 84\nSWF file handling without application/binary, 212\nContent-Type, 199 application/JavaScript, 118\ntime limits on continuously executing application/json, 118, 202\nscripts, 215 application/mathml+xml, 119\nWebKit parsing engine, 70n application/octet-stream, 200–201, 212\nwindow.open() function and, 218 charset parameter, 206, 208\nWindows Presentation Foundation image/jpeg, 118, 202, 205\nplug-ins, 136 image/svg+xml, 124\nchunked data transfers, 57–58 logic to handle absence, 198–199\nclickjacking, 179, 180–181, 263 plug-ins and, 128, 204\nclick() method, 218 slash-delmited alphanumeric\nclient certificates, 64–66 tokensin,199\nclient-server architecture, 17–18 special values, 200–201\nclient-side data, 165 text/css, 118\nclient-side databases, 258 text/html, 124\nclient-side errors (400–499), 55–56 text/plain, 118, 156, 200–201, 204, 212\nclient-side scripts, restricting privileges of unrecognized, 202–203\nHTML generated by, 250–251 and XML document parsing, 120\ncloud, 15 control characters, JavaScript shorthand\nClover, Andrew, 184 notation, 112\ncommand injection, 265 cookie-authenticated text, reading, 181\ncomments Cookie header. See cookies\nin CSS syntax, 89 cookie injection, 264\nin XHTML and HTML, 72\nINDEX 285\ncookies, 11, 257 D\ndeleting, 62\ndaap: scheme, 36\nand DNS hijacking, 153\ndata: scheme, 37, 167–168\nforcing, 264\ndata transfers, chunked, 57–58\nlimitations on third-party, 192–194\nDate/If-Modified-Since header pair, 59\nand same-origin policy, 150–151\ndeceptive framing, 180\nsecurity policy for, 149–153\ndedicated workers, for background\nsemantics, 60–62\nprocesses, 258\nuser data in, 67\ndefault policy, CSP directive for, 243\nCORS. See Cross-Origin Resource\ndefault ports, for protocols, overriding, 27\nSharing(CORS)\nDELETE method (HTTP), 53\nCR characters, stripping from HTTP\ndeleting\nheaders, 45\ncookies, 62\ncredential-passing methods, 63\nJavaScript functions, 102–103\ncredentials, in URLs, 26\ndelimiting characters, in URLs, 29\nCRLF (newline), 45\ndenial-of-service (DoS) attacks, 214–219,\ncross-browser interactions, 16–17\n248, 264\ncross-document links, 8, 9\nDeviceOrientation API, 258\ncross-domain communications, and frame\ndialog use restrictions, 218–219\ndescendant policy, 176–178\ndigest credential-passing method, 63\ncross-domain content inclusion, 181–183\nDigital Rights Management (DRM), 131\ncross-domain policy files, 155–156\ndirectory traversal, 265\ncross-domain requests, 236–239\ndisable-xss-protection, 242n\nCross-Origin Resource Sharing (CORS),\n<div> tag (HTML), 73\n148, 236\nDNS hijacking, and cookies, 153\ncurrent status, 239\nDNS labels, security mechanisms\nnon-simple requests and preflight, 238\nbasedon, 142n\nrequest types, 236–237\nDNS names, in URLs, browser\nsecurity checks, 237–238\nacceptance,27\ncross-origin subresources, 183\nDNS pinning, 142n, 190\ncross-site request forgery (XSRF, CSRF),\nDNS rebinding, 142n, 189\n84, 190, 262\nDNT request header, 193\nexploitation of flaws, 190\n<!DOCTYPE> directive, 71\nlogin forms and, 145–146\ndocument.cookie API (JavaScript), 61\ncross-site script inclusion (XSSI), 104n, 262\ndocument.domain property (JavaScript),\ncross-site scripting (XSS), 71, 262\n143–144\nbugs, and password managers, 228\ndocument-level scrollbar, 180\nexploitation of flaws, 190\ndocument namespace, mapping HTML\nfiltering, 251–252, 253\nelements to, 110\ncrossdomain.xml file, 155, 162\ndocument object (JavaScript), 108\nCSP (Content Security Policy), 242–245,\nDocument Object Model, 12, 108,\n250, 253\n109–111, 142–146\nCSRF (cross-site request forgery), 84,\ndocument rendering helpers, 130–131\n190,262\ndocuments\nexploitation of flaws, 190\nchanging location of existing, 174–178\nlogin forms and, 145–146\nscript access to other, 111–112\nCSS. See Cascading Style Sheets (CSS)\ndocument type detection logic, 198–206\nCUPS (Common UNIX Printing System),\nDomain parameter, for cookie, 61\n152–153\ndomains\ncurrentStyle API, 184\nhardcoded, 227\nCVSS (Common Vulnerability Scoring\nproblems with restrictions, 151–152\nSystem), 6–7\nDOMService mechanism, 158\nCWE (Common Weakness Enumeration), 6\nDoS (denial-of-service) attacks, 214–219,\nCyrillic alphabet, homoglyphs in, 35\n248, 264\n286 INDEX\ndownloaded files, 205–206 ExternalInterface.call() API, 133\ndrag-and-drop, 180 External XML Entity (XXE) attack, 76\nDRM (Digital Rights Management), 131\nduplicate headers, resolution of, 47–48 F\nDutta, Sunava, 239\nfalse positives, risk in XSS filtering, 251–252\nfault tolerance, 11\nE\nfeeds, 123–124\nE4X. See ECMAScript for XML (E4X) feed: scheme, 37\nEarthlink, 153 Felten, Ed, 193\nECMA (European Computer Manufac- file extensions, browser response to, 205\nturers Association), 11, 96 file formats. See also plug-ins\nECMAScript, 96 audio and video, 119\nescape codes, 112 bitmap images, 118\nstrict mode, 104 HTML. See HTML\nECMAScript for XML (E4X), 106–107 non-renderable, 124\nEich, Brendan, 95 plaintext, 64, 85, 117–118\nElectronic Frontier Foundation, 109 XML. See XML\nEloquent JavaScript (Haverbeke), 97 file inclusion, 265\n<embed> tag (HTML), 83 file path, hierarchical, in URLs, 27–28\nmixed content, 183 file: protocol, 159–160, 188\nsrc=..., 128 files, downloaded, 205–206\nEMF file format, 83 File Transfer Protocol (FTP), 26n, 205–206\nencapsulating pseudo-protocols, 37–38 filtering\nencoding schemes, for headers, 49–51 pop-up, 217–218\nencryption, protocol-level, 64–66 reserved characters, in HTML, 71\nenctype=\"text/plain\", for <form> tag, 81 Firefox (Mozilla), 13, 17\nendless loop, 101, 215 and ActiveX, 137\nENQUIRE, 9, 10 cached pages in, 37\n<!ENTITY> directive, 76 character set inheritance, 209\nentity encoding, in HTML, 76–78 CORS in, 239\nerror-handling rules, for certificates, 65–66 and credential portion of URLs, 26\nescaping reserved characters, in HTML,71 data: URLs in, 168\nescaping scheme, 91 DNT request header, 193\nEsser, Stefan, 209 entity names, 77\nETag/If-None-Match header pair, 59 external content directives, 90\nEuropean Computer Manufacturers Asso- Gecko parsing engine, 70n\nciation (ECMA), 11, 96 history.pushState() API, 256\neval() function, 102 javascript: URLs in, 169\neval-script, 242n local file access, 160\nEvans, Chris, 181, 182 modal dialogs for prompts, 219\nEV SSL (Extended Validation SSL), 65 multiple cookies for, 62\nexception printable characters in, 32\nfor eval() function, 102 privileged JavaScript in, 161\nrecovery in JavaScript, 100 prompt displayed when saving Content-\nexecution time for scripts, 215–216 Type: image/jpeg document, 205\nExpires directive, 48, 59 redirects to about:blank, 166\nExpires parameter, for cookie, 61 and RFC 2047 encoding, 50\nexplicit conditionals, in HTML, 75–76 RSS and Atom renderers for, 124\nexpression(...) function (CSS), 89 same-origin policy loopholes, 185\nExtended Validation SSL (EV SSL), 65 stored password retrieval, 228\nExtensible Application Markup Language Strict Transport Security support, 248\n(XAML), 134 SWF file handling without\nextension matching, 202n Content-Type, 199\nINDEX 287\nFirefox (continued) getElementsByTagName() function, 109\ntime limits on continuously executing GET method (HTTP), 42, 52, 58, 80–81\nscripts, 215 GetRight download utility, 137\nUTF-8 text in, 50 getters, in JavaScript, 103\nWindows Presentation Foundation getURL() function, 133\nplug-ins, 136 GIFAR vulnerability, 129\nWorker API, 258 GIF file format, 83, 129\nfirefoxurl: protocol, 17, 36 GML (Generalized Markup Language),\nFlash applets, 11 8–9\nfonts Gontmakher, Alex, 35\nCSP directive for, 243 Gonzalez, Albert, 5n\nFlash programs enumeration of, 132 gopher: scheme, 36\nForbidden status code (403), 56 Gosling, James, 134\nforecasting, statistical, 6 GPS data, 226n\nformat-string vulnerability, 266 Grossman, Jeremiah, 179\nform-based password managers, 227–229 Guninski, Georgi, 176\nform feed character, in HTML tag, 74\nforms, 80–82 H\nFound status code (302), 55\nfragment ID, in URLs, 28–29 Hansen, Robert, 179\nframe-ancestors directive, 243 hardcoded domains, 227\nframebusting, 264 Haverbeke, Marijn, Eloquent JavaScript, 97\nframe descendant policy, and cross-domain HDP file format, 83\ncommunications, 176–178 header injection, 45, 239, 262\nframes, 82 headers\ndisabling navigation descendant model, character set and encoding schemes,\n230–231 49–51\nhijacking risks, 175–176 Content Security Policy encoded in, 242\nname attribute of, 175 in HTTP requests, 43\nsandboxed, 245–247 resolution of duplicate or conflicting,\nunsolicited, 178–181 47–48\nand window interactions, 174–181 semicolon-delimited values, 48–49\nframe-src directive, 243 HEAD request (HTTP), 53\nFrom-Origin header, 240 hexadecimal notation, 77, 112\nFTP (File Transfer Protocol), 26n, 205–206 hierarchical file path, in URLs, 27–28\nftp: scheme, 36 history object (JavaScript), 108\nfull-screen mode, proposals for, 259 history.pushState() API, 256\nfully qualified absolute URLs, 24 Hodges, Jeff, 248\nfully restricted URL scheme, 188 homoglyphs, in Cyrillic alphabet, 35\nfunctional notation, in CSS, 89 Host request header, 43\nfunctions hostnames\nJavaScript, overriding, 102–103 extra periods, and cookie-setting\nresolution for JavaScript, 98–99 algorithms, 159\nnon-fully qualified, 159\nHTML (Hypertext Markup Language), 9,\nG\n69–86\nGabrilovich, Evgeniy, 35 basic concepts, 70–73\nGecko parsing engine, 70n case of tags, 72\nGeneralized Markup Language converting to plaintext, 85\n(GML),8–9 CSS interaction with, 90\ngeolocation data, 226 document misidentified as, 198\ngeolocation discovery, 258 document parsing modes, 71–72\ngeolocation-sharing prompts, 223 embedded in feed formats, 124\ngetComputedStyle API, 184 entity encoding, 76–78\ngetElementById() function, 109 explicit and implicit conditionals, 75–76\n288 INDEX\nHTTP integration semantics, 78–79 images\nhyperlinking and content inclusion, bitmap, 118\n79–84 in HTML, 83\nin-browser sanitizers, 250–251 risk of content sniffing on, 202\nmapping elements to document Scalable Vector Graphics (SVG), 83,\nnamespace, 110 121–122\nparser behavior, 73–76 image/svg+xml document type, 124\ntag interactions, 74–75 <img> tag (HTML), 83\ntype-specific content inclusion, 82–84 src parameter, 181\nversion 4, 12 for SVG images, 122\nversion 5, 70, 119, 131 implicit caching, 59\nHTTP (HyperText Transfer Protocol), 9, implicit conditionals, in HTML, 75–76\n41–67 @import, in CSS, 89–90\nauthentication, 62–63 IndexedDB design, 258\nbasic syntax, 42–51 indicator of hierarchical URLs, 25–26\nbinary, 257 information security, 1–8\ncaching behavior, 58–60 inheritance, for vbscript: scheme, 169–170\ncookie semantics, 60–62 inline-script setting, 242n\ndowngrade, 264 innerHTML property, 110–111\nhistory, 41–42 innerStaticHTML API, 251\nHTML integration semantics, 78–79 integer overflow, 266\nnewline handling, 45 Interactive Voice Response (IVR)\nproxy requests, 46–47 systems,236\nrequest types, 52–54 interconnected systems, losses in, 5\nsemantics battle, 72–73 internal networks, access to, 189–190\nsimultaneous connections, 216 Internal Revenue Service, 231\nversion 0.9, 42–43, 44 Internal Server Error (500), 56\nversion 1.0, 42, 43, 44, 48, 59 International Organization for Standard-\nversion 1.1, 42–43, 45, 48, 57, 198 ization (ISO), 11\nhttponly flag, for cookie, 61, 150 Internationalized Domain Names in\nhttp: scheme, 36 Applications (IDNA), 34–35\nHTTPS, 65 Internet Assigned Numbers Authority\ndocuments, 138n, 183 (IANA), 24, 152\ndowngrade risks, 248 Internet Engineering Task Force (IETF), 11\nhttps: scheme, 36 Internet Explorer, 10, 11–12\nhyperlinking, and content inclusion, 79–84 ActiveX and, 137\nHypertext Markup Language (HTML). and <% ... %> blocks, 75\nSeeHTML (Hypertext Markup \\ (backslash) in URLs, 29\nLanguage) acceptance of backtick as quote, 74\nHyperText Transfer Protocol (HTTP). See characters in URL scheme name\nHTTP (HyperText Transfer Protocol) ignored by, 25\nclickjacking, 182\nI content sniffing, 202\ncookies, 149\nIANA (Internet Assigned Numbers data: URLs in, 168\nAuthority), 24, 152 delete attempt of JavaScript function, 103\nICO file format, 83 extension matching, 202\nIDNA (Internationalized Domain Names fallback display, 118\nin Applications), 34–35 and file extensions in URLs, 130\nIETF (Internet Engineering Task Force), 11 frames, 177\nIf-Modified-Since header, 59 JavaScript in, 96\nIf-None-Match header, 59 JSON.parse() function alternative, 104\n<iframe> tag (HTML), 82, 176, 209, 245–247 local file access, 160\nimage/jpeg document type, 118, 202, 205 markup controlled charset on, 209\nINDEX 289\nInternet Explorer (continued) JavaScript, 10, 11n, 83, 95–107\nand multiline headers, 45 character encoding in, 112–113\nmultiline string literals support, 91 code and object inspection capabilities,\nnon-recognition of vertical tab, 112 101–102\nNUL character and, 73, 74 code execution, 100\norigin check and port number, 142 code inclusion modes and nesting risks,\nprintable characters in, 32 113–114\nproprietary security-restricted document.domain property, 143–144\nparameter,246 Document Object Model, 12, 108,\nredirects to about:blank, 166–167 109–111\nand RFC 2047 encoding, 50 embedded in PDF documents, 130\nsame-origin policy and, 143n, 185 execution order control, 100–101\nSilverlight and, 134 labeled statements support, 105n\nstored password retrieval, 228 MIME type, 118n\nSWF file handling without Netscape and, 95–96\nContent-Type, 199 runtime environment for, 102–104\ntext/plain document type, 200–201 script processing model, 97–100\nthird-party cookies blocking, 193 setters and getters, 103\ntime limits on continuously executing standard object hierarchy, 107–112\nscripts, 215 variable declaration, 99\nTrident parsing engine, 70n and WML Script (WMLS), 123\nVBScript, 96, 114 JavaScript Object Notation (JSON),\nwindow.open() function and, 218 104–106, 112\nWindows Presentation Foundation javascript: scheme, 37, 169–170\nplug-ins, 136 Jobs, Steve, 131\nXDomainRequest approach to, 148 JPEG file format, 83\nXSS-detection logic, 251 JScript, 11n\nZone.Identifier metadata, 231 JScript.Encode, 113n\nzone model, 229–231 JSObject mechanism, 158\nInternet Information Server, and Host JSON (JavaScript Object Notation),\nheaders, 47 104–106, 112\nInternet service providers, 153 JSONP (JSON with padding), 106n, 245\nInternet zone, for Internet Explorer, 230 JSON.parse() function, alternatives, 104\ninterstitials, 218\nintrusions K\nescalation of, 5\nnonmonetary costs, 5 Kaminsky, Dan, 153\nInvisible Gorilla experiment, 223 katakana, 33\nIP addresses, and cookies, 158 keepalive sessions, 56–57, 216\nISO (International Organization for Stan- keystroke redirection, 180\ndardization), 11 Kinugawa, Masato, 210\nISO-8859-1 (Western European\ncodepage), 50 L\nitms: scheme, 36\nitpc: scheme, 36 language parameter, for <script> tag, 113n\nIVR (Interactive Voice Response) Lessig, Lawrence, 192\nsystems,236 LF (newline), HTTP quirks in\nhandling,45\nLFI (local file inclusion), 265\nJ\nLie, Wium, Håkon, 87\nJackson, Collin, 16, 177, 184, 240 <link rel=stylesheet> directive, 88\njar: scheme, 37 <link rel=stylesheet href=...> tag, 181\nJava, 134–135, 157–158 LiveScript, 95\nJava Runtime Environment (JRE), 135 livescript: scheme, 37\n290 INDEX\nloadPolicyFile() method, 155–156 Threats Against and Protection of Microsoft’s\nlocal file inclusion (LFI), 265 Internal Network, 5n\nlocal files, access issues, 159–160 Windows operating system, 10\nlocal intranet zone, for Internet Microsoft Office, 130\nExplorer,229 Microsoft Silverlight, 119, 134, 157\nlocal machine zone, for Internet MIME (Multipurpose Internet Mail Exten-\nExplorer,229 sions), 43n, 81n\nlocalhost, danger of, 152–153 malformed types, 199\nlocalStorage object (JavaScript), 148 mapping types to plaintext, 118\nlocation.hash, 256 for plug-ins, 128\nlocation headers, sending user- specialized for content in sandboxed\ncontrolled,67 frame, 247\nlocation.host property, 173 Mitchell, John C., 177, 240\nlocation object (JavaScript), 108, 153–154 mixed content, 183, 262–263\nlocation of documents, changing, 174–178 mmst: scheme, 36\nlogin forms, autocompletion by mmsu: scheme, 36\nbrowsers,228 Mocha language, 95\nlookup functions, in Document Object mocha: scheme, 37\nModel, 109 modal behavior of dialogs, 218–219\nloopback interfaces, 152n Montulli, Lou, 60\nLynx, 10 Mosaic, 10. See also Netscape\nMotW (Mark of the Web), 204, 231\nM mouse cursors, redefining, 89n\nMoved Permanently status code (301), 55\nMacromedia Flash, 132 Mozilla Firefox. See Firefox (Mozilla)\nmailto: protocol, 25, 36, 256 Mozilla specification, 242\nmail user agent (MUA), 203n msbd: scheme, 36\nmalicious sites, blacklist-driven attempts to MsgBox (VBScript), 114\nblock, 226 MUA (mail user agent), 203n\nmanaged code, 134n multiline headers, support for, 45\nMark of the Web (MotW), 204, 231 multiline string literals\nmarkup filter for user content, 86 Internet Explorer support, 91\nmashups, 176 in JavaScript, 113\nMathML (Mathematical Markup Lan- multimedia playback, 130\nguage), 72, 122 Multipurpose Internet Mail Extensions\nMath.random() function, 109 (MIME). See MIME (Multipurpose\nmax-age parameter Internet Mail Extensions)\nfor cookie, 61 My computer zone, for Internet\nfor STS record, 248 Explorer,229\nmedia capture, 259\nMemex, 8\nN\nmemory pointers, 266\nmemory use restrictions for scripts, name attribute, of frames, 175\n215–216 named entities, 76\n<meta> directive, 206, 208 namespace in JavaScript, 107\n<meta http-equiv=> directive, 78–79 name: value pairs, in HTTP requests, 43\nmeta-policies, for Flash, 156–157 name=value pairs\nmhtml protocol, 38 cookies for storing, 60\nMicrosoft. See also Internet Explorer for forms, 81\ndescendant policy development, 177 National Science Foundation, backbone\n.NET Framework with XPAB network, 10\nplug-ins, 136 Naval Research Laboratory, 3–4\nobjections to CORS, 239 navigateToURL() function, 133\nSun suit over Java virtual machine, 135n\nINDEX 291\nnavigation onerror handler, on <img> tag, 184\nto sensitive schemes, 188 onerror parameter, 74\ntiming, 259 onkeydown event (JavaScript), 180\nnavigator.device.capture API, 259 onload handler, to measure load time for\nnavigator.geolocation.getCurrentPosition() document, 184\nAPI, 258 onmousemove events, 222\nnavigator object (JavaScript), 108 opacity property (CSS2), and\nnavigator:registerProtocolHandler() API, 256 JavaScriptcode, 179\nNegotiate authentication method, 63 opener.window.focus() function, 217n\n.NET runtime, 135 OpenGL-based 3D graphics, 131n\nNetflix, 134 open redirection, 263\nNetscape Opera, 10\ncookie specification, 151–152 data: URLs in, 168\nand JavaScript, 95–96 deleting JavaScript function, 103\nand same-origin policy, 142 and file extensions in URLs, 130\nNetscape Navigator, 11 history.pushState() API, 256\nnetwork fenceposts, 264 local file access, 160\nnetworking, HTTP-less, 257 modal dialogs for prompts, 219\nNew York Times, 192 and multiline headers, 45\nnewline, HTTP quirks in handling, 45 period-counting problem in, 159\nnews: scheme, 36 Presto parsing engine, 70n\nNLS, 9 printable characters in, 32\nnntp: scheme, 36 redirects to about:blank, 167\nno-cache value, for Cache-Control header, 59 Refresh redirection to javascript:, 170\nNo Content status code (204), 54 and RFC 2047 encoding, 50\nnoncanonical encodings, 32n RSS and Atom renderers for, 124\nnonencapsulating pseudo-protocols, 37 stored password retrieval, 228\nnon-HTTP resources SWF file handling without\ncharacter set detection for, 210–211 Content-Type, 199\nproxies allowing requests for, 46 Worker API, 258\nnon-renderable file types, 124 OPTIONS method (HTTP), 53\nnon-US-ASCII text, in URLs, 32–35 Origin header, 240–241\nno-store value, for Cache-Control header, 59 origin inheritance, 165–171\nNot Found status code (404), 56 about:blank document, 166–167\nNot Modified status code (304), 55, 59 for javascript: scheme, 169–170\nNotification API, 259 origins\nNTLM authentication method, 63 ambiguous or unexpected, 158–161\nNUL character, and HTTP headers, 51 attempts to broaden, 143\nNUL-containing strings, Ormandy, Tavis, 152\nJavaScriptand,109 outerHTML property, 110–111\noverwriting cookie, 62\nO\nP\nObject Linking and Embedding\n(OLE),136 P2P networking, 257\n<object> tag, 83, 84 P3P (Platform for Privacy Preference), 193\ndata=..., 128 Panopticlick, 109\nmixed content, 183 parallel HTTP connection design, 216\noctal character codes, JavaScript <param> tag (HTML), for plug-ins, 128\nsupport,112 _parent, as link target, 80\nOgg Theora, 119 parsing\nOK status code (200), 54 behavior fundamentals, 73–76\nOLE (Object Linking and JavaScript, 97–98\nEmbedding),136 modes for HTML documents, 71–72\nonbeforeunload dialog, 219n resynchronization risks, 90–91\n292 INDEX\nparsing engines, for browsers, 70n pop-under, 217\nPartial Content status code (206), 54 pop-up filtering, 217–218\npartly restricted URL scheme, 188 ports\npassive multimedia, CSP directive for, 243 default, for protocols, overriding, 27\npassword prohibited, 190–192\nin credentials portion of URLs, 26 positioning windows, 219–222\nform-based managers, 227–229 postMessage(...) API, 144–145, 258\nmethods for passing, 63 POST method (HTTP), 52, 81\nPath parameter, for cookie, 61 postponing JavaScript execution, 101\npath value, for cookie, 149–150 Pragma: no-cache request header, 59\npayload inspection, by Internet prerendering web page, 258–259\nExplorer,202 presentation, HTML tags for, 73\nPDF documents130–131 PresentationHost.exe, 135\npercent encoding, 31 pressed key, examining code of, 180\npercent sign (%), for character Presto parsing engine, 70n\nencoding,31 printable characters, browser\nper-host connection limit, 216 treatmentof, 32\nperiod (.), hostnames with, and cookie- privacy-related side channels, 184–185\nsetting algorithms, 159 private browsing modes, 249, 253\npermissions, browser- and plug-in- private value, for Cache-Control header, 59\nmanaged, 226–227 privileges, site, 225–234\npermitted-cross-domain-policies parameter, prohibited ports, 190–192\nforcrossdomain.xml file, 162 properties, definitions in CSS, 89\npersistent workers, for background proposals\nprocesses, 258 content-level, 258–259\nPetkov, Petko D., 131 I/O interfaces, 259\nphishing, 176n URL- and protocol-level, 256–257\nplaintext protocol-host-port tuple, 142, 241\nconverting HTML to, 85 protocol-level information\nas file format, 117–118 encryption, 64–66\nfor HTTP session information, 64 preserving, 78\n<plaintext> tag (HTML), 72 protocol-level proposals, 256–257\nPlatform for Privacy Preference (P3P), 193 protocols\nplug-ins, 10–11 claimed by third-party applications, 36–37\nActiveX, 129, 136–137 default ports for, overriding, 27\nAdobe Flash. See Adobe Flash registration, 256\napplication frameworks as basis, 131–136 in URL scheme name, 24\ncontent, 83 proxy-originating error responses, browser\nfor content rendering, 127–138 processing, 47\nCSP directive for, 243 proxy requests, 46–47\ndocument rendering helpers, 130–131 pseudo-functions (CSS), 89\ninvoking, 128–130 pseudo-protocols\nMicrosoft Silverlight, 119, 134, 157 encapsulating, 37–38\nfor PDF documents, 130–131 nonencapsulating, 37\nperils of content-type handling, 129–130 pseudo-URLs, 23, 24, 165\nprotocols claimed by, 36–37 restricted, 170–171\nsecurity rules, 153–158 and same-origin policy, 161\nsite permissions management, 226–227 public key cryptography, 64, 64n\nSun Java, 134–135, 157–158 Public Suffix List, 159\nXML browser applications (XBAP), public value, for Cache-Control header, 59\n135–136 public Wi-Fi networks, and HTTP\nPNG file format, 83 cachingrisk, 60\npointers, management vulnerabilities, 266 Punycode, 34\npoisoned browser cache, on trusted purging browser cache, 60\nnetwork, 60 PUT request (HTTP), 53\nINDEX 293\nQ 2616, 44\non GET requests, 58\nquery string in URLs, 28\non HTTP, 42\nQuickTime (Apple), 119, 130, 132\non resolving ambiguities, 47\nquote characters, in HTML, 71, 74\nstatus codes for server response, 54\nquoted-printable encoding scheme, 50n\non URLs, 24\nquoted-string syntax, 48–49\n2617, on authentication, 62\nand cookies, 62\n2818, on encapsulation, 64\nfor CSS property values, 89\n2965, on Cookie2, 60\n3490, 34\nR\n3492, 34\nrace conditions, in JavaScript, 101 3986, 24, 25, 33\nraw text, for CSS property values, 89 4627, on JSON, 104\nReally Simple Syndication (RSS), 123 4918, on WebDAV, 54\nrealm string, 62 6265, on cookies, 61\nRealNetworks RealPlayer, 130, 132 browser permissions to examine\nredirect headers, sending user- payload, 198\ncontrolled,67 on HTTP, 48\nRedirection status codes (300–399), 55 RFI (remote file inclusion), 265\nReferer header, 43, 51 rgb(...) pseudo functions (CSS), 89\nalternative to, 240 Riley, Chris John, 203\nleakage, 263 Rios, Billy, 129\nrelative URLs, 24 risk management, 4–6\nvs. absolute, 25 root object in JavaScript, 107\ninput filters, 40 Ross, David, 251\nresolution of, 38–39 rotate(...) pseudo functions (CSS), 89\nremote file inclusion (RFI), 265 RSS (Really Simple Syndication), 123\nRequest for Comments (RFC). See RFC rtsp: scheme, 36\n(Request for Comments) runtime environment, for JavaScript,\nrequest headers, in HTTP, 43 102–104\nrequest types\nform-triggered, 80–82\nS\nHTTP, 52–54\nreserved characters, in HTML, 31–35, 71 Safari (Apple), 13\nresource exhaustion attacks, 214 and credential portion of URLs, 26\nresponse codes, server, 54–56 deleting JavaScript function, 103\nresponse splitting, 45 hiding address bar, 221\nRestricted sites zone, for Internet and multiline headers, 45\nExplorer, 229–230 and realm string, 63\nrevalidation, 59 RSS and Atom renderers for, 124\nRFC (Request for Comments) SOP bypass flaws, 142n\n1630 stored password retrieval, 228\non query string format, 28 SWF file handling without\non reference parser, 25–26 Content-Type, 199\n1738, on URLs, 24, 25 text/plain document type, 200–201\n1866, on HTML 2.0, 69 third-party cookies, 193\n1945 time limits on continuously executing\non HTTP, 42 scripts, 215\nand TEXT token, 50 WebKit parsing engine, 70n\n2046, on application/octet-stream, 200 safeInnerHTML API, 251\n2047, for non-ISO-8859-1 string same-origin policy mechanism, 16\nformat,50 cookies impact on, 150–151\n2109, on cookies, 60, 61, 62 for Document Object Model, 142–146\n2183, on Content-Disposition header, 203 limitations, 173–186\n2368, on query string format, 28 loopholes, 185\n294 INDEX\nand pseudo-URLs, 161 converting HTML to plaintext, 85\nfor web storage, 148 cross-domain communications in\nfor XMLHttpRequest API, 146–148 JavaScript, 162, 186\nsandbox directive, 244 cross-domain resources, 186\nsandboxed frames, 245–247, 250, 253 cross-domain XMLHttpRequest\nscripting, forms and navigation (CORS),253\nrestrictions, 247 data: and javascript: URLs, 172\nsynthetic origins, 247 decoding parameters received\nsanitization throughURLs, 40\nin-browser HTML, 250–251 embedding plug-in-handled active con-\nof tags, 76 tent from third parties, 162\nScalable Vector Graphics (SVG), 83, enabling plug-in-handled files, 138\n121–122 filtering user-supplies CSS, 93\nscale(...) pseudo functions (CSS), 89 generating documents with partly\nschemes attacker-controlled contents, 212\ncurrent list of valid names, 24 generating HTML documents with\ninput filters, 40 attacker-controlled bits, 85\nname in URLs, 24–25 good practices for all websites, 212\nnavigation to sensitive, 188 hosting user-generated files, 212\nSchwab, Charles, 230–231 hosting XML-based document\nscreen object (JavaScript), 108 formats,125\nscript-nonce directive, 244 hosting your own plug-in-executed\nscripts, 83 content, 163\naccess to other documents, 111–112 hygiene for all HTML documents, 85\nbrowser-side, 95–116 interacting with browser objects on\nconnection limits, 216–217 client side, 115\ndialog use restrictions, 218–219 launching non-HTTP services, 195\nexecution time and memory use restric- loading remote scripts, 115\ntions, 215–216 loading remote stylesheets, 93\npop-up filtering, 217–218 markup filter for user content, 86\nrogue, 213–224 non-HTML document types, 125\nspecifying charset, 209 parsing JSON from server, 115\nscript-src directive (CSP), 242 permitting user-created <iframe>\n<script> tag (HTML), 72 gadgetson site, 224\nJSON and, 104–105 private browsing modes, 253\nlanguage parameter, 113n putting attacker-controlled values\nparsing and, 98 intoCSS, 93\nsrc parameter, 181 relying on HTTP cookies for\n<script> tag (XHTML), 78 authentication, 162\nscrollbar, document-level, 180 requesting elevated permissions within\nSecure attribute, for cookie, 61 web application, 232\nsecure cookies, 150, 162 sandboxed frames, 253\nsecurity security hygiene for all websites, 186\nactions subject to checks, 141 security policy hygiene for all\ndefinition, 2–4 websites,162\nnew and upcoming features, 235–253 security-sensitive UIs, 224\npractical approaches, 7–8 sending user-controlled location\nquality assurance, 7 headers, 67\nSecurity.allowDomain(...) method, for sending user-controlled redirect\nFlash,155 headers, 67\nsecurity dialogs, attacks on, 222–223 serving plug-in-handled files, 138\nsecurity engineering cheat sheet Strict Transport Security, 253\nbuilding web applications on internal third-party cookies for gadgets or sand-\nnetworks, 195 boxed content, 195\nContent Security Policy (CSP), 253 toStaticHTML() API, 253\nINDEX 295\nsecurity engineering cheat sheet site privileges, 225–234\n(continued) browser- and plug-in-managed permis-\nURL input filters, 40 sions, 226–227\nURLs constructed based on user skew(...) pseudo functions (CSS), 89\ninput,40 SMTP (Simple Mail Transfer Protocol),\nuser-controlled filenames in 27, 44, 190\nContent-Disposition headers, 67 social engineering attacks, 32n\nuser-controlled scripts, 116 software, difficulty analyzing behavior of, 3\nuser data in HTTP cookies, 67 <span> tag (HTML), 73\nuser-specified class values on HTML SPDY (Speedy), 257\nmarkup, 93 Spyglass Mosaic, 10\nuser-supplied data inside JavaScript SSL, warnings appearance, 66\nblocks, 115 Standard Generalized Markup Langauge\nwriting browser extensions, 163 (SGML), 9\nwriting plug-ins or extensions recogniz- statistical forecasting, 6\ning privileged origins, 232 Sterne, Brandon, 242\nXDomainRequest, 253 Stone, Paul, 180\nXSS filtering, 253 Strict Transport Security (STS),\nsecurity model extension frameworks, 248–249,253\n236–241 strict XML mode, 72\ncross-domain requests, 236–239 stylesheets\nXDomainRequest, 239–240 CSP directive for, 243\nsecurity model restriction frameworks, specifying charset, 209\n241–249 <style> tag (HTML), 72\nSee Other status code (303), 55 <style> tag (XHTML), 78\nselector suffixes, in CSS, 88 subframes, CSP directive for, 243\n_self, as link target, 80 subresources\nself-closing tag syntax, 72 cross-origin, 183\nsemantic web, 72–73 markup-controlled charset on, 209–210\nsemicolon (;), as delimiter Sun Java, 134–135, 157–158\nin HTTP headers, 48–49 Sun Microsystems, 129\nin URLs, 29 SVG (Scalable Vector Graphics), 83,\nserver address, in URLs, 26–27 121–122\nserver port, in URLs, 27 <svg> tag (HTML5), 122\nserver response codes, 54–56 synchronous XMLHttpRequest, 146\nserver-side code, common problems syntax-delimiting characters, in URLs, 31\nunique to, 265–266 “syntax error” message, retrieved file\nserver-side errors (500–599), 56 snippet in, 181\nService Unavailable error (503), 56\nsessionStorage object (JavaScript), 148 T\nSet-Cookie headers, 61\nsetters, in JavaScript, 103 <table> tag (HTML), 83\nSGML (Standard Generalized Markup tags, in HTML, 70\nLangauge), 9 handling those not closed before end\nshared workers, for background offile, 75\nprocesses,258 interactions, 74–75\nShockwave Flash, 132 sanitization, 76\nSHODAN, 203 target parameter, for <a href=...> tag\nshowModalDialog() method, 217 (HTML), 79, 174–175\nshttp: scheme, 36 taxonomy, 6–7\nSimple Mail Transfer Protocol (SMTP), TCP/IP, HTTP and, 42\n27, 44, 190 TCP (Transmission Control Protocol), 42n\nsip: scheme, 36 connections via XMLSocket, 156\n<site-control permitted-cross-domain- list of prohibited ports, 190–192\npolicies=.\"..\"> parameter, 157 Temporary Redirect status code (307), 55\n296 INDEX\ntesting, for Internet Explorer use, 112 Uniform Messaging Policy, 240\ntext/css document type, 118 Uniform Resource Locators (URLs), 23–40\ntext/csv document type, 198 browser processing, 29–31\ntext/html document type, 124 common schemes, 36–38\ntext message, sending to window with constructing based on user input, 40\nvalid JavaScript handle, 144 encoding, 31\ntext/plain document type, 118, 156, encoding data in fragment\n200–201, 204, 212 identifiers,144n\nTEXT token, 50 fully qualified absolute, 24\n<textarea> tag (HTML), 72, 111 hiding with encapsulating protocols, 38\nthird-party applications, protocols claimed navigation based on tiers of schemes, 188\nby, 36–37 resolution of relative, 38–39\nthird-party cookies, limitations, 192–194 structure, 24–31\nthreat evolution, 14–18 credentials, 26\ncloud, 15 fragment ID, 28–29\nnonconvergence of visions, 15–16 hierarchical file path, 27–28\nuser as security flaw, 14–15 indicator of hierarchical URLs, 25–26\nThreats Against and Protection of Microsoft’s query string, 28\nInternal Network (Microsoft), 5n scheme name, 24–25\nthree-step TCP handshake, 56 server address, 26–27\nTIFF file format, 83 server port, 27\ntimer, in JavaScript, 101 UniformRequest API, 240\ntiming attacks, on user interfaces, 222–223 University of Illinois, 10\nTLS (Transport Layer Security), 64 Unix services, listener process, 216n\n_top, as link target, 80 unreserved characters, in HTML, 32\ntop-level domains, 152 unrestricted URL scheme, 188\ntoSource() method (JavaScript), 101 URLs (Uniform Resource Locators). See\ntoStaticHTML() API, 250–251, 253 Uniform Resource Locators (URLs)\ntoString() method (JavaScript), 101 URL-handling APIs, 133\nTRACE method (HTTP), 53 URL-level proposals, 256–257\ntracking, unscrupulous online, 193 url(...) pseudo-functions (CSS), 89\ntragedy of the commons dilemma, 3 user\nTransfer-Encoding: chunked scheme, 58 browsing habits, Referer header and, 51\nTransmission Control Protocol (TCP). See collecting information about\nTCP (Transmission Control Protocol) interaction, 184\nTransport Layer Security (TLS), 64 as security flaw, 14–15\nTrident parsing engine, 70n URL construction based on input, 40\nTrusted sites zone, for Internet User-Agent request header, 43\nExplorer,229 user content, markup filter for, 86\nTuring, Alan, 3n user-controlled filenames in Content-\ntype parameter, for plug-in tag, 128 Disposition headers, 67\nuser data in HTTP cookies, 67\nU user interfaces\nbrowser extensions and, 161\nUI spoofing attacks, and Flash, 132 notifications, 259\nunauthenticated requests, by browser, 62 timing attacks on, 222–223\nUnauthorized status error (401), 55, 62 username, in credentials portion\nunhandled exception, in JavaScript, 100 ofURLs,26\nUnicode, 33 UTF-7 charset, 78\ndecimal &#number; notation for, 77 UTF-8 charset, 33, 206\nescaping method based on, 113 in HTTP headers, 50\nJavaScript support, 112 UTF-16 charset, 78, 206\nwhitespace, 74n UTF-32 charset, 78\nINDEX 297\nV window.blur() function, 217n, 220\nwindow.confirm() API, 218\nvalid scheme names, current list, 24\nwindow.createPopup() API, 222\nvariables, declaration in JavaScript, 99\nwindow.focus() method, 220\nVBScript, 96\nwindow handles, 175\nvbscript: scheme, 37, 169–170\nwindow.moveTo() method, 220\nvertical tab, in HTML tag, 74\nwindow.name property, of frames, 175\n<video> tag (HTML5), 84, 119, 131\nwindow.notifications API, 259\nview-cache: scheme, 37\nwindow.open() function, 111, 174–175, 217,\nView > Encoding menu, 209\n217n, 219, 222\nview-source: scheme, 37\nwindow.print() API, 218\nVisual Basic, 10, 114, 130\nwindow.prompt() API, 218\nVoiceXML, 236\nwindow.resizeTo() method, 220\nwindows\nW anonymous, 175\ncreating new in browser, 217\nW3C (World Wide Web Consortium),\nand frame interactions, 174–181\n12,70\npositioning, 219–222\nw3m, 10\nwindow.showModalDialog() API, 217\nWAP (Wireless Application Protocol\nWindows Media Player, 119, 130, 132\nsuite), 123\nWindows operating system, 10, 13\nWBXML, 123n\nwindow splicing, 220–221\nWDP file format, 83\nWindows Presentation Foundation,\nWeb, the. See World Wide Web\n134,136\nweb 2.0, 12–13\nWireless Application Protocol\nweb applications\nsuite(WAP), 123\ndesign issues, 263–265\nWireless Markup Language (WML), 123\nvulnerabilities specific to, 262–263\nWMF file format, 83\nWebDAV, 54\nWML Script (WMLS), and JavaScript, 123\nWebGL, 131, 131n\nWML (Wireless Markup Language), 123\nWeb Hypertext Application Technology\nWorker API, 258\nWorking Group (WHATWG), 13\nWorld Wide Web\nWebKit parsing engine, 70n, 242\nbrowser wars, 10–11, 233\ncharacter set inheritance, 209\nhistory, 8–13\nCORS in, 237, 239\nthreat of hostile takeover, 131\ndata: URLs in, 168\nWorld Wide Web Consortium (W3C),\nhistory.pushState() API, 256\n12,70\nRefresh redirection to javascript:, 170\ncreation of, 11\nStrict Transport Security support, 248\nMicrosoft and, 239\nWorker API, 258\nworms, 12\nXSS-detection logic, 251\nWWW-Authenticate header, 62, 63\nweb page, prerendering, 258–259\nwyciwyg: scheme, 37\nweb storage, same-origin policy mecha-\nnism for, 148\nWebRTC, 257 X\nWebSocket API, 257\nXAML (Extensible Application Markup\nWebSQL API, 258\nLanguage), 134\nWestern European code page\nXanadu, 9\n(ISO-8859-1), 50\nXBAP (XML browser applications), 135–136\nWHATWG (Web Hypertext Application\nXBL bindings, 89–90\nTechnology Working Group), 13\nX-Content-Type-Options header, 208\nwhitelists, 226\nX-Content-Type-Options: nosniff header, 203\nwhitespace, 74, 92\nXDomainRequest API, 239–240, 253\nwindow.alert() API, 218\nX-Frame-Options header, 179–180, 243\n298 INDEX\nXHTML, 12\nand HTML entities, 78\nminimal fault-tolerance of parser, 73\nnamed entities, 76\nsyntax, 70\nXML (Extensible Markup Language)\nand bandwidth, 123n\nbinary-only serialization, 123n\ncase of tags, 72\n<![CDATA[...]]> blocks, 72, 78, 250\nXML Binding Language files, 90\nXML browser applications (XBAP),\n135–136\nXML documents\nbrowser support, 119–124\ngeneric view, 120–121\nXMLHttpRequest API, 12, 54, 210, 236,\n237–238\nhttponly cookies and, 150\nsame-origin policy mechanism for,\n146–148\nxmlns namespace, 72, 119\n<?xml-stylesheet href=... ?> directive, 88\nXML User Interface Language (XUL),\n122–123\nXMLSocket, TCP connections via, 156\n<xmp> tag (HTML), 72\nXSRF (cross-site request forgery), 84,\n190,262\nexploitation of flaws, 190\nlogin forms and, 145–146\nXSS (cross-site scripting), 71, 262\nbugs, and password managers, 228\nexploitation of flaws, 190\nfiltering, 251–252, 253\nXUL (XML User Interface Language),\n122–123\nXXE (External XML Entity) attack, 76\nZ\nZIP files, extracting content from, 37\nZone.Identifier metadata, Internet Explorer\nand, 231\nzone model, for Internet Explorer,\n229–231\nINDEX 299\nUPDATES\nVisit http://nostarch.com/tangledweb.htm for updates, errata, and other\ninformation.\nMore no-nonsense books from NO STARCH PRESS\nA BUG HUNTER’S DIARY HACKING, 2ND EDITION THE IDA PRO BOOK,\nA Guided Tour Through the Wilds The Art of Exploitation 2ND EDITION\nofSoftware Security by JON ERICKSON The Unofficial Guide to the World’s\nby TOBIAS KLEIN FEBRUARY 2008, 488 PP. W/CD, $49.95 MostPopular Disassembler\nNOVEMBER 2011, 208 PP., $39.95 ISBN 978-1-59327-144-2\nISBN 978-1-59327-385-9 by CHRIS EAGLE\nJULY 2011, 672 PP., $69.95\nISBN 978-1-59327-289-0\nMETASPLOIT PRACTICAL PACKET PRACTICAL MALWARE\nThe Penetration Tester’s Guide ANALYSIS,2ND EDITION ANALYSIS\nby DAVID KENNEDY, JIM O’GORMAN, Using Wireshark to Solve The Hands-On Guide to\nDEVONKEARNS, and MATI AHARONI Real-World Network Problems DissectingMalicious Software\nJULY 2011, 328 PP., $49.95\nISBN 978-1-59327-288-3 by CHRIS SANDERS by MICHAEL SIKORSKI and ANDREW HONIG\nJULY 2011, 280 PP., $49.95 JANUARY 2012, 760 PP., $59.95\nISBN 978-1-59327-266-1 ISBN 978-1-59327-290-6\nPHONE: EMAIL:\n800.420.7240 OR SALES@NOSTARCH.COM\n415.863.9900\nWEB:\nWWW.NOSTARCH.COM\n“T horough and comprehensive coverage from one of the foremost\nexperts in browser security.” — TAVIS ORMANDY, GOOGLE INC.\nModern web applications are built on a tangle of Build mashups and embed gadgets without getting\nQ\ntechnologies that have been developed over time and stung by the tricky frame navigation policy\nthen haphazardly pieced together. Every piece of the\nEmbed or host user-supplied content without running\nQ\nweb application stack, from HTTP requests to browser-\ninto the trap of content sniffing\nside scripts, comes with important yet subtle security\nFor quick reference, “Security Engineering Cheat Sheets”\nconsequences. To keep users safe, it is essential for\nat the end of each chapter offer ready solutions to the\ndevelopers to confidently navigate this landscape.\nproblems you’re most likely to encounter. With coverage\nIn The Tangled Web, Michal Zalewski, one of the world’s\nextending as far as planned HTML5 features, The Tangled\ntop browser security experts, offers a compelling\nWeb will help you create secure web applications to stand\nnarrative that explains exactly how browsers work\nthe test of time.\nand why they’re fundamentally insecure. Rather than\ndispense simplistic advice on vulnerabilities, Zalewski\nABOUT THE AUTHOR\nexamines the entire browser security model, revealing\nweak points and providing crucial information for shoring Michal Zalewski is an internationally recognized\nup web application security. You’ll learn how to: information security expert with a long track record of\ncutting-edge research. He is credited with discovering\nPerform common but surprisingly complex tasks such\nQ\nhundreds of notable security vulnerabilities and\nas URL parsing and HTML sanitization\nfrequently appears on lists of the most influential\nUse modern security features like Strict Transport\nQ security experts. He is the author of Silence on the\nSecurity, Content Security Policy, and Cross-Origin\nWire (No Starch Press), Google’s “Browser Security\nResource Sharing\nHandbook,” and numerous important research papers.\nLeverage many variants of the same-origin policy to\nQ\nsafely compartmentalize complex web applications\nand protect user credentials in case of XSS bugs\nTHE FINEST IN GEEK ENTERTAINMENT™ “I LIE FLAT.”This book uses RepKover—a durable binding that won’t snap shut.\nwww.nostarch.com\n$49.95 ($52.95 CDN) Shelve In: COMPUTERS/SECURITY\nThe\nTangled\nWeb\nA Guide to Securing Modern\nWeb Applications\nZalewski\nMichal Zalewski\nA\nGuide\nto\nSecuring\nModern\nWeb\nApplications"
  }
]