[
  {
    "input": "Conclusion",
    "output": "Table of Contents\nPreface\nIntroduction to Linux and shells\nman\nls\ncd\npwd\nmkdir\nrmdir\nmv\ncp\nopen\ntouch\nfind\nln\ngzip\ngunzip\ntar\nalias\ncat\nless\ntail\nwc\ngrep\nsort\n1\nuniq\ndiff\necho\nchown\nchmod\numask\ndu\ndf\nbasename\ndirname\nps\ntop\nkill\nkillall\njobs\nbg\nfg\ntype\nwhich\nnohup\nxargs\nvim\nemacs\nnano\nwhoami\nwho\nsu\nsudo\n2\npasswd\nping\ntraceroute\nclear\nhistory\nexport\ncrontab\nuname\nenv\nprintenv\nConclusion\n3\nPreface\nThe Linux Commands Handbook follows the 80/20\nrule: learn in 20% of the time the 80% of a topic.\nI find this approach gives a well-rounded overview.\nThis book does not try to cover everything under the\nsun related to Linux and its commands. It focuses on\nthe small core commands that you will use the 80% or\n90% of the time, trying to simplify the usage of the\nmore complex ones.\nAll those commands work on Linux, macOS, WSL,\nand anywhere you have a UNIX environment.\nI hope the contents of this book will help you achieve\nwhat you want: get comfortable with Linux.\nThis book is written by Flavio. I publish\nprogramming tutorials every day on my website\nflaviocopes.com.\nYou can reach me on Twitter @flaviocopes.\nEnjoy!\n4\nIntroduction to Linux and\nshells\nLinux is an operating system, like macOS or Windows.\nIt is also the most popular Open Source and free, as in\nfreedom, operating system.\nIt powers the vast majority of the servers that\ncompose the Internet. It's the base upon which\neverything is built upon. But not just that. Android is\nbased on (a modified version of) Linux.\nThe Linux \"core\" (called kernel) was born in 1991 in\nFinland, and it went a really long way from its humble\nbeginnings. It went on to be the kernel of the GNU\nOperating System, creating the duo GNU/Linux.\nThere's one thing about Linux that corporations like\nMicrosoft and Apple, or Google, will never be able to\noffer: the freedom to do whatever you want with your\ncomputer.\nThey're actually going in the opposite direction,\nbuilding walled gardens, especially on the mobile side.\nLinux is the ultimate freedom.\nIt is developed by volunteers, some paid by\ncompanies that rely on it, some independently, but\nthere's no single commercial company that can dictate\nwhat goes into Linux, or the project priorities.\n5\nLinux can also be used as your day to day computer. I\nuse macOS because I really enjoy the applications,\nthe design and I also used to be an iOS and Mac apps\ndeveloper, but before using it I used Linux as my main\ncomputer Operating System.\nNo one can dictate which apps you can run, or \"call\nhome\" with apps that track you, your position, and\nmore.\nLinux is also special because there's not just \"one\nLinux\", like it happens on Windows or macOS.\nInstead, we have distributions.\nA \"distro\" is made by a company or organization and\npackages the Linux core with additional programs and\ntooling.\nFor example you have Debian, Red Hat, and Ubuntu,\nprobably the most popular.\nMany, many more exist. You can create your own\ndistribution, too. But most likely you'll use a popular\none, one that has lots of users and a community of\npeople around it, so you can do what you need to do\nwithout losing too much time reinventing the wheel\nand figuring out answers to common problems.\nSome desktop computers and laptops ship with Linux\npreinstalled. Or you can install it on your Windows-\nbased computer, or on a Mac.\nBut you don't need to disrupt your existing computer\njust to get an idea of how Linux works.\nI don't have a Linux computer.\n6\nIf you use a Mac you need to know that under the\nhood macOS is a UNIX Operating System, and it\nshares a lot of the same ideas and software that a\nGNU/Linux system uses, because GNU/Linux is a free\nalternative to UNIX.\nUNIX is an umbrella term that groups many\noperating systems used in big corporations and\ninstitutions, starting from the 70's\nThe macOS terminal gives you access to the same\nexact commands I'll describe in the rest of this\nhandbook.\nMicrosoft has an official Windows Subsystem for Linux\nwhich you can (and should!) install on Windows. This\nwill give you the ability to run Linux in a very easy way\non your PC.\nBut the vast majority of the time you will run a Linux\ncomputer in the cloud via a VPS (Virtual Private\nServer) like DigitalOcean.\nA shell is a command interpreter that exposes to the\nuser an interface to work with the underlying operating\nsystem.\nIt allows you to execute operations using text and\ncommands, and it provides users advanced features\nlike being able to create scripts.\nThis is important: shells let you perform things in a\nmore optimized way than a GUI (Graphical User\nInterface) could ever possibly let you do. Command\nline tools can offer many different configuration options\nwithout being too complex to use.\n7\nThere are many different kind of shells. This post\nfocuses on Unix shells, the ones that you will find\ncommonly on Linux and macOS computers.\nMany different kind of shells were created for those\nsystems over time, and a few of them dominate the\nspace: Bash, Csh, Zsh, Fish and many more!\nAll shells originate from the Bourne Shell, called sh .\n\"Bourne\" because its creator was Steve Bourne.\nBash means Bourne-again shell. sh was proprietary\nand not open source, and Bash was created in 1989\nto create a free alternative for the GNU project and the\nFree Software Foundation. Since projects had to pay\nto use the Bourne shell, Bash became very popular.\nIf you use a Mac, try opening your Mac terminal. That\nby default is running ZSH. (or, pre-Catalina, Bash)\nYou can set up your system to run any kind of shell,\nfor example I use the Fish shell.\nEach single shell has its own unique features and\nadvanced usage, but they all share a common\nfunctionality: they can let you execute programs, and\nthey can be programmed.\nIn the rest of this handbook we'll see in detail the most\ncommon commands you will use.\n8\nman\nThe first command I want to introduce is a command\nthat will help you understand all the other commands.\nEvery time I don't know how to use a command, I type\nman <command> to get the manual:\nThis is a man (from manual) page. Man pages are an\nessential tool to learn, as a developer. They contain so\nmuch information that sometimes it's almost too much.\nThe above screenshot is just 1 of 14 screens of\nexplanation for the ls command.\nMost of the times when I'm in need to learn a\ncommand quickly I use this site called tldr pages:\nhttps://tldr.sh/. It's a command you can install, then\nyou run it like this: tldr <command> , which gives you a\nvery quick overview of a command, with some handy\nexamples of common usage scenarios:\n9\nThis is not a substitute for man , but a handy tool to\navoid losing yourself in the huge amount of\ninformation present in a man page. Then you can use\nthe man page to explore all the different options and\nparameters you can use on a command.\n10\nls\nInside a folder you can list all the files that the folder\ncontains using the ls command:\nls\nIf you add a folder name or path, it will print that folder\ncontents:\nls /bin\nls accepts a lot of options. One of my favorite\noptions combinations is -al . Try it:\nls -al /bin\n11\ncompared to the plain ls , this returns much more\ninformation.\nYou have, from left to right:\nthe file permissions (and if your system supports\nACLs, you get an ACL flag as well)\nthe number of links to that file\nthe owner of the file\nthe group of the file\nthe file size in bytes\nthe file modified datetime\nthe file name\nThis set of data is generated by the l option. The a\noption instead also shows the hidden files.\nHidden files are files that start with a dot ( . ).\n12\ncd\nOnce you have a folder, you can move into it using the\ncd command. cd means change directory. You\ninvoke it specifying a folder to move into. You can\nspecify a folder name, or an entire path.\nExample:\nmkdir fruits\ncd fruits\nNow you are into the fruits folder.\nYou can use the .. special path to indicate the\nparent folder:\ncd .. #back to the home folder\nThe # character indicates the start of the comment,\nwhich lasts for the entire line after it's found.\nYou can use it to form a path:\nmkdir fruits\nmkdir cars\ncd fruits\ncd ../cars\nThere is another special path indicator which is . ,\nand indicates the current folder.\nYou can also use absolute paths, which start from the\nroot folder / :\n13\ncd /etc\nThis command works on Linux, macOS, WSL,\nand anywhere you have a UNIX environment\n14\npwd\nWhenever you feel lost in the filesystem, call the pwd\ncommand to know where you are:\npwd\nIt will print the current folder path.\n15\nmkdir\nYou create folders using the mkdir command:\nmkdir fruits\nYou can create multiple folders with one command:\nmkdir dogs cars\nYou can also create multiple nested folders by adding\nthe -p option:\nmkdir -p fruits/apples\nOptions in UNIX commands commonly take this form.\nYou add them right after the command name, and they\nchange how the command behaves. You can often\ncombine multiple options, too.\nYou can find which options a command supports by\ntyping man <commandname> . Try now with man mkdir\nfor example (press the q key to esc the man page).\nMan pages are the amazing built-in help for UNIX.\n16\nrmdir\nJust as you can create a folder using mkdir , you can\ndelete a folder using rmdir :\nmkdir fruits\nrmdir fruits\nYou can also delete multiple folders at once:\nmkdir fruits cars\nrmdir fruits cars\nThe folder you delete must be empty.\nTo delete folders with files in them, we'll use the more\ngeneric rm command which deletes files and folders,\nusing the -rf options:\nrm -rf fruits cars\nBe careful as this command does not ask for\nconfirmation and it will immediately remove anything\nyou ask it to remove.\nThere is no bin when removing files from the\ncommand line, and recovering lost files can be hard.\n17\nmv\nOnce you have a file, you can move it around using\nthe mv command. You specify the file current path,\nand its new path:\ntouch pear\nmv pear new_pear\nThe pear file is now moved to new_pear . This is how\nyou rename files and folders.\nIf the last parameter is a folder, the file located at the\nfirst parameter path is going to be moved into that\nfolder. In this case, you can specify a list of files and\nthey will all be moved in the folder path identified by\nthe last parameter:\ntouch pear\ntouch apple\nmkdir fruits\nmv pear apple fruits #pear and apple moved to the fr\n18\ncp\nYou can copy a file using the cp command:\ntouch test\ncp apple another_apple\nTo copy folders you need to add the -r option to\nrecursively copy the whole folder contents:\nmkdir fruits\ncp -r fruits cars\n19\nopen\nThe open command lets you open a file using this\nsyntax:\nopen <filename>\nYou can also open a directory, which on macOS opens\nthe Finder app with the current directory open:\nopen <directory name>\nI use it all the time to open the current directory:\nopen .\nThe special . symbol points to the current\ndirectory, as .. points to the parent directory\nThe same command can also be be used to run an\napplication:\nopen <application name>\n20\ntouch\nYou can create an empty file using the touch\ncommand:\ntouch apple\nIf the file already exists, it opens the file in write mode,\nand the timestamp of the file is updated.\n21\nfind\nThe find command can be used to find files or\nfolders matching a particular search pattern. It\nsearches recursively.\nLet's learn it by example.\nFind all the files under the current tree that have the\n.js extension and print the relative path of each file\nmatching:\nfind . -name '*.js'\nIt's important to use quotes around special characters\nlike * to avoid the shell interpreting them.\nFind directories under the current tree matching the\nname \"src\":\nfind . -type d -name src\nUse -type f to search only files, or -type l to only\nsearch symbolic links.\n-name is case sensitive. use -iname to perform a\ncase-insensitive search.\nYou can search under multiple root trees:\nfind folder1 folder2 -name filename.txt\n22\nFind directories under the current tree matching the\nname \"node_modules\" or 'public':\nfind . -type d -name node_modules -or -name public\nYou can also exclude a path, using -not -path :\nfind . -type d -name '*.md' -not -path 'node_modules\nYou can search files that have more than 100\ncharacters (bytes) in them:\nfind . -type f -size +100c\nSearch files bigger than 100KB but smaller than 1MB:\nfind . -type f -size +100k -size -1M\nSearch files edited more than 3 days ago\nfind . -type f -mtime +3\nSearch files edited in the last 24 hours\nfind . -type f -mtime -1\nYou can delete all the files matching a search by\nadding the -delete option. This deletes all the files\nedited in the last 24 hours:\nfind . -type f -mtime -1 -delete\n23\nYou can execute a command on each result of the\nsearch. In this example we run cat to print the file\ncontent:\nfind . -type f -exec cat {} \\;\nnotice the terminating \\; . {} is filled with the file\nname at execution time.\n24\nln\nThe ln command is part of the Linux file system\ncommands.\nIt's used to create links. What is a link? It's like a\npointer to another file. A file that points to another file.\nYou might be familiar with Windows shortcuts. They're\nsimilar.\nWe have 2 types of links: hard links and soft links.\nHard links\nHard links are rarely used. They have a few\nlimitations: you can't link to directories, and you can't\nlink to external filesystems (disks).\nA hard link is created using\nln <original> <link>\nFor example, say you have a file called recipes.txt.\nYou can create a hard link to it using:\nln recipes.txt newrecipes.txt\nThe new hard link you created is indistinguishable\nfrom a regular file:\n25\nNow any time you edit any of those files, the content\nwill be updated for both.\nIf you delete the original file, the link will still contain\nthe original file content, as that's not removed until\nthere is one hard link pointing to it.\nSoft links\nSoft links are different. They are more powerful as you\ncan link to other filesystems and to directories, but\nwhen the original is removed, the link will be broken.\nYou create soft links using the -s option of ln :\n26\nln -s <original> <link>\nFor example, say you have a file called recipes.txt.\nYou can create a soft link to it using:\nln -s recipes.txt newrecipes.txt\nIn this case you can see there's a special l flag\nwhen you list the file using ls -al , and the file name\nhas a @ at the end, and it's colored differently if you\nhave colors enabled:\nNow if you delete the original file, the links will be\nbroken, and the shell will tell you \"No such file or\ndirectory\" if you try to access it:\n27\ngzip\nYou can compress a file using the gzip compression\nprotocol named LZ77 using the gzip command.\nHere's the simplest usage:\ngzip filename\nThis will compress the file, and append a .gz\nextension to it. The original file is deleted. To prevent\nthis, you can use the -c option and use output\nredirection to write the output to the filename.gz file:\ngzip -c filename > filename.gz\nThe -c option specifies that output will go to the\nstandard output stream, leaving the original file\nintact\nOr you can use the -k option:\ngzip -k filename\nThere are various levels of compression. The more\nthe compression, the longer it will take to compress\n(and decompress). Levels range from 1 (fastest, worst\ncompression) to 9 (slowest, better compression), and\nthe default is 6.\nYou can choose a specific level with the -<NUMBER>\noption:\n28\ngzip -1 filename\nYou can compress multiple files by listing them:\ngzip filename1 filename2\nYou can compress all the files in a directory,\nrecursively, using the -r option:\ngzip -r a_folder\nThe -v option prints the compression percentage\ninformation. Here's an example of it being used along\nwith the -k (keep) option:\ngzip can also be used to decompress a file, using\nthe -d option:\ngzip -d filename.gz\n29\ngunzip\nThe gunzip command is basically equivalent to the\ngzip command, except the -d option is always\nenabled by default.\nThe command can be invoked in this way:\ngunzip filename.gz\nThis will gunzip and will remove the .gz extension,\nputting the result in the filename file. If that file exists,\nit will overwrite that.\nYou can extract to a different filename using output\nredirection using the -c option:\ngunzip -c filename.gz > anotherfilename\n30\ntar\nThe tar command is used to create an archive,\ngrouping multiple files in a single file.\nIts name comes from the past and means tape\narchive. Back when archives were stored on tapes.\nThis command creates an archive named\narchive.tar with the content of file1 and file2 :\ntar -cf archive.tar file1 file2\nThe c option stands for create. The f option is\nused to write to file the archive.\nTo extract files from an archive in the current folder,\nuse:\ntar -xf archive.tar\nthe x option stands for extract\nand to extract them to a specific directory, use:\ntar -xf archive.tar -C directory\nYou can also just list the files contained in an archive:\n31\ntar is often used to create a compressed archive,\ngzipping the archive.\nThis is done using the z option:\ntar -czf archive.tar.gz file1 file2\nThis is just like creating a tar archive, and then running\ngzip on it.\nTo unarchive a gzipped archive, you can use gunzip ,\nor gzip -d , and then unarchive it, but tar -xf will\nrecognize it's a gzipped archive, and do it for you:\ntar -xf archive.tar.gz\n32\nalias\nIt's common to always run a program with a set of\noptions you like using.\nFor example, take the ls command. By default it\nprints very little information:\nwhile using the -al option it will print something\nmore useful, including the file modification date, the\nsize, the owner, and the permissions, also listing\nhidden files (files starting with a . :\nYou can create a new command, for example I like to\ncall it ll , that is an alias to ls -al .\nYou do it in this way:\n33\nalias ll='ls -al'\nOnce you do, you can call ll just like it was a\nregular UNIX command:\nNow calling alias without any option will list the\naliases defined:\nThe alias will work until the terminal session is closed.\nTo make it permanent, you need to add it to the shell\nconfiguration, which could be ~/.bashrc or\n~/.profile or ~/.bash_profile if you use the Bash\nshell, depending on the use case.\nBe careful with quotes if you have variables in the\ncommand: using double quotes the variable is\nresolved at definition time, using single quotes it's\nresolved at invocation time. Those 2 are different:\n34\nalias lsthis=\"ls $PWD\"\nalias lscurrent='ls $PWD'\n$PWD refers to the current folder the shell is into. If\nyou now navigate away to a new folder, lscurrent\nlists the files in the new folder, lsthis still lists the\nfiles in the folder you were when you defined the alias.\n35\ncat\nSimilar to tail in some way, we have cat . Except\ncat can also add content to a file, and this makes it\nsuper powerful.\nIn its simplest usage, cat prints a file's content to the\nstandard output:\ncat file\nYou can print the content of multiple files:\ncat file1 file2\nand using the output redirection operator > you can\nconcatenate the content of multiple files into a new\nfile:\ncat file1 file2 > file3\nUsing >> you can append the content of multiple files\ninto a new file, creating it if it does not exist:\ncat file1 file2 >> file3\nWhen watching source code files it's great to see the\nline numbers, and you can have cat print them using\nthe -n option:\ncat -n file1\n36\nYou can only add a number to non-blank lines using -\nb , or you can also remove all the multiple empty lines\nusing -s .\ncat is often used in combination with the pipe\noperator | to feed a file content as input to another\ncommand: cat file1 | anothercommand .\n37\nless\nThe less command is one I use a lot. It shows you\nthe content stored inside a file, in a nice and\ninteractive UI.\nUsage: less <filename> .\nOnce you are inside a less session, you can quit by\npressing q .\nYou can navigate the file contents using the up and\ndown keys, or using the space bar and b to\nnavigate page by page. You can also jump to the end\nof the file pressing G and jump back to the start\npressing g .\nYou can search contents inside the file by pressing /\nand typing a word to search. This searches forward.\nYou can search backwards using the ? symbol and\ntyping a word.\n38\nThis command just visualises the file's content. You\ncan directly open an editor by pressing v . It will use\nthe system editor, which in most cases is vim .\nPressing the F key enters follow mode, or watch\nmode. When the file is changed by someone else, like\nfrom another program, you get to see the changes\nlive. By default this is not happening, and you only see\nthe file version at the time you opened it. You need to\npress ctrl-C to quit this mode. In this case the\nbehaviour is similar to running the tail -f\n<filename> command.\nYou can open multiple files, and navigate through\nthem using :n (to go to the next file) and :p (to go\nto the previous).\n39\ntail\nThe best use case of tail in my opinion is when called\nwith the -f option. It opens the file at the end, and\nwatches for file changes. Any time there is new\ncontent in the file, it is printed in the window. This is\ngreat for watching log files, for example:\ntail -f /var/log/system.log\nTo exit, press ctrl-C .\nYou can print the last 10 lines in a file:\ntail -n 10 <filename>\nYou can print the whole file content starting from a\nspecific line using + before the line number:\ntail -n +10 <filename>\ntail can do much more and as always my advice is\nto check man tail .\n40\nwc\nThe wc command gives us useful information about\na file or input it receives via pipes.\necho test >> test.txt\nwc test.txt\n1 1 5 test.txt\nExample via pipes, we can count the output of running\nthe ls -al command:\nls -al | wc\n6 47 284\nThe first column returned is the number of lines. The\nsecond is the number of words. The third is the\nnumber of bytes.\nWe can tell it to just count the lines:\nwc -l test.txt\nor just the words:\nwc -w test.txt\nor just the bytes:\nwc -c test.txt\n41\nBytes in ASCII charsets equate to characters, but with\nnon-ASCII charsets, the number of characters might\ndiffer because some characters might take multiple\nbytes, for example this happens in Unicode.\nIn this case the -m flag will help getting the correct\nvalue:\nwc -m test.txt\n42\ngrep\nThe grep command is a very useful tool, that when\nyou master will help you tremendously in your day to\nday.\nIf you're wondering, grep stands for global\nregular expression print\nYou can use grep to search in files, or combine it\nwith pipes to filter the output of another command.\nFor example here's how we can find the occurences of\nthe document.getElementById line in the index.md file:\ngrep document.getElementById index.md\nUsing the -n option it will show the line numbers:\ngrep -n document.getElementById index.md\n43\nOne very useful thing is to tell grep to print 2 lines\nbefore, and 2 lines after the matched line, to give us\nmore context. That's done using the -C option, which\naccepts a number of lines:\ngrep -nC 2 document.getElementById index.md\nSearch is case sensitive by default. Use the -i flag\nto make it insensitive.\nAs mentioned, you can use grep to filter the output of\nanother command. We can replicate the same\nfunctionality as above using:\nless index.md | grep -n document.getElementById\nThe search string can be a regular expression, and\nthis makes grep very powerful.\n44\nAnother thing you might find very useful is to invert the\nresult, excluding the lines that match a particular\nstring, using the -v option:\n45\nsort\nSuppose you have a text file which contains the\nnames of dogs:\nThis list is unordered.\nThe sort command helps us sorting them by name:\nUse the r option to reverse the order:\n46\nSorting by default is case sensitive, and alphabetic.\nUse the --ignore-case option to sort case insensitive,\nand the -n option to sort using a numeric order.\nIf the file contains duplicate lines:\nYou can use the -u option to remove them:\n47\nsort does not just works on files, as many UNIX\ncommands it also works with pipes, so you can use on\nthe output of another command, for example you can\norder the files returned by ls with:\nls | sort\nsort is very powerful and has lots more options,\nwhich you can explore calling man sort .\n48\n49\nuniq\nuniq is a command useful to sort lines of text.\nYou can get those lines from a file, or using pipes from\nthe output of another command:\nuniq dogs.txt\nls | uniq\nYou need to consider this key thing: uniq will only\ndetect adjacent duplicate lines.\nThis implies that you will most likely use it along with\nsort :\nsort dogs.txt | uniq\nThe sort command has its own way to remove\nduplicates with the -u (unique) option. But uniq has\nmore power.\nBy default it removes duplicate lines:\n50\nYou can tell it to only display duplicate lines, for\nexample, with the -d option:\nsort dogs.txt | uniq -d\n51\nYou can use the -u option to only display non-\nduplicate lines:\nYou can count the occurrences of each line with the -\nc option:\n52\nUse the special combination:\nsort dogs.txt | uniq -c | sort -nr\nto then sort those lines by most frequent:\n53\ndiff\ndiff is a handy command. Suppose you have 2\nfiles, which contain almost the same information, but\nyou can't find the difference between the two.\ndiff will process the files and will tell you what's the\ndifference.\nSuppose you have 2 files: dogs.txt and\nmoredogs.txt . The difference is that moredogs.txt\ncontains one more dog name:\ndiff dogs.txt moredogs.txt will tell you the second\nfile has one more line, line 3 with the line Vanille :\n54\nIf you invert the order of the files, it will tell you that the\nsecond file is missing line 3, whose content is\nVanille :\nUsing the -y option will compare the 2 files line by\nline:\nThe -u option however will be more familiar to you,\nbecause that's the same used by the Git version\ncontrol system to display differences between\nversions:\nComparing directories works in the same way. You\nmust use the -r option to compare recursively\n(going into subdirectories):\n55\nIn case you're interested in which files differ, rather\nthan the content, use the r and q options:\nThere are many more options you can explore in the\nman page running man diff :\n56\n57\necho\nThe echo command does one simple job: it prints to\nthe output the argument passed to it.\nThis example:\necho \"hello\"\nwill print hello to the terminal.\nWe can append the output to a file:\necho \"hello\" >> output.txt\nWe can interpolate environment variables:\necho \"The path variable is $PATH\"\nBeware that special characters need to be escaped\nwith a backslash \\ . $ for example:\n58\nThis is just the start. We can do some nice things\nwhen it comes to interacting with the shell features.\nWe can echo the files in the current folder:\necho *\nWe can echo the files in the current folder that start\nwith the letter o :\necho o*\nAny valid Bash (or any shell you are using) command\nand feature can be used here.\nYou can print your home folder path:\necho ~\nYou can also execute commands, and print the result\nto the standard output (or to file, as you saw):\necho $(ls -al)\n59\nNote that whitespace is not preserved by default. You\nneed to wrap the command in double quotes to do so:\nYou can generate a list of strings, for example ranges:\necho {1..5}\n60\nchown\nEvery file/directory in an Operating System like Linux\nor macOS (and every UNIX systems in general) has\nan owner.\nThe owner of a file can do everything with it. It can\ndecide the fate of that file.\nThe owner (and the root user) can change the\nowner to another user, too, using the chown\ncommand:\nchown <owner> <file>\nLike this:\nchown flavio test.txt\nFor example if you have a file that's owned by root ,\nyou can't write to it as another user:\nYou can use chown to transfer the ownership to you:\n61\nIt's rather common to have the need to change the\nownership of a directory, and recursively all the files\ncontained, plus all the subdirectories and the files\ncontained in them, too.\nYou can do so using the -R flag:\nchown -R <owner> <file>\nFiles/directories don't just have an owner, they also\nhave a group. Through this command you can\nchange that simultaneously while you change the\nowner:\nchown <owner>:<group> <file>\nExample:\nchown flavio:users test.txt\nYou can also just change the group of a file using the\nchgrp command:\nchgrp <group> <filename>\n62\nchmod\nEvery file in the Linux / macOS Operating Systems\n(and UNIX systems in general) has 3 permissions:\nRead, write, execute.\nGo into a folder, and run the ls -al command.\nThe weird strings you see on each file line, like drwxr-\nxr-x , define the permissions of the file or folder.\nLet's dissect it.\nThe first letter indicates the type of file:\n- means it's a normal file\nd means it's a directory\nl means it's a link\nThen you have 3 sets of values:\nThe first set represents the permissions of the\nowner of the file\nThe second set represents the permissions of the\nmembers of the group the file is associated to\n63\nThe third set represents the permissions of the\neveryone else\nThose sets are composed by 3 values. rwx means\nthat specific persona has read, write and execution\naccess. Anything that is removed is swapped with a\n- , which lets you form various combinations of\nvalues and relative permissions: rw- , r-- , r-x ,\nand so on.\nYou can change the permissions given to a file using\nthe chmod command.\nchmod can be used in 2 ways. The first is using\nsymbolic arguments, the second is using numeric\narguments. Let's start with symbols first, which is more\nintuitive.\nYou type chmod followed by a space, and a letter:\na stands for all\nu stands for user\ng stands for group\no stands for others\nThen you type either + or - to add a permission, or\nto remove it. Then you enter one or more permissions\nsymbols ( r , w , x ).\nAll followed by the file or folder name.\nHere are some examples:\nchmod a+r filename #everyone can now read\nchmod a+rw filename #everyone can now read and write\nchmod o-rwx filename #others (not the owner, not in\n64\nYou can apply the same permissions to multiple\npersonas by adding multiple letters before the + / - :\nchmod og-r filename #other and group can't read any\nIn case you are editing a folder, you can apply the\npermissions to every file contained in that folder using\nthe -r (recursive) flag.\nNumeric arguments are faster but I find them hard to\nremember when you are not using them day to day.\nYou use a digit that represents the permissions of the\npersona. This number value can be a maximum of 7,\nand it's calculated in this way:\n1 if has execution permission\n2 if has write permission\n4 if has read permission\nThis gives us 4 combinations:\n0 no permissions\n1 can execute\n2 can write\n3 can write, execute\n4 can read\n5 can read, execute\n6 can read, write\n7 can read, write and execute\nWe use them in pairs of 3, to set the permissions of all\nthe 3 groups altogether:\n65\nchmod 777 filename\nchmod 755 filename\nchmod 644 filename\n66\numask\nWhen you create a file, you don't have to decide\npermissions up front. Permissions have defaults.\nThose defaults can be controlled and modified using\nthe umask command.\nTyping umask with no arguments will show you the\ncurrent umask, in this case 0022 :\nWhat does 0022 mean? That's an octal value that\nrepresent the permissions.\nAnother common value is 0002 .\nUse umask -S to see a human-readable notation:\nIn this case, the user ( u ), owner of the file, has read,\nwrite and execution permissions on files.\n67\nOther users belonging to the same group ( g ) have\nread and execution permission, same as all the other\nusers ( o ).\nIn the numeric notation, we typically change the last 3\ndigits.\nHere's a list that gives a meaning to the number:\n0 read, write, execute\n1 read and write\n2 read and execute\n3 read only\n4 write and execute\n5 write only\n6 execute only\n7 no permissions\nNote that this numeric notation differs from the one we\nuse in chmod .\nWe can set a new value for the mask setting the value\nin numeric format:\numask 002\nor you can change a specific role's permission:\numask g+r\n68\ndu\nThe du command will calculate the size of a directory\nas a whole:\ndu\nThe 32 number here is a value expressed in bytes.\nRunning du * will calculate the size of each file\nindividually:\nYou can set du to display values in MegaBytes using\ndu -m , and GigaBytes using du -g .\n69\nThe -h option will show a human-readable notation\nfor sizes, adapting to the size:\nAdding the -a option will print the size of each file in\nthe directories, too:\nA handy thing is to sort the directories by size:\ndu -h <directory> | sort -nr\nand then piping to head to only get the first 10\nresults:\n70\n71\ndf\nThe df command is used to get disk usage\ninformation.\nIts basic form will print information about the volumes\nmounted:\nUsing the -h option ( df -h ) will show those values\nin a human-readable format:\nYou can also specify a file or directory name to get\ninformation about the specific volume it lives on:\n72\nbasename\nSuppose you have a path to a file, for example\n/Users/flavio/test.txt .\nRunning\nbasename /Users/flavio/test.txt\nwill return the test.txt string:\nIf you run basename on a path string that points to a\ndirectory, you will get the last segment of the path. In\nthis example, /Users/flavio is a directory:\n73\ndirname\nSuppose you have a path to a file, for example\n/Users/flavio/test.txt .\nRunning\ndirname /Users/flavio/test.txt\nwill return the /Users/flavio string:\n74\nps\nYour computer is running, at all times, tons of different\nprocesses.\nYou can inspect them all using the ps command:\nThis is the list of user-initiated processes currently\nrunning in the current session.\nHere I have a few fish shell instances, mostly\nopened by VS Code inside the editor, and an\ninstances of Hugo running the development preview of\na site.\nThose are just the commands assigned to the current\nuser. To list all processes we need to pass some\noptions to ps .\nThe most common I use is ps ax :\n75\nThe a option is used to also list other users\nprocesses, not just our own. x shows processes\nnot linked to any terminal (not initiated by users\nthrough a terminal).\nAs you can see, the longer commands are cut. Use\nthe command ps axww to continue the command\nlisting on a new line instead of cutting it:\nWe need to specify w 2 times to apply this\nsetting, it's not a typo.\n76\nYou can search for a specific process combining\ngrep with a pipe, like this:\nps axww | grep \"Visual Studio Code\"\nThe columns returned by ps represent some key\ninformation.\nThe first information is PID , the process ID. This is\nkey when you want to reference this process in\nanother command, for example to kill it.\nThen we have TT that tells us the terminal id used.\nThen STAT tells us the state of the process:\nI a process that is idle (sleeping for longer than\nabout 20 seconds) R a runnable process S a\nprocess that is sleeping for less than about 20\nseconds T a stopped process U a process in\nuninterruptible wait Z a dead process (a zombie)\nIf you have more than one letter, the second\nrepresents further information, which can be very\ntechnical.\n77\nIt's common to have + which indicates the process is\nin the foreground in its terminal. s means the\nprocess is a session leader.\nTIME tells us how long the process has been running.\n78\ntop\nA quick guide to the top command, used to list the\nprocesses running in real time\nThe top command is used to display dynamic real-\ntime information about running processes in the\nsystem.\nIt's really handy to understand what is going on.\nIts usage is simple, you just type top , and the\nterminal will be fully immersed in this new view:\nThe process is long-running. To quit, you can type the\nq letter or ctrl-C .\nThere's a lot of information being given to us: the\nnumber of processes, how many are running or\nsleeping, the system load, the CPU usage, and a lot\nmore.\n79\nBelow, the list of processes taking the most memory\nand CPU is constantly updated.\nBy default, as you can see from the %CPU column\nhighlighted, they are sorted by the CPU used.\nYou can add a flag to sort processes by memory\nutilized:\ntop -o mem\n80\nkill\nLinux processes can receive signals and react to\nthem.\nThat's one way we can interact with running programs.\nThe kill program can send a variety of signals to a\nprogram.\nIt's not just used to terminate a program, like the name\nwould suggest, but that's its main job.\nWe use it in this way:\nkill <PID>\nBy default, this sends the TERM signal to the process\nid specified.\nWe can use flags to send other signals, including:\nkill -HUP <PID>\nkill -INT <PID>\nkill -KILL <PID>\nkill -TERM <PID>\nkill -CONT <PID>\nkill -STOP <PID>\nHUP means hang up. It's sent automatically when a\nterminal window that started a process is closed\nbefore terminating the process.\n81\nINT means interrupt, and it sends the same signal\nused when we press ctrl-C in the terminal, which\nusually terminates the process.\nKILL is not sent to the process, but to the operating\nsystem kernel, which immediately stops and\nterminates the process.\nTERM means terminate. The process will receive it\nand terminate itself. It's the default signal sent by\nkill .\nCONT means continue. It can be used to resume a\nstopped process.\nSTOP is not sent to the process, but to the operating\nsystem kernel, which immediately stops (but does not\nterminate) the process.\nYou might see numbers used instead, like kill -1\n<PID> . In this case,\n1 corresponds to HUP . 2 corresponds to INT . 9\ncorresponds to KILL . 15 corresponds to TERM .\n18 corresponds to CONT . 15 corresponds to\nSTOP .\n82\nkillall\nSimilar to the kill command, killall instead of\nsending a signal to a specific process id will send the\nsignal to multiple processes at once.\nThis is the syntax:\nkillall <name>\nwhere name is the name of a program. For example\nyou can have multiple instances of the top program\nrunning, and killall top will terminate them all.\nYou can specify the signal, like with kill (and check\nthe kill tutorial to read more about the specific\nkinds of signals we can send), for example:\nkillall -HUP top\n83\njobs\nWhen we run a command in Linux / macOS, we can\nset it to run in the background using the & symbol\nafter the command. For example we can run top in\nthe background:\ntop &\nThis is very handy for long-running programs.\nWe can get back to that program using the fg\ncommand. This works fine if we just have one job in\nthe background, otherwise we need to use the job\nnumber: fg 1 , fg 2 and so on. To get the job\nnumber, we use the jobs command.\nSay we run top & and then top -o mem & , so we\nhave 2 top instances running. jobs will tell us this:\nNow we can switch back to one of those using fg\n<jobid> . To stop the program again we can hit cmd-\nZ .\nRunning jobs -l will also print the process id of each\njob.\n84\nbg\nWhen a command is running you can suspend it using\nctrl-Z .\nThe command will immediately stop, and you get back\nto the shell terminal.\nYou can resume the execution of the command in the\nbackground, so it will keep running but it will not\nprevent you from doing other work in the terminal.\nIn this example I have 2 commands stopped:\nI can run bg 1 to resume in the background the\nexecution of the job #1.\nI could have also said bg without any option, as the\ndefault is to pick the job #1 in the list.\n85\nfg\nWhen a command is running in the background,\nbecause you started it with & at the end (example:\ntop & or because you put it in the background with\nthe bg command, you can put it to the foreground\nusing fg .\nRunning\nfg\nwill resume to the foreground the last job that was\nsuspended.\nYou can also specify which job you want to resume to\nthe foreground passing the job number, which you can\nget using the jobs command.\nRunning fg 2 will resume job #2:\n86\n87\ntype\nA command can be one of those 4 types:\nan executable\na shell built-in program\na shell function\nan alias\nThe type command can help figure out this, in case\nwe want to know or we're just curious. It will tell you\nhow the command will be interpreted.\nThe output will depend on the shell used. This is Bash:\nThis is Zsh:\n88\nThis is Fish:\n89\nOne of the most interesting things here is that for\naliases it will tell you what is aliasing to. You can see\nthe ll alias, in the case of Bash and Zsh, but Fish\nprovides it by default, so it will tell you it's a built-in\nshell function.\n90\nwhich\nSuppose you have a command you can execute,\nbecause it's in the shell path, but you want to know\nwhere it is located.\nYou can do so using which . The command will return\nthe path to the command specified:\nwhich will only work for executables stored on disk,\nnot aliases or built-in shell functions.\n91\nnohup\nSometimes you have to run a long-lived process on a\nremote machine, and then you need to disconnect.\nOr you simply want to prevent the command to be\nhalted if there's any network issue between you and\nthe server.\nThe way to make a command run even after you log\nout or close the session to a server is to use the\nnohup command.\nUse nohup <command> to let the process continue\nworking even after you log out.\n92\nxargs\nThe xargs command is used in a UNIX shell to\nconvert input from standard input into arguments to a\ncommand.\nIn other words, through the use of xargs the output\nof a command is used as the input of another\ncommand.\nHere's the syntax you will use:\ncommand1 | xargs command2\nWe use a pipe ( | ) to pass the output to xargs . That\nwill take care of running the command2 command,\nusing the output of command1 as its argument(s).\nLet's do a simple example. You want to remove some\nspecific files from a directory. Those files are listed\ninside a text file.\nWe have 3 files: file1 , file2 , file3 .\nIn todelete.txt we have a list of files we want to\ndelete, in this example file1 and file3 :\n93\nWe will channel the output of cat todelete.txt to the\nrm command, through xargs .\nIn this way:\ncat todelete.txt | xargs rm\nThat's the result, the files we listed are now deleted:\nThe way it works is that xargs will run rm 2 times,\none for each line returned by cat .\nThis is the simplest usage of xargs . There are\nseveral options we can use.\nOne of the most useful in my opinion, especially when\nstarting to learn xargs , is -p . Using this option will\nmake xargs print a confirmation prompt with the\naction it's going to take:\n94\nThe -n option lets you tell xargs to perform one\niteration at a time, so you can individually confirm\nthem with -p . Here we tell xargs to perform one\niteration at a time with -n1 :\nThe -I option is another widely used one. It allows\nyou to get the output into a placeholder, and then you\ncan do various things.\nOne of them is to run multiple commands:\ncommand1 | xargs -I % /bin/bash -c 'command2 %; comm\nYou can swap the % symbol I used above with\nanything else, it's a variable\n95\nvim\nvim is a very popular file editor, especially among\nprogrammers. It's actively developed and frequently\nupdated, and there's a very big community around it.\nThere's even a Vim conference!\nvi in modern systems is just an alias to vim , which\nmeans vi i m proved.\nYou start it by running vi on the command line.\nYou can specify a filename at invocation time to edit\nthat specific file:\nvi test.txt\n96\nYou have to know that Vim has 2 main modes:\ncommand (or normal) mode\ninsert mode\nWhen you start the editor, you are in command mode.\nYou can't enter text like you expect from a GUI-based\neditor. You have to enter insert mode. You can do this\nby pressing the i key. Once you do so, the --\nINSERT -- word appear at the bottom of the editor:\nNow you can start typing and filling the screen with the\nfile contents:\n97\nYou can move around the file with the arrow keys, or\nusing the h - j - k - l keys. h-l for left-right,\nj-k for down-up.\nOnce you are done editing you can press the esc\nkey to exit insert mode, and go back to command\nmode.\nAt this point you can navigate the file, but you can't\nadd content to it (and be careful which keys you press\nas they might be commands).\nOne thing you might want to do now is saving the file.\nYou can do so by pressing : (colon), then w .\n98\nYou can save and quit pressing : then w and q :\n:wq\nYou can quit without saving, pressing : then q\nand ! : :q!\nYou can undo and edit by going to command mode\nand pressing u . You can redo (cancel an undo) by\npressing ctrl-r .\nThose are the basics of working with Vim. From here\nstarts a rabbit hole we can't go into in this little\nintroduction.\nI will only mention those commands that will get you\nstarted editing with Vim:\npressing the x key deletes the character\ncurrently highlighted\npressing A goes at the end of the currently\nselected line\npress 0 to go to the start of the line\ngo to the first character of a word and press d\nfollowed by w to delete that word. If you follow it\nwith e instead of w , the white space before the\nnext word is preserved\nuse a number between d and w to delete more\nthan 1 word, for example use d3w to delete 3\nwords forward\npress d followed by d to delete a whole entire\nline. Press d followed by $ to delete the entire\nline from where the cursor is, until the end\nTo find out more about Vim I can recommend the Vim\nFAQ and especially running the vimtutor command,\nwhich should already be installed in your system and\n99\nwill greatly help you start your vim explorations.\n100\nemacs\nemacs is an awesome editor and it's historically\nregarded as the editor for UNIX systems. Famously\nvi vs emacs flame wars and heated discussions\ncaused many unproductive hours for developers\naround the world.\nemacs is very powerful. Some people use it all day\nlong as a kind of operating system\n(https://news.ycombinator.com/item?id=19127258).\nWe'll just talk about the basics here.\nYou can open a new emacs session simply by\ninvoking emacs :\n101\nmacOS users, stop a second now. If you are on\nLinux there are no problems, but macOS does not\nship applications using GPLv3, and every built-in\nUNIX command that has been updated to GPLv3\nhas not been updated. While there is a little\nproblem with the commands I listed up to now, in\nthis case using an emacs version from 2007 is not\nexactly the same as using a version with 12 years\nof improvements and change. This is not a\nproblem with Vim, which is up to date. To fix this,\nrun brew install emacs and running emacs will\nuse the new version from Homebrew (make sure\nyou have Homebrew installed)\nYou can also edit an existing file calling emacs\n<filename> :\nYou can start editing and once you are done, press\nctrl-x followed by ctrl-w . You confirm the folder:\n102\nand Emacs tell you the file exists, asking you if it\nshould overwrite it:\nAnswer y , and you get a confirmation of success:\n103\nYou can exit Emacs pressing ctrl-x followed by\nctrl-c . Or ctrl-x followed by c (keep ctrl\npressed).\nThere is a lot to know about Emacs. More than I am\nable to write in this little introduction. I encourage you\nto open Emacs and press ctrl-h r to open the\nbuilt-in manual and ctrl-h t to open the official\ntutorial.\n104\nnano\nnano is a beginner friendly editor.\nRun it using nano <filename> .\nYou can directly type characters into the file without\nworrying about modes.\nYou can quit without editing using ctrl-X . If you\nedited the file buffer, the editor will ask you for\nconfirmation and you can save the edits, or discard\nthem. The help at the bottom shows you the keyboard\ncommands that let you work with the file:\npico is more or less the same, although nano is the\nGNU version of pico which at some point in history\nwas not open source and the nano clone was made\nto satisfy the GNU operating system license\nrequirements.\n105\nwhoami\nType whoami to print the user name currently logged\nin to the terminal session:\nNote: this is different from the who am i\ncommand, which prints more information\n106\nwho\nThe who command displays the users logged in to\nthe system.\nUnless you're using a server multiple people have\naccess to, chances are you will be the only user\nlogged in, multiple times:\nWhy multiple times? Because each shell opened will\ncount as an access.\nYou can see the name of the terminal used, and the\ntime/day the session was started.\nThe -aH flags will tell who to display more\ninformation, including the idle time and the process ID\nof the terminal:\n107\nThe special who am i command will list the current\nterminal session details:\n108\nsu\nWhile you're logged in to the terminal shell with one\nuser, you might have the need to switch to another\nuser.\nFor example you're logged in as root to perform some\nmaintenance, but then you want to switch to a user\naccount.\nYou can do so with the su command:\nsu <username>\nFor example: su flavio .\nIf you're logged in as a user, running su without\nanything else will prompt to enter the root user\npassword, as that's the default behavior.\nsu will start a new shell as another user.\nWhen you're done, typing exit in the shell will close\nthat shell, and will return back to the current user's\nshell.\n109\nsudo\nsudo is commonly used to run a command as root.\nYou must be enabled to use sudo , and once you do,\nyou can run commands as root by entering your user's\npassword (not the root user password).\nThe permissions are highly configurable, which is\ngreat especially in a multi-user server environment,\nand some users can be granted access to running\nspecific commands through sudo .\nFor example you can edit a system configuration file:\nsudo nano /etc/hosts\nwhich would otherwise fail to save since you don't\nhave the permissions for it.\nYou can run sudo -i to start a shell as root:\nYou can use sudo to run commands as any user.\nroot is the default, but use the -u option to specify\nanother user:\n110\nsudo -u flavio ls /Users/flavio\n111\npasswd\nUsers in Linux have a password assigned. You can\nchange the password using the passwd command.\nThere are two situations here.\nThe first is when you want to change your password.\nIn this case you type:\npasswd\nand an interactive prompt will ask you for the old\npassword, then it will ask you for the new one:\nWhen you're root (or have superuser privileges) you\ncan set the username of which you want to change the\npassword:\npasswd <username> <new password>\nIn this case you don't need to enter the old one.\n112\nping\nThe ping command pings a specific network host, on\nthe local network or on the Internet.\nYou use it with the syntax ping <host> where\n<host> could be a domain name, or an IP address.\nHere's an example pinging google.com :\nThe commands sends a request to the server, and the\nserver returns a response.\nping keep sending the request every second, by\ndefault, and will keep running until you stop it with\nctrl-C , unless you pass the number of times you\nwant to try with the -c option: ping -c 2 google.com .\nOnce ping is stopped, it will print some statistics\nabout the results: the percentage of packages lost,\nand statistics about the network performance.\nAs you can see the screen prints the host IP address,\nand the time that it took to get the response back.\n113\nNot all servers support pinging, in case the requests\ntimes out:\nSometimes this is done on purpose, to \"hide\" the\nserver, or just to reduce the load. The ping packets\ncan also be filtered by firewalls.\nping works using the ICMP protocol (Internet\nControl Message Protocol), a network layer protocol\njust like TCP or UDP.\nThe request sends a packet to the server with the\nECHO_REQUEST message, and the server returns a\nECHO_REPLY message. I won't go into details, but this\nis the basic concept.\nPinging a host is useful to know if the host is\nreachable (supposing it implements ping), and how\ndistant it is in terms of how long it takes to get back to\nyou. Usually the nearest the server is geographically,\nthe less time it will take to return back to you, for\nsimple physical laws that cause a longer distance to\nintroduce more delay in the cables.\n114\ntraceroute\nWhen you try to reach a host on the Internet, you go\nthrough your home router, then you reach your ISP\nnetwork, which in turn goes through its own upstream\nnetwork router, and so on, until you finally reach the\nhost.\nHave you ever wanted to know what are the steps that\nyour packets go through to do that?\nThe traceroute command is made for this.\nYou invoke\ntraceroute <host>\nand it will (slowly) gather all the information while the\npacket travels.\nIn this example I tried reaching for my blog with\ntraceroute flaviocopes.com :\n115\nNot every router travelled returns us information. In\nthis case, traceroute prints * * * . Otherwise, we\ncan see the hostname, the IP address, and some\nperformance indicator.\nFor every router we can see 3 samples, which means\ntraceroute tries by default 3 times to get you a good\nindication of the time needed to reach it. This is why it\ntakes this long to execute traceroute compared to\nsimply doing a ping to that host.\nYou can customize this number with the -q option:\ntraceroute -q 1 flaviocopes.com\n116\nclear\nType clear to clear all the previous commands that\nwere ran in the current terminal.\nThe screen will clear and you will just see the prompt\nat the top:\nNote: this command has a handy shortcut: ctrl-\nL\nOnce you do that, you will lose access to scrolling to\nsee the output of the previous commands entered.\nSo you might want to use clear -x instead, which\nstill clears the screen, but lets you go back to see the\nprevious work by scrolling up.\n117\nhistory\nEvery time we run a command, that's memorized in\nthe history.\nYou can display all the history using:\nhistory\nThis shows the history with numbers:\nYou can use the syntax !<command number> to repeat\na command stored in the history, in the above\nexample typing !121 will repeat the ls -al | wc -l\ncommand.\nTypically the last 500 commands are stored in the\nhistory.\nYou can combine this with grep to find a command\nyou ran:\nhistory | grep docker\n118\nTo clear the history, run history -c\n119\nexport\nThe export command is used to export variables to\nchild processes.\nWhat does this mean?\nSuppose you have a variable TEST defined in this\nway:\nTEST=\"test\"\nYou can print its value using echo $TEST :\nBut if you try defining a Bash script in a file script.sh\nwith the above command:\n120\nThen you set chmod u+x script.sh and you execute\nthis script with ./script.sh , the echo $TEST line will\nprint nothing!\nThis is because in Bash the TEST variable was\ndefined local to the shell. When executing a shell\nscript or another command, a subshell is launched to\nexecute it, which does not contain the current shell\nlocal variables.\nTo make the variable available there we need to define\nTEST not in this way:\nTEST=\"test\"\nbut in this way:\nexport TEST=\"test\"\nTry that, and running ./script.sh now should print\n\"test\":\nSometimes you need to append something to a\nvariable. It's often done with the PATH variable. You\nuse this syntax:\nexport PATH=$PATH:/new/path\n121\nIt's common to use export when you create new\nvariables in this way, but also when you create\nvariables in the .bash_profile or .bashrc\nconfiguration files with Bash, or in .zshenv with Zsh.\nTo remove a variable, use the -n option:\nexport -n TEST\nCalling export without any option will list all the\nexported variables.\n122\ncrontab\nCron jobs are jobs that are scheduled to run at specific\nintervals. You might have a command perform\nsomething every hour, or every day, or every 2 weeks.\nOr on weekends. They are very powerful, especially\non servers to perform maintenance and automations.\nThe crontab command is the entry point to work with\ncron jobs.\nThe first thing you can do is to explore which cron jobs\nare defined by you:\ncrontab -l\nYou might have none, like me:\nRun\ncrontab -e\nto edit the cron jobs, and add new ones.\n123\nBy default this opens with the default editor, which is\nusually vim . I like nano more, you can use this line\nto use a different editor:\nEDITOR=nano crontab -e\nNow you can add one line for each cron job.\nThe syntax to define cron jobs is kind of scary. This is\nwhy I usually use a website to help me generate it\nwithout errors: https://crontab-generator.org/\nYou pick a time interval for the cron job, and you type\nthe command to execute.\n124\nI chose to run a script located in\n/Users/flavio/test.sh every 12 hours. This is the\ncrontab line I need to run:\n* */12 * * * /Users/flavio/test.sh >/dev/null 2>&1\nI run crontab -e :\nEDITOR=nano crontab -e\nand I add that line, then I press ctrl-X and press y\nto save.\nIf all goes well, the cron job is set up:\nOnce this is done, you can see the list of active cron\njobs by running:\ncrontab -l\n125\nYou can remove a cron job running crontab -e again,\nremoving the line and exiting the editor:\n126\nuname\nCalling uname without any options will return the\nOperating System codename:\nThe m option shows the hardware name ( x86_64 in\nthis example) and the p option prints the processor\narchitecture name ( i386 in this example):\nThe s option prints the Operating System name. r\nprints the release, v prints the version:\n127\nThe n option prints the node network name:\nThe a option prints all the information available:\n128\nOn macOS you can also use the sw_vers command\nto print more information about the macOS Operating\nSystem. Note that this differs from the Darwin (the\nKernel) version, which above is 19.6.0 .\nDarwin is the name of the kernel of macOS. The\nkernel is the \"core\" of the Operating System, while\nthe Operating System as a whole is called\nmacOS. In Linux, Linux is the kernel, GNU/Linux\nwould be the Operating System name, although\nwe all refer to it as \"Linux\"\n129\nenv\nThe env command can be used to pass environment\nvariables without setting them on the outer\nenvironment (the current shell).\nSuppose you want to run a Node.js app and set the\nUSER variable to it.\nYou can run\nenv USER=flavio node app.js\nand the USER environment variable will be accessible\nfrom the Node.js app via the Node process.env\ninterface.\nYou can also run the command clearing all the\nenvironment variables already set, using the -i\noption:\nenv -i node app.js\nIn this case you will get an error saying env: node: No\nsuch file or directory because the node command\nis not reachable, as the PATH variable used by the\nshell to look up commands in the common paths is\nunset.\nSo you need to pass the full path to the node\nprogram:\nenv -i /usr/local/bin/node app.js\n130\nTry with a simple app.js file with this content:\nconsole.log(process.env.NAME)\nconsole.log(process.env.PATH)\nYou will see the output being\nundefined\nundefined\nYou can pass an env variable:\nenv -i NAME=flavio node app.js\nand the output will be\nflavio\nundefined\nRemoving the -i option will make PATH available\nagain inside the program:\nThe env command can also be used to print out all\nthe environment variables, if ran with no options:\nenv\n131\nit will return a list of the environment variables set, for\nexample:\nHOME=/Users/flavio\nLOGNAME=flavio\nPATH=/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/L\nPWD=/Users/flavio\nSHELL=/usr/local/bin/fish\nYou can also make a variable inaccessible inside the\nprogram you run, using the -u option, for example\nthis code removes the HOME variable from the\ncommand environment:\nenv -u HOME node app.js\n132\nprintenv\nA quick guide to the printenv command, used to\nprint the values of environment variables\nIn any shell there are a good number of environment\nvariables, set either by the system, or by your own\nshell scripts and configuration.\nYou can print them all to the terminal using the\nprintenv command. The output will be something\nlike this:\nHOME=/Users/flavio\nLOGNAME=flavio\nPATH=/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/L\nPWD=/Users/flavio\nSHELL=/usr/local/bin/fish\nwith a few more lines, usually.\nYou can append a variable name as a parameter, to\nonly show that variable value:\nprintenv PATH\n133\nConclusion\nThanks a lot for reading this book.\nI hope it will inspire you to know more about Linux and\nits capabilities.\nTo learn more, check out my blog flaviocopes.com.\nSend any feedback, errata or opinions at\nhey@flaviocopes.com\n134"
  }
]